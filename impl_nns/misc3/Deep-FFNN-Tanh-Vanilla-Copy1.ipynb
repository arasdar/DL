{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # layers\n",
    "        self.C = C # classes\n",
    "        self.losses = {'train':[], 'train_acc':[], \n",
    "                       'valid':[], 'valid_acc':[], \n",
    "                       'test':[], 'test_acc':[]}\n",
    "        \n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.dy_prev = np.zeros((1, C))\n",
    "        self.y_prev = np.zeros((1, C))\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Output layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "        dX = dout @ W.T # vanilla Backprop\n",
    "#         dX = dout @ W_fixed.T # fba backprop\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = l.tanh_forward(X=y)\n",
    "#         y, nl_cache = l.sigmoid_forward(X=y)\n",
    "        if train:\n",
    "            caches.append((fc_cache, nl_cache))\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = l.tanh_forward(X=y)\n",
    "#             y, nl_cache = l.sigmoid_forward(X=y)\n",
    "            X = y.copy() # pass to next layer\n",
    "            if train:\n",
    "                fc_caches.append(fc_cache)\n",
    "                nl_caches.append(nl_cache)\n",
    "        if train:\n",
    "            caches.append((fc_caches, nl_caches)) # caches[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        y_prob = l.softmax(X=y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "\n",
    "        return y_prob, caches # for backpropating the error\n",
    "\n",
    "    def cross_entropy(self, y_prob, y_train):\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(y_prob[range(m), y_train] + l.eps) # to avoid the devision by zero\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_prob, y_train): # this is equal for both since the reg_loss (noise) derivative is ZERO.\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         grad_y = l.softmax(y_pred)\n",
    "        grad_y = y_prob\n",
    "        grad_y[range(m), y_train] -= 1.\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y_prob, y_train):\n",
    "        \n",
    "        loss = self.cross_entropy(y_prob, y_train) # softmax is included\n",
    "        dy = self.dcross_entropy(y_prob, y_train) # dsoftmax is included\n",
    "\n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, y):\n",
    "        grads = self.grads.copy() # initialized by Zero in every iteration/epoch\n",
    "#         dy_prev = self.dy_prev.copy() # for temporal differencing\n",
    "#         self.dy_prev = dy.copy() # next iteration/ epoch\n",
    "#         y_prev = self.y_prev.copy() # for temporal differencing\n",
    "#         self.y_prev = y.copy() # next iteration/ epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        # softmax_backward is included in dcross_entropy.\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "# #         dy =  dy @ self.W_fixed[2].T # done\n",
    "#         dy_prev =  dy_prev @ self.W_fixed[2].T\n",
    "#         y =  y @ self.W_fixed[2].T # done\n",
    "#         y_prev =  y_prev @ self.W_fixed[2].T\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "            dy = l.tanh_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "#             dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "# #             dy =  dy @ self.W_fixed[2].T # done\n",
    "#             dy_prev =  dy_prev @ self.W_fixed[1][layer].T\n",
    "#             y =  y @ self.W_fixed[1][layer].T # done\n",
    "#             y_prev =  y_prev @ self.W_fixed[1][layer].T\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "        dy = l.tanh_backward(cache=nl_cache, dout=dy) # diffable function\n",
    "#         dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#         dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "#         dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_prob, _ = self.train_forward(X, train=False)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_prob\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y_prob, caches = self.train_forward(X_mini, train=True)\n",
    "            _, dy = self.loss_function(y_prob, y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, y_prob)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "            \n",
    "            # Training accuracy\n",
    "            y_pred, y_prob = self.test(X_mini)\n",
    "            loss, _ = self.loss_function(y_prob, y_mini) # softmax is included in entropy loss function\n",
    "            self.losses['train'].append(loss)\n",
    "            acc = np.mean(y_pred == y_mini) # confusion matrix\n",
    "            self.losses['train_acc'].append(acc)\n",
    "\n",
    "            # Validate the updated model\n",
    "            y_pred, y_prob = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_prob, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Test the final model\n",
    "            y_pred, y_prob = nn.test(X_test)\n",
    "            test_loss, _ = self.loss_function(y_prob, y_test) # softmax is included in entropy loss function\n",
    "            self.losses['test'].append(test_loss)\n",
    "            test_acc = np.mean(y_pred == y_test)\n",
    "            self.losses['test_acc'].append(test_acc)\n",
    "#             print('Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.\n",
    "#             format(acc.mean(), acc.std(), loss))\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{}, train loss-{:.4f}, acc-{:.4f}, valid loss-{:.4f}, acc-{:.4f}, test loss-{:.4f}, acc-{:.4f}'.format(\n",
    "                   iter, loss, acc, valid_loss, valid_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10, train loss-2.3335, acc-0.0200, valid loss-2.3323, acc-0.0604, test loss-2.3323, acc-0.0637\n",
      "Iter-20, train loss-2.3206, acc-0.0400, valid loss-2.3297, acc-0.0636, test loss-2.3295, acc-0.0660\n",
      "Iter-30, train loss-2.3172, acc-0.0400, valid loss-2.3269, acc-0.0664, test loss-2.3267, acc-0.0679\n",
      "Iter-40, train loss-2.3234, acc-0.0800, valid loss-2.3241, acc-0.0690, test loss-2.3237, acc-0.0708\n",
      "Iter-50, train loss-2.3217, acc-0.0600, valid loss-2.3214, acc-0.0708, test loss-2.3210, acc-0.0733\n",
      "Iter-60, train loss-2.3392, acc-0.0400, valid loss-2.3184, acc-0.0728, test loss-2.3179, acc-0.0768\n",
      "Iter-70, train loss-2.3430, acc-0.0000, valid loss-2.3158, acc-0.0756, test loss-2.3151, acc-0.0796\n",
      "Iter-80, train loss-2.3152, acc-0.0800, valid loss-2.3130, acc-0.0780, test loss-2.3122, acc-0.0833\n",
      "Iter-90, train loss-2.2648, acc-0.2200, valid loss-2.3103, acc-0.0810, test loss-2.3093, acc-0.0860\n",
      "Iter-100, train loss-2.3023, acc-0.0800, valid loss-2.3075, acc-0.0842, test loss-2.3065, acc-0.0888\n",
      "Iter-110, train loss-2.3114, acc-0.0800, valid loss-2.3047, acc-0.0862, test loss-2.3035, acc-0.0921\n",
      "Iter-120, train loss-2.3113, acc-0.1200, valid loss-2.3020, acc-0.0888, test loss-2.3007, acc-0.0947\n",
      "Iter-130, train loss-2.2808, acc-0.1400, valid loss-2.2993, acc-0.0910, test loss-2.2979, acc-0.0987\n",
      "Iter-140, train loss-2.2991, acc-0.0600, valid loss-2.2966, acc-0.0948, test loss-2.2951, acc-0.1023\n",
      "Iter-150, train loss-2.3008, acc-0.0600, valid loss-2.2939, acc-0.0968, test loss-2.2923, acc-0.1067\n",
      "Iter-160, train loss-2.2879, acc-0.0800, valid loss-2.2911, acc-0.1018, test loss-2.2894, acc-0.1110\n",
      "Iter-170, train loss-2.2813, acc-0.0400, valid loss-2.2885, acc-0.1044, test loss-2.2867, acc-0.1152\n",
      "Iter-180, train loss-2.2727, acc-0.1600, valid loss-2.2857, acc-0.1078, test loss-2.2838, acc-0.1192\n",
      "Iter-190, train loss-2.2622, acc-0.1400, valid loss-2.2831, acc-0.1122, test loss-2.2812, acc-0.1230\n",
      "Iter-200, train loss-2.2785, acc-0.0200, valid loss-2.2805, acc-0.1172, test loss-2.2785, acc-0.1275\n",
      "Iter-210, train loss-2.2791, acc-0.0800, valid loss-2.2781, acc-0.1208, test loss-2.2759, acc-0.1302\n",
      "Iter-220, train loss-2.2578, acc-0.0800, valid loss-2.2753, acc-0.1268, test loss-2.2730, acc-0.1344\n",
      "Iter-230, train loss-2.2328, acc-0.1000, valid loss-2.2726, acc-0.1312, test loss-2.2702, acc-0.1395\n",
      "Iter-240, train loss-2.2719, acc-0.1200, valid loss-2.2700, acc-0.1362, test loss-2.2675, acc-0.1448\n",
      "Iter-250, train loss-2.2644, acc-0.1400, valid loss-2.2673, acc-0.1388, test loss-2.2646, acc-0.1500\n",
      "Iter-260, train loss-2.2361, acc-0.2400, valid loss-2.2646, acc-0.1428, test loss-2.2620, acc-0.1536\n",
      "Iter-270, train loss-2.2722, acc-0.0800, valid loss-2.2621, acc-0.1476, test loss-2.2593, acc-0.1588\n",
      "Iter-280, train loss-2.2362, acc-0.2000, valid loss-2.2596, acc-0.1530, test loss-2.2567, acc-0.1640\n",
      "Iter-290, train loss-2.2451, acc-0.2800, valid loss-2.2569, acc-0.1594, test loss-2.2539, acc-0.1716\n",
      "Iter-300, train loss-2.2641, acc-0.1400, valid loss-2.2542, acc-0.1658, test loss-2.2511, acc-0.1781\n",
      "Iter-310, train loss-2.2213, acc-0.2200, valid loss-2.2516, acc-0.1706, test loss-2.2484, acc-0.1843\n",
      "Iter-320, train loss-2.2547, acc-0.2200, valid loss-2.2490, acc-0.1766, test loss-2.2456, acc-0.1916\n",
      "Iter-330, train loss-2.2369, acc-0.2200, valid loss-2.2463, acc-0.1806, test loss-2.2429, acc-0.1972\n",
      "Iter-340, train loss-2.2265, acc-0.2800, valid loss-2.2436, acc-0.1860, test loss-2.2401, acc-0.2042\n",
      "Iter-350, train loss-2.2417, acc-0.1400, valid loss-2.2409, acc-0.1952, test loss-2.2373, acc-0.2124\n",
      "Iter-360, train loss-2.2395, acc-0.1800, valid loss-2.2383, acc-0.2018, test loss-2.2345, acc-0.2208\n",
      "Iter-370, train loss-2.2432, acc-0.1600, valid loss-2.2355, acc-0.2102, test loss-2.2317, acc-0.2263\n",
      "Iter-380, train loss-2.2238, acc-0.2200, valid loss-2.2328, acc-0.2170, test loss-2.2289, acc-0.2344\n",
      "Iter-390, train loss-2.2321, acc-0.3400, valid loss-2.2300, acc-0.2238, test loss-2.2260, acc-0.2438\n",
      "Iter-400, train loss-2.2694, acc-0.1400, valid loss-2.2276, acc-0.2314, test loss-2.2234, acc-0.2517\n",
      "Iter-410, train loss-2.2249, acc-0.2400, valid loss-2.2250, acc-0.2394, test loss-2.2206, acc-0.2605\n",
      "Iter-420, train loss-2.2267, acc-0.2800, valid loss-2.2224, acc-0.2506, test loss-2.2180, acc-0.2701\n",
      "Iter-430, train loss-2.2509, acc-0.1800, valid loss-2.2198, acc-0.2588, test loss-2.2153, acc-0.2778\n",
      "Iter-440, train loss-2.1841, acc-0.4200, valid loss-2.2171, acc-0.2662, test loss-2.2125, acc-0.2884\n",
      "Iter-450, train loss-2.1995, acc-0.3600, valid loss-2.2146, acc-0.2726, test loss-2.2099, acc-0.2962\n",
      "Iter-460, train loss-2.2097, acc-0.3200, valid loss-2.2120, acc-0.2766, test loss-2.2072, acc-0.3041\n",
      "Iter-470, train loss-2.1888, acc-0.3200, valid loss-2.2095, acc-0.2840, test loss-2.2045, acc-0.3108\n",
      "Iter-480, train loss-2.2440, acc-0.2000, valid loss-2.2069, acc-0.2930, test loss-2.2019, acc-0.3178\n",
      "Iter-490, train loss-2.1882, acc-0.4000, valid loss-2.2044, acc-0.3000, test loss-2.1992, acc-0.3233\n",
      "Iter-500, train loss-2.1926, acc-0.3600, valid loss-2.2019, acc-0.3076, test loss-2.1966, acc-0.3296\n",
      "Iter-510, train loss-2.2047, acc-0.3200, valid loss-2.1994, acc-0.3156, test loss-2.1940, acc-0.3356\n",
      "Iter-520, train loss-2.1862, acc-0.3400, valid loss-2.1968, acc-0.3216, test loss-2.1913, acc-0.3420\n",
      "Iter-530, train loss-2.1916, acc-0.4000, valid loss-2.1942, acc-0.3278, test loss-2.1886, acc-0.3492\n",
      "Iter-540, train loss-2.1978, acc-0.3200, valid loss-2.1916, acc-0.3336, test loss-2.1860, acc-0.3546\n",
      "Iter-550, train loss-2.1901, acc-0.4000, valid loss-2.1889, acc-0.3386, test loss-2.1833, acc-0.3605\n",
      "Iter-560, train loss-2.1904, acc-0.3400, valid loss-2.1864, acc-0.3460, test loss-2.1806, acc-0.3685\n",
      "Iter-570, train loss-2.2059, acc-0.3200, valid loss-2.1839, acc-0.3500, test loss-2.1781, acc-0.3742\n",
      "Iter-580, train loss-2.1753, acc-0.4000, valid loss-2.1814, acc-0.3560, test loss-2.1755, acc-0.3789\n",
      "Iter-590, train loss-2.1893, acc-0.3600, valid loss-2.1788, acc-0.3592, test loss-2.1729, acc-0.3850\n",
      "Iter-600, train loss-2.1523, acc-0.4200, valid loss-2.1761, acc-0.3650, test loss-2.1701, acc-0.3910\n",
      "Iter-610, train loss-2.1731, acc-0.4400, valid loss-2.1736, acc-0.3710, test loss-2.1675, acc-0.3958\n",
      "Iter-620, train loss-2.1506, acc-0.4800, valid loss-2.1711, acc-0.3766, test loss-2.1649, acc-0.4009\n",
      "Iter-630, train loss-2.1737, acc-0.4000, valid loss-2.1686, acc-0.3812, test loss-2.1624, acc-0.4057\n",
      "Iter-640, train loss-2.1665, acc-0.3000, valid loss-2.1661, acc-0.3856, test loss-2.1597, acc-0.4114\n",
      "Iter-650, train loss-2.1571, acc-0.4400, valid loss-2.1636, acc-0.3896, test loss-2.1571, acc-0.4147\n",
      "Iter-660, train loss-2.1409, acc-0.6200, valid loss-2.1610, acc-0.3936, test loss-2.1545, acc-0.4190\n",
      "Iter-670, train loss-2.1616, acc-0.3600, valid loss-2.1587, acc-0.3962, test loss-2.1521, acc-0.4227\n",
      "Iter-680, train loss-2.1692, acc-0.3400, valid loss-2.1560, acc-0.4002, test loss-2.1493, acc-0.4273\n",
      "Iter-690, train loss-2.1690, acc-0.4600, valid loss-2.1535, acc-0.4036, test loss-2.1467, acc-0.4306\n",
      "Iter-700, train loss-2.1607, acc-0.4200, valid loss-2.1510, acc-0.4056, test loss-2.1442, acc-0.4345\n",
      "Iter-710, train loss-2.1708, acc-0.2800, valid loss-2.1487, acc-0.4110, test loss-2.1418, acc-0.4380\n",
      "Iter-720, train loss-2.1446, acc-0.3600, valid loss-2.1462, acc-0.4154, test loss-2.1392, acc-0.4417\n",
      "Iter-730, train loss-2.1222, acc-0.4400, valid loss-2.1436, acc-0.4204, test loss-2.1365, acc-0.4452\n",
      "Iter-740, train loss-2.1206, acc-0.5200, valid loss-2.1410, acc-0.4252, test loss-2.1339, acc-0.4494\n",
      "Iter-750, train loss-2.1613, acc-0.3600, valid loss-2.1385, acc-0.4282, test loss-2.1314, acc-0.4532\n",
      "Iter-760, train loss-2.1370, acc-0.4600, valid loss-2.1359, acc-0.4330, test loss-2.1286, acc-0.4567\n",
      "Iter-770, train loss-2.1493, acc-0.4600, valid loss-2.1333, acc-0.4358, test loss-2.1259, acc-0.4591\n",
      "Iter-780, train loss-2.1191, acc-0.4200, valid loss-2.1308, acc-0.4390, test loss-2.1233, acc-0.4611\n",
      "Iter-790, train loss-2.1149, acc-0.5000, valid loss-2.1283, acc-0.4412, test loss-2.1207, acc-0.4633\n",
      "Iter-800, train loss-2.1185, acc-0.4200, valid loss-2.1260, acc-0.4442, test loss-2.1183, acc-0.4656\n",
      "Iter-810, train loss-2.0819, acc-0.5000, valid loss-2.1232, acc-0.4482, test loss-2.1155, acc-0.4692\n",
      "Iter-820, train loss-2.1128, acc-0.4800, valid loss-2.1207, acc-0.4498, test loss-2.1128, acc-0.4717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-830, train loss-2.1227, acc-0.4600, valid loss-2.1180, acc-0.4524, test loss-2.1101, acc-0.4733\n",
      "Iter-840, train loss-2.1561, acc-0.4000, valid loss-2.1156, acc-0.4560, test loss-2.1076, acc-0.4750\n",
      "Iter-850, train loss-2.0905, acc-0.5000, valid loss-2.1130, acc-0.4588, test loss-2.1049, acc-0.4776\n",
      "Iter-860, train loss-2.0961, acc-0.5400, valid loss-2.1106, acc-0.4620, test loss-2.1024, acc-0.4798\n",
      "Iter-870, train loss-2.1269, acc-0.4400, valid loss-2.1080, acc-0.4652, test loss-2.0998, acc-0.4825\n",
      "Iter-880, train loss-2.1107, acc-0.4400, valid loss-2.1053, acc-0.4694, test loss-2.0971, acc-0.4846\n",
      "Iter-890, train loss-2.0969, acc-0.4400, valid loss-2.1028, acc-0.4710, test loss-2.0944, acc-0.4863\n",
      "Iter-900, train loss-2.1438, acc-0.3400, valid loss-2.1003, acc-0.4726, test loss-2.0918, acc-0.4886\n",
      "Iter-910, train loss-2.1117, acc-0.4000, valid loss-2.0978, acc-0.4762, test loss-2.0892, acc-0.4910\n",
      "Iter-920, train loss-2.0459, acc-0.5800, valid loss-2.0952, acc-0.4786, test loss-2.0865, acc-0.4932\n",
      "Iter-930, train loss-2.1061, acc-0.4600, valid loss-2.0925, acc-0.4812, test loss-2.0838, acc-0.4957\n",
      "Iter-940, train loss-2.0780, acc-0.4600, valid loss-2.0900, acc-0.4840, test loss-2.0812, acc-0.4972\n",
      "Iter-950, train loss-2.1220, acc-0.4400, valid loss-2.0875, acc-0.4884, test loss-2.0786, acc-0.4989\n",
      "Iter-960, train loss-2.0911, acc-0.5400, valid loss-2.0850, acc-0.4904, test loss-2.0762, acc-0.5006\n",
      "Iter-970, train loss-2.0760, acc-0.5200, valid loss-2.0825, acc-0.4928, test loss-2.0735, acc-0.5022\n",
      "Iter-980, train loss-2.0860, acc-0.5400, valid loss-2.0799, acc-0.4946, test loss-2.0710, acc-0.5032\n",
      "Iter-990, train loss-2.0929, acc-0.4400, valid loss-2.0773, acc-0.4962, test loss-2.0682, acc-0.5048\n",
      "Iter-1000, train loss-2.0774, acc-0.5200, valid loss-2.0747, acc-0.4974, test loss-2.0655, acc-0.5056\n",
      "Iter-1010, train loss-2.0633, acc-0.5400, valid loss-2.0721, acc-0.4998, test loss-2.0629, acc-0.5074\n",
      "Iter-1020, train loss-2.0321, acc-0.6200, valid loss-2.0696, acc-0.5022, test loss-2.0603, acc-0.5092\n",
      "Iter-1030, train loss-2.0634, acc-0.5800, valid loss-2.0671, acc-0.5036, test loss-2.0577, acc-0.5104\n",
      "Iter-1040, train loss-2.0275, acc-0.7000, valid loss-2.0645, acc-0.5042, test loss-2.0551, acc-0.5113\n",
      "Iter-1050, train loss-2.0869, acc-0.4600, valid loss-2.0619, acc-0.5054, test loss-2.0524, acc-0.5122\n",
      "Iter-1060, train loss-2.0791, acc-0.4200, valid loss-2.0592, acc-0.5064, test loss-2.0497, acc-0.5137\n",
      "Iter-1070, train loss-2.0942, acc-0.4800, valid loss-2.0567, acc-0.5084, test loss-2.0471, acc-0.5158\n",
      "Iter-1080, train loss-2.0734, acc-0.4400, valid loss-2.0541, acc-0.5096, test loss-2.0445, acc-0.5165\n",
      "Iter-1090, train loss-2.0552, acc-0.5400, valid loss-2.0517, acc-0.5128, test loss-2.0420, acc-0.5179\n",
      "Iter-1100, train loss-2.0512, acc-0.4800, valid loss-2.0492, acc-0.5128, test loss-2.0394, acc-0.5194\n",
      "Iter-1110, train loss-2.0851, acc-0.5000, valid loss-2.0467, acc-0.5132, test loss-2.0369, acc-0.5208\n",
      "Iter-1120, train loss-2.0491, acc-0.5400, valid loss-2.0440, acc-0.5148, test loss-2.0342, acc-0.5216\n",
      "Iter-1130, train loss-2.0262, acc-0.5600, valid loss-2.0414, acc-0.5162, test loss-2.0314, acc-0.5231\n",
      "Iter-1140, train loss-2.0333, acc-0.4600, valid loss-2.0388, acc-0.5162, test loss-2.0288, acc-0.5236\n",
      "Iter-1150, train loss-2.0437, acc-0.5400, valid loss-2.0362, acc-0.5188, test loss-2.0262, acc-0.5250\n",
      "Iter-1160, train loss-2.0858, acc-0.4600, valid loss-2.0337, acc-0.5202, test loss-2.0236, acc-0.5267\n",
      "Iter-1170, train loss-2.0353, acc-0.3800, valid loss-2.0311, acc-0.5218, test loss-2.0209, acc-0.5268\n",
      "Iter-1180, train loss-2.0652, acc-0.4000, valid loss-2.0286, acc-0.5240, test loss-2.0183, acc-0.5287\n",
      "Iter-1190, train loss-2.0966, acc-0.3800, valid loss-2.0260, acc-0.5246, test loss-2.0156, acc-0.5302\n",
      "Iter-1200, train loss-2.0504, acc-0.4600, valid loss-2.0234, acc-0.5250, test loss-2.0131, acc-0.5313\n",
      "Iter-1210, train loss-1.9738, acc-0.5800, valid loss-2.0208, acc-0.5260, test loss-2.0104, acc-0.5333\n",
      "Iter-1220, train loss-2.0031, acc-0.5800, valid loss-2.0183, acc-0.5266, test loss-2.0077, acc-0.5339\n",
      "Iter-1230, train loss-1.9985, acc-0.5200, valid loss-2.0158, acc-0.5270, test loss-2.0052, acc-0.5344\n",
      "Iter-1240, train loss-2.0218, acc-0.5200, valid loss-2.0132, acc-0.5284, test loss-2.0025, acc-0.5357\n",
      "Iter-1250, train loss-2.0236, acc-0.4600, valid loss-2.0106, acc-0.5286, test loss-1.9999, acc-0.5366\n",
      "Iter-1260, train loss-1.9691, acc-0.6000, valid loss-2.0082, acc-0.5302, test loss-1.9974, acc-0.5372\n",
      "Iter-1270, train loss-2.0621, acc-0.4600, valid loss-2.0056, acc-0.5316, test loss-1.9948, acc-0.5380\n",
      "Iter-1280, train loss-1.9671, acc-0.6200, valid loss-2.0029, acc-0.5312, test loss-1.9919, acc-0.5379\n",
      "Iter-1290, train loss-1.9782, acc-0.5600, valid loss-2.0003, acc-0.5324, test loss-1.9893, acc-0.5396\n",
      "Iter-1300, train loss-1.9316, acc-0.6200, valid loss-1.9978, acc-0.5338, test loss-1.9867, acc-0.5408\n",
      "Iter-1310, train loss-1.9547, acc-0.5800, valid loss-1.9951, acc-0.5358, test loss-1.9840, acc-0.5414\n",
      "Iter-1320, train loss-1.9854, acc-0.5600, valid loss-1.9925, acc-0.5354, test loss-1.9813, acc-0.5421\n",
      "Iter-1330, train loss-1.9970, acc-0.5200, valid loss-1.9900, acc-0.5362, test loss-1.9787, acc-0.5427\n",
      "Iter-1340, train loss-1.9651, acc-0.5600, valid loss-1.9874, acc-0.5366, test loss-1.9761, acc-0.5438\n",
      "Iter-1350, train loss-2.0308, acc-0.4800, valid loss-1.9849, acc-0.5386, test loss-1.9735, acc-0.5453\n",
      "Iter-1360, train loss-1.9572, acc-0.5000, valid loss-1.9824, acc-0.5390, test loss-1.9710, acc-0.5464\n",
      "Iter-1370, train loss-1.9055, acc-0.6800, valid loss-1.9796, acc-0.5384, test loss-1.9682, acc-0.5467\n",
      "Iter-1380, train loss-1.8267, acc-0.7800, valid loss-1.9770, acc-0.5390, test loss-1.9655, acc-0.5472\n",
      "Iter-1390, train loss-1.9036, acc-0.6800, valid loss-1.9743, acc-0.5386, test loss-1.9628, acc-0.5477\n",
      "Iter-1400, train loss-2.0139, acc-0.5200, valid loss-1.9718, acc-0.5388, test loss-1.9603, acc-0.5481\n",
      "Iter-1410, train loss-1.9538, acc-0.5600, valid loss-1.9693, acc-0.5408, test loss-1.9577, acc-0.5489\n",
      "Iter-1420, train loss-1.9298, acc-0.6000, valid loss-1.9666, acc-0.5400, test loss-1.9550, acc-0.5488\n",
      "Iter-1430, train loss-1.9126, acc-0.6800, valid loss-1.9639, acc-0.5402, test loss-1.9523, acc-0.5493\n",
      "Iter-1440, train loss-1.9807, acc-0.4600, valid loss-1.9613, acc-0.5404, test loss-1.9496, acc-0.5499\n",
      "Iter-1450, train loss-1.9937, acc-0.4400, valid loss-1.9589, acc-0.5414, test loss-1.9471, acc-0.5504\n",
      "Iter-1460, train loss-1.9573, acc-0.5400, valid loss-1.9565, acc-0.5414, test loss-1.9447, acc-0.5515\n",
      "Iter-1470, train loss-1.9252, acc-0.5400, valid loss-1.9538, acc-0.5424, test loss-1.9419, acc-0.5523\n",
      "Iter-1480, train loss-1.9501, acc-0.4800, valid loss-1.9512, acc-0.5424, test loss-1.9393, acc-0.5532\n",
      "Iter-1490, train loss-1.9601, acc-0.5800, valid loss-1.9486, acc-0.5428, test loss-1.9366, acc-0.5533\n",
      "Iter-1500, train loss-1.9675, acc-0.4800, valid loss-1.9460, acc-0.5436, test loss-1.9340, acc-0.5539\n",
      "Iter-1510, train loss-1.9215, acc-0.7000, valid loss-1.9436, acc-0.5444, test loss-1.9315, acc-0.5550\n",
      "Iter-1520, train loss-1.9557, acc-0.5200, valid loss-1.9410, acc-0.5452, test loss-1.9289, acc-0.5558\n",
      "Iter-1530, train loss-1.9106, acc-0.5200, valid loss-1.9385, acc-0.5454, test loss-1.9263, acc-0.5562\n",
      "Iter-1540, train loss-1.9491, acc-0.5600, valid loss-1.9357, acc-0.5462, test loss-1.9235, acc-0.5557\n",
      "Iter-1550, train loss-1.9280, acc-0.6000, valid loss-1.9332, acc-0.5472, test loss-1.9210, acc-0.5562\n",
      "Iter-1560, train loss-1.9190, acc-0.5600, valid loss-1.9306, acc-0.5480, test loss-1.9183, acc-0.5567\n",
      "Iter-1570, train loss-1.8905, acc-0.6200, valid loss-1.9280, acc-0.5486, test loss-1.9157, acc-0.5568\n",
      "Iter-1580, train loss-1.9135, acc-0.6400, valid loss-1.9254, acc-0.5496, test loss-1.9130, acc-0.5575\n",
      "Iter-1590, train loss-1.8725, acc-0.7200, valid loss-1.9228, acc-0.5502, test loss-1.9104, acc-0.5584\n",
      "Iter-1600, train loss-1.8875, acc-0.5800, valid loss-1.9201, acc-0.5502, test loss-1.9077, acc-0.5582\n",
      "Iter-1610, train loss-1.8634, acc-0.7200, valid loss-1.9174, acc-0.5500, test loss-1.9050, acc-0.5581\n",
      "Iter-1620, train loss-2.0666, acc-0.3200, valid loss-1.9149, acc-0.5502, test loss-1.9024, acc-0.5587\n",
      "Iter-1630, train loss-1.9723, acc-0.4800, valid loss-1.9125, acc-0.5524, test loss-1.8999, acc-0.5593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1640, train loss-1.8841, acc-0.5200, valid loss-1.9098, acc-0.5520, test loss-1.8973, acc-0.5595\n",
      "Iter-1650, train loss-1.9266, acc-0.5000, valid loss-1.9072, acc-0.5518, test loss-1.8947, acc-0.5604\n",
      "Iter-1660, train loss-1.8779, acc-0.5600, valid loss-1.9046, acc-0.5524, test loss-1.8921, acc-0.5606\n",
      "Iter-1670, train loss-1.8591, acc-0.5600, valid loss-1.9020, acc-0.5530, test loss-1.8894, acc-0.5616\n",
      "Iter-1680, train loss-1.8794, acc-0.5800, valid loss-1.8995, acc-0.5534, test loss-1.8868, acc-0.5619\n",
      "Iter-1690, train loss-1.9121, acc-0.5600, valid loss-1.8969, acc-0.5540, test loss-1.8843, acc-0.5617\n",
      "Iter-1700, train loss-1.8353, acc-0.6600, valid loss-1.8943, acc-0.5546, test loss-1.8816, acc-0.5621\n",
      "Iter-1710, train loss-1.8670, acc-0.5400, valid loss-1.8917, acc-0.5556, test loss-1.8790, acc-0.5625\n",
      "Iter-1720, train loss-1.9212, acc-0.4800, valid loss-1.8890, acc-0.5556, test loss-1.8764, acc-0.5625\n",
      "Iter-1730, train loss-1.8935, acc-0.5800, valid loss-1.8865, acc-0.5550, test loss-1.8738, acc-0.5626\n",
      "Iter-1740, train loss-1.9349, acc-0.5400, valid loss-1.8839, acc-0.5560, test loss-1.8712, acc-0.5631\n",
      "Iter-1750, train loss-1.8835, acc-0.6000, valid loss-1.8814, acc-0.5566, test loss-1.8687, acc-0.5636\n",
      "Iter-1760, train loss-1.9690, acc-0.3600, valid loss-1.8790, acc-0.5574, test loss-1.8662, acc-0.5637\n",
      "Iter-1770, train loss-1.9113, acc-0.5600, valid loss-1.8765, acc-0.5588, test loss-1.8638, acc-0.5649\n",
      "Iter-1780, train loss-1.8787, acc-0.6000, valid loss-1.8739, acc-0.5596, test loss-1.8611, acc-0.5655\n",
      "Iter-1790, train loss-1.7984, acc-0.6600, valid loss-1.8713, acc-0.5592, test loss-1.8584, acc-0.5657\n",
      "Iter-1800, train loss-1.8803, acc-0.5600, valid loss-1.8686, acc-0.5598, test loss-1.8558, acc-0.5664\n",
      "Iter-1810, train loss-1.9000, acc-0.5800, valid loss-1.8660, acc-0.5602, test loss-1.8531, acc-0.5667\n",
      "Iter-1820, train loss-1.8338, acc-0.4800, valid loss-1.8634, acc-0.5596, test loss-1.8506, acc-0.5666\n",
      "Iter-1830, train loss-1.8843, acc-0.5000, valid loss-1.8609, acc-0.5618, test loss-1.8481, acc-0.5676\n",
      "Iter-1840, train loss-1.7874, acc-0.6400, valid loss-1.8583, acc-0.5628, test loss-1.8454, acc-0.5686\n",
      "Iter-1850, train loss-1.8554, acc-0.6000, valid loss-1.8557, acc-0.5636, test loss-1.8428, acc-0.5688\n",
      "Iter-1860, train loss-1.8196, acc-0.6200, valid loss-1.8532, acc-0.5642, test loss-1.8403, acc-0.5705\n",
      "Iter-1870, train loss-1.8662, acc-0.6000, valid loss-1.8507, acc-0.5648, test loss-1.8377, acc-0.5709\n",
      "Iter-1880, train loss-1.8547, acc-0.6200, valid loss-1.8482, acc-0.5664, test loss-1.8353, acc-0.5713\n",
      "Iter-1890, train loss-1.8298, acc-0.6200, valid loss-1.8457, acc-0.5654, test loss-1.8327, acc-0.5712\n",
      "Iter-1900, train loss-1.8155, acc-0.6200, valid loss-1.8431, acc-0.5658, test loss-1.8301, acc-0.5711\n",
      "Iter-1910, train loss-1.8383, acc-0.6400, valid loss-1.8406, acc-0.5670, test loss-1.8276, acc-0.5713\n",
      "Iter-1920, train loss-1.8190, acc-0.6200, valid loss-1.8380, acc-0.5666, test loss-1.8250, acc-0.5714\n",
      "Iter-1930, train loss-1.7917, acc-0.6000, valid loss-1.8354, acc-0.5676, test loss-1.8225, acc-0.5713\n",
      "Iter-1940, train loss-1.7835, acc-0.5800, valid loss-1.8329, acc-0.5668, test loss-1.8199, acc-0.5706\n",
      "Iter-1950, train loss-1.7418, acc-0.6200, valid loss-1.8303, acc-0.5666, test loss-1.8173, acc-0.5713\n",
      "Iter-1960, train loss-1.7379, acc-0.6800, valid loss-1.8277, acc-0.5670, test loss-1.8147, acc-0.5714\n",
      "Iter-1970, train loss-1.8528, acc-0.5600, valid loss-1.8252, acc-0.5682, test loss-1.8121, acc-0.5724\n",
      "Iter-1980, train loss-1.7470, acc-0.6600, valid loss-1.8226, acc-0.5678, test loss-1.8095, acc-0.5726\n",
      "Iter-1990, train loss-1.7452, acc-0.7600, valid loss-1.8201, acc-0.5686, test loss-1.8070, acc-0.5735\n",
      "Iter-2000, train loss-1.8508, acc-0.5800, valid loss-1.8176, acc-0.5694, test loss-1.8045, acc-0.5737\n",
      "Iter-2010, train loss-1.8920, acc-0.5200, valid loss-1.8150, acc-0.5700, test loss-1.8019, acc-0.5736\n",
      "Iter-2020, train loss-1.8222, acc-0.5600, valid loss-1.8125, acc-0.5696, test loss-1.7994, acc-0.5735\n",
      "Iter-2030, train loss-1.8016, acc-0.5600, valid loss-1.8099, acc-0.5698, test loss-1.7967, acc-0.5734\n",
      "Iter-2040, train loss-1.8525, acc-0.5600, valid loss-1.8073, acc-0.5706, test loss-1.7942, acc-0.5738\n",
      "Iter-2050, train loss-1.8830, acc-0.5000, valid loss-1.8049, acc-0.5708, test loss-1.7918, acc-0.5747\n",
      "Iter-2060, train loss-1.8384, acc-0.6400, valid loss-1.8024, acc-0.5710, test loss-1.7892, acc-0.5751\n",
      "Iter-2070, train loss-1.8308, acc-0.5400, valid loss-1.7998, acc-0.5712, test loss-1.7867, acc-0.5750\n",
      "Iter-2080, train loss-1.8216, acc-0.5600, valid loss-1.7973, acc-0.5712, test loss-1.7842, acc-0.5756\n",
      "Iter-2090, train loss-1.7877, acc-0.5400, valid loss-1.7947, acc-0.5718, test loss-1.7816, acc-0.5758\n",
      "Iter-2100, train loss-1.7368, acc-0.6600, valid loss-1.7922, acc-0.5720, test loss-1.7790, acc-0.5762\n",
      "Iter-2110, train loss-1.8234, acc-0.5800, valid loss-1.7897, acc-0.5714, test loss-1.7765, acc-0.5763\n",
      "Iter-2120, train loss-1.7167, acc-0.6600, valid loss-1.7871, acc-0.5716, test loss-1.7740, acc-0.5767\n",
      "Iter-2130, train loss-1.8510, acc-0.5000, valid loss-1.7847, acc-0.5720, test loss-1.7715, acc-0.5772\n",
      "Iter-2140, train loss-1.7825, acc-0.6200, valid loss-1.7822, acc-0.5724, test loss-1.7690, acc-0.5781\n",
      "Iter-2150, train loss-1.7897, acc-0.6000, valid loss-1.7797, acc-0.5730, test loss-1.7665, acc-0.5788\n",
      "Iter-2160, train loss-1.7069, acc-0.6400, valid loss-1.7772, acc-0.5734, test loss-1.7640, acc-0.5788\n",
      "Iter-2170, train loss-1.7817, acc-0.6200, valid loss-1.7748, acc-0.5742, test loss-1.7616, acc-0.5788\n",
      "Iter-2180, train loss-1.6886, acc-0.6400, valid loss-1.7723, acc-0.5744, test loss-1.7591, acc-0.5795\n",
      "Iter-2190, train loss-1.8263, acc-0.5400, valid loss-1.7699, acc-0.5750, test loss-1.7567, acc-0.5801\n",
      "Iter-2200, train loss-1.7522, acc-0.5600, valid loss-1.7674, acc-0.5754, test loss-1.7543, acc-0.5808\n",
      "Iter-2210, train loss-1.6147, acc-0.6800, valid loss-1.7649, acc-0.5762, test loss-1.7517, acc-0.5806\n",
      "Iter-2220, train loss-1.7968, acc-0.5600, valid loss-1.7623, acc-0.5762, test loss-1.7491, acc-0.5811\n",
      "Iter-2230, train loss-1.7833, acc-0.5200, valid loss-1.7599, acc-0.5776, test loss-1.7467, acc-0.5812\n",
      "Iter-2240, train loss-1.7775, acc-0.4800, valid loss-1.7574, acc-0.5778, test loss-1.7442, acc-0.5814\n",
      "Iter-2250, train loss-1.7699, acc-0.4800, valid loss-1.7549, acc-0.5786, test loss-1.7417, acc-0.5817\n",
      "Iter-2260, train loss-1.8599, acc-0.5400, valid loss-1.7524, acc-0.5796, test loss-1.7392, acc-0.5818\n",
      "Iter-2270, train loss-1.6952, acc-0.6400, valid loss-1.7499, acc-0.5788, test loss-1.7367, acc-0.5823\n",
      "Iter-2280, train loss-1.6661, acc-0.6200, valid loss-1.7475, acc-0.5800, test loss-1.7342, acc-0.5823\n",
      "Iter-2290, train loss-1.8332, acc-0.5200, valid loss-1.7450, acc-0.5806, test loss-1.7318, acc-0.5829\n",
      "Iter-2300, train loss-1.6165, acc-0.6600, valid loss-1.7425, acc-0.5814, test loss-1.7293, acc-0.5827\n",
      "Iter-2310, train loss-1.7665, acc-0.6000, valid loss-1.7402, acc-0.5824, test loss-1.7269, acc-0.5831\n",
      "Iter-2320, train loss-1.7703, acc-0.5400, valid loss-1.7377, acc-0.5822, test loss-1.7244, acc-0.5833\n",
      "Iter-2330, train loss-1.6118, acc-0.6800, valid loss-1.7352, acc-0.5824, test loss-1.7219, acc-0.5839\n",
      "Iter-2340, train loss-1.7032, acc-0.6200, valid loss-1.7329, acc-0.5834, test loss-1.7196, acc-0.5852\n",
      "Iter-2350, train loss-1.6726, acc-0.6600, valid loss-1.7304, acc-0.5838, test loss-1.7170, acc-0.5854\n",
      "Iter-2360, train loss-1.7334, acc-0.5200, valid loss-1.7279, acc-0.5850, test loss-1.7146, acc-0.5865\n",
      "Iter-2370, train loss-1.7551, acc-0.6600, valid loss-1.7254, acc-0.5854, test loss-1.7121, acc-0.5865\n",
      "Iter-2380, train loss-1.7878, acc-0.4800, valid loss-1.7231, acc-0.5866, test loss-1.7098, acc-0.5867\n",
      "Iter-2390, train loss-1.7632, acc-0.5200, valid loss-1.7206, acc-0.5878, test loss-1.7074, acc-0.5877\n",
      "Iter-2400, train loss-1.6272, acc-0.7200, valid loss-1.7182, acc-0.5878, test loss-1.7049, acc-0.5878\n",
      "Iter-2410, train loss-1.7785, acc-0.5400, valid loss-1.7157, acc-0.5878, test loss-1.7024, acc-0.5888\n",
      "Iter-2420, train loss-1.7722, acc-0.4400, valid loss-1.7133, acc-0.5880, test loss-1.7000, acc-0.5889\n",
      "Iter-2430, train loss-1.7192, acc-0.5000, valid loss-1.7108, acc-0.5886, test loss-1.6976, acc-0.5897\n",
      "Iter-2440, train loss-1.6765, acc-0.5200, valid loss-1.7084, acc-0.5898, test loss-1.6952, acc-0.5899\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2450, train loss-1.5900, acc-0.7600, valid loss-1.7059, acc-0.5902, test loss-1.6928, acc-0.5900\n",
      "Iter-2460, train loss-1.6409, acc-0.5600, valid loss-1.7035, acc-0.5902, test loss-1.6904, acc-0.5903\n",
      "Iter-2470, train loss-1.5804, acc-0.7000, valid loss-1.7009, acc-0.5906, test loss-1.6879, acc-0.5903\n",
      "Iter-2480, train loss-1.6069, acc-0.6400, valid loss-1.6985, acc-0.5912, test loss-1.6855, acc-0.5910\n",
      "Iter-2490, train loss-1.7498, acc-0.6200, valid loss-1.6961, acc-0.5914, test loss-1.6830, acc-0.5913\n",
      "Iter-2500, train loss-1.6146, acc-0.6800, valid loss-1.6936, acc-0.5918, test loss-1.6805, acc-0.5921\n",
      "Iter-2510, train loss-1.6685, acc-0.6200, valid loss-1.6912, acc-0.5922, test loss-1.6782, acc-0.5924\n",
      "Iter-2520, train loss-1.7076, acc-0.6600, valid loss-1.6888, acc-0.5920, test loss-1.6758, acc-0.5926\n",
      "Iter-2530, train loss-1.8082, acc-0.4600, valid loss-1.6864, acc-0.5930, test loss-1.6735, acc-0.5929\n",
      "Iter-2540, train loss-1.6322, acc-0.6600, valid loss-1.6841, acc-0.5940, test loss-1.6712, acc-0.5930\n",
      "Iter-2550, train loss-1.7716, acc-0.5200, valid loss-1.6819, acc-0.5944, test loss-1.6690, acc-0.5934\n",
      "Iter-2560, train loss-1.7687, acc-0.4800, valid loss-1.6796, acc-0.5944, test loss-1.6667, acc-0.5942\n",
      "Iter-2570, train loss-1.6956, acc-0.5400, valid loss-1.6770, acc-0.5948, test loss-1.6642, acc-0.5946\n",
      "Iter-2580, train loss-1.6489, acc-0.7000, valid loss-1.6746, acc-0.5950, test loss-1.6618, acc-0.5944\n",
      "Iter-2590, train loss-1.8137, acc-0.5200, valid loss-1.6723, acc-0.5956, test loss-1.6595, acc-0.5949\n",
      "Iter-2600, train loss-1.6525, acc-0.6800, valid loss-1.6699, acc-0.5956, test loss-1.6571, acc-0.5955\n",
      "Iter-2610, train loss-1.6333, acc-0.6800, valid loss-1.6674, acc-0.5954, test loss-1.6546, acc-0.5959\n",
      "Iter-2620, train loss-1.7447, acc-0.5000, valid loss-1.6651, acc-0.5952, test loss-1.6522, acc-0.5968\n",
      "Iter-2630, train loss-1.7000, acc-0.5800, valid loss-1.6627, acc-0.5960, test loss-1.6499, acc-0.5972\n",
      "Iter-2640, train loss-1.5896, acc-0.6600, valid loss-1.6603, acc-0.5958, test loss-1.6476, acc-0.5979\n",
      "Iter-2650, train loss-1.6166, acc-0.6600, valid loss-1.6578, acc-0.5960, test loss-1.6451, acc-0.5986\n",
      "Iter-2660, train loss-1.7299, acc-0.5800, valid loss-1.6554, acc-0.5964, test loss-1.6427, acc-0.5989\n",
      "Iter-2670, train loss-1.6335, acc-0.6800, valid loss-1.6531, acc-0.5972, test loss-1.6403, acc-0.5989\n",
      "Iter-2680, train loss-1.7868, acc-0.4000, valid loss-1.6507, acc-0.5978, test loss-1.6380, acc-0.5992\n",
      "Iter-2690, train loss-1.7414, acc-0.6000, valid loss-1.6484, acc-0.5984, test loss-1.6357, acc-0.5995\n",
      "Iter-2700, train loss-1.6572, acc-0.5400, valid loss-1.6460, acc-0.5982, test loss-1.6334, acc-0.6000\n",
      "Iter-2710, train loss-1.7044, acc-0.4800, valid loss-1.6436, acc-0.5990, test loss-1.6311, acc-0.6016\n",
      "Iter-2720, train loss-1.6862, acc-0.5800, valid loss-1.6412, acc-0.6002, test loss-1.6287, acc-0.6019\n",
      "Iter-2730, train loss-1.5665, acc-0.7400, valid loss-1.6389, acc-0.5994, test loss-1.6264, acc-0.6024\n",
      "Iter-2740, train loss-1.6479, acc-0.6200, valid loss-1.6365, acc-0.6002, test loss-1.6240, acc-0.6029\n",
      "Iter-2750, train loss-1.6159, acc-0.5800, valid loss-1.6342, acc-0.6008, test loss-1.6217, acc-0.6036\n",
      "Iter-2760, train loss-1.6550, acc-0.6800, valid loss-1.6319, acc-0.6010, test loss-1.6193, acc-0.6038\n",
      "Iter-2770, train loss-1.7213, acc-0.5400, valid loss-1.6295, acc-0.6014, test loss-1.6169, acc-0.6044\n",
      "Iter-2780, train loss-1.6080, acc-0.5600, valid loss-1.6272, acc-0.6010, test loss-1.6146, acc-0.6051\n",
      "Iter-2790, train loss-1.5835, acc-0.6800, valid loss-1.6249, acc-0.6012, test loss-1.6123, acc-0.6052\n",
      "Iter-2800, train loss-1.5807, acc-0.6200, valid loss-1.6226, acc-0.6024, test loss-1.6100, acc-0.6058\n",
      "Iter-2810, train loss-1.6487, acc-0.5200, valid loss-1.6202, acc-0.6030, test loss-1.6076, acc-0.6062\n",
      "Iter-2820, train loss-1.6649, acc-0.5600, valid loss-1.6179, acc-0.6034, test loss-1.6053, acc-0.6068\n",
      "Iter-2830, train loss-1.6569, acc-0.5200, valid loss-1.6156, acc-0.6038, test loss-1.6030, acc-0.6073\n",
      "Iter-2840, train loss-1.7089, acc-0.5400, valid loss-1.6134, acc-0.6042, test loss-1.6008, acc-0.6078\n",
      "Iter-2850, train loss-1.6569, acc-0.5600, valid loss-1.6111, acc-0.6044, test loss-1.5986, acc-0.6082\n",
      "Iter-2860, train loss-1.5893, acc-0.7000, valid loss-1.6087, acc-0.6052, test loss-1.5962, acc-0.6089\n",
      "Iter-2870, train loss-1.6119, acc-0.6800, valid loss-1.6063, acc-0.6062, test loss-1.5939, acc-0.6089\n",
      "Iter-2880, train loss-1.5898, acc-0.5800, valid loss-1.6040, acc-0.6062, test loss-1.5917, acc-0.6092\n",
      "Iter-2890, train loss-1.6204, acc-0.6000, valid loss-1.6017, acc-0.6074, test loss-1.5894, acc-0.6097\n",
      "Iter-2900, train loss-1.5424, acc-0.6200, valid loss-1.5995, acc-0.6084, test loss-1.5872, acc-0.6105\n",
      "Iter-2910, train loss-1.5991, acc-0.6400, valid loss-1.5972, acc-0.6092, test loss-1.5849, acc-0.6108\n",
      "Iter-2920, train loss-1.4982, acc-0.6800, valid loss-1.5949, acc-0.6094, test loss-1.5826, acc-0.6117\n",
      "Iter-2930, train loss-1.5886, acc-0.5600, valid loss-1.5926, acc-0.6098, test loss-1.5803, acc-0.6121\n",
      "Iter-2940, train loss-1.5558, acc-0.6200, valid loss-1.5903, acc-0.6100, test loss-1.5781, acc-0.6127\n",
      "Iter-2950, train loss-1.6693, acc-0.5600, valid loss-1.5880, acc-0.6114, test loss-1.5758, acc-0.6130\n",
      "Iter-2960, train loss-1.4658, acc-0.7200, valid loss-1.5857, acc-0.6116, test loss-1.5735, acc-0.6130\n",
      "Iter-2970, train loss-1.5966, acc-0.6400, valid loss-1.5834, acc-0.6116, test loss-1.5712, acc-0.6144\n",
      "Iter-2980, train loss-1.6585, acc-0.5200, valid loss-1.5811, acc-0.6118, test loss-1.5689, acc-0.6145\n",
      "Iter-2990, train loss-1.5402, acc-0.6400, valid loss-1.5788, acc-0.6126, test loss-1.5667, acc-0.6150\n",
      "Iter-3000, train loss-1.6179, acc-0.6800, valid loss-1.5766, acc-0.6126, test loss-1.5645, acc-0.6154\n",
      "Iter-3010, train loss-1.6946, acc-0.4400, valid loss-1.5743, acc-0.6128, test loss-1.5622, acc-0.6154\n",
      "Iter-3020, train loss-1.6138, acc-0.5800, valid loss-1.5721, acc-0.6132, test loss-1.5599, acc-0.6158\n",
      "Iter-3030, train loss-1.6052, acc-0.5200, valid loss-1.5698, acc-0.6138, test loss-1.5577, acc-0.6164\n",
      "Iter-3040, train loss-1.5627, acc-0.6200, valid loss-1.5675, acc-0.6142, test loss-1.5555, acc-0.6169\n",
      "Iter-3050, train loss-1.6605, acc-0.5600, valid loss-1.5654, acc-0.6148, test loss-1.5533, acc-0.6177\n",
      "Iter-3060, train loss-1.5431, acc-0.6200, valid loss-1.5630, acc-0.6162, test loss-1.5511, acc-0.6182\n",
      "Iter-3070, train loss-1.5413, acc-0.6000, valid loss-1.5608, acc-0.6162, test loss-1.5488, acc-0.6193\n",
      "Iter-3080, train loss-1.5734, acc-0.6200, valid loss-1.5584, acc-0.6164, test loss-1.5465, acc-0.6195\n",
      "Iter-3090, train loss-1.5553, acc-0.5800, valid loss-1.5562, acc-0.6168, test loss-1.5443, acc-0.6200\n",
      "Iter-3100, train loss-1.4948, acc-0.7000, valid loss-1.5539, acc-0.6178, test loss-1.5420, acc-0.6207\n",
      "Iter-3110, train loss-1.4463, acc-0.6800, valid loss-1.5516, acc-0.6180, test loss-1.5397, acc-0.6213\n",
      "Iter-3120, train loss-1.6041, acc-0.6200, valid loss-1.5494, acc-0.6176, test loss-1.5375, acc-0.6214\n",
      "Iter-3130, train loss-1.5724, acc-0.6200, valid loss-1.5472, acc-0.6186, test loss-1.5353, acc-0.6223\n",
      "Iter-3140, train loss-1.5834, acc-0.6200, valid loss-1.5450, acc-0.6196, test loss-1.5331, acc-0.6230\n",
      "Iter-3150, train loss-1.5036, acc-0.6400, valid loss-1.5427, acc-0.6204, test loss-1.5308, acc-0.6236\n",
      "Iter-3160, train loss-1.5185, acc-0.5600, valid loss-1.5403, acc-0.6212, test loss-1.5286, acc-0.6241\n",
      "Iter-3170, train loss-1.4865, acc-0.6600, valid loss-1.5380, acc-0.6218, test loss-1.5263, acc-0.6240\n",
      "Iter-3180, train loss-1.3704, acc-0.8400, valid loss-1.5357, acc-0.6222, test loss-1.5240, acc-0.6245\n",
      "Iter-3190, train loss-1.5169, acc-0.7000, valid loss-1.5336, acc-0.6222, test loss-1.5219, acc-0.6250\n",
      "Iter-3200, train loss-1.6750, acc-0.4400, valid loss-1.5314, acc-0.6234, test loss-1.5197, acc-0.6262\n",
      "Iter-3210, train loss-1.5470, acc-0.6600, valid loss-1.5292, acc-0.6238, test loss-1.5175, acc-0.6266\n",
      "Iter-3220, train loss-1.5109, acc-0.6200, valid loss-1.5269, acc-0.6240, test loss-1.5153, acc-0.6270\n",
      "Iter-3230, train loss-1.5966, acc-0.6000, valid loss-1.5247, acc-0.6248, test loss-1.5130, acc-0.6277\n",
      "Iter-3240, train loss-1.4012, acc-0.7800, valid loss-1.5224, acc-0.6256, test loss-1.5108, acc-0.6280\n",
      "Iter-3250, train loss-1.4072, acc-0.7200, valid loss-1.5201, acc-0.6256, test loss-1.5085, acc-0.6287\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3260, train loss-1.7275, acc-0.4400, valid loss-1.5180, acc-0.6266, test loss-1.5064, acc-0.6297\n",
      "Iter-3270, train loss-1.5686, acc-0.6000, valid loss-1.5158, acc-0.6272, test loss-1.5042, acc-0.6303\n",
      "Iter-3280, train loss-1.5779, acc-0.6000, valid loss-1.5136, acc-0.6276, test loss-1.5020, acc-0.6308\n",
      "Iter-3290, train loss-1.4903, acc-0.6400, valid loss-1.5114, acc-0.6274, test loss-1.4999, acc-0.6311\n",
      "Iter-3300, train loss-1.5503, acc-0.6400, valid loss-1.5091, acc-0.6280, test loss-1.4977, acc-0.6319\n",
      "Iter-3310, train loss-1.5779, acc-0.6000, valid loss-1.5070, acc-0.6280, test loss-1.4955, acc-0.6323\n",
      "Iter-3320, train loss-1.3920, acc-0.7800, valid loss-1.5047, acc-0.6286, test loss-1.4933, acc-0.6324\n",
      "Iter-3330, train loss-1.4855, acc-0.6400, valid loss-1.5026, acc-0.6292, test loss-1.4912, acc-0.6335\n",
      "Iter-3340, train loss-1.4376, acc-0.7200, valid loss-1.5004, acc-0.6294, test loss-1.4890, acc-0.6340\n",
      "Iter-3350, train loss-1.5851, acc-0.5200, valid loss-1.4982, acc-0.6298, test loss-1.4868, acc-0.6343\n",
      "Iter-3360, train loss-1.3718, acc-0.6600, valid loss-1.4960, acc-0.6306, test loss-1.4847, acc-0.6350\n",
      "Iter-3370, train loss-1.4603, acc-0.6200, valid loss-1.4938, acc-0.6308, test loss-1.4826, acc-0.6351\n",
      "Iter-3380, train loss-1.4064, acc-0.6400, valid loss-1.4917, acc-0.6308, test loss-1.4805, acc-0.6354\n",
      "Iter-3390, train loss-1.5141, acc-0.6400, valid loss-1.4895, acc-0.6314, test loss-1.4783, acc-0.6360\n",
      "Iter-3400, train loss-1.5095, acc-0.6600, valid loss-1.4873, acc-0.6312, test loss-1.4761, acc-0.6360\n",
      "Iter-3410, train loss-1.4088, acc-0.6400, valid loss-1.4851, acc-0.6318, test loss-1.4739, acc-0.6368\n",
      "Iter-3420, train loss-1.4218, acc-0.6200, valid loss-1.4828, acc-0.6328, test loss-1.4717, acc-0.6373\n",
      "Iter-3430, train loss-1.4340, acc-0.6600, valid loss-1.4807, acc-0.6324, test loss-1.4696, acc-0.6376\n",
      "Iter-3440, train loss-1.3732, acc-0.6200, valid loss-1.4785, acc-0.6334, test loss-1.4675, acc-0.6382\n",
      "Iter-3450, train loss-1.4795, acc-0.6600, valid loss-1.4764, acc-0.6340, test loss-1.4654, acc-0.6383\n",
      "Iter-3460, train loss-1.4374, acc-0.6400, valid loss-1.4742, acc-0.6344, test loss-1.4632, acc-0.6387\n",
      "Iter-3470, train loss-1.4621, acc-0.6200, valid loss-1.4721, acc-0.6344, test loss-1.4612, acc-0.6394\n",
      "Iter-3480, train loss-1.4242, acc-0.6200, valid loss-1.4698, acc-0.6356, test loss-1.4590, acc-0.6399\n",
      "Iter-3490, train loss-1.4497, acc-0.7600, valid loss-1.4678, acc-0.6362, test loss-1.4569, acc-0.6406\n",
      "Iter-3500, train loss-1.5115, acc-0.6600, valid loss-1.4656, acc-0.6372, test loss-1.4548, acc-0.6416\n",
      "Iter-3510, train loss-1.4462, acc-0.6000, valid loss-1.4634, acc-0.6386, test loss-1.4527, acc-0.6418\n",
      "Iter-3520, train loss-1.3957, acc-0.7000, valid loss-1.4612, acc-0.6400, test loss-1.4506, acc-0.6423\n",
      "Iter-3530, train loss-1.4795, acc-0.5800, valid loss-1.4590, acc-0.6404, test loss-1.4484, acc-0.6431\n",
      "Iter-3540, train loss-1.4236, acc-0.7200, valid loss-1.4569, acc-0.6416, test loss-1.4464, acc-0.6437\n",
      "Iter-3550, train loss-1.5329, acc-0.6000, valid loss-1.4548, acc-0.6420, test loss-1.4443, acc-0.6440\n",
      "Iter-3560, train loss-1.5165, acc-0.5400, valid loss-1.4527, acc-0.6422, test loss-1.4423, acc-0.6441\n",
      "Iter-3570, train loss-1.3103, acc-0.7400, valid loss-1.4506, acc-0.6428, test loss-1.4402, acc-0.6445\n",
      "Iter-3580, train loss-1.3756, acc-0.6800, valid loss-1.4484, acc-0.6426, test loss-1.4381, acc-0.6449\n",
      "Iter-3590, train loss-1.5551, acc-0.6200, valid loss-1.4463, acc-0.6434, test loss-1.4361, acc-0.6450\n",
      "Iter-3600, train loss-1.4579, acc-0.6400, valid loss-1.4442, acc-0.6440, test loss-1.4340, acc-0.6455\n",
      "Iter-3610, train loss-1.5300, acc-0.5400, valid loss-1.4421, acc-0.6440, test loss-1.4319, acc-0.6460\n",
      "Iter-3620, train loss-1.4546, acc-0.6600, valid loss-1.4400, acc-0.6450, test loss-1.4299, acc-0.6463\n",
      "Iter-3630, train loss-1.4560, acc-0.6400, valid loss-1.4379, acc-0.6460, test loss-1.4278, acc-0.6469\n",
      "Iter-3640, train loss-1.3960, acc-0.6800, valid loss-1.4358, acc-0.6464, test loss-1.4257, acc-0.6481\n",
      "Iter-3650, train loss-1.3484, acc-0.7400, valid loss-1.4337, acc-0.6468, test loss-1.4236, acc-0.6482\n",
      "Iter-3660, train loss-1.3808, acc-0.6200, valid loss-1.4316, acc-0.6472, test loss-1.4215, acc-0.6489\n",
      "Iter-3670, train loss-1.5460, acc-0.6200, valid loss-1.4296, acc-0.6484, test loss-1.4196, acc-0.6491\n",
      "Iter-3680, train loss-1.4709, acc-0.5600, valid loss-1.4274, acc-0.6494, test loss-1.4175, acc-0.6490\n",
      "Iter-3690, train loss-1.4454, acc-0.5200, valid loss-1.4253, acc-0.6504, test loss-1.4154, acc-0.6500\n",
      "Iter-3700, train loss-1.4579, acc-0.5200, valid loss-1.4231, acc-0.6510, test loss-1.4134, acc-0.6504\n",
      "Iter-3710, train loss-1.4585, acc-0.6200, valid loss-1.4210, acc-0.6510, test loss-1.4113, acc-0.6514\n",
      "Iter-3720, train loss-1.4709, acc-0.6200, valid loss-1.4189, acc-0.6514, test loss-1.4093, acc-0.6526\n",
      "Iter-3730, train loss-1.4019, acc-0.6000, valid loss-1.4168, acc-0.6522, test loss-1.4072, acc-0.6532\n",
      "Iter-3740, train loss-1.4282, acc-0.6800, valid loss-1.4147, acc-0.6524, test loss-1.4052, acc-0.6540\n",
      "Iter-3750, train loss-1.4020, acc-0.6800, valid loss-1.4126, acc-0.6534, test loss-1.4031, acc-0.6553\n",
      "Iter-3760, train loss-1.5159, acc-0.6200, valid loss-1.4105, acc-0.6546, test loss-1.4010, acc-0.6554\n",
      "Iter-3770, train loss-1.4192, acc-0.7400, valid loss-1.4084, acc-0.6552, test loss-1.3990, acc-0.6563\n",
      "Iter-3780, train loss-1.4224, acc-0.6600, valid loss-1.4063, acc-0.6560, test loss-1.3970, acc-0.6565\n",
      "Iter-3790, train loss-1.1736, acc-0.8000, valid loss-1.4043, acc-0.6568, test loss-1.3950, acc-0.6573\n",
      "Iter-3800, train loss-1.4573, acc-0.5800, valid loss-1.4023, acc-0.6566, test loss-1.3930, acc-0.6576\n",
      "Iter-3810, train loss-1.3804, acc-0.6600, valid loss-1.4004, acc-0.6578, test loss-1.3911, acc-0.6584\n",
      "Iter-3820, train loss-1.3330, acc-0.7000, valid loss-1.3983, acc-0.6584, test loss-1.3891, acc-0.6590\n",
      "Iter-3830, train loss-1.2774, acc-0.8000, valid loss-1.3962, acc-0.6588, test loss-1.3870, acc-0.6591\n",
      "Iter-3840, train loss-1.4694, acc-0.5800, valid loss-1.3942, acc-0.6588, test loss-1.3849, acc-0.6594\n",
      "Iter-3850, train loss-1.4089, acc-0.6200, valid loss-1.3922, acc-0.6598, test loss-1.3830, acc-0.6603\n",
      "Iter-3860, train loss-1.3364, acc-0.6600, valid loss-1.3901, acc-0.6598, test loss-1.3809, acc-0.6606\n",
      "Iter-3870, train loss-1.5578, acc-0.5600, valid loss-1.3880, acc-0.6618, test loss-1.3789, acc-0.6604\n",
      "Iter-3880, train loss-1.4104, acc-0.6200, valid loss-1.3860, acc-0.6622, test loss-1.3770, acc-0.6607\n",
      "Iter-3890, train loss-1.4323, acc-0.6400, valid loss-1.3839, acc-0.6620, test loss-1.3749, acc-0.6609\n",
      "Iter-3900, train loss-1.3755, acc-0.6600, valid loss-1.3818, acc-0.6636, test loss-1.3729, acc-0.6618\n",
      "Iter-3910, train loss-1.4606, acc-0.6200, valid loss-1.3798, acc-0.6640, test loss-1.3710, acc-0.6625\n",
      "Iter-3920, train loss-1.2772, acc-0.7400, valid loss-1.3779, acc-0.6644, test loss-1.3690, acc-0.6627\n",
      "Iter-3930, train loss-1.3558, acc-0.7000, valid loss-1.3758, acc-0.6642, test loss-1.3671, acc-0.6634\n",
      "Iter-3940, train loss-1.3956, acc-0.6200, valid loss-1.3738, acc-0.6636, test loss-1.3651, acc-0.6638\n",
      "Iter-3950, train loss-1.3303, acc-0.6600, valid loss-1.3717, acc-0.6646, test loss-1.3630, acc-0.6647\n",
      "Iter-3960, train loss-1.2463, acc-0.7600, valid loss-1.3697, acc-0.6644, test loss-1.3610, acc-0.6648\n",
      "Iter-3970, train loss-1.4643, acc-0.6400, valid loss-1.3677, acc-0.6660, test loss-1.3591, acc-0.6657\n",
      "Iter-3980, train loss-1.3884, acc-0.6800, valid loss-1.3657, acc-0.6660, test loss-1.3572, acc-0.6659\n",
      "Iter-3990, train loss-1.3556, acc-0.7400, valid loss-1.3637, acc-0.6662, test loss-1.3552, acc-0.6672\n",
      "Iter-4000, train loss-1.4551, acc-0.6600, valid loss-1.3616, acc-0.6662, test loss-1.3532, acc-0.6675\n",
      "Iter-4010, train loss-1.3890, acc-0.6600, valid loss-1.3597, acc-0.6666, test loss-1.3513, acc-0.6675\n",
      "Iter-4020, train loss-1.2804, acc-0.6800, valid loss-1.3578, acc-0.6668, test loss-1.3494, acc-0.6681\n",
      "Iter-4030, train loss-1.3083, acc-0.6800, valid loss-1.3558, acc-0.6682, test loss-1.3475, acc-0.6680\n",
      "Iter-4040, train loss-1.3177, acc-0.7600, valid loss-1.3538, acc-0.6680, test loss-1.3455, acc-0.6687\n",
      "Iter-4050, train loss-1.3865, acc-0.6400, valid loss-1.3518, acc-0.6694, test loss-1.3436, acc-0.6691\n",
      "Iter-4060, train loss-1.3040, acc-0.7400, valid loss-1.3498, acc-0.6690, test loss-1.3416, acc-0.6696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4070, train loss-1.4391, acc-0.6800, valid loss-1.3479, acc-0.6684, test loss-1.3397, acc-0.6701\n",
      "Iter-4080, train loss-1.3219, acc-0.6800, valid loss-1.3459, acc-0.6686, test loss-1.3377, acc-0.6701\n",
      "Iter-4090, train loss-1.3097, acc-0.6600, valid loss-1.3438, acc-0.6704, test loss-1.3357, acc-0.6708\n",
      "Iter-4100, train loss-1.3852, acc-0.6600, valid loss-1.3418, acc-0.6716, test loss-1.3338, acc-0.6713\n",
      "Iter-4110, train loss-1.3552, acc-0.7000, valid loss-1.3398, acc-0.6724, test loss-1.3319, acc-0.6716\n",
      "Iter-4120, train loss-1.1730, acc-0.8400, valid loss-1.3378, acc-0.6740, test loss-1.3298, acc-0.6726\n",
      "Iter-4130, train loss-1.3122, acc-0.7000, valid loss-1.3357, acc-0.6740, test loss-1.3278, acc-0.6733\n",
      "Iter-4140, train loss-1.3779, acc-0.6000, valid loss-1.3338, acc-0.6742, test loss-1.3260, acc-0.6739\n",
      "Iter-4150, train loss-1.3885, acc-0.6600, valid loss-1.3318, acc-0.6756, test loss-1.3241, acc-0.6747\n",
      "Iter-4160, train loss-1.1817, acc-0.7600, valid loss-1.3299, acc-0.6746, test loss-1.3221, acc-0.6751\n",
      "Iter-4170, train loss-1.4851, acc-0.5800, valid loss-1.3280, acc-0.6748, test loss-1.3203, acc-0.6754\n",
      "Iter-4180, train loss-1.3804, acc-0.6400, valid loss-1.3260, acc-0.6758, test loss-1.3184, acc-0.6762\n",
      "Iter-4190, train loss-1.3880, acc-0.6000, valid loss-1.3241, acc-0.6784, test loss-1.3165, acc-0.6764\n",
      "Iter-4200, train loss-1.3654, acc-0.5800, valid loss-1.3221, acc-0.6786, test loss-1.3146, acc-0.6766\n",
      "Iter-4210, train loss-1.2567, acc-0.7800, valid loss-1.3201, acc-0.6784, test loss-1.3127, acc-0.6775\n",
      "Iter-4220, train loss-1.4013, acc-0.6000, valid loss-1.3182, acc-0.6788, test loss-1.3108, acc-0.6777\n",
      "Iter-4230, train loss-1.3120, acc-0.7600, valid loss-1.3164, acc-0.6790, test loss-1.3090, acc-0.6778\n",
      "Iter-4240, train loss-1.2868, acc-0.7200, valid loss-1.3145, acc-0.6794, test loss-1.3071, acc-0.6786\n",
      "Iter-4250, train loss-1.3297, acc-0.6400, valid loss-1.3126, acc-0.6798, test loss-1.3053, acc-0.6794\n",
      "Iter-4260, train loss-1.2577, acc-0.7800, valid loss-1.3107, acc-0.6802, test loss-1.3034, acc-0.6797\n",
      "Iter-4270, train loss-1.4468, acc-0.6200, valid loss-1.3088, acc-0.6806, test loss-1.3016, acc-0.6803\n",
      "Iter-4280, train loss-1.1141, acc-0.8600, valid loss-1.3070, acc-0.6804, test loss-1.2998, acc-0.6806\n",
      "Iter-4290, train loss-1.3885, acc-0.6200, valid loss-1.3051, acc-0.6810, test loss-1.2980, acc-0.6813\n",
      "Iter-4300, train loss-1.4104, acc-0.6000, valid loss-1.3033, acc-0.6816, test loss-1.2962, acc-0.6822\n",
      "Iter-4310, train loss-1.2770, acc-0.6600, valid loss-1.3014, acc-0.6818, test loss-1.2944, acc-0.6825\n",
      "Iter-4320, train loss-1.3523, acc-0.6800, valid loss-1.2997, acc-0.6814, test loss-1.2926, acc-0.6829\n",
      "Iter-4330, train loss-1.2911, acc-0.7000, valid loss-1.2978, acc-0.6820, test loss-1.2907, acc-0.6834\n",
      "Iter-4340, train loss-1.2892, acc-0.7600, valid loss-1.2959, acc-0.6830, test loss-1.2889, acc-0.6838\n",
      "Iter-4350, train loss-1.1732, acc-0.7000, valid loss-1.2941, acc-0.6832, test loss-1.2871, acc-0.6842\n",
      "Iter-4360, train loss-1.4459, acc-0.5200, valid loss-1.2923, acc-0.6842, test loss-1.2853, acc-0.6850\n",
      "Iter-4370, train loss-1.3576, acc-0.6800, valid loss-1.2904, acc-0.6858, test loss-1.2835, acc-0.6853\n",
      "Iter-4380, train loss-1.2962, acc-0.6800, valid loss-1.2886, acc-0.6860, test loss-1.2817, acc-0.6862\n",
      "Iter-4390, train loss-1.2695, acc-0.7800, valid loss-1.2868, acc-0.6872, test loss-1.2799, acc-0.6868\n",
      "Iter-4400, train loss-1.2555, acc-0.6600, valid loss-1.2849, acc-0.6878, test loss-1.2781, acc-0.6872\n",
      "Iter-4410, train loss-1.2119, acc-0.7400, valid loss-1.2831, acc-0.6884, test loss-1.2764, acc-0.6869\n",
      "Iter-4420, train loss-1.3833, acc-0.6200, valid loss-1.2814, acc-0.6878, test loss-1.2746, acc-0.6868\n",
      "Iter-4430, train loss-1.2713, acc-0.7200, valid loss-1.2796, acc-0.6876, test loss-1.2729, acc-0.6871\n",
      "Iter-4440, train loss-1.2666, acc-0.7400, valid loss-1.2779, acc-0.6880, test loss-1.2711, acc-0.6875\n",
      "Iter-4450, train loss-1.3573, acc-0.7000, valid loss-1.2761, acc-0.6886, test loss-1.2694, acc-0.6881\n",
      "Iter-4460, train loss-1.3410, acc-0.6000, valid loss-1.2743, acc-0.6894, test loss-1.2676, acc-0.6883\n",
      "Iter-4470, train loss-1.3587, acc-0.6400, valid loss-1.2725, acc-0.6908, test loss-1.2659, acc-0.6889\n",
      "Iter-4480, train loss-1.3153, acc-0.6600, valid loss-1.2708, acc-0.6908, test loss-1.2642, acc-0.6893\n",
      "Iter-4490, train loss-1.3994, acc-0.6800, valid loss-1.2690, acc-0.6926, test loss-1.2625, acc-0.6900\n",
      "Iter-4500, train loss-1.3307, acc-0.6800, valid loss-1.2672, acc-0.6930, test loss-1.2607, acc-0.6905\n",
      "Iter-4510, train loss-1.2169, acc-0.7200, valid loss-1.2654, acc-0.6922, test loss-1.2590, acc-0.6908\n",
      "Iter-4520, train loss-1.1540, acc-0.7400, valid loss-1.2636, acc-0.6922, test loss-1.2573, acc-0.6910\n",
      "Iter-4530, train loss-1.3011, acc-0.6600, valid loss-1.2618, acc-0.6936, test loss-1.2555, acc-0.6919\n",
      "Iter-4540, train loss-1.2839, acc-0.7400, valid loss-1.2599, acc-0.6946, test loss-1.2537, acc-0.6923\n",
      "Iter-4550, train loss-1.2149, acc-0.7800, valid loss-1.2582, acc-0.6934, test loss-1.2520, acc-0.6927\n",
      "Iter-4560, train loss-1.3278, acc-0.6200, valid loss-1.2564, acc-0.6940, test loss-1.2502, acc-0.6933\n",
      "Iter-4570, train loss-1.4697, acc-0.5000, valid loss-1.2546, acc-0.6958, test loss-1.2485, acc-0.6934\n",
      "Iter-4580, train loss-1.2482, acc-0.6800, valid loss-1.2528, acc-0.6968, test loss-1.2468, acc-0.6940\n",
      "Iter-4590, train loss-1.2622, acc-0.6800, valid loss-1.2511, acc-0.6974, test loss-1.2452, acc-0.6949\n",
      "Iter-4600, train loss-1.2217, acc-0.6600, valid loss-1.2493, acc-0.6978, test loss-1.2435, acc-0.6951\n",
      "Iter-4610, train loss-1.1632, acc-0.7400, valid loss-1.2476, acc-0.6984, test loss-1.2418, acc-0.6954\n",
      "Iter-4620, train loss-1.3177, acc-0.6000, valid loss-1.2459, acc-0.6982, test loss-1.2401, acc-0.6959\n",
      "Iter-4630, train loss-1.2989, acc-0.6800, valid loss-1.2441, acc-0.6990, test loss-1.2384, acc-0.6964\n",
      "Iter-4640, train loss-1.1913, acc-0.7000, valid loss-1.2423, acc-0.6992, test loss-1.2366, acc-0.6967\n",
      "Iter-4650, train loss-1.1740, acc-0.7000, valid loss-1.2406, acc-0.6998, test loss-1.2349, acc-0.6971\n",
      "Iter-4660, train loss-1.3124, acc-0.7000, valid loss-1.2388, acc-0.6998, test loss-1.2332, acc-0.6973\n",
      "Iter-4670, train loss-1.2011, acc-0.7000, valid loss-1.2370, acc-0.7004, test loss-1.2315, acc-0.6983\n",
      "Iter-4680, train loss-1.2534, acc-0.7200, valid loss-1.2353, acc-0.7006, test loss-1.2298, acc-0.6990\n",
      "Iter-4690, train loss-1.2637, acc-0.6600, valid loss-1.2336, acc-0.7014, test loss-1.2281, acc-0.6995\n",
      "Iter-4700, train loss-1.1987, acc-0.7000, valid loss-1.2318, acc-0.7014, test loss-1.2264, acc-0.7002\n",
      "Iter-4710, train loss-1.2245, acc-0.7000, valid loss-1.2301, acc-0.7022, test loss-1.2247, acc-0.7006\n",
      "Iter-4720, train loss-1.3242, acc-0.6400, valid loss-1.2284, acc-0.7028, test loss-1.2230, acc-0.7014\n",
      "Iter-4730, train loss-1.3402, acc-0.6800, valid loss-1.2267, acc-0.7034, test loss-1.2213, acc-0.7019\n",
      "Iter-4740, train loss-1.2706, acc-0.6600, valid loss-1.2250, acc-0.7036, test loss-1.2197, acc-0.7022\n",
      "Iter-4750, train loss-1.3477, acc-0.5800, valid loss-1.2232, acc-0.7048, test loss-1.2180, acc-0.7025\n",
      "Iter-4760, train loss-1.1059, acc-0.7800, valid loss-1.2216, acc-0.7054, test loss-1.2164, acc-0.7028\n",
      "Iter-4770, train loss-1.2288, acc-0.7000, valid loss-1.2199, acc-0.7058, test loss-1.2147, acc-0.7034\n",
      "Iter-4780, train loss-1.3001, acc-0.6600, valid loss-1.2181, acc-0.7068, test loss-1.2131, acc-0.7037\n",
      "Iter-4790, train loss-1.4252, acc-0.5800, valid loss-1.2165, acc-0.7068, test loss-1.2115, acc-0.7042\n",
      "Iter-4800, train loss-1.2128, acc-0.6600, valid loss-1.2148, acc-0.7070, test loss-1.2099, acc-0.7050\n",
      "Iter-4810, train loss-1.1598, acc-0.8200, valid loss-1.2131, acc-0.7072, test loss-1.2082, acc-0.7053\n",
      "Iter-4820, train loss-1.1671, acc-0.7600, valid loss-1.2115, acc-0.7086, test loss-1.2067, acc-0.7058\n",
      "Iter-4830, train loss-1.2072, acc-0.7000, valid loss-1.2098, acc-0.7082, test loss-1.2050, acc-0.7059\n",
      "Iter-4840, train loss-1.2558, acc-0.7000, valid loss-1.2081, acc-0.7088, test loss-1.2033, acc-0.7067\n",
      "Iter-4850, train loss-1.2508, acc-0.6600, valid loss-1.2064, acc-0.7086, test loss-1.2017, acc-0.7071\n",
      "Iter-4860, train loss-1.0564, acc-0.8000, valid loss-1.2047, acc-0.7096, test loss-1.2002, acc-0.7075\n",
      "Iter-4870, train loss-1.2802, acc-0.6600, valid loss-1.2030, acc-0.7104, test loss-1.1985, acc-0.7078\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4880, train loss-1.1325, acc-0.8400, valid loss-1.2015, acc-0.7110, test loss-1.1970, acc-0.7081\n",
      "Iter-4890, train loss-1.2825, acc-0.6400, valid loss-1.1998, acc-0.7114, test loss-1.1954, acc-0.7094\n",
      "Iter-4900, train loss-1.3148, acc-0.5800, valid loss-1.1982, acc-0.7120, test loss-1.1938, acc-0.7098\n",
      "Iter-4910, train loss-1.1392, acc-0.7000, valid loss-1.1966, acc-0.7122, test loss-1.1922, acc-0.7104\n",
      "Iter-4920, train loss-1.1962, acc-0.7200, valid loss-1.1950, acc-0.7124, test loss-1.1906, acc-0.7103\n",
      "Iter-4930, train loss-1.0835, acc-0.8200, valid loss-1.1933, acc-0.7122, test loss-1.1891, acc-0.7104\n",
      "Iter-4940, train loss-1.1996, acc-0.7800, valid loss-1.1918, acc-0.7134, test loss-1.1876, acc-0.7113\n",
      "Iter-4950, train loss-1.2066, acc-0.7200, valid loss-1.1901, acc-0.7136, test loss-1.1860, acc-0.7117\n",
      "Iter-4960, train loss-1.1680, acc-0.7600, valid loss-1.1885, acc-0.7130, test loss-1.1844, acc-0.7121\n",
      "Iter-4970, train loss-1.2363, acc-0.6400, valid loss-1.1869, acc-0.7138, test loss-1.1828, acc-0.7127\n",
      "Iter-4980, train loss-1.1288, acc-0.7000, valid loss-1.1852, acc-0.7142, test loss-1.1812, acc-0.7129\n",
      "Iter-4990, train loss-1.0894, acc-0.7600, valid loss-1.1836, acc-0.7148, test loss-1.1796, acc-0.7134\n",
      "Iter-5000, train loss-1.3305, acc-0.6600, valid loss-1.1820, acc-0.7156, test loss-1.1780, acc-0.7140\n",
      "Iter-5010, train loss-1.0536, acc-0.7600, valid loss-1.1804, acc-0.7154, test loss-1.1765, acc-0.7141\n",
      "Iter-5020, train loss-1.2562, acc-0.6400, valid loss-1.1789, acc-0.7154, test loss-1.1749, acc-0.7144\n",
      "Iter-5030, train loss-1.2581, acc-0.7200, valid loss-1.1773, acc-0.7162, test loss-1.1734, acc-0.7147\n",
      "Iter-5040, train loss-1.1699, acc-0.7200, valid loss-1.1757, acc-0.7172, test loss-1.1718, acc-0.7153\n",
      "Iter-5050, train loss-1.1034, acc-0.7400, valid loss-1.1741, acc-0.7178, test loss-1.1703, acc-0.7152\n",
      "Iter-5060, train loss-1.1780, acc-0.7000, valid loss-1.1725, acc-0.7184, test loss-1.1687, acc-0.7153\n",
      "Iter-5070, train loss-1.0778, acc-0.7800, valid loss-1.1709, acc-0.7188, test loss-1.1672, acc-0.7155\n",
      "Iter-5080, train loss-1.3809, acc-0.6200, valid loss-1.1694, acc-0.7188, test loss-1.1658, acc-0.7157\n",
      "Iter-5090, train loss-1.2012, acc-0.7200, valid loss-1.1679, acc-0.7194, test loss-1.1642, acc-0.7161\n",
      "Iter-5100, train loss-1.2494, acc-0.6600, valid loss-1.1664, acc-0.7194, test loss-1.1627, acc-0.7165\n",
      "Iter-5110, train loss-1.1967, acc-0.7000, valid loss-1.1648, acc-0.7196, test loss-1.1612, acc-0.7169\n",
      "Iter-5120, train loss-1.1070, acc-0.7200, valid loss-1.1632, acc-0.7202, test loss-1.1597, acc-0.7173\n",
      "Iter-5130, train loss-1.0272, acc-0.7800, valid loss-1.1619, acc-0.7204, test loss-1.1583, acc-0.7169\n",
      "Iter-5140, train loss-1.2265, acc-0.7000, valid loss-1.1603, acc-0.7208, test loss-1.1568, acc-0.7177\n",
      "Iter-5150, train loss-1.1494, acc-0.8200, valid loss-1.1587, acc-0.7206, test loss-1.1552, acc-0.7181\n",
      "Iter-5160, train loss-1.3998, acc-0.5800, valid loss-1.1572, acc-0.7210, test loss-1.1537, acc-0.7187\n",
      "Iter-5170, train loss-1.2659, acc-0.7400, valid loss-1.1557, acc-0.7212, test loss-1.1523, acc-0.7189\n",
      "Iter-5180, train loss-1.4120, acc-0.5800, valid loss-1.1542, acc-0.7216, test loss-1.1507, acc-0.7199\n",
      "Iter-5190, train loss-1.0484, acc-0.7200, valid loss-1.1526, acc-0.7222, test loss-1.1492, acc-0.7205\n",
      "Iter-5200, train loss-1.2019, acc-0.7000, valid loss-1.1510, acc-0.7234, test loss-1.1477, acc-0.7209\n",
      "Iter-5210, train loss-1.2274, acc-0.6600, valid loss-1.1495, acc-0.7240, test loss-1.1462, acc-0.7213\n",
      "Iter-5220, train loss-1.1959, acc-0.6000, valid loss-1.1480, acc-0.7246, test loss-1.1447, acc-0.7217\n",
      "Iter-5230, train loss-1.1927, acc-0.6800, valid loss-1.1465, acc-0.7252, test loss-1.1433, acc-0.7218\n",
      "Iter-5240, train loss-1.2394, acc-0.6000, valid loss-1.1450, acc-0.7252, test loss-1.1418, acc-0.7220\n",
      "Iter-5250, train loss-1.2848, acc-0.7000, valid loss-1.1435, acc-0.7256, test loss-1.1403, acc-0.7221\n",
      "Iter-5260, train loss-1.1018, acc-0.6800, valid loss-1.1419, acc-0.7254, test loss-1.1388, acc-0.7226\n",
      "Iter-5270, train loss-1.1933, acc-0.6800, valid loss-1.1404, acc-0.7270, test loss-1.1373, acc-0.7230\n",
      "Iter-5280, train loss-1.1828, acc-0.7000, valid loss-1.1389, acc-0.7270, test loss-1.1359, acc-0.7230\n",
      "Iter-5290, train loss-1.1318, acc-0.7200, valid loss-1.1375, acc-0.7276, test loss-1.1345, acc-0.7235\n",
      "Iter-5300, train loss-1.0310, acc-0.8200, valid loss-1.1359, acc-0.7286, test loss-1.1330, acc-0.7236\n",
      "Iter-5310, train loss-1.1378, acc-0.6600, valid loss-1.1345, acc-0.7286, test loss-1.1315, acc-0.7237\n",
      "Iter-5320, train loss-1.0422, acc-0.7200, valid loss-1.1330, acc-0.7296, test loss-1.1300, acc-0.7238\n",
      "Iter-5330, train loss-1.1612, acc-0.7800, valid loss-1.1314, acc-0.7296, test loss-1.1285, acc-0.7242\n",
      "Iter-5340, train loss-1.1845, acc-0.7200, valid loss-1.1299, acc-0.7300, test loss-1.1270, acc-0.7247\n",
      "Iter-5350, train loss-1.1957, acc-0.6800, valid loss-1.1284, acc-0.7296, test loss-1.1255, acc-0.7248\n",
      "Iter-5360, train loss-1.1910, acc-0.7800, valid loss-1.1269, acc-0.7298, test loss-1.1240, acc-0.7250\n",
      "Iter-5370, train loss-1.0911, acc-0.7000, valid loss-1.1254, acc-0.7310, test loss-1.1225, acc-0.7252\n",
      "Iter-5380, train loss-1.0807, acc-0.7200, valid loss-1.1239, acc-0.7308, test loss-1.1210, acc-0.7256\n",
      "Iter-5390, train loss-1.1945, acc-0.6600, valid loss-1.1224, acc-0.7314, test loss-1.1196, acc-0.7258\n",
      "Iter-5400, train loss-1.2488, acc-0.6800, valid loss-1.1209, acc-0.7320, test loss-1.1181, acc-0.7262\n",
      "Iter-5410, train loss-1.0537, acc-0.7600, valid loss-1.1194, acc-0.7322, test loss-1.1167, acc-0.7265\n",
      "Iter-5420, train loss-1.0614, acc-0.7000, valid loss-1.1180, acc-0.7316, test loss-1.1153, acc-0.7263\n",
      "Iter-5430, train loss-1.1402, acc-0.7000, valid loss-1.1165, acc-0.7320, test loss-1.1139, acc-0.7269\n",
      "Iter-5440, train loss-1.0600, acc-0.7800, valid loss-1.1151, acc-0.7324, test loss-1.1124, acc-0.7273\n",
      "Iter-5450, train loss-1.1501, acc-0.6600, valid loss-1.1137, acc-0.7322, test loss-1.1111, acc-0.7274\n",
      "Iter-5460, train loss-1.0755, acc-0.8400, valid loss-1.1123, acc-0.7328, test loss-1.1097, acc-0.7280\n",
      "Iter-5470, train loss-1.0819, acc-0.7600, valid loss-1.1109, acc-0.7316, test loss-1.1083, acc-0.7280\n",
      "Iter-5480, train loss-1.1415, acc-0.6800, valid loss-1.1094, acc-0.7326, test loss-1.1069, acc-0.7284\n",
      "Iter-5490, train loss-1.0558, acc-0.7000, valid loss-1.1080, acc-0.7330, test loss-1.1056, acc-0.7282\n",
      "Iter-5500, train loss-1.2202, acc-0.6200, valid loss-1.1066, acc-0.7336, test loss-1.1042, acc-0.7284\n",
      "Iter-5510, train loss-1.2462, acc-0.6800, valid loss-1.1051, acc-0.7340, test loss-1.1028, acc-0.7285\n",
      "Iter-5520, train loss-1.1131, acc-0.6800, valid loss-1.1037, acc-0.7340, test loss-1.1014, acc-0.7293\n",
      "Iter-5530, train loss-1.1950, acc-0.7000, valid loss-1.1023, acc-0.7340, test loss-1.1001, acc-0.7297\n",
      "Iter-5540, train loss-1.1726, acc-0.7600, valid loss-1.1009, acc-0.7342, test loss-1.0987, acc-0.7299\n",
      "Iter-5550, train loss-1.1619, acc-0.7600, valid loss-1.0995, acc-0.7344, test loss-1.0973, acc-0.7300\n",
      "Iter-5560, train loss-1.1237, acc-0.7400, valid loss-1.0981, acc-0.7348, test loss-1.0960, acc-0.7307\n",
      "Iter-5570, train loss-1.1738, acc-0.7200, valid loss-1.0967, acc-0.7350, test loss-1.0946, acc-0.7307\n",
      "Iter-5580, train loss-1.1743, acc-0.7200, valid loss-1.0952, acc-0.7358, test loss-1.0932, acc-0.7313\n",
      "Iter-5590, train loss-1.1154, acc-0.6800, valid loss-1.0938, acc-0.7358, test loss-1.0918, acc-0.7311\n",
      "Iter-5600, train loss-1.1254, acc-0.7200, valid loss-1.0923, acc-0.7366, test loss-1.0904, acc-0.7314\n",
      "Iter-5610, train loss-1.0636, acc-0.7800, valid loss-1.0910, acc-0.7368, test loss-1.0891, acc-0.7319\n",
      "Iter-5620, train loss-0.9797, acc-0.8200, valid loss-1.0896, acc-0.7374, test loss-1.0877, acc-0.7320\n",
      "Iter-5630, train loss-1.0611, acc-0.7200, valid loss-1.0883, acc-0.7370, test loss-1.0864, acc-0.7323\n",
      "Iter-5640, train loss-1.0346, acc-0.7600, valid loss-1.0870, acc-0.7372, test loss-1.0851, acc-0.7325\n",
      "Iter-5650, train loss-1.0343, acc-0.7400, valid loss-1.0856, acc-0.7372, test loss-1.0838, acc-0.7325\n",
      "Iter-5660, train loss-1.1442, acc-0.7200, valid loss-1.0843, acc-0.7376, test loss-1.0825, acc-0.7330\n",
      "Iter-5670, train loss-0.8664, acc-0.8800, valid loss-1.0830, acc-0.7378, test loss-1.0812, acc-0.7334\n",
      "Iter-5680, train loss-1.2903, acc-0.6600, valid loss-1.0816, acc-0.7378, test loss-1.0798, acc-0.7337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-5690, train loss-1.0496, acc-0.7800, valid loss-1.0803, acc-0.7380, test loss-1.0784, acc-0.7341\n",
      "Iter-5700, train loss-0.9506, acc-0.7000, valid loss-1.0790, acc-0.7380, test loss-1.0771, acc-0.7349\n",
      "Iter-5710, train loss-1.1183, acc-0.7600, valid loss-1.0776, acc-0.7376, test loss-1.0758, acc-0.7350\n",
      "Iter-5720, train loss-1.0694, acc-0.7200, valid loss-1.0762, acc-0.7376, test loss-1.0744, acc-0.7351\n",
      "Iter-5730, train loss-1.2053, acc-0.6000, valid loss-1.0748, acc-0.7386, test loss-1.0731, acc-0.7355\n",
      "Iter-5740, train loss-1.1540, acc-0.7400, valid loss-1.0735, acc-0.7390, test loss-1.0718, acc-0.7355\n",
      "Iter-5750, train loss-1.1419, acc-0.7000, valid loss-1.0722, acc-0.7386, test loss-1.0705, acc-0.7353\n",
      "Iter-5760, train loss-1.0531, acc-0.7000, valid loss-1.0709, acc-0.7394, test loss-1.0692, acc-0.7354\n",
      "Iter-5770, train loss-1.0437, acc-0.7400, valid loss-1.0696, acc-0.7396, test loss-1.0680, acc-0.7353\n",
      "Iter-5780, train loss-1.2105, acc-0.5800, valid loss-1.0683, acc-0.7396, test loss-1.0667, acc-0.7355\n",
      "Iter-5790, train loss-1.0285, acc-0.8000, valid loss-1.0670, acc-0.7398, test loss-1.0654, acc-0.7356\n",
      "Iter-5800, train loss-1.0270, acc-0.7600, valid loss-1.0657, acc-0.7402, test loss-1.0641, acc-0.7363\n",
      "Iter-5810, train loss-1.0539, acc-0.8000, valid loss-1.0644, acc-0.7404, test loss-1.0627, acc-0.7361\n",
      "Iter-5820, train loss-1.1840, acc-0.7200, valid loss-1.0632, acc-0.7400, test loss-1.0615, acc-0.7364\n",
      "Iter-5830, train loss-1.0447, acc-0.8200, valid loss-1.0619, acc-0.7402, test loss-1.0603, acc-0.7370\n",
      "Iter-5840, train loss-1.0788, acc-0.8000, valid loss-1.0606, acc-0.7410, test loss-1.0590, acc-0.7371\n",
      "Iter-5850, train loss-0.9889, acc-0.7400, valid loss-1.0593, acc-0.7414, test loss-1.0578, acc-0.7368\n",
      "Iter-5860, train loss-0.9886, acc-0.8200, valid loss-1.0580, acc-0.7414, test loss-1.0565, acc-0.7368\n",
      "Iter-5870, train loss-0.9200, acc-0.8800, valid loss-1.0567, acc-0.7414, test loss-1.0551, acc-0.7373\n",
      "Iter-5880, train loss-1.0357, acc-0.7000, valid loss-1.0554, acc-0.7422, test loss-1.0539, acc-0.7375\n",
      "Iter-5890, train loss-1.0738, acc-0.7400, valid loss-1.0541, acc-0.7426, test loss-1.0527, acc-0.7378\n",
      "Iter-5900, train loss-1.2158, acc-0.7000, valid loss-1.0529, acc-0.7430, test loss-1.0514, acc-0.7385\n",
      "Iter-5910, train loss-1.0974, acc-0.7600, valid loss-1.0516, acc-0.7434, test loss-1.0502, acc-0.7386\n",
      "Iter-5920, train loss-1.0315, acc-0.6800, valid loss-1.0504, acc-0.7440, test loss-1.0490, acc-0.7388\n",
      "Iter-5930, train loss-1.1507, acc-0.6200, valid loss-1.0491, acc-0.7440, test loss-1.0478, acc-0.7393\n",
      "Iter-5940, train loss-1.0009, acc-0.7800, valid loss-1.0479, acc-0.7438, test loss-1.0465, acc-0.7395\n",
      "Iter-5950, train loss-1.0490, acc-0.7600, valid loss-1.0466, acc-0.7446, test loss-1.0453, acc-0.7399\n",
      "Iter-5960, train loss-0.9833, acc-0.7600, valid loss-1.0453, acc-0.7448, test loss-1.0441, acc-0.7400\n",
      "Iter-5970, train loss-1.0663, acc-0.7200, valid loss-1.0441, acc-0.7448, test loss-1.0428, acc-0.7402\n",
      "Iter-5980, train loss-0.9055, acc-0.8000, valid loss-1.0428, acc-0.7446, test loss-1.0416, acc-0.7405\n",
      "Iter-5990, train loss-1.0794, acc-0.7200, valid loss-1.0417, acc-0.7448, test loss-1.0405, acc-0.7409\n",
      "Iter-6000, train loss-0.9019, acc-0.8200, valid loss-1.0404, acc-0.7452, test loss-1.0393, acc-0.7410\n",
      "Iter-6010, train loss-1.1113, acc-0.7600, valid loss-1.0392, acc-0.7450, test loss-1.0381, acc-0.7415\n",
      "Iter-6020, train loss-1.3127, acc-0.5800, valid loss-1.0380, acc-0.7450, test loss-1.0369, acc-0.7419\n",
      "Iter-6030, train loss-1.0727, acc-0.6600, valid loss-1.0368, acc-0.7448, test loss-1.0357, acc-0.7419\n",
      "Iter-6040, train loss-0.8067, acc-0.9200, valid loss-1.0356, acc-0.7448, test loss-1.0345, acc-0.7425\n",
      "Iter-6050, train loss-0.9597, acc-0.8200, valid loss-1.0344, acc-0.7448, test loss-1.0333, acc-0.7426\n",
      "Iter-6060, train loss-1.0304, acc-0.8600, valid loss-1.0332, acc-0.7450, test loss-1.0322, acc-0.7429\n",
      "Iter-6070, train loss-1.0346, acc-0.7200, valid loss-1.0320, acc-0.7444, test loss-1.0310, acc-0.7431\n",
      "Iter-6080, train loss-1.0162, acc-0.8200, valid loss-1.0307, acc-0.7448, test loss-1.0298, acc-0.7436\n",
      "Iter-6090, train loss-0.9977, acc-0.8200, valid loss-1.0296, acc-0.7456, test loss-1.0287, acc-0.7434\n",
      "Iter-6100, train loss-1.1802, acc-0.6600, valid loss-1.0284, acc-0.7460, test loss-1.0275, acc-0.7441\n",
      "Iter-6110, train loss-1.0807, acc-0.7400, valid loss-1.0272, acc-0.7464, test loss-1.0263, acc-0.7447\n",
      "Iter-6120, train loss-1.1061, acc-0.6600, valid loss-1.0259, acc-0.7460, test loss-1.0252, acc-0.7450\n",
      "Iter-6130, train loss-0.9112, acc-0.7800, valid loss-1.0247, acc-0.7464, test loss-1.0239, acc-0.7450\n",
      "Iter-6140, train loss-0.9456, acc-0.8400, valid loss-1.0235, acc-0.7464, test loss-1.0227, acc-0.7451\n",
      "Iter-6150, train loss-1.0179, acc-0.7800, valid loss-1.0223, acc-0.7464, test loss-1.0216, acc-0.7457\n",
      "Iter-6160, train loss-1.1039, acc-0.7400, valid loss-1.0211, acc-0.7462, test loss-1.0205, acc-0.7459\n",
      "Iter-6170, train loss-0.9810, acc-0.7400, valid loss-1.0200, acc-0.7466, test loss-1.0194, acc-0.7463\n",
      "Iter-6180, train loss-0.9881, acc-0.7400, valid loss-1.0187, acc-0.7464, test loss-1.0182, acc-0.7470\n",
      "Iter-6190, train loss-1.0331, acc-0.7000, valid loss-1.0176, acc-0.7462, test loss-1.0170, acc-0.7472\n",
      "Iter-6200, train loss-1.0980, acc-0.6600, valid loss-1.0163, acc-0.7464, test loss-1.0158, acc-0.7480\n",
      "Iter-6210, train loss-0.9199, acc-0.8400, valid loss-1.0152, acc-0.7470, test loss-1.0147, acc-0.7481\n",
      "Iter-6220, train loss-1.1182, acc-0.6800, valid loss-1.0140, acc-0.7478, test loss-1.0136, acc-0.7485\n",
      "Iter-6230, train loss-1.0817, acc-0.7400, valid loss-1.0128, acc-0.7476, test loss-1.0125, acc-0.7492\n",
      "Iter-6240, train loss-1.0383, acc-0.6800, valid loss-1.0116, acc-0.7480, test loss-1.0113, acc-0.7502\n",
      "Iter-6250, train loss-0.9212, acc-0.7600, valid loss-1.0105, acc-0.7484, test loss-1.0102, acc-0.7506\n",
      "Iter-6260, train loss-0.9994, acc-0.8000, valid loss-1.0093, acc-0.7486, test loss-1.0091, acc-0.7512\n",
      "Iter-6270, train loss-1.0443, acc-0.7600, valid loss-1.0082, acc-0.7488, test loss-1.0079, acc-0.7518\n",
      "Iter-6280, train loss-1.0323, acc-0.7800, valid loss-1.0070, acc-0.7488, test loss-1.0067, acc-0.7519\n",
      "Iter-6290, train loss-0.9837, acc-0.7600, valid loss-1.0057, acc-0.7494, test loss-1.0055, acc-0.7524\n",
      "Iter-6300, train loss-1.0017, acc-0.8200, valid loss-1.0045, acc-0.7494, test loss-1.0043, acc-0.7527\n",
      "Iter-6310, train loss-0.9637, acc-0.7800, valid loss-1.0034, acc-0.7500, test loss-1.0032, acc-0.7527\n",
      "Iter-6320, train loss-0.9050, acc-0.7800, valid loss-1.0022, acc-0.7502, test loss-1.0021, acc-0.7526\n",
      "Iter-6330, train loss-1.0825, acc-0.7200, valid loss-1.0010, acc-0.7506, test loss-1.0010, acc-0.7529\n",
      "Iter-6340, train loss-1.0944, acc-0.6800, valid loss-0.9998, acc-0.7510, test loss-0.9999, acc-0.7534\n",
      "Iter-6350, train loss-1.0831, acc-0.6200, valid loss-0.9987, acc-0.7518, test loss-0.9987, acc-0.7538\n",
      "Iter-6360, train loss-1.0793, acc-0.7000, valid loss-0.9976, acc-0.7520, test loss-0.9977, acc-0.7539\n",
      "Iter-6370, train loss-0.9526, acc-0.7800, valid loss-0.9965, acc-0.7522, test loss-0.9966, acc-0.7539\n",
      "Iter-6380, train loss-0.9805, acc-0.8200, valid loss-0.9954, acc-0.7524, test loss-0.9955, acc-0.7542\n",
      "Iter-6390, train loss-0.8903, acc-0.7800, valid loss-0.9943, acc-0.7532, test loss-0.9944, acc-0.7542\n",
      "Iter-6400, train loss-1.0064, acc-0.7600, valid loss-0.9932, acc-0.7538, test loss-0.9934, acc-0.7544\n",
      "Iter-6410, train loss-0.8887, acc-0.8000, valid loss-0.9921, acc-0.7540, test loss-0.9923, acc-0.7549\n",
      "Iter-6420, train loss-1.0818, acc-0.7200, valid loss-0.9910, acc-0.7540, test loss-0.9912, acc-0.7551\n",
      "Iter-6430, train loss-1.0269, acc-0.7600, valid loss-0.9898, acc-0.7542, test loss-0.9901, acc-0.7557\n",
      "Iter-6440, train loss-1.0787, acc-0.7600, valid loss-0.9887, acc-0.7548, test loss-0.9889, acc-0.7560\n",
      "Iter-6450, train loss-1.1168, acc-0.6400, valid loss-0.9876, acc-0.7544, test loss-0.9879, acc-0.7563\n",
      "Iter-6460, train loss-0.8214, acc-0.8200, valid loss-0.9865, acc-0.7546, test loss-0.9868, acc-0.7562\n",
      "Iter-6470, train loss-0.8999, acc-0.8600, valid loss-0.9854, acc-0.7554, test loss-0.9857, acc-0.7565\n",
      "Iter-6480, train loss-1.1457, acc-0.6200, valid loss-0.9843, acc-0.7548, test loss-0.9847, acc-0.7562\n",
      "Iter-6490, train loss-0.9071, acc-0.7800, valid loss-0.9833, acc-0.7554, test loss-0.9836, acc-0.7568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6500, train loss-1.1507, acc-0.6800, valid loss-0.9822, acc-0.7552, test loss-0.9825, acc-0.7566\n",
      "Iter-6510, train loss-0.9644, acc-0.7800, valid loss-0.9811, acc-0.7556, test loss-0.9815, acc-0.7563\n",
      "Iter-6520, train loss-0.9410, acc-0.7600, valid loss-0.9800, acc-0.7558, test loss-0.9804, acc-0.7566\n",
      "Iter-6530, train loss-1.0327, acc-0.7200, valid loss-0.9791, acc-0.7562, test loss-0.9794, acc-0.7571\n",
      "Iter-6540, train loss-0.9854, acc-0.6600, valid loss-0.9779, acc-0.7562, test loss-0.9783, acc-0.7573\n",
      "Iter-6550, train loss-0.9511, acc-0.7800, valid loss-0.9769, acc-0.7562, test loss-0.9772, acc-0.7580\n",
      "Iter-6560, train loss-0.9774, acc-0.7600, valid loss-0.9758, acc-0.7568, test loss-0.9762, acc-0.7584\n",
      "Iter-6570, train loss-1.0198, acc-0.7600, valid loss-0.9748, acc-0.7566, test loss-0.9751, acc-0.7583\n",
      "Iter-6580, train loss-1.1142, acc-0.6600, valid loss-0.9737, acc-0.7566, test loss-0.9741, acc-0.7582\n",
      "Iter-6590, train loss-0.9623, acc-0.8200, valid loss-0.9726, acc-0.7562, test loss-0.9731, acc-0.7589\n",
      "Iter-6600, train loss-0.9122, acc-0.7600, valid loss-0.9715, acc-0.7568, test loss-0.9719, acc-0.7595\n",
      "Iter-6610, train loss-1.0294, acc-0.7800, valid loss-0.9704, acc-0.7574, test loss-0.9709, acc-0.7598\n",
      "Iter-6620, train loss-0.9909, acc-0.7800, valid loss-0.9693, acc-0.7574, test loss-0.9699, acc-0.7598\n",
      "Iter-6630, train loss-0.9628, acc-0.7200, valid loss-0.9682, acc-0.7574, test loss-0.9688, acc-0.7605\n",
      "Iter-6640, train loss-1.0513, acc-0.7200, valid loss-0.9672, acc-0.7578, test loss-0.9678, acc-0.7605\n",
      "Iter-6650, train loss-0.9073, acc-0.8200, valid loss-0.9661, acc-0.7578, test loss-0.9668, acc-0.7603\n",
      "Iter-6660, train loss-0.8938, acc-0.8200, valid loss-0.9651, acc-0.7584, test loss-0.9658, acc-0.7607\n",
      "Iter-6670, train loss-0.9568, acc-0.8200, valid loss-0.9640, acc-0.7586, test loss-0.9647, acc-0.7605\n",
      "Iter-6680, train loss-0.9612, acc-0.7400, valid loss-0.9629, acc-0.7588, test loss-0.9636, acc-0.7612\n",
      "Iter-6690, train loss-1.1224, acc-0.6800, valid loss-0.9619, acc-0.7590, test loss-0.9626, acc-0.7616\n",
      "Iter-6700, train loss-0.8825, acc-0.8400, valid loss-0.9609, acc-0.7588, test loss-0.9616, acc-0.7621\n",
      "Iter-6710, train loss-0.9059, acc-0.8000, valid loss-0.9599, acc-0.7594, test loss-0.9606, acc-0.7622\n",
      "Iter-6720, train loss-1.0083, acc-0.7000, valid loss-0.9589, acc-0.7596, test loss-0.9596, acc-0.7624\n",
      "Iter-6730, train loss-0.8719, acc-0.7600, valid loss-0.9578, acc-0.7608, test loss-0.9586, acc-0.7635\n",
      "Iter-6740, train loss-1.0168, acc-0.6800, valid loss-0.9568, acc-0.7610, test loss-0.9577, acc-0.7641\n",
      "Iter-6750, train loss-1.0705, acc-0.6800, valid loss-0.9558, acc-0.7616, test loss-0.9567, acc-0.7641\n",
      "Iter-6760, train loss-0.9444, acc-0.8200, valid loss-0.9547, acc-0.7618, test loss-0.9556, acc-0.7641\n",
      "Iter-6770, train loss-0.9268, acc-0.8000, valid loss-0.9537, acc-0.7622, test loss-0.9546, acc-0.7643\n",
      "Iter-6780, train loss-0.9386, acc-0.7600, valid loss-0.9527, acc-0.7622, test loss-0.9536, acc-0.7641\n",
      "Iter-6790, train loss-0.9320, acc-0.8400, valid loss-0.9517, acc-0.7622, test loss-0.9526, acc-0.7644\n",
      "Iter-6800, train loss-0.9763, acc-0.7400, valid loss-0.9507, acc-0.7628, test loss-0.9516, acc-0.7647\n",
      "Iter-6810, train loss-0.8442, acc-0.8400, valid loss-0.9497, acc-0.7634, test loss-0.9507, acc-0.7648\n",
      "Iter-6820, train loss-0.9320, acc-0.7800, valid loss-0.9488, acc-0.7640, test loss-0.9498, acc-0.7646\n",
      "Iter-6830, train loss-1.0443, acc-0.7400, valid loss-0.9479, acc-0.7638, test loss-0.9488, acc-0.7650\n",
      "Iter-6840, train loss-0.8674, acc-0.8200, valid loss-0.9469, acc-0.7644, test loss-0.9479, acc-0.7652\n",
      "Iter-6850, train loss-0.8768, acc-0.8400, valid loss-0.9459, acc-0.7642, test loss-0.9469, acc-0.7656\n",
      "Iter-6860, train loss-1.1387, acc-0.7200, valid loss-0.9449, acc-0.7648, test loss-0.9459, acc-0.7655\n",
      "Iter-6870, train loss-0.9535, acc-0.7200, valid loss-0.9439, acc-0.7648, test loss-0.9450, acc-0.7659\n",
      "Iter-6880, train loss-1.0578, acc-0.8200, valid loss-0.9430, acc-0.7648, test loss-0.9441, acc-0.7661\n",
      "Iter-6890, train loss-0.9191, acc-0.7400, valid loss-0.9420, acc-0.7648, test loss-0.9431, acc-0.7660\n",
      "Iter-6900, train loss-0.9644, acc-0.7000, valid loss-0.9410, acc-0.7652, test loss-0.9422, acc-0.7664\n",
      "Iter-6910, train loss-1.0805, acc-0.6200, valid loss-0.9400, acc-0.7662, test loss-0.9412, acc-0.7675\n",
      "Iter-6920, train loss-0.9005, acc-0.8200, valid loss-0.9389, acc-0.7664, test loss-0.9402, acc-0.7675\n",
      "Iter-6930, train loss-1.0798, acc-0.7000, valid loss-0.9380, acc-0.7662, test loss-0.9393, acc-0.7678\n",
      "Iter-6940, train loss-0.8431, acc-0.8600, valid loss-0.9370, acc-0.7666, test loss-0.9384, acc-0.7685\n",
      "Iter-6950, train loss-1.0959, acc-0.6200, valid loss-0.9360, acc-0.7668, test loss-0.9374, acc-0.7683\n",
      "Iter-6960, train loss-1.0001, acc-0.8600, valid loss-0.9350, acc-0.7660, test loss-0.9365, acc-0.7680\n",
      "Iter-6970, train loss-0.9603, acc-0.7400, valid loss-0.9341, acc-0.7660, test loss-0.9355, acc-0.7677\n",
      "Iter-6980, train loss-1.0418, acc-0.7400, valid loss-0.9331, acc-0.7660, test loss-0.9346, acc-0.7677\n",
      "Iter-6990, train loss-0.9916, acc-0.8200, valid loss-0.9321, acc-0.7670, test loss-0.9336, acc-0.7682\n",
      "Iter-7000, train loss-0.9980, acc-0.7600, valid loss-0.9313, acc-0.7674, test loss-0.9327, acc-0.7687\n",
      "Iter-7010, train loss-1.0874, acc-0.7000, valid loss-0.9303, acc-0.7676, test loss-0.9317, acc-0.7689\n",
      "Iter-7020, train loss-1.0210, acc-0.7000, valid loss-0.9294, acc-0.7678, test loss-0.9308, acc-0.7689\n",
      "Iter-7030, train loss-0.8732, acc-0.7600, valid loss-0.9284, acc-0.7682, test loss-0.9299, acc-0.7694\n",
      "Iter-7040, train loss-1.2428, acc-0.6200, valid loss-0.9274, acc-0.7684, test loss-0.9289, acc-0.7700\n",
      "Iter-7050, train loss-0.8119, acc-0.8400, valid loss-0.9264, acc-0.7696, test loss-0.9280, acc-0.7702\n",
      "Iter-7060, train loss-0.9009, acc-0.7600, valid loss-0.9254, acc-0.7696, test loss-0.9271, acc-0.7703\n",
      "Iter-7070, train loss-0.9695, acc-0.7600, valid loss-0.9245, acc-0.7694, test loss-0.9261, acc-0.7705\n",
      "Iter-7080, train loss-0.9125, acc-0.8000, valid loss-0.9235, acc-0.7710, test loss-0.9251, acc-0.7711\n",
      "Iter-7090, train loss-0.8212, acc-0.8400, valid loss-0.9224, acc-0.7720, test loss-0.9241, acc-0.7716\n",
      "Iter-7100, train loss-0.9266, acc-0.8200, valid loss-0.9214, acc-0.7720, test loss-0.9232, acc-0.7718\n",
      "Iter-7110, train loss-0.8325, acc-0.8200, valid loss-0.9205, acc-0.7718, test loss-0.9222, acc-0.7725\n",
      "Iter-7120, train loss-0.8822, acc-0.8200, valid loss-0.9195, acc-0.7726, test loss-0.9213, acc-0.7722\n",
      "Iter-7130, train loss-0.9989, acc-0.6800, valid loss-0.9186, acc-0.7736, test loss-0.9204, acc-0.7725\n",
      "Iter-7140, train loss-0.9486, acc-0.7600, valid loss-0.9177, acc-0.7738, test loss-0.9194, acc-0.7725\n",
      "Iter-7150, train loss-0.9520, acc-0.7800, valid loss-0.9167, acc-0.7740, test loss-0.9185, acc-0.7726\n",
      "Iter-7160, train loss-0.9834, acc-0.7600, valid loss-0.9158, acc-0.7748, test loss-0.9175, acc-0.7727\n",
      "Iter-7170, train loss-0.9407, acc-0.8000, valid loss-0.9147, acc-0.7750, test loss-0.9166, acc-0.7732\n",
      "Iter-7180, train loss-0.9239, acc-0.7600, valid loss-0.9138, acc-0.7752, test loss-0.9157, acc-0.7730\n",
      "Iter-7190, train loss-0.9092, acc-0.7600, valid loss-0.9129, acc-0.7752, test loss-0.9148, acc-0.7734\n",
      "Iter-7200, train loss-0.9188, acc-0.7400, valid loss-0.9119, acc-0.7764, test loss-0.9138, acc-0.7741\n",
      "Iter-7210, train loss-0.8889, acc-0.7800, valid loss-0.9110, acc-0.7768, test loss-0.9130, acc-0.7744\n",
      "Iter-7220, train loss-0.8528, acc-0.8200, valid loss-0.9101, acc-0.7766, test loss-0.9121, acc-0.7747\n",
      "Iter-7230, train loss-1.0579, acc-0.6600, valid loss-0.9092, acc-0.7762, test loss-0.9113, acc-0.7750\n",
      "Iter-7240, train loss-0.8831, acc-0.8200, valid loss-0.9083, acc-0.7768, test loss-0.9104, acc-0.7751\n",
      "Iter-7250, train loss-0.8985, acc-0.8200, valid loss-0.9074, acc-0.7772, test loss-0.9095, acc-0.7752\n",
      "Iter-7260, train loss-0.8945, acc-0.8400, valid loss-0.9064, acc-0.7772, test loss-0.9086, acc-0.7751\n",
      "Iter-7270, train loss-0.8937, acc-0.8000, valid loss-0.9056, acc-0.7770, test loss-0.9078, acc-0.7753\n",
      "Iter-7280, train loss-0.8004, acc-0.8600, valid loss-0.9046, acc-0.7772, test loss-0.9070, acc-0.7754\n",
      "Iter-7290, train loss-0.7384, acc-0.8600, valid loss-0.9038, acc-0.7782, test loss-0.9061, acc-0.7754\n",
      "Iter-7300, train loss-0.9562, acc-0.7800, valid loss-0.9028, acc-0.7782, test loss-0.9052, acc-0.7757\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-7310, train loss-0.8082, acc-0.8000, valid loss-0.9019, acc-0.7786, test loss-0.9043, acc-0.7758\n",
      "Iter-7320, train loss-0.9543, acc-0.7800, valid loss-0.9010, acc-0.7786, test loss-0.9034, acc-0.7761\n",
      "Iter-7330, train loss-0.9370, acc-0.7000, valid loss-0.9001, acc-0.7786, test loss-0.9026, acc-0.7762\n",
      "Iter-7340, train loss-0.9440, acc-0.7800, valid loss-0.8993, acc-0.7786, test loss-0.9017, acc-0.7765\n",
      "Iter-7350, train loss-0.8749, acc-0.8000, valid loss-0.8984, acc-0.7790, test loss-0.9008, acc-0.7766\n",
      "Iter-7360, train loss-1.2198, acc-0.5400, valid loss-0.8976, acc-0.7792, test loss-0.9000, acc-0.7768\n",
      "Iter-7370, train loss-0.9288, acc-0.8000, valid loss-0.8967, acc-0.7790, test loss-0.8991, acc-0.7769\n",
      "Iter-7380, train loss-0.8503, acc-0.8000, valid loss-0.8959, acc-0.7792, test loss-0.8983, acc-0.7771\n",
      "Iter-7390, train loss-1.0225, acc-0.6400, valid loss-0.8950, acc-0.7798, test loss-0.8974, acc-0.7774\n",
      "Iter-7400, train loss-1.0419, acc-0.7800, valid loss-0.8941, acc-0.7794, test loss-0.8966, acc-0.7777\n",
      "Iter-7410, train loss-0.8687, acc-0.7400, valid loss-0.8932, acc-0.7798, test loss-0.8956, acc-0.7777\n",
      "Iter-7420, train loss-0.8969, acc-0.8000, valid loss-0.8923, acc-0.7796, test loss-0.8948, acc-0.7776\n",
      "Iter-7430, train loss-1.1079, acc-0.5800, valid loss-0.8914, acc-0.7800, test loss-0.8940, acc-0.7776\n",
      "Iter-7440, train loss-0.8166, acc-0.8200, valid loss-0.8905, acc-0.7810, test loss-0.8931, acc-0.7776\n",
      "Iter-7450, train loss-0.9952, acc-0.7600, valid loss-0.8896, acc-0.7812, test loss-0.8922, acc-0.7781\n",
      "Iter-7460, train loss-0.8605, acc-0.7200, valid loss-0.8888, acc-0.7814, test loss-0.8914, acc-0.7787\n",
      "Iter-7470, train loss-0.8399, acc-0.7000, valid loss-0.8879, acc-0.7820, test loss-0.8906, acc-0.7789\n",
      "Iter-7480, train loss-0.9861, acc-0.7600, valid loss-0.8871, acc-0.7818, test loss-0.8898, acc-0.7789\n",
      "Iter-7490, train loss-1.0186, acc-0.7800, valid loss-0.8862, acc-0.7824, test loss-0.8889, acc-0.7792\n",
      "Iter-7500, train loss-0.9874, acc-0.8000, valid loss-0.8854, acc-0.7826, test loss-0.8881, acc-0.7788\n",
      "Iter-7510, train loss-0.9649, acc-0.8200, valid loss-0.8845, acc-0.7838, test loss-0.8872, acc-0.7789\n",
      "Iter-7520, train loss-1.0434, acc-0.6800, valid loss-0.8836, acc-0.7842, test loss-0.8863, acc-0.7792\n",
      "Iter-7530, train loss-0.7724, acc-0.8200, valid loss-0.8828, acc-0.7840, test loss-0.8855, acc-0.7789\n",
      "Iter-7540, train loss-0.9797, acc-0.7800, valid loss-0.8820, acc-0.7842, test loss-0.8847, acc-0.7794\n",
      "Iter-7550, train loss-0.8877, acc-0.7800, valid loss-0.8811, acc-0.7846, test loss-0.8838, acc-0.7795\n",
      "Iter-7560, train loss-0.8029, acc-0.8000, valid loss-0.8802, acc-0.7844, test loss-0.8830, acc-0.7793\n",
      "Iter-7570, train loss-0.9152, acc-0.7800, valid loss-0.8794, acc-0.7850, test loss-0.8822, acc-0.7794\n",
      "Iter-7580, train loss-0.8081, acc-0.8200, valid loss-0.8786, acc-0.7850, test loss-0.8814, acc-0.7793\n",
      "Iter-7590, train loss-0.9003, acc-0.7200, valid loss-0.8777, acc-0.7854, test loss-0.8805, acc-0.7795\n",
      "Iter-7600, train loss-0.7647, acc-0.8000, valid loss-0.8769, acc-0.7852, test loss-0.8797, acc-0.7797\n",
      "Iter-7610, train loss-0.8893, acc-0.7000, valid loss-0.8761, acc-0.7858, test loss-0.8789, acc-0.7799\n",
      "Iter-7620, train loss-1.0168, acc-0.7000, valid loss-0.8752, acc-0.7864, test loss-0.8781, acc-0.7797\n",
      "Iter-7630, train loss-0.8960, acc-0.7400, valid loss-0.8744, acc-0.7860, test loss-0.8773, acc-0.7795\n",
      "Iter-7640, train loss-0.9856, acc-0.7000, valid loss-0.8736, acc-0.7868, test loss-0.8764, acc-0.7799\n",
      "Iter-7650, train loss-0.8149, acc-0.9200, valid loss-0.8728, acc-0.7866, test loss-0.8756, acc-0.7801\n",
      "Iter-7660, train loss-0.9316, acc-0.7600, valid loss-0.8720, acc-0.7864, test loss-0.8749, acc-0.7804\n",
      "Iter-7670, train loss-0.8669, acc-0.8200, valid loss-0.8711, acc-0.7862, test loss-0.8740, acc-0.7807\n",
      "Iter-7680, train loss-0.8193, acc-0.8600, valid loss-0.8702, acc-0.7862, test loss-0.8733, acc-0.7813\n",
      "Iter-7690, train loss-0.9069, acc-0.8000, valid loss-0.8694, acc-0.7870, test loss-0.8724, acc-0.7815\n",
      "Iter-7700, train loss-1.0294, acc-0.6800, valid loss-0.8686, acc-0.7868, test loss-0.8716, acc-0.7819\n",
      "Iter-7710, train loss-0.8536, acc-0.7800, valid loss-0.8678, acc-0.7874, test loss-0.8709, acc-0.7820\n",
      "Iter-7720, train loss-0.8088, acc-0.7800, valid loss-0.8670, acc-0.7870, test loss-0.8702, acc-0.7824\n",
      "Iter-7730, train loss-0.9312, acc-0.7400, valid loss-0.8662, acc-0.7874, test loss-0.8693, acc-0.7825\n",
      "Iter-7740, train loss-0.8244, acc-0.8400, valid loss-0.8654, acc-0.7878, test loss-0.8685, acc-0.7826\n",
      "Iter-7750, train loss-0.7539, acc-0.8600, valid loss-0.8646, acc-0.7876, test loss-0.8677, acc-0.7827\n",
      "Iter-7760, train loss-0.9135, acc-0.7600, valid loss-0.8637, acc-0.7878, test loss-0.8669, acc-0.7827\n",
      "Iter-7770, train loss-0.7227, acc-0.8800, valid loss-0.8629, acc-0.7878, test loss-0.8661, acc-0.7833\n",
      "Iter-7780, train loss-0.8087, acc-0.8000, valid loss-0.8621, acc-0.7878, test loss-0.8653, acc-0.7833\n",
      "Iter-7790, train loss-0.7049, acc-0.8400, valid loss-0.8613, acc-0.7882, test loss-0.8645, acc-0.7837\n",
      "Iter-7800, train loss-0.9799, acc-0.6600, valid loss-0.8605, acc-0.7882, test loss-0.8637, acc-0.7840\n",
      "Iter-7810, train loss-1.0365, acc-0.7000, valid loss-0.8597, acc-0.7884, test loss-0.8630, acc-0.7844\n",
      "Iter-7820, train loss-0.8114, acc-0.8000, valid loss-0.8589, acc-0.7882, test loss-0.8622, acc-0.7851\n",
      "Iter-7830, train loss-0.8250, acc-0.7800, valid loss-0.8581, acc-0.7882, test loss-0.8614, acc-0.7851\n",
      "Iter-7840, train loss-0.8605, acc-0.7800, valid loss-0.8573, acc-0.7886, test loss-0.8606, acc-0.7849\n",
      "Iter-7850, train loss-0.8363, acc-0.8400, valid loss-0.8565, acc-0.7886, test loss-0.8598, acc-0.7850\n",
      "Iter-7860, train loss-0.7897, acc-0.8800, valid loss-0.8557, acc-0.7884, test loss-0.8590, acc-0.7850\n",
      "Iter-7870, train loss-0.7828, acc-0.8000, valid loss-0.8548, acc-0.7882, test loss-0.8581, acc-0.7851\n",
      "Iter-7880, train loss-0.8280, acc-0.7000, valid loss-0.8541, acc-0.7884, test loss-0.8574, acc-0.7853\n",
      "Iter-7890, train loss-0.7519, acc-0.8200, valid loss-0.8533, acc-0.7880, test loss-0.8566, acc-0.7856\n",
      "Iter-7900, train loss-1.0793, acc-0.7600, valid loss-0.8525, acc-0.7884, test loss-0.8559, acc-0.7856\n",
      "Iter-7910, train loss-0.7640, acc-0.8600, valid loss-0.8517, acc-0.7882, test loss-0.8551, acc-0.7865\n",
      "Iter-7920, train loss-0.9225, acc-0.7800, valid loss-0.8509, acc-0.7890, test loss-0.8543, acc-0.7870\n",
      "Iter-7930, train loss-0.9993, acc-0.8000, valid loss-0.8502, acc-0.7888, test loss-0.8535, acc-0.7871\n",
      "Iter-7940, train loss-0.8970, acc-0.8000, valid loss-0.8493, acc-0.7892, test loss-0.8527, acc-0.7877\n",
      "Iter-7950, train loss-0.9433, acc-0.8400, valid loss-0.8485, acc-0.7894, test loss-0.8519, acc-0.7881\n",
      "Iter-7960, train loss-0.7998, acc-0.8000, valid loss-0.8477, acc-0.7896, test loss-0.8511, acc-0.7886\n",
      "Iter-7970, train loss-0.8569, acc-0.7600, valid loss-0.8470, acc-0.7896, test loss-0.8503, acc-0.7889\n",
      "Iter-7980, train loss-0.8555, acc-0.8200, valid loss-0.8462, acc-0.7888, test loss-0.8496, acc-0.7887\n",
      "Iter-7990, train loss-0.7826, acc-0.8200, valid loss-0.8455, acc-0.7898, test loss-0.8488, acc-0.7886\n",
      "Iter-8000, train loss-0.8557, acc-0.7800, valid loss-0.8447, acc-0.7904, test loss-0.8480, acc-0.7888\n",
      "Iter-8010, train loss-0.9090, acc-0.8000, valid loss-0.8439, acc-0.7906, test loss-0.8473, acc-0.7894\n",
      "Iter-8020, train loss-1.0023, acc-0.7000, valid loss-0.8431, acc-0.7912, test loss-0.8466, acc-0.7892\n",
      "Iter-8030, train loss-0.7824, acc-0.8400, valid loss-0.8423, acc-0.7922, test loss-0.8458, acc-0.7895\n",
      "Iter-8040, train loss-0.8818, acc-0.8200, valid loss-0.8415, acc-0.7926, test loss-0.8451, acc-0.7899\n",
      "Iter-8050, train loss-0.8526, acc-0.8200, valid loss-0.8407, acc-0.7926, test loss-0.8443, acc-0.7902\n",
      "Iter-8060, train loss-0.9091, acc-0.6800, valid loss-0.8399, acc-0.7936, test loss-0.8435, acc-0.7901\n",
      "Iter-8070, train loss-0.7799, acc-0.8400, valid loss-0.8391, acc-0.7942, test loss-0.8428, acc-0.7902\n",
      "Iter-8080, train loss-0.8075, acc-0.8200, valid loss-0.8384, acc-0.7942, test loss-0.8421, acc-0.7904\n",
      "Iter-8090, train loss-0.8177, acc-0.7800, valid loss-0.8376, acc-0.7946, test loss-0.8414, acc-0.7908\n",
      "Iter-8100, train loss-0.9593, acc-0.7200, valid loss-0.8369, acc-0.7946, test loss-0.8406, acc-0.7910\n",
      "Iter-8110, train loss-0.9604, acc-0.7000, valid loss-0.8362, acc-0.7952, test loss-0.8399, acc-0.7914\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8120, train loss-0.9706, acc-0.7600, valid loss-0.8354, acc-0.7950, test loss-0.8392, acc-0.7913\n",
      "Iter-8130, train loss-0.9167, acc-0.8200, valid loss-0.8347, acc-0.7952, test loss-0.8384, acc-0.7917\n",
      "Iter-8140, train loss-0.8354, acc-0.8200, valid loss-0.8339, acc-0.7954, test loss-0.8377, acc-0.7918\n",
      "Iter-8150, train loss-0.8279, acc-0.7000, valid loss-0.8331, acc-0.7956, test loss-0.8369, acc-0.7924\n",
      "Iter-8160, train loss-0.9853, acc-0.7400, valid loss-0.8324, acc-0.7956, test loss-0.8361, acc-0.7926\n",
      "Iter-8170, train loss-0.8520, acc-0.8600, valid loss-0.8316, acc-0.7954, test loss-0.8354, acc-0.7925\n",
      "Iter-8180, train loss-0.7021, acc-0.8800, valid loss-0.8308, acc-0.7956, test loss-0.8347, acc-0.7926\n",
      "Iter-8190, train loss-0.8138, acc-0.8400, valid loss-0.8302, acc-0.7958, test loss-0.8340, acc-0.7927\n",
      "Iter-8200, train loss-0.9471, acc-0.7600, valid loss-0.8294, acc-0.7962, test loss-0.8333, acc-0.7932\n",
      "Iter-8210, train loss-0.8535, acc-0.8000, valid loss-0.8287, acc-0.7962, test loss-0.8326, acc-0.7932\n",
      "Iter-8220, train loss-0.8600, acc-0.6800, valid loss-0.8280, acc-0.7964, test loss-0.8319, acc-0.7931\n",
      "Iter-8230, train loss-0.8017, acc-0.7800, valid loss-0.8272, acc-0.7962, test loss-0.8312, acc-0.7938\n",
      "Iter-8240, train loss-0.7912, acc-0.8400, valid loss-0.8265, acc-0.7972, test loss-0.8304, acc-0.7944\n",
      "Iter-8250, train loss-0.8420, acc-0.9000, valid loss-0.8257, acc-0.7974, test loss-0.8297, acc-0.7952\n",
      "Iter-8260, train loss-0.7368, acc-0.8600, valid loss-0.8250, acc-0.7976, test loss-0.8290, acc-0.7950\n",
      "Iter-8270, train loss-0.8154, acc-0.8400, valid loss-0.8243, acc-0.7978, test loss-0.8282, acc-0.7958\n",
      "Iter-8280, train loss-0.7317, acc-0.8400, valid loss-0.8236, acc-0.7980, test loss-0.8276, acc-0.7957\n",
      "Iter-8290, train loss-0.8256, acc-0.7800, valid loss-0.8228, acc-0.7978, test loss-0.8269, acc-0.7962\n",
      "Iter-8300, train loss-0.9875, acc-0.6800, valid loss-0.8221, acc-0.7982, test loss-0.8261, acc-0.7966\n",
      "Iter-8310, train loss-0.8408, acc-0.8000, valid loss-0.8214, acc-0.7988, test loss-0.8254, acc-0.7967\n",
      "Iter-8320, train loss-0.9476, acc-0.7200, valid loss-0.8206, acc-0.7992, test loss-0.8247, acc-0.7969\n",
      "Iter-8330, train loss-0.9116, acc-0.7800, valid loss-0.8199, acc-0.7992, test loss-0.8240, acc-0.7969\n",
      "Iter-8340, train loss-0.7405, acc-0.9200, valid loss-0.8192, acc-0.7992, test loss-0.8233, acc-0.7967\n",
      "Iter-8350, train loss-0.8453, acc-0.8000, valid loss-0.8185, acc-0.7992, test loss-0.8226, acc-0.7972\n",
      "Iter-8360, train loss-0.8605, acc-0.7800, valid loss-0.8178, acc-0.7994, test loss-0.8219, acc-0.7969\n",
      "Iter-8370, train loss-0.9766, acc-0.7200, valid loss-0.8172, acc-0.7994, test loss-0.8212, acc-0.7973\n",
      "Iter-8380, train loss-0.9341, acc-0.7400, valid loss-0.8165, acc-0.8000, test loss-0.8205, acc-0.7970\n",
      "Iter-8390, train loss-0.7299, acc-0.7800, valid loss-0.8158, acc-0.8002, test loss-0.8198, acc-0.7976\n",
      "Iter-8400, train loss-0.8331, acc-0.7400, valid loss-0.8150, acc-0.8002, test loss-0.8190, acc-0.7975\n",
      "Iter-8410, train loss-0.7401, acc-0.7800, valid loss-0.8144, acc-0.8004, test loss-0.8183, acc-0.7976\n",
      "Iter-8420, train loss-0.6856, acc-0.8400, valid loss-0.8136, acc-0.8004, test loss-0.8176, acc-0.7979\n",
      "Iter-8430, train loss-0.8967, acc-0.7600, valid loss-0.8129, acc-0.8006, test loss-0.8169, acc-0.7979\n",
      "Iter-8440, train loss-0.8297, acc-0.7400, valid loss-0.8122, acc-0.8010, test loss-0.8162, acc-0.7979\n",
      "Iter-8450, train loss-0.8032, acc-0.8000, valid loss-0.8116, acc-0.8010, test loss-0.8155, acc-0.7982\n",
      "Iter-8460, train loss-0.7327, acc-0.8400, valid loss-0.8109, acc-0.8012, test loss-0.8147, acc-0.7984\n",
      "Iter-8470, train loss-0.7519, acc-0.8200, valid loss-0.8102, acc-0.8014, test loss-0.8141, acc-0.7984\n",
      "Iter-8480, train loss-0.9337, acc-0.7200, valid loss-0.8095, acc-0.8010, test loss-0.8134, acc-0.7985\n",
      "Iter-8490, train loss-0.7593, acc-0.8600, valid loss-0.8088, acc-0.8018, test loss-0.8127, acc-0.7988\n",
      "Iter-8500, train loss-0.9710, acc-0.7200, valid loss-0.8081, acc-0.8018, test loss-0.8121, acc-0.7989\n",
      "Iter-8510, train loss-0.7426, acc-0.8400, valid loss-0.8075, acc-0.8018, test loss-0.8115, acc-0.7987\n",
      "Iter-8520, train loss-0.7252, acc-0.9000, valid loss-0.8069, acc-0.8020, test loss-0.8108, acc-0.7988\n",
      "Iter-8530, train loss-0.8289, acc-0.8000, valid loss-0.8063, acc-0.8020, test loss-0.8102, acc-0.7991\n",
      "Iter-8540, train loss-0.7737, acc-0.8200, valid loss-0.8056, acc-0.8022, test loss-0.8095, acc-0.7988\n",
      "Iter-8550, train loss-0.9854, acc-0.7200, valid loss-0.8050, acc-0.8024, test loss-0.8089, acc-0.7992\n",
      "Iter-8560, train loss-0.8640, acc-0.8000, valid loss-0.8043, acc-0.8024, test loss-0.8082, acc-0.7992\n",
      "Iter-8570, train loss-0.8811, acc-0.8000, valid loss-0.8036, acc-0.8032, test loss-0.8076, acc-0.7993\n",
      "Iter-8580, train loss-0.7996, acc-0.8200, valid loss-0.8029, acc-0.8032, test loss-0.8069, acc-0.7999\n",
      "Iter-8590, train loss-0.9679, acc-0.7000, valid loss-0.8022, acc-0.8032, test loss-0.8062, acc-0.8000\n",
      "Iter-8600, train loss-0.8197, acc-0.7400, valid loss-0.8015, acc-0.8040, test loss-0.8055, acc-0.8001\n",
      "Iter-8610, train loss-0.6599, acc-0.8400, valid loss-0.8008, acc-0.8040, test loss-0.8049, acc-0.8001\n",
      "Iter-8620, train loss-0.8091, acc-0.8400, valid loss-0.8000, acc-0.8042, test loss-0.8041, acc-0.8004\n",
      "Iter-8630, train loss-0.7458, acc-0.8200, valid loss-0.7993, acc-0.8048, test loss-0.8035, acc-0.8007\n",
      "Iter-8640, train loss-0.7368, acc-0.8800, valid loss-0.7987, acc-0.8048, test loss-0.8028, acc-0.8009\n",
      "Iter-8650, train loss-0.7595, acc-0.8400, valid loss-0.7980, acc-0.8056, test loss-0.8022, acc-0.8012\n",
      "Iter-8660, train loss-0.5747, acc-0.8600, valid loss-0.7973, acc-0.8060, test loss-0.8016, acc-0.8012\n",
      "Iter-8670, train loss-0.8813, acc-0.7600, valid loss-0.7967, acc-0.8066, test loss-0.8010, acc-0.8018\n",
      "Iter-8680, train loss-0.8181, acc-0.8200, valid loss-0.7960, acc-0.8068, test loss-0.8004, acc-0.8017\n",
      "Iter-8690, train loss-0.8305, acc-0.8000, valid loss-0.7954, acc-0.8066, test loss-0.7998, acc-0.8018\n",
      "Iter-8700, train loss-0.7841, acc-0.7800, valid loss-0.7946, acc-0.8068, test loss-0.7991, acc-0.8016\n",
      "Iter-8710, train loss-0.7872, acc-0.8000, valid loss-0.7940, acc-0.8066, test loss-0.7985, acc-0.8018\n",
      "Iter-8720, train loss-0.5797, acc-0.9200, valid loss-0.7934, acc-0.8066, test loss-0.7979, acc-0.8018\n",
      "Iter-8730, train loss-0.9236, acc-0.7400, valid loss-0.7927, acc-0.8064, test loss-0.7972, acc-0.8021\n",
      "Iter-8740, train loss-0.6669, acc-0.8800, valid loss-0.7920, acc-0.8064, test loss-0.7965, acc-0.8027\n",
      "Iter-8750, train loss-0.7013, acc-0.8400, valid loss-0.7914, acc-0.8064, test loss-0.7959, acc-0.8025\n",
      "Iter-8760, train loss-0.5361, acc-0.9200, valid loss-0.7908, acc-0.8064, test loss-0.7953, acc-0.8025\n",
      "Iter-8770, train loss-0.6843, acc-0.8800, valid loss-0.7901, acc-0.8072, test loss-0.7946, acc-0.8026\n",
      "Iter-8780, train loss-0.8214, acc-0.7600, valid loss-0.7895, acc-0.8072, test loss-0.7940, acc-0.8029\n",
      "Iter-8790, train loss-0.7713, acc-0.8400, valid loss-0.7888, acc-0.8074, test loss-0.7933, acc-0.8036\n",
      "Iter-8800, train loss-0.9757, acc-0.7800, valid loss-0.7882, acc-0.8078, test loss-0.7927, acc-0.8034\n",
      "Iter-8810, train loss-0.7006, acc-0.8600, valid loss-0.7875, acc-0.8080, test loss-0.7920, acc-0.8036\n",
      "Iter-8820, train loss-1.0000, acc-0.7400, valid loss-0.7868, acc-0.8082, test loss-0.7913, acc-0.8039\n",
      "Iter-8830, train loss-0.8938, acc-0.8200, valid loss-0.7862, acc-0.8084, test loss-0.7907, acc-0.8040\n",
      "Iter-8840, train loss-0.8004, acc-0.8200, valid loss-0.7856, acc-0.8082, test loss-0.7901, acc-0.8043\n",
      "Iter-8850, train loss-0.8424, acc-0.7600, valid loss-0.7850, acc-0.8088, test loss-0.7895, acc-0.8042\n",
      "Iter-8860, train loss-0.8300, acc-0.8000, valid loss-0.7844, acc-0.8086, test loss-0.7888, acc-0.8042\n",
      "Iter-8870, train loss-0.8340, acc-0.8200, valid loss-0.7838, acc-0.8088, test loss-0.7882, acc-0.8042\n",
      "Iter-8880, train loss-0.7657, acc-0.7800, valid loss-0.7832, acc-0.8092, test loss-0.7876, acc-0.8038\n",
      "Iter-8890, train loss-0.8707, acc-0.7600, valid loss-0.7826, acc-0.8092, test loss-0.7870, acc-0.8036\n",
      "Iter-8900, train loss-0.9673, acc-0.7600, valid loss-0.7819, acc-0.8094, test loss-0.7864, acc-0.8040\n",
      "Iter-8910, train loss-0.8277, acc-0.7600, valid loss-0.7813, acc-0.8096, test loss-0.7858, acc-0.8042\n",
      "Iter-8920, train loss-0.8022, acc-0.9000, valid loss-0.7806, acc-0.8096, test loss-0.7852, acc-0.8045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8930, train loss-0.7971, acc-0.8200, valid loss-0.7800, acc-0.8096, test loss-0.7845, acc-0.8046\n",
      "Iter-8940, train loss-0.9373, acc-0.7000, valid loss-0.7793, acc-0.8096, test loss-0.7840, acc-0.8046\n",
      "Iter-8950, train loss-0.8324, acc-0.7800, valid loss-0.7787, acc-0.8098, test loss-0.7834, acc-0.8049\n",
      "Iter-8960, train loss-0.7419, acc-0.8400, valid loss-0.7781, acc-0.8098, test loss-0.7828, acc-0.8048\n",
      "Iter-8970, train loss-0.9221, acc-0.7200, valid loss-0.7775, acc-0.8096, test loss-0.7822, acc-0.8045\n",
      "Iter-8980, train loss-0.8152, acc-0.8200, valid loss-0.7769, acc-0.8100, test loss-0.7816, acc-0.8047\n",
      "Iter-8990, train loss-0.8533, acc-0.7200, valid loss-0.7763, acc-0.8100, test loss-0.7810, acc-0.8050\n",
      "Iter-9000, train loss-0.7046, acc-0.8200, valid loss-0.7756, acc-0.8102, test loss-0.7804, acc-0.8054\n",
      "Iter-9010, train loss-0.8421, acc-0.7800, valid loss-0.7750, acc-0.8104, test loss-0.7798, acc-0.8052\n",
      "Iter-9020, train loss-1.0195, acc-0.6400, valid loss-0.7744, acc-0.8104, test loss-0.7791, acc-0.8055\n",
      "Iter-9030, train loss-0.7837, acc-0.8000, valid loss-0.7737, acc-0.8104, test loss-0.7785, acc-0.8058\n",
      "Iter-9040, train loss-0.7935, acc-0.7400, valid loss-0.7731, acc-0.8104, test loss-0.7780, acc-0.8058\n",
      "Iter-9050, train loss-0.7363, acc-0.8600, valid loss-0.7725, acc-0.8104, test loss-0.7773, acc-0.8056\n",
      "Iter-9060, train loss-0.7600, acc-0.7400, valid loss-0.7719, acc-0.8104, test loss-0.7767, acc-0.8056\n",
      "Iter-9070, train loss-0.8550, acc-0.7200, valid loss-0.7712, acc-0.8106, test loss-0.7762, acc-0.8061\n",
      "Iter-9080, train loss-0.8815, acc-0.8000, valid loss-0.7706, acc-0.8102, test loss-0.7756, acc-0.8059\n",
      "Iter-9090, train loss-0.8734, acc-0.7000, valid loss-0.7700, acc-0.8102, test loss-0.7750, acc-0.8053\n",
      "Iter-9100, train loss-0.8597, acc-0.8200, valid loss-0.7694, acc-0.8106, test loss-0.7744, acc-0.8061\n",
      "Iter-9110, train loss-0.6981, acc-0.8800, valid loss-0.7688, acc-0.8106, test loss-0.7737, acc-0.8067\n",
      "Iter-9120, train loss-0.7944, acc-0.8600, valid loss-0.7682, acc-0.8104, test loss-0.7731, acc-0.8063\n",
      "Iter-9130, train loss-0.7635, acc-0.8200, valid loss-0.7676, acc-0.8106, test loss-0.7725, acc-0.8061\n",
      "Iter-9140, train loss-0.8482, acc-0.7800, valid loss-0.7670, acc-0.8108, test loss-0.7719, acc-0.8067\n",
      "Iter-9150, train loss-0.7862, acc-0.8400, valid loss-0.7664, acc-0.8106, test loss-0.7714, acc-0.8069\n",
      "Iter-9160, train loss-0.7690, acc-0.8000, valid loss-0.7658, acc-0.8112, test loss-0.7708, acc-0.8070\n",
      "Iter-9170, train loss-0.7722, acc-0.8800, valid loss-0.7652, acc-0.8112, test loss-0.7702, acc-0.8074\n",
      "Iter-9180, train loss-0.7704, acc-0.8200, valid loss-0.7646, acc-0.8118, test loss-0.7697, acc-0.8075\n",
      "Iter-9190, train loss-0.7853, acc-0.7800, valid loss-0.7640, acc-0.8116, test loss-0.7691, acc-0.8074\n",
      "Iter-9200, train loss-0.7959, acc-0.8800, valid loss-0.7634, acc-0.8120, test loss-0.7685, acc-0.8077\n",
      "Iter-9210, train loss-0.7907, acc-0.7800, valid loss-0.7628, acc-0.8118, test loss-0.7679, acc-0.8076\n",
      "Iter-9220, train loss-0.9676, acc-0.7000, valid loss-0.7623, acc-0.8116, test loss-0.7673, acc-0.8077\n",
      "Iter-9230, train loss-0.6795, acc-0.8200, valid loss-0.7617, acc-0.8120, test loss-0.7667, acc-0.8080\n",
      "Iter-9240, train loss-0.7153, acc-0.9200, valid loss-0.7611, acc-0.8122, test loss-0.7661, acc-0.8082\n",
      "Iter-9250, train loss-0.9675, acc-0.7800, valid loss-0.7605, acc-0.8122, test loss-0.7655, acc-0.8081\n",
      "Iter-9260, train loss-0.8383, acc-0.8400, valid loss-0.7599, acc-0.8122, test loss-0.7649, acc-0.8085\n",
      "Iter-9270, train loss-0.7171, acc-0.8400, valid loss-0.7592, acc-0.8136, test loss-0.7643, acc-0.8088\n",
      "Iter-9280, train loss-0.7503, acc-0.8600, valid loss-0.7586, acc-0.8132, test loss-0.7637, acc-0.8086\n",
      "Iter-9290, train loss-0.7086, acc-0.8600, valid loss-0.7581, acc-0.8134, test loss-0.7632, acc-0.8089\n",
      "Iter-9300, train loss-0.8265, acc-0.7600, valid loss-0.7576, acc-0.8136, test loss-0.7627, acc-0.8091\n",
      "Iter-9310, train loss-0.7610, acc-0.8200, valid loss-0.7570, acc-0.8132, test loss-0.7621, acc-0.8089\n",
      "Iter-9320, train loss-0.7274, acc-0.8200, valid loss-0.7564, acc-0.8128, test loss-0.7616, acc-0.8085\n",
      "Iter-9330, train loss-0.8065, acc-0.7400, valid loss-0.7559, acc-0.8130, test loss-0.7610, acc-0.8085\n",
      "Iter-9340, train loss-0.7215, acc-0.7800, valid loss-0.7553, acc-0.8130, test loss-0.7604, acc-0.8087\n",
      "Iter-9350, train loss-0.6442, acc-0.9000, valid loss-0.7547, acc-0.8132, test loss-0.7598, acc-0.8087\n",
      "Iter-9360, train loss-0.7189, acc-0.8200, valid loss-0.7541, acc-0.8134, test loss-0.7593, acc-0.8092\n",
      "Iter-9370, train loss-0.7934, acc-0.7400, valid loss-0.7535, acc-0.8144, test loss-0.7587, acc-0.8097\n",
      "Iter-9380, train loss-0.8029, acc-0.7800, valid loss-0.7529, acc-0.8146, test loss-0.7582, acc-0.8098\n",
      "Iter-9390, train loss-0.6642, acc-0.8400, valid loss-0.7523, acc-0.8150, test loss-0.7577, acc-0.8103\n",
      "Iter-9400, train loss-0.7639, acc-0.7400, valid loss-0.7517, acc-0.8152, test loss-0.7572, acc-0.8103\n",
      "Iter-9410, train loss-0.8148, acc-0.8600, valid loss-0.7512, acc-0.8154, test loss-0.7566, acc-0.8103\n",
      "Iter-9420, train loss-0.8065, acc-0.7800, valid loss-0.7506, acc-0.8152, test loss-0.7561, acc-0.8104\n",
      "Iter-9430, train loss-0.9461, acc-0.6800, valid loss-0.7501, acc-0.8156, test loss-0.7555, acc-0.8106\n",
      "Iter-9440, train loss-0.8116, acc-0.7800, valid loss-0.7496, acc-0.8154, test loss-0.7549, acc-0.8109\n",
      "Iter-9450, train loss-0.6619, acc-0.9200, valid loss-0.7490, acc-0.8162, test loss-0.7544, acc-0.8112\n",
      "Iter-9460, train loss-0.6663, acc-0.8800, valid loss-0.7484, acc-0.8158, test loss-0.7538, acc-0.8111\n",
      "Iter-9470, train loss-0.7502, acc-0.8200, valid loss-0.7478, acc-0.8160, test loss-0.7533, acc-0.8113\n",
      "Iter-9480, train loss-0.6691, acc-0.8200, valid loss-0.7472, acc-0.8164, test loss-0.7527, acc-0.8118\n",
      "Iter-9490, train loss-0.7003, acc-0.9000, valid loss-0.7467, acc-0.8170, test loss-0.7522, acc-0.8112\n",
      "Iter-9500, train loss-0.7897, acc-0.8600, valid loss-0.7461, acc-0.8170, test loss-0.7516, acc-0.8116\n",
      "Iter-9510, train loss-0.6943, acc-0.8200, valid loss-0.7456, acc-0.8172, test loss-0.7511, acc-0.8119\n",
      "Iter-9520, train loss-0.8072, acc-0.7200, valid loss-0.7450, acc-0.8180, test loss-0.7505, acc-0.8122\n",
      "Iter-9530, train loss-0.7567, acc-0.7400, valid loss-0.7445, acc-0.8178, test loss-0.7500, acc-0.8121\n",
      "Iter-9540, train loss-0.7325, acc-0.7800, valid loss-0.7440, acc-0.8180, test loss-0.7494, acc-0.8122\n",
      "Iter-9550, train loss-0.7848, acc-0.8400, valid loss-0.7434, acc-0.8180, test loss-0.7489, acc-0.8123\n",
      "Iter-9560, train loss-0.7879, acc-0.7800, valid loss-0.7429, acc-0.8186, test loss-0.7483, acc-0.8127\n",
      "Iter-9570, train loss-0.5865, acc-0.9200, valid loss-0.7423, acc-0.8186, test loss-0.7478, acc-0.8127\n",
      "Iter-9580, train loss-0.7047, acc-0.8200, valid loss-0.7418, acc-0.8184, test loss-0.7473, acc-0.8127\n",
      "Iter-9590, train loss-0.6964, acc-0.8800, valid loss-0.7413, acc-0.8188, test loss-0.7468, acc-0.8128\n",
      "Iter-9600, train loss-0.7247, acc-0.8600, valid loss-0.7407, acc-0.8188, test loss-0.7462, acc-0.8127\n",
      "Iter-9610, train loss-0.6567, acc-0.8600, valid loss-0.7402, acc-0.8188, test loss-0.7457, acc-0.8127\n",
      "Iter-9620, train loss-0.8243, acc-0.7400, valid loss-0.7396, acc-0.8190, test loss-0.7452, acc-0.8129\n",
      "Iter-9630, train loss-0.6743, acc-0.9000, valid loss-0.7391, acc-0.8190, test loss-0.7446, acc-0.8129\n",
      "Iter-9640, train loss-0.6830, acc-0.8600, valid loss-0.7385, acc-0.8188, test loss-0.7441, acc-0.8127\n",
      "Iter-9650, train loss-0.6865, acc-0.8400, valid loss-0.7380, acc-0.8194, test loss-0.7435, acc-0.8129\n",
      "Iter-9660, train loss-0.8145, acc-0.7800, valid loss-0.7375, acc-0.8194, test loss-0.7429, acc-0.8131\n",
      "Iter-9670, train loss-0.7166, acc-0.8200, valid loss-0.7369, acc-0.8198, test loss-0.7424, acc-0.8134\n",
      "Iter-9680, train loss-0.6038, acc-0.8400, valid loss-0.7364, acc-0.8196, test loss-0.7418, acc-0.8135\n",
      "Iter-9690, train loss-0.8962, acc-0.7000, valid loss-0.7358, acc-0.8200, test loss-0.7413, acc-0.8139\n",
      "Iter-9700, train loss-0.7437, acc-0.8200, valid loss-0.7353, acc-0.8200, test loss-0.7408, acc-0.8137\n",
      "Iter-9710, train loss-0.8668, acc-0.7600, valid loss-0.7347, acc-0.8200, test loss-0.7403, acc-0.8138\n",
      "Iter-9720, train loss-0.7096, acc-0.8400, valid loss-0.7342, acc-0.8206, test loss-0.7397, acc-0.8137\n",
      "Iter-9730, train loss-0.9512, acc-0.7000, valid loss-0.7337, acc-0.8208, test loss-0.7392, acc-0.8139\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-9740, train loss-0.8176, acc-0.7800, valid loss-0.7332, acc-0.8210, test loss-0.7387, acc-0.8140\n",
      "Iter-9750, train loss-0.7251, acc-0.8200, valid loss-0.7326, acc-0.8214, test loss-0.7383, acc-0.8142\n",
      "Iter-9760, train loss-0.6976, acc-0.8400, valid loss-0.7322, acc-0.8214, test loss-0.7378, acc-0.8140\n",
      "Iter-9770, train loss-0.6698, acc-0.7800, valid loss-0.7316, acc-0.8216, test loss-0.7373, acc-0.8142\n",
      "Iter-9780, train loss-0.6659, acc-0.9000, valid loss-0.7311, acc-0.8216, test loss-0.7367, acc-0.8143\n",
      "Iter-9790, train loss-0.8535, acc-0.7200, valid loss-0.7305, acc-0.8224, test loss-0.7361, acc-0.8147\n",
      "Iter-9800, train loss-0.7600, acc-0.8800, valid loss-0.7300, acc-0.8228, test loss-0.7356, acc-0.8147\n",
      "Iter-9810, train loss-0.7628, acc-0.7800, valid loss-0.7294, acc-0.8230, test loss-0.7351, acc-0.8150\n",
      "Iter-9820, train loss-0.8473, acc-0.8000, valid loss-0.7289, acc-0.8226, test loss-0.7346, acc-0.8151\n",
      "Iter-9830, train loss-0.6342, acc-0.9000, valid loss-0.7283, acc-0.8224, test loss-0.7340, acc-0.8151\n",
      "Iter-9840, train loss-0.9053, acc-0.7400, valid loss-0.7278, acc-0.8228, test loss-0.7335, acc-0.8152\n",
      "Iter-9850, train loss-0.7288, acc-0.8000, valid loss-0.7273, acc-0.8230, test loss-0.7330, acc-0.8156\n",
      "Iter-9860, train loss-0.8849, acc-0.8000, valid loss-0.7268, acc-0.8232, test loss-0.7325, acc-0.8159\n",
      "Iter-9870, train loss-0.9047, acc-0.7600, valid loss-0.7262, acc-0.8234, test loss-0.7320, acc-0.8159\n",
      "Iter-9880, train loss-0.7381, acc-0.8400, valid loss-0.7258, acc-0.8236, test loss-0.7314, acc-0.8159\n",
      "Iter-9890, train loss-0.7916, acc-0.7600, valid loss-0.7252, acc-0.8238, test loss-0.7309, acc-0.8162\n",
      "Iter-9900, train loss-0.8727, acc-0.8000, valid loss-0.7247, acc-0.8238, test loss-0.7304, acc-0.8161\n",
      "Iter-9910, train loss-0.6690, acc-0.8200, valid loss-0.7242, acc-0.8238, test loss-0.7299, acc-0.8162\n",
      "Iter-9920, train loss-0.7028, acc-0.8000, valid loss-0.7237, acc-0.8240, test loss-0.7294, acc-0.8164\n",
      "Iter-9930, train loss-0.8186, acc-0.7200, valid loss-0.7231, acc-0.8246, test loss-0.7289, acc-0.8166\n",
      "Iter-9940, train loss-0.7219, acc-0.8400, valid loss-0.7226, acc-0.8248, test loss-0.7284, acc-0.8165\n",
      "Iter-9950, train loss-0.9345, acc-0.8000, valid loss-0.7221, acc-0.8248, test loss-0.7279, acc-0.8163\n",
      "Iter-9960, train loss-0.6293, acc-0.8600, valid loss-0.7216, acc-0.8250, test loss-0.7274, acc-0.8164\n",
      "Iter-9970, train loss-0.8108, acc-0.8200, valid loss-0.7211, acc-0.8252, test loss-0.7269, acc-0.8169\n",
      "Iter-9980, train loss-0.7874, acc-0.8000, valid loss-0.7207, acc-0.8254, test loss-0.7265, acc-0.8172\n",
      "Iter-9990, train loss-0.5828, acc-0.9200, valid loss-0.7201, acc-0.8252, test loss-0.7259, acc-0.8176\n",
      "Iter-10000, train loss-0.8235, acc-0.8200, valid loss-0.7196, acc-0.8250, test loss-0.7255, acc-0.8175\n",
      "Iter-10010, train loss-0.7097, acc-0.8000, valid loss-0.7191, acc-0.8250, test loss-0.7249, acc-0.8174\n",
      "Iter-10020, train loss-0.8829, acc-0.7400, valid loss-0.7186, acc-0.8248, test loss-0.7244, acc-0.8180\n",
      "Iter-10030, train loss-0.7600, acc-0.8000, valid loss-0.7181, acc-0.8254, test loss-0.7240, acc-0.8178\n",
      "Iter-10040, train loss-0.7331, acc-0.7600, valid loss-0.7176, acc-0.8256, test loss-0.7235, acc-0.8177\n",
      "Iter-10050, train loss-0.6941, acc-0.8400, valid loss-0.7170, acc-0.8260, test loss-0.7229, acc-0.8180\n",
      "Iter-10060, train loss-0.7412, acc-0.8000, valid loss-0.7165, acc-0.8258, test loss-0.7225, acc-0.8182\n",
      "Iter-10070, train loss-0.6761, acc-0.8000, valid loss-0.7161, acc-0.8260, test loss-0.7220, acc-0.8181\n",
      "Iter-10080, train loss-0.7011, acc-0.8200, valid loss-0.7156, acc-0.8260, test loss-0.7215, acc-0.8184\n",
      "Iter-10090, train loss-0.7911, acc-0.8200, valid loss-0.7151, acc-0.8258, test loss-0.7210, acc-0.8189\n",
      "Iter-10100, train loss-0.8441, acc-0.7400, valid loss-0.7146, acc-0.8268, test loss-0.7205, acc-0.8188\n",
      "Iter-10110, train loss-0.6806, acc-0.7800, valid loss-0.7141, acc-0.8264, test loss-0.7201, acc-0.8188\n",
      "Iter-10120, train loss-0.6050, acc-0.8800, valid loss-0.7136, acc-0.8268, test loss-0.7196, acc-0.8193\n",
      "Iter-10130, train loss-0.9342, acc-0.7000, valid loss-0.7131, acc-0.8266, test loss-0.7191, acc-0.8193\n",
      "Iter-10140, train loss-0.7465, acc-0.7800, valid loss-0.7126, acc-0.8270, test loss-0.7187, acc-0.8188\n",
      "Iter-10150, train loss-0.8667, acc-0.7600, valid loss-0.7121, acc-0.8272, test loss-0.7182, acc-0.8191\n",
      "Iter-10160, train loss-0.6963, acc-0.8400, valid loss-0.7116, acc-0.8266, test loss-0.7177, acc-0.8187\n",
      "Iter-10170, train loss-0.7847, acc-0.7800, valid loss-0.7111, acc-0.8268, test loss-0.7172, acc-0.8194\n",
      "Iter-10180, train loss-0.7978, acc-0.7400, valid loss-0.7106, acc-0.8270, test loss-0.7167, acc-0.8195\n",
      "Iter-10190, train loss-0.8121, acc-0.7400, valid loss-0.7102, acc-0.8270, test loss-0.7162, acc-0.8190\n",
      "Iter-10200, train loss-0.8383, acc-0.7600, valid loss-0.7097, acc-0.8274, test loss-0.7158, acc-0.8190\n",
      "Iter-10210, train loss-0.8015, acc-0.7800, valid loss-0.7092, acc-0.8274, test loss-0.7153, acc-0.8195\n",
      "Iter-10220, train loss-0.6274, acc-0.9400, valid loss-0.7087, acc-0.8272, test loss-0.7148, acc-0.8191\n",
      "Iter-10230, train loss-0.8036, acc-0.7200, valid loss-0.7083, acc-0.8274, test loss-0.7143, acc-0.8200\n",
      "Iter-10240, train loss-0.7116, acc-0.8400, valid loss-0.7078, acc-0.8274, test loss-0.7138, acc-0.8201\n",
      "Iter-10250, train loss-0.7493, acc-0.8400, valid loss-0.7073, acc-0.8274, test loss-0.7134, acc-0.8200\n",
      "Iter-10260, train loss-0.6518, acc-0.9000, valid loss-0.7068, acc-0.8276, test loss-0.7129, acc-0.8204\n",
      "Iter-10270, train loss-0.6539, acc-0.8600, valid loss-0.7063, acc-0.8276, test loss-0.7124, acc-0.8204\n",
      "Iter-10280, train loss-0.6944, acc-0.8600, valid loss-0.7058, acc-0.8274, test loss-0.7119, acc-0.8207\n",
      "Iter-10290, train loss-0.8077, acc-0.7600, valid loss-0.7054, acc-0.8278, test loss-0.7115, acc-0.8208\n",
      "Iter-10300, train loss-0.7796, acc-0.7400, valid loss-0.7049, acc-0.8278, test loss-0.7110, acc-0.8211\n",
      "Iter-10310, train loss-0.7288, acc-0.8000, valid loss-0.7044, acc-0.8284, test loss-0.7105, acc-0.8213\n",
      "Iter-10320, train loss-0.7871, acc-0.7800, valid loss-0.7039, acc-0.8282, test loss-0.7101, acc-0.8214\n",
      "Iter-10330, train loss-0.6303, acc-0.8600, valid loss-0.7035, acc-0.8284, test loss-0.7096, acc-0.8216\n",
      "Iter-10340, train loss-0.8238, acc-0.7800, valid loss-0.7030, acc-0.8284, test loss-0.7092, acc-0.8215\n",
      "Iter-10350, train loss-0.5632, acc-0.9200, valid loss-0.7025, acc-0.8284, test loss-0.7087, acc-0.8214\n",
      "Iter-10360, train loss-0.8604, acc-0.7600, valid loss-0.7020, acc-0.8286, test loss-0.7082, acc-0.8214\n",
      "Iter-10370, train loss-0.8021, acc-0.8400, valid loss-0.7015, acc-0.8286, test loss-0.7077, acc-0.8217\n",
      "Iter-10380, train loss-0.8477, acc-0.7600, valid loss-0.7010, acc-0.8290, test loss-0.7073, acc-0.8221\n",
      "Iter-10390, train loss-0.7470, acc-0.8600, valid loss-0.7005, acc-0.8292, test loss-0.7068, acc-0.8225\n",
      "Iter-10400, train loss-0.7134, acc-0.8200, valid loss-0.7000, acc-0.8292, test loss-0.7063, acc-0.8229\n",
      "Iter-10410, train loss-0.6808, acc-0.8600, valid loss-0.6996, acc-0.8296, test loss-0.7058, acc-0.8230\n",
      "Iter-10420, train loss-0.8377, acc-0.8200, valid loss-0.6991, acc-0.8302, test loss-0.7054, acc-0.8230\n",
      "Iter-10430, train loss-0.7032, acc-0.8000, valid loss-0.6986, acc-0.8308, test loss-0.7049, acc-0.8232\n",
      "Iter-10440, train loss-0.6819, acc-0.8000, valid loss-0.6982, acc-0.8302, test loss-0.7044, acc-0.8234\n",
      "Iter-10450, train loss-0.7887, acc-0.8000, valid loss-0.6977, acc-0.8306, test loss-0.7039, acc-0.8239\n",
      "Iter-10460, train loss-0.8400, acc-0.7200, valid loss-0.6973, acc-0.8302, test loss-0.7035, acc-0.8241\n",
      "Iter-10470, train loss-0.5448, acc-0.9200, valid loss-0.6968, acc-0.8300, test loss-0.7030, acc-0.8240\n",
      "Iter-10480, train loss-0.9540, acc-0.7400, valid loss-0.6963, acc-0.8304, test loss-0.7025, acc-0.8242\n",
      "Iter-10490, train loss-0.7347, acc-0.8400, valid loss-0.6958, acc-0.8304, test loss-0.7021, acc-0.8244\n",
      "Iter-10500, train loss-0.5890, acc-0.9000, valid loss-0.6954, acc-0.8308, test loss-0.7016, acc-0.8244\n",
      "Iter-10510, train loss-0.8286, acc-0.7800, valid loss-0.6949, acc-0.8310, test loss-0.7012, acc-0.8244\n",
      "Iter-10520, train loss-0.9882, acc-0.7400, valid loss-0.6945, acc-0.8310, test loss-0.7007, acc-0.8247\n",
      "Iter-10530, train loss-0.6575, acc-0.8400, valid loss-0.6940, acc-0.8314, test loss-0.7003, acc-0.8246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10540, train loss-0.7417, acc-0.7800, valid loss-0.6935, acc-0.8316, test loss-0.6998, acc-0.8248\n",
      "Iter-10550, train loss-0.5807, acc-0.9200, valid loss-0.6931, acc-0.8312, test loss-0.6994, acc-0.8248\n",
      "Iter-10560, train loss-0.8093, acc-0.7000, valid loss-0.6926, acc-0.8316, test loss-0.6989, acc-0.8249\n",
      "Iter-10570, train loss-0.7437, acc-0.8000, valid loss-0.6921, acc-0.8316, test loss-0.6985, acc-0.8249\n",
      "Iter-10580, train loss-0.7909, acc-0.7800, valid loss-0.6917, acc-0.8316, test loss-0.6980, acc-0.8248\n",
      "Iter-10590, train loss-0.7426, acc-0.8400, valid loss-0.6912, acc-0.8316, test loss-0.6976, acc-0.8250\n",
      "Iter-10600, train loss-0.6651, acc-0.8400, valid loss-0.6908, acc-0.8314, test loss-0.6972, acc-0.8253\n",
      "Iter-10610, train loss-0.6676, acc-0.8200, valid loss-0.6903, acc-0.8316, test loss-0.6968, acc-0.8253\n",
      "Iter-10620, train loss-0.6380, acc-0.8200, valid loss-0.6899, acc-0.8316, test loss-0.6963, acc-0.8255\n",
      "Iter-10630, train loss-0.6716, acc-0.8800, valid loss-0.6894, acc-0.8320, test loss-0.6959, acc-0.8258\n",
      "Iter-10640, train loss-0.5832, acc-0.8800, valid loss-0.6890, acc-0.8326, test loss-0.6954, acc-0.8258\n",
      "Iter-10650, train loss-0.7477, acc-0.8800, valid loss-0.6885, acc-0.8328, test loss-0.6950, acc-0.8258\n",
      "Iter-10660, train loss-0.6809, acc-0.8600, valid loss-0.6881, acc-0.8336, test loss-0.6946, acc-0.8261\n",
      "Iter-10670, train loss-0.9085, acc-0.7000, valid loss-0.6876, acc-0.8336, test loss-0.6941, acc-0.8259\n",
      "Iter-10680, train loss-0.7097, acc-0.8000, valid loss-0.6872, acc-0.8334, test loss-0.6937, acc-0.8258\n",
      "Iter-10690, train loss-0.7233, acc-0.9000, valid loss-0.6868, acc-0.8332, test loss-0.6932, acc-0.8260\n",
      "Iter-10700, train loss-0.6833, acc-0.8000, valid loss-0.6863, acc-0.8334, test loss-0.6928, acc-0.8260\n",
      "Iter-10710, train loss-0.7075, acc-0.8200, valid loss-0.6859, acc-0.8336, test loss-0.6923, acc-0.8263\n",
      "Iter-10720, train loss-0.6801, acc-0.8200, valid loss-0.6854, acc-0.8334, test loss-0.6919, acc-0.8266\n",
      "Iter-10730, train loss-0.6276, acc-0.9000, valid loss-0.6850, acc-0.8340, test loss-0.6914, acc-0.8267\n",
      "Iter-10740, train loss-0.7174, acc-0.8000, valid loss-0.6845, acc-0.8338, test loss-0.6909, acc-0.8270\n",
      "Iter-10750, train loss-0.6165, acc-0.8000, valid loss-0.6841, acc-0.8340, test loss-0.6905, acc-0.8270\n",
      "Iter-10760, train loss-0.5732, acc-0.8600, valid loss-0.6837, acc-0.8342, test loss-0.6901, acc-0.8271\n",
      "Iter-10770, train loss-0.6637, acc-0.8600, valid loss-0.6832, acc-0.8346, test loss-0.6897, acc-0.8272\n",
      "Iter-10780, train loss-0.7366, acc-0.7800, valid loss-0.6828, acc-0.8352, test loss-0.6892, acc-0.8274\n",
      "Iter-10790, train loss-0.6615, acc-0.8800, valid loss-0.6824, acc-0.8348, test loss-0.6887, acc-0.8273\n",
      "Iter-10800, train loss-0.6778, acc-0.8600, valid loss-0.6819, acc-0.8344, test loss-0.6883, acc-0.8276\n",
      "Iter-10810, train loss-0.7602, acc-0.7800, valid loss-0.6815, acc-0.8344, test loss-0.6879, acc-0.8274\n",
      "Iter-10820, train loss-0.8229, acc-0.7400, valid loss-0.6810, acc-0.8344, test loss-0.6875, acc-0.8275\n",
      "Iter-10830, train loss-0.6785, acc-0.8400, valid loss-0.6806, acc-0.8346, test loss-0.6870, acc-0.8278\n",
      "Iter-10840, train loss-0.6447, acc-0.8400, valid loss-0.6801, acc-0.8346, test loss-0.6865, acc-0.8281\n",
      "Iter-10850, train loss-0.7462, acc-0.8000, valid loss-0.6797, acc-0.8344, test loss-0.6861, acc-0.8282\n",
      "Iter-10860, train loss-0.7125, acc-0.8400, valid loss-0.6792, acc-0.8346, test loss-0.6856, acc-0.8286\n",
      "Iter-10870, train loss-0.7734, acc-0.7600, valid loss-0.6788, acc-0.8344, test loss-0.6852, acc-0.8286\n",
      "Iter-10880, train loss-0.8807, acc-0.7200, valid loss-0.6783, acc-0.8342, test loss-0.6847, acc-0.8284\n",
      "Iter-10890, train loss-0.7175, acc-0.8600, valid loss-0.6779, acc-0.8344, test loss-0.6843, acc-0.8284\n",
      "Iter-10900, train loss-0.7006, acc-0.8400, valid loss-0.6774, acc-0.8344, test loss-0.6839, acc-0.8287\n",
      "Iter-10910, train loss-0.6626, acc-0.8200, valid loss-0.6770, acc-0.8342, test loss-0.6835, acc-0.8290\n",
      "Iter-10920, train loss-0.6787, acc-0.8400, valid loss-0.6766, acc-0.8346, test loss-0.6830, acc-0.8289\n",
      "Iter-10930, train loss-0.8864, acc-0.7400, valid loss-0.6762, acc-0.8348, test loss-0.6826, acc-0.8291\n",
      "Iter-10940, train loss-0.8163, acc-0.7400, valid loss-0.6757, acc-0.8348, test loss-0.6822, acc-0.8292\n",
      "Iter-10950, train loss-0.6472, acc-0.8600, valid loss-0.6753, acc-0.8348, test loss-0.6818, acc-0.8291\n",
      "Iter-10960, train loss-0.7316, acc-0.8400, valid loss-0.6749, acc-0.8350, test loss-0.6813, acc-0.8292\n",
      "Iter-10970, train loss-0.5594, acc-0.8400, valid loss-0.6745, acc-0.8350, test loss-0.6809, acc-0.8293\n",
      "Iter-10980, train loss-0.6498, acc-0.8800, valid loss-0.6740, acc-0.8354, test loss-0.6805, acc-0.8298\n",
      "Iter-10990, train loss-0.7304, acc-0.8600, valid loss-0.6736, acc-0.8352, test loss-0.6801, acc-0.8300\n",
      "Iter-11000, train loss-0.7204, acc-0.8200, valid loss-0.6732, acc-0.8350, test loss-0.6797, acc-0.8298\n",
      "Iter-11010, train loss-0.6811, acc-0.8200, valid loss-0.6727, acc-0.8352, test loss-0.6793, acc-0.8302\n",
      "Iter-11020, train loss-0.5740, acc-0.9000, valid loss-0.6723, acc-0.8354, test loss-0.6789, acc-0.8300\n",
      "Iter-11030, train loss-0.7477, acc-0.8000, valid loss-0.6718, acc-0.8352, test loss-0.6784, acc-0.8297\n",
      "Iter-11040, train loss-0.7618, acc-0.8000, valid loss-0.6714, acc-0.8352, test loss-0.6780, acc-0.8302\n",
      "Iter-11050, train loss-0.5643, acc-0.8600, valid loss-0.6710, acc-0.8354, test loss-0.6776, acc-0.8300\n",
      "Iter-11060, train loss-0.6992, acc-0.8000, valid loss-0.6706, acc-0.8354, test loss-0.6771, acc-0.8301\n",
      "Iter-11070, train loss-0.7471, acc-0.8400, valid loss-0.6701, acc-0.8360, test loss-0.6767, acc-0.8306\n",
      "Iter-11080, train loss-0.6049, acc-0.8800, valid loss-0.6698, acc-0.8356, test loss-0.6763, acc-0.8307\n",
      "Iter-11090, train loss-1.0050, acc-0.8000, valid loss-0.6694, acc-0.8360, test loss-0.6759, acc-0.8308\n",
      "Iter-11100, train loss-0.5841, acc-0.9000, valid loss-0.6690, acc-0.8364, test loss-0.6755, acc-0.8312\n",
      "Iter-11110, train loss-0.5508, acc-0.9200, valid loss-0.6685, acc-0.8360, test loss-0.6750, acc-0.8312\n",
      "Iter-11120, train loss-0.7146, acc-0.7400, valid loss-0.6681, acc-0.8372, test loss-0.6746, acc-0.8313\n",
      "Iter-11130, train loss-0.6407, acc-0.9000, valid loss-0.6677, acc-0.8372, test loss-0.6742, acc-0.8309\n",
      "Iter-11140, train loss-0.6567, acc-0.8200, valid loss-0.6673, acc-0.8370, test loss-0.6738, acc-0.8313\n",
      "Iter-11150, train loss-0.6006, acc-0.8600, valid loss-0.6669, acc-0.8370, test loss-0.6734, acc-0.8311\n",
      "Iter-11160, train loss-0.6015, acc-0.9200, valid loss-0.6665, acc-0.8370, test loss-0.6729, acc-0.8313\n",
      "Iter-11170, train loss-0.6412, acc-0.8800, valid loss-0.6661, acc-0.8370, test loss-0.6724, acc-0.8312\n",
      "Iter-11180, train loss-0.8154, acc-0.7200, valid loss-0.6657, acc-0.8374, test loss-0.6720, acc-0.8312\n",
      "Iter-11190, train loss-0.7565, acc-0.8400, valid loss-0.6653, acc-0.8374, test loss-0.6716, acc-0.8316\n",
      "Iter-11200, train loss-0.6213, acc-0.8400, valid loss-0.6649, acc-0.8374, test loss-0.6711, acc-0.8315\n",
      "Iter-11210, train loss-0.7638, acc-0.7600, valid loss-0.6644, acc-0.8370, test loss-0.6707, acc-0.8314\n",
      "Iter-11220, train loss-0.5924, acc-0.9000, valid loss-0.6640, acc-0.8370, test loss-0.6703, acc-0.8313\n",
      "Iter-11230, train loss-0.6649, acc-0.8400, valid loss-0.6636, acc-0.8372, test loss-0.6699, acc-0.8314\n",
      "Iter-11240, train loss-0.6708, acc-0.8000, valid loss-0.6631, acc-0.8374, test loss-0.6694, acc-0.8318\n",
      "Iter-11250, train loss-0.7441, acc-0.7600, valid loss-0.6627, acc-0.8374, test loss-0.6691, acc-0.8318\n",
      "Iter-11260, train loss-0.6603, acc-0.8600, valid loss-0.6623, acc-0.8376, test loss-0.6686, acc-0.8322\n",
      "Iter-11270, train loss-0.7054, acc-0.8400, valid loss-0.6619, acc-0.8378, test loss-0.6682, acc-0.8319\n",
      "Iter-11280, train loss-0.5749, acc-0.8800, valid loss-0.6615, acc-0.8378, test loss-0.6678, acc-0.8322\n",
      "Iter-11290, train loss-0.6391, acc-0.8600, valid loss-0.6611, acc-0.8372, test loss-0.6675, acc-0.8326\n",
      "Iter-11300, train loss-0.5840, acc-0.8600, valid loss-0.6608, acc-0.8382, test loss-0.6670, acc-0.8322\n",
      "Iter-11310, train loss-0.6584, acc-0.8400, valid loss-0.6604, acc-0.8386, test loss-0.6666, acc-0.8325\n",
      "Iter-11320, train loss-0.4367, acc-0.9600, valid loss-0.6600, acc-0.8386, test loss-0.6662, acc-0.8325\n",
      "Iter-11330, train loss-0.7794, acc-0.7600, valid loss-0.6596, acc-0.8386, test loss-0.6659, acc-0.8330\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-11340, train loss-0.7332, acc-0.8400, valid loss-0.6592, acc-0.8390, test loss-0.6655, acc-0.8332\n",
      "Iter-11350, train loss-0.4801, acc-0.9000, valid loss-0.6587, acc-0.8392, test loss-0.6651, acc-0.8333\n",
      "Iter-11360, train loss-0.5975, acc-0.9000, valid loss-0.6583, acc-0.8386, test loss-0.6648, acc-0.8333\n",
      "Iter-11370, train loss-0.6563, acc-0.8400, valid loss-0.6579, acc-0.8388, test loss-0.6643, acc-0.8334\n",
      "Iter-11380, train loss-0.7367, acc-0.8000, valid loss-0.6576, acc-0.8394, test loss-0.6639, acc-0.8332\n",
      "Iter-11390, train loss-0.7012, acc-0.7800, valid loss-0.6572, acc-0.8392, test loss-0.6635, acc-0.8334\n",
      "Iter-11400, train loss-0.6638, acc-0.8600, valid loss-0.6568, acc-0.8396, test loss-0.6632, acc-0.8333\n",
      "Iter-11410, train loss-0.6718, acc-0.8600, valid loss-0.6564, acc-0.8400, test loss-0.6628, acc-0.8331\n",
      "Iter-11420, train loss-0.7143, acc-0.7800, valid loss-0.6560, acc-0.8402, test loss-0.6624, acc-0.8333\n",
      "Iter-11430, train loss-0.7240, acc-0.7800, valid loss-0.6556, acc-0.8402, test loss-0.6620, acc-0.8333\n",
      "Iter-11440, train loss-0.6323, acc-0.8600, valid loss-0.6552, acc-0.8400, test loss-0.6617, acc-0.8338\n",
      "Iter-11450, train loss-0.7586, acc-0.8000, valid loss-0.6548, acc-0.8402, test loss-0.6613, acc-0.8337\n",
      "Iter-11460, train loss-0.7369, acc-0.7400, valid loss-0.6544, acc-0.8398, test loss-0.6608, acc-0.8340\n",
      "Iter-11470, train loss-0.7781, acc-0.8200, valid loss-0.6540, acc-0.8396, test loss-0.6604, acc-0.8337\n",
      "Iter-11480, train loss-0.6075, acc-0.8400, valid loss-0.6536, acc-0.8400, test loss-0.6601, acc-0.8342\n",
      "Iter-11490, train loss-0.6241, acc-0.9000, valid loss-0.6532, acc-0.8402, test loss-0.6596, acc-0.8343\n",
      "Iter-11500, train loss-0.7928, acc-0.8200, valid loss-0.6528, acc-0.8400, test loss-0.6592, acc-0.8340\n",
      "Iter-11510, train loss-0.6409, acc-0.8800, valid loss-0.6525, acc-0.8406, test loss-0.6588, acc-0.8344\n",
      "Iter-11520, train loss-0.6527, acc-0.8200, valid loss-0.6521, acc-0.8404, test loss-0.6584, acc-0.8345\n",
      "Iter-11530, train loss-0.6621, acc-0.8200, valid loss-0.6517, acc-0.8408, test loss-0.6580, acc-0.8344\n",
      "Iter-11540, train loss-0.5534, acc-0.8600, valid loss-0.6513, acc-0.8406, test loss-0.6577, acc-0.8343\n",
      "Iter-11550, train loss-0.7442, acc-0.7800, valid loss-0.6509, acc-0.8408, test loss-0.6573, acc-0.8350\n",
      "Iter-11560, train loss-0.6003, acc-0.8600, valid loss-0.6505, acc-0.8406, test loss-0.6569, acc-0.8347\n",
      "Iter-11570, train loss-0.6875, acc-0.8400, valid loss-0.6501, acc-0.8418, test loss-0.6565, acc-0.8352\n",
      "Iter-11580, train loss-0.5200, acc-0.9000, valid loss-0.6497, acc-0.8420, test loss-0.6561, acc-0.8353\n",
      "Iter-11590, train loss-0.7965, acc-0.7600, valid loss-0.6493, acc-0.8418, test loss-0.6557, acc-0.8356\n",
      "Iter-11600, train loss-0.7404, acc-0.7800, valid loss-0.6489, acc-0.8418, test loss-0.6553, acc-0.8356\n",
      "Iter-11610, train loss-0.5955, acc-0.7600, valid loss-0.6486, acc-0.8422, test loss-0.6550, acc-0.8355\n",
      "Iter-11620, train loss-0.5306, acc-0.9000, valid loss-0.6482, acc-0.8426, test loss-0.6546, acc-0.8355\n",
      "Iter-11630, train loss-0.7270, acc-0.8200, valid loss-0.6478, acc-0.8422, test loss-0.6541, acc-0.8355\n",
      "Iter-11640, train loss-0.6990, acc-0.8600, valid loss-0.6474, acc-0.8422, test loss-0.6537, acc-0.8351\n",
      "Iter-11650, train loss-0.7317, acc-0.8000, valid loss-0.6470, acc-0.8426, test loss-0.6534, acc-0.8350\n",
      "Iter-11660, train loss-0.6828, acc-0.7600, valid loss-0.6467, acc-0.8426, test loss-0.6530, acc-0.8350\n",
      "Iter-11670, train loss-0.6855, acc-0.8400, valid loss-0.6463, acc-0.8428, test loss-0.6527, acc-0.8351\n",
      "Iter-11680, train loss-0.6453, acc-0.8800, valid loss-0.6459, acc-0.8428, test loss-0.6523, acc-0.8352\n",
      "Iter-11690, train loss-0.6245, acc-0.8600, valid loss-0.6454, acc-0.8430, test loss-0.6519, acc-0.8356\n",
      "Iter-11700, train loss-0.4607, acc-0.8800, valid loss-0.6450, acc-0.8432, test loss-0.6515, acc-0.8356\n",
      "Iter-11710, train loss-0.5741, acc-0.8200, valid loss-0.6446, acc-0.8438, test loss-0.6511, acc-0.8360\n",
      "Iter-11720, train loss-0.8289, acc-0.8200, valid loss-0.6443, acc-0.8432, test loss-0.6507, acc-0.8362\n",
      "Iter-11730, train loss-0.6408, acc-0.8400, valid loss-0.6439, acc-0.8430, test loss-0.6504, acc-0.8361\n",
      "Iter-11740, train loss-0.5674, acc-0.8200, valid loss-0.6435, acc-0.8428, test loss-0.6500, acc-0.8363\n",
      "Iter-11750, train loss-0.8253, acc-0.7600, valid loss-0.6431, acc-0.8430, test loss-0.6497, acc-0.8360\n",
      "Iter-11760, train loss-0.6169, acc-0.8600, valid loss-0.6427, acc-0.8434, test loss-0.6493, acc-0.8361\n",
      "Iter-11770, train loss-0.7207, acc-0.8200, valid loss-0.6424, acc-0.8430, test loss-0.6489, acc-0.8362\n",
      "Iter-11780, train loss-0.6278, acc-0.8200, valid loss-0.6420, acc-0.8438, test loss-0.6486, acc-0.8367\n",
      "Iter-11790, train loss-0.5772, acc-0.8800, valid loss-0.6416, acc-0.8434, test loss-0.6482, acc-0.8367\n",
      "Iter-11800, train loss-0.4880, acc-0.9200, valid loss-0.6412, acc-0.8432, test loss-0.6479, acc-0.8365\n",
      "Iter-11810, train loss-0.6545, acc-0.8800, valid loss-0.6409, acc-0.8440, test loss-0.6475, acc-0.8365\n",
      "Iter-11820, train loss-0.6005, acc-0.8400, valid loss-0.6405, acc-0.8444, test loss-0.6471, acc-0.8363\n",
      "Iter-11830, train loss-0.5123, acc-0.9400, valid loss-0.6401, acc-0.8444, test loss-0.6467, acc-0.8364\n",
      "Iter-11840, train loss-0.7013, acc-0.8000, valid loss-0.6397, acc-0.8440, test loss-0.6463, acc-0.8367\n",
      "Iter-11850, train loss-0.6585, acc-0.8200, valid loss-0.6394, acc-0.8446, test loss-0.6460, acc-0.8369\n",
      "Iter-11860, train loss-0.6228, acc-0.8400, valid loss-0.6391, acc-0.8444, test loss-0.6456, acc-0.8368\n",
      "Iter-11870, train loss-0.6738, acc-0.8000, valid loss-0.6387, acc-0.8442, test loss-0.6453, acc-0.8368\n",
      "Iter-11880, train loss-0.6003, acc-0.8400, valid loss-0.6383, acc-0.8446, test loss-0.6449, acc-0.8369\n",
      "Iter-11890, train loss-0.5732, acc-0.8800, valid loss-0.6379, acc-0.8438, test loss-0.6446, acc-0.8370\n",
      "Iter-11900, train loss-0.6036, acc-0.7800, valid loss-0.6376, acc-0.8444, test loss-0.6442, acc-0.8371\n",
      "Iter-11910, train loss-0.5835, acc-0.8800, valid loss-0.6372, acc-0.8438, test loss-0.6438, acc-0.8369\n",
      "Iter-11920, train loss-0.7800, acc-0.7800, valid loss-0.6368, acc-0.8436, test loss-0.6435, acc-0.8366\n",
      "Iter-11930, train loss-0.6516, acc-0.7600, valid loss-0.6365, acc-0.8440, test loss-0.6432, acc-0.8370\n",
      "Iter-11940, train loss-0.5398, acc-0.9400, valid loss-0.6361, acc-0.8444, test loss-0.6428, acc-0.8375\n",
      "Iter-11950, train loss-0.6270, acc-0.8800, valid loss-0.6358, acc-0.8442, test loss-0.6424, acc-0.8373\n",
      "Iter-11960, train loss-0.7478, acc-0.8200, valid loss-0.6355, acc-0.8440, test loss-0.6421, acc-0.8375\n",
      "Iter-11970, train loss-0.7938, acc-0.8000, valid loss-0.6351, acc-0.8444, test loss-0.6417, acc-0.8377\n",
      "Iter-11980, train loss-0.5686, acc-0.8800, valid loss-0.6347, acc-0.8438, test loss-0.6414, acc-0.8373\n",
      "Iter-11990, train loss-0.7232, acc-0.8400, valid loss-0.6344, acc-0.8440, test loss-0.6410, acc-0.8375\n",
      "Iter-12000, train loss-0.5767, acc-0.9000, valid loss-0.6340, acc-0.8444, test loss-0.6407, acc-0.8375\n",
      "Iter-12010, train loss-0.7707, acc-0.8000, valid loss-0.6336, acc-0.8446, test loss-0.6403, acc-0.8377\n",
      "Iter-12020, train loss-0.6837, acc-0.8000, valid loss-0.6333, acc-0.8444, test loss-0.6399, acc-0.8375\n",
      "Iter-12030, train loss-0.5938, acc-0.9000, valid loss-0.6329, acc-0.8442, test loss-0.6395, acc-0.8376\n",
      "Iter-12040, train loss-0.7856, acc-0.8000, valid loss-0.6325, acc-0.8446, test loss-0.6391, acc-0.8376\n",
      "Iter-12050, train loss-0.8290, acc-0.7400, valid loss-0.6321, acc-0.8448, test loss-0.6388, acc-0.8377\n",
      "Iter-12060, train loss-0.6893, acc-0.8200, valid loss-0.6318, acc-0.8446, test loss-0.6384, acc-0.8378\n",
      "Iter-12070, train loss-0.7257, acc-0.8000, valid loss-0.6314, acc-0.8448, test loss-0.6380, acc-0.8378\n",
      "Iter-12080, train loss-0.6898, acc-0.8400, valid loss-0.6310, acc-0.8450, test loss-0.6377, acc-0.8379\n",
      "Iter-12090, train loss-0.6158, acc-0.8800, valid loss-0.6306, acc-0.8456, test loss-0.6373, acc-0.8378\n",
      "Iter-12100, train loss-0.6175, acc-0.8800, valid loss-0.6303, acc-0.8456, test loss-0.6369, acc-0.8382\n",
      "Iter-12110, train loss-0.5871, acc-0.8600, valid loss-0.6299, acc-0.8458, test loss-0.6365, acc-0.8381\n",
      "Iter-12120, train loss-0.6838, acc-0.8200, valid loss-0.6296, acc-0.8454, test loss-0.6362, acc-0.8381\n",
      "Iter-12130, train loss-0.6228, acc-0.8400, valid loss-0.6292, acc-0.8458, test loss-0.6358, acc-0.8383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12140, train loss-0.6039, acc-0.8600, valid loss-0.6289, acc-0.8462, test loss-0.6354, acc-0.8384\n",
      "Iter-12150, train loss-0.5752, acc-0.8800, valid loss-0.6284, acc-0.8466, test loss-0.6350, acc-0.8381\n",
      "Iter-12160, train loss-0.6771, acc-0.8200, valid loss-0.6280, acc-0.8472, test loss-0.6347, acc-0.8383\n",
      "Iter-12170, train loss-0.7306, acc-0.7400, valid loss-0.6276, acc-0.8472, test loss-0.6344, acc-0.8383\n",
      "Iter-12180, train loss-0.8162, acc-0.7600, valid loss-0.6273, acc-0.8472, test loss-0.6340, acc-0.8382\n",
      "Iter-12190, train loss-0.6588, acc-0.7800, valid loss-0.6269, acc-0.8474, test loss-0.6337, acc-0.8382\n",
      "Iter-12200, train loss-0.6132, acc-0.8000, valid loss-0.6266, acc-0.8474, test loss-0.6334, acc-0.8384\n",
      "Iter-12210, train loss-0.6906, acc-0.8000, valid loss-0.6262, acc-0.8476, test loss-0.6330, acc-0.8388\n",
      "Iter-12220, train loss-0.6016, acc-0.8600, valid loss-0.6259, acc-0.8472, test loss-0.6327, acc-0.8386\n",
      "Iter-12230, train loss-0.6962, acc-0.8000, valid loss-0.6255, acc-0.8470, test loss-0.6324, acc-0.8387\n",
      "Iter-12240, train loss-0.4555, acc-0.9000, valid loss-0.6251, acc-0.8470, test loss-0.6320, acc-0.8387\n",
      "Iter-12250, train loss-0.5184, acc-0.8800, valid loss-0.6248, acc-0.8470, test loss-0.6317, acc-0.8387\n",
      "Iter-12260, train loss-0.5065, acc-0.9200, valid loss-0.6245, acc-0.8474, test loss-0.6313, acc-0.8390\n",
      "Iter-12270, train loss-0.8196, acc-0.8000, valid loss-0.6241, acc-0.8466, test loss-0.6310, acc-0.8389\n",
      "Iter-12280, train loss-0.6903, acc-0.8000, valid loss-0.6238, acc-0.8470, test loss-0.6307, acc-0.8387\n",
      "Iter-12290, train loss-0.6073, acc-0.8400, valid loss-0.6235, acc-0.8472, test loss-0.6303, acc-0.8388\n",
      "Iter-12300, train loss-0.5592, acc-0.8000, valid loss-0.6230, acc-0.8472, test loss-0.6299, acc-0.8390\n",
      "Iter-12310, train loss-0.6790, acc-0.8600, valid loss-0.6227, acc-0.8470, test loss-0.6296, acc-0.8390\n",
      "Iter-12320, train loss-0.8046, acc-0.8200, valid loss-0.6224, acc-0.8470, test loss-0.6293, acc-0.8391\n",
      "Iter-12330, train loss-0.5608, acc-0.8800, valid loss-0.6220, acc-0.8472, test loss-0.6290, acc-0.8393\n",
      "Iter-12340, train loss-0.7681, acc-0.7200, valid loss-0.6217, acc-0.8478, test loss-0.6287, acc-0.8393\n",
      "Iter-12350, train loss-0.6638, acc-0.8000, valid loss-0.6213, acc-0.8480, test loss-0.6283, acc-0.8391\n",
      "Iter-12360, train loss-0.5995, acc-0.8400, valid loss-0.6209, acc-0.8476, test loss-0.6279, acc-0.8398\n",
      "Iter-12370, train loss-0.5905, acc-0.8400, valid loss-0.6206, acc-0.8478, test loss-0.6276, acc-0.8396\n",
      "Iter-12380, train loss-0.6464, acc-0.8800, valid loss-0.6203, acc-0.8482, test loss-0.6273, acc-0.8396\n",
      "Iter-12390, train loss-0.5939, acc-0.9000, valid loss-0.6200, acc-0.8478, test loss-0.6269, acc-0.8394\n",
      "Iter-12400, train loss-0.5106, acc-0.9000, valid loss-0.6196, acc-0.8478, test loss-0.6266, acc-0.8395\n",
      "Iter-12410, train loss-0.5798, acc-0.8400, valid loss-0.6193, acc-0.8478, test loss-0.6263, acc-0.8396\n",
      "Iter-12420, train loss-0.6016, acc-0.8600, valid loss-0.6189, acc-0.8482, test loss-0.6259, acc-0.8395\n",
      "Iter-12430, train loss-0.8584, acc-0.7000, valid loss-0.6186, acc-0.8482, test loss-0.6256, acc-0.8397\n",
      "Iter-12440, train loss-0.6928, acc-0.8800, valid loss-0.6182, acc-0.8482, test loss-0.6252, acc-0.8401\n",
      "Iter-12450, train loss-0.5965, acc-0.9000, valid loss-0.6178, acc-0.8484, test loss-0.6249, acc-0.8399\n",
      "Iter-12460, train loss-0.5765, acc-0.8400, valid loss-0.6174, acc-0.8480, test loss-0.6246, acc-0.8401\n",
      "Iter-12470, train loss-0.4983, acc-0.9200, valid loss-0.6171, acc-0.8480, test loss-0.6242, acc-0.8404\n",
      "Iter-12480, train loss-0.6239, acc-0.8000, valid loss-0.6167, acc-0.8482, test loss-0.6239, acc-0.8408\n",
      "Iter-12490, train loss-0.4499, acc-0.9400, valid loss-0.6164, acc-0.8486, test loss-0.6236, acc-0.8411\n",
      "Iter-12500, train loss-0.7068, acc-0.7800, valid loss-0.6159, acc-0.8486, test loss-0.6232, acc-0.8411\n",
      "Iter-12510, train loss-0.6057, acc-0.8200, valid loss-0.6156, acc-0.8486, test loss-0.6229, acc-0.8410\n",
      "Iter-12520, train loss-0.6478, acc-0.8400, valid loss-0.6152, acc-0.8486, test loss-0.6225, acc-0.8412\n",
      "Iter-12530, train loss-0.6069, acc-0.8600, valid loss-0.6148, acc-0.8486, test loss-0.6222, acc-0.8413\n",
      "Iter-12540, train loss-0.7013, acc-0.8400, valid loss-0.6145, acc-0.8490, test loss-0.6218, acc-0.8415\n",
      "Iter-12550, train loss-0.5719, acc-0.8600, valid loss-0.6142, acc-0.8488, test loss-0.6214, acc-0.8416\n",
      "Iter-12560, train loss-0.7189, acc-0.8000, valid loss-0.6139, acc-0.8486, test loss-0.6211, acc-0.8420\n",
      "Iter-12570, train loss-0.5409, acc-0.8800, valid loss-0.6135, acc-0.8490, test loss-0.6208, acc-0.8417\n",
      "Iter-12580, train loss-0.5966, acc-0.7800, valid loss-0.6133, acc-0.8486, test loss-0.6205, acc-0.8415\n",
      "Iter-12590, train loss-0.6427, acc-0.8000, valid loss-0.6129, acc-0.8492, test loss-0.6202, acc-0.8416\n",
      "Iter-12600, train loss-0.6491, acc-0.8400, valid loss-0.6125, acc-0.8490, test loss-0.6198, acc-0.8417\n",
      "Iter-12610, train loss-0.6450, acc-0.8600, valid loss-0.6122, acc-0.8490, test loss-0.6195, acc-0.8417\n",
      "Iter-12620, train loss-0.6520, acc-0.8400, valid loss-0.6119, acc-0.8492, test loss-0.6192, acc-0.8419\n",
      "Iter-12630, train loss-0.6285, acc-0.8600, valid loss-0.6116, acc-0.8492, test loss-0.6189, acc-0.8423\n",
      "Iter-12640, train loss-0.6973, acc-0.8400, valid loss-0.6112, acc-0.8494, test loss-0.6186, acc-0.8420\n",
      "Iter-12650, train loss-0.7029, acc-0.8200, valid loss-0.6109, acc-0.8494, test loss-0.6182, acc-0.8419\n",
      "Iter-12660, train loss-0.5875, acc-0.8800, valid loss-0.6106, acc-0.8492, test loss-0.6178, acc-0.8422\n",
      "Iter-12670, train loss-0.8710, acc-0.7800, valid loss-0.6103, acc-0.8492, test loss-0.6175, acc-0.8423\n",
      "Iter-12680, train loss-0.5015, acc-0.9000, valid loss-0.6099, acc-0.8494, test loss-0.6171, acc-0.8420\n",
      "Iter-12690, train loss-0.8241, acc-0.7200, valid loss-0.6096, acc-0.8498, test loss-0.6167, acc-0.8426\n",
      "Iter-12700, train loss-0.7639, acc-0.8400, valid loss-0.6093, acc-0.8498, test loss-0.6164, acc-0.8426\n",
      "Iter-12710, train loss-0.7065, acc-0.8000, valid loss-0.6090, acc-0.8494, test loss-0.6162, acc-0.8425\n",
      "Iter-12720, train loss-0.7154, acc-0.7800, valid loss-0.6087, acc-0.8492, test loss-0.6158, acc-0.8426\n",
      "Iter-12730, train loss-0.8163, acc-0.7400, valid loss-0.6084, acc-0.8496, test loss-0.6155, acc-0.8426\n",
      "Iter-12740, train loss-0.6600, acc-0.8000, valid loss-0.6081, acc-0.8494, test loss-0.6151, acc-0.8429\n",
      "Iter-12750, train loss-0.4909, acc-0.9000, valid loss-0.6077, acc-0.8496, test loss-0.6148, acc-0.8428\n",
      "Iter-12760, train loss-0.7319, acc-0.8400, valid loss-0.6074, acc-0.8498, test loss-0.6145, acc-0.8430\n",
      "Iter-12770, train loss-0.5579, acc-0.8400, valid loss-0.6070, acc-0.8498, test loss-0.6142, acc-0.8430\n",
      "Iter-12780, train loss-0.5747, acc-0.8600, valid loss-0.6067, acc-0.8498, test loss-0.6138, acc-0.8429\n",
      "Iter-12790, train loss-0.7295, acc-0.7600, valid loss-0.6064, acc-0.8498, test loss-0.6135, acc-0.8430\n",
      "Iter-12800, train loss-0.8375, acc-0.7200, valid loss-0.6061, acc-0.8498, test loss-0.6132, acc-0.8430\n",
      "Iter-12810, train loss-0.4881, acc-0.9400, valid loss-0.6057, acc-0.8498, test loss-0.6129, acc-0.8430\n",
      "Iter-12820, train loss-0.6397, acc-0.8200, valid loss-0.6054, acc-0.8498, test loss-0.6125, acc-0.8429\n",
      "Iter-12830, train loss-0.5436, acc-0.8200, valid loss-0.6051, acc-0.8498, test loss-0.6122, acc-0.8430\n",
      "Iter-12840, train loss-0.4489, acc-0.9400, valid loss-0.6048, acc-0.8498, test loss-0.6119, acc-0.8433\n",
      "Iter-12850, train loss-0.8945, acc-0.7200, valid loss-0.6045, acc-0.8498, test loss-0.6115, acc-0.8436\n",
      "Iter-12860, train loss-0.6378, acc-0.8600, valid loss-0.6042, acc-0.8498, test loss-0.6111, acc-0.8439\n",
      "Iter-12870, train loss-0.6669, acc-0.8200, valid loss-0.6038, acc-0.8498, test loss-0.6108, acc-0.8439\n",
      "Iter-12880, train loss-0.6260, acc-0.8600, valid loss-0.6035, acc-0.8498, test loss-0.6105, acc-0.8441\n",
      "Iter-12890, train loss-0.6658, acc-0.8600, valid loss-0.6032, acc-0.8498, test loss-0.6102, acc-0.8443\n",
      "Iter-12900, train loss-0.5041, acc-0.8400, valid loss-0.6029, acc-0.8500, test loss-0.6098, acc-0.8441\n",
      "Iter-12910, train loss-0.7037, acc-0.7800, valid loss-0.6025, acc-0.8498, test loss-0.6096, acc-0.8442\n",
      "Iter-12920, train loss-0.6692, acc-0.8200, valid loss-0.6023, acc-0.8502, test loss-0.6092, acc-0.8443\n",
      "Iter-12930, train loss-0.5915, acc-0.8400, valid loss-0.6019, acc-0.8502, test loss-0.6089, acc-0.8441\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12940, train loss-0.5298, acc-0.8800, valid loss-0.6015, acc-0.8502, test loss-0.6086, acc-0.8444\n",
      "Iter-12950, train loss-0.7874, acc-0.9000, valid loss-0.6012, acc-0.8502, test loss-0.6082, acc-0.8447\n",
      "Iter-12960, train loss-0.5175, acc-0.8800, valid loss-0.6009, acc-0.8506, test loss-0.6079, acc-0.8446\n",
      "Iter-12970, train loss-0.4721, acc-0.8200, valid loss-0.6006, acc-0.8506, test loss-0.6076, acc-0.8451\n",
      "Iter-12980, train loss-0.6414, acc-0.8400, valid loss-0.6002, acc-0.8504, test loss-0.6073, acc-0.8449\n",
      "Iter-12990, train loss-0.6619, acc-0.7800, valid loss-0.5999, acc-0.8510, test loss-0.6069, acc-0.8454\n",
      "Iter-13000, train loss-0.5354, acc-0.9000, valid loss-0.5996, acc-0.8508, test loss-0.6066, acc-0.8458\n",
      "Iter-13010, train loss-0.5064, acc-0.8800, valid loss-0.5992, acc-0.8512, test loss-0.6063, acc-0.8459\n",
      "Iter-13020, train loss-0.5124, acc-0.8400, valid loss-0.5989, acc-0.8510, test loss-0.6060, acc-0.8462\n",
      "Iter-13030, train loss-0.7753, acc-0.7200, valid loss-0.5986, acc-0.8512, test loss-0.6057, acc-0.8466\n",
      "Iter-13040, train loss-0.7339, acc-0.7800, valid loss-0.5983, acc-0.8510, test loss-0.6054, acc-0.8464\n",
      "Iter-13050, train loss-0.7649, acc-0.7400, valid loss-0.5980, acc-0.8512, test loss-0.6051, acc-0.8462\n",
      "Iter-13060, train loss-0.8676, acc-0.7200, valid loss-0.5977, acc-0.8516, test loss-0.6048, acc-0.8463\n",
      "Iter-13070, train loss-0.6188, acc-0.8400, valid loss-0.5973, acc-0.8516, test loss-0.6044, acc-0.8460\n",
      "Iter-13080, train loss-0.5220, acc-0.9200, valid loss-0.5970, acc-0.8516, test loss-0.6042, acc-0.8460\n",
      "Iter-13090, train loss-0.6470, acc-0.8200, valid loss-0.5967, acc-0.8518, test loss-0.6038, acc-0.8462\n",
      "Iter-13100, train loss-0.5459, acc-0.9200, valid loss-0.5964, acc-0.8516, test loss-0.6035, acc-0.8464\n",
      "Iter-13110, train loss-0.6439, acc-0.8200, valid loss-0.5961, acc-0.8516, test loss-0.6032, acc-0.8464\n",
      "Iter-13120, train loss-0.6340, acc-0.8000, valid loss-0.5958, acc-0.8516, test loss-0.6029, acc-0.8469\n",
      "Iter-13130, train loss-0.6897, acc-0.7600, valid loss-0.5955, acc-0.8516, test loss-0.6026, acc-0.8466\n",
      "Iter-13140, train loss-0.6492, acc-0.9000, valid loss-0.5952, acc-0.8516, test loss-0.6023, acc-0.8465\n",
      "Iter-13150, train loss-0.6950, acc-0.8200, valid loss-0.5949, acc-0.8516, test loss-0.6020, acc-0.8465\n",
      "Iter-13160, train loss-0.6276, acc-0.8400, valid loss-0.5946, acc-0.8518, test loss-0.6017, acc-0.8466\n",
      "Iter-13170, train loss-0.6615, acc-0.8400, valid loss-0.5944, acc-0.8518, test loss-0.6015, acc-0.8466\n",
      "Iter-13180, train loss-0.6161, acc-0.8400, valid loss-0.5940, acc-0.8518, test loss-0.6012, acc-0.8467\n",
      "Iter-13190, train loss-0.5055, acc-0.8800, valid loss-0.5937, acc-0.8518, test loss-0.6009, acc-0.8468\n",
      "Iter-13200, train loss-0.7097, acc-0.8200, valid loss-0.5934, acc-0.8518, test loss-0.6006, acc-0.8467\n",
      "Iter-13210, train loss-0.5086, acc-0.9000, valid loss-0.5931, acc-0.8520, test loss-0.6003, acc-0.8468\n",
      "Iter-13220, train loss-0.5796, acc-0.8800, valid loss-0.5928, acc-0.8520, test loss-0.5999, acc-0.8466\n",
      "Iter-13230, train loss-0.5934, acc-0.8800, valid loss-0.5925, acc-0.8520, test loss-0.5996, acc-0.8464\n",
      "Iter-13240, train loss-0.5267, acc-0.8600, valid loss-0.5922, acc-0.8522, test loss-0.5993, acc-0.8468\n",
      "Iter-13250, train loss-0.6806, acc-0.8200, valid loss-0.5919, acc-0.8524, test loss-0.5990, acc-0.8466\n",
      "Iter-13260, train loss-0.5108, acc-0.8400, valid loss-0.5916, acc-0.8524, test loss-0.5987, acc-0.8469\n",
      "Iter-13270, train loss-0.6050, acc-0.8200, valid loss-0.5913, acc-0.8526, test loss-0.5984, acc-0.8469\n",
      "Iter-13280, train loss-0.4612, acc-0.9000, valid loss-0.5910, acc-0.8526, test loss-0.5981, acc-0.8470\n",
      "Iter-13290, train loss-0.6011, acc-0.8600, valid loss-0.5907, acc-0.8528, test loss-0.5977, acc-0.8468\n",
      "Iter-13300, train loss-0.6594, acc-0.8400, valid loss-0.5903, acc-0.8528, test loss-0.5975, acc-0.8468\n",
      "Iter-13310, train loss-0.5861, acc-0.8200, valid loss-0.5900, acc-0.8528, test loss-0.5972, acc-0.8471\n",
      "Iter-13320, train loss-0.8390, acc-0.7600, valid loss-0.5897, acc-0.8530, test loss-0.5969, acc-0.8471\n",
      "Iter-13330, train loss-0.5906, acc-0.8200, valid loss-0.5893, acc-0.8526, test loss-0.5966, acc-0.8472\n",
      "Iter-13340, train loss-0.6206, acc-0.7600, valid loss-0.5891, acc-0.8528, test loss-0.5963, acc-0.8473\n",
      "Iter-13350, train loss-0.9996, acc-0.7200, valid loss-0.5888, acc-0.8526, test loss-0.5960, acc-0.8473\n",
      "Iter-13360, train loss-0.7567, acc-0.8000, valid loss-0.5886, acc-0.8530, test loss-0.5957, acc-0.8474\n",
      "Iter-13370, train loss-0.6561, acc-0.8000, valid loss-0.5883, acc-0.8528, test loss-0.5954, acc-0.8473\n",
      "Iter-13380, train loss-0.7785, acc-0.7000, valid loss-0.5880, acc-0.8534, test loss-0.5951, acc-0.8472\n",
      "Iter-13390, train loss-0.5810, acc-0.8600, valid loss-0.5877, acc-0.8534, test loss-0.5948, acc-0.8474\n",
      "Iter-13400, train loss-0.6985, acc-0.8400, valid loss-0.5874, acc-0.8536, test loss-0.5945, acc-0.8473\n",
      "Iter-13410, train loss-0.6004, acc-0.8600, valid loss-0.5872, acc-0.8538, test loss-0.5943, acc-0.8475\n",
      "Iter-13420, train loss-0.4657, acc-0.8800, valid loss-0.5869, acc-0.8542, test loss-0.5940, acc-0.8477\n",
      "Iter-13430, train loss-0.6262, acc-0.9000, valid loss-0.5866, acc-0.8542, test loss-0.5937, acc-0.8478\n",
      "Iter-13440, train loss-0.5026, acc-0.8800, valid loss-0.5862, acc-0.8540, test loss-0.5934, acc-0.8479\n",
      "Iter-13450, train loss-0.5281, acc-0.9000, valid loss-0.5860, acc-0.8542, test loss-0.5931, acc-0.8477\n",
      "Iter-13460, train loss-0.3965, acc-0.9800, valid loss-0.5856, acc-0.8540, test loss-0.5928, acc-0.8477\n",
      "Iter-13470, train loss-0.5969, acc-0.8400, valid loss-0.5854, acc-0.8546, test loss-0.5925, acc-0.8481\n",
      "Iter-13480, train loss-0.6709, acc-0.8200, valid loss-0.5850, acc-0.8544, test loss-0.5922, acc-0.8479\n",
      "Iter-13490, train loss-0.5495, acc-0.7800, valid loss-0.5847, acc-0.8542, test loss-0.5919, acc-0.8480\n",
      "Iter-13500, train loss-0.5579, acc-0.8800, valid loss-0.5844, acc-0.8546, test loss-0.5917, acc-0.8480\n",
      "Iter-13510, train loss-0.6414, acc-0.8800, valid loss-0.5841, acc-0.8548, test loss-0.5914, acc-0.8480\n",
      "Iter-13520, train loss-0.5474, acc-0.9000, valid loss-0.5838, acc-0.8548, test loss-0.5911, acc-0.8479\n",
      "Iter-13530, train loss-0.8146, acc-0.7400, valid loss-0.5835, acc-0.8552, test loss-0.5908, acc-0.8479\n",
      "Iter-13540, train loss-0.5117, acc-0.9200, valid loss-0.5832, acc-0.8558, test loss-0.5906, acc-0.8480\n",
      "Iter-13550, train loss-0.5808, acc-0.8200, valid loss-0.5829, acc-0.8556, test loss-0.5903, acc-0.8481\n",
      "Iter-13560, train loss-0.5538, acc-0.8800, valid loss-0.5825, acc-0.8558, test loss-0.5900, acc-0.8482\n",
      "Iter-13570, train loss-0.6883, acc-0.8800, valid loss-0.5823, acc-0.8556, test loss-0.5897, acc-0.8483\n",
      "Iter-13580, train loss-0.8180, acc-0.7000, valid loss-0.5820, acc-0.8560, test loss-0.5894, acc-0.8481\n",
      "Iter-13590, train loss-0.6851, acc-0.8400, valid loss-0.5817, acc-0.8558, test loss-0.5891, acc-0.8480\n",
      "Iter-13600, train loss-0.4667, acc-0.9400, valid loss-0.5814, acc-0.8556, test loss-0.5888, acc-0.8483\n",
      "Iter-13610, train loss-0.7921, acc-0.8000, valid loss-0.5811, acc-0.8558, test loss-0.5885, acc-0.8483\n",
      "Iter-13620, train loss-0.4861, acc-0.8800, valid loss-0.5809, acc-0.8556, test loss-0.5882, acc-0.8485\n",
      "Iter-13630, train loss-0.7406, acc-0.7400, valid loss-0.5806, acc-0.8554, test loss-0.5879, acc-0.8485\n",
      "Iter-13640, train loss-0.6375, acc-0.8200, valid loss-0.5803, acc-0.8560, test loss-0.5876, acc-0.8485\n",
      "Iter-13650, train loss-0.7911, acc-0.8600, valid loss-0.5800, acc-0.8558, test loss-0.5872, acc-0.8485\n",
      "Iter-13660, train loss-0.6949, acc-0.8000, valid loss-0.5796, acc-0.8564, test loss-0.5870, acc-0.8485\n",
      "Iter-13670, train loss-0.6143, acc-0.9000, valid loss-0.5794, acc-0.8566, test loss-0.5867, acc-0.8487\n",
      "Iter-13680, train loss-0.5741, acc-0.8400, valid loss-0.5791, acc-0.8566, test loss-0.5865, acc-0.8489\n",
      "Iter-13690, train loss-0.5891, acc-0.8400, valid loss-0.5787, acc-0.8572, test loss-0.5861, acc-0.8491\n",
      "Iter-13700, train loss-0.7145, acc-0.8000, valid loss-0.5784, acc-0.8574, test loss-0.5859, acc-0.8492\n",
      "Iter-13710, train loss-0.7072, acc-0.7800, valid loss-0.5781, acc-0.8572, test loss-0.5856, acc-0.8491\n",
      "Iter-13720, train loss-0.6323, acc-0.8200, valid loss-0.5778, acc-0.8570, test loss-0.5853, acc-0.8492\n",
      "Iter-13730, train loss-0.6834, acc-0.8200, valid loss-0.5775, acc-0.8572, test loss-0.5850, acc-0.8490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13740, train loss-0.5551, acc-0.8800, valid loss-0.5772, acc-0.8574, test loss-0.5847, acc-0.8490\n",
      "Iter-13750, train loss-0.6638, acc-0.8400, valid loss-0.5768, acc-0.8574, test loss-0.5844, acc-0.8488\n",
      "Iter-13760, train loss-0.4607, acc-0.8800, valid loss-0.5766, acc-0.8576, test loss-0.5841, acc-0.8492\n",
      "Iter-13770, train loss-0.8108, acc-0.7600, valid loss-0.5763, acc-0.8568, test loss-0.5838, acc-0.8491\n",
      "Iter-13780, train loss-0.5825, acc-0.8200, valid loss-0.5760, acc-0.8570, test loss-0.5835, acc-0.8490\n",
      "Iter-13790, train loss-0.6381, acc-0.7800, valid loss-0.5757, acc-0.8572, test loss-0.5831, acc-0.8494\n",
      "Iter-13800, train loss-0.4717, acc-0.9000, valid loss-0.5755, acc-0.8574, test loss-0.5828, acc-0.8491\n",
      "Iter-13810, train loss-0.4967, acc-0.8800, valid loss-0.5752, acc-0.8572, test loss-0.5825, acc-0.8494\n",
      "Iter-13820, train loss-0.5820, acc-0.9000, valid loss-0.5749, acc-0.8574, test loss-0.5822, acc-0.8495\n",
      "Iter-13830, train loss-0.6323, acc-0.8200, valid loss-0.5746, acc-0.8576, test loss-0.5819, acc-0.8497\n",
      "Iter-13840, train loss-0.4119, acc-0.9000, valid loss-0.5744, acc-0.8572, test loss-0.5816, acc-0.8495\n",
      "Iter-13850, train loss-0.5540, acc-0.8600, valid loss-0.5741, acc-0.8578, test loss-0.5813, acc-0.8493\n",
      "Iter-13860, train loss-0.5974, acc-0.8600, valid loss-0.5739, acc-0.8578, test loss-0.5811, acc-0.8494\n",
      "Iter-13870, train loss-0.5658, acc-0.8600, valid loss-0.5736, acc-0.8578, test loss-0.5808, acc-0.8499\n",
      "Iter-13880, train loss-0.6829, acc-0.8600, valid loss-0.5733, acc-0.8578, test loss-0.5805, acc-0.8502\n",
      "Iter-13890, train loss-0.6172, acc-0.8200, valid loss-0.5730, acc-0.8580, test loss-0.5802, acc-0.8497\n",
      "Iter-13900, train loss-0.5972, acc-0.9000, valid loss-0.5727, acc-0.8580, test loss-0.5798, acc-0.8499\n",
      "Iter-13910, train loss-0.6856, acc-0.7600, valid loss-0.5724, acc-0.8580, test loss-0.5796, acc-0.8501\n",
      "Iter-13920, train loss-0.7084, acc-0.7800, valid loss-0.5722, acc-0.8580, test loss-0.5794, acc-0.8501\n",
      "Iter-13930, train loss-0.6463, acc-0.7800, valid loss-0.5719, acc-0.8582, test loss-0.5791, acc-0.8502\n",
      "Iter-13940, train loss-0.5021, acc-0.8800, valid loss-0.5717, acc-0.8582, test loss-0.5789, acc-0.8503\n",
      "Iter-13950, train loss-0.6696, acc-0.8400, valid loss-0.5714, acc-0.8582, test loss-0.5786, acc-0.8502\n",
      "Iter-13960, train loss-0.5962, acc-0.8800, valid loss-0.5711, acc-0.8584, test loss-0.5784, acc-0.8503\n",
      "Iter-13970, train loss-0.5752, acc-0.8200, valid loss-0.5708, acc-0.8584, test loss-0.5781, acc-0.8505\n",
      "Iter-13980, train loss-0.7229, acc-0.7800, valid loss-0.5705, acc-0.8582, test loss-0.5778, acc-0.8501\n",
      "Iter-13990, train loss-0.5497, acc-0.8000, valid loss-0.5702, acc-0.8586, test loss-0.5775, acc-0.8503\n",
      "Iter-14000, train loss-0.6685, acc-0.8000, valid loss-0.5700, acc-0.8586, test loss-0.5773, acc-0.8503\n",
      "Iter-14010, train loss-0.5750, acc-0.8200, valid loss-0.5697, acc-0.8588, test loss-0.5770, acc-0.8502\n",
      "Iter-14020, train loss-0.6311, acc-0.8600, valid loss-0.5694, acc-0.8588, test loss-0.5768, acc-0.8500\n",
      "Iter-14030, train loss-0.5868, acc-0.8600, valid loss-0.5691, acc-0.8590, test loss-0.5765, acc-0.8502\n",
      "Iter-14040, train loss-0.5075, acc-0.9000, valid loss-0.5688, acc-0.8588, test loss-0.5763, acc-0.8503\n",
      "Iter-14050, train loss-0.4874, acc-0.8400, valid loss-0.5686, acc-0.8596, test loss-0.5760, acc-0.8506\n",
      "Iter-14060, train loss-0.6564, acc-0.8000, valid loss-0.5682, acc-0.8592, test loss-0.5757, acc-0.8501\n",
      "Iter-14070, train loss-0.5619, acc-0.9000, valid loss-0.5680, acc-0.8584, test loss-0.5754, acc-0.8501\n",
      "Iter-14080, train loss-0.5282, acc-0.8800, valid loss-0.5677, acc-0.8588, test loss-0.5752, acc-0.8501\n",
      "Iter-14090, train loss-0.4793, acc-0.9200, valid loss-0.5674, acc-0.8592, test loss-0.5749, acc-0.8502\n",
      "Iter-14100, train loss-0.6025, acc-0.8600, valid loss-0.5671, acc-0.8596, test loss-0.5746, acc-0.8508\n",
      "Iter-14110, train loss-0.7366, acc-0.7600, valid loss-0.5668, acc-0.8596, test loss-0.5744, acc-0.8510\n",
      "Iter-14120, train loss-0.6128, acc-0.8400, valid loss-0.5665, acc-0.8594, test loss-0.5741, acc-0.8512\n",
      "Iter-14130, train loss-0.4644, acc-0.9200, valid loss-0.5662, acc-0.8594, test loss-0.5738, acc-0.8515\n",
      "Iter-14140, train loss-0.5489, acc-0.8400, valid loss-0.5659, acc-0.8594, test loss-0.5735, acc-0.8519\n",
      "Iter-14150, train loss-0.5768, acc-0.8400, valid loss-0.5657, acc-0.8598, test loss-0.5733, acc-0.8518\n",
      "Iter-14160, train loss-0.4647, acc-0.8800, valid loss-0.5654, acc-0.8604, test loss-0.5730, acc-0.8522\n",
      "Iter-14170, train loss-0.6113, acc-0.8400, valid loss-0.5651, acc-0.8608, test loss-0.5727, acc-0.8519\n",
      "Iter-14180, train loss-0.6224, acc-0.8800, valid loss-0.5649, acc-0.8604, test loss-0.5725, acc-0.8521\n",
      "Iter-14190, train loss-0.7531, acc-0.8400, valid loss-0.5646, acc-0.8606, test loss-0.5722, acc-0.8520\n",
      "Iter-14200, train loss-0.5131, acc-0.8800, valid loss-0.5643, acc-0.8608, test loss-0.5719, acc-0.8523\n",
      "Iter-14210, train loss-0.4423, acc-0.9400, valid loss-0.5640, acc-0.8614, test loss-0.5717, acc-0.8525\n",
      "Iter-14220, train loss-0.5749, acc-0.8600, valid loss-0.5638, acc-0.8612, test loss-0.5715, acc-0.8523\n",
      "Iter-14230, train loss-0.7208, acc-0.8800, valid loss-0.5635, acc-0.8610, test loss-0.5713, acc-0.8523\n",
      "Iter-14240, train loss-0.3882, acc-0.9600, valid loss-0.5632, acc-0.8610, test loss-0.5710, acc-0.8520\n",
      "Iter-14250, train loss-0.7063, acc-0.8200, valid loss-0.5629, acc-0.8618, test loss-0.5707, acc-0.8524\n",
      "Iter-14260, train loss-0.4257, acc-0.9600, valid loss-0.5626, acc-0.8616, test loss-0.5705, acc-0.8527\n",
      "Iter-14270, train loss-0.5606, acc-0.8400, valid loss-0.5623, acc-0.8624, test loss-0.5702, acc-0.8529\n",
      "Iter-14280, train loss-0.7246, acc-0.7800, valid loss-0.5620, acc-0.8624, test loss-0.5699, acc-0.8528\n",
      "Iter-14290, train loss-0.4502, acc-0.9200, valid loss-0.5617, acc-0.8620, test loss-0.5697, acc-0.8532\n",
      "Iter-14300, train loss-0.5082, acc-0.9000, valid loss-0.5614, acc-0.8622, test loss-0.5695, acc-0.8533\n",
      "Iter-14310, train loss-0.4889, acc-0.9000, valid loss-0.5612, acc-0.8618, test loss-0.5693, acc-0.8534\n",
      "Iter-14320, train loss-0.5320, acc-0.8600, valid loss-0.5609, acc-0.8620, test loss-0.5690, acc-0.8538\n",
      "Iter-14330, train loss-0.5627, acc-0.8600, valid loss-0.5607, acc-0.8620, test loss-0.5688, acc-0.8538\n",
      "Iter-14340, train loss-0.5819, acc-0.8800, valid loss-0.5604, acc-0.8620, test loss-0.5685, acc-0.8542\n",
      "Iter-14350, train loss-0.5965, acc-0.9000, valid loss-0.5601, acc-0.8618, test loss-0.5682, acc-0.8544\n",
      "Iter-14360, train loss-0.5407, acc-0.8800, valid loss-0.5599, acc-0.8622, test loss-0.5680, acc-0.8544\n",
      "Iter-14370, train loss-0.6148, acc-0.8000, valid loss-0.5597, acc-0.8628, test loss-0.5677, acc-0.8539\n",
      "Iter-14380, train loss-0.5873, acc-0.7800, valid loss-0.5594, acc-0.8624, test loss-0.5674, acc-0.8539\n",
      "Iter-14390, train loss-0.4467, acc-0.8600, valid loss-0.5591, acc-0.8626, test loss-0.5671, acc-0.8541\n",
      "Iter-14400, train loss-0.4877, acc-0.9200, valid loss-0.5588, acc-0.8630, test loss-0.5668, acc-0.8542\n",
      "Iter-14410, train loss-0.6146, acc-0.8000, valid loss-0.5586, acc-0.8632, test loss-0.5665, acc-0.8541\n",
      "Iter-14420, train loss-0.5927, acc-0.8400, valid loss-0.5583, acc-0.8632, test loss-0.5663, acc-0.8544\n",
      "Iter-14430, train loss-0.5471, acc-0.8600, valid loss-0.5580, acc-0.8632, test loss-0.5660, acc-0.8544\n",
      "Iter-14440, train loss-0.7118, acc-0.8600, valid loss-0.5578, acc-0.8630, test loss-0.5658, acc-0.8545\n",
      "Iter-14450, train loss-0.5695, acc-0.8600, valid loss-0.5575, acc-0.8632, test loss-0.5655, acc-0.8547\n",
      "Iter-14460, train loss-0.7275, acc-0.7600, valid loss-0.5573, acc-0.8636, test loss-0.5652, acc-0.8544\n",
      "Iter-14470, train loss-0.4453, acc-0.9000, valid loss-0.5570, acc-0.8634, test loss-0.5649, acc-0.8548\n",
      "Iter-14480, train loss-0.4767, acc-0.9000, valid loss-0.5567, acc-0.8634, test loss-0.5647, acc-0.8548\n",
      "Iter-14490, train loss-0.6840, acc-0.8200, valid loss-0.5564, acc-0.8636, test loss-0.5644, acc-0.8549\n",
      "Iter-14500, train loss-0.6145, acc-0.8600, valid loss-0.5562, acc-0.8638, test loss-0.5641, acc-0.8552\n",
      "Iter-14510, train loss-0.4913, acc-0.8600, valid loss-0.5559, acc-0.8638, test loss-0.5638, acc-0.8551\n",
      "Iter-14520, train loss-0.3736, acc-0.9600, valid loss-0.5556, acc-0.8636, test loss-0.5636, acc-0.8555\n",
      "Iter-14530, train loss-0.5180, acc-0.8800, valid loss-0.5553, acc-0.8638, test loss-0.5633, acc-0.8552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-14540, train loss-0.5023, acc-0.8800, valid loss-0.5551, acc-0.8640, test loss-0.5630, acc-0.8552\n",
      "Iter-14550, train loss-0.5478, acc-0.9000, valid loss-0.5548, acc-0.8640, test loss-0.5627, acc-0.8553\n",
      "Iter-14560, train loss-0.8305, acc-0.7800, valid loss-0.5545, acc-0.8640, test loss-0.5624, acc-0.8553\n",
      "Iter-14570, train loss-0.6562, acc-0.8000, valid loss-0.5543, acc-0.8642, test loss-0.5621, acc-0.8553\n",
      "Iter-14580, train loss-0.5209, acc-0.8400, valid loss-0.5540, acc-0.8644, test loss-0.5619, acc-0.8556\n",
      "Iter-14590, train loss-0.7004, acc-0.7400, valid loss-0.5537, acc-0.8644, test loss-0.5615, acc-0.8557\n",
      "Iter-14600, train loss-0.5082, acc-0.9000, valid loss-0.5534, acc-0.8642, test loss-0.5613, acc-0.8561\n",
      "Iter-14610, train loss-0.6241, acc-0.8400, valid loss-0.5532, acc-0.8646, test loss-0.5610, acc-0.8558\n",
      "Iter-14620, train loss-0.4587, acc-0.8800, valid loss-0.5529, acc-0.8644, test loss-0.5607, acc-0.8559\n",
      "Iter-14630, train loss-0.6460, acc-0.8600, valid loss-0.5526, acc-0.8644, test loss-0.5605, acc-0.8561\n",
      "Iter-14640, train loss-0.7225, acc-0.8000, valid loss-0.5524, acc-0.8646, test loss-0.5602, acc-0.8561\n",
      "Iter-14650, train loss-0.6131, acc-0.8800, valid loss-0.5521, acc-0.8644, test loss-0.5599, acc-0.8565\n",
      "Iter-14660, train loss-0.4784, acc-0.8600, valid loss-0.5519, acc-0.8642, test loss-0.5597, acc-0.8563\n",
      "Iter-14670, train loss-0.5910, acc-0.8600, valid loss-0.5516, acc-0.8646, test loss-0.5594, acc-0.8564\n",
      "Iter-14680, train loss-0.7912, acc-0.7000, valid loss-0.5514, acc-0.8646, test loss-0.5591, acc-0.8566\n",
      "Iter-14690, train loss-0.4472, acc-0.9200, valid loss-0.5511, acc-0.8646, test loss-0.5588, acc-0.8567\n",
      "Iter-14700, train loss-0.4268, acc-0.9400, valid loss-0.5508, acc-0.8650, test loss-0.5586, acc-0.8571\n",
      "Iter-14710, train loss-0.4577, acc-0.9000, valid loss-0.5506, acc-0.8648, test loss-0.5583, acc-0.8575\n",
      "Iter-14720, train loss-0.4761, acc-0.8800, valid loss-0.5503, acc-0.8652, test loss-0.5580, acc-0.8576\n",
      "Iter-14730, train loss-0.5489, acc-0.8800, valid loss-0.5500, acc-0.8652, test loss-0.5578, acc-0.8574\n",
      "Iter-14740, train loss-0.6996, acc-0.8200, valid loss-0.5498, acc-0.8658, test loss-0.5575, acc-0.8574\n",
      "Iter-14750, train loss-0.5593, acc-0.8000, valid loss-0.5496, acc-0.8658, test loss-0.5573, acc-0.8578\n",
      "Iter-14760, train loss-0.5256, acc-0.9000, valid loss-0.5493, acc-0.8656, test loss-0.5570, acc-0.8579\n",
      "Iter-14770, train loss-0.6455, acc-0.7800, valid loss-0.5491, acc-0.8658, test loss-0.5568, acc-0.8582\n",
      "Iter-14780, train loss-0.5332, acc-0.8600, valid loss-0.5488, acc-0.8660, test loss-0.5565, acc-0.8579\n",
      "Iter-14790, train loss-0.6495, acc-0.8000, valid loss-0.5486, acc-0.8658, test loss-0.5562, acc-0.8584\n",
      "Iter-14800, train loss-0.5157, acc-0.8600, valid loss-0.5483, acc-0.8662, test loss-0.5560, acc-0.8582\n",
      "Iter-14810, train loss-0.6485, acc-0.8200, valid loss-0.5481, acc-0.8656, test loss-0.5558, acc-0.8585\n",
      "Iter-14820, train loss-0.5837, acc-0.8000, valid loss-0.5479, acc-0.8660, test loss-0.5555, acc-0.8585\n",
      "Iter-14830, train loss-0.4831, acc-0.9000, valid loss-0.5476, acc-0.8658, test loss-0.5552, acc-0.8585\n",
      "Iter-14840, train loss-0.4099, acc-0.9200, valid loss-0.5473, acc-0.8658, test loss-0.5550, acc-0.8590\n",
      "Iter-14850, train loss-0.6490, acc-0.7800, valid loss-0.5471, acc-0.8662, test loss-0.5548, acc-0.8591\n",
      "Iter-14860, train loss-0.5597, acc-0.9200, valid loss-0.5468, acc-0.8658, test loss-0.5545, acc-0.8592\n",
      "Iter-14870, train loss-0.5060, acc-0.8200, valid loss-0.5465, acc-0.8662, test loss-0.5542, acc-0.8594\n",
      "Iter-14880, train loss-0.5373, acc-0.8400, valid loss-0.5462, acc-0.8658, test loss-0.5539, acc-0.8596\n",
      "Iter-14890, train loss-0.5083, acc-0.8800, valid loss-0.5460, acc-0.8660, test loss-0.5537, acc-0.8595\n",
      "Iter-14900, train loss-0.5840, acc-0.8600, valid loss-0.5457, acc-0.8662, test loss-0.5534, acc-0.8596\n",
      "Iter-14910, train loss-0.5821, acc-0.8600, valid loss-0.5455, acc-0.8664, test loss-0.5532, acc-0.8594\n",
      "Iter-14920, train loss-0.4125, acc-0.9200, valid loss-0.5452, acc-0.8668, test loss-0.5529, acc-0.8592\n",
      "Iter-14930, train loss-0.5502, acc-0.8800, valid loss-0.5450, acc-0.8666, test loss-0.5526, acc-0.8590\n",
      "Iter-14940, train loss-0.3626, acc-0.9600, valid loss-0.5447, acc-0.8670, test loss-0.5524, acc-0.8596\n",
      "Iter-14950, train loss-0.8049, acc-0.7600, valid loss-0.5444, acc-0.8674, test loss-0.5521, acc-0.8595\n",
      "Iter-14960, train loss-0.9478, acc-0.7800, valid loss-0.5442, acc-0.8674, test loss-0.5519, acc-0.8596\n",
      "Iter-14970, train loss-0.5128, acc-0.8600, valid loss-0.5440, acc-0.8674, test loss-0.5517, acc-0.8596\n",
      "Iter-14980, train loss-0.4397, acc-0.9200, valid loss-0.5437, acc-0.8678, test loss-0.5515, acc-0.8594\n",
      "Iter-14990, train loss-0.4509, acc-0.9000, valid loss-0.5435, acc-0.8676, test loss-0.5512, acc-0.8596\n",
      "Iter-15000, train loss-0.6958, acc-0.8400, valid loss-0.5433, acc-0.8676, test loss-0.5509, acc-0.8598\n",
      "Iter-15010, train loss-0.6781, acc-0.8600, valid loss-0.5430, acc-0.8676, test loss-0.5507, acc-0.8599\n",
      "Iter-15020, train loss-0.7140, acc-0.7600, valid loss-0.5428, acc-0.8678, test loss-0.5505, acc-0.8601\n",
      "Iter-15030, train loss-0.6859, acc-0.8200, valid loss-0.5424, acc-0.8672, test loss-0.5502, acc-0.8609\n",
      "Iter-15040, train loss-0.4488, acc-0.9400, valid loss-0.5422, acc-0.8680, test loss-0.5500, acc-0.8610\n",
      "Iter-15050, train loss-0.5417, acc-0.9000, valid loss-0.5419, acc-0.8682, test loss-0.5497, acc-0.8613\n",
      "Iter-15060, train loss-0.5365, acc-0.8800, valid loss-0.5417, acc-0.8676, test loss-0.5494, acc-0.8608\n",
      "Iter-15070, train loss-0.4944, acc-0.9400, valid loss-0.5415, acc-0.8676, test loss-0.5492, acc-0.8609\n",
      "Iter-15080, train loss-0.5750, acc-0.8200, valid loss-0.5413, acc-0.8678, test loss-0.5490, acc-0.8603\n",
      "Iter-15090, train loss-0.6831, acc-0.7400, valid loss-0.5410, acc-0.8680, test loss-0.5487, acc-0.8609\n",
      "Iter-15100, train loss-0.5060, acc-0.8600, valid loss-0.5407, acc-0.8684, test loss-0.5485, acc-0.8613\n",
      "Iter-15110, train loss-0.5629, acc-0.9000, valid loss-0.5404, acc-0.8682, test loss-0.5483, acc-0.8614\n",
      "Iter-15120, train loss-0.7155, acc-0.7800, valid loss-0.5402, acc-0.8682, test loss-0.5480, acc-0.8615\n",
      "Iter-15130, train loss-0.4895, acc-0.8200, valid loss-0.5399, acc-0.8680, test loss-0.5478, acc-0.8612\n",
      "Iter-15140, train loss-0.5842, acc-0.8200, valid loss-0.5397, acc-0.8684, test loss-0.5475, acc-0.8613\n",
      "Iter-15150, train loss-0.5600, acc-0.8200, valid loss-0.5394, acc-0.8684, test loss-0.5474, acc-0.8614\n",
      "Iter-15160, train loss-0.6610, acc-0.7800, valid loss-0.5392, acc-0.8682, test loss-0.5471, acc-0.8615\n",
      "Iter-15170, train loss-0.6308, acc-0.8200, valid loss-0.5389, acc-0.8688, test loss-0.5469, acc-0.8617\n",
      "Iter-15180, train loss-0.5625, acc-0.9000, valid loss-0.5387, acc-0.8686, test loss-0.5466, acc-0.8616\n",
      "Iter-15190, train loss-0.5402, acc-0.8800, valid loss-0.5384, acc-0.8686, test loss-0.5464, acc-0.8619\n",
      "Iter-15200, train loss-0.5725, acc-0.7800, valid loss-0.5382, acc-0.8686, test loss-0.5461, acc-0.8620\n",
      "Iter-15210, train loss-0.5434, acc-0.8600, valid loss-0.5379, acc-0.8690, test loss-0.5459, acc-0.8621\n",
      "Iter-15220, train loss-0.8079, acc-0.7200, valid loss-0.5377, acc-0.8692, test loss-0.5457, acc-0.8624\n",
      "Iter-15230, train loss-0.6425, acc-0.8200, valid loss-0.5375, acc-0.8684, test loss-0.5454, acc-0.8622\n",
      "Iter-15240, train loss-0.6133, acc-0.8600, valid loss-0.5372, acc-0.8686, test loss-0.5451, acc-0.8624\n",
      "Iter-15250, train loss-0.4430, acc-0.8400, valid loss-0.5369, acc-0.8682, test loss-0.5449, acc-0.8624\n",
      "Iter-15260, train loss-0.6177, acc-0.8200, valid loss-0.5367, acc-0.8692, test loss-0.5446, acc-0.8623\n",
      "Iter-15270, train loss-0.4833, acc-0.9000, valid loss-0.5365, acc-0.8688, test loss-0.5444, acc-0.8624\n",
      "Iter-15280, train loss-0.4926, acc-0.8800, valid loss-0.5363, acc-0.8696, test loss-0.5442, acc-0.8623\n",
      "Iter-15290, train loss-0.4231, acc-0.8800, valid loss-0.5360, acc-0.8696, test loss-0.5439, acc-0.8627\n",
      "Iter-15300, train loss-0.6178, acc-0.8400, valid loss-0.5358, acc-0.8692, test loss-0.5437, acc-0.8627\n",
      "Iter-15310, train loss-0.7672, acc-0.7800, valid loss-0.5356, acc-0.8698, test loss-0.5435, acc-0.8625\n",
      "Iter-15320, train loss-0.4130, acc-0.9000, valid loss-0.5353, acc-0.8698, test loss-0.5433, acc-0.8626\n",
      "Iter-15330, train loss-0.6390, acc-0.8600, valid loss-0.5351, acc-0.8702, test loss-0.5431, acc-0.8626\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-15340, train loss-0.5915, acc-0.8400, valid loss-0.5349, acc-0.8700, test loss-0.5428, acc-0.8625\n",
      "Iter-15350, train loss-0.6971, acc-0.8400, valid loss-0.5346, acc-0.8700, test loss-0.5426, acc-0.8626\n",
      "Iter-15360, train loss-0.3691, acc-0.9400, valid loss-0.5344, acc-0.8700, test loss-0.5423, acc-0.8626\n",
      "Iter-15370, train loss-0.5168, acc-0.9000, valid loss-0.5341, acc-0.8702, test loss-0.5421, acc-0.8628\n",
      "Iter-15380, train loss-0.6813, acc-0.8200, valid loss-0.5339, acc-0.8708, test loss-0.5419, acc-0.8629\n",
      "Iter-15390, train loss-0.5753, acc-0.8600, valid loss-0.5337, acc-0.8706, test loss-0.5416, acc-0.8633\n",
      "Iter-15400, train loss-0.5696, acc-0.8800, valid loss-0.5334, acc-0.8708, test loss-0.5414, acc-0.8635\n",
      "Iter-15410, train loss-0.4375, acc-0.9400, valid loss-0.5331, acc-0.8712, test loss-0.5412, acc-0.8637\n",
      "Iter-15420, train loss-0.5162, acc-0.8600, valid loss-0.5329, acc-0.8714, test loss-0.5410, acc-0.8636\n",
      "Iter-15430, train loss-0.6543, acc-0.8200, valid loss-0.5327, acc-0.8712, test loss-0.5407, acc-0.8639\n",
      "Iter-15440, train loss-0.5762, acc-0.8400, valid loss-0.5324, acc-0.8716, test loss-0.5405, acc-0.8639\n",
      "Iter-15450, train loss-0.4276, acc-0.9600, valid loss-0.5322, acc-0.8716, test loss-0.5402, acc-0.8639\n",
      "Iter-15460, train loss-0.6465, acc-0.8400, valid loss-0.5319, acc-0.8716, test loss-0.5400, acc-0.8640\n",
      "Iter-15470, train loss-0.6675, acc-0.7800, valid loss-0.5317, acc-0.8716, test loss-0.5398, acc-0.8641\n",
      "Iter-15480, train loss-0.5312, acc-0.8400, valid loss-0.5314, acc-0.8718, test loss-0.5396, acc-0.8642\n",
      "Iter-15490, train loss-0.7843, acc-0.7000, valid loss-0.5312, acc-0.8714, test loss-0.5393, acc-0.8645\n",
      "Iter-15500, train loss-0.4051, acc-0.9600, valid loss-0.5310, acc-0.8716, test loss-0.5391, acc-0.8645\n",
      "Iter-15510, train loss-0.6366, acc-0.8400, valid loss-0.5307, acc-0.8714, test loss-0.5389, acc-0.8645\n",
      "Iter-15520, train loss-0.5409, acc-0.9200, valid loss-0.5304, acc-0.8714, test loss-0.5386, acc-0.8645\n",
      "Iter-15530, train loss-0.4919, acc-0.9000, valid loss-0.5302, acc-0.8714, test loss-0.5385, acc-0.8645\n",
      "Iter-15540, train loss-0.4948, acc-0.9200, valid loss-0.5300, acc-0.8716, test loss-0.5383, acc-0.8645\n",
      "Iter-15550, train loss-0.6043, acc-0.8400, valid loss-0.5297, acc-0.8712, test loss-0.5380, acc-0.8645\n",
      "Iter-15560, train loss-0.6150, acc-0.8200, valid loss-0.5295, acc-0.8712, test loss-0.5378, acc-0.8647\n",
      "Iter-15570, train loss-0.5262, acc-0.8200, valid loss-0.5292, acc-0.8720, test loss-0.5375, acc-0.8647\n",
      "Iter-15580, train loss-0.5622, acc-0.9000, valid loss-0.5290, acc-0.8722, test loss-0.5372, acc-0.8645\n",
      "Iter-15590, train loss-0.6101, acc-0.8800, valid loss-0.5288, acc-0.8718, test loss-0.5370, acc-0.8648\n",
      "Iter-15600, train loss-0.8030, acc-0.7800, valid loss-0.5286, acc-0.8716, test loss-0.5367, acc-0.8648\n",
      "Iter-15610, train loss-0.4774, acc-0.8800, valid loss-0.5284, acc-0.8718, test loss-0.5365, acc-0.8649\n",
      "Iter-15620, train loss-0.6506, acc-0.8600, valid loss-0.5281, acc-0.8722, test loss-0.5362, acc-0.8647\n",
      "Iter-15630, train loss-0.4305, acc-0.9000, valid loss-0.5279, acc-0.8720, test loss-0.5359, acc-0.8649\n",
      "Iter-15640, train loss-0.6415, acc-0.8200, valid loss-0.5276, acc-0.8720, test loss-0.5357, acc-0.8653\n",
      "Iter-15650, train loss-0.6449, acc-0.8000, valid loss-0.5274, acc-0.8722, test loss-0.5355, acc-0.8655\n",
      "Iter-15660, train loss-0.4499, acc-0.9000, valid loss-0.5272, acc-0.8722, test loss-0.5353, acc-0.8652\n",
      "Iter-15670, train loss-0.4336, acc-0.8600, valid loss-0.5270, acc-0.8724, test loss-0.5351, acc-0.8653\n",
      "Iter-15680, train loss-0.5880, acc-0.8600, valid loss-0.5268, acc-0.8722, test loss-0.5348, acc-0.8655\n",
      "Iter-15690, train loss-0.4370, acc-0.9200, valid loss-0.5265, acc-0.8726, test loss-0.5345, acc-0.8658\n",
      "Iter-15700, train loss-0.4931, acc-0.9200, valid loss-0.5262, acc-0.8728, test loss-0.5343, acc-0.8659\n",
      "Iter-15710, train loss-0.4133, acc-0.9000, valid loss-0.5260, acc-0.8730, test loss-0.5341, acc-0.8661\n",
      "Iter-15720, train loss-0.4656, acc-0.9000, valid loss-0.5257, acc-0.8726, test loss-0.5339, acc-0.8659\n",
      "Iter-15730, train loss-0.3820, acc-0.9200, valid loss-0.5255, acc-0.8728, test loss-0.5337, acc-0.8659\n",
      "Iter-15740, train loss-0.4880, acc-0.9000, valid loss-0.5253, acc-0.8728, test loss-0.5334, acc-0.8657\n",
      "Iter-15750, train loss-0.5630, acc-0.8600, valid loss-0.5251, acc-0.8728, test loss-0.5332, acc-0.8658\n",
      "Iter-15760, train loss-0.4776, acc-0.9400, valid loss-0.5249, acc-0.8724, test loss-0.5330, acc-0.8663\n",
      "Iter-15770, train loss-0.6681, acc-0.8000, valid loss-0.5246, acc-0.8722, test loss-0.5329, acc-0.8667\n",
      "Iter-15780, train loss-0.5669, acc-0.8600, valid loss-0.5244, acc-0.8724, test loss-0.5326, acc-0.8668\n",
      "Iter-15790, train loss-0.3929, acc-0.9400, valid loss-0.5241, acc-0.8722, test loss-0.5324, acc-0.8668\n",
      "Iter-15800, train loss-0.5976, acc-0.8200, valid loss-0.5239, acc-0.8718, test loss-0.5321, acc-0.8668\n",
      "Iter-15810, train loss-0.5912, acc-0.8400, valid loss-0.5237, acc-0.8720, test loss-0.5318, acc-0.8670\n",
      "Iter-15820, train loss-0.6704, acc-0.7800, valid loss-0.5234, acc-0.8720, test loss-0.5316, acc-0.8670\n",
      "Iter-15830, train loss-0.4267, acc-0.8600, valid loss-0.5232, acc-0.8720, test loss-0.5313, acc-0.8668\n",
      "Iter-15840, train loss-0.7651, acc-0.8600, valid loss-0.5230, acc-0.8722, test loss-0.5310, acc-0.8670\n",
      "Iter-15850, train loss-0.4350, acc-0.9000, valid loss-0.5228, acc-0.8724, test loss-0.5308, acc-0.8671\n",
      "Iter-15860, train loss-0.8269, acc-0.7600, valid loss-0.5226, acc-0.8730, test loss-0.5305, acc-0.8669\n",
      "Iter-15870, train loss-0.5307, acc-0.8200, valid loss-0.5223, acc-0.8732, test loss-0.5302, acc-0.8671\n",
      "Iter-15880, train loss-0.5679, acc-0.8400, valid loss-0.5221, acc-0.8730, test loss-0.5300, acc-0.8670\n",
      "Iter-15890, train loss-0.6213, acc-0.8800, valid loss-0.5219, acc-0.8728, test loss-0.5297, acc-0.8672\n",
      "Iter-15900, train loss-0.6488, acc-0.8600, valid loss-0.5216, acc-0.8730, test loss-0.5295, acc-0.8670\n",
      "Iter-15910, train loss-0.5309, acc-0.8800, valid loss-0.5213, acc-0.8730, test loss-0.5292, acc-0.8667\n",
      "Iter-15920, train loss-0.4895, acc-0.9200, valid loss-0.5211, acc-0.8730, test loss-0.5290, acc-0.8669\n",
      "Iter-15930, train loss-0.2907, acc-0.9800, valid loss-0.5208, acc-0.8732, test loss-0.5288, acc-0.8673\n",
      "Iter-15940, train loss-0.4925, acc-0.8600, valid loss-0.5206, acc-0.8730, test loss-0.5286, acc-0.8675\n",
      "Iter-15950, train loss-0.5696, acc-0.8600, valid loss-0.5204, acc-0.8730, test loss-0.5284, acc-0.8673\n",
      "Iter-15960, train loss-0.6691, acc-0.8400, valid loss-0.5202, acc-0.8732, test loss-0.5281, acc-0.8675\n",
      "Iter-15970, train loss-0.5204, acc-0.8800, valid loss-0.5200, acc-0.8728, test loss-0.5279, acc-0.8674\n",
      "Iter-15980, train loss-0.4847, acc-0.8400, valid loss-0.5198, acc-0.8730, test loss-0.5276, acc-0.8674\n",
      "Iter-15990, train loss-0.4849, acc-0.8800, valid loss-0.5195, acc-0.8728, test loss-0.5274, acc-0.8679\n",
      "Iter-16000, train loss-0.5559, acc-0.8600, valid loss-0.5193, acc-0.8730, test loss-0.5272, acc-0.8676\n",
      "Iter-16010, train loss-0.5938, acc-0.8400, valid loss-0.5191, acc-0.8732, test loss-0.5270, acc-0.8683\n",
      "Iter-16020, train loss-0.4930, acc-0.9200, valid loss-0.5189, acc-0.8734, test loss-0.5267, acc-0.8681\n",
      "Iter-16030, train loss-0.5733, acc-0.8200, valid loss-0.5187, acc-0.8736, test loss-0.5265, acc-0.8681\n",
      "Iter-16040, train loss-0.5030, acc-0.9000, valid loss-0.5184, acc-0.8740, test loss-0.5263, acc-0.8682\n",
      "Iter-16050, train loss-0.5347, acc-0.8600, valid loss-0.5182, acc-0.8740, test loss-0.5260, acc-0.8682\n",
      "Iter-16060, train loss-0.7531, acc-0.8400, valid loss-0.5180, acc-0.8736, test loss-0.5259, acc-0.8683\n",
      "Iter-16070, train loss-0.4674, acc-0.9200, valid loss-0.5178, acc-0.8732, test loss-0.5257, acc-0.8687\n",
      "Iter-16080, train loss-0.6230, acc-0.8000, valid loss-0.5175, acc-0.8732, test loss-0.5254, acc-0.8685\n",
      "Iter-16090, train loss-0.6599, acc-0.8600, valid loss-0.5173, acc-0.8732, test loss-0.5252, acc-0.8686\n",
      "Iter-16100, train loss-0.5181, acc-0.9000, valid loss-0.5170, acc-0.8730, test loss-0.5250, acc-0.8685\n",
      "Iter-16110, train loss-0.4537, acc-0.9400, valid loss-0.5168, acc-0.8730, test loss-0.5248, acc-0.8687\n",
      "Iter-16120, train loss-0.4151, acc-0.9400, valid loss-0.5166, acc-0.8734, test loss-0.5246, acc-0.8689\n",
      "Iter-16130, train loss-0.3976, acc-0.9200, valid loss-0.5164, acc-0.8736, test loss-0.5244, acc-0.8688\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16140, train loss-0.4461, acc-0.9400, valid loss-0.5161, acc-0.8734, test loss-0.5242, acc-0.8684\n",
      "Iter-16150, train loss-0.5882, acc-0.8800, valid loss-0.5159, acc-0.8736, test loss-0.5239, acc-0.8685\n",
      "Iter-16160, train loss-0.6096, acc-0.8600, valid loss-0.5157, acc-0.8734, test loss-0.5237, acc-0.8684\n",
      "Iter-16170, train loss-0.6721, acc-0.8000, valid loss-0.5155, acc-0.8734, test loss-0.5235, acc-0.8685\n",
      "Iter-16180, train loss-0.7064, acc-0.7400, valid loss-0.5153, acc-0.8734, test loss-0.5233, acc-0.8688\n",
      "Iter-16190, train loss-0.4013, acc-0.9000, valid loss-0.5151, acc-0.8736, test loss-0.5231, acc-0.8692\n",
      "Iter-16200, train loss-0.5684, acc-0.8000, valid loss-0.5149, acc-0.8732, test loss-0.5228, acc-0.8691\n",
      "Iter-16210, train loss-0.4907, acc-0.8400, valid loss-0.5146, acc-0.8738, test loss-0.5226, acc-0.8691\n",
      "Iter-16220, train loss-0.8340, acc-0.7800, valid loss-0.5144, acc-0.8738, test loss-0.5223, acc-0.8691\n",
      "Iter-16230, train loss-0.5352, acc-0.8400, valid loss-0.5142, acc-0.8736, test loss-0.5221, acc-0.8692\n",
      "Iter-16240, train loss-0.3878, acc-0.9400, valid loss-0.5140, acc-0.8738, test loss-0.5220, acc-0.8691\n",
      "Iter-16250, train loss-0.5833, acc-0.8200, valid loss-0.5138, acc-0.8734, test loss-0.5218, acc-0.8689\n",
      "Iter-16260, train loss-0.5384, acc-0.9200, valid loss-0.5136, acc-0.8738, test loss-0.5215, acc-0.8692\n",
      "Iter-16270, train loss-0.6023, acc-0.8400, valid loss-0.5133, acc-0.8736, test loss-0.5213, acc-0.8694\n",
      "Iter-16280, train loss-0.5247, acc-0.8800, valid loss-0.5131, acc-0.8740, test loss-0.5211, acc-0.8694\n",
      "Iter-16290, train loss-0.5913, acc-0.8000, valid loss-0.5129, acc-0.8740, test loss-0.5209, acc-0.8696\n",
      "Iter-16300, train loss-0.4392, acc-0.8800, valid loss-0.5126, acc-0.8742, test loss-0.5207, acc-0.8693\n",
      "Iter-16310, train loss-0.4988, acc-0.8800, valid loss-0.5124, acc-0.8742, test loss-0.5204, acc-0.8697\n",
      "Iter-16320, train loss-0.3717, acc-0.9600, valid loss-0.5122, acc-0.8740, test loss-0.5202, acc-0.8694\n",
      "Iter-16330, train loss-0.5676, acc-0.9000, valid loss-0.5120, acc-0.8740, test loss-0.5200, acc-0.8697\n",
      "Iter-16340, train loss-0.4426, acc-0.8800, valid loss-0.5118, acc-0.8740, test loss-0.5198, acc-0.8699\n",
      "Iter-16350, train loss-0.5719, acc-0.8400, valid loss-0.5116, acc-0.8744, test loss-0.5196, acc-0.8701\n",
      "Iter-16360, train loss-0.4604, acc-0.9400, valid loss-0.5114, acc-0.8742, test loss-0.5194, acc-0.8702\n",
      "Iter-16370, train loss-0.3207, acc-0.9400, valid loss-0.5112, acc-0.8742, test loss-0.5192, acc-0.8702\n",
      "Iter-16380, train loss-0.4729, acc-0.8800, valid loss-0.5110, acc-0.8746, test loss-0.5191, acc-0.8703\n",
      "Iter-16390, train loss-0.4331, acc-0.9000, valid loss-0.5108, acc-0.8740, test loss-0.5188, acc-0.8702\n",
      "Iter-16400, train loss-0.5732, acc-0.8600, valid loss-0.5106, acc-0.8744, test loss-0.5186, acc-0.8700\n",
      "Iter-16410, train loss-0.4755, acc-0.8800, valid loss-0.5104, acc-0.8742, test loss-0.5184, acc-0.8702\n",
      "Iter-16420, train loss-0.4714, acc-0.8800, valid loss-0.5101, acc-0.8742, test loss-0.5182, acc-0.8704\n",
      "Iter-16430, train loss-0.3656, acc-0.9200, valid loss-0.5099, acc-0.8744, test loss-0.5180, acc-0.8705\n",
      "Iter-16440, train loss-0.4913, acc-0.9000, valid loss-0.5097, acc-0.8742, test loss-0.5177, acc-0.8701\n",
      "Iter-16450, train loss-0.5490, acc-0.9200, valid loss-0.5095, acc-0.8742, test loss-0.5175, acc-0.8703\n",
      "Iter-16460, train loss-0.6036, acc-0.8600, valid loss-0.5094, acc-0.8744, test loss-0.5173, acc-0.8705\n",
      "Iter-16470, train loss-0.4749, acc-0.8000, valid loss-0.5092, acc-0.8744, test loss-0.5172, acc-0.8707\n",
      "Iter-16480, train loss-0.5321, acc-0.8000, valid loss-0.5090, acc-0.8748, test loss-0.5170, acc-0.8708\n",
      "Iter-16490, train loss-0.5648, acc-0.8600, valid loss-0.5089, acc-0.8742, test loss-0.5168, acc-0.8708\n",
      "Iter-16500, train loss-0.6155, acc-0.8200, valid loss-0.5087, acc-0.8742, test loss-0.5166, acc-0.8710\n",
      "Iter-16510, train loss-0.3777, acc-0.9000, valid loss-0.5085, acc-0.8744, test loss-0.5165, acc-0.8709\n",
      "Iter-16520, train loss-0.4836, acc-0.9200, valid loss-0.5083, acc-0.8746, test loss-0.5163, acc-0.8708\n",
      "Iter-16530, train loss-0.4219, acc-0.9200, valid loss-0.5081, acc-0.8744, test loss-0.5161, acc-0.8708\n",
      "Iter-16540, train loss-0.3910, acc-0.9400, valid loss-0.5079, acc-0.8744, test loss-0.5159, acc-0.8708\n",
      "Iter-16550, train loss-0.4656, acc-0.8600, valid loss-0.5078, acc-0.8744, test loss-0.5157, acc-0.8708\n",
      "Iter-16560, train loss-0.4806, acc-0.8600, valid loss-0.5076, acc-0.8744, test loss-0.5155, acc-0.8707\n",
      "Iter-16570, train loss-0.7781, acc-0.7200, valid loss-0.5074, acc-0.8742, test loss-0.5153, acc-0.8709\n",
      "Iter-16580, train loss-0.5960, acc-0.9000, valid loss-0.5071, acc-0.8742, test loss-0.5151, acc-0.8709\n",
      "Iter-16590, train loss-0.5663, acc-0.7800, valid loss-0.5070, acc-0.8742, test loss-0.5149, acc-0.8710\n",
      "Iter-16600, train loss-0.4189, acc-0.9400, valid loss-0.5068, acc-0.8742, test loss-0.5147, acc-0.8707\n",
      "Iter-16610, train loss-0.7045, acc-0.8200, valid loss-0.5065, acc-0.8744, test loss-0.5145, acc-0.8709\n",
      "Iter-16620, train loss-0.5543, acc-0.7600, valid loss-0.5063, acc-0.8748, test loss-0.5143, acc-0.8709\n",
      "Iter-16630, train loss-0.6881, acc-0.8200, valid loss-0.5061, acc-0.8748, test loss-0.5141, acc-0.8713\n",
      "Iter-16640, train loss-0.5108, acc-0.8200, valid loss-0.5059, acc-0.8752, test loss-0.5138, acc-0.8714\n",
      "Iter-16650, train loss-0.6137, acc-0.8400, valid loss-0.5057, acc-0.8754, test loss-0.5136, acc-0.8715\n",
      "Iter-16660, train loss-0.4945, acc-0.9000, valid loss-0.5055, acc-0.8756, test loss-0.5134, acc-0.8711\n",
      "Iter-16670, train loss-0.4846, acc-0.9200, valid loss-0.5052, acc-0.8754, test loss-0.5132, acc-0.8710\n",
      "Iter-16680, train loss-0.4947, acc-0.8600, valid loss-0.5050, acc-0.8750, test loss-0.5130, acc-0.8711\n",
      "Iter-16690, train loss-0.4921, acc-0.8600, valid loss-0.5048, acc-0.8752, test loss-0.5127, acc-0.8714\n",
      "Iter-16700, train loss-0.4086, acc-0.9000, valid loss-0.5046, acc-0.8752, test loss-0.5125, acc-0.8716\n",
      "Iter-16710, train loss-0.5074, acc-0.8600, valid loss-0.5044, acc-0.8758, test loss-0.5123, acc-0.8717\n",
      "Iter-16720, train loss-0.6151, acc-0.8800, valid loss-0.5041, acc-0.8760, test loss-0.5121, acc-0.8717\n",
      "Iter-16730, train loss-0.4545, acc-0.8800, valid loss-0.5039, acc-0.8758, test loss-0.5120, acc-0.8722\n",
      "Iter-16740, train loss-0.4246, acc-0.9000, valid loss-0.5037, acc-0.8754, test loss-0.5118, acc-0.8724\n",
      "Iter-16750, train loss-0.6116, acc-0.8000, valid loss-0.5036, acc-0.8754, test loss-0.5116, acc-0.8715\n",
      "Iter-16760, train loss-0.5664, acc-0.8800, valid loss-0.5033, acc-0.8764, test loss-0.5114, acc-0.8723\n",
      "Iter-16770, train loss-0.5700, acc-0.7800, valid loss-0.5032, acc-0.8764, test loss-0.5112, acc-0.8723\n",
      "Iter-16780, train loss-0.6405, acc-0.8000, valid loss-0.5030, acc-0.8764, test loss-0.5110, acc-0.8720\n",
      "Iter-16790, train loss-0.5474, acc-0.9000, valid loss-0.5027, acc-0.8766, test loss-0.5108, acc-0.8720\n",
      "Iter-16800, train loss-0.4361, acc-0.9200, valid loss-0.5025, acc-0.8762, test loss-0.5106, acc-0.8719\n",
      "Iter-16810, train loss-0.5059, acc-0.8800, valid loss-0.5024, acc-0.8774, test loss-0.5104, acc-0.8721\n",
      "Iter-16820, train loss-0.3388, acc-0.9200, valid loss-0.5021, acc-0.8770, test loss-0.5102, acc-0.8723\n",
      "Iter-16830, train loss-0.4408, acc-0.9400, valid loss-0.5019, acc-0.8760, test loss-0.5099, acc-0.8725\n",
      "Iter-16840, train loss-0.4469, acc-0.8800, valid loss-0.5017, acc-0.8764, test loss-0.5098, acc-0.8724\n",
      "Iter-16850, train loss-0.4249, acc-0.9000, valid loss-0.5016, acc-0.8764, test loss-0.5096, acc-0.8725\n",
      "Iter-16860, train loss-0.4536, acc-0.8800, valid loss-0.5013, acc-0.8766, test loss-0.5093, acc-0.8726\n",
      "Iter-16870, train loss-0.5677, acc-0.7800, valid loss-0.5011, acc-0.8770, test loss-0.5091, acc-0.8725\n",
      "Iter-16880, train loss-0.5146, acc-0.8400, valid loss-0.5009, acc-0.8770, test loss-0.5089, acc-0.8726\n",
      "Iter-16890, train loss-0.4626, acc-0.9000, valid loss-0.5007, acc-0.8770, test loss-0.5087, acc-0.8724\n",
      "Iter-16900, train loss-0.5763, acc-0.8600, valid loss-0.5005, acc-0.8776, test loss-0.5085, acc-0.8727\n",
      "Iter-16910, train loss-0.5965, acc-0.8000, valid loss-0.5003, acc-0.8774, test loss-0.5082, acc-0.8726\n",
      "Iter-16920, train loss-0.6483, acc-0.8200, valid loss-0.5002, acc-0.8774, test loss-0.5080, acc-0.8727\n",
      "Iter-16930, train loss-0.5007, acc-0.9000, valid loss-0.5000, acc-0.8774, test loss-0.5079, acc-0.8729\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16940, train loss-0.5138, acc-0.9000, valid loss-0.4998, acc-0.8772, test loss-0.5077, acc-0.8730\n",
      "Iter-16950, train loss-0.5112, acc-0.8800, valid loss-0.4996, acc-0.8772, test loss-0.5075, acc-0.8729\n",
      "Iter-16960, train loss-0.5383, acc-0.8600, valid loss-0.4994, acc-0.8774, test loss-0.5072, acc-0.8729\n",
      "Iter-16970, train loss-0.5581, acc-0.8400, valid loss-0.4992, acc-0.8772, test loss-0.5071, acc-0.8729\n",
      "Iter-16980, train loss-0.6404, acc-0.8400, valid loss-0.4990, acc-0.8776, test loss-0.5068, acc-0.8730\n",
      "Iter-16990, train loss-0.6407, acc-0.7600, valid loss-0.4988, acc-0.8780, test loss-0.5066, acc-0.8728\n",
      "Iter-17000, train loss-0.6076, acc-0.8600, valid loss-0.4986, acc-0.8776, test loss-0.5064, acc-0.8730\n",
      "Iter-17010, train loss-0.4886, acc-0.8600, valid loss-0.4984, acc-0.8780, test loss-0.5062, acc-0.8731\n",
      "Iter-17020, train loss-0.4824, acc-0.9000, valid loss-0.4982, acc-0.8780, test loss-0.5060, acc-0.8733\n",
      "Iter-17030, train loss-0.4266, acc-0.9000, valid loss-0.4980, acc-0.8780, test loss-0.5058, acc-0.8732\n",
      "Iter-17040, train loss-0.7217, acc-0.8600, valid loss-0.4978, acc-0.8778, test loss-0.5056, acc-0.8733\n",
      "Iter-17050, train loss-0.5355, acc-0.8200, valid loss-0.4977, acc-0.8778, test loss-0.5055, acc-0.8729\n",
      "Iter-17060, train loss-0.4928, acc-0.9000, valid loss-0.4974, acc-0.8774, test loss-0.5053, acc-0.8731\n",
      "Iter-17070, train loss-0.4373, acc-0.9200, valid loss-0.4972, acc-0.8774, test loss-0.5051, acc-0.8734\n",
      "Iter-17080, train loss-0.4619, acc-0.9000, valid loss-0.4970, acc-0.8774, test loss-0.5049, acc-0.8731\n",
      "Iter-17090, train loss-0.4491, acc-0.9200, valid loss-0.4967, acc-0.8780, test loss-0.5047, acc-0.8737\n",
      "Iter-17100, train loss-0.3862, acc-0.9400, valid loss-0.4965, acc-0.8780, test loss-0.5045, acc-0.8739\n",
      "Iter-17110, train loss-0.5406, acc-0.8600, valid loss-0.4963, acc-0.8782, test loss-0.5043, acc-0.8739\n",
      "Iter-17120, train loss-0.5861, acc-0.8400, valid loss-0.4961, acc-0.8786, test loss-0.5041, acc-0.8741\n",
      "Iter-17130, train loss-0.5203, acc-0.9000, valid loss-0.4959, acc-0.8784, test loss-0.5039, acc-0.8736\n",
      "Iter-17140, train loss-0.4827, acc-0.8800, valid loss-0.4958, acc-0.8786, test loss-0.5037, acc-0.8739\n",
      "Iter-17150, train loss-0.5379, acc-0.8400, valid loss-0.4955, acc-0.8786, test loss-0.5035, acc-0.8741\n",
      "Iter-17160, train loss-0.6755, acc-0.8600, valid loss-0.4953, acc-0.8786, test loss-0.5033, acc-0.8739\n",
      "Iter-17170, train loss-0.4354, acc-0.9200, valid loss-0.4951, acc-0.8786, test loss-0.5032, acc-0.8740\n",
      "Iter-17180, train loss-0.6109, acc-0.8400, valid loss-0.4949, acc-0.8786, test loss-0.5029, acc-0.8742\n",
      "Iter-17190, train loss-0.4060, acc-0.9000, valid loss-0.4947, acc-0.8788, test loss-0.5028, acc-0.8743\n",
      "Iter-17200, train loss-0.5727, acc-0.8600, valid loss-0.4945, acc-0.8790, test loss-0.5025, acc-0.8743\n",
      "Iter-17210, train loss-0.6300, acc-0.8600, valid loss-0.4943, acc-0.8788, test loss-0.5023, acc-0.8738\n",
      "Iter-17220, train loss-0.4120, acc-0.9000, valid loss-0.4941, acc-0.8788, test loss-0.5021, acc-0.8739\n",
      "Iter-17230, train loss-0.8515, acc-0.8200, valid loss-0.4939, acc-0.8788, test loss-0.5020, acc-0.8741\n",
      "Iter-17240, train loss-0.5287, acc-0.8600, valid loss-0.4938, acc-0.8792, test loss-0.5018, acc-0.8741\n",
      "Iter-17250, train loss-0.6821, acc-0.8400, valid loss-0.4936, acc-0.8792, test loss-0.5016, acc-0.8740\n",
      "Iter-17260, train loss-0.5810, acc-0.8200, valid loss-0.4934, acc-0.8788, test loss-0.5014, acc-0.8742\n",
      "Iter-17270, train loss-0.4118, acc-0.9000, valid loss-0.4933, acc-0.8790, test loss-0.5012, acc-0.8744\n",
      "Iter-17280, train loss-0.3648, acc-0.9200, valid loss-0.4930, acc-0.8792, test loss-0.5010, acc-0.8741\n",
      "Iter-17290, train loss-0.5604, acc-0.8000, valid loss-0.4928, acc-0.8790, test loss-0.5007, acc-0.8740\n",
      "Iter-17300, train loss-0.2991, acc-0.9800, valid loss-0.4926, acc-0.8792, test loss-0.5006, acc-0.8742\n",
      "Iter-17310, train loss-0.4520, acc-0.8800, valid loss-0.4924, acc-0.8792, test loss-0.5004, acc-0.8742\n",
      "Iter-17320, train loss-0.8174, acc-0.7600, valid loss-0.4922, acc-0.8792, test loss-0.5003, acc-0.8744\n",
      "Iter-17330, train loss-0.5310, acc-0.8600, valid loss-0.4920, acc-0.8798, test loss-0.5000, acc-0.8745\n",
      "Iter-17340, train loss-0.5102, acc-0.8800, valid loss-0.4919, acc-0.8790, test loss-0.4999, acc-0.8747\n",
      "Iter-17350, train loss-0.3829, acc-0.9000, valid loss-0.4917, acc-0.8794, test loss-0.4997, acc-0.8745\n",
      "Iter-17360, train loss-0.5105, acc-0.8400, valid loss-0.4915, acc-0.8794, test loss-0.4994, acc-0.8746\n",
      "Iter-17370, train loss-0.6663, acc-0.7400, valid loss-0.4913, acc-0.8794, test loss-0.4993, acc-0.8745\n",
      "Iter-17380, train loss-0.6402, acc-0.8200, valid loss-0.4911, acc-0.8794, test loss-0.4991, acc-0.8748\n",
      "Iter-17390, train loss-0.4573, acc-0.8800, valid loss-0.4909, acc-0.8790, test loss-0.4989, acc-0.8748\n",
      "Iter-17400, train loss-0.7688, acc-0.8600, valid loss-0.4907, acc-0.8792, test loss-0.4987, acc-0.8748\n",
      "Iter-17410, train loss-0.3706, acc-0.9200, valid loss-0.4905, acc-0.8792, test loss-0.4985, acc-0.8750\n",
      "Iter-17420, train loss-0.6107, acc-0.8000, valid loss-0.4903, acc-0.8796, test loss-0.4983, acc-0.8751\n",
      "Iter-17430, train loss-0.3838, acc-0.9400, valid loss-0.4902, acc-0.8798, test loss-0.4982, acc-0.8752\n",
      "Iter-17440, train loss-0.4640, acc-0.8400, valid loss-0.4900, acc-0.8798, test loss-0.4980, acc-0.8751\n",
      "Iter-17450, train loss-0.5318, acc-0.8400, valid loss-0.4898, acc-0.8796, test loss-0.4978, acc-0.8749\n",
      "Iter-17460, train loss-0.2975, acc-0.9600, valid loss-0.4896, acc-0.8798, test loss-0.4976, acc-0.8754\n",
      "Iter-17470, train loss-0.3824, acc-0.9200, valid loss-0.4894, acc-0.8800, test loss-0.4974, acc-0.8751\n",
      "Iter-17480, train loss-0.3599, acc-0.9200, valid loss-0.4892, acc-0.8800, test loss-0.4973, acc-0.8752\n",
      "Iter-17490, train loss-0.5275, acc-0.8800, valid loss-0.4891, acc-0.8800, test loss-0.4971, acc-0.8751\n",
      "Iter-17500, train loss-0.4305, acc-0.9000, valid loss-0.4889, acc-0.8802, test loss-0.4969, acc-0.8751\n",
      "Iter-17510, train loss-0.4165, acc-0.9200, valid loss-0.4886, acc-0.8802, test loss-0.4967, acc-0.8754\n",
      "Iter-17520, train loss-0.4919, acc-0.8600, valid loss-0.4885, acc-0.8804, test loss-0.4965, acc-0.8755\n",
      "Iter-17530, train loss-0.6093, acc-0.8800, valid loss-0.4883, acc-0.8804, test loss-0.4964, acc-0.8754\n",
      "Iter-17540, train loss-0.4838, acc-0.8400, valid loss-0.4881, acc-0.8802, test loss-0.4962, acc-0.8756\n",
      "Iter-17550, train loss-0.5256, acc-0.8200, valid loss-0.4880, acc-0.8798, test loss-0.4960, acc-0.8751\n",
      "Iter-17560, train loss-0.5645, acc-0.9000, valid loss-0.4877, acc-0.8802, test loss-0.4958, acc-0.8756\n",
      "Iter-17570, train loss-0.6316, acc-0.7800, valid loss-0.4875, acc-0.8800, test loss-0.4956, acc-0.8759\n",
      "Iter-17580, train loss-0.5632, acc-0.7800, valid loss-0.4873, acc-0.8798, test loss-0.4955, acc-0.8759\n",
      "Iter-17590, train loss-0.4093, acc-0.9200, valid loss-0.4871, acc-0.8806, test loss-0.4952, acc-0.8761\n",
      "Iter-17600, train loss-0.6266, acc-0.8400, valid loss-0.4870, acc-0.8800, test loss-0.4951, acc-0.8759\n",
      "Iter-17610, train loss-0.5661, acc-0.8000, valid loss-0.4868, acc-0.8802, test loss-0.4949, acc-0.8759\n",
      "Iter-17620, train loss-0.5417, acc-0.9200, valid loss-0.4866, acc-0.8806, test loss-0.4948, acc-0.8761\n",
      "Iter-17630, train loss-0.3668, acc-0.9400, valid loss-0.4865, acc-0.8806, test loss-0.4946, acc-0.8759\n",
      "Iter-17640, train loss-0.6429, acc-0.8000, valid loss-0.4863, acc-0.8806, test loss-0.4944, acc-0.8758\n",
      "Iter-17650, train loss-0.5132, acc-0.8400, valid loss-0.4861, acc-0.8806, test loss-0.4942, acc-0.8760\n",
      "Iter-17660, train loss-0.8842, acc-0.8000, valid loss-0.4859, acc-0.8808, test loss-0.4941, acc-0.8760\n",
      "Iter-17670, train loss-0.3603, acc-0.9400, valid loss-0.4856, acc-0.8806, test loss-0.4939, acc-0.8760\n",
      "Iter-17680, train loss-0.5603, acc-0.8000, valid loss-0.4854, acc-0.8810, test loss-0.4937, acc-0.8759\n",
      "Iter-17690, train loss-0.5730, acc-0.8000, valid loss-0.4852, acc-0.8812, test loss-0.4936, acc-0.8761\n",
      "Iter-17700, train loss-0.6165, acc-0.8000, valid loss-0.4850, acc-0.8810, test loss-0.4934, acc-0.8761\n",
      "Iter-17710, train loss-0.6099, acc-0.8000, valid loss-0.4848, acc-0.8810, test loss-0.4932, acc-0.8763\n",
      "Iter-17720, train loss-0.6538, acc-0.8400, valid loss-0.4846, acc-0.8810, test loss-0.4930, acc-0.8759\n",
      "Iter-17730, train loss-0.5961, acc-0.9000, valid loss-0.4844, acc-0.8816, test loss-0.4928, acc-0.8762\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-17740, train loss-0.6864, acc-0.8200, valid loss-0.4842, acc-0.8816, test loss-0.4926, acc-0.8763\n",
      "Iter-17750, train loss-0.5637, acc-0.8400, valid loss-0.4840, acc-0.8814, test loss-0.4924, acc-0.8764\n",
      "Iter-17760, train loss-0.5550, acc-0.8600, valid loss-0.4838, acc-0.8814, test loss-0.4922, acc-0.8761\n",
      "Iter-17770, train loss-0.4447, acc-0.8800, valid loss-0.4836, acc-0.8812, test loss-0.4921, acc-0.8761\n",
      "Iter-17780, train loss-0.4927, acc-0.8400, valid loss-0.4834, acc-0.8816, test loss-0.4919, acc-0.8763\n",
      "Iter-17790, train loss-0.3521, acc-0.9200, valid loss-0.4832, acc-0.8824, test loss-0.4918, acc-0.8761\n",
      "Iter-17800, train loss-0.5241, acc-0.8800, valid loss-0.4830, acc-0.8816, test loss-0.4916, acc-0.8762\n",
      "Iter-17810, train loss-0.5008, acc-0.9000, valid loss-0.4829, acc-0.8822, test loss-0.4914, acc-0.8764\n",
      "Iter-17820, train loss-0.4230, acc-0.9200, valid loss-0.4827, acc-0.8822, test loss-0.4912, acc-0.8767\n",
      "Iter-17830, train loss-0.6164, acc-0.7800, valid loss-0.4825, acc-0.8824, test loss-0.4910, acc-0.8765\n",
      "Iter-17840, train loss-0.5243, acc-0.8400, valid loss-0.4824, acc-0.8828, test loss-0.4909, acc-0.8768\n",
      "Iter-17850, train loss-0.5125, acc-0.8600, valid loss-0.4822, acc-0.8828, test loss-0.4907, acc-0.8766\n",
      "Iter-17860, train loss-0.4685, acc-0.8800, valid loss-0.4820, acc-0.8830, test loss-0.4904, acc-0.8769\n",
      "Iter-17870, train loss-0.4830, acc-0.8600, valid loss-0.4817, acc-0.8830, test loss-0.4902, acc-0.8767\n",
      "Iter-17880, train loss-0.3773, acc-0.9000, valid loss-0.4816, acc-0.8828, test loss-0.4901, acc-0.8765\n",
      "Iter-17890, train loss-0.3379, acc-0.9400, valid loss-0.4814, acc-0.8828, test loss-0.4899, acc-0.8768\n",
      "Iter-17900, train loss-0.4494, acc-0.8600, valid loss-0.4812, acc-0.8826, test loss-0.4898, acc-0.8768\n",
      "Iter-17910, train loss-0.5607, acc-0.8600, valid loss-0.4810, acc-0.8828, test loss-0.4896, acc-0.8769\n",
      "Iter-17920, train loss-0.3891, acc-0.9200, valid loss-0.4808, acc-0.8828, test loss-0.4895, acc-0.8773\n",
      "Iter-17930, train loss-0.5068, acc-0.8800, valid loss-0.4807, acc-0.8826, test loss-0.4893, acc-0.8769\n",
      "Iter-17940, train loss-0.5318, acc-0.8200, valid loss-0.4805, acc-0.8824, test loss-0.4891, acc-0.8769\n",
      "Iter-17950, train loss-0.3150, acc-0.9400, valid loss-0.4803, acc-0.8828, test loss-0.4889, acc-0.8770\n",
      "Iter-17960, train loss-0.6376, acc-0.8200, valid loss-0.4801, acc-0.8828, test loss-0.4887, acc-0.8770\n",
      "Iter-17970, train loss-0.5909, acc-0.8200, valid loss-0.4800, acc-0.8828, test loss-0.4885, acc-0.8772\n",
      "Iter-17980, train loss-0.4944, acc-0.8800, valid loss-0.4798, acc-0.8830, test loss-0.4883, acc-0.8775\n",
      "Iter-17990, train loss-0.4488, acc-0.9200, valid loss-0.4796, acc-0.8828, test loss-0.4882, acc-0.8774\n",
      "Iter-18000, train loss-0.4373, acc-0.8400, valid loss-0.4794, acc-0.8828, test loss-0.4879, acc-0.8774\n",
      "Iter-18010, train loss-0.5401, acc-0.8400, valid loss-0.4792, acc-0.8830, test loss-0.4878, acc-0.8773\n",
      "Iter-18020, train loss-0.4594, acc-0.9200, valid loss-0.4790, acc-0.8830, test loss-0.4876, acc-0.8773\n",
      "Iter-18030, train loss-0.4252, acc-0.9000, valid loss-0.4788, acc-0.8830, test loss-0.4873, acc-0.8774\n",
      "Iter-18040, train loss-0.4125, acc-0.8800, valid loss-0.4786, acc-0.8830, test loss-0.4871, acc-0.8773\n",
      "Iter-18050, train loss-0.4473, acc-0.8800, valid loss-0.4784, acc-0.8832, test loss-0.4870, acc-0.8775\n",
      "Iter-18060, train loss-0.5784, acc-0.8200, valid loss-0.4783, acc-0.8830, test loss-0.4868, acc-0.8776\n",
      "Iter-18070, train loss-0.4851, acc-0.8800, valid loss-0.4781, acc-0.8830, test loss-0.4866, acc-0.8776\n",
      "Iter-18080, train loss-0.4222, acc-0.8800, valid loss-0.4780, acc-0.8830, test loss-0.4864, acc-0.8777\n",
      "Iter-18090, train loss-0.4656, acc-0.8400, valid loss-0.4778, acc-0.8836, test loss-0.4863, acc-0.8778\n",
      "Iter-18100, train loss-0.4127, acc-0.9000, valid loss-0.4777, acc-0.8836, test loss-0.4861, acc-0.8777\n",
      "Iter-18110, train loss-0.4345, acc-0.9000, valid loss-0.4775, acc-0.8838, test loss-0.4859, acc-0.8781\n",
      "Iter-18120, train loss-0.4217, acc-0.8600, valid loss-0.4773, acc-0.8842, test loss-0.4857, acc-0.8780\n",
      "Iter-18130, train loss-0.6966, acc-0.8200, valid loss-0.4772, acc-0.8838, test loss-0.4856, acc-0.8783\n",
      "Iter-18140, train loss-0.5001, acc-0.8800, valid loss-0.4770, acc-0.8836, test loss-0.4854, acc-0.8781\n",
      "Iter-18150, train loss-0.5088, acc-0.8800, valid loss-0.4768, acc-0.8838, test loss-0.4853, acc-0.8782\n",
      "Iter-18160, train loss-0.5063, acc-0.8800, valid loss-0.4766, acc-0.8838, test loss-0.4851, acc-0.8778\n",
      "Iter-18170, train loss-0.5337, acc-0.8600, valid loss-0.4765, acc-0.8834, test loss-0.4849, acc-0.8780\n",
      "Iter-18180, train loss-0.5718, acc-0.8400, valid loss-0.4763, acc-0.8834, test loss-0.4848, acc-0.8780\n",
      "Iter-18190, train loss-0.5183, acc-0.8800, valid loss-0.4762, acc-0.8836, test loss-0.4846, acc-0.8782\n",
      "Iter-18200, train loss-0.6554, acc-0.7600, valid loss-0.4760, acc-0.8836, test loss-0.4844, acc-0.8785\n",
      "Iter-18210, train loss-0.3939, acc-0.8800, valid loss-0.4759, acc-0.8834, test loss-0.4843, acc-0.8785\n",
      "Iter-18220, train loss-0.3217, acc-0.9400, valid loss-0.4757, acc-0.8834, test loss-0.4841, acc-0.8784\n",
      "Iter-18230, train loss-0.5174, acc-0.8800, valid loss-0.4755, acc-0.8836, test loss-0.4839, acc-0.8784\n",
      "Iter-18240, train loss-0.4508, acc-0.8400, valid loss-0.4754, acc-0.8834, test loss-0.4838, acc-0.8785\n",
      "Iter-18250, train loss-0.4764, acc-0.9000, valid loss-0.4752, acc-0.8834, test loss-0.4836, acc-0.8785\n",
      "Iter-18260, train loss-0.5298, acc-0.8800, valid loss-0.4750, acc-0.8838, test loss-0.4835, acc-0.8784\n",
      "Iter-18270, train loss-0.4530, acc-0.9200, valid loss-0.4748, acc-0.8840, test loss-0.4833, acc-0.8784\n",
      "Iter-18280, train loss-0.4828, acc-0.9000, valid loss-0.4747, acc-0.8838, test loss-0.4831, acc-0.8785\n",
      "Iter-18290, train loss-0.3649, acc-0.9200, valid loss-0.4745, acc-0.8838, test loss-0.4829, acc-0.8785\n",
      "Iter-18300, train loss-0.4280, acc-0.9000, valid loss-0.4743, acc-0.8836, test loss-0.4827, acc-0.8787\n",
      "Iter-18310, train loss-0.5701, acc-0.8600, valid loss-0.4741, acc-0.8840, test loss-0.4825, acc-0.8786\n",
      "Iter-18320, train loss-0.6381, acc-0.8400, valid loss-0.4740, acc-0.8838, test loss-0.4824, acc-0.8787\n",
      "Iter-18330, train loss-0.4706, acc-0.9000, valid loss-0.4737, acc-0.8838, test loss-0.4822, acc-0.8789\n",
      "Iter-18340, train loss-0.4775, acc-0.8400, valid loss-0.4736, acc-0.8838, test loss-0.4820, acc-0.8789\n",
      "Iter-18350, train loss-0.6663, acc-0.8200, valid loss-0.4734, acc-0.8842, test loss-0.4819, acc-0.8789\n",
      "Iter-18360, train loss-0.7058, acc-0.8000, valid loss-0.4732, acc-0.8840, test loss-0.4817, acc-0.8788\n",
      "Iter-18370, train loss-0.4209, acc-0.9000, valid loss-0.4730, acc-0.8848, test loss-0.4815, acc-0.8790\n",
      "Iter-18380, train loss-0.5560, acc-0.8800, valid loss-0.4729, acc-0.8848, test loss-0.4813, acc-0.8790\n",
      "Iter-18390, train loss-0.5519, acc-0.8400, valid loss-0.4727, acc-0.8848, test loss-0.4811, acc-0.8790\n",
      "Iter-18400, train loss-0.4221, acc-0.9000, valid loss-0.4725, acc-0.8850, test loss-0.4810, acc-0.8790\n",
      "Iter-18410, train loss-0.3358, acc-0.9200, valid loss-0.4723, acc-0.8850, test loss-0.4808, acc-0.8792\n",
      "Iter-18420, train loss-0.4631, acc-0.9200, valid loss-0.4721, acc-0.8850, test loss-0.4806, acc-0.8792\n",
      "Iter-18430, train loss-0.4520, acc-0.8200, valid loss-0.4720, acc-0.8848, test loss-0.4804, acc-0.8793\n",
      "Iter-18440, train loss-0.4604, acc-0.8800, valid loss-0.4718, acc-0.8848, test loss-0.4803, acc-0.8794\n",
      "Iter-18450, train loss-0.4784, acc-0.8400, valid loss-0.4716, acc-0.8846, test loss-0.4801, acc-0.8794\n",
      "Iter-18460, train loss-0.5236, acc-0.9000, valid loss-0.4714, acc-0.8848, test loss-0.4799, acc-0.8796\n",
      "Iter-18470, train loss-0.4525, acc-0.9200, valid loss-0.4712, acc-0.8846, test loss-0.4798, acc-0.8796\n",
      "Iter-18480, train loss-0.5651, acc-0.8000, valid loss-0.4711, acc-0.8846, test loss-0.4796, acc-0.8801\n",
      "Iter-18490, train loss-0.4418, acc-0.8800, valid loss-0.4709, acc-0.8846, test loss-0.4795, acc-0.8797\n",
      "Iter-18500, train loss-0.6908, acc-0.8600, valid loss-0.4708, acc-0.8852, test loss-0.4793, acc-0.8797\n",
      "Iter-18510, train loss-0.8084, acc-0.8000, valid loss-0.4706, acc-0.8850, test loss-0.4791, acc-0.8798\n",
      "Iter-18520, train loss-0.2830, acc-0.9400, valid loss-0.4705, acc-0.8848, test loss-0.4790, acc-0.8797\n",
      "Iter-18530, train loss-0.3516, acc-0.9400, valid loss-0.4703, acc-0.8856, test loss-0.4788, acc-0.8800\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-18540, train loss-0.4338, acc-0.8800, valid loss-0.4701, acc-0.8854, test loss-0.4786, acc-0.8800\n",
      "Iter-18550, train loss-0.3893, acc-0.9200, valid loss-0.4700, acc-0.8852, test loss-0.4784, acc-0.8801\n",
      "Iter-18560, train loss-0.5918, acc-0.8600, valid loss-0.4698, acc-0.8854, test loss-0.4783, acc-0.8800\n",
      "Iter-18570, train loss-0.4758, acc-0.8800, valid loss-0.4696, acc-0.8854, test loss-0.4781, acc-0.8800\n",
      "Iter-18580, train loss-0.4894, acc-0.9000, valid loss-0.4694, acc-0.8854, test loss-0.4779, acc-0.8803\n",
      "Iter-18590, train loss-0.3026, acc-0.9600, valid loss-0.4693, acc-0.8856, test loss-0.4778, acc-0.8804\n",
      "Iter-18600, train loss-0.4840, acc-0.8600, valid loss-0.4691, acc-0.8856, test loss-0.4776, acc-0.8806\n",
      "Iter-18610, train loss-0.5172, acc-0.7800, valid loss-0.4689, acc-0.8854, test loss-0.4775, acc-0.8803\n",
      "Iter-18620, train loss-0.5324, acc-0.8200, valid loss-0.4688, acc-0.8854, test loss-0.4773, acc-0.8804\n",
      "Iter-18630, train loss-0.4534, acc-0.9200, valid loss-0.4686, acc-0.8856, test loss-0.4772, acc-0.8806\n",
      "Iter-18640, train loss-0.3235, acc-0.9200, valid loss-0.4684, acc-0.8858, test loss-0.4770, acc-0.8806\n",
      "Iter-18650, train loss-0.6533, acc-0.7600, valid loss-0.4683, acc-0.8856, test loss-0.4768, acc-0.8807\n",
      "Iter-18660, train loss-0.4787, acc-0.9000, valid loss-0.4681, acc-0.8854, test loss-0.4768, acc-0.8809\n",
      "Iter-18670, train loss-0.4213, acc-0.9000, valid loss-0.4679, acc-0.8856, test loss-0.4766, acc-0.8809\n",
      "Iter-18680, train loss-0.4655, acc-0.9000, valid loss-0.4677, acc-0.8856, test loss-0.4765, acc-0.8808\n",
      "Iter-18690, train loss-0.4221, acc-0.9200, valid loss-0.4675, acc-0.8856, test loss-0.4763, acc-0.8807\n",
      "Iter-18700, train loss-0.2072, acc-1.0000, valid loss-0.4673, acc-0.8854, test loss-0.4761, acc-0.8810\n",
      "Iter-18710, train loss-0.5283, acc-0.8400, valid loss-0.4671, acc-0.8856, test loss-0.4759, acc-0.8807\n",
      "Iter-18720, train loss-0.3388, acc-0.9400, valid loss-0.4670, acc-0.8858, test loss-0.4758, acc-0.8805\n",
      "Iter-18730, train loss-0.4789, acc-0.8600, valid loss-0.4668, acc-0.8856, test loss-0.4756, acc-0.8807\n",
      "Iter-18740, train loss-0.4082, acc-0.9000, valid loss-0.4667, acc-0.8858, test loss-0.4754, acc-0.8807\n",
      "Iter-18750, train loss-0.4982, acc-0.8800, valid loss-0.4665, acc-0.8856, test loss-0.4753, acc-0.8810\n",
      "Iter-18760, train loss-0.6202, acc-0.8600, valid loss-0.4663, acc-0.8856, test loss-0.4751, acc-0.8807\n",
      "Iter-18770, train loss-0.3611, acc-0.9200, valid loss-0.4662, acc-0.8856, test loss-0.4750, acc-0.8806\n",
      "Iter-18780, train loss-0.3361, acc-0.9200, valid loss-0.4660, acc-0.8856, test loss-0.4748, acc-0.8808\n",
      "Iter-18790, train loss-0.5525, acc-0.8600, valid loss-0.4658, acc-0.8858, test loss-0.4747, acc-0.8810\n",
      "Iter-18800, train loss-0.4087, acc-0.9000, valid loss-0.4656, acc-0.8856, test loss-0.4744, acc-0.8811\n",
      "Iter-18810, train loss-0.2717, acc-0.9200, valid loss-0.4654, acc-0.8856, test loss-0.4742, acc-0.8814\n",
      "Iter-18820, train loss-0.5450, acc-0.8600, valid loss-0.4653, acc-0.8856, test loss-0.4740, acc-0.8815\n",
      "Iter-18830, train loss-0.5107, acc-0.8800, valid loss-0.4652, acc-0.8854, test loss-0.4739, acc-0.8812\n",
      "Iter-18840, train loss-0.7075, acc-0.7600, valid loss-0.4651, acc-0.8856, test loss-0.4737, acc-0.8812\n",
      "Iter-18850, train loss-0.4450, acc-0.8600, valid loss-0.4649, acc-0.8856, test loss-0.4735, acc-0.8810\n",
      "Iter-18860, train loss-0.5343, acc-0.8400, valid loss-0.4647, acc-0.8858, test loss-0.4734, acc-0.8811\n",
      "Iter-18870, train loss-0.4086, acc-0.9000, valid loss-0.4646, acc-0.8858, test loss-0.4732, acc-0.8814\n",
      "Iter-18880, train loss-0.6343, acc-0.8200, valid loss-0.4644, acc-0.8858, test loss-0.4731, acc-0.8815\n",
      "Iter-18890, train loss-0.5739, acc-0.8000, valid loss-0.4643, acc-0.8860, test loss-0.4729, acc-0.8815\n",
      "Iter-18900, train loss-0.3910, acc-0.9200, valid loss-0.4642, acc-0.8858, test loss-0.4728, acc-0.8818\n",
      "Iter-18910, train loss-0.3905, acc-0.9000, valid loss-0.4641, acc-0.8858, test loss-0.4726, acc-0.8815\n",
      "Iter-18920, train loss-0.4776, acc-0.8400, valid loss-0.4639, acc-0.8858, test loss-0.4724, acc-0.8815\n",
      "Iter-18930, train loss-0.3571, acc-0.9200, valid loss-0.4638, acc-0.8856, test loss-0.4723, acc-0.8815\n",
      "Iter-18940, train loss-0.3732, acc-0.8800, valid loss-0.4636, acc-0.8858, test loss-0.4721, acc-0.8817\n",
      "Iter-18950, train loss-0.4076, acc-0.9200, valid loss-0.4634, acc-0.8856, test loss-0.4719, acc-0.8815\n",
      "Iter-18960, train loss-0.5452, acc-0.8400, valid loss-0.4632, acc-0.8858, test loss-0.4717, acc-0.8816\n",
      "Iter-18970, train loss-0.5247, acc-0.8400, valid loss-0.4631, acc-0.8854, test loss-0.4716, acc-0.8819\n",
      "Iter-18980, train loss-0.6217, acc-0.8600, valid loss-0.4629, acc-0.8858, test loss-0.4714, acc-0.8820\n",
      "Iter-18990, train loss-0.5332, acc-0.8600, valid loss-0.4628, acc-0.8858, test loss-0.4712, acc-0.8818\n",
      "Iter-19000, train loss-0.4829, acc-0.8600, valid loss-0.4626, acc-0.8856, test loss-0.4710, acc-0.8819\n",
      "Iter-19010, train loss-0.5283, acc-0.8600, valid loss-0.4625, acc-0.8858, test loss-0.4708, acc-0.8820\n",
      "Iter-19020, train loss-0.3747, acc-0.9000, valid loss-0.4623, acc-0.8856, test loss-0.4707, acc-0.8820\n",
      "Iter-19030, train loss-0.2948, acc-0.9600, valid loss-0.4622, acc-0.8856, test loss-0.4706, acc-0.8820\n",
      "Iter-19040, train loss-0.5499, acc-0.8800, valid loss-0.4620, acc-0.8854, test loss-0.4704, acc-0.8820\n",
      "Iter-19050, train loss-0.4813, acc-0.8600, valid loss-0.4619, acc-0.8856, test loss-0.4703, acc-0.8821\n",
      "Iter-19060, train loss-0.4978, acc-0.8400, valid loss-0.4617, acc-0.8858, test loss-0.4701, acc-0.8819\n",
      "Iter-19070, train loss-0.4484, acc-0.9000, valid loss-0.4616, acc-0.8856, test loss-0.4700, acc-0.8821\n",
      "Iter-19080, train loss-0.5460, acc-0.8200, valid loss-0.4614, acc-0.8856, test loss-0.4698, acc-0.8822\n",
      "Iter-19090, train loss-0.6000, acc-0.8800, valid loss-0.4613, acc-0.8854, test loss-0.4697, acc-0.8821\n",
      "Iter-19100, train loss-0.5981, acc-0.8000, valid loss-0.4611, acc-0.8858, test loss-0.4696, acc-0.8823\n",
      "Iter-19110, train loss-0.5394, acc-0.8800, valid loss-0.4609, acc-0.8862, test loss-0.4694, acc-0.8824\n",
      "Iter-19120, train loss-0.5542, acc-0.8400, valid loss-0.4608, acc-0.8860, test loss-0.4692, acc-0.8823\n",
      "Iter-19130, train loss-0.4433, acc-0.9000, valid loss-0.4606, acc-0.8862, test loss-0.4691, acc-0.8823\n",
      "Iter-19140, train loss-0.4701, acc-0.8600, valid loss-0.4605, acc-0.8862, test loss-0.4690, acc-0.8822\n",
      "Iter-19150, train loss-0.6099, acc-0.8400, valid loss-0.4603, acc-0.8862, test loss-0.4688, acc-0.8824\n",
      "Iter-19160, train loss-0.5631, acc-0.8200, valid loss-0.4602, acc-0.8860, test loss-0.4687, acc-0.8820\n",
      "Iter-19170, train loss-0.6483, acc-0.8200, valid loss-0.4600, acc-0.8858, test loss-0.4685, acc-0.8820\n",
      "Iter-19180, train loss-0.4952, acc-0.8200, valid loss-0.4599, acc-0.8858, test loss-0.4684, acc-0.8820\n",
      "Iter-19190, train loss-0.4881, acc-0.8800, valid loss-0.4597, acc-0.8858, test loss-0.4682, acc-0.8817\n",
      "Iter-19200, train loss-0.4941, acc-0.8600, valid loss-0.4596, acc-0.8854, test loss-0.4681, acc-0.8819\n",
      "Iter-19210, train loss-0.5278, acc-0.8800, valid loss-0.4594, acc-0.8858, test loss-0.4679, acc-0.8819\n",
      "Iter-19220, train loss-0.4612, acc-0.8800, valid loss-0.4592, acc-0.8858, test loss-0.4677, acc-0.8822\n",
      "Iter-19230, train loss-0.4237, acc-0.9400, valid loss-0.4591, acc-0.8858, test loss-0.4676, acc-0.8821\n",
      "Iter-19240, train loss-0.6855, acc-0.7600, valid loss-0.4590, acc-0.8860, test loss-0.4674, acc-0.8820\n",
      "Iter-19250, train loss-0.4389, acc-0.9000, valid loss-0.4587, acc-0.8862, test loss-0.4672, acc-0.8819\n",
      "Iter-19260, train loss-0.4431, acc-0.9000, valid loss-0.4585, acc-0.8864, test loss-0.4671, acc-0.8820\n",
      "Iter-19270, train loss-0.3790, acc-0.9600, valid loss-0.4584, acc-0.8862, test loss-0.4669, acc-0.8824\n",
      "Iter-19280, train loss-0.6470, acc-0.8000, valid loss-0.4582, acc-0.8864, test loss-0.4667, acc-0.8822\n",
      "Iter-19290, train loss-0.6686, acc-0.8000, valid loss-0.4580, acc-0.8862, test loss-0.4666, acc-0.8824\n",
      "Iter-19300, train loss-0.4012, acc-0.9200, valid loss-0.4579, acc-0.8862, test loss-0.4664, acc-0.8826\n",
      "Iter-19310, train loss-0.6855, acc-0.8000, valid loss-0.4577, acc-0.8860, test loss-0.4663, acc-0.8829\n",
      "Iter-19320, train loss-0.3608, acc-0.9600, valid loss-0.4575, acc-0.8862, test loss-0.4661, acc-0.8833\n",
      "Iter-19330, train loss-0.4267, acc-0.9000, valid loss-0.4574, acc-0.8870, test loss-0.4660, acc-0.8828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-19340, train loss-0.6276, acc-0.8400, valid loss-0.4572, acc-0.8868, test loss-0.4659, acc-0.8829\n",
      "Iter-19350, train loss-0.3437, acc-0.9200, valid loss-0.4571, acc-0.8870, test loss-0.4657, acc-0.8832\n",
      "Iter-19360, train loss-0.5082, acc-0.7800, valid loss-0.4569, acc-0.8874, test loss-0.4655, acc-0.8831\n",
      "Iter-19370, train loss-0.6467, acc-0.7800, valid loss-0.4568, acc-0.8872, test loss-0.4654, acc-0.8830\n",
      "Iter-19380, train loss-0.6884, acc-0.7800, valid loss-0.4566, acc-0.8870, test loss-0.4652, acc-0.8832\n",
      "Iter-19390, train loss-0.5103, acc-0.8800, valid loss-0.4565, acc-0.8874, test loss-0.4651, acc-0.8835\n",
      "Iter-19400, train loss-0.3171, acc-0.9200, valid loss-0.4564, acc-0.8872, test loss-0.4650, acc-0.8831\n",
      "Iter-19410, train loss-0.4337, acc-0.9200, valid loss-0.4563, acc-0.8872, test loss-0.4648, acc-0.8829\n",
      "Iter-19420, train loss-0.6174, acc-0.8400, valid loss-0.4562, acc-0.8870, test loss-0.4646, acc-0.8831\n",
      "Iter-19430, train loss-0.5582, acc-0.9000, valid loss-0.4560, acc-0.8872, test loss-0.4645, acc-0.8833\n",
      "Iter-19440, train loss-0.4721, acc-0.8600, valid loss-0.4559, acc-0.8870, test loss-0.4644, acc-0.8834\n",
      "Iter-19450, train loss-0.7297, acc-0.8200, valid loss-0.4557, acc-0.8872, test loss-0.4642, acc-0.8834\n",
      "Iter-19460, train loss-0.5469, acc-0.8600, valid loss-0.4556, acc-0.8872, test loss-0.4641, acc-0.8840\n",
      "Iter-19470, train loss-0.4706, acc-0.8800, valid loss-0.4554, acc-0.8868, test loss-0.4639, acc-0.8838\n",
      "Iter-19480, train loss-0.4028, acc-0.9000, valid loss-0.4553, acc-0.8870, test loss-0.4638, acc-0.8837\n",
      "Iter-19490, train loss-0.6051, acc-0.7600, valid loss-0.4551, acc-0.8872, test loss-0.4637, acc-0.8841\n",
      "Iter-19500, train loss-0.7079, acc-0.8000, valid loss-0.4550, acc-0.8868, test loss-0.4634, acc-0.8838\n",
      "Iter-19510, train loss-0.3931, acc-0.8800, valid loss-0.4548, acc-0.8872, test loss-0.4634, acc-0.8837\n",
      "Iter-19520, train loss-0.4677, acc-0.8800, valid loss-0.4547, acc-0.8868, test loss-0.4632, acc-0.8836\n",
      "Iter-19530, train loss-0.5974, acc-0.8600, valid loss-0.4545, acc-0.8866, test loss-0.4631, acc-0.8836\n",
      "Iter-19540, train loss-0.4521, acc-0.8400, valid loss-0.4544, acc-0.8866, test loss-0.4629, acc-0.8835\n",
      "Iter-19550, train loss-0.4745, acc-0.8800, valid loss-0.4542, acc-0.8866, test loss-0.4628, acc-0.8833\n",
      "Iter-19560, train loss-0.4402, acc-0.9000, valid loss-0.4541, acc-0.8864, test loss-0.4626, acc-0.8835\n",
      "Iter-19570, train loss-0.5997, acc-0.8600, valid loss-0.4540, acc-0.8868, test loss-0.4625, acc-0.8836\n",
      "Iter-19580, train loss-0.5113, acc-0.8200, valid loss-0.4539, acc-0.8864, test loss-0.4623, acc-0.8835\n",
      "Iter-19590, train loss-0.4905, acc-0.8800, valid loss-0.4537, acc-0.8864, test loss-0.4622, acc-0.8837\n",
      "Iter-19600, train loss-0.5612, acc-0.7800, valid loss-0.4535, acc-0.8862, test loss-0.4621, acc-0.8837\n",
      "Iter-19610, train loss-0.2991, acc-0.9600, valid loss-0.4534, acc-0.8868, test loss-0.4619, acc-0.8839\n",
      "Iter-19620, train loss-0.3810, acc-0.9200, valid loss-0.4532, acc-0.8864, test loss-0.4617, acc-0.8838\n",
      "Iter-19630, train loss-0.5342, acc-0.8600, valid loss-0.4531, acc-0.8864, test loss-0.4616, acc-0.8841\n",
      "Iter-19640, train loss-0.4927, acc-0.9000, valid loss-0.4529, acc-0.8864, test loss-0.4615, acc-0.8843\n",
      "Iter-19650, train loss-0.5055, acc-0.8200, valid loss-0.4528, acc-0.8864, test loss-0.4613, acc-0.8842\n",
      "Iter-19660, train loss-0.3667, acc-0.9000, valid loss-0.4527, acc-0.8864, test loss-0.4612, acc-0.8845\n",
      "Iter-19670, train loss-0.4922, acc-0.8400, valid loss-0.4525, acc-0.8866, test loss-0.4610, acc-0.8843\n",
      "Iter-19680, train loss-0.4587, acc-0.8400, valid loss-0.4523, acc-0.8864, test loss-0.4608, acc-0.8842\n",
      "Iter-19690, train loss-0.5104, acc-0.8600, valid loss-0.4521, acc-0.8868, test loss-0.4607, acc-0.8842\n",
      "Iter-19700, train loss-0.5338, acc-0.8400, valid loss-0.4520, acc-0.8862, test loss-0.4606, acc-0.8843\n",
      "Iter-19710, train loss-0.4915, acc-0.8600, valid loss-0.4518, acc-0.8864, test loss-0.4605, acc-0.8845\n",
      "Iter-19720, train loss-0.4768, acc-0.9400, valid loss-0.4517, acc-0.8866, test loss-0.4603, acc-0.8844\n",
      "Iter-19730, train loss-0.3827, acc-0.9000, valid loss-0.4516, acc-0.8862, test loss-0.4602, acc-0.8844\n",
      "Iter-19740, train loss-0.4780, acc-0.8800, valid loss-0.4514, acc-0.8862, test loss-0.4600, acc-0.8843\n",
      "Iter-19750, train loss-0.3561, acc-0.9000, valid loss-0.4512, acc-0.8868, test loss-0.4599, acc-0.8843\n",
      "Iter-19760, train loss-0.3880, acc-0.9400, valid loss-0.4511, acc-0.8868, test loss-0.4598, acc-0.8843\n",
      "Iter-19770, train loss-0.3580, acc-0.9400, valid loss-0.4509, acc-0.8868, test loss-0.4597, acc-0.8843\n",
      "Iter-19780, train loss-0.4920, acc-0.8800, valid loss-0.4508, acc-0.8868, test loss-0.4595, acc-0.8844\n",
      "Iter-19790, train loss-0.4622, acc-0.9000, valid loss-0.4506, acc-0.8866, test loss-0.4594, acc-0.8844\n",
      "Iter-19800, train loss-0.5606, acc-0.8400, valid loss-0.4505, acc-0.8866, test loss-0.4592, acc-0.8844\n",
      "Iter-19810, train loss-0.6381, acc-0.8000, valid loss-0.4504, acc-0.8866, test loss-0.4591, acc-0.8844\n",
      "Iter-19820, train loss-0.3620, acc-0.9200, valid loss-0.4503, acc-0.8866, test loss-0.4590, acc-0.8842\n",
      "Iter-19830, train loss-0.3719, acc-0.9200, valid loss-0.4501, acc-0.8866, test loss-0.4588, acc-0.8845\n",
      "Iter-19840, train loss-0.3066, acc-0.9400, valid loss-0.4500, acc-0.8866, test loss-0.4586, acc-0.8844\n",
      "Iter-19850, train loss-0.4517, acc-0.9000, valid loss-0.4499, acc-0.8864, test loss-0.4585, acc-0.8845\n",
      "Iter-19860, train loss-0.4065, acc-0.9000, valid loss-0.4497, acc-0.8864, test loss-0.4583, acc-0.8846\n",
      "Iter-19870, train loss-0.3827, acc-0.9000, valid loss-0.4496, acc-0.8864, test loss-0.4581, acc-0.8847\n",
      "Iter-19880, train loss-0.5888, acc-0.8400, valid loss-0.4494, acc-0.8870, test loss-0.4579, acc-0.8847\n",
      "Iter-19890, train loss-0.5562, acc-0.8400, valid loss-0.4493, acc-0.8866, test loss-0.4578, acc-0.8849\n",
      "Iter-19900, train loss-0.5568, acc-0.8600, valid loss-0.4491, acc-0.8866, test loss-0.4576, acc-0.8849\n",
      "Iter-19910, train loss-0.6047, acc-0.8600, valid loss-0.4489, acc-0.8868, test loss-0.4575, acc-0.8849\n",
      "Iter-19920, train loss-0.3422, acc-0.9000, valid loss-0.4488, acc-0.8866, test loss-0.4574, acc-0.8848\n",
      "Iter-19930, train loss-0.3781, acc-0.9000, valid loss-0.4486, acc-0.8866, test loss-0.4572, acc-0.8851\n",
      "Iter-19940, train loss-0.4480, acc-0.8800, valid loss-0.4486, acc-0.8866, test loss-0.4571, acc-0.8851\n",
      "Iter-19950, train loss-0.4330, acc-0.8800, valid loss-0.4484, acc-0.8870, test loss-0.4570, acc-0.8851\n",
      "Iter-19960, train loss-0.6430, acc-0.8000, valid loss-0.4483, acc-0.8870, test loss-0.4569, acc-0.8850\n",
      "Iter-19970, train loss-0.4490, acc-0.9000, valid loss-0.4481, acc-0.8870, test loss-0.4567, acc-0.8851\n",
      "Iter-19980, train loss-0.4604, acc-0.8600, valid loss-0.4480, acc-0.8870, test loss-0.4566, acc-0.8852\n",
      "Iter-19990, train loss-0.5879, acc-0.8800, valid loss-0.4479, acc-0.8874, test loss-0.4564, acc-0.8850\n",
      "Iter-20000, train loss-0.5010, acc-0.9000, valid loss-0.4477, acc-0.8874, test loss-0.4563, acc-0.8852\n",
      "Iter-20010, train loss-0.4469, acc-0.9000, valid loss-0.4476, acc-0.8872, test loss-0.4562, acc-0.8851\n",
      "Iter-20020, train loss-0.7132, acc-0.7800, valid loss-0.4475, acc-0.8872, test loss-0.4560, acc-0.8855\n",
      "Iter-20030, train loss-0.6099, acc-0.8800, valid loss-0.4474, acc-0.8872, test loss-0.4559, acc-0.8854\n",
      "Iter-20040, train loss-0.3134, acc-0.9200, valid loss-0.4472, acc-0.8870, test loss-0.4557, acc-0.8856\n",
      "Iter-20050, train loss-0.5172, acc-0.8200, valid loss-0.4471, acc-0.8870, test loss-0.4556, acc-0.8854\n",
      "Iter-20060, train loss-0.3775, acc-0.8800, valid loss-0.4469, acc-0.8870, test loss-0.4555, acc-0.8855\n",
      "Iter-20070, train loss-0.3732, acc-0.8800, valid loss-0.4467, acc-0.8874, test loss-0.4553, acc-0.8859\n",
      "Iter-20080, train loss-0.3622, acc-0.9200, valid loss-0.4466, acc-0.8876, test loss-0.4552, acc-0.8858\n",
      "Iter-20090, train loss-0.5973, acc-0.8400, valid loss-0.4464, acc-0.8876, test loss-0.4550, acc-0.8860\n",
      "Iter-20100, train loss-0.5493, acc-0.8800, valid loss-0.4462, acc-0.8876, test loss-0.4549, acc-0.8860\n",
      "Iter-20110, train loss-0.6628, acc-0.8200, valid loss-0.4460, acc-0.8878, test loss-0.4548, acc-0.8859\n",
      "Iter-20120, train loss-0.5228, acc-0.8400, valid loss-0.4459, acc-0.8878, test loss-0.4546, acc-0.8855\n",
      "Iter-20130, train loss-0.4290, acc-0.8800, valid loss-0.4457, acc-0.8878, test loss-0.4545, acc-0.8857\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20140, train loss-0.3837, acc-0.9200, valid loss-0.4456, acc-0.8878, test loss-0.4544, acc-0.8857\n",
      "Iter-20150, train loss-0.4901, acc-0.8800, valid loss-0.4455, acc-0.8876, test loss-0.4542, acc-0.8854\n",
      "Iter-20160, train loss-0.5589, acc-0.8200, valid loss-0.4453, acc-0.8876, test loss-0.4541, acc-0.8854\n",
      "Iter-20170, train loss-0.3645, acc-0.9400, valid loss-0.4452, acc-0.8872, test loss-0.4540, acc-0.8857\n",
      "Iter-20180, train loss-0.4782, acc-0.8800, valid loss-0.4450, acc-0.8874, test loss-0.4538, acc-0.8862\n",
      "Iter-20190, train loss-0.4402, acc-0.8800, valid loss-0.4449, acc-0.8874, test loss-0.4537, acc-0.8859\n",
      "Iter-20200, train loss-0.4516, acc-0.9000, valid loss-0.4447, acc-0.8874, test loss-0.4536, acc-0.8860\n",
      "Iter-20210, train loss-0.4350, acc-0.8200, valid loss-0.4445, acc-0.8876, test loss-0.4534, acc-0.8860\n",
      "Iter-20220, train loss-0.4804, acc-0.8800, valid loss-0.4443, acc-0.8878, test loss-0.4533, acc-0.8858\n",
      "Iter-20230, train loss-0.5242, acc-0.8600, valid loss-0.4442, acc-0.8878, test loss-0.4531, acc-0.8858\n",
      "Iter-20240, train loss-0.7751, acc-0.7800, valid loss-0.4441, acc-0.8876, test loss-0.4530, acc-0.8858\n",
      "Iter-20250, train loss-0.5770, acc-0.8400, valid loss-0.4439, acc-0.8878, test loss-0.4528, acc-0.8861\n",
      "Iter-20260, train loss-0.3946, acc-0.9400, valid loss-0.4438, acc-0.8882, test loss-0.4527, acc-0.8862\n",
      "Iter-20270, train loss-0.5507, acc-0.8600, valid loss-0.4436, acc-0.8880, test loss-0.4525, acc-0.8858\n",
      "Iter-20280, train loss-0.5392, acc-0.8600, valid loss-0.4435, acc-0.8876, test loss-0.4524, acc-0.8858\n",
      "Iter-20290, train loss-0.4300, acc-0.8800, valid loss-0.4434, acc-0.8880, test loss-0.4522, acc-0.8861\n",
      "Iter-20300, train loss-0.3500, acc-0.9000, valid loss-0.4432, acc-0.8880, test loss-0.4521, acc-0.8858\n",
      "Iter-20310, train loss-0.4527, acc-0.8000, valid loss-0.4431, acc-0.8880, test loss-0.4520, acc-0.8859\n",
      "Iter-20320, train loss-0.4896, acc-0.8800, valid loss-0.4430, acc-0.8882, test loss-0.4519, acc-0.8860\n",
      "Iter-20330, train loss-0.4142, acc-0.8800, valid loss-0.4428, acc-0.8884, test loss-0.4517, acc-0.8862\n",
      "Iter-20340, train loss-0.3678, acc-0.9200, valid loss-0.4427, acc-0.8884, test loss-0.4516, acc-0.8861\n",
      "Iter-20350, train loss-0.5511, acc-0.8600, valid loss-0.4425, acc-0.8884, test loss-0.4514, acc-0.8864\n",
      "Iter-20360, train loss-0.3982, acc-0.9200, valid loss-0.4424, acc-0.8886, test loss-0.4513, acc-0.8862\n",
      "Iter-20370, train loss-0.4441, acc-0.8200, valid loss-0.4422, acc-0.8886, test loss-0.4511, acc-0.8863\n",
      "Iter-20380, train loss-0.5063, acc-0.8800, valid loss-0.4421, acc-0.8888, test loss-0.4510, acc-0.8861\n",
      "Iter-20390, train loss-0.5408, acc-0.8800, valid loss-0.4419, acc-0.8888, test loss-0.4509, acc-0.8861\n",
      "Iter-20400, train loss-0.4285, acc-0.9200, valid loss-0.4418, acc-0.8880, test loss-0.4507, acc-0.8864\n",
      "Iter-20410, train loss-0.3307, acc-0.9200, valid loss-0.4417, acc-0.8880, test loss-0.4506, acc-0.8864\n",
      "Iter-20420, train loss-0.6694, acc-0.8600, valid loss-0.4415, acc-0.8880, test loss-0.4505, acc-0.8863\n",
      "Iter-20430, train loss-0.3338, acc-0.9200, valid loss-0.4414, acc-0.8878, test loss-0.4503, acc-0.8864\n",
      "Iter-20440, train loss-0.3084, acc-0.9200, valid loss-0.4413, acc-0.8880, test loss-0.4502, acc-0.8862\n",
      "Iter-20450, train loss-0.4018, acc-0.9200, valid loss-0.4411, acc-0.8878, test loss-0.4501, acc-0.8861\n",
      "Iter-20460, train loss-0.4883, acc-0.8400, valid loss-0.4410, acc-0.8882, test loss-0.4500, acc-0.8859\n",
      "Iter-20470, train loss-0.4406, acc-0.8200, valid loss-0.4408, acc-0.8880, test loss-0.4499, acc-0.8861\n",
      "Iter-20480, train loss-0.4825, acc-0.8800, valid loss-0.4407, acc-0.8884, test loss-0.4498, acc-0.8860\n",
      "Iter-20490, train loss-0.6266, acc-0.9000, valid loss-0.4406, acc-0.8880, test loss-0.4496, acc-0.8861\n",
      "Iter-20500, train loss-0.4561, acc-0.8800, valid loss-0.4405, acc-0.8878, test loss-0.4495, acc-0.8862\n",
      "Iter-20510, train loss-0.6828, acc-0.8200, valid loss-0.4404, acc-0.8878, test loss-0.4494, acc-0.8859\n",
      "Iter-20520, train loss-0.3683, acc-0.9000, valid loss-0.4402, acc-0.8884, test loss-0.4492, acc-0.8861\n",
      "Iter-20530, train loss-0.2888, acc-0.9800, valid loss-0.4401, acc-0.8882, test loss-0.4490, acc-0.8862\n",
      "Iter-20540, train loss-0.4551, acc-0.8800, valid loss-0.4399, acc-0.8878, test loss-0.4489, acc-0.8860\n",
      "Iter-20550, train loss-0.5479, acc-0.8800, valid loss-0.4398, acc-0.8884, test loss-0.4488, acc-0.8862\n",
      "Iter-20560, train loss-0.7645, acc-0.8000, valid loss-0.4397, acc-0.8884, test loss-0.4486, acc-0.8867\n",
      "Iter-20570, train loss-0.4323, acc-0.8400, valid loss-0.4396, acc-0.8884, test loss-0.4485, acc-0.8867\n",
      "Iter-20580, train loss-0.7527, acc-0.7000, valid loss-0.4395, acc-0.8882, test loss-0.4484, acc-0.8867\n",
      "Iter-20590, train loss-0.5055, acc-0.7800, valid loss-0.4393, acc-0.8882, test loss-0.4482, acc-0.8864\n",
      "Iter-20600, train loss-0.3492, acc-0.9200, valid loss-0.4392, acc-0.8888, test loss-0.4481, acc-0.8864\n",
      "Iter-20610, train loss-0.6394, acc-0.8400, valid loss-0.4391, acc-0.8884, test loss-0.4480, acc-0.8867\n",
      "Iter-20620, train loss-0.3387, acc-0.9200, valid loss-0.4390, acc-0.8886, test loss-0.4478, acc-0.8868\n",
      "Iter-20630, train loss-0.3627, acc-0.9000, valid loss-0.4388, acc-0.8882, test loss-0.4477, acc-0.8869\n",
      "Iter-20640, train loss-0.3643, acc-0.9600, valid loss-0.4387, acc-0.8886, test loss-0.4475, acc-0.8867\n",
      "Iter-20650, train loss-0.6852, acc-0.8200, valid loss-0.4386, acc-0.8886, test loss-0.4474, acc-0.8869\n",
      "Iter-20660, train loss-0.3797, acc-0.8800, valid loss-0.4384, acc-0.8890, test loss-0.4472, acc-0.8869\n",
      "Iter-20670, train loss-0.5471, acc-0.9000, valid loss-0.4382, acc-0.8886, test loss-0.4471, acc-0.8868\n",
      "Iter-20680, train loss-0.3461, acc-0.9200, valid loss-0.4381, acc-0.8886, test loss-0.4470, acc-0.8870\n",
      "Iter-20690, train loss-0.5160, acc-0.8600, valid loss-0.4380, acc-0.8888, test loss-0.4469, acc-0.8873\n",
      "Iter-20700, train loss-0.4803, acc-0.8600, valid loss-0.4378, acc-0.8888, test loss-0.4468, acc-0.8873\n",
      "Iter-20710, train loss-0.4720, acc-0.9000, valid loss-0.4377, acc-0.8888, test loss-0.4466, acc-0.8873\n",
      "Iter-20720, train loss-0.5213, acc-0.8000, valid loss-0.4376, acc-0.8886, test loss-0.4465, acc-0.8872\n",
      "Iter-20730, train loss-0.6389, acc-0.8200, valid loss-0.4375, acc-0.8886, test loss-0.4463, acc-0.8873\n",
      "Iter-20740, train loss-0.4736, acc-0.8000, valid loss-0.4374, acc-0.8888, test loss-0.4461, acc-0.8873\n",
      "Iter-20750, train loss-0.5003, acc-0.8800, valid loss-0.4373, acc-0.8890, test loss-0.4459, acc-0.8873\n",
      "Iter-20760, train loss-0.5222, acc-0.8400, valid loss-0.4372, acc-0.8896, test loss-0.4458, acc-0.8873\n",
      "Iter-20770, train loss-0.4585, acc-0.8600, valid loss-0.4370, acc-0.8896, test loss-0.4456, acc-0.8874\n",
      "Iter-20780, train loss-0.5352, acc-0.8200, valid loss-0.4369, acc-0.8898, test loss-0.4455, acc-0.8874\n",
      "Iter-20790, train loss-0.5053, acc-0.8600, valid loss-0.4368, acc-0.8894, test loss-0.4453, acc-0.8876\n",
      "Iter-20800, train loss-0.4296, acc-0.8800, valid loss-0.4366, acc-0.8896, test loss-0.4452, acc-0.8874\n",
      "Iter-20810, train loss-0.3400, acc-0.9000, valid loss-0.4365, acc-0.8898, test loss-0.4451, acc-0.8875\n",
      "Iter-20820, train loss-0.3055, acc-0.9400, valid loss-0.4363, acc-0.8898, test loss-0.4450, acc-0.8874\n",
      "Iter-20830, train loss-0.4115, acc-0.9200, valid loss-0.4361, acc-0.8898, test loss-0.4448, acc-0.8875\n",
      "Iter-20840, train loss-0.3982, acc-0.9000, valid loss-0.4360, acc-0.8900, test loss-0.4447, acc-0.8873\n",
      "Iter-20850, train loss-0.3842, acc-0.9000, valid loss-0.4358, acc-0.8902, test loss-0.4446, acc-0.8872\n",
      "Iter-20860, train loss-0.4199, acc-0.9000, valid loss-0.4357, acc-0.8908, test loss-0.4445, acc-0.8874\n",
      "Iter-20870, train loss-0.4631, acc-0.8800, valid loss-0.4356, acc-0.8908, test loss-0.4443, acc-0.8872\n",
      "Iter-20880, train loss-0.3556, acc-0.9000, valid loss-0.4355, acc-0.8908, test loss-0.4442, acc-0.8872\n",
      "Iter-20890, train loss-0.4773, acc-0.8800, valid loss-0.4354, acc-0.8908, test loss-0.4441, acc-0.8872\n",
      "Iter-20900, train loss-0.4896, acc-0.8400, valid loss-0.4352, acc-0.8908, test loss-0.4439, acc-0.8870\n",
      "Iter-20910, train loss-0.4868, acc-0.8800, valid loss-0.4350, acc-0.8910, test loss-0.4438, acc-0.8870\n",
      "Iter-20920, train loss-0.2879, acc-0.9600, valid loss-0.4348, acc-0.8916, test loss-0.4436, acc-0.8868\n",
      "Iter-20930, train loss-0.4509, acc-0.9000, valid loss-0.4347, acc-0.8914, test loss-0.4435, acc-0.8868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20940, train loss-0.3043, acc-0.9400, valid loss-0.4345, acc-0.8916, test loss-0.4433, acc-0.8868\n",
      "Iter-20950, train loss-0.4304, acc-0.8800, valid loss-0.4344, acc-0.8918, test loss-0.4432, acc-0.8874\n",
      "Iter-20960, train loss-0.4238, acc-0.8800, valid loss-0.4343, acc-0.8918, test loss-0.4431, acc-0.8870\n",
      "Iter-20970, train loss-0.3384, acc-0.9400, valid loss-0.4341, acc-0.8918, test loss-0.4430, acc-0.8870\n",
      "Iter-20980, train loss-0.3436, acc-0.9400, valid loss-0.4340, acc-0.8920, test loss-0.4429, acc-0.8872\n",
      "Iter-20990, train loss-0.2584, acc-0.9800, valid loss-0.4339, acc-0.8920, test loss-0.4427, acc-0.8871\n",
      "Iter-21000, train loss-0.4333, acc-0.8200, valid loss-0.4337, acc-0.8920, test loss-0.4426, acc-0.8874\n",
      "Iter-21010, train loss-0.4461, acc-0.9000, valid loss-0.4336, acc-0.8920, test loss-0.4425, acc-0.8874\n",
      "Iter-21020, train loss-0.6077, acc-0.8400, valid loss-0.4334, acc-0.8920, test loss-0.4424, acc-0.8873\n",
      "Iter-21030, train loss-0.3691, acc-0.8800, valid loss-0.4333, acc-0.8920, test loss-0.4422, acc-0.8874\n",
      "Iter-21040, train loss-0.4370, acc-0.8800, valid loss-0.4332, acc-0.8920, test loss-0.4421, acc-0.8874\n",
      "Iter-21050, train loss-0.4185, acc-0.9200, valid loss-0.4331, acc-0.8920, test loss-0.4421, acc-0.8874\n",
      "Iter-21060, train loss-0.5838, acc-0.8400, valid loss-0.4330, acc-0.8920, test loss-0.4419, acc-0.8872\n",
      "Iter-21070, train loss-0.4028, acc-0.9000, valid loss-0.4329, acc-0.8920, test loss-0.4418, acc-0.8873\n",
      "Iter-21080, train loss-0.4073, acc-0.8800, valid loss-0.4327, acc-0.8918, test loss-0.4417, acc-0.8871\n",
      "Iter-21090, train loss-0.5323, acc-0.8000, valid loss-0.4326, acc-0.8920, test loss-0.4415, acc-0.8874\n",
      "Iter-21100, train loss-0.7266, acc-0.8200, valid loss-0.4325, acc-0.8920, test loss-0.4414, acc-0.8873\n",
      "Iter-21110, train loss-0.3986, acc-0.9400, valid loss-0.4323, acc-0.8920, test loss-0.4413, acc-0.8872\n",
      "Iter-21120, train loss-0.3490, acc-0.9800, valid loss-0.4322, acc-0.8920, test loss-0.4412, acc-0.8876\n",
      "Iter-21130, train loss-0.3903, acc-0.9200, valid loss-0.4320, acc-0.8922, test loss-0.4411, acc-0.8873\n",
      "Iter-21140, train loss-0.3320, acc-0.9600, valid loss-0.4319, acc-0.8920, test loss-0.4409, acc-0.8877\n",
      "Iter-21150, train loss-0.4493, acc-0.9000, valid loss-0.4318, acc-0.8920, test loss-0.4408, acc-0.8877\n",
      "Iter-21160, train loss-0.4429, acc-0.8600, valid loss-0.4317, acc-0.8916, test loss-0.4407, acc-0.8877\n",
      "Iter-21170, train loss-0.2980, acc-0.9000, valid loss-0.4315, acc-0.8914, test loss-0.4406, acc-0.8877\n",
      "Iter-21180, train loss-0.3530, acc-0.9400, valid loss-0.4314, acc-0.8916, test loss-0.4405, acc-0.8881\n",
      "Iter-21190, train loss-0.3779, acc-0.9200, valid loss-0.4313, acc-0.8916, test loss-0.4403, acc-0.8876\n",
      "Iter-21200, train loss-0.3986, acc-0.9000, valid loss-0.4311, acc-0.8916, test loss-0.4402, acc-0.8879\n",
      "Iter-21210, train loss-0.4766, acc-0.8800, valid loss-0.4310, acc-0.8914, test loss-0.4400, acc-0.8881\n",
      "Iter-21220, train loss-0.4188, acc-0.9000, valid loss-0.4308, acc-0.8918, test loss-0.4399, acc-0.8880\n",
      "Iter-21230, train loss-0.5145, acc-0.8400, valid loss-0.4307, acc-0.8918, test loss-0.4398, acc-0.8876\n",
      "Iter-21240, train loss-0.2349, acc-0.9600, valid loss-0.4306, acc-0.8914, test loss-0.4397, acc-0.8877\n",
      "Iter-21250, train loss-0.5460, acc-0.9000, valid loss-0.4304, acc-0.8914, test loss-0.4396, acc-0.8877\n",
      "Iter-21260, train loss-0.3829, acc-0.9000, valid loss-0.4303, acc-0.8918, test loss-0.4394, acc-0.8877\n",
      "Iter-21270, train loss-0.3560, acc-0.9000, valid loss-0.4301, acc-0.8918, test loss-0.4393, acc-0.8880\n",
      "Iter-21280, train loss-0.4039, acc-0.9000, valid loss-0.4301, acc-0.8920, test loss-0.4391, acc-0.8878\n",
      "Iter-21290, train loss-0.3769, acc-0.8800, valid loss-0.4299, acc-0.8920, test loss-0.4390, acc-0.8879\n",
      "Iter-21300, train loss-0.2024, acc-1.0000, valid loss-0.4298, acc-0.8920, test loss-0.4389, acc-0.8880\n",
      "Iter-21310, train loss-0.6104, acc-0.8200, valid loss-0.4297, acc-0.8920, test loss-0.4388, acc-0.8875\n",
      "Iter-21320, train loss-0.4130, acc-0.9400, valid loss-0.4296, acc-0.8918, test loss-0.4386, acc-0.8879\n",
      "Iter-21330, train loss-0.2650, acc-0.9400, valid loss-0.4294, acc-0.8918, test loss-0.4385, acc-0.8881\n",
      "Iter-21340, train loss-0.6293, acc-0.8600, valid loss-0.4293, acc-0.8920, test loss-0.4384, acc-0.8882\n",
      "Iter-21350, train loss-0.5684, acc-0.8200, valid loss-0.4291, acc-0.8920, test loss-0.4383, acc-0.8879\n",
      "Iter-21360, train loss-0.4451, acc-0.9000, valid loss-0.4291, acc-0.8918, test loss-0.4382, acc-0.8880\n",
      "Iter-21370, train loss-0.4045, acc-0.8800, valid loss-0.4289, acc-0.8924, test loss-0.4381, acc-0.8879\n",
      "Iter-21380, train loss-0.4705, acc-0.8600, valid loss-0.4288, acc-0.8926, test loss-0.4379, acc-0.8881\n",
      "Iter-21390, train loss-0.6513, acc-0.8400, valid loss-0.4286, acc-0.8924, test loss-0.4378, acc-0.8882\n",
      "Iter-21400, train loss-0.5292, acc-0.8800, valid loss-0.4285, acc-0.8928, test loss-0.4377, acc-0.8882\n",
      "Iter-21410, train loss-0.3425, acc-0.9400, valid loss-0.4284, acc-0.8926, test loss-0.4375, acc-0.8885\n",
      "Iter-21420, train loss-0.2501, acc-0.9200, valid loss-0.4282, acc-0.8928, test loss-0.4374, acc-0.8881\n",
      "Iter-21430, train loss-0.5145, acc-0.8400, valid loss-0.4281, acc-0.8928, test loss-0.4372, acc-0.8882\n",
      "Iter-21440, train loss-0.4042, acc-0.8800, valid loss-0.4280, acc-0.8928, test loss-0.4371, acc-0.8883\n",
      "Iter-21450, train loss-0.3693, acc-0.9000, valid loss-0.4279, acc-0.8926, test loss-0.4370, acc-0.8881\n",
      "Iter-21460, train loss-0.5777, acc-0.8400, valid loss-0.4278, acc-0.8930, test loss-0.4369, acc-0.8881\n",
      "Iter-21470, train loss-0.4322, acc-0.8600, valid loss-0.4276, acc-0.8930, test loss-0.4367, acc-0.8882\n",
      "Iter-21480, train loss-0.4802, acc-0.8400, valid loss-0.4275, acc-0.8930, test loss-0.4366, acc-0.8878\n",
      "Iter-21490, train loss-0.4207, acc-0.9400, valid loss-0.4274, acc-0.8932, test loss-0.4364, acc-0.8877\n",
      "Iter-21500, train loss-0.4969, acc-0.8000, valid loss-0.4273, acc-0.8932, test loss-0.4363, acc-0.8877\n",
      "Iter-21510, train loss-0.4092, acc-0.9600, valid loss-0.4271, acc-0.8928, test loss-0.4362, acc-0.8878\n",
      "Iter-21520, train loss-0.7907, acc-0.7800, valid loss-0.4270, acc-0.8930, test loss-0.4361, acc-0.8877\n",
      "Iter-21530, train loss-0.2986, acc-0.9600, valid loss-0.4269, acc-0.8930, test loss-0.4360, acc-0.8877\n",
      "Iter-21540, train loss-0.4198, acc-0.8800, valid loss-0.4268, acc-0.8934, test loss-0.4359, acc-0.8880\n",
      "Iter-21550, train loss-0.5340, acc-0.8400, valid loss-0.4266, acc-0.8930, test loss-0.4358, acc-0.8880\n",
      "Iter-21560, train loss-0.6099, acc-0.8600, valid loss-0.4265, acc-0.8932, test loss-0.4356, acc-0.8880\n",
      "Iter-21570, train loss-0.5113, acc-0.8600, valid loss-0.4264, acc-0.8934, test loss-0.4355, acc-0.8878\n",
      "Iter-21580, train loss-0.4475, acc-0.9000, valid loss-0.4262, acc-0.8936, test loss-0.4353, acc-0.8879\n",
      "Iter-21590, train loss-0.3673, acc-0.9200, valid loss-0.4261, acc-0.8934, test loss-0.4352, acc-0.8880\n",
      "Iter-21600, train loss-0.4998, acc-0.8800, valid loss-0.4260, acc-0.8938, test loss-0.4351, acc-0.8883\n",
      "Iter-21610, train loss-0.3294, acc-0.9000, valid loss-0.4259, acc-0.8936, test loss-0.4350, acc-0.8880\n",
      "Iter-21620, train loss-0.2990, acc-0.9800, valid loss-0.4258, acc-0.8936, test loss-0.4349, acc-0.8881\n",
      "Iter-21630, train loss-0.4197, acc-0.9200, valid loss-0.4256, acc-0.8942, test loss-0.4348, acc-0.8882\n",
      "Iter-21640, train loss-0.3777, acc-0.9400, valid loss-0.4254, acc-0.8940, test loss-0.4347, acc-0.8883\n",
      "Iter-21650, train loss-0.5315, acc-0.8400, valid loss-0.4254, acc-0.8938, test loss-0.4345, acc-0.8884\n",
      "Iter-21660, train loss-0.5457, acc-0.8400, valid loss-0.4252, acc-0.8938, test loss-0.4344, acc-0.8885\n",
      "Iter-21670, train loss-0.4423, acc-0.8800, valid loss-0.4251, acc-0.8940, test loss-0.4343, acc-0.8886\n",
      "Iter-21680, train loss-0.2961, acc-0.9200, valid loss-0.4250, acc-0.8934, test loss-0.4342, acc-0.8887\n",
      "Iter-21690, train loss-0.3267, acc-0.9400, valid loss-0.4249, acc-0.8940, test loss-0.4340, acc-0.8888\n",
      "Iter-21700, train loss-0.3652, acc-0.9200, valid loss-0.4248, acc-0.8940, test loss-0.4339, acc-0.8886\n",
      "Iter-21710, train loss-0.5614, acc-0.8600, valid loss-0.4246, acc-0.8940, test loss-0.4338, acc-0.8886\n",
      "Iter-21720, train loss-0.5581, acc-0.8600, valid loss-0.4245, acc-0.8942, test loss-0.4336, acc-0.8888\n",
      "Iter-21730, train loss-0.6989, acc-0.7600, valid loss-0.4244, acc-0.8940, test loss-0.4335, acc-0.8889\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-21740, train loss-0.4866, acc-0.8800, valid loss-0.4242, acc-0.8942, test loss-0.4334, acc-0.8890\n",
      "Iter-21750, train loss-0.5170, acc-0.8200, valid loss-0.4242, acc-0.8940, test loss-0.4333, acc-0.8890\n",
      "Iter-21760, train loss-0.4514, acc-0.8800, valid loss-0.4240, acc-0.8942, test loss-0.4332, acc-0.8890\n",
      "Iter-21770, train loss-0.3765, acc-0.9000, valid loss-0.4239, acc-0.8938, test loss-0.4330, acc-0.8889\n",
      "Iter-21780, train loss-0.4558, acc-0.9200, valid loss-0.4238, acc-0.8940, test loss-0.4329, acc-0.8888\n",
      "Iter-21790, train loss-0.4111, acc-0.9400, valid loss-0.4237, acc-0.8942, test loss-0.4328, acc-0.8888\n",
      "Iter-21800, train loss-0.3864, acc-0.8800, valid loss-0.4235, acc-0.8942, test loss-0.4327, acc-0.8889\n",
      "Iter-21810, train loss-0.3999, acc-0.9000, valid loss-0.4234, acc-0.8944, test loss-0.4326, acc-0.8889\n",
      "Iter-21820, train loss-0.4470, acc-0.9400, valid loss-0.4233, acc-0.8942, test loss-0.4325, acc-0.8889\n",
      "Iter-21830, train loss-0.4201, acc-0.9000, valid loss-0.4231, acc-0.8940, test loss-0.4324, acc-0.8890\n",
      "Iter-21840, train loss-0.4833, acc-0.9200, valid loss-0.4230, acc-0.8942, test loss-0.4322, acc-0.8891\n",
      "Iter-21850, train loss-0.2690, acc-0.9200, valid loss-0.4229, acc-0.8942, test loss-0.4321, acc-0.8890\n",
      "Iter-21860, train loss-0.5305, acc-0.8000, valid loss-0.4227, acc-0.8944, test loss-0.4320, acc-0.8889\n",
      "Iter-21870, train loss-0.3453, acc-0.9400, valid loss-0.4226, acc-0.8942, test loss-0.4319, acc-0.8888\n",
      "Iter-21880, train loss-0.3723, acc-0.9600, valid loss-0.4225, acc-0.8944, test loss-0.4318, acc-0.8888\n",
      "Iter-21890, train loss-0.3641, acc-0.9200, valid loss-0.4223, acc-0.8944, test loss-0.4317, acc-0.8887\n",
      "Iter-21900, train loss-0.3815, acc-0.9400, valid loss-0.4222, acc-0.8944, test loss-0.4316, acc-0.8888\n",
      "Iter-21910, train loss-0.4940, acc-0.8400, valid loss-0.4221, acc-0.8946, test loss-0.4315, acc-0.8891\n",
      "Iter-21920, train loss-0.5488, acc-0.8200, valid loss-0.4219, acc-0.8946, test loss-0.4313, acc-0.8890\n",
      "Iter-21930, train loss-0.4288, acc-0.8600, valid loss-0.4218, acc-0.8946, test loss-0.4312, acc-0.8889\n",
      "Iter-21940, train loss-0.4547, acc-0.9200, valid loss-0.4217, acc-0.8946, test loss-0.4310, acc-0.8888\n",
      "Iter-21950, train loss-0.5664, acc-0.8600, valid loss-0.4216, acc-0.8946, test loss-0.4309, acc-0.8888\n",
      "Iter-21960, train loss-0.3713, acc-0.9000, valid loss-0.4215, acc-0.8946, test loss-0.4308, acc-0.8889\n",
      "Iter-21970, train loss-0.4377, acc-0.8600, valid loss-0.4213, acc-0.8946, test loss-0.4307, acc-0.8888\n",
      "Iter-21980, train loss-0.2807, acc-0.9600, valid loss-0.4212, acc-0.8948, test loss-0.4307, acc-0.8889\n",
      "Iter-21990, train loss-0.4162, acc-0.8600, valid loss-0.4211, acc-0.8948, test loss-0.4305, acc-0.8890\n",
      "Iter-22000, train loss-0.3880, acc-0.8200, valid loss-0.4210, acc-0.8944, test loss-0.4304, acc-0.8892\n",
      "Iter-22010, train loss-0.5031, acc-0.8400, valid loss-0.4209, acc-0.8946, test loss-0.4303, acc-0.8888\n",
      "Iter-22020, train loss-0.3925, acc-0.8800, valid loss-0.4207, acc-0.8946, test loss-0.4301, acc-0.8891\n",
      "Iter-22030, train loss-0.7068, acc-0.8000, valid loss-0.4206, acc-0.8946, test loss-0.4300, acc-0.8894\n",
      "Iter-22040, train loss-0.4418, acc-0.9000, valid loss-0.4204, acc-0.8948, test loss-0.4299, acc-0.8897\n",
      "Iter-22050, train loss-0.6322, acc-0.8600, valid loss-0.4203, acc-0.8946, test loss-0.4298, acc-0.8896\n",
      "Iter-22060, train loss-0.6378, acc-0.7800, valid loss-0.4202, acc-0.8942, test loss-0.4297, acc-0.8899\n",
      "Iter-22070, train loss-0.3002, acc-0.9600, valid loss-0.4201, acc-0.8940, test loss-0.4296, acc-0.8897\n",
      "Iter-22080, train loss-0.3516, acc-0.9400, valid loss-0.4200, acc-0.8940, test loss-0.4294, acc-0.8897\n",
      "Iter-22090, train loss-0.3472, acc-0.9400, valid loss-0.4199, acc-0.8938, test loss-0.4294, acc-0.8894\n",
      "Iter-22100, train loss-0.3505, acc-0.9400, valid loss-0.4198, acc-0.8940, test loss-0.4292, acc-0.8895\n",
      "Iter-22110, train loss-0.5598, acc-0.8200, valid loss-0.4197, acc-0.8940, test loss-0.4291, acc-0.8895\n",
      "Iter-22120, train loss-0.5549, acc-0.8400, valid loss-0.4196, acc-0.8942, test loss-0.4290, acc-0.8893\n",
      "Iter-22130, train loss-0.5738, acc-0.8200, valid loss-0.4194, acc-0.8940, test loss-0.4289, acc-0.8897\n",
      "Iter-22140, train loss-0.4425, acc-0.8800, valid loss-0.4193, acc-0.8942, test loss-0.4288, acc-0.8897\n",
      "Iter-22150, train loss-0.4616, acc-0.9000, valid loss-0.4192, acc-0.8942, test loss-0.4287, acc-0.8895\n",
      "Iter-22160, train loss-0.4827, acc-0.8800, valid loss-0.4190, acc-0.8944, test loss-0.4285, acc-0.8894\n",
      "Iter-22170, train loss-0.4855, acc-0.8400, valid loss-0.4189, acc-0.8942, test loss-0.4284, acc-0.8895\n",
      "Iter-22180, train loss-0.3615, acc-0.9400, valid loss-0.4188, acc-0.8944, test loss-0.4283, acc-0.8897\n",
      "Iter-22190, train loss-0.4093, acc-0.8600, valid loss-0.4187, acc-0.8942, test loss-0.4282, acc-0.8895\n",
      "Iter-22200, train loss-0.3885, acc-0.8800, valid loss-0.4186, acc-0.8946, test loss-0.4281, acc-0.8897\n",
      "Iter-22210, train loss-0.3729, acc-0.8800, valid loss-0.4184, acc-0.8946, test loss-0.4280, acc-0.8897\n",
      "Iter-22220, train loss-0.4359, acc-0.8600, valid loss-0.4183, acc-0.8946, test loss-0.4278, acc-0.8897\n",
      "Iter-22230, train loss-0.2994, acc-0.9400, valid loss-0.4182, acc-0.8950, test loss-0.4277, acc-0.8899\n",
      "Iter-22240, train loss-0.3274, acc-0.9000, valid loss-0.4181, acc-0.8948, test loss-0.4276, acc-0.8899\n",
      "Iter-22250, train loss-0.2980, acc-0.9400, valid loss-0.4181, acc-0.8948, test loss-0.4275, acc-0.8895\n",
      "Iter-22260, train loss-0.3663, acc-0.9400, valid loss-0.4180, acc-0.8948, test loss-0.4274, acc-0.8898\n",
      "Iter-22270, train loss-0.4702, acc-0.8200, valid loss-0.4178, acc-0.8948, test loss-0.4273, acc-0.8895\n",
      "Iter-22280, train loss-0.5902, acc-0.8600, valid loss-0.4177, acc-0.8950, test loss-0.4272, acc-0.8898\n",
      "Iter-22290, train loss-0.4924, acc-0.8400, valid loss-0.4176, acc-0.8952, test loss-0.4271, acc-0.8899\n",
      "Iter-22300, train loss-0.4702, acc-0.9000, valid loss-0.4174, acc-0.8956, test loss-0.4270, acc-0.8898\n",
      "Iter-22310, train loss-0.6082, acc-0.8400, valid loss-0.4174, acc-0.8958, test loss-0.4268, acc-0.8903\n",
      "Iter-22320, train loss-0.3577, acc-0.9200, valid loss-0.4172, acc-0.8956, test loss-0.4267, acc-0.8900\n",
      "Iter-22330, train loss-0.3377, acc-0.9400, valid loss-0.4172, acc-0.8958, test loss-0.4266, acc-0.8900\n",
      "Iter-22340, train loss-0.3622, acc-0.9000, valid loss-0.4170, acc-0.8958, test loss-0.4264, acc-0.8899\n",
      "Iter-22350, train loss-0.4279, acc-0.9000, valid loss-0.4169, acc-0.8954, test loss-0.4263, acc-0.8901\n",
      "Iter-22360, train loss-0.3788, acc-0.9400, valid loss-0.4168, acc-0.8954, test loss-0.4262, acc-0.8902\n",
      "Iter-22370, train loss-0.2942, acc-0.9400, valid loss-0.4168, acc-0.8954, test loss-0.4260, acc-0.8898\n",
      "Iter-22380, train loss-0.3099, acc-0.9200, valid loss-0.4167, acc-0.8956, test loss-0.4260, acc-0.8902\n",
      "Iter-22390, train loss-0.2792, acc-0.9600, valid loss-0.4166, acc-0.8956, test loss-0.4259, acc-0.8901\n",
      "Iter-22400, train loss-0.4449, acc-0.8800, valid loss-0.4165, acc-0.8952, test loss-0.4258, acc-0.8900\n",
      "Iter-22410, train loss-0.4954, acc-0.8800, valid loss-0.4164, acc-0.8956, test loss-0.4257, acc-0.8901\n",
      "Iter-22420, train loss-0.4835, acc-0.8800, valid loss-0.4163, acc-0.8956, test loss-0.4256, acc-0.8901\n",
      "Iter-22430, train loss-0.6627, acc-0.7800, valid loss-0.4162, acc-0.8956, test loss-0.4255, acc-0.8903\n",
      "Iter-22440, train loss-0.7434, acc-0.7800, valid loss-0.4161, acc-0.8956, test loss-0.4254, acc-0.8901\n",
      "Iter-22450, train loss-0.4514, acc-0.8800, valid loss-0.4159, acc-0.8954, test loss-0.4252, acc-0.8902\n",
      "Iter-22460, train loss-0.5365, acc-0.8400, valid loss-0.4158, acc-0.8954, test loss-0.4251, acc-0.8902\n",
      "Iter-22470, train loss-0.4110, acc-0.8800, valid loss-0.4158, acc-0.8954, test loss-0.4250, acc-0.8898\n",
      "Iter-22480, train loss-0.4240, acc-0.8800, valid loss-0.4157, acc-0.8952, test loss-0.4249, acc-0.8902\n",
      "Iter-22490, train loss-0.5202, acc-0.9000, valid loss-0.4156, acc-0.8952, test loss-0.4248, acc-0.8902\n",
      "Iter-22500, train loss-0.3938, acc-0.9200, valid loss-0.4155, acc-0.8952, test loss-0.4247, acc-0.8900\n",
      "Iter-22510, train loss-0.5915, acc-0.8600, valid loss-0.4154, acc-0.8950, test loss-0.4246, acc-0.8902\n",
      "Iter-22520, train loss-0.4038, acc-0.9200, valid loss-0.4152, acc-0.8958, test loss-0.4245, acc-0.8904\n",
      "Iter-22530, train loss-0.3616, acc-0.9400, valid loss-0.4152, acc-0.8956, test loss-0.4244, acc-0.8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-22540, train loss-0.3555, acc-0.9000, valid loss-0.4151, acc-0.8958, test loss-0.4242, acc-0.8905\n",
      "Iter-22550, train loss-0.5485, acc-0.8200, valid loss-0.4149, acc-0.8956, test loss-0.4242, acc-0.8903\n",
      "Iter-22560, train loss-0.4097, acc-0.8800, valid loss-0.4148, acc-0.8956, test loss-0.4241, acc-0.8905\n",
      "Iter-22570, train loss-0.4593, acc-0.8200, valid loss-0.4147, acc-0.8960, test loss-0.4240, acc-0.8905\n",
      "Iter-22580, train loss-0.5195, acc-0.8800, valid loss-0.4146, acc-0.8960, test loss-0.4239, acc-0.8908\n",
      "Iter-22590, train loss-0.2509, acc-0.9800, valid loss-0.4146, acc-0.8960, test loss-0.4238, acc-0.8908\n",
      "Iter-22600, train loss-0.6084, acc-0.8400, valid loss-0.4144, acc-0.8960, test loss-0.4236, acc-0.8909\n",
      "Iter-22610, train loss-0.4141, acc-0.8600, valid loss-0.4143, acc-0.8960, test loss-0.4236, acc-0.8908\n",
      "Iter-22620, train loss-0.5049, acc-0.9000, valid loss-0.4142, acc-0.8962, test loss-0.4234, acc-0.8909\n",
      "Iter-22630, train loss-0.5213, acc-0.8600, valid loss-0.4141, acc-0.8960, test loss-0.4233, acc-0.8909\n",
      "Iter-22640, train loss-0.4850, acc-0.9000, valid loss-0.4139, acc-0.8960, test loss-0.4232, acc-0.8909\n",
      "Iter-22650, train loss-0.5005, acc-0.8800, valid loss-0.4138, acc-0.8962, test loss-0.4230, acc-0.8909\n",
      "Iter-22660, train loss-0.4212, acc-0.9200, valid loss-0.4136, acc-0.8962, test loss-0.4230, acc-0.8908\n",
      "Iter-22670, train loss-0.4344, acc-0.8600, valid loss-0.4135, acc-0.8960, test loss-0.4228, acc-0.8909\n",
      "Iter-22680, train loss-0.3320, acc-0.9400, valid loss-0.4134, acc-0.8960, test loss-0.4227, acc-0.8906\n",
      "Iter-22690, train loss-0.4899, acc-0.8800, valid loss-0.4133, acc-0.8964, test loss-0.4226, acc-0.8908\n",
      "Iter-22700, train loss-0.4650, acc-0.9000, valid loss-0.4131, acc-0.8962, test loss-0.4225, acc-0.8910\n",
      "Iter-22710, train loss-0.6467, acc-0.7800, valid loss-0.4130, acc-0.8952, test loss-0.4223, acc-0.8907\n",
      "Iter-22720, train loss-0.5750, acc-0.8600, valid loss-0.4129, acc-0.8956, test loss-0.4222, acc-0.8907\n",
      "Iter-22730, train loss-0.5667, acc-0.8200, valid loss-0.4127, acc-0.8962, test loss-0.4221, acc-0.8908\n",
      "Iter-22740, train loss-0.3204, acc-0.9400, valid loss-0.4126, acc-0.8962, test loss-0.4220, acc-0.8908\n",
      "Iter-22750, train loss-0.4169, acc-0.8400, valid loss-0.4125, acc-0.8960, test loss-0.4218, acc-0.8909\n",
      "Iter-22760, train loss-0.4396, acc-0.8800, valid loss-0.4124, acc-0.8964, test loss-0.4217, acc-0.8910\n",
      "Iter-22770, train loss-0.2446, acc-0.9600, valid loss-0.4123, acc-0.8962, test loss-0.4216, acc-0.8910\n",
      "Iter-22780, train loss-0.4373, acc-0.9200, valid loss-0.4122, acc-0.8962, test loss-0.4215, acc-0.8908\n",
      "Iter-22790, train loss-0.4086, acc-0.9000, valid loss-0.4121, acc-0.8962, test loss-0.4213, acc-0.8907\n",
      "Iter-22800, train loss-0.3218, acc-0.9200, valid loss-0.4120, acc-0.8960, test loss-0.4212, acc-0.8907\n",
      "Iter-22810, train loss-0.3912, acc-0.8800, valid loss-0.4119, acc-0.8960, test loss-0.4211, acc-0.8909\n",
      "Iter-22820, train loss-0.4302, acc-0.9000, valid loss-0.4118, acc-0.8960, test loss-0.4210, acc-0.8910\n",
      "Iter-22830, train loss-0.3045, acc-0.9400, valid loss-0.4117, acc-0.8960, test loss-0.4209, acc-0.8910\n",
      "Iter-22840, train loss-0.4288, acc-0.8600, valid loss-0.4116, acc-0.8958, test loss-0.4209, acc-0.8910\n",
      "Iter-22850, train loss-0.4050, acc-0.8800, valid loss-0.4114, acc-0.8962, test loss-0.4207, acc-0.8910\n",
      "Iter-22860, train loss-0.3510, acc-0.9200, valid loss-0.4113, acc-0.8964, test loss-0.4207, acc-0.8909\n",
      "Iter-22870, train loss-0.3362, acc-0.9200, valid loss-0.4111, acc-0.8966, test loss-0.4205, acc-0.8909\n",
      "Iter-22880, train loss-0.5124, acc-0.8200, valid loss-0.4111, acc-0.8964, test loss-0.4205, acc-0.8908\n",
      "Iter-22890, train loss-0.5317, acc-0.8800, valid loss-0.4110, acc-0.8962, test loss-0.4203, acc-0.8908\n",
      "Iter-22900, train loss-0.3005, acc-0.9400, valid loss-0.4109, acc-0.8962, test loss-0.4202, acc-0.8910\n",
      "Iter-22910, train loss-0.3575, acc-0.9000, valid loss-0.4108, acc-0.8966, test loss-0.4201, acc-0.8907\n",
      "Iter-22920, train loss-0.4735, acc-0.8600, valid loss-0.4107, acc-0.8964, test loss-0.4200, acc-0.8909\n",
      "Iter-22930, train loss-0.3944, acc-0.9200, valid loss-0.4105, acc-0.8966, test loss-0.4198, acc-0.8909\n",
      "Iter-22940, train loss-0.4199, acc-0.9000, valid loss-0.4104, acc-0.8968, test loss-0.4197, acc-0.8909\n",
      "Iter-22950, train loss-0.3731, acc-0.9200, valid loss-0.4103, acc-0.8968, test loss-0.4195, acc-0.8910\n",
      "Iter-22960, train loss-0.4306, acc-0.8800, valid loss-0.4102, acc-0.8968, test loss-0.4195, acc-0.8912\n",
      "Iter-22970, train loss-0.3869, acc-0.9000, valid loss-0.4101, acc-0.8968, test loss-0.4194, acc-0.8912\n",
      "Iter-22980, train loss-0.5421, acc-0.8600, valid loss-0.4100, acc-0.8970, test loss-0.4193, acc-0.8911\n",
      "Iter-22990, train loss-0.3787, acc-0.9400, valid loss-0.4099, acc-0.8970, test loss-0.4192, acc-0.8911\n",
      "Iter-23000, train loss-0.5214, acc-0.8600, valid loss-0.4098, acc-0.8968, test loss-0.4191, acc-0.8912\n",
      "Iter-23010, train loss-0.3177, acc-0.9600, valid loss-0.4097, acc-0.8970, test loss-0.4190, acc-0.8911\n",
      "Iter-23020, train loss-0.6170, acc-0.7600, valid loss-0.4096, acc-0.8968, test loss-0.4189, acc-0.8911\n",
      "Iter-23030, train loss-0.5651, acc-0.8400, valid loss-0.4095, acc-0.8968, test loss-0.4187, acc-0.8910\n",
      "Iter-23040, train loss-0.5195, acc-0.8400, valid loss-0.4094, acc-0.8966, test loss-0.4186, acc-0.8914\n",
      "Iter-23050, train loss-0.3637, acc-0.9000, valid loss-0.4092, acc-0.8974, test loss-0.4185, acc-0.8914\n",
      "Iter-23060, train loss-0.4426, acc-0.8800, valid loss-0.4091, acc-0.8972, test loss-0.4184, acc-0.8914\n",
      "Iter-23070, train loss-0.3686, acc-0.9200, valid loss-0.4090, acc-0.8974, test loss-0.4183, acc-0.8915\n",
      "Iter-23080, train loss-0.5224, acc-0.8200, valid loss-0.4090, acc-0.8976, test loss-0.4181, acc-0.8914\n",
      "Iter-23090, train loss-0.4407, acc-0.8800, valid loss-0.4088, acc-0.8976, test loss-0.4180, acc-0.8914\n",
      "Iter-23100, train loss-0.2735, acc-0.9400, valid loss-0.4087, acc-0.8978, test loss-0.4180, acc-0.8915\n",
      "Iter-23110, train loss-0.5964, acc-0.8800, valid loss-0.4086, acc-0.8976, test loss-0.4179, acc-0.8916\n",
      "Iter-23120, train loss-0.3797, acc-0.9000, valid loss-0.4084, acc-0.8978, test loss-0.4178, acc-0.8918\n",
      "Iter-23130, train loss-0.2994, acc-0.9200, valid loss-0.4083, acc-0.8980, test loss-0.4177, acc-0.8916\n",
      "Iter-23140, train loss-0.5210, acc-0.8600, valid loss-0.4082, acc-0.8980, test loss-0.4176, acc-0.8915\n",
      "Iter-23150, train loss-0.4442, acc-0.8800, valid loss-0.4081, acc-0.8980, test loss-0.4175, acc-0.8914\n",
      "Iter-23160, train loss-0.3375, acc-0.9200, valid loss-0.4080, acc-0.8978, test loss-0.4174, acc-0.8916\n",
      "Iter-23170, train loss-0.4826, acc-0.8200, valid loss-0.4079, acc-0.8982, test loss-0.4173, acc-0.8918\n",
      "Iter-23180, train loss-0.5886, acc-0.8400, valid loss-0.4078, acc-0.8984, test loss-0.4172, acc-0.8918\n",
      "Iter-23190, train loss-0.3321, acc-0.9000, valid loss-0.4077, acc-0.8982, test loss-0.4171, acc-0.8915\n",
      "Iter-23200, train loss-0.4163, acc-0.8800, valid loss-0.4075, acc-0.8982, test loss-0.4169, acc-0.8914\n",
      "Iter-23210, train loss-0.4571, acc-0.8800, valid loss-0.4074, acc-0.8984, test loss-0.4168, acc-0.8918\n",
      "Iter-23220, train loss-0.3502, acc-0.9200, valid loss-0.4073, acc-0.8984, test loss-0.4167, acc-0.8917\n",
      "Iter-23230, train loss-0.5173, acc-0.8400, valid loss-0.4072, acc-0.8986, test loss-0.4166, acc-0.8915\n",
      "Iter-23240, train loss-0.3691, acc-0.9000, valid loss-0.4071, acc-0.8986, test loss-0.4165, acc-0.8918\n",
      "Iter-23250, train loss-0.3639, acc-0.9000, valid loss-0.4070, acc-0.8990, test loss-0.4163, acc-0.8918\n",
      "Iter-23260, train loss-0.4392, acc-0.9000, valid loss-0.4069, acc-0.8986, test loss-0.4162, acc-0.8917\n",
      "Iter-23270, train loss-0.2479, acc-0.9800, valid loss-0.4068, acc-0.8990, test loss-0.4161, acc-0.8915\n",
      "Iter-23280, train loss-0.5371, acc-0.8600, valid loss-0.4067, acc-0.8988, test loss-0.4161, acc-0.8916\n",
      "Iter-23290, train loss-0.3701, acc-0.8800, valid loss-0.4065, acc-0.8990, test loss-0.4159, acc-0.8913\n",
      "Iter-23300, train loss-0.3928, acc-0.8600, valid loss-0.4065, acc-0.8988, test loss-0.4159, acc-0.8912\n",
      "Iter-23310, train loss-0.6235, acc-0.8200, valid loss-0.4064, acc-0.8990, test loss-0.4158, acc-0.8912\n",
      "Iter-23320, train loss-0.4211, acc-0.8200, valid loss-0.4063, acc-0.8988, test loss-0.4157, acc-0.8914\n",
      "Iter-23330, train loss-0.4869, acc-0.8200, valid loss-0.4062, acc-0.8992, test loss-0.4156, acc-0.8915\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-23340, train loss-0.4865, acc-0.8800, valid loss-0.4061, acc-0.8990, test loss-0.4155, acc-0.8916\n",
      "Iter-23350, train loss-0.4042, acc-0.8800, valid loss-0.4060, acc-0.8992, test loss-0.4154, acc-0.8916\n",
      "Iter-23360, train loss-0.3872, acc-0.9000, valid loss-0.4059, acc-0.8998, test loss-0.4153, acc-0.8918\n",
      "Iter-23370, train loss-0.3443, acc-0.9200, valid loss-0.4058, acc-0.8992, test loss-0.4152, acc-0.8918\n",
      "Iter-23380, train loss-0.5032, acc-0.8800, valid loss-0.4057, acc-0.8990, test loss-0.4151, acc-0.8919\n",
      "Iter-23390, train loss-0.4338, acc-0.9000, valid loss-0.4056, acc-0.8998, test loss-0.4150, acc-0.8920\n",
      "Iter-23400, train loss-0.3631, acc-0.9400, valid loss-0.4055, acc-0.8996, test loss-0.4149, acc-0.8917\n",
      "Iter-23410, train loss-0.3218, acc-0.9200, valid loss-0.4054, acc-0.8998, test loss-0.4148, acc-0.8917\n",
      "Iter-23420, train loss-0.4665, acc-0.9000, valid loss-0.4053, acc-0.9000, test loss-0.4147, acc-0.8919\n",
      "Iter-23430, train loss-0.3466, acc-0.9400, valid loss-0.4052, acc-0.9000, test loss-0.4146, acc-0.8919\n",
      "Iter-23440, train loss-0.4489, acc-0.9000, valid loss-0.4051, acc-0.8994, test loss-0.4145, acc-0.8920\n",
      "Iter-23450, train loss-0.4104, acc-0.8600, valid loss-0.4049, acc-0.8994, test loss-0.4144, acc-0.8918\n",
      "Iter-23460, train loss-0.4711, acc-0.8200, valid loss-0.4048, acc-0.8994, test loss-0.4143, acc-0.8922\n",
      "Iter-23470, train loss-0.3836, acc-0.9000, valid loss-0.4047, acc-0.8998, test loss-0.4142, acc-0.8920\n",
      "Iter-23480, train loss-0.4558, acc-0.9000, valid loss-0.4046, acc-0.9000, test loss-0.4142, acc-0.8918\n",
      "Iter-23490, train loss-0.4590, acc-0.8600, valid loss-0.4045, acc-0.9000, test loss-0.4140, acc-0.8920\n",
      "Iter-23500, train loss-0.5308, acc-0.8600, valid loss-0.4044, acc-0.9002, test loss-0.4139, acc-0.8923\n",
      "Iter-23510, train loss-0.5942, acc-0.7600, valid loss-0.4043, acc-0.9002, test loss-0.4139, acc-0.8918\n",
      "Iter-23520, train loss-0.4870, acc-0.8600, valid loss-0.4043, acc-0.9004, test loss-0.4138, acc-0.8922\n",
      "Iter-23530, train loss-0.2575, acc-0.9600, valid loss-0.4042, acc-0.9004, test loss-0.4137, acc-0.8921\n",
      "Iter-23540, train loss-0.5037, acc-0.8600, valid loss-0.4041, acc-0.9004, test loss-0.4136, acc-0.8920\n",
      "Iter-23550, train loss-0.3064, acc-0.9200, valid loss-0.4039, acc-0.9004, test loss-0.4135, acc-0.8922\n",
      "Iter-23560, train loss-0.5172, acc-0.8000, valid loss-0.4038, acc-0.9000, test loss-0.4134, acc-0.8922\n",
      "Iter-23570, train loss-0.5681, acc-0.8600, valid loss-0.4036, acc-0.9004, test loss-0.4134, acc-0.8923\n",
      "Iter-23580, train loss-0.3068, acc-0.9200, valid loss-0.4035, acc-0.9004, test loss-0.4133, acc-0.8925\n",
      "Iter-23590, train loss-0.3557, acc-0.9200, valid loss-0.4034, acc-0.9008, test loss-0.4132, acc-0.8925\n",
      "Iter-23600, train loss-0.4731, acc-0.9000, valid loss-0.4033, acc-0.9008, test loss-0.4131, acc-0.8925\n",
      "Iter-23610, train loss-0.2809, acc-0.9600, valid loss-0.4032, acc-0.9010, test loss-0.4130, acc-0.8923\n",
      "Iter-23620, train loss-0.3955, acc-0.9000, valid loss-0.4031, acc-0.9010, test loss-0.4129, acc-0.8922\n",
      "Iter-23630, train loss-0.4627, acc-0.8800, valid loss-0.4030, acc-0.9010, test loss-0.4128, acc-0.8923\n",
      "Iter-23640, train loss-0.4889, acc-0.8200, valid loss-0.4029, acc-0.9010, test loss-0.4127, acc-0.8921\n",
      "Iter-23650, train loss-0.3621, acc-0.9400, valid loss-0.4028, acc-0.9010, test loss-0.4126, acc-0.8922\n",
      "Iter-23660, train loss-0.5651, acc-0.8000, valid loss-0.4027, acc-0.9012, test loss-0.4125, acc-0.8920\n",
      "Iter-23670, train loss-0.5307, acc-0.8400, valid loss-0.4026, acc-0.9012, test loss-0.4124, acc-0.8921\n",
      "Iter-23680, train loss-0.2055, acc-1.0000, valid loss-0.4025, acc-0.9012, test loss-0.4123, acc-0.8923\n",
      "Iter-23690, train loss-0.3675, acc-0.9400, valid loss-0.4024, acc-0.9010, test loss-0.4122, acc-0.8926\n",
      "Iter-23700, train loss-0.4349, acc-0.8800, valid loss-0.4022, acc-0.9008, test loss-0.4121, acc-0.8921\n",
      "Iter-23710, train loss-0.3963, acc-0.9000, valid loss-0.4021, acc-0.9010, test loss-0.4121, acc-0.8923\n",
      "Iter-23720, train loss-0.4013, acc-0.8400, valid loss-0.4020, acc-0.9008, test loss-0.4120, acc-0.8924\n",
      "Iter-23730, train loss-0.4215, acc-0.9000, valid loss-0.4018, acc-0.9004, test loss-0.4120, acc-0.8925\n",
      "Iter-23740, train loss-0.4031, acc-0.9200, valid loss-0.4017, acc-0.9004, test loss-0.4118, acc-0.8927\n",
      "Iter-23750, train loss-0.3791, acc-0.8600, valid loss-0.4015, acc-0.9006, test loss-0.4117, acc-0.8925\n",
      "Iter-23760, train loss-0.3870, acc-0.9000, valid loss-0.4014, acc-0.9004, test loss-0.4116, acc-0.8924\n",
      "Iter-23770, train loss-0.6510, acc-0.8800, valid loss-0.4012, acc-0.9006, test loss-0.4116, acc-0.8925\n",
      "Iter-23780, train loss-0.4150, acc-0.9200, valid loss-0.4012, acc-0.9006, test loss-0.4115, acc-0.8926\n",
      "Iter-23790, train loss-0.3808, acc-0.9200, valid loss-0.4010, acc-0.9010, test loss-0.4114, acc-0.8925\n",
      "Iter-23800, train loss-0.3652, acc-0.8800, valid loss-0.4009, acc-0.9008, test loss-0.4113, acc-0.8926\n",
      "Iter-23810, train loss-0.3087, acc-0.9200, valid loss-0.4008, acc-0.9004, test loss-0.4112, acc-0.8924\n",
      "Iter-23820, train loss-0.5261, acc-0.8400, valid loss-0.4007, acc-0.9002, test loss-0.4111, acc-0.8926\n",
      "Iter-23830, train loss-0.6497, acc-0.8000, valid loss-0.4006, acc-0.9004, test loss-0.4110, acc-0.8929\n",
      "Iter-23840, train loss-0.3940, acc-0.8800, valid loss-0.4005, acc-0.9004, test loss-0.4110, acc-0.8928\n",
      "Iter-23850, train loss-0.4721, acc-0.8600, valid loss-0.4004, acc-0.9008, test loss-0.4109, acc-0.8926\n",
      "Iter-23860, train loss-0.4473, acc-0.9200, valid loss-0.4003, acc-0.9012, test loss-0.4107, acc-0.8927\n",
      "Iter-23870, train loss-0.1977, acc-0.9800, valid loss-0.4002, acc-0.9016, test loss-0.4106, acc-0.8926\n",
      "Iter-23880, train loss-0.6133, acc-0.7400, valid loss-0.4001, acc-0.9016, test loss-0.4106, acc-0.8926\n",
      "Iter-23890, train loss-0.4371, acc-0.8600, valid loss-0.4000, acc-0.9012, test loss-0.4104, acc-0.8926\n",
      "Iter-23900, train loss-0.4749, acc-0.9200, valid loss-0.3999, acc-0.9010, test loss-0.4103, acc-0.8925\n",
      "Iter-23910, train loss-0.2658, acc-0.9600, valid loss-0.3999, acc-0.9008, test loss-0.4102, acc-0.8929\n",
      "Iter-23920, train loss-0.4737, acc-0.8800, valid loss-0.3997, acc-0.9014, test loss-0.4101, acc-0.8930\n",
      "Iter-23930, train loss-0.4008, acc-0.9000, valid loss-0.3996, acc-0.9008, test loss-0.4100, acc-0.8928\n",
      "Iter-23940, train loss-0.3682, acc-0.9000, valid loss-0.3995, acc-0.9010, test loss-0.4099, acc-0.8932\n",
      "Iter-23950, train loss-0.5161, acc-0.8600, valid loss-0.3994, acc-0.9014, test loss-0.4098, acc-0.8932\n",
      "Iter-23960, train loss-0.1836, acc-0.9800, valid loss-0.3993, acc-0.9014, test loss-0.4097, acc-0.8935\n",
      "Iter-23970, train loss-0.3417, acc-0.9000, valid loss-0.3993, acc-0.9016, test loss-0.4096, acc-0.8936\n",
      "Iter-23980, train loss-0.5153, acc-0.8600, valid loss-0.3992, acc-0.9014, test loss-0.4095, acc-0.8931\n",
      "Iter-23990, train loss-0.4261, acc-0.8600, valid loss-0.3990, acc-0.9020, test loss-0.4094, acc-0.8933\n",
      "Iter-24000, train loss-0.4466, acc-0.9000, valid loss-0.3990, acc-0.9014, test loss-0.4094, acc-0.8931\n",
      "Iter-24010, train loss-0.2908, acc-0.9200, valid loss-0.3989, acc-0.9014, test loss-0.4093, acc-0.8934\n",
      "Iter-24020, train loss-0.5546, acc-0.8600, valid loss-0.3988, acc-0.9016, test loss-0.4092, acc-0.8930\n",
      "Iter-24030, train loss-0.3879, acc-0.8800, valid loss-0.3987, acc-0.9014, test loss-0.4091, acc-0.8930\n",
      "Iter-24040, train loss-0.2786, acc-0.9800, valid loss-0.3986, acc-0.9016, test loss-0.4090, acc-0.8930\n",
      "Iter-24050, train loss-0.2568, acc-0.9600, valid loss-0.3986, acc-0.9018, test loss-0.4090, acc-0.8931\n",
      "Iter-24060, train loss-0.3054, acc-0.9400, valid loss-0.3985, acc-0.9018, test loss-0.4089, acc-0.8932\n",
      "Iter-24070, train loss-0.2088, acc-0.9800, valid loss-0.3984, acc-0.9016, test loss-0.4088, acc-0.8932\n",
      "Iter-24080, train loss-0.5144, acc-0.8400, valid loss-0.3983, acc-0.9014, test loss-0.4087, acc-0.8932\n",
      "Iter-24090, train loss-0.4259, acc-0.8800, valid loss-0.3982, acc-0.9014, test loss-0.4086, acc-0.8933\n",
      "Iter-24100, train loss-0.5175, acc-0.8800, valid loss-0.3982, acc-0.9014, test loss-0.4085, acc-0.8933\n",
      "Iter-24110, train loss-0.7531, acc-0.7800, valid loss-0.3980, acc-0.9014, test loss-0.4084, acc-0.8932\n",
      "Iter-24120, train loss-0.2694, acc-0.9800, valid loss-0.3980, acc-0.9014, test loss-0.4083, acc-0.8933\n",
      "Iter-24130, train loss-0.4858, acc-0.8400, valid loss-0.3979, acc-0.9016, test loss-0.4082, acc-0.8936\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24140, train loss-0.2417, acc-0.9600, valid loss-0.3978, acc-0.9014, test loss-0.4081, acc-0.8937\n",
      "Iter-24150, train loss-0.5420, acc-0.8400, valid loss-0.3977, acc-0.9012, test loss-0.4080, acc-0.8937\n",
      "Iter-24160, train loss-0.5044, acc-0.8400, valid loss-0.3975, acc-0.9018, test loss-0.4079, acc-0.8936\n",
      "Iter-24170, train loss-0.4283, acc-0.8600, valid loss-0.3975, acc-0.9014, test loss-0.4078, acc-0.8937\n",
      "Iter-24180, train loss-0.3757, acc-0.9200, valid loss-0.3973, acc-0.9018, test loss-0.4077, acc-0.8939\n",
      "Iter-24190, train loss-0.4212, acc-0.9000, valid loss-0.3972, acc-0.9018, test loss-0.4075, acc-0.8940\n",
      "Iter-24200, train loss-0.3543, acc-0.9400, valid loss-0.3971, acc-0.9018, test loss-0.4074, acc-0.8938\n",
      "Iter-24210, train loss-0.3412, acc-0.8800, valid loss-0.3971, acc-0.9016, test loss-0.4073, acc-0.8938\n",
      "Iter-24220, train loss-0.3276, acc-0.9400, valid loss-0.3970, acc-0.9016, test loss-0.4072, acc-0.8939\n",
      "Iter-24230, train loss-0.2867, acc-0.9400, valid loss-0.3969, acc-0.9016, test loss-0.4071, acc-0.8939\n",
      "Iter-24240, train loss-0.4916, acc-0.8400, valid loss-0.3968, acc-0.9016, test loss-0.4070, acc-0.8940\n",
      "Iter-24250, train loss-0.5084, acc-0.8400, valid loss-0.3967, acc-0.9018, test loss-0.4069, acc-0.8935\n",
      "Iter-24260, train loss-0.4628, acc-0.8600, valid loss-0.3966, acc-0.9016, test loss-0.4069, acc-0.8935\n",
      "Iter-24270, train loss-0.4758, acc-0.9000, valid loss-0.3965, acc-0.9018, test loss-0.4068, acc-0.8936\n",
      "Iter-24280, train loss-0.5562, acc-0.8400, valid loss-0.3964, acc-0.9016, test loss-0.4067, acc-0.8937\n",
      "Iter-24290, train loss-0.4758, acc-0.8600, valid loss-0.3962, acc-0.9018, test loss-0.4065, acc-0.8941\n",
      "Iter-24300, train loss-0.5495, acc-0.9000, valid loss-0.3962, acc-0.9016, test loss-0.4065, acc-0.8938\n",
      "Iter-24310, train loss-0.6654, acc-0.8200, valid loss-0.3961, acc-0.9020, test loss-0.4064, acc-0.8941\n",
      "Iter-24320, train loss-0.5926, acc-0.8400, valid loss-0.3960, acc-0.9022, test loss-0.4063, acc-0.8941\n",
      "Iter-24330, train loss-0.3623, acc-0.9000, valid loss-0.3959, acc-0.9024, test loss-0.4063, acc-0.8941\n",
      "Iter-24340, train loss-0.3340, acc-0.9400, valid loss-0.3958, acc-0.9022, test loss-0.4062, acc-0.8940\n",
      "Iter-24350, train loss-0.4174, acc-0.9000, valid loss-0.3957, acc-0.9024, test loss-0.4060, acc-0.8940\n",
      "Iter-24360, train loss-0.3653, acc-0.9000, valid loss-0.3956, acc-0.9024, test loss-0.4059, acc-0.8939\n",
      "Iter-24370, train loss-0.2991, acc-0.9400, valid loss-0.3955, acc-0.9026, test loss-0.4059, acc-0.8939\n",
      "Iter-24380, train loss-0.4357, acc-0.8800, valid loss-0.3953, acc-0.9024, test loss-0.4058, acc-0.8940\n",
      "Iter-24390, train loss-0.3070, acc-0.9200, valid loss-0.3952, acc-0.9024, test loss-0.4057, acc-0.8942\n",
      "Iter-24400, train loss-0.3609, acc-0.9000, valid loss-0.3951, acc-0.9022, test loss-0.4056, acc-0.8941\n",
      "Iter-24410, train loss-0.4542, acc-0.8800, valid loss-0.3951, acc-0.9020, test loss-0.4056, acc-0.8938\n",
      "Iter-24420, train loss-0.3735, acc-0.8200, valid loss-0.3950, acc-0.9020, test loss-0.4055, acc-0.8941\n",
      "Iter-24430, train loss-0.3464, acc-0.9200, valid loss-0.3949, acc-0.9022, test loss-0.4053, acc-0.8941\n",
      "Iter-24440, train loss-0.2251, acc-0.9600, valid loss-0.3948, acc-0.9020, test loss-0.4052, acc-0.8940\n",
      "Iter-24450, train loss-0.3936, acc-0.8800, valid loss-0.3948, acc-0.9020, test loss-0.4051, acc-0.8942\n",
      "Iter-24460, train loss-0.4568, acc-0.8600, valid loss-0.3947, acc-0.9024, test loss-0.4050, acc-0.8941\n",
      "Iter-24470, train loss-0.2983, acc-0.9600, valid loss-0.3946, acc-0.9022, test loss-0.4049, acc-0.8941\n",
      "Iter-24480, train loss-0.4581, acc-0.8200, valid loss-0.3945, acc-0.9022, test loss-0.4048, acc-0.8942\n",
      "Iter-24490, train loss-0.4330, acc-0.8800, valid loss-0.3944, acc-0.9022, test loss-0.4046, acc-0.8939\n",
      "Iter-24500, train loss-0.4747, acc-0.8800, valid loss-0.3943, acc-0.9024, test loss-0.4045, acc-0.8941\n",
      "Iter-24510, train loss-0.3578, acc-0.9000, valid loss-0.3942, acc-0.9020, test loss-0.4044, acc-0.8941\n",
      "Iter-24520, train loss-0.5651, acc-0.8400, valid loss-0.3941, acc-0.9022, test loss-0.4043, acc-0.8940\n",
      "Iter-24530, train loss-0.3377, acc-0.9200, valid loss-0.3940, acc-0.9026, test loss-0.4042, acc-0.8942\n",
      "Iter-24540, train loss-0.5152, acc-0.8800, valid loss-0.3939, acc-0.9024, test loss-0.4042, acc-0.8943\n",
      "Iter-24550, train loss-0.5540, acc-0.8400, valid loss-0.3938, acc-0.9022, test loss-0.4040, acc-0.8944\n",
      "Iter-24560, train loss-0.3344, acc-0.9400, valid loss-0.3938, acc-0.9022, test loss-0.4038, acc-0.8944\n",
      "Iter-24570, train loss-0.3347, acc-0.9200, valid loss-0.3937, acc-0.9022, test loss-0.4037, acc-0.8947\n",
      "Iter-24580, train loss-0.2216, acc-0.9600, valid loss-0.3936, acc-0.9022, test loss-0.4037, acc-0.8943\n",
      "Iter-24590, train loss-0.4424, acc-0.8600, valid loss-0.3935, acc-0.9022, test loss-0.4036, acc-0.8946\n",
      "Iter-24600, train loss-0.5011, acc-0.8400, valid loss-0.3934, acc-0.9024, test loss-0.4035, acc-0.8946\n",
      "Iter-24610, train loss-0.4462, acc-0.8400, valid loss-0.3933, acc-0.9024, test loss-0.4034, acc-0.8945\n",
      "Iter-24620, train loss-0.4554, acc-0.8600, valid loss-0.3932, acc-0.9022, test loss-0.4033, acc-0.8944\n",
      "Iter-24630, train loss-0.3337, acc-0.9200, valid loss-0.3931, acc-0.9024, test loss-0.4032, acc-0.8942\n",
      "Iter-24640, train loss-0.3259, acc-0.9000, valid loss-0.3930, acc-0.9024, test loss-0.4031, acc-0.8945\n",
      "Iter-24650, train loss-0.5303, acc-0.8600, valid loss-0.3929, acc-0.9020, test loss-0.4030, acc-0.8946\n",
      "Iter-24660, train loss-0.4712, acc-0.8600, valid loss-0.3929, acc-0.9022, test loss-0.4030, acc-0.8948\n",
      "Iter-24670, train loss-0.3314, acc-0.9000, valid loss-0.3928, acc-0.9022, test loss-0.4029, acc-0.8947\n",
      "Iter-24680, train loss-0.2145, acc-0.9800, valid loss-0.3927, acc-0.9020, test loss-0.4028, acc-0.8946\n",
      "Iter-24690, train loss-0.3949, acc-0.8800, valid loss-0.3926, acc-0.9024, test loss-0.4027, acc-0.8948\n",
      "Iter-24700, train loss-0.2412, acc-0.9600, valid loss-0.3926, acc-0.9022, test loss-0.4026, acc-0.8945\n",
      "Iter-24710, train loss-0.3552, acc-0.9000, valid loss-0.3925, acc-0.9022, test loss-0.4025, acc-0.8945\n",
      "Iter-24720, train loss-0.4473, acc-0.9000, valid loss-0.3925, acc-0.9022, test loss-0.4024, acc-0.8944\n",
      "Iter-24730, train loss-0.5198, acc-0.8200, valid loss-0.3924, acc-0.9024, test loss-0.4023, acc-0.8945\n",
      "Iter-24740, train loss-0.4035, acc-0.9200, valid loss-0.3923, acc-0.9024, test loss-0.4022, acc-0.8944\n",
      "Iter-24750, train loss-0.4912, acc-0.8600, valid loss-0.3921, acc-0.9026, test loss-0.4021, acc-0.8947\n",
      "Iter-24760, train loss-0.3461, acc-0.9400, valid loss-0.3921, acc-0.9028, test loss-0.4020, acc-0.8946\n",
      "Iter-24770, train loss-0.4685, acc-0.8800, valid loss-0.3920, acc-0.9028, test loss-0.4019, acc-0.8947\n",
      "Iter-24780, train loss-0.4955, acc-0.9000, valid loss-0.3920, acc-0.9028, test loss-0.4019, acc-0.8947\n",
      "Iter-24790, train loss-0.4783, acc-0.8800, valid loss-0.3918, acc-0.9030, test loss-0.4018, acc-0.8948\n",
      "Iter-24800, train loss-0.2906, acc-0.9000, valid loss-0.3918, acc-0.9032, test loss-0.4017, acc-0.8947\n",
      "Iter-24810, train loss-0.4099, acc-0.9200, valid loss-0.3917, acc-0.9030, test loss-0.4016, acc-0.8947\n",
      "Iter-24820, train loss-0.3327, acc-0.8800, valid loss-0.3915, acc-0.9030, test loss-0.4015, acc-0.8946\n",
      "Iter-24830, train loss-0.4472, acc-0.9200, valid loss-0.3914, acc-0.9030, test loss-0.4014, acc-0.8944\n",
      "Iter-24840, train loss-0.6285, acc-0.7600, valid loss-0.3913, acc-0.9032, test loss-0.4013, acc-0.8945\n",
      "Iter-24850, train loss-0.2943, acc-0.9800, valid loss-0.3912, acc-0.9028, test loss-0.4012, acc-0.8947\n",
      "Iter-24860, train loss-0.2676, acc-0.9400, valid loss-0.3910, acc-0.9030, test loss-0.4011, acc-0.8946\n",
      "Iter-24870, train loss-0.3888, acc-0.9000, valid loss-0.3910, acc-0.9030, test loss-0.4010, acc-0.8947\n",
      "Iter-24880, train loss-0.4861, acc-0.8200, valid loss-0.3908, acc-0.9028, test loss-0.4010, acc-0.8947\n",
      "Iter-24890, train loss-0.4965, acc-0.8400, valid loss-0.3908, acc-0.9030, test loss-0.4009, acc-0.8948\n",
      "Iter-24900, train loss-0.2771, acc-0.9800, valid loss-0.3907, acc-0.9034, test loss-0.4009, acc-0.8946\n",
      "Iter-24910, train loss-0.4486, acc-0.9200, valid loss-0.3906, acc-0.9034, test loss-0.4007, acc-0.8950\n",
      "Iter-24920, train loss-0.5453, acc-0.8800, valid loss-0.3905, acc-0.9034, test loss-0.4007, acc-0.8944\n",
      "Iter-24930, train loss-0.4145, acc-0.8800, valid loss-0.3904, acc-0.9032, test loss-0.4006, acc-0.8945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24940, train loss-0.4390, acc-0.8600, valid loss-0.3903, acc-0.9034, test loss-0.4004, acc-0.8949\n",
      "Iter-24950, train loss-0.4598, acc-0.8600, valid loss-0.3902, acc-0.9032, test loss-0.4004, acc-0.8947\n",
      "Iter-24960, train loss-0.4401, acc-0.8800, valid loss-0.3901, acc-0.9032, test loss-0.4003, acc-0.8946\n",
      "Iter-24970, train loss-0.2867, acc-0.9400, valid loss-0.3900, acc-0.9032, test loss-0.4003, acc-0.8948\n",
      "Iter-24980, train loss-0.3706, acc-0.8600, valid loss-0.3900, acc-0.9036, test loss-0.4002, acc-0.8948\n",
      "Iter-24990, train loss-0.3669, acc-0.9000, valid loss-0.3899, acc-0.9034, test loss-0.4001, acc-0.8947\n",
      "Iter-25000, train loss-0.4529, acc-0.8600, valid loss-0.3898, acc-0.9036, test loss-0.4001, acc-0.8946\n",
      "Iter-25010, train loss-0.3857, acc-0.9200, valid loss-0.3897, acc-0.9038, test loss-0.4000, acc-0.8951\n",
      "Iter-25020, train loss-0.3364, acc-0.9000, valid loss-0.3896, acc-0.9040, test loss-0.3999, acc-0.8949\n",
      "Iter-25030, train loss-0.2886, acc-0.9200, valid loss-0.3895, acc-0.9038, test loss-0.3998, acc-0.8950\n",
      "Iter-25040, train loss-0.4429, acc-0.8200, valid loss-0.3895, acc-0.9040, test loss-0.3997, acc-0.8953\n",
      "Iter-25050, train loss-0.2353, acc-0.9800, valid loss-0.3894, acc-0.9040, test loss-0.3997, acc-0.8948\n",
      "Iter-25060, train loss-0.4704, acc-0.8800, valid loss-0.3893, acc-0.9038, test loss-0.3996, acc-0.8949\n",
      "Iter-25070, train loss-0.2950, acc-0.9600, valid loss-0.3892, acc-0.9038, test loss-0.3995, acc-0.8948\n",
      "Iter-25080, train loss-0.4112, acc-0.9200, valid loss-0.3892, acc-0.9038, test loss-0.3994, acc-0.8946\n",
      "Iter-25090, train loss-0.3340, acc-0.9200, valid loss-0.3890, acc-0.9034, test loss-0.3993, acc-0.8948\n",
      "Iter-25100, train loss-0.4174, acc-0.8800, valid loss-0.3890, acc-0.9034, test loss-0.3992, acc-0.8949\n",
      "Iter-25110, train loss-0.3390, acc-0.9200, valid loss-0.3889, acc-0.9034, test loss-0.3991, acc-0.8946\n",
      "Iter-25120, train loss-0.3425, acc-0.9200, valid loss-0.3888, acc-0.9036, test loss-0.3990, acc-0.8951\n",
      "Iter-25130, train loss-0.3745, acc-0.9400, valid loss-0.3887, acc-0.9034, test loss-0.3989, acc-0.8951\n",
      "Iter-25140, train loss-0.3711, acc-0.8800, valid loss-0.3886, acc-0.9036, test loss-0.3988, acc-0.8948\n",
      "Iter-25150, train loss-0.4645, acc-0.9400, valid loss-0.3886, acc-0.9036, test loss-0.3987, acc-0.8951\n",
      "Iter-25160, train loss-0.2919, acc-0.9600, valid loss-0.3885, acc-0.9042, test loss-0.3986, acc-0.8952\n",
      "Iter-25170, train loss-0.3728, acc-0.8600, valid loss-0.3884, acc-0.9038, test loss-0.3985, acc-0.8950\n",
      "Iter-25180, train loss-0.4510, acc-0.8800, valid loss-0.3884, acc-0.9034, test loss-0.3985, acc-0.8949\n",
      "Iter-25190, train loss-0.5080, acc-0.8800, valid loss-0.3883, acc-0.9042, test loss-0.3984, acc-0.8947\n",
      "Iter-25200, train loss-0.4451, acc-0.9000, valid loss-0.3882, acc-0.9038, test loss-0.3983, acc-0.8950\n",
      "Iter-25210, train loss-0.5097, acc-0.8800, valid loss-0.3881, acc-0.9038, test loss-0.3983, acc-0.8950\n",
      "Iter-25220, train loss-0.2986, acc-0.8800, valid loss-0.3880, acc-0.9040, test loss-0.3982, acc-0.8949\n",
      "Iter-25230, train loss-0.2912, acc-0.8800, valid loss-0.3879, acc-0.9036, test loss-0.3982, acc-0.8950\n",
      "Iter-25240, train loss-0.4052, acc-0.8600, valid loss-0.3879, acc-0.9036, test loss-0.3981, acc-0.8949\n",
      "Iter-25250, train loss-0.3665, acc-0.8600, valid loss-0.3877, acc-0.9036, test loss-0.3980, acc-0.8950\n",
      "Iter-25260, train loss-0.3926, acc-0.8800, valid loss-0.3877, acc-0.9038, test loss-0.3979, acc-0.8952\n",
      "Iter-25270, train loss-0.4095, acc-0.8600, valid loss-0.3876, acc-0.9038, test loss-0.3978, acc-0.8949\n",
      "Iter-25280, train loss-0.5264, acc-0.8000, valid loss-0.3875, acc-0.9036, test loss-0.3977, acc-0.8952\n",
      "Iter-25290, train loss-0.4079, acc-0.8200, valid loss-0.3874, acc-0.9036, test loss-0.3976, acc-0.8953\n",
      "Iter-25300, train loss-0.5678, acc-0.7800, valid loss-0.3874, acc-0.9034, test loss-0.3974, acc-0.8953\n",
      "Iter-25310, train loss-0.4189, acc-0.9200, valid loss-0.3874, acc-0.9034, test loss-0.3974, acc-0.8950\n",
      "Iter-25320, train loss-0.4512, acc-0.8800, valid loss-0.3873, acc-0.9030, test loss-0.3973, acc-0.8952\n",
      "Iter-25330, train loss-0.4818, acc-0.8400, valid loss-0.3872, acc-0.9032, test loss-0.3972, acc-0.8956\n",
      "Iter-25340, train loss-0.4126, acc-0.9000, valid loss-0.3871, acc-0.9032, test loss-0.3971, acc-0.8956\n",
      "Iter-25350, train loss-0.5773, acc-0.8400, valid loss-0.3870, acc-0.9032, test loss-0.3970, acc-0.8956\n",
      "Iter-25360, train loss-0.3437, acc-0.9400, valid loss-0.3869, acc-0.9032, test loss-0.3970, acc-0.8955\n",
      "Iter-25370, train loss-0.4226, acc-0.9000, valid loss-0.3869, acc-0.9030, test loss-0.3969, acc-0.8954\n",
      "Iter-25380, train loss-0.4706, acc-0.8400, valid loss-0.3867, acc-0.9028, test loss-0.3968, acc-0.8957\n",
      "Iter-25390, train loss-0.2094, acc-0.9800, valid loss-0.3867, acc-0.9030, test loss-0.3967, acc-0.8954\n",
      "Iter-25400, train loss-0.3693, acc-0.9400, valid loss-0.3866, acc-0.9024, test loss-0.3966, acc-0.8958\n",
      "Iter-25410, train loss-0.4844, acc-0.8400, valid loss-0.3865, acc-0.9028, test loss-0.3965, acc-0.8960\n",
      "Iter-25420, train loss-0.6202, acc-0.8400, valid loss-0.3864, acc-0.9028, test loss-0.3964, acc-0.8958\n",
      "Iter-25430, train loss-0.3341, acc-0.9200, valid loss-0.3864, acc-0.9028, test loss-0.3964, acc-0.8959\n",
      "Iter-25440, train loss-0.4895, acc-0.8000, valid loss-0.3862, acc-0.9028, test loss-0.3963, acc-0.8960\n",
      "Iter-25450, train loss-0.2509, acc-0.9400, valid loss-0.3861, acc-0.9028, test loss-0.3963, acc-0.8957\n",
      "Iter-25460, train loss-0.3341, acc-0.9000, valid loss-0.3861, acc-0.9028, test loss-0.3962, acc-0.8958\n",
      "Iter-25470, train loss-0.3518, acc-0.9200, valid loss-0.3860, acc-0.9028, test loss-0.3961, acc-0.8960\n",
      "Iter-25480, train loss-0.3516, acc-0.9200, valid loss-0.3859, acc-0.9028, test loss-0.3960, acc-0.8959\n",
      "Iter-25490, train loss-0.2633, acc-0.9400, valid loss-0.3859, acc-0.9028, test loss-0.3959, acc-0.8958\n",
      "Iter-25500, train loss-0.4291, acc-0.9000, valid loss-0.3858, acc-0.9030, test loss-0.3958, acc-0.8962\n",
      "Iter-25510, train loss-0.3891, acc-0.8800, valid loss-0.3857, acc-0.9030, test loss-0.3957, acc-0.8962\n",
      "Iter-25520, train loss-0.4738, acc-0.8800, valid loss-0.3856, acc-0.9030, test loss-0.3956, acc-0.8959\n",
      "Iter-25530, train loss-0.3471, acc-0.9200, valid loss-0.3855, acc-0.9032, test loss-0.3956, acc-0.8961\n",
      "Iter-25540, train loss-0.4649, acc-0.8600, valid loss-0.3854, acc-0.9032, test loss-0.3955, acc-0.8964\n",
      "Iter-25550, train loss-0.4438, acc-0.9000, valid loss-0.3853, acc-0.9032, test loss-0.3953, acc-0.8963\n",
      "Iter-25560, train loss-0.3791, acc-0.9200, valid loss-0.3851, acc-0.9032, test loss-0.3952, acc-0.8961\n",
      "Iter-25570, train loss-0.3740, acc-0.9200, valid loss-0.3851, acc-0.9030, test loss-0.3952, acc-0.8963\n",
      "Iter-25580, train loss-0.6240, acc-0.8000, valid loss-0.3850, acc-0.9034, test loss-0.3950, acc-0.8963\n",
      "Iter-25590, train loss-0.6165, acc-0.8400, valid loss-0.3850, acc-0.9032, test loss-0.3950, acc-0.8963\n",
      "Iter-25600, train loss-0.2889, acc-0.9200, valid loss-0.3848, acc-0.9034, test loss-0.3949, acc-0.8964\n",
      "Iter-25610, train loss-0.4109, acc-0.9200, valid loss-0.3847, acc-0.9036, test loss-0.3948, acc-0.8965\n",
      "Iter-25620, train loss-0.4134, acc-0.9200, valid loss-0.3847, acc-0.9036, test loss-0.3947, acc-0.8964\n",
      "Iter-25630, train loss-0.4402, acc-0.9000, valid loss-0.3845, acc-0.9036, test loss-0.3946, acc-0.8966\n",
      "Iter-25640, train loss-0.4020, acc-0.8800, valid loss-0.3844, acc-0.9034, test loss-0.3946, acc-0.8967\n",
      "Iter-25650, train loss-0.4730, acc-0.8800, valid loss-0.3843, acc-0.9034, test loss-0.3945, acc-0.8968\n",
      "Iter-25660, train loss-0.2915, acc-0.9400, valid loss-0.3842, acc-0.9034, test loss-0.3944, acc-0.8968\n",
      "Iter-25670, train loss-0.5541, acc-0.8200, valid loss-0.3842, acc-0.9032, test loss-0.3943, acc-0.8971\n",
      "Iter-25680, train loss-0.3171, acc-0.9000, valid loss-0.3841, acc-0.9032, test loss-0.3942, acc-0.8972\n",
      "Iter-25690, train loss-0.3325, acc-0.9200, valid loss-0.3840, acc-0.9028, test loss-0.3941, acc-0.8969\n",
      "Iter-25700, train loss-0.4577, acc-0.9000, valid loss-0.3839, acc-0.9028, test loss-0.3940, acc-0.8969\n",
      "Iter-25710, train loss-0.4754, acc-0.8800, valid loss-0.3838, acc-0.9030, test loss-0.3940, acc-0.8968\n",
      "Iter-25720, train loss-0.4614, acc-0.9200, valid loss-0.3837, acc-0.9032, test loss-0.3939, acc-0.8968\n",
      "Iter-25730, train loss-0.4825, acc-0.8800, valid loss-0.3836, acc-0.9036, test loss-0.3938, acc-0.8967\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-25740, train loss-0.3287, acc-0.9400, valid loss-0.3835, acc-0.9034, test loss-0.3937, acc-0.8968\n",
      "Iter-25750, train loss-0.2996, acc-0.9600, valid loss-0.3835, acc-0.9034, test loss-0.3936, acc-0.8968\n",
      "Iter-25760, train loss-0.6340, acc-0.8200, valid loss-0.3833, acc-0.9036, test loss-0.3935, acc-0.8964\n",
      "Iter-25770, train loss-0.6139, acc-0.8400, valid loss-0.3832, acc-0.9038, test loss-0.3934, acc-0.8965\n",
      "Iter-25780, train loss-0.4024, acc-0.8800, valid loss-0.3831, acc-0.9036, test loss-0.3933, acc-0.8964\n",
      "Iter-25790, train loss-0.4483, acc-0.8800, valid loss-0.3830, acc-0.9036, test loss-0.3932, acc-0.8965\n",
      "Iter-25800, train loss-0.4379, acc-0.8600, valid loss-0.3829, acc-0.9032, test loss-0.3931, acc-0.8967\n",
      "Iter-25810, train loss-0.3489, acc-0.9000, valid loss-0.3828, acc-0.9030, test loss-0.3930, acc-0.8968\n",
      "Iter-25820, train loss-0.3420, acc-0.9200, valid loss-0.3827, acc-0.9030, test loss-0.3929, acc-0.8964\n",
      "Iter-25830, train loss-0.3269, acc-0.9200, valid loss-0.3826, acc-0.9038, test loss-0.3928, acc-0.8968\n",
      "Iter-25840, train loss-0.4380, acc-0.9000, valid loss-0.3825, acc-0.9038, test loss-0.3927, acc-0.8968\n",
      "Iter-25850, train loss-0.5322, acc-0.8200, valid loss-0.3824, acc-0.9040, test loss-0.3926, acc-0.8970\n",
      "Iter-25860, train loss-0.5718, acc-0.9000, valid loss-0.3824, acc-0.9038, test loss-0.3925, acc-0.8972\n",
      "Iter-25870, train loss-0.2354, acc-0.9400, valid loss-0.3823, acc-0.9036, test loss-0.3925, acc-0.8972\n",
      "Iter-25880, train loss-0.4667, acc-0.8600, valid loss-0.3822, acc-0.9038, test loss-0.3924, acc-0.8972\n",
      "Iter-25890, train loss-0.2785, acc-0.9400, valid loss-0.3821, acc-0.9040, test loss-0.3923, acc-0.8970\n",
      "Iter-25900, train loss-0.4195, acc-0.8800, valid loss-0.3820, acc-0.9036, test loss-0.3922, acc-0.8973\n",
      "Iter-25910, train loss-0.4400, acc-0.8400, valid loss-0.3820, acc-0.9038, test loss-0.3921, acc-0.8976\n",
      "Iter-25920, train loss-0.5247, acc-0.8800, valid loss-0.3818, acc-0.9036, test loss-0.3920, acc-0.8977\n",
      "Iter-25930, train loss-0.2012, acc-0.9600, valid loss-0.3818, acc-0.9036, test loss-0.3919, acc-0.8972\n",
      "Iter-25940, train loss-0.5874, acc-0.8200, valid loss-0.3817, acc-0.9038, test loss-0.3919, acc-0.8976\n",
      "Iter-25950, train loss-0.3241, acc-0.9400, valid loss-0.3816, acc-0.9034, test loss-0.3918, acc-0.8977\n",
      "Iter-25960, train loss-0.4198, acc-0.9000, valid loss-0.3816, acc-0.9032, test loss-0.3917, acc-0.8976\n",
      "Iter-25970, train loss-0.4990, acc-0.9000, valid loss-0.3815, acc-0.9034, test loss-0.3917, acc-0.8980\n",
      "Iter-25980, train loss-0.3850, acc-0.9200, valid loss-0.3814, acc-0.9036, test loss-0.3916, acc-0.8978\n",
      "Iter-25990, train loss-0.5542, acc-0.8600, valid loss-0.3814, acc-0.9036, test loss-0.3915, acc-0.8976\n",
      "Iter-26000, train loss-0.3859, acc-0.9000, valid loss-0.3813, acc-0.9036, test loss-0.3914, acc-0.8975\n",
      "Iter-26010, train loss-0.3597, acc-0.9000, valid loss-0.3813, acc-0.9038, test loss-0.3913, acc-0.8976\n",
      "Iter-26020, train loss-0.4094, acc-0.8600, valid loss-0.3812, acc-0.9036, test loss-0.3912, acc-0.8978\n",
      "Iter-26030, train loss-0.3378, acc-0.9200, valid loss-0.3811, acc-0.9038, test loss-0.3912, acc-0.8976\n",
      "Iter-26040, train loss-0.5463, acc-0.8600, valid loss-0.3810, acc-0.9036, test loss-0.3912, acc-0.8975\n",
      "Iter-26050, train loss-0.4187, acc-0.9200, valid loss-0.3808, acc-0.9038, test loss-0.3911, acc-0.8975\n",
      "Iter-26060, train loss-0.5964, acc-0.8200, valid loss-0.3808, acc-0.9034, test loss-0.3910, acc-0.8974\n",
      "Iter-26070, train loss-0.3857, acc-0.8400, valid loss-0.3807, acc-0.9036, test loss-0.3910, acc-0.8976\n",
      "Iter-26080, train loss-0.3718, acc-0.8600, valid loss-0.3806, acc-0.9036, test loss-0.3908, acc-0.8975\n",
      "Iter-26090, train loss-0.5162, acc-0.8400, valid loss-0.3806, acc-0.9038, test loss-0.3907, acc-0.8977\n",
      "Iter-26100, train loss-0.1598, acc-1.0000, valid loss-0.3805, acc-0.9038, test loss-0.3907, acc-0.8975\n",
      "Iter-26110, train loss-0.6226, acc-0.7800, valid loss-0.3804, acc-0.9040, test loss-0.3906, acc-0.8976\n",
      "Iter-26120, train loss-0.3380, acc-0.9000, valid loss-0.3803, acc-0.9038, test loss-0.3906, acc-0.8976\n",
      "Iter-26130, train loss-0.3802, acc-0.9000, valid loss-0.3802, acc-0.9040, test loss-0.3905, acc-0.8978\n",
      "Iter-26140, train loss-0.3376, acc-0.9200, valid loss-0.3801, acc-0.9036, test loss-0.3904, acc-0.8976\n",
      "Iter-26150, train loss-0.3181, acc-0.9400, valid loss-0.3800, acc-0.9038, test loss-0.3904, acc-0.8975\n",
      "Iter-26160, train loss-0.2494, acc-0.9800, valid loss-0.3799, acc-0.9038, test loss-0.3903, acc-0.8972\n",
      "Iter-26170, train loss-0.2798, acc-0.9000, valid loss-0.3798, acc-0.9038, test loss-0.3902, acc-0.8974\n",
      "Iter-26180, train loss-0.4382, acc-0.8800, valid loss-0.3797, acc-0.9036, test loss-0.3902, acc-0.8975\n",
      "Iter-26190, train loss-0.3146, acc-0.9200, valid loss-0.3797, acc-0.9036, test loss-0.3901, acc-0.8975\n",
      "Iter-26200, train loss-0.6378, acc-0.8400, valid loss-0.3797, acc-0.9036, test loss-0.3900, acc-0.8978\n",
      "Iter-26210, train loss-0.2203, acc-0.9400, valid loss-0.3796, acc-0.9038, test loss-0.3899, acc-0.8977\n",
      "Iter-26220, train loss-0.6514, acc-0.7800, valid loss-0.3795, acc-0.9034, test loss-0.3898, acc-0.8975\n",
      "Iter-26230, train loss-0.3090, acc-0.9200, valid loss-0.3794, acc-0.9036, test loss-0.3897, acc-0.8975\n",
      "Iter-26240, train loss-0.4192, acc-0.9000, valid loss-0.3793, acc-0.9036, test loss-0.3896, acc-0.8975\n",
      "Iter-26250, train loss-0.3980, acc-0.9000, valid loss-0.3792, acc-0.9034, test loss-0.3895, acc-0.8973\n",
      "Iter-26260, train loss-0.3223, acc-0.9200, valid loss-0.3791, acc-0.9036, test loss-0.3894, acc-0.8974\n",
      "Iter-26270, train loss-0.5561, acc-0.8600, valid loss-0.3790, acc-0.9040, test loss-0.3893, acc-0.8975\n",
      "Iter-26280, train loss-0.2452, acc-0.9600, valid loss-0.3789, acc-0.9042, test loss-0.3892, acc-0.8974\n",
      "Iter-26290, train loss-0.5125, acc-0.8600, valid loss-0.3788, acc-0.9042, test loss-0.3892, acc-0.8975\n",
      "Iter-26300, train loss-0.4125, acc-0.8800, valid loss-0.3788, acc-0.9042, test loss-0.3891, acc-0.8974\n",
      "Iter-26310, train loss-0.3354, acc-0.9200, valid loss-0.3787, acc-0.9040, test loss-0.3890, acc-0.8972\n",
      "Iter-26320, train loss-0.3972, acc-0.9200, valid loss-0.3786, acc-0.9044, test loss-0.3890, acc-0.8976\n",
      "Iter-26330, train loss-0.4128, acc-0.8800, valid loss-0.3785, acc-0.9042, test loss-0.3889, acc-0.8975\n",
      "Iter-26340, train loss-0.3796, acc-0.8600, valid loss-0.3784, acc-0.9044, test loss-0.3888, acc-0.8977\n",
      "Iter-26350, train loss-0.3338, acc-0.9000, valid loss-0.3783, acc-0.9044, test loss-0.3887, acc-0.8979\n",
      "Iter-26360, train loss-0.3274, acc-0.9000, valid loss-0.3782, acc-0.9044, test loss-0.3887, acc-0.8981\n",
      "Iter-26370, train loss-0.4820, acc-0.8400, valid loss-0.3781, acc-0.9042, test loss-0.3886, acc-0.8981\n",
      "Iter-26380, train loss-0.2401, acc-0.9800, valid loss-0.3781, acc-0.9042, test loss-0.3884, acc-0.8982\n",
      "Iter-26390, train loss-0.5713, acc-0.8200, valid loss-0.3780, acc-0.9042, test loss-0.3884, acc-0.8980\n",
      "Iter-26400, train loss-0.4345, acc-0.9000, valid loss-0.3779, acc-0.9044, test loss-0.3883, acc-0.8981\n",
      "Iter-26410, train loss-0.3432, acc-0.9200, valid loss-0.3778, acc-0.9044, test loss-0.3882, acc-0.8984\n",
      "Iter-26420, train loss-0.2778, acc-0.9000, valid loss-0.3778, acc-0.9046, test loss-0.3881, acc-0.8980\n",
      "Iter-26430, train loss-0.3977, acc-0.9200, valid loss-0.3777, acc-0.9044, test loss-0.3880, acc-0.8978\n",
      "Iter-26440, train loss-0.4327, acc-0.9200, valid loss-0.3776, acc-0.9044, test loss-0.3879, acc-0.8977\n",
      "Iter-26450, train loss-0.3867, acc-0.9200, valid loss-0.3775, acc-0.9042, test loss-0.3878, acc-0.8977\n",
      "Iter-26460, train loss-0.2545, acc-0.9600, valid loss-0.3775, acc-0.9044, test loss-0.3877, acc-0.8976\n",
      "Iter-26470, train loss-0.5318, acc-0.8600, valid loss-0.3775, acc-0.9044, test loss-0.3877, acc-0.8978\n",
      "Iter-26480, train loss-0.5117, acc-0.8600, valid loss-0.3773, acc-0.9044, test loss-0.3876, acc-0.8977\n",
      "Iter-26490, train loss-0.5291, acc-0.8800, valid loss-0.3772, acc-0.9044, test loss-0.3875, acc-0.8975\n",
      "Iter-26500, train loss-0.4152, acc-0.9000, valid loss-0.3772, acc-0.9046, test loss-0.3875, acc-0.8976\n",
      "Iter-26510, train loss-0.4630, acc-0.8600, valid loss-0.3771, acc-0.9046, test loss-0.3874, acc-0.8979\n",
      "Iter-26520, train loss-0.4179, acc-0.8600, valid loss-0.3770, acc-0.9048, test loss-0.3874, acc-0.8979\n",
      "Iter-26530, train loss-0.3200, acc-0.8800, valid loss-0.3769, acc-0.9044, test loss-0.3873, acc-0.8979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-26540, train loss-0.3309, acc-0.9400, valid loss-0.3768, acc-0.9044, test loss-0.3872, acc-0.8979\n",
      "Iter-26550, train loss-0.4314, acc-0.9000, valid loss-0.3768, acc-0.9046, test loss-0.3872, acc-0.8979\n",
      "Iter-26560, train loss-0.3739, acc-0.9000, valid loss-0.3767, acc-0.9046, test loss-0.3872, acc-0.8979\n",
      "Iter-26570, train loss-0.2746, acc-0.9200, valid loss-0.3766, acc-0.9044, test loss-0.3871, acc-0.8980\n",
      "Iter-26580, train loss-0.5372, acc-0.8600, valid loss-0.3766, acc-0.9042, test loss-0.3870, acc-0.8979\n",
      "Iter-26590, train loss-0.3635, acc-0.9200, valid loss-0.3765, acc-0.9044, test loss-0.3869, acc-0.8979\n",
      "Iter-26600, train loss-0.3940, acc-0.8800, valid loss-0.3765, acc-0.9042, test loss-0.3868, acc-0.8980\n",
      "Iter-26610, train loss-0.2558, acc-1.0000, valid loss-0.3764, acc-0.9044, test loss-0.3867, acc-0.8977\n",
      "Iter-26620, train loss-0.5194, acc-0.8600, valid loss-0.3763, acc-0.9042, test loss-0.3866, acc-0.8981\n",
      "Iter-26630, train loss-0.2710, acc-0.9600, valid loss-0.3762, acc-0.9042, test loss-0.3866, acc-0.8983\n",
      "Iter-26640, train loss-0.4842, acc-0.9000, valid loss-0.3761, acc-0.9042, test loss-0.3865, acc-0.8984\n",
      "Iter-26650, train loss-0.4569, acc-0.8600, valid loss-0.3761, acc-0.9042, test loss-0.3864, acc-0.8983\n",
      "Iter-26660, train loss-0.3895, acc-0.9400, valid loss-0.3760, acc-0.9042, test loss-0.3862, acc-0.8982\n",
      "Iter-26670, train loss-0.4111, acc-0.8800, valid loss-0.3759, acc-0.9042, test loss-0.3861, acc-0.8985\n",
      "Iter-26680, train loss-0.2693, acc-0.9400, valid loss-0.3758, acc-0.9042, test loss-0.3861, acc-0.8987\n",
      "Iter-26690, train loss-0.4580, acc-0.8400, valid loss-0.3757, acc-0.9042, test loss-0.3860, acc-0.8986\n",
      "Iter-26700, train loss-0.5048, acc-0.8800, valid loss-0.3756, acc-0.9042, test loss-0.3859, acc-0.8986\n",
      "Iter-26710, train loss-0.4186, acc-0.8800, valid loss-0.3755, acc-0.9042, test loss-0.3858, acc-0.8986\n",
      "Iter-26720, train loss-0.3335, acc-0.9600, valid loss-0.3754, acc-0.9040, test loss-0.3858, acc-0.8986\n",
      "Iter-26730, train loss-0.2363, acc-0.9600, valid loss-0.3753, acc-0.9042, test loss-0.3857, acc-0.8987\n",
      "Iter-26740, train loss-0.2748, acc-0.9400, valid loss-0.3753, acc-0.9042, test loss-0.3856, acc-0.8987\n",
      "Iter-26750, train loss-0.4027, acc-0.9000, valid loss-0.3752, acc-0.9040, test loss-0.3856, acc-0.8986\n",
      "Iter-26760, train loss-0.3531, acc-0.9000, valid loss-0.3752, acc-0.9040, test loss-0.3855, acc-0.8983\n",
      "Iter-26770, train loss-0.4417, acc-0.8800, valid loss-0.3751, acc-0.9040, test loss-0.3855, acc-0.8983\n",
      "Iter-26780, train loss-0.3604, acc-0.9000, valid loss-0.3751, acc-0.9038, test loss-0.3855, acc-0.8982\n",
      "Iter-26790, train loss-0.5245, acc-0.8400, valid loss-0.3750, acc-0.9040, test loss-0.3854, acc-0.8984\n",
      "Iter-26800, train loss-0.6478, acc-0.8200, valid loss-0.3749, acc-0.9040, test loss-0.3853, acc-0.8983\n",
      "Iter-26810, train loss-0.2556, acc-0.9400, valid loss-0.3748, acc-0.9040, test loss-0.3851, acc-0.8981\n",
      "Iter-26820, train loss-0.3915, acc-0.8800, valid loss-0.3747, acc-0.9038, test loss-0.3851, acc-0.8986\n",
      "Iter-26830, train loss-0.5932, acc-0.8400, valid loss-0.3746, acc-0.9038, test loss-0.3850, acc-0.8988\n",
      "Iter-26840, train loss-0.3644, acc-0.9400, valid loss-0.3745, acc-0.9040, test loss-0.3849, acc-0.8987\n",
      "Iter-26850, train loss-0.3978, acc-0.8600, valid loss-0.3744, acc-0.9042, test loss-0.3848, acc-0.8984\n",
      "Iter-26860, train loss-0.5036, acc-0.8400, valid loss-0.3743, acc-0.9038, test loss-0.3847, acc-0.8986\n",
      "Iter-26870, train loss-0.3623, acc-0.9400, valid loss-0.3742, acc-0.9042, test loss-0.3846, acc-0.8989\n",
      "Iter-26880, train loss-0.2200, acc-0.9600, valid loss-0.3742, acc-0.9042, test loss-0.3845, acc-0.8987\n",
      "Iter-26890, train loss-0.4184, acc-0.8800, valid loss-0.3741, acc-0.9044, test loss-0.3844, acc-0.8986\n",
      "Iter-26900, train loss-0.3928, acc-0.9000, valid loss-0.3741, acc-0.9044, test loss-0.3844, acc-0.8987\n",
      "Iter-26910, train loss-0.4496, acc-0.9000, valid loss-0.3740, acc-0.9042, test loss-0.3843, acc-0.8988\n",
      "Iter-26920, train loss-0.3718, acc-0.9200, valid loss-0.3739, acc-0.9042, test loss-0.3843, acc-0.8989\n",
      "Iter-26930, train loss-0.2516, acc-0.9600, valid loss-0.3738, acc-0.9042, test loss-0.3842, acc-0.8986\n",
      "Iter-26940, train loss-0.2257, acc-0.9600, valid loss-0.3736, acc-0.9042, test loss-0.3841, acc-0.8989\n",
      "Iter-26950, train loss-0.3579, acc-0.9200, valid loss-0.3736, acc-0.9042, test loss-0.3841, acc-0.8990\n",
      "Iter-26960, train loss-0.3360, acc-0.8800, valid loss-0.3735, acc-0.9042, test loss-0.3840, acc-0.8987\n",
      "Iter-26970, train loss-0.2135, acc-0.9200, valid loss-0.3734, acc-0.9044, test loss-0.3839, acc-0.8990\n",
      "Iter-26980, train loss-0.5641, acc-0.8600, valid loss-0.3734, acc-0.9042, test loss-0.3838, acc-0.8987\n",
      "Iter-26990, train loss-0.2892, acc-0.9400, valid loss-0.3733, acc-0.9042, test loss-0.3838, acc-0.8990\n",
      "Iter-27000, train loss-0.2838, acc-0.9400, valid loss-0.3732, acc-0.9040, test loss-0.3836, acc-0.8986\n",
      "Iter-27010, train loss-0.2628, acc-0.9600, valid loss-0.3731, acc-0.9042, test loss-0.3836, acc-0.8985\n",
      "Iter-27020, train loss-0.3307, acc-0.9200, valid loss-0.3731, acc-0.9040, test loss-0.3836, acc-0.8984\n",
      "Iter-27030, train loss-0.3813, acc-0.9000, valid loss-0.3730, acc-0.9042, test loss-0.3835, acc-0.8984\n",
      "Iter-27040, train loss-0.4911, acc-0.8600, valid loss-0.3729, acc-0.9042, test loss-0.3835, acc-0.8986\n",
      "Iter-27050, train loss-0.3187, acc-0.9000, valid loss-0.3729, acc-0.9038, test loss-0.3834, acc-0.8982\n",
      "Iter-27060, train loss-0.2874, acc-0.9200, valid loss-0.3728, acc-0.9038, test loss-0.3834, acc-0.8984\n",
      "Iter-27070, train loss-0.3829, acc-0.9000, valid loss-0.3727, acc-0.9042, test loss-0.3833, acc-0.8983\n",
      "Iter-27080, train loss-0.3475, acc-0.9000, valid loss-0.3726, acc-0.9044, test loss-0.3832, acc-0.8984\n",
      "Iter-27090, train loss-0.5034, acc-0.9000, valid loss-0.3725, acc-0.9040, test loss-0.3832, acc-0.8986\n",
      "Iter-27100, train loss-0.3651, acc-0.9200, valid loss-0.3725, acc-0.9040, test loss-0.3831, acc-0.8987\n",
      "Iter-27110, train loss-0.4049, acc-0.9200, valid loss-0.3724, acc-0.9042, test loss-0.3831, acc-0.8988\n",
      "Iter-27120, train loss-0.5412, acc-0.8200, valid loss-0.3723, acc-0.9044, test loss-0.3830, acc-0.8988\n",
      "Iter-27130, train loss-0.4040, acc-0.8600, valid loss-0.3722, acc-0.9044, test loss-0.3829, acc-0.8987\n",
      "Iter-27140, train loss-0.3814, acc-0.8800, valid loss-0.3721, acc-0.9046, test loss-0.3827, acc-0.8990\n",
      "Iter-27150, train loss-0.3407, acc-0.9000, valid loss-0.3720, acc-0.9046, test loss-0.3827, acc-0.8993\n",
      "Iter-27160, train loss-0.2577, acc-0.9200, valid loss-0.3720, acc-0.9046, test loss-0.3826, acc-0.8992\n",
      "Iter-27170, train loss-0.3452, acc-0.9000, valid loss-0.3719, acc-0.9048, test loss-0.3825, acc-0.8994\n",
      "Iter-27180, train loss-0.3892, acc-0.8600, valid loss-0.3718, acc-0.9050, test loss-0.3825, acc-0.8994\n",
      "Iter-27190, train loss-0.3652, acc-0.9200, valid loss-0.3717, acc-0.9052, test loss-0.3824, acc-0.8996\n",
      "Iter-27200, train loss-0.3481, acc-0.8600, valid loss-0.3717, acc-0.9048, test loss-0.3823, acc-0.8996\n",
      "Iter-27210, train loss-0.4763, acc-0.8800, valid loss-0.3716, acc-0.9048, test loss-0.3823, acc-0.8995\n",
      "Iter-27220, train loss-0.3614, acc-0.9200, valid loss-0.3715, acc-0.9046, test loss-0.3822, acc-0.8995\n",
      "Iter-27230, train loss-0.2980, acc-0.9600, valid loss-0.3714, acc-0.9048, test loss-0.3821, acc-0.8994\n",
      "Iter-27240, train loss-0.3888, acc-0.9000, valid loss-0.3714, acc-0.9044, test loss-0.3820, acc-0.8994\n",
      "Iter-27250, train loss-0.3518, acc-0.9200, valid loss-0.3713, acc-0.9052, test loss-0.3820, acc-0.8995\n",
      "Iter-27260, train loss-0.4093, acc-0.8600, valid loss-0.3712, acc-0.9046, test loss-0.3818, acc-0.8994\n",
      "Iter-27270, train loss-0.3323, acc-0.9800, valid loss-0.3712, acc-0.9046, test loss-0.3818, acc-0.8996\n",
      "Iter-27280, train loss-0.5202, acc-0.9000, valid loss-0.3711, acc-0.9048, test loss-0.3817, acc-0.8995\n",
      "Iter-27290, train loss-0.3661, acc-0.8800, valid loss-0.3710, acc-0.9050, test loss-0.3816, acc-0.8997\n",
      "Iter-27300, train loss-0.2977, acc-0.9600, valid loss-0.3710, acc-0.9046, test loss-0.3816, acc-0.8996\n",
      "Iter-27310, train loss-0.4889, acc-0.9000, valid loss-0.3709, acc-0.9046, test loss-0.3815, acc-0.8997\n",
      "Iter-27320, train loss-0.4326, acc-0.8400, valid loss-0.3709, acc-0.9048, test loss-0.3814, acc-0.8997\n",
      "Iter-27330, train loss-0.4563, acc-0.8400, valid loss-0.3708, acc-0.9050, test loss-0.3813, acc-0.8997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-27340, train loss-0.4232, acc-0.9400, valid loss-0.3707, acc-0.9048, test loss-0.3812, acc-0.8996\n",
      "Iter-27350, train loss-0.4092, acc-0.8600, valid loss-0.3707, acc-0.9050, test loss-0.3811, acc-0.8996\n",
      "Iter-27360, train loss-0.1959, acc-1.0000, valid loss-0.3706, acc-0.9048, test loss-0.3811, acc-0.8997\n",
      "Iter-27370, train loss-0.3793, acc-0.9400, valid loss-0.3705, acc-0.9050, test loss-0.3810, acc-0.8999\n",
      "Iter-27380, train loss-0.3221, acc-0.9400, valid loss-0.3705, acc-0.9050, test loss-0.3809, acc-0.8999\n",
      "Iter-27390, train loss-0.4390, acc-0.9200, valid loss-0.3704, acc-0.9050, test loss-0.3808, acc-0.8998\n",
      "Iter-27400, train loss-0.2502, acc-0.9600, valid loss-0.3703, acc-0.9052, test loss-0.3808, acc-0.8998\n",
      "Iter-27410, train loss-0.5172, acc-0.8600, valid loss-0.3702, acc-0.9050, test loss-0.3807, acc-0.8998\n",
      "Iter-27420, train loss-0.2345, acc-0.9600, valid loss-0.3701, acc-0.9048, test loss-0.3806, acc-0.9000\n",
      "Iter-27430, train loss-0.2754, acc-0.9600, valid loss-0.3700, acc-0.9048, test loss-0.3805, acc-0.9000\n",
      "Iter-27440, train loss-0.3235, acc-0.9200, valid loss-0.3700, acc-0.9050, test loss-0.3804, acc-0.8997\n",
      "Iter-27450, train loss-0.2346, acc-0.9400, valid loss-0.3699, acc-0.9052, test loss-0.3803, acc-0.8994\n",
      "Iter-27460, train loss-0.5404, acc-0.8200, valid loss-0.3698, acc-0.9050, test loss-0.3803, acc-0.8994\n",
      "Iter-27470, train loss-0.3969, acc-0.8800, valid loss-0.3697, acc-0.9054, test loss-0.3802, acc-0.8996\n",
      "Iter-27480, train loss-0.4457, acc-0.8800, valid loss-0.3696, acc-0.9056, test loss-0.3802, acc-0.8997\n",
      "Iter-27490, train loss-0.2931, acc-0.9600, valid loss-0.3695, acc-0.9056, test loss-0.3801, acc-0.8997\n",
      "Iter-27500, train loss-0.3525, acc-0.8800, valid loss-0.3694, acc-0.9052, test loss-0.3800, acc-0.8995\n",
      "Iter-27510, train loss-0.4283, acc-0.9000, valid loss-0.3694, acc-0.9056, test loss-0.3800, acc-0.8996\n",
      "Iter-27520, train loss-0.3659, acc-0.9200, valid loss-0.3693, acc-0.9056, test loss-0.3799, acc-0.8997\n",
      "Iter-27530, train loss-0.5517, acc-0.8400, valid loss-0.3692, acc-0.9056, test loss-0.3798, acc-0.8996\n",
      "Iter-27540, train loss-0.3142, acc-0.9200, valid loss-0.3691, acc-0.9052, test loss-0.3798, acc-0.8999\n",
      "Iter-27550, train loss-0.3766, acc-0.9200, valid loss-0.3691, acc-0.9054, test loss-0.3797, acc-0.8997\n",
      "Iter-27560, train loss-0.3230, acc-0.9200, valid loss-0.3690, acc-0.9054, test loss-0.3797, acc-0.8997\n",
      "Iter-27570, train loss-0.7236, acc-0.7800, valid loss-0.3689, acc-0.9056, test loss-0.3796, acc-0.8999\n",
      "Iter-27580, train loss-0.5586, acc-0.7800, valid loss-0.3689, acc-0.9054, test loss-0.3795, acc-0.8997\n",
      "Iter-27590, train loss-0.6194, acc-0.8400, valid loss-0.3689, acc-0.9052, test loss-0.3794, acc-0.8995\n",
      "Iter-27600, train loss-0.3258, acc-0.9200, valid loss-0.3689, acc-0.9052, test loss-0.3793, acc-0.9000\n",
      "Iter-27610, train loss-0.3098, acc-0.9200, valid loss-0.3688, acc-0.9052, test loss-0.3793, acc-0.9000\n",
      "Iter-27620, train loss-0.3947, acc-0.8800, valid loss-0.3687, acc-0.9056, test loss-0.3792, acc-0.9000\n",
      "Iter-27630, train loss-0.3799, acc-0.9200, valid loss-0.3687, acc-0.9056, test loss-0.3791, acc-0.9001\n",
      "Iter-27640, train loss-0.3864, acc-0.9000, valid loss-0.3686, acc-0.9052, test loss-0.3791, acc-0.9000\n",
      "Iter-27650, train loss-0.4776, acc-0.8400, valid loss-0.3685, acc-0.9052, test loss-0.3790, acc-0.8999\n",
      "Iter-27660, train loss-0.3074, acc-0.8800, valid loss-0.3684, acc-0.9054, test loss-0.3790, acc-0.8998\n",
      "Iter-27670, train loss-0.2774, acc-0.9400, valid loss-0.3683, acc-0.9054, test loss-0.3789, acc-0.8999\n",
      "Iter-27680, train loss-0.2776, acc-0.9200, valid loss-0.3682, acc-0.9058, test loss-0.3788, acc-0.9000\n",
      "Iter-27690, train loss-0.4074, acc-0.8800, valid loss-0.3680, acc-0.9058, test loss-0.3787, acc-0.9001\n",
      "Iter-27700, train loss-0.3870, acc-0.9000, valid loss-0.3680, acc-0.9056, test loss-0.3786, acc-0.9001\n",
      "Iter-27710, train loss-0.3030, acc-0.9200, valid loss-0.3680, acc-0.9054, test loss-0.3786, acc-0.9001\n",
      "Iter-27720, train loss-0.3792, acc-0.8800, valid loss-0.3679, acc-0.9054, test loss-0.3785, acc-0.8998\n",
      "Iter-27730, train loss-0.3615, acc-0.9200, valid loss-0.3678, acc-0.9052, test loss-0.3785, acc-0.8998\n",
      "Iter-27740, train loss-0.3195, acc-0.9200, valid loss-0.3677, acc-0.9062, test loss-0.3784, acc-0.8998\n",
      "Iter-27750, train loss-0.4311, acc-0.8800, valid loss-0.3677, acc-0.9060, test loss-0.3783, acc-0.8998\n",
      "Iter-27760, train loss-0.4067, acc-0.9000, valid loss-0.3676, acc-0.9060, test loss-0.3782, acc-0.8998\n",
      "Iter-27770, train loss-0.6859, acc-0.8200, valid loss-0.3676, acc-0.9056, test loss-0.3782, acc-0.8998\n",
      "Iter-27780, train loss-0.3002, acc-0.9200, valid loss-0.3675, acc-0.9056, test loss-0.3782, acc-0.8999\n",
      "Iter-27790, train loss-0.3719, acc-0.9000, valid loss-0.3674, acc-0.9054, test loss-0.3781, acc-0.8997\n",
      "Iter-27800, train loss-0.3155, acc-0.9200, valid loss-0.3673, acc-0.9056, test loss-0.3780, acc-0.8998\n",
      "Iter-27810, train loss-0.1852, acc-0.9800, valid loss-0.3672, acc-0.9056, test loss-0.3780, acc-0.9001\n",
      "Iter-27820, train loss-0.3510, acc-0.9000, valid loss-0.3672, acc-0.9054, test loss-0.3779, acc-0.9001\n",
      "Iter-27830, train loss-0.5842, acc-0.8400, valid loss-0.3672, acc-0.9052, test loss-0.3778, acc-0.9003\n",
      "Iter-27840, train loss-0.3964, acc-0.8800, valid loss-0.3672, acc-0.9050, test loss-0.3778, acc-0.9002\n",
      "Iter-27850, train loss-0.2814, acc-0.9400, valid loss-0.3671, acc-0.9050, test loss-0.3777, acc-0.9002\n",
      "Iter-27860, train loss-0.4775, acc-0.8600, valid loss-0.3670, acc-0.9054, test loss-0.3776, acc-0.9005\n",
      "Iter-27870, train loss-0.2883, acc-0.9600, valid loss-0.3670, acc-0.9058, test loss-0.3775, acc-0.9007\n",
      "Iter-27880, train loss-0.4344, acc-0.8800, valid loss-0.3669, acc-0.9058, test loss-0.3774, acc-0.9005\n",
      "Iter-27890, train loss-0.3504, acc-0.9400, valid loss-0.3668, acc-0.9058, test loss-0.3774, acc-0.9002\n",
      "Iter-27900, train loss-0.2963, acc-0.9600, valid loss-0.3667, acc-0.9058, test loss-0.3773, acc-0.9005\n",
      "Iter-27910, train loss-0.2936, acc-0.9200, valid loss-0.3667, acc-0.9058, test loss-0.3772, acc-0.9004\n",
      "Iter-27920, train loss-0.4258, acc-0.8400, valid loss-0.3666, acc-0.9062, test loss-0.3771, acc-0.9006\n",
      "Iter-27930, train loss-0.2269, acc-0.9600, valid loss-0.3666, acc-0.9056, test loss-0.3770, acc-0.9005\n",
      "Iter-27940, train loss-0.4113, acc-0.9000, valid loss-0.3664, acc-0.9060, test loss-0.3770, acc-0.9004\n",
      "Iter-27950, train loss-0.4321, acc-0.8800, valid loss-0.3664, acc-0.9058, test loss-0.3769, acc-0.9006\n",
      "Iter-27960, train loss-0.2882, acc-0.9000, valid loss-0.3663, acc-0.9056, test loss-0.3768, acc-0.9007\n",
      "Iter-27970, train loss-0.5143, acc-0.8800, valid loss-0.3662, acc-0.9052, test loss-0.3768, acc-0.9008\n",
      "Iter-27980, train loss-0.3709, acc-0.9000, valid loss-0.3661, acc-0.9054, test loss-0.3768, acc-0.9009\n",
      "Iter-27990, train loss-0.2452, acc-0.9600, valid loss-0.3661, acc-0.9054, test loss-0.3767, acc-0.9008\n",
      "Iter-28000, train loss-0.5541, acc-0.8200, valid loss-0.3660, acc-0.9056, test loss-0.3766, acc-0.9008\n",
      "Iter-28010, train loss-0.7392, acc-0.7600, valid loss-0.3659, acc-0.9056, test loss-0.3766, acc-0.9007\n",
      "Iter-28020, train loss-0.4584, acc-0.8400, valid loss-0.3659, acc-0.9056, test loss-0.3765, acc-0.9006\n",
      "Iter-28030, train loss-0.5082, acc-0.8400, valid loss-0.3658, acc-0.9058, test loss-0.3765, acc-0.9007\n",
      "Iter-28040, train loss-0.3579, acc-0.8800, valid loss-0.3657, acc-0.9058, test loss-0.3764, acc-0.9006\n",
      "Iter-28050, train loss-0.3342, acc-0.9400, valid loss-0.3656, acc-0.9058, test loss-0.3764, acc-0.9004\n",
      "Iter-28060, train loss-0.5018, acc-0.9000, valid loss-0.3655, acc-0.9058, test loss-0.3764, acc-0.9007\n",
      "Iter-28070, train loss-0.3637, acc-0.9400, valid loss-0.3654, acc-0.9056, test loss-0.3763, acc-0.9010\n",
      "Iter-28080, train loss-0.3359, acc-0.9400, valid loss-0.3654, acc-0.9056, test loss-0.3762, acc-0.9007\n",
      "Iter-28090, train loss-0.4079, acc-0.9000, valid loss-0.3654, acc-0.9056, test loss-0.3762, acc-0.9004\n",
      "Iter-28100, train loss-0.3630, acc-0.8800, valid loss-0.3653, acc-0.9058, test loss-0.3761, acc-0.9007\n",
      "Iter-28110, train loss-0.6355, acc-0.7800, valid loss-0.3652, acc-0.9058, test loss-0.3760, acc-0.9006\n",
      "Iter-28120, train loss-0.3337, acc-0.9400, valid loss-0.3651, acc-0.9062, test loss-0.3759, acc-0.9005\n",
      "Iter-28130, train loss-0.2110, acc-0.9800, valid loss-0.3650, acc-0.9060, test loss-0.3759, acc-0.9003\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28140, train loss-0.3223, acc-0.9000, valid loss-0.3649, acc-0.9060, test loss-0.3758, acc-0.9004\n",
      "Iter-28150, train loss-0.4791, acc-0.8800, valid loss-0.3648, acc-0.9058, test loss-0.3757, acc-0.9005\n",
      "Iter-28160, train loss-0.4614, acc-0.8600, valid loss-0.3648, acc-0.9062, test loss-0.3756, acc-0.9006\n",
      "Iter-28170, train loss-0.2685, acc-0.9200, valid loss-0.3648, acc-0.9058, test loss-0.3756, acc-0.9007\n",
      "Iter-28180, train loss-0.3623, acc-0.8800, valid loss-0.3647, acc-0.9058, test loss-0.3755, acc-0.9007\n",
      "Iter-28190, train loss-0.2459, acc-0.9400, valid loss-0.3646, acc-0.9054, test loss-0.3754, acc-0.9009\n",
      "Iter-28200, train loss-0.4205, acc-0.9000, valid loss-0.3645, acc-0.9060, test loss-0.3754, acc-0.9008\n",
      "Iter-28210, train loss-0.4041, acc-0.9200, valid loss-0.3644, acc-0.9064, test loss-0.3753, acc-0.9008\n",
      "Iter-28220, train loss-0.2847, acc-0.9200, valid loss-0.3644, acc-0.9064, test loss-0.3752, acc-0.9009\n",
      "Iter-28230, train loss-0.3452, acc-0.9000, valid loss-0.3643, acc-0.9060, test loss-0.3752, acc-0.9009\n",
      "Iter-28240, train loss-0.4230, acc-0.8800, valid loss-0.3642, acc-0.9060, test loss-0.3751, acc-0.9007\n",
      "Iter-28250, train loss-0.1445, acc-1.0000, valid loss-0.3641, acc-0.9058, test loss-0.3750, acc-0.9008\n",
      "Iter-28260, train loss-0.5178, acc-0.8400, valid loss-0.3641, acc-0.9058, test loss-0.3749, acc-0.9008\n",
      "Iter-28270, train loss-0.3306, acc-0.9000, valid loss-0.3640, acc-0.9060, test loss-0.3749, acc-0.9007\n",
      "Iter-28280, train loss-0.3481, acc-0.8800, valid loss-0.3640, acc-0.9060, test loss-0.3748, acc-0.9007\n",
      "Iter-28290, train loss-0.3005, acc-0.9200, valid loss-0.3640, acc-0.9062, test loss-0.3747, acc-0.9009\n",
      "Iter-28300, train loss-0.4442, acc-0.8400, valid loss-0.3639, acc-0.9060, test loss-0.3747, acc-0.9008\n",
      "Iter-28310, train loss-0.3116, acc-0.8600, valid loss-0.3638, acc-0.9060, test loss-0.3746, acc-0.9008\n",
      "Iter-28320, train loss-0.4816, acc-0.8400, valid loss-0.3637, acc-0.9062, test loss-0.3745, acc-0.9010\n",
      "Iter-28330, train loss-0.5769, acc-0.8800, valid loss-0.3636, acc-0.9060, test loss-0.3745, acc-0.9009\n",
      "Iter-28340, train loss-0.3399, acc-0.9200, valid loss-0.3636, acc-0.9060, test loss-0.3745, acc-0.9012\n",
      "Iter-28350, train loss-0.3633, acc-0.9000, valid loss-0.3635, acc-0.9060, test loss-0.3744, acc-0.9011\n",
      "Iter-28360, train loss-0.3514, acc-0.9400, valid loss-0.3634, acc-0.9060, test loss-0.3743, acc-0.9013\n",
      "Iter-28370, train loss-0.2099, acc-0.9400, valid loss-0.3633, acc-0.9056, test loss-0.3742, acc-0.9012\n",
      "Iter-28380, train loss-0.2791, acc-0.9200, valid loss-0.3632, acc-0.9056, test loss-0.3742, acc-0.9012\n",
      "Iter-28390, train loss-0.2841, acc-0.9000, valid loss-0.3631, acc-0.9060, test loss-0.3742, acc-0.9012\n",
      "Iter-28400, train loss-0.4608, acc-0.8800, valid loss-0.3630, acc-0.9060, test loss-0.3741, acc-0.9013\n",
      "Iter-28410, train loss-0.3085, acc-0.9600, valid loss-0.3630, acc-0.9060, test loss-0.3740, acc-0.9013\n",
      "Iter-28420, train loss-0.4073, acc-0.9000, valid loss-0.3630, acc-0.9056, test loss-0.3739, acc-0.9014\n",
      "Iter-28430, train loss-0.3657, acc-0.9400, valid loss-0.3629, acc-0.9056, test loss-0.3738, acc-0.9014\n",
      "Iter-28440, train loss-0.4579, acc-0.8800, valid loss-0.3629, acc-0.9058, test loss-0.3738, acc-0.9014\n",
      "Iter-28450, train loss-0.3556, acc-0.9000, valid loss-0.3628, acc-0.9058, test loss-0.3737, acc-0.9015\n",
      "Iter-28460, train loss-0.4393, acc-0.8800, valid loss-0.3628, acc-0.9062, test loss-0.3736, acc-0.9014\n",
      "Iter-28470, train loss-0.6199, acc-0.8400, valid loss-0.3627, acc-0.9058, test loss-0.3735, acc-0.9016\n",
      "Iter-28480, train loss-0.4095, acc-0.9000, valid loss-0.3627, acc-0.9062, test loss-0.3734, acc-0.9015\n",
      "Iter-28490, train loss-0.4157, acc-0.8800, valid loss-0.3626, acc-0.9062, test loss-0.3734, acc-0.9015\n",
      "Iter-28500, train loss-0.2388, acc-0.9600, valid loss-0.3625, acc-0.9062, test loss-0.3733, acc-0.9014\n",
      "Iter-28510, train loss-0.3872, acc-0.9000, valid loss-0.3625, acc-0.9064, test loss-0.3733, acc-0.9014\n",
      "Iter-28520, train loss-0.6519, acc-0.8000, valid loss-0.3624, acc-0.9064, test loss-0.3733, acc-0.9013\n",
      "Iter-28530, train loss-0.4280, acc-0.9400, valid loss-0.3624, acc-0.9066, test loss-0.3732, acc-0.9011\n",
      "Iter-28540, train loss-0.2671, acc-0.9000, valid loss-0.3623, acc-0.9066, test loss-0.3731, acc-0.9011\n",
      "Iter-28550, train loss-0.4716, acc-0.8800, valid loss-0.3622, acc-0.9066, test loss-0.3731, acc-0.9012\n",
      "Iter-28560, train loss-0.4442, acc-0.8400, valid loss-0.3621, acc-0.9068, test loss-0.3730, acc-0.9014\n",
      "Iter-28570, train loss-0.3580, acc-0.8600, valid loss-0.3621, acc-0.9068, test loss-0.3729, acc-0.9013\n",
      "Iter-28580, train loss-0.3197, acc-0.9000, valid loss-0.3620, acc-0.9068, test loss-0.3728, acc-0.9014\n",
      "Iter-28590, train loss-0.4941, acc-0.8200, valid loss-0.3619, acc-0.9068, test loss-0.3727, acc-0.9011\n",
      "Iter-28600, train loss-0.3086, acc-0.9200, valid loss-0.3618, acc-0.9068, test loss-0.3727, acc-0.9013\n",
      "Iter-28610, train loss-0.3546, acc-0.8600, valid loss-0.3618, acc-0.9068, test loss-0.3726, acc-0.9012\n",
      "Iter-28620, train loss-0.3872, acc-0.9000, valid loss-0.3617, acc-0.9066, test loss-0.3726, acc-0.9011\n",
      "Iter-28630, train loss-0.3660, acc-0.8600, valid loss-0.3617, acc-0.9064, test loss-0.3725, acc-0.9011\n",
      "Iter-28640, train loss-0.3511, acc-0.8800, valid loss-0.3616, acc-0.9066, test loss-0.3724, acc-0.9012\n",
      "Iter-28650, train loss-0.2256, acc-0.9200, valid loss-0.3615, acc-0.9066, test loss-0.3723, acc-0.9011\n",
      "Iter-28660, train loss-0.2531, acc-0.9400, valid loss-0.3615, acc-0.9066, test loss-0.3723, acc-0.9013\n",
      "Iter-28670, train loss-0.5855, acc-0.8400, valid loss-0.3614, acc-0.9066, test loss-0.3722, acc-0.9013\n",
      "Iter-28680, train loss-0.4600, acc-0.8600, valid loss-0.3613, acc-0.9066, test loss-0.3722, acc-0.9014\n",
      "Iter-28690, train loss-0.4497, acc-0.9000, valid loss-0.3613, acc-0.9064, test loss-0.3722, acc-0.9013\n",
      "Iter-28700, train loss-0.3975, acc-0.8600, valid loss-0.3612, acc-0.9064, test loss-0.3721, acc-0.9014\n",
      "Iter-28710, train loss-0.5425, acc-0.8800, valid loss-0.3611, acc-0.9066, test loss-0.3720, acc-0.9018\n",
      "Iter-28720, train loss-0.3599, acc-0.8800, valid loss-0.3611, acc-0.9066, test loss-0.3720, acc-0.9015\n",
      "Iter-28730, train loss-0.4308, acc-0.8600, valid loss-0.3611, acc-0.9066, test loss-0.3719, acc-0.9014\n",
      "Iter-28740, train loss-0.6003, acc-0.8600, valid loss-0.3610, acc-0.9066, test loss-0.3718, acc-0.9013\n",
      "Iter-28750, train loss-0.4097, acc-0.9200, valid loss-0.3610, acc-0.9068, test loss-0.3718, acc-0.9016\n",
      "Iter-28760, train loss-0.4290, acc-0.8800, valid loss-0.3609, acc-0.9070, test loss-0.3717, acc-0.9017\n",
      "Iter-28770, train loss-0.5629, acc-0.8200, valid loss-0.3608, acc-0.9070, test loss-0.3716, acc-0.9017\n",
      "Iter-28780, train loss-0.2241, acc-0.9800, valid loss-0.3608, acc-0.9068, test loss-0.3715, acc-0.9014\n",
      "Iter-28790, train loss-0.4396, acc-0.8800, valid loss-0.3607, acc-0.9070, test loss-0.3715, acc-0.9014\n",
      "Iter-28800, train loss-0.4481, acc-0.9200, valid loss-0.3606, acc-0.9068, test loss-0.3714, acc-0.9015\n",
      "Iter-28810, train loss-0.5005, acc-0.8600, valid loss-0.3606, acc-0.9066, test loss-0.3713, acc-0.9013\n",
      "Iter-28820, train loss-0.5559, acc-0.8400, valid loss-0.3604, acc-0.9068, test loss-0.3713, acc-0.9013\n",
      "Iter-28830, train loss-0.3018, acc-0.9000, valid loss-0.3603, acc-0.9064, test loss-0.3712, acc-0.9014\n",
      "Iter-28840, train loss-0.4340, acc-0.8800, valid loss-0.3602, acc-0.9062, test loss-0.3712, acc-0.9015\n",
      "Iter-28850, train loss-0.5194, acc-0.8800, valid loss-0.3602, acc-0.9066, test loss-0.3711, acc-0.9014\n",
      "Iter-28860, train loss-0.4504, acc-0.8600, valid loss-0.3601, acc-0.9066, test loss-0.3710, acc-0.9013\n",
      "Iter-28870, train loss-0.2592, acc-0.9800, valid loss-0.3601, acc-0.9066, test loss-0.3710, acc-0.9014\n",
      "Iter-28880, train loss-0.2727, acc-0.9400, valid loss-0.3600, acc-0.9068, test loss-0.3709, acc-0.9015\n",
      "Iter-28890, train loss-0.3840, acc-0.9200, valid loss-0.3600, acc-0.9062, test loss-0.3708, acc-0.9014\n",
      "Iter-28900, train loss-0.3646, acc-0.8800, valid loss-0.3599, acc-0.9066, test loss-0.3707, acc-0.9015\n",
      "Iter-28910, train loss-0.3167, acc-0.9200, valid loss-0.3599, acc-0.9068, test loss-0.3707, acc-0.9016\n",
      "Iter-28920, train loss-0.3710, acc-0.9400, valid loss-0.3598, acc-0.9066, test loss-0.3706, acc-0.9014\n",
      "Iter-28930, train loss-0.4453, acc-0.8800, valid loss-0.3597, acc-0.9066, test loss-0.3706, acc-0.9012\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28940, train loss-0.4682, acc-0.8400, valid loss-0.3596, acc-0.9064, test loss-0.3705, acc-0.9012\n",
      "Iter-28950, train loss-0.2120, acc-0.9800, valid loss-0.3596, acc-0.9066, test loss-0.3705, acc-0.9013\n",
      "Iter-28960, train loss-0.3800, acc-0.8800, valid loss-0.3595, acc-0.9066, test loss-0.3704, acc-0.9015\n",
      "Iter-28970, train loss-0.3879, acc-0.9000, valid loss-0.3593, acc-0.9066, test loss-0.3703, acc-0.9016\n",
      "Iter-28980, train loss-0.4310, acc-0.9000, valid loss-0.3593, acc-0.9066, test loss-0.3703, acc-0.9014\n",
      "Iter-28990, train loss-0.4993, acc-0.8600, valid loss-0.3593, acc-0.9062, test loss-0.3702, acc-0.9016\n",
      "Iter-29000, train loss-0.4992, acc-0.8800, valid loss-0.3591, acc-0.9062, test loss-0.3702, acc-0.9018\n",
      "Iter-29010, train loss-0.3546, acc-0.9200, valid loss-0.3591, acc-0.9060, test loss-0.3702, acc-0.9018\n",
      "Iter-29020, train loss-0.2618, acc-0.9200, valid loss-0.3590, acc-0.9062, test loss-0.3701, acc-0.9018\n",
      "Iter-29030, train loss-0.3513, acc-0.9000, valid loss-0.3590, acc-0.9064, test loss-0.3700, acc-0.9018\n",
      "Iter-29040, train loss-0.6132, acc-0.8000, valid loss-0.3590, acc-0.9064, test loss-0.3700, acc-0.9018\n",
      "Iter-29050, train loss-0.1968, acc-0.9600, valid loss-0.3589, acc-0.9064, test loss-0.3699, acc-0.9019\n",
      "Iter-29060, train loss-0.3413, acc-0.8600, valid loss-0.3588, acc-0.9066, test loss-0.3698, acc-0.9019\n",
      "Iter-29070, train loss-0.3009, acc-0.9600, valid loss-0.3588, acc-0.9068, test loss-0.3697, acc-0.9019\n",
      "Iter-29080, train loss-0.5128, acc-0.8600, valid loss-0.3587, acc-0.9068, test loss-0.3697, acc-0.9021\n",
      "Iter-29090, train loss-0.7143, acc-0.8000, valid loss-0.3586, acc-0.9066, test loss-0.3696, acc-0.9024\n",
      "Iter-29100, train loss-0.4836, acc-0.8400, valid loss-0.3586, acc-0.9070, test loss-0.3696, acc-0.9021\n",
      "Iter-29110, train loss-0.2896, acc-0.9200, valid loss-0.3586, acc-0.9068, test loss-0.3696, acc-0.9020\n",
      "Iter-29120, train loss-0.2528, acc-0.9200, valid loss-0.3585, acc-0.9070, test loss-0.3695, acc-0.9022\n",
      "Iter-29130, train loss-0.2865, acc-0.9200, valid loss-0.3585, acc-0.9072, test loss-0.3694, acc-0.9022\n",
      "Iter-29140, train loss-0.2649, acc-0.9800, valid loss-0.3584, acc-0.9072, test loss-0.3694, acc-0.9022\n",
      "Iter-29150, train loss-0.2687, acc-0.9600, valid loss-0.3583, acc-0.9072, test loss-0.3693, acc-0.9020\n",
      "Iter-29160, train loss-0.3696, acc-0.9000, valid loss-0.3583, acc-0.9072, test loss-0.3693, acc-0.9023\n",
      "Iter-29170, train loss-0.4289, acc-0.8600, valid loss-0.3583, acc-0.9072, test loss-0.3693, acc-0.9023\n",
      "Iter-29180, train loss-0.5053, acc-0.8400, valid loss-0.3582, acc-0.9072, test loss-0.3692, acc-0.9023\n",
      "Iter-29190, train loss-0.4223, acc-0.8600, valid loss-0.3582, acc-0.9070, test loss-0.3691, acc-0.9025\n",
      "Iter-29200, train loss-0.2311, acc-0.9400, valid loss-0.3581, acc-0.9068, test loss-0.3691, acc-0.9021\n",
      "Iter-29210, train loss-0.2851, acc-0.9200, valid loss-0.3581, acc-0.9070, test loss-0.3690, acc-0.9020\n",
      "Iter-29220, train loss-0.4538, acc-0.9000, valid loss-0.3581, acc-0.9070, test loss-0.3690, acc-0.9021\n",
      "Iter-29230, train loss-0.3304, acc-0.8800, valid loss-0.3580, acc-0.9068, test loss-0.3689, acc-0.9021\n",
      "Iter-29240, train loss-0.4531, acc-0.8400, valid loss-0.3579, acc-0.9068, test loss-0.3689, acc-0.9020\n",
      "Iter-29250, train loss-0.3502, acc-0.9400, valid loss-0.3578, acc-0.9066, test loss-0.3688, acc-0.9023\n",
      "Iter-29260, train loss-0.3079, acc-0.9000, valid loss-0.3578, acc-0.9068, test loss-0.3687, acc-0.9022\n",
      "Iter-29270, train loss-0.2487, acc-0.9400, valid loss-0.3577, acc-0.9066, test loss-0.3686, acc-0.9022\n",
      "Iter-29280, train loss-0.7052, acc-0.8000, valid loss-0.3577, acc-0.9070, test loss-0.3685, acc-0.9025\n",
      "Iter-29290, train loss-0.5001, acc-0.8800, valid loss-0.3577, acc-0.9070, test loss-0.3685, acc-0.9023\n",
      "Iter-29300, train loss-0.3728, acc-0.8800, valid loss-0.3576, acc-0.9070, test loss-0.3684, acc-0.9026\n",
      "Iter-29310, train loss-0.4662, acc-0.8800, valid loss-0.3575, acc-0.9070, test loss-0.3683, acc-0.9023\n",
      "Iter-29320, train loss-0.6677, acc-0.8200, valid loss-0.3575, acc-0.9070, test loss-0.3683, acc-0.9023\n",
      "Iter-29330, train loss-0.3442, acc-0.8800, valid loss-0.3574, acc-0.9070, test loss-0.3682, acc-0.9024\n",
      "Iter-29340, train loss-0.3589, acc-0.9200, valid loss-0.3575, acc-0.9070, test loss-0.3681, acc-0.9025\n",
      "Iter-29350, train loss-0.2084, acc-1.0000, valid loss-0.3574, acc-0.9072, test loss-0.3681, acc-0.9025\n",
      "Iter-29360, train loss-0.3648, acc-0.9200, valid loss-0.3572, acc-0.9070, test loss-0.3680, acc-0.9024\n",
      "Iter-29370, train loss-0.2914, acc-0.8800, valid loss-0.3572, acc-0.9070, test loss-0.3680, acc-0.9025\n",
      "Iter-29380, train loss-0.5924, acc-0.8600, valid loss-0.3571, acc-0.9070, test loss-0.3679, acc-0.9025\n",
      "Iter-29390, train loss-0.4372, acc-0.8600, valid loss-0.3570, acc-0.9070, test loss-0.3678, acc-0.9023\n",
      "Iter-29400, train loss-0.3041, acc-0.9200, valid loss-0.3569, acc-0.9070, test loss-0.3677, acc-0.9024\n",
      "Iter-29410, train loss-0.4222, acc-0.8400, valid loss-0.3569, acc-0.9070, test loss-0.3676, acc-0.9025\n",
      "Iter-29420, train loss-0.5532, acc-0.8000, valid loss-0.3568, acc-0.9070, test loss-0.3676, acc-0.9027\n",
      "Iter-29430, train loss-0.3120, acc-0.9200, valid loss-0.3568, acc-0.9070, test loss-0.3675, acc-0.9026\n",
      "Iter-29440, train loss-0.3327, acc-0.8800, valid loss-0.3567, acc-0.9068, test loss-0.3674, acc-0.9028\n",
      "Iter-29450, train loss-0.4455, acc-0.8600, valid loss-0.3566, acc-0.9068, test loss-0.3674, acc-0.9026\n",
      "Iter-29460, train loss-0.4714, acc-0.8600, valid loss-0.3565, acc-0.9068, test loss-0.3673, acc-0.9027\n",
      "Iter-29470, train loss-0.3938, acc-0.8800, valid loss-0.3565, acc-0.9068, test loss-0.3672, acc-0.9029\n",
      "Iter-29480, train loss-0.5263, acc-0.8600, valid loss-0.3563, acc-0.9068, test loss-0.3671, acc-0.9029\n",
      "Iter-29490, train loss-0.2428, acc-0.9400, valid loss-0.3563, acc-0.9070, test loss-0.3670, acc-0.9030\n",
      "Iter-29500, train loss-0.2958, acc-0.9200, valid loss-0.3562, acc-0.9070, test loss-0.3670, acc-0.9030\n",
      "Iter-29510, train loss-0.4022, acc-0.8800, valid loss-0.3562, acc-0.9070, test loss-0.3669, acc-0.9031\n",
      "Iter-29520, train loss-0.3624, acc-0.9200, valid loss-0.3561, acc-0.9070, test loss-0.3669, acc-0.9031\n",
      "Iter-29530, train loss-0.5275, acc-0.8200, valid loss-0.3561, acc-0.9072, test loss-0.3668, acc-0.9031\n",
      "Iter-29540, train loss-0.4682, acc-0.8800, valid loss-0.3560, acc-0.9072, test loss-0.3667, acc-0.9033\n",
      "Iter-29550, train loss-0.3983, acc-0.9200, valid loss-0.3560, acc-0.9070, test loss-0.3667, acc-0.9033\n",
      "Iter-29560, train loss-0.4074, acc-0.8400, valid loss-0.3558, acc-0.9068, test loss-0.3667, acc-0.9032\n",
      "Iter-29570, train loss-0.3456, acc-0.9200, valid loss-0.3557, acc-0.9068, test loss-0.3666, acc-0.9032\n",
      "Iter-29580, train loss-0.2504, acc-0.9200, valid loss-0.3557, acc-0.9068, test loss-0.3665, acc-0.9030\n",
      "Iter-29590, train loss-0.4509, acc-0.8800, valid loss-0.3556, acc-0.9068, test loss-0.3665, acc-0.9031\n",
      "Iter-29600, train loss-0.2126, acc-0.9600, valid loss-0.3555, acc-0.9068, test loss-0.3664, acc-0.9030\n",
      "Iter-29610, train loss-0.5527, acc-0.8200, valid loss-0.3555, acc-0.9064, test loss-0.3663, acc-0.9030\n",
      "Iter-29620, train loss-0.4369, acc-0.9000, valid loss-0.3554, acc-0.9066, test loss-0.3662, acc-0.9034\n",
      "Iter-29630, train loss-0.3601, acc-0.9000, valid loss-0.3554, acc-0.9068, test loss-0.3662, acc-0.9036\n",
      "Iter-29640, train loss-0.5546, acc-0.8600, valid loss-0.3553, acc-0.9070, test loss-0.3662, acc-0.9034\n",
      "Iter-29650, train loss-0.3165, acc-0.9000, valid loss-0.3551, acc-0.9070, test loss-0.3661, acc-0.9034\n",
      "Iter-29660, train loss-0.3013, acc-0.9200, valid loss-0.3550, acc-0.9070, test loss-0.3661, acc-0.9035\n",
      "Iter-29670, train loss-0.2373, acc-0.9400, valid loss-0.3550, acc-0.9074, test loss-0.3660, acc-0.9034\n",
      "Iter-29680, train loss-0.4024, acc-0.8800, valid loss-0.3549, acc-0.9074, test loss-0.3660, acc-0.9034\n",
      "Iter-29690, train loss-0.4842, acc-0.8800, valid loss-0.3549, acc-0.9074, test loss-0.3659, acc-0.9035\n",
      "Iter-29700, train loss-0.2557, acc-0.9800, valid loss-0.3549, acc-0.9074, test loss-0.3658, acc-0.9037\n",
      "Iter-29710, train loss-0.3054, acc-0.9400, valid loss-0.3549, acc-0.9070, test loss-0.3657, acc-0.9035\n",
      "Iter-29720, train loss-0.2529, acc-0.9600, valid loss-0.3548, acc-0.9070, test loss-0.3657, acc-0.9035\n",
      "Iter-29730, train loss-0.4608, acc-0.9200, valid loss-0.3548, acc-0.9070, test loss-0.3656, acc-0.9036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-29740, train loss-0.5090, acc-0.8400, valid loss-0.3548, acc-0.9076, test loss-0.3655, acc-0.9036\n",
      "Iter-29750, train loss-0.4057, acc-0.8400, valid loss-0.3547, acc-0.9076, test loss-0.3655, acc-0.9036\n",
      "Iter-29760, train loss-0.4136, acc-0.8400, valid loss-0.3546, acc-0.9078, test loss-0.3655, acc-0.9039\n",
      "Iter-29770, train loss-0.4517, acc-0.8800, valid loss-0.3545, acc-0.9078, test loss-0.3654, acc-0.9037\n",
      "Iter-29780, train loss-0.6225, acc-0.8200, valid loss-0.3545, acc-0.9074, test loss-0.3653, acc-0.9037\n",
      "Iter-29790, train loss-0.7052, acc-0.7600, valid loss-0.3544, acc-0.9074, test loss-0.3653, acc-0.9037\n",
      "Iter-29800, train loss-0.2714, acc-0.9200, valid loss-0.3543, acc-0.9070, test loss-0.3652, acc-0.9037\n",
      "Iter-29810, train loss-0.4621, acc-0.8600, valid loss-0.3543, acc-0.9076, test loss-0.3651, acc-0.9036\n",
      "Iter-29820, train loss-0.3013, acc-0.9200, valid loss-0.3542, acc-0.9076, test loss-0.3650, acc-0.9036\n",
      "Iter-29830, train loss-0.2650, acc-0.9200, valid loss-0.3542, acc-0.9072, test loss-0.3650, acc-0.9035\n",
      "Iter-29840, train loss-0.2634, acc-0.9400, valid loss-0.3541, acc-0.9072, test loss-0.3649, acc-0.9034\n",
      "Iter-29850, train loss-0.3572, acc-0.8800, valid loss-0.3540, acc-0.9070, test loss-0.3649, acc-0.9034\n",
      "Iter-29860, train loss-0.3155, acc-0.9200, valid loss-0.3540, acc-0.9072, test loss-0.3648, acc-0.9034\n",
      "Iter-29870, train loss-0.3604, acc-0.8800, valid loss-0.3539, acc-0.9074, test loss-0.3647, acc-0.9035\n",
      "Iter-29880, train loss-0.4961, acc-0.9000, valid loss-0.3538, acc-0.9076, test loss-0.3647, acc-0.9035\n",
      "Iter-29890, train loss-0.2195, acc-0.9400, valid loss-0.3537, acc-0.9074, test loss-0.3646, acc-0.9030\n",
      "Iter-29900, train loss-0.3829, acc-0.9400, valid loss-0.3536, acc-0.9074, test loss-0.3646, acc-0.9032\n",
      "Iter-29910, train loss-0.3654, acc-0.9200, valid loss-0.3536, acc-0.9072, test loss-0.3645, acc-0.9031\n",
      "Iter-29920, train loss-0.4150, acc-0.9000, valid loss-0.3536, acc-0.9074, test loss-0.3644, acc-0.9034\n",
      "Iter-29930, train loss-0.3607, acc-0.8600, valid loss-0.3535, acc-0.9074, test loss-0.3643, acc-0.9034\n",
      "Iter-29940, train loss-0.4364, acc-0.9000, valid loss-0.3535, acc-0.9076, test loss-0.3643, acc-0.9036\n",
      "Iter-29950, train loss-0.4764, acc-0.9000, valid loss-0.3534, acc-0.9076, test loss-0.3643, acc-0.9032\n",
      "Iter-29960, train loss-0.3322, acc-0.9000, valid loss-0.3533, acc-0.9076, test loss-0.3642, acc-0.9035\n",
      "Iter-29970, train loss-0.3399, acc-0.9200, valid loss-0.3533, acc-0.9074, test loss-0.3641, acc-0.9034\n",
      "Iter-29980, train loss-0.3570, acc-0.8800, valid loss-0.3532, acc-0.9078, test loss-0.3641, acc-0.9035\n",
      "Iter-29990, train loss-0.2914, acc-0.9200, valid loss-0.3532, acc-0.9076, test loss-0.3640, acc-0.9034\n",
      "Iter-30000, train loss-0.3755, acc-0.8800, valid loss-0.3531, acc-0.9076, test loss-0.3639, acc-0.9033\n",
      "Iter-30010, train loss-0.5398, acc-0.8400, valid loss-0.3531, acc-0.9076, test loss-0.3639, acc-0.9034\n",
      "Iter-30020, train loss-0.3748, acc-0.9200, valid loss-0.3530, acc-0.9080, test loss-0.3639, acc-0.9035\n",
      "Iter-30030, train loss-0.3617, acc-0.8800, valid loss-0.3530, acc-0.9080, test loss-0.3639, acc-0.9035\n",
      "Iter-30040, train loss-0.6605, acc-0.8000, valid loss-0.3529, acc-0.9080, test loss-0.3639, acc-0.9035\n",
      "Iter-30050, train loss-0.3565, acc-0.9000, valid loss-0.3528, acc-0.9080, test loss-0.3638, acc-0.9037\n",
      "Iter-30060, train loss-0.2938, acc-0.9400, valid loss-0.3527, acc-0.9080, test loss-0.3637, acc-0.9035\n",
      "Iter-30070, train loss-0.1607, acc-0.9800, valid loss-0.3526, acc-0.9080, test loss-0.3637, acc-0.9036\n",
      "Iter-30080, train loss-0.3695, acc-0.9200, valid loss-0.3526, acc-0.9078, test loss-0.3637, acc-0.9039\n",
      "Iter-30090, train loss-0.2482, acc-0.9400, valid loss-0.3525, acc-0.9080, test loss-0.3636, acc-0.9038\n",
      "Iter-30100, train loss-0.5276, acc-0.8800, valid loss-0.3525, acc-0.9080, test loss-0.3635, acc-0.9039\n",
      "Iter-30110, train loss-0.4386, acc-0.8800, valid loss-0.3524, acc-0.9082, test loss-0.3634, acc-0.9038\n",
      "Iter-30120, train loss-0.3423, acc-0.9400, valid loss-0.3524, acc-0.9084, test loss-0.3634, acc-0.9036\n",
      "Iter-30130, train loss-0.2926, acc-0.9400, valid loss-0.3523, acc-0.9086, test loss-0.3633, acc-0.9039\n",
      "Iter-30140, train loss-0.4267, acc-0.8600, valid loss-0.3522, acc-0.9088, test loss-0.3633, acc-0.9041\n",
      "Iter-30150, train loss-0.5204, acc-0.8200, valid loss-0.3523, acc-0.9084, test loss-0.3632, acc-0.9042\n",
      "Iter-30160, train loss-0.5197, acc-0.9200, valid loss-0.3522, acc-0.9082, test loss-0.3632, acc-0.9040\n",
      "Iter-30170, train loss-0.5025, acc-0.8800, valid loss-0.3522, acc-0.9078, test loss-0.3631, acc-0.9041\n",
      "Iter-30180, train loss-0.3864, acc-0.8800, valid loss-0.3521, acc-0.9078, test loss-0.3631, acc-0.9043\n",
      "Iter-30190, train loss-0.4434, acc-0.8800, valid loss-0.3521, acc-0.9076, test loss-0.3630, acc-0.9040\n",
      "Iter-30200, train loss-0.2873, acc-0.9000, valid loss-0.3520, acc-0.9080, test loss-0.3629, acc-0.9042\n",
      "Iter-30210, train loss-0.2291, acc-0.9400, valid loss-0.3520, acc-0.9084, test loss-0.3629, acc-0.9043\n",
      "Iter-30220, train loss-0.4397, acc-0.8600, valid loss-0.3519, acc-0.9086, test loss-0.3628, acc-0.9041\n",
      "Iter-30230, train loss-0.2279, acc-0.9800, valid loss-0.3518, acc-0.9082, test loss-0.3627, acc-0.9041\n",
      "Iter-30240, train loss-0.3251, acc-0.8800, valid loss-0.3517, acc-0.9082, test loss-0.3626, acc-0.9043\n",
      "Iter-30250, train loss-0.4667, acc-0.8600, valid loss-0.3517, acc-0.9082, test loss-0.3626, acc-0.9044\n",
      "Iter-30260, train loss-0.4927, acc-0.7800, valid loss-0.3517, acc-0.9082, test loss-0.3625, acc-0.9045\n",
      "Iter-30270, train loss-0.5075, acc-0.8000, valid loss-0.3516, acc-0.9086, test loss-0.3625, acc-0.9042\n",
      "Iter-30280, train loss-0.3709, acc-0.9000, valid loss-0.3515, acc-0.9086, test loss-0.3624, acc-0.9042\n",
      "Iter-30290, train loss-0.2865, acc-0.9400, valid loss-0.3514, acc-0.9088, test loss-0.3624, acc-0.9043\n",
      "Iter-30300, train loss-0.3696, acc-0.9200, valid loss-0.3514, acc-0.9090, test loss-0.3623, acc-0.9041\n",
      "Iter-30310, train loss-0.3528, acc-0.8800, valid loss-0.3514, acc-0.9088, test loss-0.3623, acc-0.9041\n",
      "Iter-30320, train loss-0.3017, acc-0.9200, valid loss-0.3513, acc-0.9086, test loss-0.3622, acc-0.9044\n",
      "Iter-30330, train loss-0.4809, acc-0.8400, valid loss-0.3513, acc-0.9090, test loss-0.3622, acc-0.9044\n",
      "Iter-30340, train loss-0.2656, acc-0.9400, valid loss-0.3512, acc-0.9086, test loss-0.3621, acc-0.9042\n",
      "Iter-30350, train loss-0.2870, acc-0.9000, valid loss-0.3512, acc-0.9084, test loss-0.3620, acc-0.9044\n",
      "Iter-30360, train loss-0.4420, acc-0.9400, valid loss-0.3512, acc-0.9082, test loss-0.3619, acc-0.9043\n",
      "Iter-30370, train loss-0.3934, acc-0.8800, valid loss-0.3511, acc-0.9080, test loss-0.3619, acc-0.9044\n",
      "Iter-30380, train loss-0.2736, acc-0.9400, valid loss-0.3511, acc-0.9080, test loss-0.3618, acc-0.9045\n",
      "Iter-30390, train loss-0.4626, acc-0.9000, valid loss-0.3510, acc-0.9078, test loss-0.3617, acc-0.9045\n",
      "Iter-30400, train loss-0.2344, acc-0.9400, valid loss-0.3509, acc-0.9080, test loss-0.3616, acc-0.9045\n",
      "Iter-30410, train loss-0.4380, acc-0.8800, valid loss-0.3509, acc-0.9080, test loss-0.3616, acc-0.9042\n",
      "Iter-30420, train loss-0.4443, acc-0.9000, valid loss-0.3509, acc-0.9080, test loss-0.3615, acc-0.9042\n",
      "Iter-30430, train loss-0.2597, acc-0.9200, valid loss-0.3508, acc-0.9080, test loss-0.3614, acc-0.9044\n",
      "Iter-30440, train loss-0.4109, acc-0.8600, valid loss-0.3507, acc-0.9080, test loss-0.3613, acc-0.9042\n",
      "Iter-30450, train loss-0.2970, acc-0.9400, valid loss-0.3507, acc-0.9078, test loss-0.3612, acc-0.9043\n",
      "Iter-30460, train loss-0.4007, acc-0.8800, valid loss-0.3506, acc-0.9078, test loss-0.3611, acc-0.9043\n",
      "Iter-30470, train loss-0.4550, acc-0.8800, valid loss-0.3506, acc-0.9080, test loss-0.3611, acc-0.9044\n",
      "Iter-30480, train loss-0.3763, acc-0.8600, valid loss-0.3505, acc-0.9082, test loss-0.3610, acc-0.9044\n",
      "Iter-30490, train loss-0.5446, acc-0.8600, valid loss-0.3504, acc-0.9084, test loss-0.3610, acc-0.9046\n",
      "Iter-30500, train loss-0.2659, acc-0.9200, valid loss-0.3503, acc-0.9080, test loss-0.3609, acc-0.9045\n",
      "Iter-30510, train loss-0.4406, acc-0.8800, valid loss-0.3503, acc-0.9080, test loss-0.3609, acc-0.9045\n",
      "Iter-30520, train loss-0.4433, acc-0.8800, valid loss-0.3503, acc-0.9082, test loss-0.3608, acc-0.9046\n",
      "Iter-30530, train loss-0.3499, acc-0.8800, valid loss-0.3502, acc-0.9082, test loss-0.3607, acc-0.9048\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-30540, train loss-0.3062, acc-0.9000, valid loss-0.3501, acc-0.9082, test loss-0.3606, acc-0.9049\n",
      "Iter-30550, train loss-0.2849, acc-0.9600, valid loss-0.3501, acc-0.9080, test loss-0.3605, acc-0.9045\n",
      "Iter-30560, train loss-0.6897, acc-0.8400, valid loss-0.3501, acc-0.9080, test loss-0.3604, acc-0.9049\n",
      "Iter-30570, train loss-0.3763, acc-0.8600, valid loss-0.3500, acc-0.9084, test loss-0.3604, acc-0.9048\n",
      "Iter-30580, train loss-0.3273, acc-0.9200, valid loss-0.3499, acc-0.9088, test loss-0.3603, acc-0.9049\n",
      "Iter-30590, train loss-0.4398, acc-0.8400, valid loss-0.3499, acc-0.9084, test loss-0.3603, acc-0.9048\n",
      "Iter-30600, train loss-0.4883, acc-0.8800, valid loss-0.3499, acc-0.9082, test loss-0.3603, acc-0.9045\n",
      "Iter-30610, train loss-0.4237, acc-0.8800, valid loss-0.3498, acc-0.9082, test loss-0.3602, acc-0.9043\n",
      "Iter-30620, train loss-0.5557, acc-0.8400, valid loss-0.3497, acc-0.9082, test loss-0.3602, acc-0.9044\n",
      "Iter-30630, train loss-0.3838, acc-0.9000, valid loss-0.3496, acc-0.9086, test loss-0.3600, acc-0.9048\n",
      "Iter-30640, train loss-0.4898, acc-0.9200, valid loss-0.3496, acc-0.9086, test loss-0.3600, acc-0.9048\n",
      "Iter-30650, train loss-0.2811, acc-0.9600, valid loss-0.3496, acc-0.9088, test loss-0.3599, acc-0.9043\n",
      "Iter-30660, train loss-0.4435, acc-0.8600, valid loss-0.3495, acc-0.9084, test loss-0.3599, acc-0.9046\n",
      "Iter-30670, train loss-0.3520, acc-0.9000, valid loss-0.3495, acc-0.9086, test loss-0.3598, acc-0.9045\n",
      "Iter-30680, train loss-0.3235, acc-0.9200, valid loss-0.3494, acc-0.9086, test loss-0.3597, acc-0.9043\n",
      "Iter-30690, train loss-0.3957, acc-0.8800, valid loss-0.3493, acc-0.9086, test loss-0.3597, acc-0.9044\n",
      "Iter-30700, train loss-0.3087, acc-0.8800, valid loss-0.3493, acc-0.9086, test loss-0.3596, acc-0.9046\n",
      "Iter-30710, train loss-0.2766, acc-0.9600, valid loss-0.3493, acc-0.9086, test loss-0.3596, acc-0.9046\n",
      "Iter-30720, train loss-0.3101, acc-0.9200, valid loss-0.3492, acc-0.9088, test loss-0.3595, acc-0.9047\n",
      "Iter-30730, train loss-0.3047, acc-0.9200, valid loss-0.3492, acc-0.9084, test loss-0.3595, acc-0.9049\n",
      "Iter-30740, train loss-0.2733, acc-0.9200, valid loss-0.3491, acc-0.9084, test loss-0.3594, acc-0.9047\n",
      "Iter-30750, train loss-0.4482, acc-0.8400, valid loss-0.3491, acc-0.9082, test loss-0.3594, acc-0.9045\n",
      "Iter-30760, train loss-0.2113, acc-0.9800, valid loss-0.3491, acc-0.9084, test loss-0.3593, acc-0.9047\n",
      "Iter-30770, train loss-0.2541, acc-0.9200, valid loss-0.3490, acc-0.9082, test loss-0.3593, acc-0.9045\n",
      "Iter-30780, train loss-0.2539, acc-0.9400, valid loss-0.3490, acc-0.9084, test loss-0.3592, acc-0.9046\n",
      "Iter-30790, train loss-0.3603, acc-0.9000, valid loss-0.3490, acc-0.9088, test loss-0.3591, acc-0.9047\n",
      "Iter-30800, train loss-0.2414, acc-0.9400, valid loss-0.3489, acc-0.9088, test loss-0.3591, acc-0.9047\n",
      "Iter-30810, train loss-0.5108, acc-0.8400, valid loss-0.3489, acc-0.9088, test loss-0.3590, acc-0.9047\n",
      "Iter-30820, train loss-0.2953, acc-0.9000, valid loss-0.3489, acc-0.9086, test loss-0.3589, acc-0.9049\n",
      "Iter-30830, train loss-0.3529, acc-0.8800, valid loss-0.3488, acc-0.9084, test loss-0.3589, acc-0.9051\n",
      "Iter-30840, train loss-0.1719, acc-0.9800, valid loss-0.3488, acc-0.9086, test loss-0.3588, acc-0.9048\n",
      "Iter-30850, train loss-0.2807, acc-0.9400, valid loss-0.3488, acc-0.9086, test loss-0.3588, acc-0.9045\n",
      "Iter-30860, train loss-0.6288, acc-0.8000, valid loss-0.3487, acc-0.9086, test loss-0.3587, acc-0.9049\n",
      "Iter-30870, train loss-0.4309, acc-0.8800, valid loss-0.3487, acc-0.9084, test loss-0.3587, acc-0.9049\n",
      "Iter-30880, train loss-0.1972, acc-0.9800, valid loss-0.3486, acc-0.9084, test loss-0.3586, acc-0.9047\n",
      "Iter-30890, train loss-0.3367, acc-0.9000, valid loss-0.3486, acc-0.9086, test loss-0.3586, acc-0.9048\n",
      "Iter-30900, train loss-0.3927, acc-0.8600, valid loss-0.3485, acc-0.9086, test loss-0.3586, acc-0.9048\n",
      "Iter-30910, train loss-0.3967, acc-0.8800, valid loss-0.3485, acc-0.9084, test loss-0.3585, acc-0.9049\n",
      "Iter-30920, train loss-0.3234, acc-0.9200, valid loss-0.3484, acc-0.9084, test loss-0.3584, acc-0.9048\n",
      "Iter-30930, train loss-0.4502, acc-0.8600, valid loss-0.3484, acc-0.9084, test loss-0.3583, acc-0.9047\n",
      "Iter-30940, train loss-0.2541, acc-0.9200, valid loss-0.3484, acc-0.9082, test loss-0.3583, acc-0.9050\n",
      "Iter-30950, train loss-0.3471, acc-0.9000, valid loss-0.3484, acc-0.9082, test loss-0.3583, acc-0.9046\n",
      "Iter-30960, train loss-0.5005, acc-0.9000, valid loss-0.3483, acc-0.9084, test loss-0.3582, acc-0.9047\n",
      "Iter-30970, train loss-0.2919, acc-0.9200, valid loss-0.3483, acc-0.9086, test loss-0.3582, acc-0.9050\n",
      "Iter-30980, train loss-0.2652, acc-0.9400, valid loss-0.3482, acc-0.9084, test loss-0.3581, acc-0.9049\n",
      "Iter-30990, train loss-0.3594, acc-0.9200, valid loss-0.3481, acc-0.9086, test loss-0.3581, acc-0.9049\n",
      "Iter-31000, train loss-0.4106, acc-0.8800, valid loss-0.3481, acc-0.9086, test loss-0.3580, acc-0.9050\n",
      "Iter-31010, train loss-0.2064, acc-0.9600, valid loss-0.3481, acc-0.9084, test loss-0.3579, acc-0.9046\n",
      "Iter-31020, train loss-0.3424, acc-0.8800, valid loss-0.3480, acc-0.9086, test loss-0.3578, acc-0.9051\n",
      "Iter-31030, train loss-0.3495, acc-0.9200, valid loss-0.3478, acc-0.9084, test loss-0.3577, acc-0.9049\n",
      "Iter-31040, train loss-0.5308, acc-0.8400, valid loss-0.3478, acc-0.9086, test loss-0.3576, acc-0.9050\n",
      "Iter-31050, train loss-0.3377, acc-0.9200, valid loss-0.3478, acc-0.9084, test loss-0.3575, acc-0.9050\n",
      "Iter-31060, train loss-0.2529, acc-0.9200, valid loss-0.3477, acc-0.9082, test loss-0.3575, acc-0.9052\n",
      "Iter-31070, train loss-0.3060, acc-0.9000, valid loss-0.3476, acc-0.9086, test loss-0.3574, acc-0.9045\n",
      "Iter-31080, train loss-0.2531, acc-0.9000, valid loss-0.3475, acc-0.9088, test loss-0.3573, acc-0.9045\n",
      "Iter-31090, train loss-0.2242, acc-0.9600, valid loss-0.3474, acc-0.9082, test loss-0.3573, acc-0.9046\n",
      "Iter-31100, train loss-0.3722, acc-0.9000, valid loss-0.3474, acc-0.9084, test loss-0.3572, acc-0.9045\n",
      "Iter-31110, train loss-0.4478, acc-0.8400, valid loss-0.3473, acc-0.9084, test loss-0.3572, acc-0.9044\n",
      "Iter-31120, train loss-0.2691, acc-0.9600, valid loss-0.3473, acc-0.9084, test loss-0.3572, acc-0.9042\n",
      "Iter-31130, train loss-0.3691, acc-0.9000, valid loss-0.3472, acc-0.9086, test loss-0.3571, acc-0.9046\n",
      "Iter-31140, train loss-0.3886, acc-0.8800, valid loss-0.3472, acc-0.9086, test loss-0.3571, acc-0.9044\n",
      "Iter-31150, train loss-0.3800, acc-0.9200, valid loss-0.3471, acc-0.9086, test loss-0.3570, acc-0.9047\n",
      "Iter-31160, train loss-0.2925, acc-0.9000, valid loss-0.3471, acc-0.9090, test loss-0.3569, acc-0.9051\n",
      "Iter-31170, train loss-0.4978, acc-0.8800, valid loss-0.3470, acc-0.9084, test loss-0.3568, acc-0.9051\n",
      "Iter-31180, train loss-0.2100, acc-0.9600, valid loss-0.3469, acc-0.9088, test loss-0.3568, acc-0.9051\n",
      "Iter-31190, train loss-0.2606, acc-0.9400, valid loss-0.3469, acc-0.9088, test loss-0.3567, acc-0.9050\n",
      "Iter-31200, train loss-0.2374, acc-0.9400, valid loss-0.3469, acc-0.9086, test loss-0.3567, acc-0.9049\n",
      "Iter-31210, train loss-0.5359, acc-0.8400, valid loss-0.3468, acc-0.9088, test loss-0.3566, acc-0.9051\n",
      "Iter-31220, train loss-0.2156, acc-0.9600, valid loss-0.3467, acc-0.9086, test loss-0.3565, acc-0.9053\n",
      "Iter-31230, train loss-0.3817, acc-0.9200, valid loss-0.3467, acc-0.9090, test loss-0.3565, acc-0.9054\n",
      "Iter-31240, train loss-0.2556, acc-0.9400, valid loss-0.3466, acc-0.9086, test loss-0.3565, acc-0.9051\n",
      "Iter-31250, train loss-0.4109, acc-0.9000, valid loss-0.3465, acc-0.9084, test loss-0.3564, acc-0.9049\n",
      "Iter-31260, train loss-0.3866, acc-0.9000, valid loss-0.3465, acc-0.9084, test loss-0.3563, acc-0.9046\n",
      "Iter-31270, train loss-0.3519, acc-0.9000, valid loss-0.3464, acc-0.9084, test loss-0.3563, acc-0.9046\n",
      "Iter-31280, train loss-0.2593, acc-0.9200, valid loss-0.3464, acc-0.9084, test loss-0.3562, acc-0.9048\n",
      "Iter-31290, train loss-0.5767, acc-0.8600, valid loss-0.3464, acc-0.9086, test loss-0.3562, acc-0.9048\n",
      "Iter-31300, train loss-0.4962, acc-0.8400, valid loss-0.3463, acc-0.9088, test loss-0.3561, acc-0.9051\n",
      "Iter-31310, train loss-0.5008, acc-0.9000, valid loss-0.3462, acc-0.9090, test loss-0.3560, acc-0.9050\n",
      "Iter-31320, train loss-0.2236, acc-0.9800, valid loss-0.3461, acc-0.9090, test loss-0.3560, acc-0.9046\n",
      "Iter-31330, train loss-0.2261, acc-0.9400, valid loss-0.3461, acc-0.9088, test loss-0.3559, acc-0.9046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-31340, train loss-0.3059, acc-0.8800, valid loss-0.3461, acc-0.9090, test loss-0.3559, acc-0.9047\n",
      "Iter-31350, train loss-0.5565, acc-0.8400, valid loss-0.3460, acc-0.9082, test loss-0.3559, acc-0.9046\n",
      "Iter-31360, train loss-0.4576, acc-0.9000, valid loss-0.3460, acc-0.9086, test loss-0.3558, acc-0.9048\n",
      "Iter-31370, train loss-0.3024, acc-0.9200, valid loss-0.3459, acc-0.9088, test loss-0.3557, acc-0.9049\n",
      "Iter-31380, train loss-0.2755, acc-0.9200, valid loss-0.3458, acc-0.9088, test loss-0.3557, acc-0.9051\n",
      "Iter-31390, train loss-0.3844, acc-0.9200, valid loss-0.3457, acc-0.9086, test loss-0.3556, acc-0.9051\n",
      "Iter-31400, train loss-0.3484, acc-0.9200, valid loss-0.3456, acc-0.9088, test loss-0.3556, acc-0.9050\n",
      "Iter-31410, train loss-0.5332, acc-0.8200, valid loss-0.3456, acc-0.9088, test loss-0.3556, acc-0.9049\n",
      "Iter-31420, train loss-0.3568, acc-0.8400, valid loss-0.3455, acc-0.9088, test loss-0.3555, acc-0.9049\n",
      "Iter-31430, train loss-0.3003, acc-0.9200, valid loss-0.3455, acc-0.9086, test loss-0.3554, acc-0.9051\n",
      "Iter-31440, train loss-0.3140, acc-0.9200, valid loss-0.3454, acc-0.9088, test loss-0.3554, acc-0.9051\n",
      "Iter-31450, train loss-0.3106, acc-0.9200, valid loss-0.3453, acc-0.9088, test loss-0.3553, acc-0.9055\n",
      "Iter-31460, train loss-0.2093, acc-0.9600, valid loss-0.3453, acc-0.9090, test loss-0.3552, acc-0.9051\n",
      "Iter-31470, train loss-0.4168, acc-0.9200, valid loss-0.3452, acc-0.9090, test loss-0.3552, acc-0.9050\n",
      "Iter-31480, train loss-0.1687, acc-0.9800, valid loss-0.3451, acc-0.9090, test loss-0.3552, acc-0.9050\n",
      "Iter-31490, train loss-0.4862, acc-0.8800, valid loss-0.3451, acc-0.9094, test loss-0.3552, acc-0.9051\n",
      "Iter-31500, train loss-0.2814, acc-0.9200, valid loss-0.3450, acc-0.9090, test loss-0.3551, acc-0.9050\n",
      "Iter-31510, train loss-0.4309, acc-0.8200, valid loss-0.3449, acc-0.9090, test loss-0.3551, acc-0.9051\n",
      "Iter-31520, train loss-0.4019, acc-0.8800, valid loss-0.3449, acc-0.9090, test loss-0.3550, acc-0.9054\n",
      "Iter-31530, train loss-0.2264, acc-0.9600, valid loss-0.3448, acc-0.9090, test loss-0.3550, acc-0.9055\n",
      "Iter-31540, train loss-0.3300, acc-0.9400, valid loss-0.3447, acc-0.9088, test loss-0.3549, acc-0.9055\n",
      "Iter-31550, train loss-0.4984, acc-0.8600, valid loss-0.3447, acc-0.9088, test loss-0.3548, acc-0.9058\n",
      "Iter-31560, train loss-0.2747, acc-0.9600, valid loss-0.3446, acc-0.9088, test loss-0.3548, acc-0.9058\n",
      "Iter-31570, train loss-0.4629, acc-0.9200, valid loss-0.3445, acc-0.9088, test loss-0.3547, acc-0.9059\n",
      "Iter-31580, train loss-0.3383, acc-0.9200, valid loss-0.3444, acc-0.9088, test loss-0.3546, acc-0.9062\n",
      "Iter-31590, train loss-0.6975, acc-0.8200, valid loss-0.3444, acc-0.9090, test loss-0.3546, acc-0.9060\n",
      "Iter-31600, train loss-0.3057, acc-0.9200, valid loss-0.3444, acc-0.9092, test loss-0.3545, acc-0.9059\n",
      "Iter-31610, train loss-0.1972, acc-0.9800, valid loss-0.3443, acc-0.9094, test loss-0.3544, acc-0.9060\n",
      "Iter-31620, train loss-0.4700, acc-0.9200, valid loss-0.3443, acc-0.9092, test loss-0.3543, acc-0.9060\n",
      "Iter-31630, train loss-0.3087, acc-0.9200, valid loss-0.3442, acc-0.9094, test loss-0.3543, acc-0.9062\n",
      "Iter-31640, train loss-0.4060, acc-0.8800, valid loss-0.3441, acc-0.9094, test loss-0.3542, acc-0.9063\n",
      "Iter-31650, train loss-0.4198, acc-0.8800, valid loss-0.3441, acc-0.9094, test loss-0.3542, acc-0.9061\n",
      "Iter-31660, train loss-0.4127, acc-0.8800, valid loss-0.3440, acc-0.9094, test loss-0.3541, acc-0.9064\n",
      "Iter-31670, train loss-0.4234, acc-0.8600, valid loss-0.3439, acc-0.9094, test loss-0.3540, acc-0.9063\n",
      "Iter-31680, train loss-0.2577, acc-0.9200, valid loss-0.3439, acc-0.9090, test loss-0.3540, acc-0.9066\n",
      "Iter-31690, train loss-0.3038, acc-0.9000, valid loss-0.3438, acc-0.9096, test loss-0.3539, acc-0.9064\n",
      "Iter-31700, train loss-0.3448, acc-0.8400, valid loss-0.3437, acc-0.9100, test loss-0.3538, acc-0.9065\n",
      "Iter-31710, train loss-0.3706, acc-0.8800, valid loss-0.3437, acc-0.9094, test loss-0.3538, acc-0.9065\n",
      "Iter-31720, train loss-0.4001, acc-0.8400, valid loss-0.3437, acc-0.9092, test loss-0.3537, acc-0.9066\n",
      "Iter-31730, train loss-0.1713, acc-1.0000, valid loss-0.3436, acc-0.9094, test loss-0.3537, acc-0.9064\n",
      "Iter-31740, train loss-0.5186, acc-0.8600, valid loss-0.3436, acc-0.9092, test loss-0.3536, acc-0.9060\n",
      "Iter-31750, train loss-0.5457, acc-0.8600, valid loss-0.3435, acc-0.9094, test loss-0.3536, acc-0.9060\n",
      "Iter-31760, train loss-0.4655, acc-0.8600, valid loss-0.3435, acc-0.9094, test loss-0.3536, acc-0.9062\n",
      "Iter-31770, train loss-0.3674, acc-0.8800, valid loss-0.3435, acc-0.9090, test loss-0.3535, acc-0.9060\n",
      "Iter-31780, train loss-0.4020, acc-0.8600, valid loss-0.3435, acc-0.9094, test loss-0.3534, acc-0.9058\n",
      "Iter-31790, train loss-0.3593, acc-0.8600, valid loss-0.3434, acc-0.9092, test loss-0.3534, acc-0.9060\n",
      "Iter-31800, train loss-0.3153, acc-0.9400, valid loss-0.3434, acc-0.9090, test loss-0.3533, acc-0.9061\n",
      "Iter-31810, train loss-0.4085, acc-0.8800, valid loss-0.3433, acc-0.9094, test loss-0.3532, acc-0.9059\n",
      "Iter-31820, train loss-0.5009, acc-0.8200, valid loss-0.3432, acc-0.9094, test loss-0.3532, acc-0.9062\n",
      "Iter-31830, train loss-0.4341, acc-0.9000, valid loss-0.3432, acc-0.9094, test loss-0.3532, acc-0.9065\n",
      "Iter-31840, train loss-0.2334, acc-0.9600, valid loss-0.3431, acc-0.9090, test loss-0.3531, acc-0.9065\n",
      "Iter-31850, train loss-0.4091, acc-0.8400, valid loss-0.3430, acc-0.9090, test loss-0.3530, acc-0.9066\n",
      "Iter-31860, train loss-0.4726, acc-0.8600, valid loss-0.3430, acc-0.9090, test loss-0.3530, acc-0.9065\n",
      "Iter-31870, train loss-0.3316, acc-0.9200, valid loss-0.3429, acc-0.9090, test loss-0.3529, acc-0.9065\n",
      "Iter-31880, train loss-0.2118, acc-0.9800, valid loss-0.3428, acc-0.9096, test loss-0.3529, acc-0.9064\n",
      "Iter-31890, train loss-0.2883, acc-0.9400, valid loss-0.3428, acc-0.9098, test loss-0.3528, acc-0.9064\n",
      "Iter-31900, train loss-0.5189, acc-0.8200, valid loss-0.3427, acc-0.9098, test loss-0.3527, acc-0.9064\n",
      "Iter-31910, train loss-0.2620, acc-0.9200, valid loss-0.3427, acc-0.9098, test loss-0.3527, acc-0.9066\n",
      "Iter-31920, train loss-0.3340, acc-0.9000, valid loss-0.3425, acc-0.9096, test loss-0.3527, acc-0.9067\n",
      "Iter-31930, train loss-0.4909, acc-0.8400, valid loss-0.3424, acc-0.9098, test loss-0.3527, acc-0.9065\n",
      "Iter-31940, train loss-0.3742, acc-0.9000, valid loss-0.3423, acc-0.9098, test loss-0.3526, acc-0.9065\n",
      "Iter-31950, train loss-0.5175, acc-0.8000, valid loss-0.3423, acc-0.9096, test loss-0.3526, acc-0.9064\n",
      "Iter-31960, train loss-0.5790, acc-0.8000, valid loss-0.3423, acc-0.9096, test loss-0.3525, acc-0.9060\n",
      "Iter-31970, train loss-0.3682, acc-0.8600, valid loss-0.3423, acc-0.9096, test loss-0.3524, acc-0.9063\n",
      "Iter-31980, train loss-0.3305, acc-0.9000, valid loss-0.3422, acc-0.9098, test loss-0.3524, acc-0.9061\n",
      "Iter-31990, train loss-0.2196, acc-0.9600, valid loss-0.3422, acc-0.9094, test loss-0.3523, acc-0.9063\n",
      "Iter-32000, train loss-0.4011, acc-0.9200, valid loss-0.3421, acc-0.9098, test loss-0.3523, acc-0.9064\n",
      "Iter-32010, train loss-0.3407, acc-0.9400, valid loss-0.3421, acc-0.9096, test loss-0.3523, acc-0.9063\n",
      "Iter-32020, train loss-0.2356, acc-0.9400, valid loss-0.3420, acc-0.9096, test loss-0.3522, acc-0.9066\n",
      "Iter-32030, train loss-0.4200, acc-0.8800, valid loss-0.3420, acc-0.9096, test loss-0.3522, acc-0.9065\n",
      "Iter-32040, train loss-0.6239, acc-0.8600, valid loss-0.3419, acc-0.9094, test loss-0.3521, acc-0.9066\n",
      "Iter-32050, train loss-0.3797, acc-0.9200, valid loss-0.3419, acc-0.9098, test loss-0.3521, acc-0.9068\n",
      "Iter-32060, train loss-0.4965, acc-0.9000, valid loss-0.3419, acc-0.9100, test loss-0.3521, acc-0.9067\n",
      "Iter-32070, train loss-0.3014, acc-0.9200, valid loss-0.3418, acc-0.9098, test loss-0.3520, acc-0.9067\n",
      "Iter-32080, train loss-0.4067, acc-0.9000, valid loss-0.3418, acc-0.9098, test loss-0.3520, acc-0.9067\n",
      "Iter-32090, train loss-0.2721, acc-0.9400, valid loss-0.3417, acc-0.9096, test loss-0.3520, acc-0.9067\n",
      "Iter-32100, train loss-0.2867, acc-0.9200, valid loss-0.3416, acc-0.9092, test loss-0.3519, acc-0.9067\n",
      "Iter-32110, train loss-0.3198, acc-0.8800, valid loss-0.3416, acc-0.9094, test loss-0.3519, acc-0.9068\n",
      "Iter-32120, train loss-0.5949, acc-0.8800, valid loss-0.3416, acc-0.9094, test loss-0.3519, acc-0.9066\n",
      "Iter-32130, train loss-0.2232, acc-0.9600, valid loss-0.3415, acc-0.9094, test loss-0.3518, acc-0.9066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32140, train loss-0.4161, acc-0.8800, valid loss-0.3414, acc-0.9094, test loss-0.3518, acc-0.9067\n",
      "Iter-32150, train loss-0.4183, acc-0.8600, valid loss-0.3414, acc-0.9098, test loss-0.3517, acc-0.9067\n",
      "Iter-32160, train loss-0.5856, acc-0.8400, valid loss-0.3414, acc-0.9098, test loss-0.3517, acc-0.9069\n",
      "Iter-32170, train loss-0.3219, acc-0.8800, valid loss-0.3413, acc-0.9098, test loss-0.3516, acc-0.9072\n",
      "Iter-32180, train loss-0.4960, acc-0.8200, valid loss-0.3413, acc-0.9096, test loss-0.3516, acc-0.9074\n",
      "Iter-32190, train loss-0.3023, acc-0.9200, valid loss-0.3412, acc-0.9098, test loss-0.3516, acc-0.9074\n",
      "Iter-32200, train loss-0.3791, acc-0.8600, valid loss-0.3412, acc-0.9098, test loss-0.3515, acc-0.9075\n",
      "Iter-32210, train loss-0.3271, acc-0.9200, valid loss-0.3411, acc-0.9098, test loss-0.3515, acc-0.9073\n",
      "Iter-32220, train loss-0.5287, acc-0.8600, valid loss-0.3411, acc-0.9100, test loss-0.3515, acc-0.9074\n",
      "Iter-32230, train loss-0.3202, acc-0.9400, valid loss-0.3410, acc-0.9102, test loss-0.3514, acc-0.9075\n",
      "Iter-32240, train loss-0.2802, acc-0.9400, valid loss-0.3409, acc-0.9102, test loss-0.3514, acc-0.9077\n",
      "Iter-32250, train loss-0.2317, acc-0.9800, valid loss-0.3409, acc-0.9104, test loss-0.3513, acc-0.9075\n",
      "Iter-32260, train loss-0.4652, acc-0.8800, valid loss-0.3408, acc-0.9104, test loss-0.3513, acc-0.9074\n",
      "Iter-32270, train loss-0.4357, acc-0.8800, valid loss-0.3407, acc-0.9100, test loss-0.3512, acc-0.9072\n",
      "Iter-32280, train loss-0.2894, acc-0.9200, valid loss-0.3406, acc-0.9102, test loss-0.3511, acc-0.9075\n",
      "Iter-32290, train loss-0.4884, acc-0.8600, valid loss-0.3406, acc-0.9102, test loss-0.3512, acc-0.9077\n",
      "Iter-32300, train loss-0.4084, acc-0.8800, valid loss-0.3405, acc-0.9100, test loss-0.3511, acc-0.9077\n",
      "Iter-32310, train loss-0.3782, acc-0.8800, valid loss-0.3405, acc-0.9102, test loss-0.3510, acc-0.9076\n",
      "Iter-32320, train loss-0.4841, acc-0.8600, valid loss-0.3405, acc-0.9100, test loss-0.3510, acc-0.9076\n",
      "Iter-32330, train loss-0.3473, acc-0.9200, valid loss-0.3405, acc-0.9104, test loss-0.3509, acc-0.9076\n",
      "Iter-32340, train loss-0.4476, acc-0.8800, valid loss-0.3404, acc-0.9102, test loss-0.3508, acc-0.9076\n",
      "Iter-32350, train loss-0.3302, acc-0.9000, valid loss-0.3403, acc-0.9104, test loss-0.3507, acc-0.9075\n",
      "Iter-32360, train loss-0.3391, acc-0.9200, valid loss-0.3403, acc-0.9108, test loss-0.3507, acc-0.9078\n",
      "Iter-32370, train loss-0.4537, acc-0.9000, valid loss-0.3402, acc-0.9106, test loss-0.3506, acc-0.9076\n",
      "Iter-32380, train loss-0.3396, acc-0.9200, valid loss-0.3402, acc-0.9104, test loss-0.3505, acc-0.9077\n",
      "Iter-32390, train loss-0.1368, acc-1.0000, valid loss-0.3401, acc-0.9102, test loss-0.3505, acc-0.9076\n",
      "Iter-32400, train loss-0.2660, acc-0.9200, valid loss-0.3401, acc-0.9106, test loss-0.3504, acc-0.9075\n",
      "Iter-32410, train loss-0.1826, acc-0.9800, valid loss-0.3400, acc-0.9102, test loss-0.3503, acc-0.9078\n",
      "Iter-32420, train loss-0.5007, acc-0.8200, valid loss-0.3399, acc-0.9104, test loss-0.3503, acc-0.9075\n",
      "Iter-32430, train loss-0.4644, acc-0.8600, valid loss-0.3399, acc-0.9106, test loss-0.3502, acc-0.9078\n",
      "Iter-32440, train loss-0.3239, acc-0.8400, valid loss-0.3399, acc-0.9106, test loss-0.3502, acc-0.9075\n",
      "Iter-32450, train loss-0.2795, acc-0.9200, valid loss-0.3398, acc-0.9104, test loss-0.3501, acc-0.9075\n",
      "Iter-32460, train loss-0.3443, acc-0.8800, valid loss-0.3397, acc-0.9104, test loss-0.3500, acc-0.9074\n",
      "Iter-32470, train loss-0.3578, acc-0.8600, valid loss-0.3397, acc-0.9104, test loss-0.3500, acc-0.9074\n",
      "Iter-32480, train loss-0.1826, acc-0.9600, valid loss-0.3396, acc-0.9108, test loss-0.3499, acc-0.9075\n",
      "Iter-32490, train loss-0.2267, acc-0.9200, valid loss-0.3396, acc-0.9108, test loss-0.3499, acc-0.9076\n",
      "Iter-32500, train loss-0.2678, acc-0.9200, valid loss-0.3395, acc-0.9106, test loss-0.3498, acc-0.9074\n",
      "Iter-32510, train loss-0.3191, acc-0.9400, valid loss-0.3394, acc-0.9106, test loss-0.3497, acc-0.9073\n",
      "Iter-32520, train loss-0.3743, acc-0.8800, valid loss-0.3394, acc-0.9106, test loss-0.3497, acc-0.9073\n",
      "Iter-32530, train loss-0.3540, acc-0.9000, valid loss-0.3393, acc-0.9108, test loss-0.3497, acc-0.9076\n",
      "Iter-32540, train loss-0.2902, acc-0.9600, valid loss-0.3392, acc-0.9108, test loss-0.3496, acc-0.9075\n",
      "Iter-32550, train loss-0.1994, acc-0.9600, valid loss-0.3391, acc-0.9106, test loss-0.3495, acc-0.9076\n",
      "Iter-32560, train loss-0.3642, acc-0.9000, valid loss-0.3391, acc-0.9108, test loss-0.3495, acc-0.9077\n",
      "Iter-32570, train loss-0.3539, acc-0.9400, valid loss-0.3391, acc-0.9110, test loss-0.3494, acc-0.9078\n",
      "Iter-32580, train loss-0.3516, acc-0.8800, valid loss-0.3391, acc-0.9110, test loss-0.3494, acc-0.9077\n",
      "Iter-32590, train loss-0.3409, acc-0.8800, valid loss-0.3390, acc-0.9110, test loss-0.3494, acc-0.9076\n",
      "Iter-32600, train loss-0.3643, acc-0.8800, valid loss-0.3390, acc-0.9102, test loss-0.3493, acc-0.9077\n",
      "Iter-32610, train loss-0.2584, acc-0.9200, valid loss-0.3389, acc-0.9110, test loss-0.3493, acc-0.9076\n",
      "Iter-32620, train loss-0.3304, acc-0.9000, valid loss-0.3389, acc-0.9110, test loss-0.3493, acc-0.9076\n",
      "Iter-32630, train loss-0.3073, acc-0.9400, valid loss-0.3388, acc-0.9110, test loss-0.3492, acc-0.9075\n",
      "Iter-32640, train loss-0.3673, acc-0.9000, valid loss-0.3388, acc-0.9108, test loss-0.3492, acc-0.9076\n",
      "Iter-32650, train loss-0.3523, acc-0.9200, valid loss-0.3386, acc-0.9112, test loss-0.3492, acc-0.9075\n",
      "Iter-32660, train loss-0.4128, acc-0.9000, valid loss-0.3386, acc-0.9110, test loss-0.3492, acc-0.9075\n",
      "Iter-32670, train loss-0.3790, acc-0.9400, valid loss-0.3386, acc-0.9112, test loss-0.3491, acc-0.9076\n",
      "Iter-32680, train loss-0.2991, acc-0.9200, valid loss-0.3385, acc-0.9108, test loss-0.3491, acc-0.9077\n",
      "Iter-32690, train loss-0.2946, acc-0.9400, valid loss-0.3385, acc-0.9108, test loss-0.3490, acc-0.9076\n",
      "Iter-32700, train loss-0.5285, acc-0.9000, valid loss-0.3384, acc-0.9108, test loss-0.3489, acc-0.9078\n",
      "Iter-32710, train loss-0.5346, acc-0.8800, valid loss-0.3384, acc-0.9104, test loss-0.3489, acc-0.9077\n",
      "Iter-32720, train loss-0.3006, acc-0.9400, valid loss-0.3382, acc-0.9106, test loss-0.3489, acc-0.9079\n",
      "Iter-32730, train loss-0.3327, acc-0.9400, valid loss-0.3382, acc-0.9108, test loss-0.3488, acc-0.9078\n",
      "Iter-32740, train loss-0.6844, acc-0.8600, valid loss-0.3381, acc-0.9112, test loss-0.3488, acc-0.9077\n",
      "Iter-32750, train loss-0.2483, acc-0.9600, valid loss-0.3381, acc-0.9114, test loss-0.3488, acc-0.9077\n",
      "Iter-32760, train loss-0.2604, acc-0.9400, valid loss-0.3380, acc-0.9110, test loss-0.3487, acc-0.9077\n",
      "Iter-32770, train loss-0.2677, acc-0.9200, valid loss-0.3380, acc-0.9108, test loss-0.3486, acc-0.9076\n",
      "Iter-32780, train loss-0.4659, acc-0.9200, valid loss-0.3379, acc-0.9116, test loss-0.3486, acc-0.9075\n",
      "Iter-32790, train loss-0.3120, acc-0.9400, valid loss-0.3378, acc-0.9120, test loss-0.3485, acc-0.9075\n",
      "Iter-32800, train loss-0.4818, acc-0.8600, valid loss-0.3378, acc-0.9122, test loss-0.3485, acc-0.9075\n",
      "Iter-32810, train loss-0.3171, acc-0.9400, valid loss-0.3378, acc-0.9122, test loss-0.3484, acc-0.9074\n",
      "Iter-32820, train loss-0.2894, acc-0.9000, valid loss-0.3378, acc-0.9122, test loss-0.3483, acc-0.9076\n",
      "Iter-32830, train loss-0.2214, acc-0.9600, valid loss-0.3377, acc-0.9122, test loss-0.3483, acc-0.9077\n",
      "Iter-32840, train loss-0.3908, acc-0.8600, valid loss-0.3376, acc-0.9120, test loss-0.3483, acc-0.9075\n",
      "Iter-32850, train loss-0.4733, acc-0.8800, valid loss-0.3376, acc-0.9124, test loss-0.3482, acc-0.9075\n",
      "Iter-32860, train loss-0.2221, acc-0.9800, valid loss-0.3375, acc-0.9120, test loss-0.3482, acc-0.9074\n",
      "Iter-32870, train loss-0.3586, acc-0.8800, valid loss-0.3375, acc-0.9124, test loss-0.3481, acc-0.9077\n",
      "Iter-32880, train loss-0.3650, acc-0.9200, valid loss-0.3375, acc-0.9122, test loss-0.3481, acc-0.9080\n",
      "Iter-32890, train loss-0.3961, acc-0.9000, valid loss-0.3374, acc-0.9122, test loss-0.3480, acc-0.9080\n",
      "Iter-32900, train loss-0.2651, acc-0.9400, valid loss-0.3374, acc-0.9118, test loss-0.3480, acc-0.9077\n",
      "Iter-32910, train loss-0.3908, acc-0.9400, valid loss-0.3374, acc-0.9118, test loss-0.3479, acc-0.9078\n",
      "Iter-32920, train loss-0.3990, acc-0.8800, valid loss-0.3373, acc-0.9116, test loss-0.3479, acc-0.9079\n",
      "Iter-32930, train loss-0.3625, acc-0.9000, valid loss-0.3372, acc-0.9114, test loss-0.3478, acc-0.9076\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32940, train loss-0.5485, acc-0.8600, valid loss-0.3372, acc-0.9112, test loss-0.3478, acc-0.9079\n",
      "Iter-32950, train loss-0.3492, acc-0.9200, valid loss-0.3372, acc-0.9114, test loss-0.3478, acc-0.9077\n",
      "Iter-32960, train loss-0.4388, acc-0.8800, valid loss-0.3371, acc-0.9112, test loss-0.3478, acc-0.9077\n",
      "Iter-32970, train loss-0.2659, acc-0.9400, valid loss-0.3370, acc-0.9112, test loss-0.3477, acc-0.9080\n",
      "Iter-32980, train loss-0.2972, acc-0.9000, valid loss-0.3370, acc-0.9116, test loss-0.3477, acc-0.9080\n",
      "Iter-32990, train loss-0.3010, acc-0.9000, valid loss-0.3370, acc-0.9112, test loss-0.3476, acc-0.9083\n",
      "Iter-33000, train loss-0.2489, acc-0.9600, valid loss-0.3369, acc-0.9114, test loss-0.3476, acc-0.9082\n",
      "Iter-33010, train loss-0.6763, acc-0.8200, valid loss-0.3368, acc-0.9114, test loss-0.3475, acc-0.9084\n",
      "Iter-33020, train loss-0.4431, acc-0.8800, valid loss-0.3368, acc-0.9114, test loss-0.3475, acc-0.9081\n",
      "Iter-33030, train loss-0.2533, acc-0.9400, valid loss-0.3367, acc-0.9116, test loss-0.3474, acc-0.9080\n",
      "Iter-33040, train loss-0.2723, acc-0.9200, valid loss-0.3367, acc-0.9116, test loss-0.3474, acc-0.9081\n",
      "Iter-33050, train loss-0.3921, acc-0.8600, valid loss-0.3367, acc-0.9116, test loss-0.3473, acc-0.9085\n",
      "Iter-33060, train loss-0.3430, acc-0.9200, valid loss-0.3366, acc-0.9116, test loss-0.3472, acc-0.9084\n",
      "Iter-33070, train loss-0.3400, acc-0.9000, valid loss-0.3365, acc-0.9114, test loss-0.3472, acc-0.9085\n",
      "Iter-33080, train loss-0.2178, acc-0.9400, valid loss-0.3365, acc-0.9114, test loss-0.3471, acc-0.9084\n",
      "Iter-33090, train loss-0.4401, acc-0.8800, valid loss-0.3365, acc-0.9114, test loss-0.3470, acc-0.9083\n",
      "Iter-33100, train loss-0.1860, acc-0.9400, valid loss-0.3364, acc-0.9114, test loss-0.3470, acc-0.9082\n",
      "Iter-33110, train loss-0.4189, acc-0.8800, valid loss-0.3363, acc-0.9116, test loss-0.3469, acc-0.9082\n",
      "Iter-33120, train loss-0.3553, acc-0.8600, valid loss-0.3363, acc-0.9118, test loss-0.3469, acc-0.9082\n",
      "Iter-33130, train loss-0.3530, acc-0.9000, valid loss-0.3362, acc-0.9118, test loss-0.3468, acc-0.9083\n",
      "Iter-33140, train loss-0.6335, acc-0.7600, valid loss-0.3362, acc-0.9118, test loss-0.3468, acc-0.9084\n",
      "Iter-33150, train loss-0.2559, acc-0.9400, valid loss-0.3361, acc-0.9120, test loss-0.3467, acc-0.9086\n",
      "Iter-33160, train loss-0.4296, acc-0.9200, valid loss-0.3361, acc-0.9120, test loss-0.3467, acc-0.9086\n",
      "Iter-33170, train loss-0.3854, acc-0.9000, valid loss-0.3361, acc-0.9120, test loss-0.3467, acc-0.9082\n",
      "Iter-33180, train loss-0.1820, acc-0.9400, valid loss-0.3361, acc-0.9120, test loss-0.3467, acc-0.9084\n",
      "Iter-33190, train loss-0.4905, acc-0.8400, valid loss-0.3360, acc-0.9120, test loss-0.3466, acc-0.9082\n",
      "Iter-33200, train loss-0.3514, acc-0.9200, valid loss-0.3359, acc-0.9120, test loss-0.3465, acc-0.9081\n",
      "Iter-33210, train loss-0.2987, acc-0.9600, valid loss-0.3359, acc-0.9120, test loss-0.3465, acc-0.9085\n",
      "Iter-33220, train loss-0.2999, acc-0.9600, valid loss-0.3358, acc-0.9118, test loss-0.3464, acc-0.9084\n",
      "Iter-33230, train loss-0.3605, acc-0.8600, valid loss-0.3358, acc-0.9120, test loss-0.3463, acc-0.9086\n",
      "Iter-33240, train loss-0.4337, acc-0.8800, valid loss-0.3357, acc-0.9120, test loss-0.3462, acc-0.9085\n",
      "Iter-33250, train loss-0.3695, acc-0.8600, valid loss-0.3357, acc-0.9122, test loss-0.3462, acc-0.9087\n",
      "Iter-33260, train loss-0.3141, acc-0.9000, valid loss-0.3357, acc-0.9120, test loss-0.3462, acc-0.9087\n",
      "Iter-33270, train loss-0.4392, acc-0.8600, valid loss-0.3357, acc-0.9118, test loss-0.3462, acc-0.9086\n",
      "Iter-33280, train loss-0.3070, acc-0.9600, valid loss-0.3356, acc-0.9120, test loss-0.3462, acc-0.9085\n",
      "Iter-33290, train loss-0.4875, acc-0.8800, valid loss-0.3356, acc-0.9118, test loss-0.3461, acc-0.9086\n",
      "Iter-33300, train loss-0.4202, acc-0.8600, valid loss-0.3355, acc-0.9118, test loss-0.3460, acc-0.9087\n",
      "Iter-33310, train loss-0.3661, acc-0.9200, valid loss-0.3355, acc-0.9114, test loss-0.3460, acc-0.9086\n",
      "Iter-33320, train loss-0.2073, acc-1.0000, valid loss-0.3354, acc-0.9118, test loss-0.3458, acc-0.9084\n",
      "Iter-33330, train loss-0.5535, acc-0.8600, valid loss-0.3354, acc-0.9116, test loss-0.3457, acc-0.9086\n",
      "Iter-33340, train loss-0.3772, acc-0.8600, valid loss-0.3353, acc-0.9116, test loss-0.3457, acc-0.9083\n",
      "Iter-33350, train loss-0.3932, acc-0.9000, valid loss-0.3352, acc-0.9118, test loss-0.3457, acc-0.9082\n",
      "Iter-33360, train loss-0.6459, acc-0.7800, valid loss-0.3351, acc-0.9116, test loss-0.3456, acc-0.9081\n",
      "Iter-33370, train loss-0.4239, acc-0.8400, valid loss-0.3351, acc-0.9114, test loss-0.3456, acc-0.9083\n",
      "Iter-33380, train loss-0.2607, acc-0.9400, valid loss-0.3351, acc-0.9114, test loss-0.3455, acc-0.9079\n",
      "Iter-33390, train loss-0.3159, acc-0.9200, valid loss-0.3350, acc-0.9116, test loss-0.3455, acc-0.9081\n",
      "Iter-33400, train loss-0.2876, acc-0.9000, valid loss-0.3350, acc-0.9118, test loss-0.3454, acc-0.9083\n",
      "Iter-33410, train loss-0.4234, acc-0.8800, valid loss-0.3349, acc-0.9116, test loss-0.3453, acc-0.9084\n",
      "Iter-33420, train loss-0.3070, acc-0.8800, valid loss-0.3348, acc-0.9114, test loss-0.3453, acc-0.9084\n",
      "Iter-33430, train loss-0.3752, acc-0.9000, valid loss-0.3348, acc-0.9114, test loss-0.3453, acc-0.9086\n",
      "Iter-33440, train loss-0.2942, acc-0.9400, valid loss-0.3348, acc-0.9116, test loss-0.3452, acc-0.9085\n",
      "Iter-33450, train loss-0.2931, acc-0.9200, valid loss-0.3348, acc-0.9112, test loss-0.3452, acc-0.9083\n",
      "Iter-33460, train loss-0.2547, acc-0.9600, valid loss-0.3347, acc-0.9114, test loss-0.3451, acc-0.9083\n",
      "Iter-33470, train loss-0.6091, acc-0.8200, valid loss-0.3347, acc-0.9112, test loss-0.3451, acc-0.9083\n",
      "Iter-33480, train loss-0.2803, acc-0.9000, valid loss-0.3346, acc-0.9112, test loss-0.3450, acc-0.9084\n",
      "Iter-33490, train loss-0.3567, acc-0.8400, valid loss-0.3346, acc-0.9110, test loss-0.3450, acc-0.9086\n",
      "Iter-33500, train loss-0.2956, acc-0.9200, valid loss-0.3346, acc-0.9110, test loss-0.3449, acc-0.9086\n",
      "Iter-33510, train loss-0.3372, acc-0.9000, valid loss-0.3345, acc-0.9110, test loss-0.3449, acc-0.9084\n",
      "Iter-33520, train loss-0.4996, acc-0.8800, valid loss-0.3344, acc-0.9112, test loss-0.3448, acc-0.9083\n",
      "Iter-33530, train loss-0.3648, acc-0.9400, valid loss-0.3344, acc-0.9114, test loss-0.3448, acc-0.9085\n",
      "Iter-33540, train loss-0.5078, acc-0.8200, valid loss-0.3343, acc-0.9116, test loss-0.3448, acc-0.9085\n",
      "Iter-33550, train loss-0.4093, acc-0.8000, valid loss-0.3343, acc-0.9122, test loss-0.3448, acc-0.9088\n",
      "Iter-33560, train loss-0.3689, acc-0.9200, valid loss-0.3342, acc-0.9122, test loss-0.3447, acc-0.9084\n",
      "Iter-33570, train loss-0.3535, acc-0.8600, valid loss-0.3342, acc-0.9118, test loss-0.3447, acc-0.9084\n",
      "Iter-33580, train loss-0.2618, acc-0.9400, valid loss-0.3341, acc-0.9118, test loss-0.3446, acc-0.9086\n",
      "Iter-33590, train loss-0.2310, acc-0.9600, valid loss-0.3341, acc-0.9116, test loss-0.3446, acc-0.9085\n",
      "Iter-33600, train loss-0.4259, acc-0.8600, valid loss-0.3341, acc-0.9120, test loss-0.3446, acc-0.9086\n",
      "Iter-33610, train loss-0.2869, acc-0.9600, valid loss-0.3340, acc-0.9116, test loss-0.3445, acc-0.9088\n",
      "Iter-33620, train loss-0.2660, acc-0.9400, valid loss-0.3339, acc-0.9120, test loss-0.3445, acc-0.9088\n",
      "Iter-33630, train loss-0.3051, acc-0.9800, valid loss-0.3339, acc-0.9118, test loss-0.3445, acc-0.9086\n",
      "Iter-33640, train loss-0.3867, acc-0.8800, valid loss-0.3338, acc-0.9118, test loss-0.3444, acc-0.9086\n",
      "Iter-33650, train loss-0.1699, acc-0.9400, valid loss-0.3338, acc-0.9116, test loss-0.3444, acc-0.9086\n",
      "Iter-33660, train loss-0.2469, acc-0.9200, valid loss-0.3337, acc-0.9118, test loss-0.3444, acc-0.9086\n",
      "Iter-33670, train loss-0.2295, acc-0.9200, valid loss-0.3336, acc-0.9120, test loss-0.3443, acc-0.9087\n",
      "Iter-33680, train loss-0.3942, acc-0.9000, valid loss-0.3336, acc-0.9118, test loss-0.3443, acc-0.9086\n",
      "Iter-33690, train loss-0.2880, acc-0.9800, valid loss-0.3336, acc-0.9124, test loss-0.3442, acc-0.9087\n",
      "Iter-33700, train loss-0.4418, acc-0.9000, valid loss-0.3335, acc-0.9122, test loss-0.3442, acc-0.9087\n",
      "Iter-33710, train loss-0.3786, acc-0.8600, valid loss-0.3334, acc-0.9120, test loss-0.3441, acc-0.9088\n",
      "Iter-33720, train loss-0.2389, acc-0.9600, valid loss-0.3334, acc-0.9122, test loss-0.3441, acc-0.9087\n",
      "Iter-33730, train loss-0.3553, acc-0.8600, valid loss-0.3334, acc-0.9120, test loss-0.3441, acc-0.9086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-33740, train loss-0.3850, acc-0.8800, valid loss-0.3333, acc-0.9120, test loss-0.3441, acc-0.9086\n",
      "Iter-33750, train loss-0.2446, acc-0.9200, valid loss-0.3333, acc-0.9124, test loss-0.3440, acc-0.9084\n",
      "Iter-33760, train loss-0.3428, acc-0.8800, valid loss-0.3332, acc-0.9120, test loss-0.3439, acc-0.9087\n",
      "Iter-33770, train loss-0.4053, acc-0.9000, valid loss-0.3332, acc-0.9118, test loss-0.3439, acc-0.9087\n",
      "Iter-33780, train loss-0.3271, acc-0.9000, valid loss-0.3332, acc-0.9120, test loss-0.3439, acc-0.9088\n",
      "Iter-33790, train loss-0.2849, acc-0.9400, valid loss-0.3331, acc-0.9120, test loss-0.3438, acc-0.9085\n",
      "Iter-33800, train loss-0.2942, acc-0.9400, valid loss-0.3330, acc-0.9118, test loss-0.3438, acc-0.9085\n",
      "Iter-33810, train loss-0.4390, acc-0.9000, valid loss-0.3331, acc-0.9126, test loss-0.3437, acc-0.9084\n",
      "Iter-33820, train loss-0.4174, acc-0.9400, valid loss-0.3331, acc-0.9126, test loss-0.3437, acc-0.9083\n",
      "Iter-33830, train loss-0.2084, acc-0.9600, valid loss-0.3330, acc-0.9120, test loss-0.3436, acc-0.9085\n",
      "Iter-33840, train loss-0.3665, acc-0.8800, valid loss-0.3330, acc-0.9118, test loss-0.3436, acc-0.9085\n",
      "Iter-33850, train loss-0.2583, acc-0.9400, valid loss-0.3328, acc-0.9120, test loss-0.3436, acc-0.9088\n",
      "Iter-33860, train loss-0.3397, acc-0.9200, valid loss-0.3329, acc-0.9120, test loss-0.3435, acc-0.9089\n",
      "Iter-33870, train loss-0.2182, acc-0.9400, valid loss-0.3328, acc-0.9122, test loss-0.3434, acc-0.9088\n",
      "Iter-33880, train loss-0.4751, acc-0.8600, valid loss-0.3328, acc-0.9122, test loss-0.3434, acc-0.9087\n",
      "Iter-33890, train loss-0.2266, acc-0.9400, valid loss-0.3327, acc-0.9118, test loss-0.3433, acc-0.9086\n",
      "Iter-33900, train loss-0.4676, acc-0.8600, valid loss-0.3327, acc-0.9118, test loss-0.3433, acc-0.9088\n",
      "Iter-33910, train loss-0.4130, acc-0.9000, valid loss-0.3326, acc-0.9116, test loss-0.3432, acc-0.9087\n",
      "Iter-33920, train loss-0.2886, acc-0.9200, valid loss-0.3326, acc-0.9118, test loss-0.3432, acc-0.9087\n",
      "Iter-33930, train loss-0.3175, acc-0.9200, valid loss-0.3326, acc-0.9116, test loss-0.3431, acc-0.9089\n",
      "Iter-33940, train loss-0.1848, acc-0.9800, valid loss-0.3326, acc-0.9118, test loss-0.3431, acc-0.9087\n",
      "Iter-33950, train loss-0.3508, acc-0.9000, valid loss-0.3326, acc-0.9118, test loss-0.3430, acc-0.9088\n",
      "Iter-33960, train loss-0.2901, acc-0.9600, valid loss-0.3325, acc-0.9120, test loss-0.3429, acc-0.9089\n",
      "Iter-33970, train loss-0.5202, acc-0.8200, valid loss-0.3325, acc-0.9120, test loss-0.3429, acc-0.9086\n",
      "Iter-33980, train loss-0.3133, acc-0.9200, valid loss-0.3324, acc-0.9122, test loss-0.3428, acc-0.9089\n",
      "Iter-33990, train loss-0.3654, acc-0.9000, valid loss-0.3324, acc-0.9126, test loss-0.3428, acc-0.9091\n",
      "Iter-34000, train loss-0.3533, acc-0.9000, valid loss-0.3324, acc-0.9124, test loss-0.3428, acc-0.9091\n",
      "Iter-34010, train loss-0.3067, acc-0.9400, valid loss-0.3323, acc-0.9122, test loss-0.3427, acc-0.9092\n",
      "Iter-34020, train loss-0.4801, acc-0.8800, valid loss-0.3323, acc-0.9120, test loss-0.3427, acc-0.9093\n",
      "Iter-34030, train loss-0.3213, acc-0.8800, valid loss-0.3323, acc-0.9120, test loss-0.3426, acc-0.9093\n",
      "Iter-34040, train loss-0.3126, acc-0.8800, valid loss-0.3322, acc-0.9120, test loss-0.3426, acc-0.9093\n",
      "Iter-34050, train loss-0.2803, acc-0.8800, valid loss-0.3322, acc-0.9122, test loss-0.3426, acc-0.9090\n",
      "Iter-34060, train loss-0.3911, acc-0.9200, valid loss-0.3321, acc-0.9122, test loss-0.3425, acc-0.9092\n",
      "Iter-34070, train loss-0.4766, acc-0.8200, valid loss-0.3321, acc-0.9122, test loss-0.3425, acc-0.9091\n",
      "Iter-34080, train loss-0.5394, acc-0.8200, valid loss-0.3321, acc-0.9122, test loss-0.3425, acc-0.9094\n",
      "Iter-34090, train loss-0.1772, acc-0.9800, valid loss-0.3320, acc-0.9120, test loss-0.3424, acc-0.9093\n",
      "Iter-34100, train loss-0.3104, acc-0.9400, valid loss-0.3320, acc-0.9122, test loss-0.3424, acc-0.9094\n",
      "Iter-34110, train loss-0.5352, acc-0.8800, valid loss-0.3319, acc-0.9124, test loss-0.3423, acc-0.9095\n",
      "Iter-34120, train loss-0.5337, acc-0.8400, valid loss-0.3318, acc-0.9126, test loss-0.3423, acc-0.9098\n",
      "Iter-34130, train loss-0.4681, acc-0.8600, valid loss-0.3318, acc-0.9124, test loss-0.3422, acc-0.9094\n",
      "Iter-34140, train loss-0.2732, acc-0.9000, valid loss-0.3317, acc-0.9122, test loss-0.3422, acc-0.9096\n",
      "Iter-34150, train loss-0.3054, acc-0.9400, valid loss-0.3316, acc-0.9122, test loss-0.3421, acc-0.9097\n",
      "Iter-34160, train loss-0.2679, acc-0.9600, valid loss-0.3315, acc-0.9122, test loss-0.3421, acc-0.9099\n",
      "Iter-34170, train loss-0.2732, acc-0.9200, valid loss-0.3315, acc-0.9124, test loss-0.3420, acc-0.9099\n",
      "Iter-34180, train loss-0.4426, acc-0.8600, valid loss-0.3315, acc-0.9124, test loss-0.3419, acc-0.9099\n",
      "Iter-34190, train loss-0.2146, acc-0.9400, valid loss-0.3315, acc-0.9120, test loss-0.3419, acc-0.9100\n",
      "Iter-34200, train loss-0.4623, acc-0.8800, valid loss-0.3314, acc-0.9122, test loss-0.3418, acc-0.9100\n",
      "Iter-34210, train loss-0.5910, acc-0.8800, valid loss-0.3313, acc-0.9124, test loss-0.3418, acc-0.9101\n",
      "Iter-34220, train loss-0.4068, acc-0.9000, valid loss-0.3313, acc-0.9126, test loss-0.3417, acc-0.9099\n",
      "Iter-34230, train loss-0.3194, acc-0.9200, valid loss-0.3312, acc-0.9126, test loss-0.3417, acc-0.9098\n",
      "Iter-34240, train loss-0.4827, acc-0.8600, valid loss-0.3311, acc-0.9124, test loss-0.3416, acc-0.9099\n",
      "Iter-34250, train loss-0.2426, acc-0.9400, valid loss-0.3311, acc-0.9124, test loss-0.3416, acc-0.9097\n",
      "Iter-34260, train loss-0.2052, acc-0.9800, valid loss-0.3310, acc-0.9122, test loss-0.3415, acc-0.9096\n",
      "Iter-34270, train loss-0.2882, acc-0.9400, valid loss-0.3309, acc-0.9122, test loss-0.3414, acc-0.9096\n",
      "Iter-34280, train loss-0.2513, acc-0.9200, valid loss-0.3309, acc-0.9124, test loss-0.3414, acc-0.9095\n",
      "Iter-34290, train loss-0.2014, acc-0.9800, valid loss-0.3309, acc-0.9126, test loss-0.3413, acc-0.9098\n",
      "Iter-34300, train loss-0.3556, acc-0.9200, valid loss-0.3309, acc-0.9124, test loss-0.3412, acc-0.9097\n",
      "Iter-34310, train loss-0.3377, acc-0.9200, valid loss-0.3308, acc-0.9126, test loss-0.3412, acc-0.9098\n",
      "Iter-34320, train loss-0.3398, acc-0.9200, valid loss-0.3308, acc-0.9128, test loss-0.3412, acc-0.9100\n",
      "Iter-34330, train loss-0.4509, acc-0.8600, valid loss-0.3308, acc-0.9130, test loss-0.3412, acc-0.9101\n",
      "Iter-34340, train loss-0.3381, acc-0.9000, valid loss-0.3307, acc-0.9132, test loss-0.3411, acc-0.9102\n",
      "Iter-34350, train loss-0.4068, acc-0.9400, valid loss-0.3307, acc-0.9132, test loss-0.3410, acc-0.9102\n",
      "Iter-34360, train loss-0.3361, acc-0.9000, valid loss-0.3306, acc-0.9132, test loss-0.3410, acc-0.9102\n",
      "Iter-34370, train loss-0.4067, acc-0.9400, valid loss-0.3306, acc-0.9126, test loss-0.3409, acc-0.9101\n",
      "Iter-34380, train loss-0.4277, acc-0.8800, valid loss-0.3305, acc-0.9130, test loss-0.3409, acc-0.9101\n",
      "Iter-34390, train loss-0.5549, acc-0.8400, valid loss-0.3305, acc-0.9132, test loss-0.3409, acc-0.9099\n",
      "Iter-34400, train loss-0.3047, acc-0.9400, valid loss-0.3304, acc-0.9130, test loss-0.3408, acc-0.9098\n",
      "Iter-34410, train loss-0.2446, acc-0.9600, valid loss-0.3304, acc-0.9134, test loss-0.3408, acc-0.9099\n",
      "Iter-34420, train loss-0.2558, acc-0.9200, valid loss-0.3304, acc-0.9134, test loss-0.3407, acc-0.9098\n",
      "Iter-34430, train loss-0.4057, acc-0.9400, valid loss-0.3304, acc-0.9134, test loss-0.3407, acc-0.9099\n",
      "Iter-34440, train loss-0.3364, acc-0.9200, valid loss-0.3303, acc-0.9134, test loss-0.3407, acc-0.9098\n",
      "Iter-34450, train loss-0.2821, acc-0.9200, valid loss-0.3302, acc-0.9134, test loss-0.3406, acc-0.9100\n",
      "Iter-34460, train loss-0.4353, acc-0.9000, valid loss-0.3302, acc-0.9136, test loss-0.3406, acc-0.9101\n",
      "Iter-34470, train loss-0.1711, acc-0.9800, valid loss-0.3301, acc-0.9134, test loss-0.3405, acc-0.9101\n",
      "Iter-34480, train loss-0.2126, acc-0.9400, valid loss-0.3301, acc-0.9132, test loss-0.3405, acc-0.9098\n",
      "Iter-34490, train loss-0.3814, acc-0.8400, valid loss-0.3301, acc-0.9128, test loss-0.3404, acc-0.9103\n",
      "Iter-34500, train loss-0.3255, acc-0.8600, valid loss-0.3300, acc-0.9126, test loss-0.3404, acc-0.9101\n",
      "Iter-34510, train loss-0.5574, acc-0.8600, valid loss-0.3300, acc-0.9128, test loss-0.3403, acc-0.9101\n",
      "Iter-34520, train loss-0.2279, acc-0.9600, valid loss-0.3299, acc-0.9122, test loss-0.3403, acc-0.9101\n",
      "Iter-34530, train loss-0.4424, acc-0.9400, valid loss-0.3299, acc-0.9126, test loss-0.3402, acc-0.9100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-34540, train loss-0.2280, acc-0.9600, valid loss-0.3299, acc-0.9128, test loss-0.3402, acc-0.9100\n",
      "Iter-34550, train loss-0.2641, acc-0.9200, valid loss-0.3299, acc-0.9124, test loss-0.3402, acc-0.9099\n",
      "Iter-34560, train loss-0.3671, acc-0.9000, valid loss-0.3299, acc-0.9124, test loss-0.3401, acc-0.9101\n",
      "Iter-34570, train loss-0.4102, acc-0.8600, valid loss-0.3298, acc-0.9124, test loss-0.3400, acc-0.9102\n",
      "Iter-34580, train loss-0.5285, acc-0.8800, valid loss-0.3298, acc-0.9122, test loss-0.3400, acc-0.9102\n",
      "Iter-34590, train loss-0.4584, acc-0.9000, valid loss-0.3297, acc-0.9120, test loss-0.3400, acc-0.9102\n",
      "Iter-34600, train loss-0.3288, acc-0.9000, valid loss-0.3296, acc-0.9120, test loss-0.3399, acc-0.9101\n",
      "Iter-34610, train loss-0.3679, acc-0.9000, valid loss-0.3295, acc-0.9122, test loss-0.3399, acc-0.9101\n",
      "Iter-34620, train loss-0.2799, acc-0.9200, valid loss-0.3295, acc-0.9124, test loss-0.3399, acc-0.9103\n",
      "Iter-34630, train loss-0.2644, acc-0.9200, valid loss-0.3294, acc-0.9126, test loss-0.3398, acc-0.9101\n",
      "Iter-34640, train loss-0.3013, acc-0.9200, valid loss-0.3294, acc-0.9122, test loss-0.3398, acc-0.9103\n",
      "Iter-34650, train loss-0.2814, acc-0.9000, valid loss-0.3293, acc-0.9128, test loss-0.3398, acc-0.9102\n",
      "Iter-34660, train loss-0.2119, acc-0.9600, valid loss-0.3293, acc-0.9122, test loss-0.3398, acc-0.9102\n",
      "Iter-34670, train loss-0.4166, acc-0.8400, valid loss-0.3293, acc-0.9124, test loss-0.3398, acc-0.9103\n",
      "Iter-34680, train loss-0.4129, acc-0.8800, valid loss-0.3292, acc-0.9130, test loss-0.3397, acc-0.9102\n",
      "Iter-34690, train loss-0.6050, acc-0.9000, valid loss-0.3292, acc-0.9124, test loss-0.3397, acc-0.9102\n",
      "Iter-34700, train loss-0.3323, acc-0.9000, valid loss-0.3292, acc-0.9126, test loss-0.3396, acc-0.9100\n",
      "Iter-34710, train loss-0.2805, acc-0.9000, valid loss-0.3292, acc-0.9126, test loss-0.3396, acc-0.9099\n",
      "Iter-34720, train loss-0.3009, acc-0.9200, valid loss-0.3292, acc-0.9124, test loss-0.3395, acc-0.9101\n",
      "Iter-34730, train loss-0.3622, acc-0.8800, valid loss-0.3292, acc-0.9124, test loss-0.3395, acc-0.9101\n",
      "Iter-34740, train loss-0.5558, acc-0.8400, valid loss-0.3291, acc-0.9124, test loss-0.3394, acc-0.9100\n",
      "Iter-34750, train loss-0.3571, acc-0.9000, valid loss-0.3291, acc-0.9124, test loss-0.3394, acc-0.9101\n",
      "Iter-34760, train loss-0.2769, acc-0.9400, valid loss-0.3291, acc-0.9128, test loss-0.3393, acc-0.9101\n",
      "Iter-34770, train loss-0.3832, acc-0.9400, valid loss-0.3290, acc-0.9130, test loss-0.3393, acc-0.9102\n",
      "Iter-34780, train loss-0.3438, acc-0.9000, valid loss-0.3289, acc-0.9128, test loss-0.3393, acc-0.9100\n",
      "Iter-34790, train loss-0.4079, acc-0.9200, valid loss-0.3289, acc-0.9128, test loss-0.3393, acc-0.9100\n",
      "Iter-34800, train loss-0.3930, acc-0.8800, valid loss-0.3289, acc-0.9130, test loss-0.3393, acc-0.9100\n",
      "Iter-34810, train loss-0.4194, acc-0.9000, valid loss-0.3287, acc-0.9132, test loss-0.3392, acc-0.9099\n",
      "Iter-34820, train loss-0.4501, acc-0.8600, valid loss-0.3287, acc-0.9128, test loss-0.3392, acc-0.9101\n",
      "Iter-34830, train loss-0.2479, acc-0.9800, valid loss-0.3286, acc-0.9130, test loss-0.3391, acc-0.9101\n",
      "Iter-34840, train loss-0.5630, acc-0.8600, valid loss-0.3286, acc-0.9128, test loss-0.3391, acc-0.9101\n",
      "Iter-34850, train loss-0.2954, acc-0.9000, valid loss-0.3286, acc-0.9130, test loss-0.3390, acc-0.9100\n",
      "Iter-34860, train loss-0.2680, acc-0.9200, valid loss-0.3285, acc-0.9128, test loss-0.3391, acc-0.9101\n",
      "Iter-34870, train loss-0.2670, acc-0.9600, valid loss-0.3285, acc-0.9128, test loss-0.3391, acc-0.9100\n",
      "Iter-34880, train loss-0.2618, acc-0.9200, valid loss-0.3284, acc-0.9128, test loss-0.3390, acc-0.9101\n",
      "Iter-34890, train loss-0.4723, acc-0.8400, valid loss-0.3284, acc-0.9128, test loss-0.3390, acc-0.9100\n",
      "Iter-34900, train loss-0.3892, acc-0.8800, valid loss-0.3284, acc-0.9130, test loss-0.3390, acc-0.9098\n",
      "Iter-34910, train loss-0.3925, acc-0.8800, valid loss-0.3283, acc-0.9130, test loss-0.3390, acc-0.9099\n",
      "Iter-34920, train loss-0.2821, acc-0.9200, valid loss-0.3283, acc-0.9130, test loss-0.3390, acc-0.9098\n",
      "Iter-34930, train loss-0.4863, acc-0.9400, valid loss-0.3282, acc-0.9126, test loss-0.3389, acc-0.9100\n",
      "Iter-34940, train loss-0.3226, acc-0.9200, valid loss-0.3282, acc-0.9130, test loss-0.3388, acc-0.9098\n",
      "Iter-34950, train loss-0.6036, acc-0.7400, valid loss-0.3281, acc-0.9132, test loss-0.3388, acc-0.9099\n",
      "Iter-34960, train loss-0.4426, acc-0.8600, valid loss-0.3281, acc-0.9132, test loss-0.3388, acc-0.9098\n",
      "Iter-34970, train loss-0.3337, acc-0.9000, valid loss-0.3281, acc-0.9130, test loss-0.3387, acc-0.9099\n",
      "Iter-34980, train loss-0.3663, acc-0.8800, valid loss-0.3280, acc-0.9132, test loss-0.3387, acc-0.9100\n",
      "Iter-34990, train loss-0.3860, acc-0.9000, valid loss-0.3280, acc-0.9132, test loss-0.3387, acc-0.9101\n",
      "Iter-35000, train loss-0.2324, acc-0.9000, valid loss-0.3279, acc-0.9128, test loss-0.3387, acc-0.9098\n",
      "Iter-35010, train loss-0.2281, acc-0.9400, valid loss-0.3279, acc-0.9126, test loss-0.3386, acc-0.9098\n",
      "Iter-35020, train loss-0.2925, acc-0.9200, valid loss-0.3279, acc-0.9126, test loss-0.3386, acc-0.9097\n",
      "Iter-35030, train loss-0.5867, acc-0.7800, valid loss-0.3279, acc-0.9128, test loss-0.3385, acc-0.9098\n",
      "Iter-35040, train loss-0.2953, acc-0.9000, valid loss-0.3279, acc-0.9130, test loss-0.3385, acc-0.9098\n",
      "Iter-35050, train loss-0.2172, acc-0.9000, valid loss-0.3278, acc-0.9126, test loss-0.3385, acc-0.9099\n",
      "Iter-35060, train loss-0.2863, acc-0.9400, valid loss-0.3278, acc-0.9126, test loss-0.3385, acc-0.9100\n",
      "Iter-35070, train loss-0.1893, acc-0.9800, valid loss-0.3278, acc-0.9130, test loss-0.3384, acc-0.9099\n",
      "Iter-35080, train loss-0.2590, acc-0.9600, valid loss-0.3278, acc-0.9128, test loss-0.3383, acc-0.9101\n",
      "Iter-35090, train loss-0.3040, acc-0.9000, valid loss-0.3277, acc-0.9128, test loss-0.3383, acc-0.9100\n",
      "Iter-35100, train loss-0.3339, acc-0.9000, valid loss-0.3277, acc-0.9130, test loss-0.3383, acc-0.9100\n",
      "Iter-35110, train loss-0.4384, acc-0.8800, valid loss-0.3276, acc-0.9132, test loss-0.3382, acc-0.9100\n",
      "Iter-35120, train loss-0.2659, acc-0.9200, valid loss-0.3275, acc-0.9132, test loss-0.3382, acc-0.9099\n",
      "Iter-35130, train loss-0.3889, acc-0.9400, valid loss-0.3274, acc-0.9136, test loss-0.3381, acc-0.9102\n",
      "Iter-35140, train loss-0.4954, acc-0.8800, valid loss-0.3273, acc-0.9132, test loss-0.3381, acc-0.9101\n",
      "Iter-35150, train loss-0.3874, acc-0.9000, valid loss-0.3273, acc-0.9136, test loss-0.3380, acc-0.9102\n",
      "Iter-35160, train loss-0.2030, acc-0.9600, valid loss-0.3273, acc-0.9136, test loss-0.3379, acc-0.9100\n",
      "Iter-35170, train loss-0.4675, acc-0.9000, valid loss-0.3272, acc-0.9134, test loss-0.3379, acc-0.9103\n",
      "Iter-35180, train loss-0.4017, acc-0.8800, valid loss-0.3271, acc-0.9136, test loss-0.3379, acc-0.9103\n",
      "Iter-35190, train loss-0.1934, acc-0.9400, valid loss-0.3271, acc-0.9136, test loss-0.3378, acc-0.9102\n",
      "Iter-35200, train loss-0.3943, acc-0.8800, valid loss-0.3271, acc-0.9140, test loss-0.3378, acc-0.9101\n",
      "Iter-35210, train loss-0.2463, acc-0.9200, valid loss-0.3270, acc-0.9140, test loss-0.3377, acc-0.9103\n",
      "Iter-35220, train loss-0.3187, acc-0.9400, valid loss-0.3269, acc-0.9138, test loss-0.3377, acc-0.9105\n",
      "Iter-35230, train loss-0.4713, acc-0.8600, valid loss-0.3270, acc-0.9134, test loss-0.3377, acc-0.9102\n",
      "Iter-35240, train loss-0.3061, acc-0.9600, valid loss-0.3269, acc-0.9138, test loss-0.3376, acc-0.9107\n",
      "Iter-35250, train loss-0.4456, acc-0.8800, valid loss-0.3268, acc-0.9136, test loss-0.3376, acc-0.9106\n",
      "Iter-35260, train loss-0.2896, acc-0.9000, valid loss-0.3268, acc-0.9138, test loss-0.3375, acc-0.9107\n",
      "Iter-35270, train loss-0.2385, acc-0.9400, valid loss-0.3268, acc-0.9138, test loss-0.3375, acc-0.9107\n",
      "Iter-35280, train loss-0.2376, acc-0.9400, valid loss-0.3268, acc-0.9138, test loss-0.3375, acc-0.9106\n",
      "Iter-35290, train loss-0.5120, acc-0.8600, valid loss-0.3268, acc-0.9138, test loss-0.3374, acc-0.9108\n",
      "Iter-35300, train loss-0.2854, acc-0.9400, valid loss-0.3268, acc-0.9136, test loss-0.3374, acc-0.9109\n",
      "Iter-35310, train loss-0.3601, acc-0.9200, valid loss-0.3267, acc-0.9140, test loss-0.3374, acc-0.9109\n",
      "Iter-35320, train loss-0.2990, acc-0.9200, valid loss-0.3267, acc-0.9140, test loss-0.3373, acc-0.9109\n",
      "Iter-35330, train loss-0.1952, acc-0.9600, valid loss-0.3266, acc-0.9140, test loss-0.3373, acc-0.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-35340, train loss-0.3269, acc-0.8800, valid loss-0.3266, acc-0.9138, test loss-0.3372, acc-0.9108\n",
      "Iter-35350, train loss-0.3860, acc-0.8600, valid loss-0.3266, acc-0.9138, test loss-0.3372, acc-0.9109\n",
      "Iter-35360, train loss-0.4204, acc-0.8800, valid loss-0.3265, acc-0.9136, test loss-0.3372, acc-0.9108\n",
      "Iter-35370, train loss-0.4882, acc-0.9200, valid loss-0.3265, acc-0.9138, test loss-0.3371, acc-0.9110\n",
      "Iter-35380, train loss-0.3905, acc-0.9200, valid loss-0.3265, acc-0.9140, test loss-0.3370, acc-0.9110\n",
      "Iter-35390, train loss-0.5303, acc-0.8200, valid loss-0.3264, acc-0.9132, test loss-0.3370, acc-0.9109\n",
      "Iter-35400, train loss-0.3320, acc-0.9400, valid loss-0.3264, acc-0.9134, test loss-0.3370, acc-0.9110\n",
      "Iter-35410, train loss-0.3069, acc-0.9400, valid loss-0.3263, acc-0.9136, test loss-0.3369, acc-0.9109\n",
      "Iter-35420, train loss-0.5099, acc-0.8600, valid loss-0.3262, acc-0.9130, test loss-0.3369, acc-0.9107\n",
      "Iter-35430, train loss-0.3513, acc-0.9200, valid loss-0.3261, acc-0.9134, test loss-0.3369, acc-0.9106\n",
      "Iter-35440, train loss-0.3425, acc-0.9000, valid loss-0.3260, acc-0.9132, test loss-0.3368, acc-0.9105\n",
      "Iter-35450, train loss-0.4838, acc-0.8600, valid loss-0.3259, acc-0.9130, test loss-0.3368, acc-0.9106\n",
      "Iter-35460, train loss-0.2382, acc-0.9400, valid loss-0.3259, acc-0.9134, test loss-0.3368, acc-0.9108\n",
      "Iter-35470, train loss-0.3792, acc-0.9400, valid loss-0.3259, acc-0.9132, test loss-0.3367, acc-0.9106\n",
      "Iter-35480, train loss-0.5027, acc-0.8800, valid loss-0.3258, acc-0.9134, test loss-0.3367, acc-0.9107\n",
      "Iter-35490, train loss-0.4212, acc-0.9000, valid loss-0.3258, acc-0.9134, test loss-0.3366, acc-0.9108\n",
      "Iter-35500, train loss-0.2953, acc-0.9000, valid loss-0.3258, acc-0.9134, test loss-0.3365, acc-0.9107\n",
      "Iter-35510, train loss-0.3749, acc-0.8600, valid loss-0.3257, acc-0.9144, test loss-0.3364, acc-0.9111\n",
      "Iter-35520, train loss-0.2098, acc-0.9400, valid loss-0.3257, acc-0.9144, test loss-0.3364, acc-0.9111\n",
      "Iter-35530, train loss-0.3005, acc-0.9200, valid loss-0.3256, acc-0.9144, test loss-0.3364, acc-0.9110\n",
      "Iter-35540, train loss-0.2391, acc-0.9400, valid loss-0.3255, acc-0.9142, test loss-0.3363, acc-0.9111\n",
      "Iter-35550, train loss-0.4920, acc-0.8800, valid loss-0.3255, acc-0.9144, test loss-0.3363, acc-0.9111\n",
      "Iter-35560, train loss-0.3964, acc-0.8600, valid loss-0.3254, acc-0.9138, test loss-0.3362, acc-0.9111\n",
      "Iter-35570, train loss-0.1417, acc-0.9800, valid loss-0.3254, acc-0.9142, test loss-0.3361, acc-0.9105\n",
      "Iter-35580, train loss-0.4119, acc-0.8400, valid loss-0.3253, acc-0.9138, test loss-0.3361, acc-0.9106\n",
      "Iter-35590, train loss-0.3618, acc-0.8600, valid loss-0.3253, acc-0.9138, test loss-0.3360, acc-0.9106\n",
      "Iter-35600, train loss-0.1120, acc-1.0000, valid loss-0.3253, acc-0.9138, test loss-0.3360, acc-0.9108\n",
      "Iter-35610, train loss-0.2021, acc-0.9800, valid loss-0.3253, acc-0.9136, test loss-0.3360, acc-0.9109\n",
      "Iter-35620, train loss-0.3012, acc-0.9400, valid loss-0.3252, acc-0.9140, test loss-0.3359, acc-0.9107\n",
      "Iter-35630, train loss-0.3095, acc-0.9200, valid loss-0.3252, acc-0.9138, test loss-0.3358, acc-0.9105\n",
      "Iter-35640, train loss-0.3707, acc-0.9000, valid loss-0.3251, acc-0.9138, test loss-0.3358, acc-0.9108\n",
      "Iter-35650, train loss-0.2959, acc-0.9000, valid loss-0.3251, acc-0.9136, test loss-0.3357, acc-0.9111\n",
      "Iter-35660, train loss-0.2932, acc-0.9000, valid loss-0.3250, acc-0.9140, test loss-0.3356, acc-0.9110\n",
      "Iter-35670, train loss-0.1827, acc-0.9600, valid loss-0.3249, acc-0.9140, test loss-0.3356, acc-0.9109\n",
      "Iter-35680, train loss-0.4316, acc-0.8400, valid loss-0.3249, acc-0.9142, test loss-0.3356, acc-0.9108\n",
      "Iter-35690, train loss-0.1980, acc-0.9400, valid loss-0.3248, acc-0.9140, test loss-0.3355, acc-0.9109\n",
      "Iter-35700, train loss-0.3175, acc-0.8800, valid loss-0.3248, acc-0.9140, test loss-0.3354, acc-0.9106\n",
      "Iter-35710, train loss-0.3504, acc-0.9000, valid loss-0.3248, acc-0.9140, test loss-0.3354, acc-0.9105\n",
      "Iter-35720, train loss-0.2660, acc-0.9600, valid loss-0.3248, acc-0.9142, test loss-0.3353, acc-0.9107\n",
      "Iter-35730, train loss-0.3117, acc-0.9200, valid loss-0.3247, acc-0.9138, test loss-0.3352, acc-0.9109\n",
      "Iter-35740, train loss-0.3245, acc-0.9000, valid loss-0.3246, acc-0.9138, test loss-0.3352, acc-0.9108\n",
      "Iter-35750, train loss-0.3611, acc-0.8800, valid loss-0.3246, acc-0.9144, test loss-0.3351, acc-0.9108\n",
      "Iter-35760, train loss-0.3058, acc-0.9000, valid loss-0.3245, acc-0.9144, test loss-0.3351, acc-0.9112\n",
      "Iter-35770, train loss-0.2774, acc-0.9200, valid loss-0.3245, acc-0.9144, test loss-0.3350, acc-0.9112\n",
      "Iter-35780, train loss-0.3434, acc-0.8800, valid loss-0.3245, acc-0.9142, test loss-0.3350, acc-0.9112\n",
      "Iter-35790, train loss-0.3484, acc-0.8800, valid loss-0.3244, acc-0.9142, test loss-0.3350, acc-0.9112\n",
      "Iter-35800, train loss-0.2775, acc-0.9000, valid loss-0.3244, acc-0.9144, test loss-0.3349, acc-0.9113\n",
      "Iter-35810, train loss-0.1997, acc-0.9200, valid loss-0.3243, acc-0.9140, test loss-0.3349, acc-0.9113\n",
      "Iter-35820, train loss-0.4918, acc-0.8600, valid loss-0.3243, acc-0.9142, test loss-0.3349, acc-0.9113\n",
      "Iter-35830, train loss-0.2296, acc-0.9600, valid loss-0.3242, acc-0.9140, test loss-0.3349, acc-0.9112\n",
      "Iter-35840, train loss-0.2928, acc-0.9200, valid loss-0.3241, acc-0.9142, test loss-0.3348, acc-0.9112\n",
      "Iter-35850, train loss-0.5321, acc-0.8600, valid loss-0.3241, acc-0.9142, test loss-0.3349, acc-0.9112\n",
      "Iter-35860, train loss-0.4278, acc-0.9200, valid loss-0.3241, acc-0.9142, test loss-0.3348, acc-0.9112\n",
      "Iter-35870, train loss-0.2817, acc-0.9200, valid loss-0.3240, acc-0.9144, test loss-0.3348, acc-0.9110\n",
      "Iter-35880, train loss-0.2763, acc-0.9600, valid loss-0.3239, acc-0.9144, test loss-0.3347, acc-0.9111\n",
      "Iter-35890, train loss-0.3897, acc-0.8600, valid loss-0.3238, acc-0.9144, test loss-0.3346, acc-0.9111\n",
      "Iter-35900, train loss-0.3191, acc-0.9400, valid loss-0.3238, acc-0.9144, test loss-0.3347, acc-0.9111\n",
      "Iter-35910, train loss-0.3912, acc-0.8800, valid loss-0.3238, acc-0.9140, test loss-0.3346, acc-0.9109\n",
      "Iter-35920, train loss-0.4856, acc-0.9200, valid loss-0.3237, acc-0.9136, test loss-0.3346, acc-0.9107\n",
      "Iter-35930, train loss-0.2905, acc-0.9600, valid loss-0.3237, acc-0.9136, test loss-0.3346, acc-0.9108\n",
      "Iter-35940, train loss-0.2689, acc-0.9000, valid loss-0.3236, acc-0.9134, test loss-0.3345, acc-0.9109\n",
      "Iter-35950, train loss-0.1861, acc-0.9800, valid loss-0.3236, acc-0.9136, test loss-0.3344, acc-0.9109\n",
      "Iter-35960, train loss-0.3695, acc-0.8400, valid loss-0.3236, acc-0.9138, test loss-0.3344, acc-0.9108\n",
      "Iter-35970, train loss-0.2796, acc-0.9200, valid loss-0.3236, acc-0.9140, test loss-0.3343, acc-0.9110\n",
      "Iter-35980, train loss-0.4291, acc-0.8400, valid loss-0.3235, acc-0.9140, test loss-0.3343, acc-0.9107\n",
      "Iter-35990, train loss-0.2538, acc-0.9600, valid loss-0.3235, acc-0.9140, test loss-0.3343, acc-0.9108\n",
      "Iter-36000, train loss-0.4119, acc-0.9000, valid loss-0.3235, acc-0.9140, test loss-0.3342, acc-0.9109\n",
      "Iter-36010, train loss-0.4609, acc-0.9000, valid loss-0.3234, acc-0.9138, test loss-0.3342, acc-0.9111\n",
      "Iter-36020, train loss-0.3740, acc-0.9000, valid loss-0.3235, acc-0.9140, test loss-0.3342, acc-0.9111\n",
      "Iter-36030, train loss-0.3387, acc-0.9200, valid loss-0.3234, acc-0.9140, test loss-0.3341, acc-0.9110\n",
      "Iter-36040, train loss-0.2484, acc-0.9600, valid loss-0.3234, acc-0.9138, test loss-0.3340, acc-0.9111\n",
      "Iter-36050, train loss-0.4217, acc-0.8600, valid loss-0.3233, acc-0.9136, test loss-0.3339, acc-0.9109\n",
      "Iter-36060, train loss-0.2966, acc-0.9000, valid loss-0.3233, acc-0.9138, test loss-0.3339, acc-0.9110\n",
      "Iter-36070, train loss-0.6007, acc-0.8000, valid loss-0.3232, acc-0.9136, test loss-0.3339, acc-0.9112\n",
      "Iter-36080, train loss-0.1956, acc-0.9600, valid loss-0.3232, acc-0.9136, test loss-0.3339, acc-0.9112\n",
      "Iter-36090, train loss-0.2957, acc-0.9200, valid loss-0.3231, acc-0.9134, test loss-0.3338, acc-0.9111\n",
      "Iter-36100, train loss-0.1606, acc-0.9600, valid loss-0.3230, acc-0.9138, test loss-0.3338, acc-0.9109\n",
      "Iter-36110, train loss-0.2603, acc-0.9600, valid loss-0.3230, acc-0.9138, test loss-0.3338, acc-0.9109\n",
      "Iter-36120, train loss-0.3988, acc-0.8600, valid loss-0.3230, acc-0.9138, test loss-0.3337, acc-0.9109\n",
      "Iter-36130, train loss-0.2566, acc-0.9600, valid loss-0.3229, acc-0.9138, test loss-0.3337, acc-0.9109\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36140, train loss-0.3967, acc-0.8800, valid loss-0.3229, acc-0.9138, test loss-0.3337, acc-0.9107\n",
      "Iter-36150, train loss-0.3926, acc-0.9000, valid loss-0.3228, acc-0.9132, test loss-0.3337, acc-0.9110\n",
      "Iter-36160, train loss-0.5075, acc-0.8400, valid loss-0.3228, acc-0.9134, test loss-0.3337, acc-0.9109\n",
      "Iter-36170, train loss-0.4324, acc-0.8400, valid loss-0.3227, acc-0.9134, test loss-0.3337, acc-0.9108\n",
      "Iter-36180, train loss-0.2407, acc-0.9400, valid loss-0.3226, acc-0.9134, test loss-0.3337, acc-0.9109\n",
      "Iter-36190, train loss-0.4709, acc-0.9000, valid loss-0.3226, acc-0.9138, test loss-0.3336, acc-0.9108\n",
      "Iter-36200, train loss-0.2956, acc-0.9400, valid loss-0.3226, acc-0.9138, test loss-0.3336, acc-0.9108\n",
      "Iter-36210, train loss-0.3689, acc-0.9000, valid loss-0.3225, acc-0.9136, test loss-0.3336, acc-0.9111\n",
      "Iter-36220, train loss-0.4192, acc-0.8400, valid loss-0.3225, acc-0.9142, test loss-0.3335, acc-0.9108\n",
      "Iter-36230, train loss-0.4042, acc-0.8600, valid loss-0.3226, acc-0.9140, test loss-0.3335, acc-0.9109\n",
      "Iter-36240, train loss-0.3631, acc-0.8600, valid loss-0.3226, acc-0.9140, test loss-0.3335, acc-0.9108\n",
      "Iter-36250, train loss-0.4215, acc-0.8400, valid loss-0.3225, acc-0.9142, test loss-0.3334, acc-0.9108\n",
      "Iter-36260, train loss-0.3294, acc-0.9200, valid loss-0.3225, acc-0.9142, test loss-0.3333, acc-0.9108\n",
      "Iter-36270, train loss-0.2929, acc-0.9600, valid loss-0.3223, acc-0.9142, test loss-0.3333, acc-0.9106\n",
      "Iter-36280, train loss-0.5988, acc-0.8200, valid loss-0.3223, acc-0.9142, test loss-0.3332, acc-0.9105\n",
      "Iter-36290, train loss-0.2334, acc-0.9400, valid loss-0.3223, acc-0.9144, test loss-0.3332, acc-0.9104\n",
      "Iter-36300, train loss-0.3690, acc-0.9200, valid loss-0.3222, acc-0.9144, test loss-0.3332, acc-0.9106\n",
      "Iter-36310, train loss-0.6323, acc-0.7400, valid loss-0.3222, acc-0.9142, test loss-0.3331, acc-0.9106\n",
      "Iter-36320, train loss-0.2072, acc-0.9400, valid loss-0.3221, acc-0.9146, test loss-0.3330, acc-0.9106\n",
      "Iter-36330, train loss-0.4836, acc-0.9000, valid loss-0.3221, acc-0.9144, test loss-0.3330, acc-0.9108\n",
      "Iter-36340, train loss-0.2337, acc-0.9600, valid loss-0.3220, acc-0.9142, test loss-0.3329, acc-0.9109\n",
      "Iter-36350, train loss-0.2689, acc-0.9600, valid loss-0.3220, acc-0.9144, test loss-0.3328, acc-0.9107\n",
      "Iter-36360, train loss-0.4133, acc-0.9200, valid loss-0.3219, acc-0.9144, test loss-0.3327, acc-0.9108\n",
      "Iter-36370, train loss-0.3909, acc-0.9000, valid loss-0.3219, acc-0.9144, test loss-0.3327, acc-0.9108\n",
      "Iter-36380, train loss-0.4306, acc-0.9200, valid loss-0.3219, acc-0.9142, test loss-0.3326, acc-0.9109\n",
      "Iter-36390, train loss-0.2453, acc-0.9400, valid loss-0.3218, acc-0.9144, test loss-0.3325, acc-0.9110\n",
      "Iter-36400, train loss-0.3523, acc-0.9200, valid loss-0.3218, acc-0.9146, test loss-0.3325, acc-0.9112\n",
      "Iter-36410, train loss-0.2769, acc-0.9400, valid loss-0.3218, acc-0.9142, test loss-0.3325, acc-0.9113\n",
      "Iter-36420, train loss-0.3360, acc-0.8800, valid loss-0.3218, acc-0.9142, test loss-0.3325, acc-0.9112\n",
      "Iter-36430, train loss-0.4606, acc-0.9000, valid loss-0.3217, acc-0.9140, test loss-0.3325, acc-0.9111\n",
      "Iter-36440, train loss-0.3049, acc-0.8800, valid loss-0.3217, acc-0.9144, test loss-0.3324, acc-0.9110\n",
      "Iter-36450, train loss-0.3880, acc-0.9000, valid loss-0.3217, acc-0.9142, test loss-0.3324, acc-0.9112\n",
      "Iter-36460, train loss-0.3529, acc-0.9400, valid loss-0.3217, acc-0.9144, test loss-0.3323, acc-0.9112\n",
      "Iter-36470, train loss-0.3373, acc-0.9000, valid loss-0.3217, acc-0.9142, test loss-0.3323, acc-0.9113\n",
      "Iter-36480, train loss-0.3357, acc-0.9200, valid loss-0.3216, acc-0.9142, test loss-0.3322, acc-0.9113\n",
      "Iter-36490, train loss-0.3493, acc-0.9000, valid loss-0.3216, acc-0.9142, test loss-0.3322, acc-0.9113\n",
      "Iter-36500, train loss-0.2790, acc-0.9200, valid loss-0.3216, acc-0.9142, test loss-0.3322, acc-0.9110\n",
      "Iter-36510, train loss-0.2002, acc-0.9600, valid loss-0.3215, acc-0.9142, test loss-0.3322, acc-0.9111\n",
      "Iter-36520, train loss-0.4292, acc-0.8800, valid loss-0.3215, acc-0.9142, test loss-0.3321, acc-0.9111\n",
      "Iter-36530, train loss-0.2931, acc-0.8800, valid loss-0.3214, acc-0.9144, test loss-0.3321, acc-0.9114\n",
      "Iter-36540, train loss-0.2738, acc-0.9400, valid loss-0.3214, acc-0.9146, test loss-0.3320, acc-0.9113\n",
      "Iter-36550, train loss-0.3545, acc-0.9000, valid loss-0.3214, acc-0.9144, test loss-0.3319, acc-0.9112\n",
      "Iter-36560, train loss-0.2291, acc-0.9600, valid loss-0.3213, acc-0.9144, test loss-0.3319, acc-0.9111\n",
      "Iter-36570, train loss-0.2962, acc-0.9200, valid loss-0.3213, acc-0.9144, test loss-0.3319, acc-0.9111\n",
      "Iter-36580, train loss-0.3504, acc-0.8800, valid loss-0.3213, acc-0.9146, test loss-0.3319, acc-0.9110\n",
      "Iter-36590, train loss-0.2542, acc-0.9200, valid loss-0.3212, acc-0.9146, test loss-0.3319, acc-0.9110\n",
      "Iter-36600, train loss-0.4568, acc-0.8600, valid loss-0.3211, acc-0.9146, test loss-0.3318, acc-0.9109\n",
      "Iter-36610, train loss-0.2551, acc-0.9400, valid loss-0.3212, acc-0.9148, test loss-0.3318, acc-0.9109\n",
      "Iter-36620, train loss-0.2518, acc-0.9400, valid loss-0.3211, acc-0.9146, test loss-0.3317, acc-0.9110\n",
      "Iter-36630, train loss-0.2194, acc-0.9400, valid loss-0.3211, acc-0.9144, test loss-0.3316, acc-0.9112\n",
      "Iter-36640, train loss-0.2923, acc-0.8800, valid loss-0.3210, acc-0.9144, test loss-0.3316, acc-0.9112\n",
      "Iter-36650, train loss-0.3515, acc-0.8600, valid loss-0.3209, acc-0.9144, test loss-0.3315, acc-0.9115\n",
      "Iter-36660, train loss-0.5015, acc-0.8600, valid loss-0.3209, acc-0.9146, test loss-0.3314, acc-0.9113\n",
      "Iter-36670, train loss-0.4313, acc-0.8800, valid loss-0.3209, acc-0.9146, test loss-0.3314, acc-0.9115\n",
      "Iter-36680, train loss-0.4038, acc-0.9000, valid loss-0.3209, acc-0.9150, test loss-0.3313, acc-0.9118\n",
      "Iter-36690, train loss-0.3329, acc-0.9200, valid loss-0.3208, acc-0.9150, test loss-0.3313, acc-0.9119\n",
      "Iter-36700, train loss-0.5008, acc-0.9200, valid loss-0.3208, acc-0.9148, test loss-0.3313, acc-0.9118\n",
      "Iter-36710, train loss-0.2526, acc-0.9000, valid loss-0.3207, acc-0.9146, test loss-0.3312, acc-0.9121\n",
      "Iter-36720, train loss-0.3555, acc-0.9000, valid loss-0.3207, acc-0.9144, test loss-0.3313, acc-0.9120\n",
      "Iter-36730, train loss-0.3793, acc-0.8800, valid loss-0.3207, acc-0.9146, test loss-0.3312, acc-0.9120\n",
      "Iter-36740, train loss-0.2312, acc-0.9600, valid loss-0.3206, acc-0.9146, test loss-0.3312, acc-0.9121\n",
      "Iter-36750, train loss-0.3400, acc-0.8800, valid loss-0.3206, acc-0.9140, test loss-0.3311, acc-0.9125\n",
      "Iter-36760, train loss-0.4037, acc-0.8800, valid loss-0.3205, acc-0.9144, test loss-0.3310, acc-0.9122\n",
      "Iter-36770, train loss-0.2630, acc-0.9400, valid loss-0.3205, acc-0.9148, test loss-0.3310, acc-0.9125\n",
      "Iter-36780, train loss-0.1097, acc-0.9800, valid loss-0.3205, acc-0.9146, test loss-0.3310, acc-0.9125\n",
      "Iter-36790, train loss-0.4676, acc-0.8600, valid loss-0.3204, acc-0.9144, test loss-0.3309, acc-0.9124\n",
      "Iter-36800, train loss-0.2078, acc-0.9800, valid loss-0.3204, acc-0.9144, test loss-0.3309, acc-0.9124\n",
      "Iter-36810, train loss-0.3319, acc-0.9000, valid loss-0.3204, acc-0.9142, test loss-0.3308, acc-0.9125\n",
      "Iter-36820, train loss-0.3133, acc-0.9200, valid loss-0.3203, acc-0.9142, test loss-0.3308, acc-0.9125\n",
      "Iter-36830, train loss-0.3044, acc-0.9400, valid loss-0.3202, acc-0.9146, test loss-0.3308, acc-0.9127\n",
      "Iter-36840, train loss-0.4829, acc-0.9000, valid loss-0.3202, acc-0.9146, test loss-0.3307, acc-0.9127\n",
      "Iter-36850, train loss-0.2903, acc-0.8800, valid loss-0.3201, acc-0.9146, test loss-0.3307, acc-0.9124\n",
      "Iter-36860, train loss-0.4067, acc-0.8800, valid loss-0.3201, acc-0.9148, test loss-0.3307, acc-0.9127\n",
      "Iter-36870, train loss-0.3205, acc-0.9400, valid loss-0.3201, acc-0.9146, test loss-0.3306, acc-0.9123\n",
      "Iter-36880, train loss-0.2028, acc-0.9600, valid loss-0.3200, acc-0.9144, test loss-0.3306, acc-0.9122\n",
      "Iter-36890, train loss-0.3137, acc-0.9400, valid loss-0.3200, acc-0.9148, test loss-0.3306, acc-0.9122\n",
      "Iter-36900, train loss-0.3922, acc-0.8800, valid loss-0.3199, acc-0.9152, test loss-0.3306, acc-0.9119\n",
      "Iter-36910, train loss-0.4679, acc-0.8400, valid loss-0.3198, acc-0.9154, test loss-0.3305, acc-0.9120\n",
      "Iter-36920, train loss-0.2140, acc-0.9400, valid loss-0.3198, acc-0.9154, test loss-0.3305, acc-0.9121\n",
      "Iter-36930, train loss-0.5282, acc-0.8200, valid loss-0.3198, acc-0.9154, test loss-0.3304, acc-0.9119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36940, train loss-0.1670, acc-0.9800, valid loss-0.3197, acc-0.9152, test loss-0.3304, acc-0.9123\n",
      "Iter-36950, train loss-0.1943, acc-0.9600, valid loss-0.3197, acc-0.9150, test loss-0.3304, acc-0.9119\n",
      "Iter-36960, train loss-0.4247, acc-0.9000, valid loss-0.3196, acc-0.9148, test loss-0.3303, acc-0.9120\n",
      "Iter-36970, train loss-0.3628, acc-0.9400, valid loss-0.3196, acc-0.9146, test loss-0.3303, acc-0.9123\n",
      "Iter-36980, train loss-0.3531, acc-0.8600, valid loss-0.3195, acc-0.9154, test loss-0.3302, acc-0.9124\n",
      "Iter-36990, train loss-0.2678, acc-0.9600, valid loss-0.3194, acc-0.9148, test loss-0.3302, acc-0.9122\n",
      "Iter-37000, train loss-0.3954, acc-0.9000, valid loss-0.3194, acc-0.9148, test loss-0.3302, acc-0.9121\n",
      "Iter-37010, train loss-0.2240, acc-0.9600, valid loss-0.3194, acc-0.9152, test loss-0.3302, acc-0.9119\n",
      "Iter-37020, train loss-0.2375, acc-0.9600, valid loss-0.3193, acc-0.9152, test loss-0.3301, acc-0.9120\n",
      "Iter-37030, train loss-0.2519, acc-0.9200, valid loss-0.3193, acc-0.9154, test loss-0.3301, acc-0.9120\n",
      "Iter-37040, train loss-0.3301, acc-0.9000, valid loss-0.3193, acc-0.9152, test loss-0.3300, acc-0.9120\n",
      "Iter-37050, train loss-0.3138, acc-0.9200, valid loss-0.3193, acc-0.9148, test loss-0.3299, acc-0.9123\n",
      "Iter-37060, train loss-0.1551, acc-0.9800, valid loss-0.3193, acc-0.9148, test loss-0.3299, acc-0.9121\n",
      "Iter-37070, train loss-0.3560, acc-0.9200, valid loss-0.3193, acc-0.9150, test loss-0.3298, acc-0.9124\n",
      "Iter-37080, train loss-0.4298, acc-0.8600, valid loss-0.3192, acc-0.9150, test loss-0.3298, acc-0.9125\n",
      "Iter-37090, train loss-0.3801, acc-0.8600, valid loss-0.3192, acc-0.9150, test loss-0.3298, acc-0.9123\n",
      "Iter-37100, train loss-0.2876, acc-0.9400, valid loss-0.3191, acc-0.9150, test loss-0.3297, acc-0.9124\n",
      "Iter-37110, train loss-0.2949, acc-0.9000, valid loss-0.3191, acc-0.9148, test loss-0.3297, acc-0.9122\n",
      "Iter-37120, train loss-0.4032, acc-0.9200, valid loss-0.3191, acc-0.9148, test loss-0.3296, acc-0.9122\n",
      "Iter-37130, train loss-0.2955, acc-0.9200, valid loss-0.3191, acc-0.9150, test loss-0.3296, acc-0.9123\n",
      "Iter-37140, train loss-0.4823, acc-0.8600, valid loss-0.3191, acc-0.9148, test loss-0.3296, acc-0.9123\n",
      "Iter-37150, train loss-0.4121, acc-0.8600, valid loss-0.3190, acc-0.9152, test loss-0.3295, acc-0.9123\n",
      "Iter-37160, train loss-0.3022, acc-0.9200, valid loss-0.3190, acc-0.9148, test loss-0.3294, acc-0.9123\n",
      "Iter-37170, train loss-0.3178, acc-0.9000, valid loss-0.3190, acc-0.9146, test loss-0.3294, acc-0.9126\n",
      "Iter-37180, train loss-0.4562, acc-0.8800, valid loss-0.3190, acc-0.9144, test loss-0.3293, acc-0.9125\n",
      "Iter-37190, train loss-0.3010, acc-0.8800, valid loss-0.3189, acc-0.9144, test loss-0.3292, acc-0.9126\n",
      "Iter-37200, train loss-0.2346, acc-0.9600, valid loss-0.3189, acc-0.9144, test loss-0.3292, acc-0.9124\n",
      "Iter-37210, train loss-0.3308, acc-0.8800, valid loss-0.3189, acc-0.9144, test loss-0.3292, acc-0.9122\n",
      "Iter-37220, train loss-0.2197, acc-0.9200, valid loss-0.3189, acc-0.9144, test loss-0.3291, acc-0.9124\n",
      "Iter-37230, train loss-0.2625, acc-0.9600, valid loss-0.3188, acc-0.9144, test loss-0.3291, acc-0.9124\n",
      "Iter-37240, train loss-0.4469, acc-0.8800, valid loss-0.3187, acc-0.9146, test loss-0.3290, acc-0.9125\n",
      "Iter-37250, train loss-0.5065, acc-0.8800, valid loss-0.3187, acc-0.9146, test loss-0.3290, acc-0.9124\n",
      "Iter-37260, train loss-0.2423, acc-0.8800, valid loss-0.3186, acc-0.9146, test loss-0.3289, acc-0.9126\n",
      "Iter-37270, train loss-0.2572, acc-0.9000, valid loss-0.3185, acc-0.9146, test loss-0.3289, acc-0.9126\n",
      "Iter-37280, train loss-0.4318, acc-0.9000, valid loss-0.3185, acc-0.9144, test loss-0.3289, acc-0.9125\n",
      "Iter-37290, train loss-0.4408, acc-0.8600, valid loss-0.3185, acc-0.9142, test loss-0.3288, acc-0.9125\n",
      "Iter-37300, train loss-0.3497, acc-0.9200, valid loss-0.3185, acc-0.9144, test loss-0.3288, acc-0.9123\n",
      "Iter-37310, train loss-0.2298, acc-0.9600, valid loss-0.3185, acc-0.9144, test loss-0.3287, acc-0.9124\n",
      "Iter-37320, train loss-0.2872, acc-0.9200, valid loss-0.3185, acc-0.9144, test loss-0.3287, acc-0.9124\n",
      "Iter-37330, train loss-0.2493, acc-0.9400, valid loss-0.3185, acc-0.9144, test loss-0.3286, acc-0.9124\n",
      "Iter-37340, train loss-0.2827, acc-0.9400, valid loss-0.3185, acc-0.9144, test loss-0.3286, acc-0.9123\n",
      "Iter-37350, train loss-0.1202, acc-0.9600, valid loss-0.3184, acc-0.9148, test loss-0.3286, acc-0.9124\n",
      "Iter-37360, train loss-0.2908, acc-0.9000, valid loss-0.3184, acc-0.9146, test loss-0.3285, acc-0.9124\n",
      "Iter-37370, train loss-0.2474, acc-0.9400, valid loss-0.3183, acc-0.9144, test loss-0.3285, acc-0.9123\n",
      "Iter-37380, train loss-0.3361, acc-0.9000, valid loss-0.3182, acc-0.9146, test loss-0.3285, acc-0.9124\n",
      "Iter-37390, train loss-0.2705, acc-0.9400, valid loss-0.3181, acc-0.9144, test loss-0.3284, acc-0.9128\n",
      "Iter-37400, train loss-0.3934, acc-0.9000, valid loss-0.3181, acc-0.9144, test loss-0.3284, acc-0.9127\n",
      "Iter-37410, train loss-0.2653, acc-0.9000, valid loss-0.3180, acc-0.9150, test loss-0.3284, acc-0.9127\n",
      "Iter-37420, train loss-0.2266, acc-0.9200, valid loss-0.3180, acc-0.9144, test loss-0.3284, acc-0.9127\n",
      "Iter-37430, train loss-0.2857, acc-0.9200, valid loss-0.3179, acc-0.9146, test loss-0.3284, acc-0.9126\n",
      "Iter-37440, train loss-0.3803, acc-0.8800, valid loss-0.3179, acc-0.9146, test loss-0.3283, acc-0.9129\n",
      "Iter-37450, train loss-0.3449, acc-0.9200, valid loss-0.3178, acc-0.9146, test loss-0.3283, acc-0.9129\n",
      "Iter-37460, train loss-0.3336, acc-0.9000, valid loss-0.3178, acc-0.9144, test loss-0.3282, acc-0.9128\n",
      "Iter-37470, train loss-0.1763, acc-0.9400, valid loss-0.3178, acc-0.9144, test loss-0.3281, acc-0.9129\n",
      "Iter-37480, train loss-0.3947, acc-0.8400, valid loss-0.3177, acc-0.9144, test loss-0.3281, acc-0.9130\n",
      "Iter-37490, train loss-0.3206, acc-0.9200, valid loss-0.3177, acc-0.9144, test loss-0.3281, acc-0.9129\n",
      "Iter-37500, train loss-0.2211, acc-0.9800, valid loss-0.3177, acc-0.9148, test loss-0.3281, acc-0.9129\n",
      "Iter-37510, train loss-0.1905, acc-0.9400, valid loss-0.3176, acc-0.9148, test loss-0.3280, acc-0.9129\n",
      "Iter-37520, train loss-0.3166, acc-0.8800, valid loss-0.3175, acc-0.9148, test loss-0.3280, acc-0.9127\n",
      "Iter-37530, train loss-0.3537, acc-0.8800, valid loss-0.3175, acc-0.9148, test loss-0.3279, acc-0.9127\n",
      "Iter-37540, train loss-0.2585, acc-0.9400, valid loss-0.3174, acc-0.9152, test loss-0.3278, acc-0.9128\n",
      "Iter-37550, train loss-0.2882, acc-0.9200, valid loss-0.3174, acc-0.9154, test loss-0.3279, acc-0.9128\n",
      "Iter-37560, train loss-0.2552, acc-0.8800, valid loss-0.3173, acc-0.9150, test loss-0.3278, acc-0.9128\n",
      "Iter-37570, train loss-0.2223, acc-0.9600, valid loss-0.3174, acc-0.9148, test loss-0.3278, acc-0.9128\n",
      "Iter-37580, train loss-0.4638, acc-0.9000, valid loss-0.3173, acc-0.9150, test loss-0.3278, acc-0.9127\n",
      "Iter-37590, train loss-0.3454, acc-0.8800, valid loss-0.3173, acc-0.9148, test loss-0.3277, acc-0.9127\n",
      "Iter-37600, train loss-0.3735, acc-0.9000, valid loss-0.3172, acc-0.9156, test loss-0.3277, acc-0.9127\n",
      "Iter-37610, train loss-0.4949, acc-0.8800, valid loss-0.3172, acc-0.9152, test loss-0.3277, acc-0.9128\n",
      "Iter-37620, train loss-0.2178, acc-0.9400, valid loss-0.3171, acc-0.9158, test loss-0.3277, acc-0.9128\n",
      "Iter-37630, train loss-0.4739, acc-0.8000, valid loss-0.3171, acc-0.9158, test loss-0.3277, acc-0.9127\n",
      "Iter-37640, train loss-0.2831, acc-0.9200, valid loss-0.3171, acc-0.9158, test loss-0.3276, acc-0.9125\n",
      "Iter-37650, train loss-0.3515, acc-0.9200, valid loss-0.3171, acc-0.9162, test loss-0.3276, acc-0.9124\n",
      "Iter-37660, train loss-0.3574, acc-0.9400, valid loss-0.3170, acc-0.9160, test loss-0.3276, acc-0.9125\n",
      "Iter-37670, train loss-0.5080, acc-0.8600, valid loss-0.3170, acc-0.9158, test loss-0.3276, acc-0.9126\n",
      "Iter-37680, train loss-0.4307, acc-0.9000, valid loss-0.3171, acc-0.9160, test loss-0.3275, acc-0.9125\n",
      "Iter-37690, train loss-0.3626, acc-0.9000, valid loss-0.3170, acc-0.9160, test loss-0.3275, acc-0.9126\n",
      "Iter-37700, train loss-0.3337, acc-0.9000, valid loss-0.3170, acc-0.9156, test loss-0.3274, acc-0.9126\n",
      "Iter-37710, train loss-0.1589, acc-0.9800, valid loss-0.3169, acc-0.9156, test loss-0.3273, acc-0.9126\n",
      "Iter-37720, train loss-0.4052, acc-0.9000, valid loss-0.3169, acc-0.9156, test loss-0.3273, acc-0.9128\n",
      "Iter-37730, train loss-0.2373, acc-0.9200, valid loss-0.3169, acc-0.9160, test loss-0.3273, acc-0.9127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-37740, train loss-0.3010, acc-0.9200, valid loss-0.3169, acc-0.9162, test loss-0.3273, acc-0.9127\n",
      "Iter-37750, train loss-0.3422, acc-0.9000, valid loss-0.3169, acc-0.9156, test loss-0.3273, acc-0.9128\n",
      "Iter-37760, train loss-0.4542, acc-0.8800, valid loss-0.3169, acc-0.9156, test loss-0.3273, acc-0.9128\n",
      "Iter-37770, train loss-0.2156, acc-0.9200, valid loss-0.3168, acc-0.9156, test loss-0.3273, acc-0.9127\n",
      "Iter-37780, train loss-0.2631, acc-0.9200, valid loss-0.3167, acc-0.9158, test loss-0.3272, acc-0.9128\n",
      "Iter-37790, train loss-0.5865, acc-0.8600, valid loss-0.3167, acc-0.9158, test loss-0.3272, acc-0.9127\n",
      "Iter-37800, train loss-0.2372, acc-0.9200, valid loss-0.3166, acc-0.9160, test loss-0.3271, acc-0.9128\n",
      "Iter-37810, train loss-0.2628, acc-0.9000, valid loss-0.3166, acc-0.9162, test loss-0.3271, acc-0.9129\n",
      "Iter-37820, train loss-0.3822, acc-0.8800, valid loss-0.3165, acc-0.9162, test loss-0.3271, acc-0.9128\n",
      "Iter-37830, train loss-0.3040, acc-0.9000, valid loss-0.3166, acc-0.9162, test loss-0.3271, acc-0.9127\n",
      "Iter-37840, train loss-0.1621, acc-0.9800, valid loss-0.3165, acc-0.9164, test loss-0.3270, acc-0.9126\n",
      "Iter-37850, train loss-0.4096, acc-0.9000, valid loss-0.3165, acc-0.9162, test loss-0.3270, acc-0.9126\n",
      "Iter-37860, train loss-0.2671, acc-0.9000, valid loss-0.3165, acc-0.9162, test loss-0.3269, acc-0.9124\n",
      "Iter-37870, train loss-0.2559, acc-0.9600, valid loss-0.3164, acc-0.9164, test loss-0.3268, acc-0.9124\n",
      "Iter-37880, train loss-0.4005, acc-0.8800, valid loss-0.3164, acc-0.9162, test loss-0.3268, acc-0.9123\n",
      "Iter-37890, train loss-0.1972, acc-0.9400, valid loss-0.3163, acc-0.9158, test loss-0.3268, acc-0.9126\n",
      "Iter-37900, train loss-0.3898, acc-0.9000, valid loss-0.3163, acc-0.9162, test loss-0.3267, acc-0.9125\n",
      "Iter-37910, train loss-0.4404, acc-0.9000, valid loss-0.3162, acc-0.9160, test loss-0.3267, acc-0.9127\n",
      "Iter-37920, train loss-0.2607, acc-0.9800, valid loss-0.3161, acc-0.9160, test loss-0.3267, acc-0.9127\n",
      "Iter-37930, train loss-0.3114, acc-0.8600, valid loss-0.3161, acc-0.9162, test loss-0.3266, acc-0.9127\n",
      "Iter-37940, train loss-0.2979, acc-0.8600, valid loss-0.3160, acc-0.9156, test loss-0.3266, acc-0.9128\n",
      "Iter-37950, train loss-0.4311, acc-0.8600, valid loss-0.3160, acc-0.9160, test loss-0.3265, acc-0.9128\n",
      "Iter-37960, train loss-0.5098, acc-0.8800, valid loss-0.3159, acc-0.9156, test loss-0.3265, acc-0.9130\n",
      "Iter-37970, train loss-0.2660, acc-0.9200, valid loss-0.3159, acc-0.9156, test loss-0.3264, acc-0.9131\n",
      "Iter-37980, train loss-0.3276, acc-0.9000, valid loss-0.3159, acc-0.9158, test loss-0.3264, acc-0.9129\n",
      "Iter-37990, train loss-0.3291, acc-0.9400, valid loss-0.3158, acc-0.9160, test loss-0.3264, acc-0.9129\n",
      "Iter-38000, train loss-0.3270, acc-0.9000, valid loss-0.3157, acc-0.9160, test loss-0.3264, acc-0.9128\n",
      "Iter-38010, train loss-0.2617, acc-0.9600, valid loss-0.3157, acc-0.9156, test loss-0.3263, acc-0.9130\n",
      "Iter-38020, train loss-0.1741, acc-1.0000, valid loss-0.3157, acc-0.9156, test loss-0.3263, acc-0.9131\n",
      "Iter-38030, train loss-0.2750, acc-0.9200, valid loss-0.3156, acc-0.9154, test loss-0.3263, acc-0.9132\n",
      "Iter-38040, train loss-0.2394, acc-0.9400, valid loss-0.3155, acc-0.9152, test loss-0.3262, acc-0.9130\n",
      "Iter-38050, train loss-0.2683, acc-0.9200, valid loss-0.3155, acc-0.9154, test loss-0.3261, acc-0.9132\n",
      "Iter-38060, train loss-0.4320, acc-0.8400, valid loss-0.3154, acc-0.9152, test loss-0.3261, acc-0.9132\n",
      "Iter-38070, train loss-0.2527, acc-0.9400, valid loss-0.3154, acc-0.9154, test loss-0.3260, acc-0.9131\n",
      "Iter-38080, train loss-0.4692, acc-0.8400, valid loss-0.3153, acc-0.9152, test loss-0.3260, acc-0.9133\n",
      "Iter-38090, train loss-0.4552, acc-0.8400, valid loss-0.3153, acc-0.9154, test loss-0.3260, acc-0.9133\n",
      "Iter-38100, train loss-0.3437, acc-0.9000, valid loss-0.3152, acc-0.9154, test loss-0.3259, acc-0.9133\n",
      "Iter-38110, train loss-0.4161, acc-0.9000, valid loss-0.3152, acc-0.9156, test loss-0.3259, acc-0.9132\n",
      "Iter-38120, train loss-0.2745, acc-0.9200, valid loss-0.3152, acc-0.9158, test loss-0.3259, acc-0.9131\n",
      "Iter-38130, train loss-0.3912, acc-0.9000, valid loss-0.3152, acc-0.9156, test loss-0.3259, acc-0.9133\n",
      "Iter-38140, train loss-0.4112, acc-0.8200, valid loss-0.3152, acc-0.9156, test loss-0.3258, acc-0.9132\n",
      "Iter-38150, train loss-0.2930, acc-0.9000, valid loss-0.3152, acc-0.9156, test loss-0.3258, acc-0.9131\n",
      "Iter-38160, train loss-0.3046, acc-0.9000, valid loss-0.3151, acc-0.9160, test loss-0.3258, acc-0.9130\n",
      "Iter-38170, train loss-0.4379, acc-0.9000, valid loss-0.3151, acc-0.9158, test loss-0.3257, acc-0.9132\n",
      "Iter-38180, train loss-0.4062, acc-0.8800, valid loss-0.3150, acc-0.9160, test loss-0.3257, acc-0.9130\n",
      "Iter-38190, train loss-0.1715, acc-0.9800, valid loss-0.3149, acc-0.9162, test loss-0.3256, acc-0.9131\n",
      "Iter-38200, train loss-0.4990, acc-0.8800, valid loss-0.3149, acc-0.9160, test loss-0.3256, acc-0.9130\n",
      "Iter-38210, train loss-0.1592, acc-0.9600, valid loss-0.3149, acc-0.9160, test loss-0.3256, acc-0.9130\n",
      "Iter-38220, train loss-0.2614, acc-0.9600, valid loss-0.3149, acc-0.9160, test loss-0.3256, acc-0.9127\n",
      "Iter-38230, train loss-0.2508, acc-0.9200, valid loss-0.3149, acc-0.9160, test loss-0.3255, acc-0.9128\n",
      "Iter-38240, train loss-0.3094, acc-0.9000, valid loss-0.3148, acc-0.9158, test loss-0.3254, acc-0.9127\n",
      "Iter-38250, train loss-0.3745, acc-0.8600, valid loss-0.3148, acc-0.9158, test loss-0.3254, acc-0.9131\n",
      "Iter-38260, train loss-0.3949, acc-0.9000, valid loss-0.3148, acc-0.9158, test loss-0.3253, acc-0.9129\n",
      "Iter-38270, train loss-0.3404, acc-0.9200, valid loss-0.3147, acc-0.9162, test loss-0.3253, acc-0.9129\n",
      "Iter-38280, train loss-0.1928, acc-0.9800, valid loss-0.3146, acc-0.9162, test loss-0.3253, acc-0.9128\n",
      "Iter-38290, train loss-0.5147, acc-0.8800, valid loss-0.3146, acc-0.9160, test loss-0.3253, acc-0.9128\n",
      "Iter-38300, train loss-0.2962, acc-0.9200, valid loss-0.3145, acc-0.9160, test loss-0.3253, acc-0.9127\n",
      "Iter-38310, train loss-0.1941, acc-0.9400, valid loss-0.3145, acc-0.9162, test loss-0.3252, acc-0.9128\n",
      "Iter-38320, train loss-0.2783, acc-0.9200, valid loss-0.3145, acc-0.9164, test loss-0.3252, acc-0.9127\n",
      "Iter-38330, train loss-0.3895, acc-0.9000, valid loss-0.3144, acc-0.9162, test loss-0.3251, acc-0.9129\n",
      "Iter-38340, train loss-0.2982, acc-0.9000, valid loss-0.3143, acc-0.9164, test loss-0.3251, acc-0.9129\n",
      "Iter-38350, train loss-0.1973, acc-0.9600, valid loss-0.3143, acc-0.9164, test loss-0.3250, acc-0.9129\n",
      "Iter-38360, train loss-0.1650, acc-0.9800, valid loss-0.3143, acc-0.9164, test loss-0.3250, acc-0.9129\n",
      "Iter-38370, train loss-0.2508, acc-0.9200, valid loss-0.3143, acc-0.9162, test loss-0.3249, acc-0.9129\n",
      "Iter-38380, train loss-0.2571, acc-0.9200, valid loss-0.3143, acc-0.9162, test loss-0.3249, acc-0.9127\n",
      "Iter-38390, train loss-0.5697, acc-0.8600, valid loss-0.3142, acc-0.9162, test loss-0.3249, acc-0.9127\n",
      "Iter-38400, train loss-0.3752, acc-0.9000, valid loss-0.3142, acc-0.9160, test loss-0.3248, acc-0.9127\n",
      "Iter-38410, train loss-0.2330, acc-0.9600, valid loss-0.3143, acc-0.9160, test loss-0.3248, acc-0.9128\n",
      "Iter-38420, train loss-0.6597, acc-0.8400, valid loss-0.3142, acc-0.9158, test loss-0.3247, acc-0.9128\n",
      "Iter-38430, train loss-0.4201, acc-0.9000, valid loss-0.3143, acc-0.9158, test loss-0.3247, acc-0.9128\n",
      "Iter-38440, train loss-0.4354, acc-0.8800, valid loss-0.3142, acc-0.9154, test loss-0.3246, acc-0.9130\n",
      "Iter-38450, train loss-0.1426, acc-0.9800, valid loss-0.3141, acc-0.9158, test loss-0.3246, acc-0.9127\n",
      "Iter-38460, train loss-0.3408, acc-0.9200, valid loss-0.3141, acc-0.9158, test loss-0.3245, acc-0.9127\n",
      "Iter-38470, train loss-0.3700, acc-0.9000, valid loss-0.3141, acc-0.9160, test loss-0.3245, acc-0.9129\n",
      "Iter-38480, train loss-0.3413, acc-0.9400, valid loss-0.3141, acc-0.9160, test loss-0.3245, acc-0.9129\n",
      "Iter-38490, train loss-0.2408, acc-0.9200, valid loss-0.3141, acc-0.9160, test loss-0.3244, acc-0.9127\n",
      "Iter-38500, train loss-0.6453, acc-0.7800, valid loss-0.3141, acc-0.9158, test loss-0.3244, acc-0.9128\n",
      "Iter-38510, train loss-0.4304, acc-0.8800, valid loss-0.3141, acc-0.9156, test loss-0.3244, acc-0.9126\n",
      "Iter-38520, train loss-0.3709, acc-0.8800, valid loss-0.3140, acc-0.9164, test loss-0.3244, acc-0.9124\n",
      "Iter-38530, train loss-0.4009, acc-0.8800, valid loss-0.3140, acc-0.9158, test loss-0.3244, acc-0.9125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-38540, train loss-0.4096, acc-0.8800, valid loss-0.3139, acc-0.9162, test loss-0.3243, acc-0.9126\n",
      "Iter-38550, train loss-0.2645, acc-0.9200, valid loss-0.3139, acc-0.9160, test loss-0.3243, acc-0.9126\n",
      "Iter-38560, train loss-0.4952, acc-0.8400, valid loss-0.3138, acc-0.9162, test loss-0.3242, acc-0.9126\n",
      "Iter-38570, train loss-0.1489, acc-0.9800, valid loss-0.3138, acc-0.9168, test loss-0.3242, acc-0.9127\n",
      "Iter-38580, train loss-0.2828, acc-0.8800, valid loss-0.3137, acc-0.9160, test loss-0.3241, acc-0.9128\n",
      "Iter-38590, train loss-0.5931, acc-0.8200, valid loss-0.3137, acc-0.9160, test loss-0.3241, acc-0.9127\n",
      "Iter-38600, train loss-0.4014, acc-0.8600, valid loss-0.3136, acc-0.9164, test loss-0.3241, acc-0.9128\n",
      "Iter-38610, train loss-0.4386, acc-0.9000, valid loss-0.3135, acc-0.9164, test loss-0.3240, acc-0.9129\n",
      "Iter-38620, train loss-0.6832, acc-0.8000, valid loss-0.3135, acc-0.9164, test loss-0.3239, acc-0.9128\n",
      "Iter-38630, train loss-0.5213, acc-0.8600, valid loss-0.3134, acc-0.9168, test loss-0.3239, acc-0.9128\n",
      "Iter-38640, train loss-0.2763, acc-0.9200, valid loss-0.3134, acc-0.9168, test loss-0.3238, acc-0.9129\n",
      "Iter-38650, train loss-0.3223, acc-0.9400, valid loss-0.3134, acc-0.9168, test loss-0.3238, acc-0.9128\n",
      "Iter-38660, train loss-0.2734, acc-0.9200, valid loss-0.3134, acc-0.9166, test loss-0.3237, acc-0.9129\n",
      "Iter-38670, train loss-0.3756, acc-0.8600, valid loss-0.3133, acc-0.9162, test loss-0.3237, acc-0.9130\n",
      "Iter-38680, train loss-0.3250, acc-0.9400, valid loss-0.3133, acc-0.9166, test loss-0.3236, acc-0.9129\n",
      "Iter-38690, train loss-0.2978, acc-0.9400, valid loss-0.3131, acc-0.9168, test loss-0.3235, acc-0.9130\n",
      "Iter-38700, train loss-0.2051, acc-0.9600, valid loss-0.3131, acc-0.9164, test loss-0.3236, acc-0.9129\n",
      "Iter-38710, train loss-0.2819, acc-0.9200, valid loss-0.3131, acc-0.9170, test loss-0.3235, acc-0.9129\n",
      "Iter-38720, train loss-0.2110, acc-0.9200, valid loss-0.3131, acc-0.9164, test loss-0.3235, acc-0.9130\n",
      "Iter-38730, train loss-0.3391, acc-0.8800, valid loss-0.3130, acc-0.9168, test loss-0.3234, acc-0.9130\n",
      "Iter-38740, train loss-0.3231, acc-0.9000, valid loss-0.3130, acc-0.9168, test loss-0.3234, acc-0.9131\n",
      "Iter-38750, train loss-0.4828, acc-0.8800, valid loss-0.3129, acc-0.9166, test loss-0.3234, acc-0.9131\n",
      "Iter-38760, train loss-0.4472, acc-0.9000, valid loss-0.3128, acc-0.9166, test loss-0.3233, acc-0.9134\n",
      "Iter-38770, train loss-0.2645, acc-0.9200, valid loss-0.3129, acc-0.9168, test loss-0.3233, acc-0.9137\n",
      "Iter-38780, train loss-0.2874, acc-0.9600, valid loss-0.3129, acc-0.9166, test loss-0.3232, acc-0.9134\n",
      "Iter-38790, train loss-0.3598, acc-0.9000, valid loss-0.3129, acc-0.9170, test loss-0.3232, acc-0.9133\n",
      "Iter-38800, train loss-0.2175, acc-0.9200, valid loss-0.3128, acc-0.9170, test loss-0.3231, acc-0.9136\n",
      "Iter-38810, train loss-0.3386, acc-0.9000, valid loss-0.3128, acc-0.9170, test loss-0.3231, acc-0.9134\n",
      "Iter-38820, train loss-0.5053, acc-0.8600, valid loss-0.3128, acc-0.9170, test loss-0.3231, acc-0.9137\n",
      "Iter-38830, train loss-0.3611, acc-0.8800, valid loss-0.3128, acc-0.9170, test loss-0.3231, acc-0.9136\n",
      "Iter-38840, train loss-0.3244, acc-0.9400, valid loss-0.3128, acc-0.9168, test loss-0.3230, acc-0.9138\n",
      "Iter-38850, train loss-0.2174, acc-0.9200, valid loss-0.3127, acc-0.9172, test loss-0.3230, acc-0.9137\n",
      "Iter-38860, train loss-0.4416, acc-0.8600, valid loss-0.3127, acc-0.9172, test loss-0.3229, acc-0.9135\n",
      "Iter-38870, train loss-0.3192, acc-0.9400, valid loss-0.3127, acc-0.9172, test loss-0.3229, acc-0.9133\n",
      "Iter-38880, train loss-0.2439, acc-0.9600, valid loss-0.3126, acc-0.9174, test loss-0.3229, acc-0.9135\n",
      "Iter-38890, train loss-0.2208, acc-0.9800, valid loss-0.3126, acc-0.9168, test loss-0.3228, acc-0.9134\n",
      "Iter-38900, train loss-0.2733, acc-0.9400, valid loss-0.3125, acc-0.9168, test loss-0.3228, acc-0.9136\n",
      "Iter-38910, train loss-0.4384, acc-0.8400, valid loss-0.3125, acc-0.9170, test loss-0.3228, acc-0.9138\n",
      "Iter-38920, train loss-0.1937, acc-0.9800, valid loss-0.3124, acc-0.9166, test loss-0.3228, acc-0.9135\n",
      "Iter-38930, train loss-0.2348, acc-0.9400, valid loss-0.3123, acc-0.9166, test loss-0.3227, acc-0.9138\n",
      "Iter-38940, train loss-0.2830, acc-0.8800, valid loss-0.3123, acc-0.9166, test loss-0.3227, acc-0.9136\n",
      "Iter-38950, train loss-0.5445, acc-0.8000, valid loss-0.3122, acc-0.9166, test loss-0.3227, acc-0.9136\n",
      "Iter-38960, train loss-0.4389, acc-0.8400, valid loss-0.3122, acc-0.9168, test loss-0.3226, acc-0.9137\n",
      "Iter-38970, train loss-0.3511, acc-0.8400, valid loss-0.3122, acc-0.9170, test loss-0.3226, acc-0.9137\n",
      "Iter-38980, train loss-0.2170, acc-0.9400, valid loss-0.3122, acc-0.9170, test loss-0.3226, acc-0.9138\n",
      "Iter-38990, train loss-0.5151, acc-0.8200, valid loss-0.3120, acc-0.9166, test loss-0.3226, acc-0.9136\n",
      "Iter-39000, train loss-0.2007, acc-1.0000, valid loss-0.3120, acc-0.9172, test loss-0.3225, acc-0.9136\n",
      "Iter-39010, train loss-0.3421, acc-0.9000, valid loss-0.3120, acc-0.9166, test loss-0.3225, acc-0.9135\n",
      "Iter-39020, train loss-0.2448, acc-0.9000, valid loss-0.3119, acc-0.9168, test loss-0.3224, acc-0.9136\n",
      "Iter-39030, train loss-0.3367, acc-0.9200, valid loss-0.3119, acc-0.9168, test loss-0.3224, acc-0.9137\n",
      "Iter-39040, train loss-0.2606, acc-0.9000, valid loss-0.3119, acc-0.9166, test loss-0.3224, acc-0.9137\n",
      "Iter-39050, train loss-0.3139, acc-0.9400, valid loss-0.3119, acc-0.9168, test loss-0.3223, acc-0.9139\n",
      "Iter-39060, train loss-0.2029, acc-0.9400, valid loss-0.3119, acc-0.9172, test loss-0.3222, acc-0.9137\n",
      "Iter-39070, train loss-0.4102, acc-0.8800, valid loss-0.3118, acc-0.9166, test loss-0.3222, acc-0.9137\n",
      "Iter-39080, train loss-0.4051, acc-0.8400, valid loss-0.3118, acc-0.9172, test loss-0.3222, acc-0.9136\n",
      "Iter-39090, train loss-0.3593, acc-0.8600, valid loss-0.3118, acc-0.9172, test loss-0.3222, acc-0.9137\n",
      "Iter-39100, train loss-0.3595, acc-0.9600, valid loss-0.3118, acc-0.9172, test loss-0.3221, acc-0.9138\n",
      "Iter-39110, train loss-0.5771, acc-0.8200, valid loss-0.3117, acc-0.9172, test loss-0.3221, acc-0.9138\n",
      "Iter-39120, train loss-0.3134, acc-0.9600, valid loss-0.3117, acc-0.9170, test loss-0.3221, acc-0.9137\n",
      "Iter-39130, train loss-0.2440, acc-0.9400, valid loss-0.3116, acc-0.9170, test loss-0.3220, acc-0.9137\n",
      "Iter-39140, train loss-0.3229, acc-0.9200, valid loss-0.3116, acc-0.9174, test loss-0.3219, acc-0.9137\n",
      "Iter-39150, train loss-0.2954, acc-0.8800, valid loss-0.3116, acc-0.9172, test loss-0.3219, acc-0.9138\n",
      "Iter-39160, train loss-0.3217, acc-0.9200, valid loss-0.3116, acc-0.9172, test loss-0.3219, acc-0.9138\n",
      "Iter-39170, train loss-0.3856, acc-0.9200, valid loss-0.3116, acc-0.9174, test loss-0.3219, acc-0.9138\n",
      "Iter-39180, train loss-0.2148, acc-0.9600, valid loss-0.3115, acc-0.9174, test loss-0.3218, acc-0.9138\n",
      "Iter-39190, train loss-0.1967, acc-0.9600, valid loss-0.3114, acc-0.9172, test loss-0.3218, acc-0.9138\n",
      "Iter-39200, train loss-0.2934, acc-0.8600, valid loss-0.3114, acc-0.9172, test loss-0.3218, acc-0.9137\n",
      "Iter-39210, train loss-0.3136, acc-0.9200, valid loss-0.3114, acc-0.9172, test loss-0.3217, acc-0.9137\n",
      "Iter-39220, train loss-0.6053, acc-0.7600, valid loss-0.3113, acc-0.9172, test loss-0.3217, acc-0.9137\n",
      "Iter-39230, train loss-0.1660, acc-0.9800, valid loss-0.3113, acc-0.9166, test loss-0.3217, acc-0.9137\n",
      "Iter-39240, train loss-0.4489, acc-0.9000, valid loss-0.3112, acc-0.9170, test loss-0.3217, acc-0.9136\n",
      "Iter-39250, train loss-0.2440, acc-0.9400, valid loss-0.3112, acc-0.9170, test loss-0.3217, acc-0.9136\n",
      "Iter-39260, train loss-0.2854, acc-0.9000, valid loss-0.3111, acc-0.9168, test loss-0.3216, acc-0.9138\n",
      "Iter-39270, train loss-0.3087, acc-0.9000, valid loss-0.3111, acc-0.9170, test loss-0.3216, acc-0.9137\n",
      "Iter-39280, train loss-0.4369, acc-0.8600, valid loss-0.3110, acc-0.9172, test loss-0.3215, acc-0.9136\n",
      "Iter-39290, train loss-0.3792, acc-0.9000, valid loss-0.3110, acc-0.9172, test loss-0.3215, acc-0.9136\n",
      "Iter-39300, train loss-0.3408, acc-0.8800, valid loss-0.3109, acc-0.9172, test loss-0.3215, acc-0.9136\n",
      "Iter-39310, train loss-0.3092, acc-0.9000, valid loss-0.3108, acc-0.9170, test loss-0.3215, acc-0.9136\n",
      "Iter-39320, train loss-0.2470, acc-0.9200, valid loss-0.3108, acc-0.9170, test loss-0.3214, acc-0.9136\n",
      "Iter-39330, train loss-0.2350, acc-0.9400, valid loss-0.3107, acc-0.9170, test loss-0.3214, acc-0.9135\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-39340, train loss-0.3285, acc-0.9000, valid loss-0.3107, acc-0.9170, test loss-0.3213, acc-0.9137\n",
      "Iter-39350, train loss-0.4332, acc-0.8800, valid loss-0.3106, acc-0.9168, test loss-0.3212, acc-0.9138\n",
      "Iter-39360, train loss-0.2538, acc-0.9400, valid loss-0.3106, acc-0.9168, test loss-0.3212, acc-0.9138\n",
      "Iter-39370, train loss-0.1361, acc-0.9600, valid loss-0.3106, acc-0.9168, test loss-0.3212, acc-0.9138\n",
      "Iter-39380, train loss-0.2601, acc-0.9200, valid loss-0.3106, acc-0.9170, test loss-0.3212, acc-0.9138\n",
      "Iter-39390, train loss-0.2261, acc-0.9400, valid loss-0.3106, acc-0.9176, test loss-0.3211, acc-0.9136\n",
      "Iter-39400, train loss-0.4897, acc-0.8600, valid loss-0.3106, acc-0.9172, test loss-0.3211, acc-0.9135\n",
      "Iter-39410, train loss-0.3460, acc-0.8800, valid loss-0.3105, acc-0.9172, test loss-0.3210, acc-0.9136\n",
      "Iter-39420, train loss-0.3009, acc-0.9400, valid loss-0.3105, acc-0.9176, test loss-0.3210, acc-0.9136\n",
      "Iter-39430, train loss-0.4487, acc-0.8800, valid loss-0.3105, acc-0.9176, test loss-0.3210, acc-0.9136\n",
      "Iter-39440, train loss-0.2716, acc-0.9200, valid loss-0.3104, acc-0.9174, test loss-0.3209, acc-0.9138\n",
      "Iter-39450, train loss-0.2483, acc-0.9400, valid loss-0.3104, acc-0.9178, test loss-0.3209, acc-0.9138\n",
      "Iter-39460, train loss-0.4870, acc-0.8800, valid loss-0.3104, acc-0.9178, test loss-0.3208, acc-0.9138\n",
      "Iter-39470, train loss-0.3048, acc-0.9000, valid loss-0.3104, acc-0.9174, test loss-0.3208, acc-0.9136\n",
      "Iter-39480, train loss-0.4475, acc-0.8800, valid loss-0.3104, acc-0.9172, test loss-0.3208, acc-0.9140\n",
      "Iter-39490, train loss-0.2195, acc-0.9400, valid loss-0.3104, acc-0.9172, test loss-0.3207, acc-0.9137\n",
      "Iter-39500, train loss-0.2140, acc-0.9200, valid loss-0.3103, acc-0.9172, test loss-0.3207, acc-0.9137\n",
      "Iter-39510, train loss-0.2310, acc-0.9400, valid loss-0.3103, acc-0.9174, test loss-0.3206, acc-0.9138\n",
      "Iter-39520, train loss-0.3146, acc-0.9000, valid loss-0.3102, acc-0.9174, test loss-0.3206, acc-0.9136\n",
      "Iter-39530, train loss-0.1389, acc-0.9600, valid loss-0.3102, acc-0.9174, test loss-0.3206, acc-0.9135\n",
      "Iter-39540, train loss-0.1962, acc-0.9600, valid loss-0.3102, acc-0.9174, test loss-0.3205, acc-0.9136\n",
      "Iter-39550, train loss-0.2848, acc-0.9200, valid loss-0.3101, acc-0.9176, test loss-0.3205, acc-0.9136\n",
      "Iter-39560, train loss-0.2903, acc-0.9200, valid loss-0.3100, acc-0.9172, test loss-0.3205, acc-0.9134\n",
      "Iter-39570, train loss-0.5423, acc-0.8800, valid loss-0.3100, acc-0.9178, test loss-0.3204, acc-0.9134\n",
      "Iter-39580, train loss-0.2187, acc-0.9600, valid loss-0.3100, acc-0.9178, test loss-0.3204, acc-0.9135\n",
      "Iter-39590, train loss-0.4543, acc-0.9000, valid loss-0.3099, acc-0.9174, test loss-0.3204, acc-0.9134\n",
      "Iter-39600, train loss-0.3300, acc-0.9200, valid loss-0.3099, acc-0.9178, test loss-0.3203, acc-0.9133\n",
      "Iter-39610, train loss-0.3426, acc-0.8800, valid loss-0.3098, acc-0.9176, test loss-0.3203, acc-0.9139\n",
      "Iter-39620, train loss-0.3580, acc-0.8600, valid loss-0.3097, acc-0.9176, test loss-0.3203, acc-0.9139\n",
      "Iter-39630, train loss-0.3902, acc-0.8600, valid loss-0.3097, acc-0.9176, test loss-0.3203, acc-0.9139\n",
      "Iter-39640, train loss-0.2792, acc-0.8800, valid loss-0.3096, acc-0.9176, test loss-0.3203, acc-0.9136\n",
      "Iter-39650, train loss-0.4829, acc-0.8800, valid loss-0.3096, acc-0.9180, test loss-0.3202, acc-0.9137\n",
      "Iter-39660, train loss-0.3763, acc-0.9200, valid loss-0.3096, acc-0.9176, test loss-0.3202, acc-0.9137\n",
      "Iter-39670, train loss-0.6197, acc-0.8400, valid loss-0.3095, acc-0.9174, test loss-0.3202, acc-0.9137\n",
      "Iter-39680, train loss-0.2794, acc-0.9400, valid loss-0.3095, acc-0.9174, test loss-0.3201, acc-0.9138\n",
      "Iter-39690, train loss-0.3300, acc-0.9200, valid loss-0.3095, acc-0.9176, test loss-0.3200, acc-0.9138\n",
      "Iter-39700, train loss-0.3529, acc-0.9400, valid loss-0.3095, acc-0.9174, test loss-0.3200, acc-0.9134\n",
      "Iter-39710, train loss-0.3317, acc-0.9800, valid loss-0.3095, acc-0.9174, test loss-0.3200, acc-0.9134\n",
      "Iter-39720, train loss-0.2168, acc-0.9200, valid loss-0.3094, acc-0.9172, test loss-0.3199, acc-0.9134\n",
      "Iter-39730, train loss-0.2991, acc-0.8800, valid loss-0.3094, acc-0.9176, test loss-0.3199, acc-0.9133\n",
      "Iter-39740, train loss-0.3668, acc-0.9200, valid loss-0.3095, acc-0.9170, test loss-0.3199, acc-0.9131\n",
      "Iter-39750, train loss-0.2966, acc-0.9000, valid loss-0.3094, acc-0.9174, test loss-0.3199, acc-0.9134\n",
      "Iter-39760, train loss-0.2352, acc-0.9600, valid loss-0.3093, acc-0.9174, test loss-0.3198, acc-0.9135\n",
      "Iter-39770, train loss-0.1824, acc-0.9600, valid loss-0.3093, acc-0.9176, test loss-0.3198, acc-0.9133\n",
      "Iter-39780, train loss-0.3346, acc-0.9000, valid loss-0.3093, acc-0.9176, test loss-0.3198, acc-0.9135\n",
      "Iter-39790, train loss-0.3716, acc-0.9000, valid loss-0.3093, acc-0.9176, test loss-0.3197, acc-0.9135\n",
      "Iter-39800, train loss-0.2876, acc-0.9400, valid loss-0.3092, acc-0.9176, test loss-0.3197, acc-0.9135\n",
      "Iter-39810, train loss-0.2724, acc-0.9200, valid loss-0.3092, acc-0.9172, test loss-0.3197, acc-0.9135\n",
      "Iter-39820, train loss-0.3972, acc-0.9000, valid loss-0.3092, acc-0.9174, test loss-0.3197, acc-0.9136\n",
      "Iter-39830, train loss-0.1543, acc-0.9600, valid loss-0.3092, acc-0.9172, test loss-0.3196, acc-0.9136\n",
      "Iter-39840, train loss-0.4186, acc-0.8600, valid loss-0.3091, acc-0.9174, test loss-0.3196, acc-0.9135\n",
      "Iter-39850, train loss-0.3065, acc-0.9000, valid loss-0.3091, acc-0.9170, test loss-0.3196, acc-0.9133\n",
      "Iter-39860, train loss-0.3219, acc-0.9200, valid loss-0.3090, acc-0.9170, test loss-0.3195, acc-0.9134\n",
      "Iter-39870, train loss-0.2356, acc-0.9400, valid loss-0.3090, acc-0.9170, test loss-0.3195, acc-0.9134\n",
      "Iter-39880, train loss-0.3256, acc-0.8800, valid loss-0.3089, acc-0.9168, test loss-0.3195, acc-0.9133\n",
      "Iter-39890, train loss-0.3627, acc-0.9000, valid loss-0.3089, acc-0.9166, test loss-0.3194, acc-0.9136\n",
      "Iter-39900, train loss-0.3594, acc-0.8800, valid loss-0.3089, acc-0.9166, test loss-0.3194, acc-0.9136\n",
      "Iter-39910, train loss-0.4172, acc-0.8800, valid loss-0.3088, acc-0.9164, test loss-0.3193, acc-0.9137\n",
      "Iter-39920, train loss-0.3965, acc-0.8600, valid loss-0.3088, acc-0.9162, test loss-0.3193, acc-0.9137\n",
      "Iter-39930, train loss-0.4073, acc-0.9000, valid loss-0.3087, acc-0.9162, test loss-0.3192, acc-0.9136\n",
      "Iter-39940, train loss-0.3765, acc-0.9200, valid loss-0.3086, acc-0.9166, test loss-0.3192, acc-0.9135\n",
      "Iter-39950, train loss-0.3451, acc-0.9000, valid loss-0.3086, acc-0.9166, test loss-0.3191, acc-0.9135\n",
      "Iter-39960, train loss-0.3849, acc-0.8800, valid loss-0.3085, acc-0.9168, test loss-0.3191, acc-0.9135\n",
      "Iter-39970, train loss-0.2005, acc-0.9200, valid loss-0.3084, acc-0.9174, test loss-0.3191, acc-0.9135\n",
      "Iter-39980, train loss-0.4411, acc-0.8600, valid loss-0.3084, acc-0.9170, test loss-0.3190, acc-0.9137\n",
      "Iter-39990, train loss-0.1963, acc-0.9600, valid loss-0.3084, acc-0.9168, test loss-0.3190, acc-0.9137\n",
      "Iter-40000, train loss-0.3043, acc-0.9200, valid loss-0.3084, acc-0.9162, test loss-0.3190, acc-0.9135\n",
      "Iter-40010, train loss-0.2150, acc-0.9600, valid loss-0.3084, acc-0.9164, test loss-0.3190, acc-0.9134\n",
      "Iter-40020, train loss-0.3760, acc-0.8800, valid loss-0.3084, acc-0.9164, test loss-0.3189, acc-0.9135\n",
      "Iter-40030, train loss-0.3386, acc-0.9200, valid loss-0.3084, acc-0.9166, test loss-0.3189, acc-0.9136\n",
      "Iter-40040, train loss-0.3744, acc-0.9000, valid loss-0.3084, acc-0.9170, test loss-0.3189, acc-0.9136\n",
      "Iter-40050, train loss-0.4813, acc-0.8400, valid loss-0.3085, acc-0.9170, test loss-0.3188, acc-0.9138\n",
      "Iter-40060, train loss-0.2651, acc-0.9400, valid loss-0.3083, acc-0.9172, test loss-0.3188, acc-0.9139\n",
      "Iter-40070, train loss-0.1656, acc-0.9600, valid loss-0.3083, acc-0.9170, test loss-0.3188, acc-0.9140\n",
      "Iter-40080, train loss-0.2975, acc-0.8800, valid loss-0.3082, acc-0.9168, test loss-0.3187, acc-0.9140\n",
      "Iter-40090, train loss-0.4974, acc-0.8800, valid loss-0.3081, acc-0.9168, test loss-0.3187, acc-0.9140\n",
      "Iter-40100, train loss-0.2243, acc-0.9400, valid loss-0.3080, acc-0.9168, test loss-0.3186, acc-0.9142\n",
      "Iter-40110, train loss-0.3181, acc-0.8800, valid loss-0.3080, acc-0.9168, test loss-0.3186, acc-0.9142\n",
      "Iter-40120, train loss-0.3532, acc-0.9000, valid loss-0.3080, acc-0.9176, test loss-0.3185, acc-0.9143\n",
      "Iter-40130, train loss-0.4584, acc-0.8200, valid loss-0.3079, acc-0.9174, test loss-0.3185, acc-0.9143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40140, train loss-0.3452, acc-0.8800, valid loss-0.3079, acc-0.9176, test loss-0.3185, acc-0.9142\n",
      "Iter-40150, train loss-0.5147, acc-0.8800, valid loss-0.3079, acc-0.9172, test loss-0.3185, acc-0.9141\n",
      "Iter-40160, train loss-0.3901, acc-0.8600, valid loss-0.3079, acc-0.9170, test loss-0.3184, acc-0.9143\n",
      "Iter-40170, train loss-0.2212, acc-0.9400, valid loss-0.3078, acc-0.9170, test loss-0.3184, acc-0.9142\n",
      "Iter-40180, train loss-0.3055, acc-0.9400, valid loss-0.3078, acc-0.9170, test loss-0.3184, acc-0.9142\n",
      "Iter-40190, train loss-0.1931, acc-0.9600, valid loss-0.3077, acc-0.9170, test loss-0.3183, acc-0.9142\n",
      "Iter-40200, train loss-0.2888, acc-0.9400, valid loss-0.3077, acc-0.9170, test loss-0.3183, acc-0.9142\n",
      "Iter-40210, train loss-0.1714, acc-0.9600, valid loss-0.3077, acc-0.9168, test loss-0.3182, acc-0.9145\n",
      "Iter-40220, train loss-0.3523, acc-0.9200, valid loss-0.3077, acc-0.9170, test loss-0.3182, acc-0.9143\n",
      "Iter-40230, train loss-0.4746, acc-0.8400, valid loss-0.3077, acc-0.9170, test loss-0.3181, acc-0.9141\n",
      "Iter-40240, train loss-0.4436, acc-0.8800, valid loss-0.3077, acc-0.9170, test loss-0.3180, acc-0.9143\n",
      "Iter-40250, train loss-0.1825, acc-0.9600, valid loss-0.3076, acc-0.9172, test loss-0.3180, acc-0.9142\n",
      "Iter-40260, train loss-0.1972, acc-0.9400, valid loss-0.3076, acc-0.9170, test loss-0.3180, acc-0.9144\n",
      "Iter-40270, train loss-0.5050, acc-0.8800, valid loss-0.3075, acc-0.9176, test loss-0.3179, acc-0.9144\n",
      "Iter-40280, train loss-0.4792, acc-0.8800, valid loss-0.3075, acc-0.9172, test loss-0.3179, acc-0.9144\n",
      "Iter-40290, train loss-0.2940, acc-0.9600, valid loss-0.3075, acc-0.9172, test loss-0.3178, acc-0.9141\n",
      "Iter-40300, train loss-0.2857, acc-0.9000, valid loss-0.3076, acc-0.9170, test loss-0.3178, acc-0.9142\n",
      "Iter-40310, train loss-0.2769, acc-0.9000, valid loss-0.3075, acc-0.9172, test loss-0.3177, acc-0.9141\n",
      "Iter-40320, train loss-0.4714, acc-0.8200, valid loss-0.3075, acc-0.9174, test loss-0.3177, acc-0.9143\n",
      "Iter-40330, train loss-0.4087, acc-0.8800, valid loss-0.3075, acc-0.9174, test loss-0.3177, acc-0.9141\n",
      "Iter-40340, train loss-0.1505, acc-0.9800, valid loss-0.3074, acc-0.9172, test loss-0.3176, acc-0.9140\n",
      "Iter-40350, train loss-0.2166, acc-0.9600, valid loss-0.3074, acc-0.9176, test loss-0.3176, acc-0.9141\n",
      "Iter-40360, train loss-0.3625, acc-0.9600, valid loss-0.3074, acc-0.9178, test loss-0.3176, acc-0.9142\n",
      "Iter-40370, train loss-0.3703, acc-0.9200, valid loss-0.3073, acc-0.9178, test loss-0.3176, acc-0.9143\n",
      "Iter-40380, train loss-0.2684, acc-0.9200, valid loss-0.3072, acc-0.9176, test loss-0.3176, acc-0.9143\n",
      "Iter-40390, train loss-0.3927, acc-0.9200, valid loss-0.3072, acc-0.9174, test loss-0.3176, acc-0.9143\n",
      "Iter-40400, train loss-0.3168, acc-0.8400, valid loss-0.3071, acc-0.9174, test loss-0.3176, acc-0.9143\n",
      "Iter-40410, train loss-0.4868, acc-0.8400, valid loss-0.3071, acc-0.9176, test loss-0.3175, acc-0.9143\n",
      "Iter-40420, train loss-0.2477, acc-0.9200, valid loss-0.3071, acc-0.9178, test loss-0.3175, acc-0.9144\n",
      "Iter-40430, train loss-0.2324, acc-0.9600, valid loss-0.3070, acc-0.9178, test loss-0.3175, acc-0.9140\n",
      "Iter-40440, train loss-0.3053, acc-0.8800, valid loss-0.3069, acc-0.9178, test loss-0.3174, acc-0.9143\n",
      "Iter-40450, train loss-0.5422, acc-0.9200, valid loss-0.3069, acc-0.9178, test loss-0.3174, acc-0.9142\n",
      "Iter-40460, train loss-0.2483, acc-0.9400, valid loss-0.3069, acc-0.9178, test loss-0.3174, acc-0.9144\n",
      "Iter-40470, train loss-0.3410, acc-0.8800, valid loss-0.3069, acc-0.9180, test loss-0.3174, acc-0.9144\n",
      "Iter-40480, train loss-0.2745, acc-0.9400, valid loss-0.3069, acc-0.9178, test loss-0.3173, acc-0.9144\n",
      "Iter-40490, train loss-0.4827, acc-0.9200, valid loss-0.3069, acc-0.9182, test loss-0.3173, acc-0.9143\n",
      "Iter-40500, train loss-0.3156, acc-0.8800, valid loss-0.3068, acc-0.9178, test loss-0.3173, acc-0.9142\n",
      "Iter-40510, train loss-0.1826, acc-0.9800, valid loss-0.3067, acc-0.9178, test loss-0.3172, acc-0.9140\n",
      "Iter-40520, train loss-0.4823, acc-0.8800, valid loss-0.3067, acc-0.9178, test loss-0.3172, acc-0.9143\n",
      "Iter-40530, train loss-0.5340, acc-0.9000, valid loss-0.3067, acc-0.9180, test loss-0.3172, acc-0.9145\n",
      "Iter-40540, train loss-0.4508, acc-0.8400, valid loss-0.3066, acc-0.9176, test loss-0.3172, acc-0.9145\n",
      "Iter-40550, train loss-0.2756, acc-0.9400, valid loss-0.3066, acc-0.9172, test loss-0.3171, acc-0.9144\n",
      "Iter-40560, train loss-0.2615, acc-0.9200, valid loss-0.3066, acc-0.9172, test loss-0.3171, acc-0.9145\n",
      "Iter-40570, train loss-0.2730, acc-0.9000, valid loss-0.3066, acc-0.9172, test loss-0.3171, acc-0.9145\n",
      "Iter-40580, train loss-0.3340, acc-0.9000, valid loss-0.3066, acc-0.9172, test loss-0.3170, acc-0.9147\n",
      "Iter-40590, train loss-0.2217, acc-0.9400, valid loss-0.3066, acc-0.9170, test loss-0.3170, acc-0.9146\n",
      "Iter-40600, train loss-0.1747, acc-0.9600, valid loss-0.3065, acc-0.9172, test loss-0.3170, acc-0.9145\n",
      "Iter-40610, train loss-0.2243, acc-0.9200, valid loss-0.3065, acc-0.9172, test loss-0.3169, acc-0.9145\n",
      "Iter-40620, train loss-0.4838, acc-0.8200, valid loss-0.3064, acc-0.9174, test loss-0.3169, acc-0.9145\n",
      "Iter-40630, train loss-0.2664, acc-0.9000, valid loss-0.3064, acc-0.9172, test loss-0.3169, acc-0.9145\n",
      "Iter-40640, train loss-0.4619, acc-0.8600, valid loss-0.3063, acc-0.9178, test loss-0.3169, acc-0.9146\n",
      "Iter-40650, train loss-0.3626, acc-0.9400, valid loss-0.3063, acc-0.9172, test loss-0.3169, acc-0.9149\n",
      "Iter-40660, train loss-0.1816, acc-0.9800, valid loss-0.3062, acc-0.9174, test loss-0.3168, acc-0.9150\n",
      "Iter-40670, train loss-0.2059, acc-0.9400, valid loss-0.3062, acc-0.9174, test loss-0.3168, acc-0.9148\n",
      "Iter-40680, train loss-0.1765, acc-0.9600, valid loss-0.3062, acc-0.9174, test loss-0.3168, acc-0.9147\n",
      "Iter-40690, train loss-0.5517, acc-0.8600, valid loss-0.3062, acc-0.9172, test loss-0.3167, acc-0.9147\n",
      "Iter-40700, train loss-0.2003, acc-0.9600, valid loss-0.3062, acc-0.9174, test loss-0.3168, acc-0.9147\n",
      "Iter-40710, train loss-0.1682, acc-0.9800, valid loss-0.3061, acc-0.9174, test loss-0.3168, acc-0.9145\n",
      "Iter-40720, train loss-0.2206, acc-0.9200, valid loss-0.3061, acc-0.9172, test loss-0.3167, acc-0.9145\n",
      "Iter-40730, train loss-0.4232, acc-0.9400, valid loss-0.3060, acc-0.9172, test loss-0.3167, acc-0.9144\n",
      "Iter-40740, train loss-0.3682, acc-0.9000, valid loss-0.3061, acc-0.9174, test loss-0.3167, acc-0.9143\n",
      "Iter-40750, train loss-0.3726, acc-0.8800, valid loss-0.3059, acc-0.9174, test loss-0.3167, acc-0.9143\n",
      "Iter-40760, train loss-0.3333, acc-0.9200, valid loss-0.3060, acc-0.9174, test loss-0.3167, acc-0.9142\n",
      "Iter-40770, train loss-0.2842, acc-0.9200, valid loss-0.3059, acc-0.9172, test loss-0.3166, acc-0.9143\n",
      "Iter-40780, train loss-0.2051, acc-0.9400, valid loss-0.3059, acc-0.9180, test loss-0.3166, acc-0.9144\n",
      "Iter-40790, train loss-0.2593, acc-0.9000, valid loss-0.3058, acc-0.9170, test loss-0.3165, acc-0.9145\n",
      "Iter-40800, train loss-0.3690, acc-0.9200, valid loss-0.3058, acc-0.9176, test loss-0.3165, acc-0.9142\n",
      "Iter-40810, train loss-0.2327, acc-0.9200, valid loss-0.3057, acc-0.9176, test loss-0.3164, acc-0.9145\n",
      "Iter-40820, train loss-0.3519, acc-0.9200, valid loss-0.3057, acc-0.9176, test loss-0.3164, acc-0.9145\n",
      "Iter-40830, train loss-0.4103, acc-0.9000, valid loss-0.3057, acc-0.9178, test loss-0.3164, acc-0.9147\n",
      "Iter-40840, train loss-0.3339, acc-0.9000, valid loss-0.3057, acc-0.9178, test loss-0.3163, acc-0.9144\n",
      "Iter-40850, train loss-0.2572, acc-0.8800, valid loss-0.3056, acc-0.9178, test loss-0.3163, acc-0.9144\n",
      "Iter-40860, train loss-0.3551, acc-0.9000, valid loss-0.3056, acc-0.9180, test loss-0.3163, acc-0.9145\n",
      "Iter-40870, train loss-0.3235, acc-0.9200, valid loss-0.3056, acc-0.9180, test loss-0.3162, acc-0.9146\n",
      "Iter-40880, train loss-0.2081, acc-0.9400, valid loss-0.3055, acc-0.9176, test loss-0.3162, acc-0.9145\n",
      "Iter-40890, train loss-0.2202, acc-0.9200, valid loss-0.3055, acc-0.9176, test loss-0.3161, acc-0.9145\n",
      "Iter-40900, train loss-0.3986, acc-0.9000, valid loss-0.3055, acc-0.9174, test loss-0.3161, acc-0.9145\n",
      "Iter-40910, train loss-0.3084, acc-0.9200, valid loss-0.3055, acc-0.9174, test loss-0.3161, acc-0.9144\n",
      "Iter-40920, train loss-0.3815, acc-0.9200, valid loss-0.3055, acc-0.9174, test loss-0.3161, acc-0.9146\n",
      "Iter-40930, train loss-0.3024, acc-0.9200, valid loss-0.3054, acc-0.9174, test loss-0.3161, acc-0.9144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40940, train loss-0.2571, acc-0.9600, valid loss-0.3054, acc-0.9170, test loss-0.3161, acc-0.9146\n",
      "Iter-40950, train loss-0.4449, acc-0.8400, valid loss-0.3053, acc-0.9172, test loss-0.3160, acc-0.9146\n",
      "Iter-40960, train loss-0.3248, acc-0.9000, valid loss-0.3053, acc-0.9176, test loss-0.3159, acc-0.9144\n",
      "Iter-40970, train loss-0.2069, acc-0.9200, valid loss-0.3052, acc-0.9176, test loss-0.3159, acc-0.9145\n",
      "Iter-40980, train loss-0.6230, acc-0.8800, valid loss-0.3052, acc-0.9180, test loss-0.3159, acc-0.9146\n",
      "Iter-40990, train loss-0.2902, acc-0.8800, valid loss-0.3052, acc-0.9172, test loss-0.3158, acc-0.9146\n",
      "Iter-41000, train loss-0.2435, acc-0.9600, valid loss-0.3051, acc-0.9174, test loss-0.3158, acc-0.9147\n",
      "Iter-41010, train loss-0.3143, acc-0.9400, valid loss-0.3050, acc-0.9174, test loss-0.3157, acc-0.9147\n",
      "Iter-41020, train loss-0.3384, acc-0.9000, valid loss-0.3050, acc-0.9176, test loss-0.3157, acc-0.9147\n",
      "Iter-41030, train loss-0.2655, acc-0.9000, valid loss-0.3050, acc-0.9172, test loss-0.3158, acc-0.9146\n",
      "Iter-41040, train loss-0.3477, acc-0.9200, valid loss-0.3050, acc-0.9172, test loss-0.3157, acc-0.9144\n",
      "Iter-41050, train loss-0.4291, acc-0.8400, valid loss-0.3049, acc-0.9176, test loss-0.3157, acc-0.9145\n",
      "Iter-41060, train loss-0.2852, acc-0.9200, valid loss-0.3049, acc-0.9176, test loss-0.3156, acc-0.9145\n",
      "Iter-41070, train loss-0.2364, acc-0.9400, valid loss-0.3048, acc-0.9178, test loss-0.3156, acc-0.9146\n",
      "Iter-41080, train loss-0.1587, acc-0.9800, valid loss-0.3048, acc-0.9176, test loss-0.3155, acc-0.9146\n",
      "Iter-41090, train loss-0.4524, acc-0.8800, valid loss-0.3048, acc-0.9176, test loss-0.3155, acc-0.9146\n",
      "Iter-41100, train loss-0.2665, acc-0.9200, valid loss-0.3047, acc-0.9174, test loss-0.3155, acc-0.9148\n",
      "Iter-41110, train loss-0.2273, acc-0.9800, valid loss-0.3048, acc-0.9174, test loss-0.3155, acc-0.9148\n",
      "Iter-41120, train loss-0.3540, acc-0.9000, valid loss-0.3048, acc-0.9178, test loss-0.3154, acc-0.9146\n",
      "Iter-41130, train loss-0.4065, acc-0.8600, valid loss-0.3048, acc-0.9178, test loss-0.3154, acc-0.9146\n",
      "Iter-41140, train loss-0.4283, acc-0.8800, valid loss-0.3048, acc-0.9180, test loss-0.3154, acc-0.9148\n",
      "Iter-41150, train loss-0.1474, acc-0.9600, valid loss-0.3047, acc-0.9182, test loss-0.3154, acc-0.9148\n",
      "Iter-41160, train loss-0.2175, acc-0.9800, valid loss-0.3046, acc-0.9182, test loss-0.3153, acc-0.9147\n",
      "Iter-41170, train loss-0.3206, acc-0.9400, valid loss-0.3046, acc-0.9178, test loss-0.3153, acc-0.9147\n",
      "Iter-41180, train loss-0.2893, acc-0.9200, valid loss-0.3045, acc-0.9178, test loss-0.3153, acc-0.9145\n",
      "Iter-41190, train loss-0.2631, acc-0.9200, valid loss-0.3045, acc-0.9178, test loss-0.3153, acc-0.9145\n",
      "Iter-41200, train loss-0.3740, acc-0.8600, valid loss-0.3045, acc-0.9180, test loss-0.3153, acc-0.9145\n",
      "Iter-41210, train loss-0.2632, acc-0.9400, valid loss-0.3045, acc-0.9182, test loss-0.3153, acc-0.9146\n",
      "Iter-41220, train loss-0.1593, acc-0.9800, valid loss-0.3044, acc-0.9178, test loss-0.3152, acc-0.9147\n",
      "Iter-41230, train loss-0.2692, acc-0.9000, valid loss-0.3043, acc-0.9182, test loss-0.3152, acc-0.9146\n",
      "Iter-41240, train loss-0.3756, acc-0.9200, valid loss-0.3043, acc-0.9182, test loss-0.3152, acc-0.9145\n",
      "Iter-41250, train loss-0.2511, acc-0.9000, valid loss-0.3044, acc-0.9182, test loss-0.3151, acc-0.9147\n",
      "Iter-41260, train loss-0.2644, acc-0.9200, valid loss-0.3043, acc-0.9180, test loss-0.3151, acc-0.9147\n",
      "Iter-41270, train loss-0.2453, acc-0.9200, valid loss-0.3043, acc-0.9178, test loss-0.3151, acc-0.9147\n",
      "Iter-41280, train loss-0.5221, acc-0.7800, valid loss-0.3042, acc-0.9178, test loss-0.3151, acc-0.9146\n",
      "Iter-41290, train loss-0.5379, acc-0.8400, valid loss-0.3042, acc-0.9180, test loss-0.3151, acc-0.9148\n",
      "Iter-41300, train loss-0.4750, acc-0.8400, valid loss-0.3042, acc-0.9180, test loss-0.3150, acc-0.9148\n",
      "Iter-41310, train loss-0.2802, acc-0.9200, valid loss-0.3041, acc-0.9180, test loss-0.3150, acc-0.9147\n",
      "Iter-41320, train loss-0.3266, acc-0.9200, valid loss-0.3041, acc-0.9180, test loss-0.3149, acc-0.9147\n",
      "Iter-41330, train loss-0.2640, acc-0.9000, valid loss-0.3041, acc-0.9180, test loss-0.3148, acc-0.9146\n",
      "Iter-41340, train loss-0.2909, acc-0.9200, valid loss-0.3041, acc-0.9178, test loss-0.3148, acc-0.9147\n",
      "Iter-41350, train loss-0.2826, acc-0.9200, valid loss-0.3041, acc-0.9178, test loss-0.3148, acc-0.9148\n",
      "Iter-41360, train loss-0.4483, acc-0.8400, valid loss-0.3041, acc-0.9180, test loss-0.3148, acc-0.9149\n",
      "Iter-41370, train loss-0.2008, acc-0.9400, valid loss-0.3040, acc-0.9176, test loss-0.3148, acc-0.9148\n",
      "Iter-41380, train loss-0.4444, acc-0.8800, valid loss-0.3040, acc-0.9178, test loss-0.3148, acc-0.9148\n",
      "Iter-41390, train loss-0.3355, acc-0.8800, valid loss-0.3040, acc-0.9182, test loss-0.3147, acc-0.9148\n",
      "Iter-41400, train loss-0.3692, acc-0.9000, valid loss-0.3039, acc-0.9184, test loss-0.3147, acc-0.9149\n",
      "Iter-41410, train loss-0.3577, acc-0.8800, valid loss-0.3039, acc-0.9178, test loss-0.3147, acc-0.9148\n",
      "Iter-41420, train loss-0.4316, acc-0.8800, valid loss-0.3039, acc-0.9184, test loss-0.3147, acc-0.9149\n",
      "Iter-41430, train loss-0.3558, acc-0.9400, valid loss-0.3038, acc-0.9180, test loss-0.3147, acc-0.9149\n",
      "Iter-41440, train loss-0.4316, acc-0.9000, valid loss-0.3037, acc-0.9178, test loss-0.3146, acc-0.9148\n",
      "Iter-41450, train loss-0.3785, acc-0.9200, valid loss-0.3037, acc-0.9182, test loss-0.3146, acc-0.9147\n",
      "Iter-41460, train loss-0.2346, acc-0.9200, valid loss-0.3036, acc-0.9182, test loss-0.3146, acc-0.9148\n",
      "Iter-41470, train loss-0.4663, acc-0.8600, valid loss-0.3036, acc-0.9182, test loss-0.3146, acc-0.9147\n",
      "Iter-41480, train loss-0.2682, acc-0.9000, valid loss-0.3036, acc-0.9182, test loss-0.3146, acc-0.9147\n",
      "Iter-41490, train loss-0.1998, acc-0.9600, valid loss-0.3036, acc-0.9178, test loss-0.3146, acc-0.9148\n",
      "Iter-41500, train loss-0.4268, acc-0.8800, valid loss-0.3036, acc-0.9176, test loss-0.3146, acc-0.9149\n",
      "Iter-41510, train loss-0.2029, acc-0.9400, valid loss-0.3036, acc-0.9180, test loss-0.3146, acc-0.9149\n",
      "Iter-41520, train loss-0.4739, acc-0.8600, valid loss-0.3035, acc-0.9182, test loss-0.3145, acc-0.9149\n",
      "Iter-41530, train loss-0.3661, acc-0.8200, valid loss-0.3035, acc-0.9184, test loss-0.3145, acc-0.9147\n",
      "Iter-41540, train loss-0.3562, acc-0.9200, valid loss-0.3035, acc-0.9188, test loss-0.3144, acc-0.9148\n",
      "Iter-41550, train loss-0.4907, acc-0.9000, valid loss-0.3035, acc-0.9188, test loss-0.3144, acc-0.9147\n",
      "Iter-41560, train loss-0.2869, acc-0.9400, valid loss-0.3035, acc-0.9182, test loss-0.3145, acc-0.9149\n",
      "Iter-41570, train loss-0.2513, acc-0.9000, valid loss-0.3035, acc-0.9182, test loss-0.3144, acc-0.9149\n",
      "Iter-41580, train loss-0.2271, acc-0.9600, valid loss-0.3034, acc-0.9190, test loss-0.3144, acc-0.9149\n",
      "Iter-41590, train loss-0.3652, acc-0.8600, valid loss-0.3034, acc-0.9186, test loss-0.3144, acc-0.9148\n",
      "Iter-41600, train loss-0.2649, acc-0.9000, valid loss-0.3034, acc-0.9182, test loss-0.3144, acc-0.9146\n",
      "Iter-41610, train loss-0.4327, acc-0.8600, valid loss-0.3034, acc-0.9186, test loss-0.3143, acc-0.9148\n",
      "Iter-41620, train loss-0.4131, acc-0.9000, valid loss-0.3034, acc-0.9186, test loss-0.3143, acc-0.9146\n",
      "Iter-41630, train loss-0.5440, acc-0.8600, valid loss-0.3033, acc-0.9186, test loss-0.3142, acc-0.9146\n",
      "Iter-41640, train loss-0.4912, acc-0.8600, valid loss-0.3033, acc-0.9188, test loss-0.3142, acc-0.9147\n",
      "Iter-41650, train loss-0.3080, acc-0.9400, valid loss-0.3033, acc-0.9184, test loss-0.3142, acc-0.9149\n",
      "Iter-41660, train loss-0.2240, acc-0.9200, valid loss-0.3033, acc-0.9186, test loss-0.3142, acc-0.9151\n",
      "Iter-41670, train loss-0.1597, acc-0.9800, valid loss-0.3033, acc-0.9188, test loss-0.3141, acc-0.9147\n",
      "Iter-41680, train loss-0.3075, acc-0.9000, valid loss-0.3033, acc-0.9190, test loss-0.3141, acc-0.9148\n",
      "Iter-41690, train loss-0.1767, acc-0.9600, valid loss-0.3032, acc-0.9190, test loss-0.3141, acc-0.9147\n",
      "Iter-41700, train loss-0.3744, acc-0.9400, valid loss-0.3032, acc-0.9188, test loss-0.3141, acc-0.9150\n",
      "Iter-41710, train loss-0.4081, acc-0.9000, valid loss-0.3031, acc-0.9186, test loss-0.3140, acc-0.9147\n",
      "Iter-41720, train loss-0.4171, acc-0.9000, valid loss-0.3031, acc-0.9186, test loss-0.3140, acc-0.9148\n",
      "Iter-41730, train loss-0.3697, acc-0.9200, valid loss-0.3031, acc-0.9188, test loss-0.3140, acc-0.9149\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-41740, train loss-0.2706, acc-0.9400, valid loss-0.3031, acc-0.9186, test loss-0.3140, acc-0.9146\n",
      "Iter-41750, train loss-0.2932, acc-0.9200, valid loss-0.3030, acc-0.9188, test loss-0.3140, acc-0.9145\n",
      "Iter-41760, train loss-0.4242, acc-0.8200, valid loss-0.3030, acc-0.9188, test loss-0.3140, acc-0.9145\n",
      "Iter-41770, train loss-0.3916, acc-0.8800, valid loss-0.3029, acc-0.9190, test loss-0.3139, acc-0.9147\n",
      "Iter-41780, train loss-0.4762, acc-0.8200, valid loss-0.3029, acc-0.9190, test loss-0.3139, acc-0.9146\n",
      "Iter-41790, train loss-0.2559, acc-0.9200, valid loss-0.3029, acc-0.9190, test loss-0.3138, acc-0.9145\n",
      "Iter-41800, train loss-0.3257, acc-0.9200, valid loss-0.3028, acc-0.9186, test loss-0.3138, acc-0.9146\n",
      "Iter-41810, train loss-0.2849, acc-0.9600, valid loss-0.3028, acc-0.9190, test loss-0.3138, acc-0.9147\n",
      "Iter-41820, train loss-0.3076, acc-0.9400, valid loss-0.3028, acc-0.9188, test loss-0.3138, acc-0.9149\n",
      "Iter-41830, train loss-0.3308, acc-0.8800, valid loss-0.3028, acc-0.9188, test loss-0.3138, acc-0.9149\n",
      "Iter-41840, train loss-0.3194, acc-0.9000, valid loss-0.3028, acc-0.9190, test loss-0.3138, acc-0.9148\n",
      "Iter-41850, train loss-0.3032, acc-0.9400, valid loss-0.3028, acc-0.9192, test loss-0.3138, acc-0.9147\n",
      "Iter-41860, train loss-0.2707, acc-0.9200, valid loss-0.3028, acc-0.9192, test loss-0.3138, acc-0.9150\n",
      "Iter-41870, train loss-0.4976, acc-0.9000, valid loss-0.3028, acc-0.9188, test loss-0.3138, acc-0.9150\n",
      "Iter-41880, train loss-0.3197, acc-0.9000, valid loss-0.3028, acc-0.9188, test loss-0.3137, acc-0.9143\n",
      "Iter-41890, train loss-0.2722, acc-0.9000, valid loss-0.3029, acc-0.9190, test loss-0.3138, acc-0.9146\n",
      "Iter-41900, train loss-0.2989, acc-0.9000, valid loss-0.3029, acc-0.9192, test loss-0.3137, acc-0.9145\n",
      "Iter-41910, train loss-0.2550, acc-0.9600, valid loss-0.3029, acc-0.9190, test loss-0.3137, acc-0.9146\n",
      "Iter-41920, train loss-0.4836, acc-0.8800, valid loss-0.3028, acc-0.9188, test loss-0.3137, acc-0.9147\n",
      "Iter-41930, train loss-0.3418, acc-0.9000, valid loss-0.3028, acc-0.9192, test loss-0.3137, acc-0.9144\n",
      "Iter-41940, train loss-0.4117, acc-0.8800, valid loss-0.3028, acc-0.9192, test loss-0.3136, acc-0.9144\n",
      "Iter-41950, train loss-0.2288, acc-0.9600, valid loss-0.3028, acc-0.9194, test loss-0.3136, acc-0.9145\n",
      "Iter-41960, train loss-0.4388, acc-0.8800, valid loss-0.3027, acc-0.9194, test loss-0.3136, acc-0.9146\n",
      "Iter-41970, train loss-0.3540, acc-0.8800, valid loss-0.3028, acc-0.9192, test loss-0.3136, acc-0.9148\n",
      "Iter-41980, train loss-0.2773, acc-0.9600, valid loss-0.3028, acc-0.9194, test loss-0.3135, acc-0.9149\n",
      "Iter-41990, train loss-0.3215, acc-0.8800, valid loss-0.3026, acc-0.9190, test loss-0.3135, acc-0.9147\n",
      "Iter-42000, train loss-0.2425, acc-0.9400, valid loss-0.3026, acc-0.9192, test loss-0.3135, acc-0.9149\n",
      "Iter-42010, train loss-0.3583, acc-0.9000, valid loss-0.3025, acc-0.9190, test loss-0.3135, acc-0.9147\n",
      "Iter-42020, train loss-0.3335, acc-0.9000, valid loss-0.3025, acc-0.9188, test loss-0.3134, acc-0.9149\n",
      "Iter-42030, train loss-0.3258, acc-0.9200, valid loss-0.3025, acc-0.9188, test loss-0.3134, acc-0.9149\n",
      "Iter-42040, train loss-0.2188, acc-0.9600, valid loss-0.3025, acc-0.9192, test loss-0.3133, acc-0.9150\n",
      "Iter-42050, train loss-0.3081, acc-0.9200, valid loss-0.3024, acc-0.9192, test loss-0.3134, acc-0.9150\n",
      "Iter-42060, train loss-0.2240, acc-0.9200, valid loss-0.3024, acc-0.9196, test loss-0.3133, acc-0.9150\n",
      "Iter-42070, train loss-0.4820, acc-0.8800, valid loss-0.3024, acc-0.9190, test loss-0.3133, acc-0.9150\n",
      "Iter-42080, train loss-0.4379, acc-0.9200, valid loss-0.3024, acc-0.9186, test loss-0.3132, acc-0.9147\n",
      "Iter-42090, train loss-0.2084, acc-0.9600, valid loss-0.3023, acc-0.9190, test loss-0.3132, acc-0.9147\n",
      "Iter-42100, train loss-0.2290, acc-0.9400, valid loss-0.3023, acc-0.9188, test loss-0.3132, acc-0.9147\n",
      "Iter-42110, train loss-0.4675, acc-0.8800, valid loss-0.3022, acc-0.9192, test loss-0.3131, acc-0.9147\n",
      "Iter-42120, train loss-0.4397, acc-0.8800, valid loss-0.3022, acc-0.9190, test loss-0.3131, acc-0.9149\n",
      "Iter-42130, train loss-0.3339, acc-0.9000, valid loss-0.3022, acc-0.9186, test loss-0.3130, acc-0.9152\n",
      "Iter-42140, train loss-0.2601, acc-0.9200, valid loss-0.3021, acc-0.9188, test loss-0.3130, acc-0.9152\n",
      "Iter-42150, train loss-0.4404, acc-0.8800, valid loss-0.3021, acc-0.9180, test loss-0.3129, acc-0.9154\n",
      "Iter-42160, train loss-0.2831, acc-0.9200, valid loss-0.3021, acc-0.9182, test loss-0.3129, acc-0.9152\n",
      "Iter-42170, train loss-0.3401, acc-0.9000, valid loss-0.3020, acc-0.9180, test loss-0.3128, acc-0.9151\n",
      "Iter-42180, train loss-0.2584, acc-0.9000, valid loss-0.3020, acc-0.9182, test loss-0.3128, acc-0.9154\n",
      "Iter-42190, train loss-0.2852, acc-0.9400, valid loss-0.3020, acc-0.9184, test loss-0.3128, acc-0.9155\n",
      "Iter-42200, train loss-0.3603, acc-0.9000, valid loss-0.3019, acc-0.9182, test loss-0.3127, acc-0.9154\n",
      "Iter-42210, train loss-0.3419, acc-0.9000, valid loss-0.3018, acc-0.9180, test loss-0.3127, acc-0.9154\n",
      "Iter-42220, train loss-0.1600, acc-0.9800, valid loss-0.3018, acc-0.9174, test loss-0.3126, acc-0.9153\n",
      "Iter-42230, train loss-0.4266, acc-0.9000, valid loss-0.3018, acc-0.9180, test loss-0.3126, acc-0.9152\n",
      "Iter-42240, train loss-0.1780, acc-0.9600, valid loss-0.3017, acc-0.9180, test loss-0.3125, acc-0.9154\n",
      "Iter-42250, train loss-0.3402, acc-0.8800, valid loss-0.3017, acc-0.9184, test loss-0.3125, acc-0.9153\n",
      "Iter-42260, train loss-0.3261, acc-0.9200, valid loss-0.3016, acc-0.9182, test loss-0.3125, acc-0.9154\n",
      "Iter-42270, train loss-0.2931, acc-0.8800, valid loss-0.3016, acc-0.9182, test loss-0.3124, acc-0.9153\n",
      "Iter-42280, train loss-0.3839, acc-0.8800, valid loss-0.3016, acc-0.9182, test loss-0.3124, acc-0.9154\n",
      "Iter-42290, train loss-0.3936, acc-0.8600, valid loss-0.3015, acc-0.9184, test loss-0.3125, acc-0.9155\n",
      "Iter-42300, train loss-0.3337, acc-0.9600, valid loss-0.3014, acc-0.9186, test loss-0.3124, acc-0.9154\n",
      "Iter-42310, train loss-0.3931, acc-0.9200, valid loss-0.3015, acc-0.9190, test loss-0.3124, acc-0.9151\n",
      "Iter-42320, train loss-0.4007, acc-0.9000, valid loss-0.3015, acc-0.9186, test loss-0.3123, acc-0.9151\n",
      "Iter-42330, train loss-0.3049, acc-0.9400, valid loss-0.3014, acc-0.9186, test loss-0.3123, acc-0.9152\n",
      "Iter-42340, train loss-0.3076, acc-0.9200, valid loss-0.3014, acc-0.9190, test loss-0.3123, acc-0.9151\n",
      "Iter-42350, train loss-0.4536, acc-0.8800, valid loss-0.3014, acc-0.9186, test loss-0.3123, acc-0.9150\n",
      "Iter-42360, train loss-0.3629, acc-0.8800, valid loss-0.3014, acc-0.9186, test loss-0.3122, acc-0.9151\n",
      "Iter-42370, train loss-0.2318, acc-0.9400, valid loss-0.3013, acc-0.9186, test loss-0.3122, acc-0.9154\n",
      "Iter-42380, train loss-0.1634, acc-0.9400, valid loss-0.3013, acc-0.9186, test loss-0.3121, acc-0.9152\n",
      "Iter-42390, train loss-0.2634, acc-0.9000, valid loss-0.3013, acc-0.9188, test loss-0.3121, acc-0.9151\n",
      "Iter-42400, train loss-0.2735, acc-0.9200, valid loss-0.3012, acc-0.9188, test loss-0.3121, acc-0.9151\n",
      "Iter-42410, train loss-0.2810, acc-0.9000, valid loss-0.3012, acc-0.9186, test loss-0.3120, acc-0.9151\n",
      "Iter-42420, train loss-0.1664, acc-0.9600, valid loss-0.3012, acc-0.9186, test loss-0.3120, acc-0.9151\n",
      "Iter-42430, train loss-0.3859, acc-0.9200, valid loss-0.3012, acc-0.9186, test loss-0.3120, acc-0.9147\n",
      "Iter-42440, train loss-0.4749, acc-0.8800, valid loss-0.3012, acc-0.9186, test loss-0.3120, acc-0.9150\n",
      "Iter-42450, train loss-0.3105, acc-0.9400, valid loss-0.3012, acc-0.9186, test loss-0.3119, acc-0.9149\n",
      "Iter-42460, train loss-0.3216, acc-0.9200, valid loss-0.3011, acc-0.9186, test loss-0.3119, acc-0.9148\n",
      "Iter-42470, train loss-0.2032, acc-0.9600, valid loss-0.3011, acc-0.9182, test loss-0.3118, acc-0.9153\n",
      "Iter-42480, train loss-0.4589, acc-0.8600, valid loss-0.3010, acc-0.9182, test loss-0.3118, acc-0.9152\n",
      "Iter-42490, train loss-0.5188, acc-0.8600, valid loss-0.3010, acc-0.9184, test loss-0.3117, acc-0.9153\n",
      "Iter-42500, train loss-0.2654, acc-0.9200, valid loss-0.3009, acc-0.9180, test loss-0.3118, acc-0.9153\n",
      "Iter-42510, train loss-0.2662, acc-0.9400, valid loss-0.3009, acc-0.9180, test loss-0.3118, acc-0.9149\n",
      "Iter-42520, train loss-0.2866, acc-0.9400, valid loss-0.3009, acc-0.9182, test loss-0.3118, acc-0.9149\n",
      "Iter-42530, train loss-0.1937, acc-0.9600, valid loss-0.3009, acc-0.9182, test loss-0.3117, acc-0.9151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-42540, train loss-0.1774, acc-0.9600, valid loss-0.3008, acc-0.9180, test loss-0.3117, acc-0.9153\n",
      "Iter-42550, train loss-0.2701, acc-0.9200, valid loss-0.3009, acc-0.9180, test loss-0.3116, acc-0.9152\n",
      "Iter-42560, train loss-0.3465, acc-0.8800, valid loss-0.3008, acc-0.9182, test loss-0.3117, acc-0.9152\n",
      "Iter-42570, train loss-0.3069, acc-0.9000, valid loss-0.3007, acc-0.9182, test loss-0.3116, acc-0.9148\n",
      "Iter-42580, train loss-0.2102, acc-0.9600, valid loss-0.3007, acc-0.9184, test loss-0.3116, acc-0.9149\n",
      "Iter-42590, train loss-0.4035, acc-0.9200, valid loss-0.3007, acc-0.9184, test loss-0.3115, acc-0.9148\n",
      "Iter-42600, train loss-0.2448, acc-0.9200, valid loss-0.3007, acc-0.9186, test loss-0.3115, acc-0.9149\n",
      "Iter-42610, train loss-0.2900, acc-0.9200, valid loss-0.3007, acc-0.9186, test loss-0.3115, acc-0.9149\n",
      "Iter-42620, train loss-0.2996, acc-0.9400, valid loss-0.3007, acc-0.9186, test loss-0.3114, acc-0.9149\n",
      "Iter-42630, train loss-0.3138, acc-0.9200, valid loss-0.3006, acc-0.9184, test loss-0.3114, acc-0.9150\n",
      "Iter-42640, train loss-0.5408, acc-0.8200, valid loss-0.3007, acc-0.9182, test loss-0.3114, acc-0.9149\n",
      "Iter-42650, train loss-0.2666, acc-0.8800, valid loss-0.3007, acc-0.9184, test loss-0.3113, acc-0.9148\n",
      "Iter-42660, train loss-0.4598, acc-0.9000, valid loss-0.3006, acc-0.9182, test loss-0.3113, acc-0.9148\n",
      "Iter-42670, train loss-0.2559, acc-0.9600, valid loss-0.3006, acc-0.9188, test loss-0.3113, acc-0.9149\n",
      "Iter-42680, train loss-0.4062, acc-0.8800, valid loss-0.3005, acc-0.9188, test loss-0.3112, acc-0.9148\n",
      "Iter-42690, train loss-0.3422, acc-0.9000, valid loss-0.3005, acc-0.9188, test loss-0.3112, acc-0.9152\n",
      "Iter-42700, train loss-0.2976, acc-0.9200, valid loss-0.3005, acc-0.9188, test loss-0.3111, acc-0.9153\n",
      "Iter-42710, train loss-0.1786, acc-0.9600, valid loss-0.3004, acc-0.9186, test loss-0.3112, acc-0.9155\n",
      "Iter-42720, train loss-0.1944, acc-0.9200, valid loss-0.3005, acc-0.9190, test loss-0.3112, acc-0.9154\n",
      "Iter-42730, train loss-0.3585, acc-0.9400, valid loss-0.3004, acc-0.9188, test loss-0.3111, acc-0.9155\n",
      "Iter-42740, train loss-0.3144, acc-0.9200, valid loss-0.3003, acc-0.9190, test loss-0.3111, acc-0.9155\n",
      "Iter-42750, train loss-0.5814, acc-0.8200, valid loss-0.3003, acc-0.9192, test loss-0.3112, acc-0.9156\n",
      "Iter-42760, train loss-0.2557, acc-0.9000, valid loss-0.3002, acc-0.9190, test loss-0.3111, acc-0.9156\n",
      "Iter-42770, train loss-0.4348, acc-0.9000, valid loss-0.3002, acc-0.9194, test loss-0.3111, acc-0.9154\n",
      "Iter-42780, train loss-0.2618, acc-0.9000, valid loss-0.3002, acc-0.9194, test loss-0.3111, acc-0.9154\n",
      "Iter-42790, train loss-0.3268, acc-0.9000, valid loss-0.3002, acc-0.9192, test loss-0.3111, acc-0.9155\n",
      "Iter-42800, train loss-0.4587, acc-0.9000, valid loss-0.3001, acc-0.9196, test loss-0.3110, acc-0.9154\n",
      "Iter-42810, train loss-0.2286, acc-0.9400, valid loss-0.3001, acc-0.9190, test loss-0.3110, acc-0.9152\n",
      "Iter-42820, train loss-0.3673, acc-0.8800, valid loss-0.3000, acc-0.9192, test loss-0.3109, acc-0.9151\n",
      "Iter-42830, train loss-0.3136, acc-0.9000, valid loss-0.3000, acc-0.9194, test loss-0.3109, acc-0.9151\n",
      "Iter-42840, train loss-0.3283, acc-0.9200, valid loss-0.2999, acc-0.9194, test loss-0.3108, acc-0.9153\n",
      "Iter-42850, train loss-0.2490, acc-0.9400, valid loss-0.2998, acc-0.9190, test loss-0.3108, acc-0.9152\n",
      "Iter-42860, train loss-0.2731, acc-0.8800, valid loss-0.2998, acc-0.9194, test loss-0.3108, acc-0.9153\n",
      "Iter-42870, train loss-0.2840, acc-0.9000, valid loss-0.2997, acc-0.9190, test loss-0.3107, acc-0.9151\n",
      "Iter-42880, train loss-0.2568, acc-0.9400, valid loss-0.2997, acc-0.9194, test loss-0.3107, acc-0.9155\n",
      "Iter-42890, train loss-0.4245, acc-0.8600, valid loss-0.2997, acc-0.9192, test loss-0.3106, acc-0.9156\n",
      "Iter-42900, train loss-0.3446, acc-0.9400, valid loss-0.2996, acc-0.9192, test loss-0.3106, acc-0.9156\n",
      "Iter-42910, train loss-0.2276, acc-0.9600, valid loss-0.2996, acc-0.9192, test loss-0.3105, acc-0.9155\n",
      "Iter-42920, train loss-0.5162, acc-0.8600, valid loss-0.2996, acc-0.9188, test loss-0.3105, acc-0.9155\n",
      "Iter-42930, train loss-0.1738, acc-0.9600, valid loss-0.2996, acc-0.9190, test loss-0.3105, acc-0.9156\n",
      "Iter-42940, train loss-0.5475, acc-0.8200, valid loss-0.2996, acc-0.9188, test loss-0.3105, acc-0.9156\n",
      "Iter-42950, train loss-0.3461, acc-0.9000, valid loss-0.2997, acc-0.9186, test loss-0.3105, acc-0.9154\n",
      "Iter-42960, train loss-0.1954, acc-0.9600, valid loss-0.2996, acc-0.9184, test loss-0.3105, acc-0.9154\n",
      "Iter-42970, train loss-0.3013, acc-0.9000, valid loss-0.2996, acc-0.9188, test loss-0.3104, acc-0.9156\n",
      "Iter-42980, train loss-0.2580, acc-0.9400, valid loss-0.2995, acc-0.9194, test loss-0.3104, acc-0.9155\n",
      "Iter-42990, train loss-0.5068, acc-0.9200, valid loss-0.2995, acc-0.9188, test loss-0.3104, acc-0.9158\n",
      "Iter-43000, train loss-0.3121, acc-0.9400, valid loss-0.2995, acc-0.9190, test loss-0.3103, acc-0.9157\n",
      "Iter-43010, train loss-0.2683, acc-0.9600, valid loss-0.2994, acc-0.9188, test loss-0.3103, acc-0.9156\n",
      "Iter-43020, train loss-0.2738, acc-0.9400, valid loss-0.2994, acc-0.9192, test loss-0.3102, acc-0.9157\n",
      "Iter-43030, train loss-0.2700, acc-0.9200, valid loss-0.2993, acc-0.9194, test loss-0.3102, acc-0.9158\n",
      "Iter-43040, train loss-0.4834, acc-0.8600, valid loss-0.2993, acc-0.9196, test loss-0.3102, acc-0.9159\n",
      "Iter-43050, train loss-0.1121, acc-1.0000, valid loss-0.2993, acc-0.9196, test loss-0.3101, acc-0.9160\n",
      "Iter-43060, train loss-0.2720, acc-0.9400, valid loss-0.2993, acc-0.9194, test loss-0.3100, acc-0.9160\n",
      "Iter-43070, train loss-0.5514, acc-0.8800, valid loss-0.2993, acc-0.9192, test loss-0.3100, acc-0.9159\n",
      "Iter-43080, train loss-0.3713, acc-0.8800, valid loss-0.2993, acc-0.9194, test loss-0.3100, acc-0.9159\n",
      "Iter-43090, train loss-0.2163, acc-0.9600, valid loss-0.2993, acc-0.9194, test loss-0.3099, acc-0.9159\n",
      "Iter-43100, train loss-0.1450, acc-0.9600, valid loss-0.2993, acc-0.9194, test loss-0.3100, acc-0.9155\n",
      "Iter-43110, train loss-0.4079, acc-0.9000, valid loss-0.2992, acc-0.9192, test loss-0.3100, acc-0.9157\n",
      "Iter-43120, train loss-0.3155, acc-0.8800, valid loss-0.2992, acc-0.9194, test loss-0.3099, acc-0.9159\n",
      "Iter-43130, train loss-0.2866, acc-0.9200, valid loss-0.2992, acc-0.9192, test loss-0.3098, acc-0.9159\n",
      "Iter-43140, train loss-0.3469, acc-0.9200, valid loss-0.2991, acc-0.9192, test loss-0.3098, acc-0.9158\n",
      "Iter-43150, train loss-0.4017, acc-0.8400, valid loss-0.2991, acc-0.9192, test loss-0.3098, acc-0.9158\n",
      "Iter-43160, train loss-0.2347, acc-0.9400, valid loss-0.2990, acc-0.9192, test loss-0.3098, acc-0.9159\n",
      "Iter-43170, train loss-0.3034, acc-0.9000, valid loss-0.2990, acc-0.9190, test loss-0.3098, acc-0.9158\n",
      "Iter-43180, train loss-0.2546, acc-0.9200, valid loss-0.2990, acc-0.9190, test loss-0.3097, acc-0.9158\n",
      "Iter-43190, train loss-0.3717, acc-0.9400, valid loss-0.2989, acc-0.9192, test loss-0.3097, acc-0.9158\n",
      "Iter-43200, train loss-0.3232, acc-0.9200, valid loss-0.2990, acc-0.9194, test loss-0.3097, acc-0.9157\n",
      "Iter-43210, train loss-0.2575, acc-0.9400, valid loss-0.2989, acc-0.9192, test loss-0.3097, acc-0.9160\n",
      "Iter-43220, train loss-0.3011, acc-0.9000, valid loss-0.2989, acc-0.9196, test loss-0.3097, acc-0.9159\n",
      "Iter-43230, train loss-0.2025, acc-0.9600, valid loss-0.2989, acc-0.9196, test loss-0.3097, acc-0.9159\n",
      "Iter-43240, train loss-0.5961, acc-0.8400, valid loss-0.2989, acc-0.9188, test loss-0.3096, acc-0.9158\n",
      "Iter-43250, train loss-0.4543, acc-0.9000, valid loss-0.2988, acc-0.9186, test loss-0.3096, acc-0.9155\n",
      "Iter-43260, train loss-0.3348, acc-0.9000, valid loss-0.2988, acc-0.9190, test loss-0.3095, acc-0.9156\n",
      "Iter-43270, train loss-0.2032, acc-0.9400, valid loss-0.2988, acc-0.9188, test loss-0.3095, acc-0.9158\n",
      "Iter-43280, train loss-0.4077, acc-0.9200, valid loss-0.2987, acc-0.9188, test loss-0.3094, acc-0.9160\n",
      "Iter-43290, train loss-0.2583, acc-0.8800, valid loss-0.2987, acc-0.9190, test loss-0.3094, acc-0.9160\n",
      "Iter-43300, train loss-0.2851, acc-0.9400, valid loss-0.2987, acc-0.9188, test loss-0.3094, acc-0.9160\n",
      "Iter-43310, train loss-0.2778, acc-0.8800, valid loss-0.2988, acc-0.9190, test loss-0.3094, acc-0.9161\n",
      "Iter-43320, train loss-0.3114, acc-0.9000, valid loss-0.2987, acc-0.9190, test loss-0.3093, acc-0.9158\n",
      "Iter-43330, train loss-0.2699, acc-0.9200, valid loss-0.2987, acc-0.9192, test loss-0.3093, acc-0.9156\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-43340, train loss-0.2506, acc-0.9000, valid loss-0.2987, acc-0.9194, test loss-0.3093, acc-0.9160\n",
      "Iter-43350, train loss-0.3372, acc-0.9200, valid loss-0.2987, acc-0.9194, test loss-0.3093, acc-0.9160\n",
      "Iter-43360, train loss-0.3644, acc-0.9000, valid loss-0.2986, acc-0.9192, test loss-0.3092, acc-0.9160\n",
      "Iter-43370, train loss-0.3323, acc-0.9200, valid loss-0.2986, acc-0.9190, test loss-0.3092, acc-0.9158\n",
      "Iter-43380, train loss-0.3601, acc-0.9400, valid loss-0.2986, acc-0.9194, test loss-0.3092, acc-0.9160\n",
      "Iter-43390, train loss-0.2297, acc-0.9200, valid loss-0.2986, acc-0.9192, test loss-0.3091, acc-0.9160\n",
      "Iter-43400, train loss-0.3487, acc-0.9000, valid loss-0.2986, acc-0.9192, test loss-0.3092, acc-0.9160\n",
      "Iter-43410, train loss-0.3198, acc-0.8800, valid loss-0.2985, acc-0.9194, test loss-0.3091, acc-0.9160\n",
      "Iter-43420, train loss-0.3659, acc-0.8600, valid loss-0.2985, acc-0.9190, test loss-0.3091, acc-0.9158\n",
      "Iter-43430, train loss-0.3074, acc-0.9000, valid loss-0.2985, acc-0.9190, test loss-0.3090, acc-0.9161\n",
      "Iter-43440, train loss-0.2730, acc-0.9200, valid loss-0.2984, acc-0.9190, test loss-0.3091, acc-0.9156\n",
      "Iter-43450, train loss-0.2759, acc-0.9200, valid loss-0.2984, acc-0.9190, test loss-0.3090, acc-0.9156\n",
      "Iter-43460, train loss-0.2507, acc-0.9200, valid loss-0.2983, acc-0.9190, test loss-0.3090, acc-0.9154\n",
      "Iter-43470, train loss-0.4805, acc-0.8800, valid loss-0.2983, acc-0.9190, test loss-0.3090, acc-0.9156\n",
      "Iter-43480, train loss-0.3674, acc-0.8800, valid loss-0.2982, acc-0.9194, test loss-0.3090, acc-0.9158\n",
      "Iter-43490, train loss-0.3193, acc-0.9400, valid loss-0.2982, acc-0.9188, test loss-0.3089, acc-0.9160\n",
      "Iter-43500, train loss-0.3037, acc-0.9200, valid loss-0.2982, acc-0.9186, test loss-0.3089, acc-0.9157\n",
      "Iter-43510, train loss-0.1760, acc-0.9800, valid loss-0.2982, acc-0.9188, test loss-0.3089, acc-0.9159\n",
      "Iter-43520, train loss-0.2131, acc-0.9400, valid loss-0.2981, acc-0.9188, test loss-0.3089, acc-0.9156\n",
      "Iter-43530, train loss-0.1922, acc-0.9400, valid loss-0.2981, acc-0.9188, test loss-0.3088, acc-0.9158\n",
      "Iter-43540, train loss-0.1735, acc-0.9600, valid loss-0.2981, acc-0.9190, test loss-0.3088, acc-0.9160\n",
      "Iter-43550, train loss-0.2145, acc-0.9400, valid loss-0.2980, acc-0.9192, test loss-0.3087, acc-0.9160\n",
      "Iter-43560, train loss-0.3097, acc-0.9000, valid loss-0.2980, acc-0.9190, test loss-0.3087, acc-0.9160\n",
      "Iter-43570, train loss-0.2542, acc-0.9400, valid loss-0.2980, acc-0.9190, test loss-0.3086, acc-0.9160\n",
      "Iter-43580, train loss-0.2816, acc-0.9200, valid loss-0.2980, acc-0.9192, test loss-0.3086, acc-0.9162\n",
      "Iter-43590, train loss-0.3604, acc-0.8400, valid loss-0.2980, acc-0.9190, test loss-0.3085, acc-0.9162\n",
      "Iter-43600, train loss-0.3892, acc-0.8600, valid loss-0.2979, acc-0.9190, test loss-0.3084, acc-0.9160\n",
      "Iter-43610, train loss-0.3405, acc-0.8800, valid loss-0.2979, acc-0.9194, test loss-0.3084, acc-0.9162\n",
      "Iter-43620, train loss-0.2128, acc-0.9600, valid loss-0.2978, acc-0.9196, test loss-0.3083, acc-0.9162\n",
      "Iter-43630, train loss-0.3708, acc-0.8800, valid loss-0.2978, acc-0.9192, test loss-0.3083, acc-0.9160\n",
      "Iter-43640, train loss-0.1292, acc-0.9600, valid loss-0.2978, acc-0.9192, test loss-0.3083, acc-0.9160\n",
      "Iter-43650, train loss-0.2187, acc-0.9400, valid loss-0.2978, acc-0.9194, test loss-0.3082, acc-0.9161\n",
      "Iter-43660, train loss-0.5299, acc-0.8000, valid loss-0.2978, acc-0.9194, test loss-0.3081, acc-0.9161\n",
      "Iter-43670, train loss-0.1820, acc-0.9400, valid loss-0.2977, acc-0.9194, test loss-0.3081, acc-0.9161\n",
      "Iter-43680, train loss-0.3992, acc-0.8800, valid loss-0.2976, acc-0.9194, test loss-0.3081, acc-0.9158\n",
      "Iter-43690, train loss-0.4354, acc-0.8600, valid loss-0.2975, acc-0.9198, test loss-0.3081, acc-0.9159\n",
      "Iter-43700, train loss-0.2661, acc-0.8800, valid loss-0.2975, acc-0.9200, test loss-0.3080, acc-0.9159\n",
      "Iter-43710, train loss-0.3464, acc-0.8400, valid loss-0.2974, acc-0.9200, test loss-0.3080, acc-0.9160\n",
      "Iter-43720, train loss-0.2125, acc-0.9200, valid loss-0.2974, acc-0.9198, test loss-0.3080, acc-0.9160\n",
      "Iter-43730, train loss-0.3416, acc-0.9200, valid loss-0.2974, acc-0.9196, test loss-0.3080, acc-0.9160\n",
      "Iter-43740, train loss-0.1505, acc-0.9600, valid loss-0.2974, acc-0.9196, test loss-0.3079, acc-0.9159\n",
      "Iter-43750, train loss-0.3673, acc-0.9000, valid loss-0.2973, acc-0.9196, test loss-0.3079, acc-0.9162\n",
      "Iter-43760, train loss-0.3199, acc-0.9400, valid loss-0.2974, acc-0.9192, test loss-0.3080, acc-0.9163\n",
      "Iter-43770, train loss-0.3812, acc-0.8800, valid loss-0.2974, acc-0.9196, test loss-0.3079, acc-0.9163\n",
      "Iter-43780, train loss-0.1787, acc-0.9600, valid loss-0.2974, acc-0.9198, test loss-0.3079, acc-0.9159\n",
      "Iter-43790, train loss-0.2652, acc-0.9600, valid loss-0.2973, acc-0.9202, test loss-0.3079, acc-0.9157\n",
      "Iter-43800, train loss-0.3023, acc-0.9200, valid loss-0.2973, acc-0.9198, test loss-0.3079, acc-0.9159\n",
      "Iter-43810, train loss-0.2889, acc-0.9000, valid loss-0.2972, acc-0.9196, test loss-0.3079, acc-0.9160\n",
      "Iter-43820, train loss-0.2486, acc-0.9200, valid loss-0.2972, acc-0.9198, test loss-0.3079, acc-0.9162\n",
      "Iter-43830, train loss-0.3009, acc-0.9400, valid loss-0.2971, acc-0.9200, test loss-0.3079, acc-0.9159\n",
      "Iter-43840, train loss-0.2972, acc-0.9600, valid loss-0.2970, acc-0.9198, test loss-0.3079, acc-0.9156\n",
      "Iter-43850, train loss-0.1680, acc-0.9600, valid loss-0.2970, acc-0.9200, test loss-0.3079, acc-0.9158\n",
      "Iter-43860, train loss-0.4885, acc-0.8800, valid loss-0.2970, acc-0.9202, test loss-0.3078, acc-0.9159\n",
      "Iter-43870, train loss-0.1598, acc-0.9800, valid loss-0.2969, acc-0.9202, test loss-0.3078, acc-0.9158\n",
      "Iter-43880, train loss-0.2755, acc-0.8800, valid loss-0.2970, acc-0.9200, test loss-0.3078, acc-0.9160\n",
      "Iter-43890, train loss-0.5733, acc-0.8800, valid loss-0.2970, acc-0.9202, test loss-0.3077, acc-0.9158\n",
      "Iter-43900, train loss-0.2606, acc-0.9200, valid loss-0.2969, acc-0.9202, test loss-0.3076, acc-0.9158\n",
      "Iter-43910, train loss-0.3302, acc-0.9000, valid loss-0.2969, acc-0.9200, test loss-0.3076, acc-0.9156\n",
      "Iter-43920, train loss-0.2097, acc-0.9400, valid loss-0.2969, acc-0.9202, test loss-0.3076, acc-0.9157\n",
      "Iter-43930, train loss-0.3052, acc-0.9200, valid loss-0.2968, acc-0.9200, test loss-0.3076, acc-0.9158\n",
      "Iter-43940, train loss-0.2513, acc-0.9600, valid loss-0.2968, acc-0.9200, test loss-0.3075, acc-0.9158\n",
      "Iter-43950, train loss-0.3393, acc-0.9400, valid loss-0.2968, acc-0.9200, test loss-0.3075, acc-0.9159\n",
      "Iter-43960, train loss-0.3485, acc-0.8800, valid loss-0.2968, acc-0.9200, test loss-0.3075, acc-0.9157\n",
      "Iter-43970, train loss-0.2348, acc-0.9400, valid loss-0.2968, acc-0.9202, test loss-0.3074, acc-0.9158\n",
      "Iter-43980, train loss-0.2666, acc-0.9400, valid loss-0.2968, acc-0.9202, test loss-0.3074, acc-0.9159\n",
      "Iter-43990, train loss-0.3197, acc-0.9400, valid loss-0.2967, acc-0.9202, test loss-0.3074, acc-0.9158\n",
      "Iter-44000, train loss-0.3018, acc-0.9400, valid loss-0.2967, acc-0.9204, test loss-0.3073, acc-0.9158\n",
      "Iter-44010, train loss-0.4077, acc-0.9000, valid loss-0.2967, acc-0.9204, test loss-0.3073, acc-0.9160\n",
      "Iter-44020, train loss-0.4517, acc-0.8800, valid loss-0.2967, acc-0.9204, test loss-0.3072, acc-0.9159\n",
      "Iter-44030, train loss-0.1633, acc-0.9600, valid loss-0.2967, acc-0.9204, test loss-0.3072, acc-0.9161\n",
      "Iter-44040, train loss-0.2163, acc-0.9200, valid loss-0.2967, acc-0.9204, test loss-0.3071, acc-0.9161\n",
      "Iter-44050, train loss-0.3527, acc-0.8600, valid loss-0.2966, acc-0.9204, test loss-0.3071, acc-0.9161\n",
      "Iter-44060, train loss-0.3049, acc-0.9400, valid loss-0.2966, acc-0.9202, test loss-0.3071, acc-0.9161\n",
      "Iter-44070, train loss-0.6161, acc-0.8800, valid loss-0.2966, acc-0.9204, test loss-0.3071, acc-0.9161\n",
      "Iter-44080, train loss-0.3890, acc-0.8800, valid loss-0.2965, acc-0.9204, test loss-0.3070, acc-0.9162\n",
      "Iter-44090, train loss-0.2489, acc-0.8800, valid loss-0.2965, acc-0.9204, test loss-0.3070, acc-0.9162\n",
      "Iter-44100, train loss-0.5299, acc-0.8400, valid loss-0.2965, acc-0.9204, test loss-0.3070, acc-0.9163\n",
      "Iter-44110, train loss-0.4133, acc-0.8200, valid loss-0.2965, acc-0.9202, test loss-0.3070, acc-0.9161\n",
      "Iter-44120, train loss-0.3234, acc-0.8800, valid loss-0.2964, acc-0.9198, test loss-0.3070, acc-0.9162\n",
      "Iter-44130, train loss-0.4372, acc-0.8600, valid loss-0.2964, acc-0.9202, test loss-0.3069, acc-0.9160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44140, train loss-0.2104, acc-0.9600, valid loss-0.2964, acc-0.9202, test loss-0.3069, acc-0.9160\n",
      "Iter-44150, train loss-0.1762, acc-0.9600, valid loss-0.2963, acc-0.9202, test loss-0.3069, acc-0.9160\n",
      "Iter-44160, train loss-0.4237, acc-0.8000, valid loss-0.2963, acc-0.9200, test loss-0.3068, acc-0.9162\n",
      "Iter-44170, train loss-0.4040, acc-0.8400, valid loss-0.2962, acc-0.9202, test loss-0.3068, acc-0.9160\n",
      "Iter-44180, train loss-0.3159, acc-0.9400, valid loss-0.2962, acc-0.9200, test loss-0.3068, acc-0.9158\n",
      "Iter-44190, train loss-0.3383, acc-0.8600, valid loss-0.2962, acc-0.9202, test loss-0.3068, acc-0.9158\n",
      "Iter-44200, train loss-0.3117, acc-0.9000, valid loss-0.2963, acc-0.9202, test loss-0.3067, acc-0.9159\n",
      "Iter-44210, train loss-0.5343, acc-0.9200, valid loss-0.2962, acc-0.9202, test loss-0.3067, acc-0.9159\n",
      "Iter-44220, train loss-0.2397, acc-0.9400, valid loss-0.2962, acc-0.9200, test loss-0.3066, acc-0.9157\n",
      "Iter-44230, train loss-0.1317, acc-1.0000, valid loss-0.2962, acc-0.9200, test loss-0.3066, acc-0.9157\n",
      "Iter-44240, train loss-0.3455, acc-0.9200, valid loss-0.2962, acc-0.9202, test loss-0.3065, acc-0.9156\n",
      "Iter-44250, train loss-0.2761, acc-0.9000, valid loss-0.2962, acc-0.9200, test loss-0.3065, acc-0.9157\n",
      "Iter-44260, train loss-0.3546, acc-0.8800, valid loss-0.2962, acc-0.9200, test loss-0.3064, acc-0.9160\n",
      "Iter-44270, train loss-0.3013, acc-0.8800, valid loss-0.2961, acc-0.9198, test loss-0.3063, acc-0.9160\n",
      "Iter-44280, train loss-0.3486, acc-0.9000, valid loss-0.2961, acc-0.9198, test loss-0.3063, acc-0.9161\n",
      "Iter-44290, train loss-0.2437, acc-0.9400, valid loss-0.2960, acc-0.9198, test loss-0.3063, acc-0.9161\n",
      "Iter-44300, train loss-0.1996, acc-0.9600, valid loss-0.2959, acc-0.9196, test loss-0.3063, acc-0.9165\n",
      "Iter-44310, train loss-0.4314, acc-0.8600, valid loss-0.2959, acc-0.9198, test loss-0.3063, acc-0.9164\n",
      "Iter-44320, train loss-0.3452, acc-0.8800, valid loss-0.2958, acc-0.9200, test loss-0.3062, acc-0.9163\n",
      "Iter-44330, train loss-0.2660, acc-0.9600, valid loss-0.2959, acc-0.9202, test loss-0.3061, acc-0.9164\n",
      "Iter-44340, train loss-0.4188, acc-0.9400, valid loss-0.2958, acc-0.9200, test loss-0.3061, acc-0.9164\n",
      "Iter-44350, train loss-0.3854, acc-0.8400, valid loss-0.2958, acc-0.9202, test loss-0.3062, acc-0.9163\n",
      "Iter-44360, train loss-0.4357, acc-0.8600, valid loss-0.2957, acc-0.9202, test loss-0.3062, acc-0.9163\n",
      "Iter-44370, train loss-0.2493, acc-0.9000, valid loss-0.2957, acc-0.9204, test loss-0.3061, acc-0.9164\n",
      "Iter-44380, train loss-0.2654, acc-0.9600, valid loss-0.2957, acc-0.9204, test loss-0.3061, acc-0.9163\n",
      "Iter-44390, train loss-0.2609, acc-0.9400, valid loss-0.2957, acc-0.9204, test loss-0.3061, acc-0.9161\n",
      "Iter-44400, train loss-0.3601, acc-0.8800, valid loss-0.2956, acc-0.9202, test loss-0.3060, acc-0.9161\n",
      "Iter-44410, train loss-0.3611, acc-0.8800, valid loss-0.2955, acc-0.9204, test loss-0.3060, acc-0.9161\n",
      "Iter-44420, train loss-0.3003, acc-0.9000, valid loss-0.2955, acc-0.9202, test loss-0.3059, acc-0.9162\n",
      "Iter-44430, train loss-0.3063, acc-0.9400, valid loss-0.2955, acc-0.9204, test loss-0.3059, acc-0.9164\n",
      "Iter-44440, train loss-0.3735, acc-0.8800, valid loss-0.2955, acc-0.9202, test loss-0.3058, acc-0.9165\n",
      "Iter-44450, train loss-0.1603, acc-0.9600, valid loss-0.2955, acc-0.9200, test loss-0.3058, acc-0.9164\n",
      "Iter-44460, train loss-0.4057, acc-0.8800, valid loss-0.2955, acc-0.9202, test loss-0.3058, acc-0.9164\n",
      "Iter-44470, train loss-0.2535, acc-0.9600, valid loss-0.2954, acc-0.9202, test loss-0.3058, acc-0.9164\n",
      "Iter-44480, train loss-0.2282, acc-0.9400, valid loss-0.2953, acc-0.9202, test loss-0.3058, acc-0.9161\n",
      "Iter-44490, train loss-0.2548, acc-0.9200, valid loss-0.2953, acc-0.9202, test loss-0.3058, acc-0.9163\n",
      "Iter-44500, train loss-0.2676, acc-0.9400, valid loss-0.2953, acc-0.9202, test loss-0.3057, acc-0.9164\n",
      "Iter-44510, train loss-0.3431, acc-0.9000, valid loss-0.2952, acc-0.9202, test loss-0.3057, acc-0.9163\n",
      "Iter-44520, train loss-0.2965, acc-0.9000, valid loss-0.2952, acc-0.9202, test loss-0.3056, acc-0.9161\n",
      "Iter-44530, train loss-0.2214, acc-0.9200, valid loss-0.2951, acc-0.9200, test loss-0.3056, acc-0.9159\n",
      "Iter-44540, train loss-0.2267, acc-0.9600, valid loss-0.2950, acc-0.9204, test loss-0.3056, acc-0.9161\n",
      "Iter-44550, train loss-0.3437, acc-0.9000, valid loss-0.2950, acc-0.9202, test loss-0.3055, acc-0.9163\n",
      "Iter-44560, train loss-0.4538, acc-0.9000, valid loss-0.2950, acc-0.9204, test loss-0.3055, acc-0.9164\n",
      "Iter-44570, train loss-0.4770, acc-0.8000, valid loss-0.2950, acc-0.9202, test loss-0.3055, acc-0.9164\n",
      "Iter-44580, train loss-0.1979, acc-0.9600, valid loss-0.2949, acc-0.9204, test loss-0.3055, acc-0.9166\n",
      "Iter-44590, train loss-0.2824, acc-0.9200, valid loss-0.2949, acc-0.9206, test loss-0.3054, acc-0.9165\n",
      "Iter-44600, train loss-0.7478, acc-0.8400, valid loss-0.2949, acc-0.9206, test loss-0.3054, acc-0.9166\n",
      "Iter-44610, train loss-0.3618, acc-0.9200, valid loss-0.2949, acc-0.9202, test loss-0.3053, acc-0.9164\n",
      "Iter-44620, train loss-0.3784, acc-0.8800, valid loss-0.2949, acc-0.9204, test loss-0.3053, acc-0.9166\n",
      "Iter-44630, train loss-0.1915, acc-0.9600, valid loss-0.2949, acc-0.9206, test loss-0.3053, acc-0.9166\n",
      "Iter-44640, train loss-0.5260, acc-0.8400, valid loss-0.2949, acc-0.9208, test loss-0.3052, acc-0.9165\n",
      "Iter-44650, train loss-0.2254, acc-0.9400, valid loss-0.2949, acc-0.9208, test loss-0.3052, acc-0.9164\n",
      "Iter-44660, train loss-0.1400, acc-0.9800, valid loss-0.2948, acc-0.9206, test loss-0.3052, acc-0.9164\n",
      "Iter-44670, train loss-0.3547, acc-0.8600, valid loss-0.2948, acc-0.9204, test loss-0.3052, acc-0.9165\n",
      "Iter-44680, train loss-0.3723, acc-0.8800, valid loss-0.2948, acc-0.9202, test loss-0.3052, acc-0.9165\n",
      "Iter-44690, train loss-0.2094, acc-0.9400, valid loss-0.2948, acc-0.9204, test loss-0.3052, acc-0.9168\n",
      "Iter-44700, train loss-0.1425, acc-0.9600, valid loss-0.2948, acc-0.9204, test loss-0.3052, acc-0.9167\n",
      "Iter-44710, train loss-0.2825, acc-0.9000, valid loss-0.2947, acc-0.9204, test loss-0.3052, acc-0.9167\n",
      "Iter-44720, train loss-0.3058, acc-0.9200, valid loss-0.2947, acc-0.9202, test loss-0.3052, acc-0.9166\n",
      "Iter-44730, train loss-0.3156, acc-0.8800, valid loss-0.2947, acc-0.9206, test loss-0.3052, acc-0.9166\n",
      "Iter-44740, train loss-0.2477, acc-0.9400, valid loss-0.2947, acc-0.9200, test loss-0.3052, acc-0.9166\n",
      "Iter-44750, train loss-0.3982, acc-0.8400, valid loss-0.2946, acc-0.9204, test loss-0.3052, acc-0.9166\n",
      "Iter-44760, train loss-0.2482, acc-0.9400, valid loss-0.2946, acc-0.9202, test loss-0.3051, acc-0.9166\n",
      "Iter-44770, train loss-0.2750, acc-0.9400, valid loss-0.2946, acc-0.9200, test loss-0.3051, acc-0.9165\n",
      "Iter-44780, train loss-0.2712, acc-0.9400, valid loss-0.2946, acc-0.9202, test loss-0.3051, acc-0.9164\n",
      "Iter-44790, train loss-0.2642, acc-0.8800, valid loss-0.2945, acc-0.9202, test loss-0.3050, acc-0.9164\n",
      "Iter-44800, train loss-0.3338, acc-0.9000, valid loss-0.2945, acc-0.9200, test loss-0.3050, acc-0.9164\n",
      "Iter-44810, train loss-0.3044, acc-0.9400, valid loss-0.2944, acc-0.9202, test loss-0.3050, acc-0.9164\n",
      "Iter-44820, train loss-0.2769, acc-0.9400, valid loss-0.2944, acc-0.9200, test loss-0.3050, acc-0.9165\n",
      "Iter-44830, train loss-0.2251, acc-0.9000, valid loss-0.2944, acc-0.9202, test loss-0.3049, acc-0.9165\n",
      "Iter-44840, train loss-0.1956, acc-0.9400, valid loss-0.2944, acc-0.9196, test loss-0.3049, acc-0.9164\n",
      "Iter-44850, train loss-0.2872, acc-0.9000, valid loss-0.2944, acc-0.9194, test loss-0.3048, acc-0.9164\n",
      "Iter-44860, train loss-0.2358, acc-0.9200, valid loss-0.2944, acc-0.9196, test loss-0.3047, acc-0.9162\n",
      "Iter-44870, train loss-0.3320, acc-0.9200, valid loss-0.2944, acc-0.9196, test loss-0.3047, acc-0.9164\n",
      "Iter-44880, train loss-0.4436, acc-0.8800, valid loss-0.2943, acc-0.9196, test loss-0.3046, acc-0.9166\n",
      "Iter-44890, train loss-0.1986, acc-0.9600, valid loss-0.2943, acc-0.9198, test loss-0.3046, acc-0.9166\n",
      "Iter-44900, train loss-0.2757, acc-0.9000, valid loss-0.2942, acc-0.9202, test loss-0.3045, acc-0.9167\n",
      "Iter-44910, train loss-0.3013, acc-0.9000, valid loss-0.2942, acc-0.9200, test loss-0.3045, acc-0.9166\n",
      "Iter-44920, train loss-0.3104, acc-0.8800, valid loss-0.2942, acc-0.9200, test loss-0.3045, acc-0.9166\n",
      "Iter-44930, train loss-0.3227, acc-0.9400, valid loss-0.2942, acc-0.9202, test loss-0.3045, acc-0.9165\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44940, train loss-0.3420, acc-0.9000, valid loss-0.2942, acc-0.9200, test loss-0.3044, acc-0.9164\n",
      "Iter-44950, train loss-0.2907, acc-0.8800, valid loss-0.2942, acc-0.9204, test loss-0.3044, acc-0.9164\n",
      "Iter-44960, train loss-0.2557, acc-0.9200, valid loss-0.2941, acc-0.9204, test loss-0.3044, acc-0.9165\n",
      "Iter-44970, train loss-0.5051, acc-0.8400, valid loss-0.2940, acc-0.9202, test loss-0.3044, acc-0.9166\n",
      "Iter-44980, train loss-0.3128, acc-0.9200, valid loss-0.2940, acc-0.9204, test loss-0.3044, acc-0.9168\n",
      "Iter-44990, train loss-0.5899, acc-0.8400, valid loss-0.2939, acc-0.9204, test loss-0.3043, acc-0.9168\n",
      "Iter-45000, train loss-0.2487, acc-0.9400, valid loss-0.2939, acc-0.9204, test loss-0.3043, acc-0.9167\n",
      "Iter-45010, train loss-0.3695, acc-0.8800, valid loss-0.2939, acc-0.9204, test loss-0.3043, acc-0.9167\n",
      "Iter-45020, train loss-0.4130, acc-0.8400, valid loss-0.2938, acc-0.9206, test loss-0.3043, acc-0.9165\n",
      "Iter-45030, train loss-0.3264, acc-0.9000, valid loss-0.2937, acc-0.9206, test loss-0.3043, acc-0.9168\n",
      "Iter-45040, train loss-0.2888, acc-0.9000, valid loss-0.2937, acc-0.9206, test loss-0.3043, acc-0.9168\n",
      "Iter-45050, train loss-0.6592, acc-0.8000, valid loss-0.2937, acc-0.9206, test loss-0.3042, acc-0.9168\n",
      "Iter-45060, train loss-0.2252, acc-0.9400, valid loss-0.2937, acc-0.9206, test loss-0.3042, acc-0.9164\n",
      "Iter-45070, train loss-0.2645, acc-0.9600, valid loss-0.2936, acc-0.9204, test loss-0.3042, acc-0.9165\n",
      "Iter-45080, train loss-0.5251, acc-0.8800, valid loss-0.2936, acc-0.9206, test loss-0.3042, acc-0.9168\n",
      "Iter-45090, train loss-0.3694, acc-0.9200, valid loss-0.2936, acc-0.9206, test loss-0.3042, acc-0.9168\n",
      "Iter-45100, train loss-0.2644, acc-0.9200, valid loss-0.2935, acc-0.9206, test loss-0.3041, acc-0.9172\n",
      "Iter-45110, train loss-0.1421, acc-0.9600, valid loss-0.2935, acc-0.9206, test loss-0.3041, acc-0.9171\n",
      "Iter-45120, train loss-0.3218, acc-0.9000, valid loss-0.2935, acc-0.9206, test loss-0.3041, acc-0.9170\n",
      "Iter-45130, train loss-0.1532, acc-0.9600, valid loss-0.2935, acc-0.9206, test loss-0.3041, acc-0.9170\n",
      "Iter-45140, train loss-0.2779, acc-0.9600, valid loss-0.2934, acc-0.9208, test loss-0.3040, acc-0.9170\n",
      "Iter-45150, train loss-0.1794, acc-0.9600, valid loss-0.2933, acc-0.9208, test loss-0.3040, acc-0.9172\n",
      "Iter-45160, train loss-0.2227, acc-0.9200, valid loss-0.2933, acc-0.9206, test loss-0.3039, acc-0.9171\n",
      "Iter-45170, train loss-0.2555, acc-0.9200, valid loss-0.2933, acc-0.9208, test loss-0.3039, acc-0.9172\n",
      "Iter-45180, train loss-0.2551, acc-0.9400, valid loss-0.2933, acc-0.9208, test loss-0.3039, acc-0.9174\n",
      "Iter-45190, train loss-0.2248, acc-0.9400, valid loss-0.2933, acc-0.9208, test loss-0.3039, acc-0.9172\n",
      "Iter-45200, train loss-0.2576, acc-0.9600, valid loss-0.2932, acc-0.9208, test loss-0.3039, acc-0.9170\n",
      "Iter-45210, train loss-0.3420, acc-0.9200, valid loss-0.2933, acc-0.9208, test loss-0.3039, acc-0.9173\n",
      "Iter-45220, train loss-0.1688, acc-0.9800, valid loss-0.2932, acc-0.9208, test loss-0.3039, acc-0.9174\n",
      "Iter-45230, train loss-0.2882, acc-0.9400, valid loss-0.2932, acc-0.9210, test loss-0.3039, acc-0.9172\n",
      "Iter-45240, train loss-0.3829, acc-0.8800, valid loss-0.2931, acc-0.9208, test loss-0.3039, acc-0.9171\n",
      "Iter-45250, train loss-0.3299, acc-0.9200, valid loss-0.2931, acc-0.9208, test loss-0.3038, acc-0.9170\n",
      "Iter-45260, train loss-0.3165, acc-0.9000, valid loss-0.2930, acc-0.9208, test loss-0.3038, acc-0.9167\n",
      "Iter-45270, train loss-0.3302, acc-0.9400, valid loss-0.2930, acc-0.9210, test loss-0.3038, acc-0.9168\n",
      "Iter-45280, train loss-0.3292, acc-0.9000, valid loss-0.2930, acc-0.9212, test loss-0.3038, acc-0.9167\n",
      "Iter-45290, train loss-0.1700, acc-0.9400, valid loss-0.2929, acc-0.9212, test loss-0.3037, acc-0.9172\n",
      "Iter-45300, train loss-0.1976, acc-0.9800, valid loss-0.2929, acc-0.9210, test loss-0.3037, acc-0.9175\n",
      "Iter-45310, train loss-0.2219, acc-0.9200, valid loss-0.2930, acc-0.9210, test loss-0.3037, acc-0.9173\n",
      "Iter-45320, train loss-0.3987, acc-0.8800, valid loss-0.2930, acc-0.9210, test loss-0.3037, acc-0.9177\n",
      "Iter-45330, train loss-0.2497, acc-0.9200, valid loss-0.2929, acc-0.9210, test loss-0.3036, acc-0.9176\n",
      "Iter-45340, train loss-0.5628, acc-0.9000, valid loss-0.2929, acc-0.9206, test loss-0.3035, acc-0.9174\n",
      "Iter-45350, train loss-0.3261, acc-0.9200, valid loss-0.2929, acc-0.9206, test loss-0.3035, acc-0.9174\n",
      "Iter-45360, train loss-0.4563, acc-0.9000, valid loss-0.2928, acc-0.9208, test loss-0.3034, acc-0.9174\n",
      "Iter-45370, train loss-0.2560, acc-0.9400, valid loss-0.2929, acc-0.9208, test loss-0.3034, acc-0.9177\n",
      "Iter-45380, train loss-0.3988, acc-0.8600, valid loss-0.2929, acc-0.9208, test loss-0.3034, acc-0.9176\n",
      "Iter-45390, train loss-0.4103, acc-0.8600, valid loss-0.2928, acc-0.9208, test loss-0.3033, acc-0.9179\n",
      "Iter-45400, train loss-0.4212, acc-0.8800, valid loss-0.2928, acc-0.9208, test loss-0.3033, acc-0.9179\n",
      "Iter-45410, train loss-0.2389, acc-0.9400, valid loss-0.2927, acc-0.9208, test loss-0.3033, acc-0.9179\n",
      "Iter-45420, train loss-0.2857, acc-0.9000, valid loss-0.2927, acc-0.9210, test loss-0.3032, acc-0.9179\n",
      "Iter-45430, train loss-0.2174, acc-0.9200, valid loss-0.2927, acc-0.9208, test loss-0.3032, acc-0.9177\n",
      "Iter-45440, train loss-0.3750, acc-0.8600, valid loss-0.2927, acc-0.9210, test loss-0.3032, acc-0.9181\n",
      "Iter-45450, train loss-0.2085, acc-0.9400, valid loss-0.2927, acc-0.9212, test loss-0.3032, acc-0.9182\n",
      "Iter-45460, train loss-0.4543, acc-0.9000, valid loss-0.2927, acc-0.9212, test loss-0.3031, acc-0.9182\n",
      "Iter-45470, train loss-0.4614, acc-0.8400, valid loss-0.2926, acc-0.9212, test loss-0.3031, acc-0.9179\n",
      "Iter-45480, train loss-0.1636, acc-0.9600, valid loss-0.2926, acc-0.9212, test loss-0.3031, acc-0.9180\n",
      "Iter-45490, train loss-0.1340, acc-0.9800, valid loss-0.2927, acc-0.9212, test loss-0.3031, acc-0.9179\n",
      "Iter-45500, train loss-0.2464, acc-0.9200, valid loss-0.2927, acc-0.9212, test loss-0.3031, acc-0.9177\n",
      "Iter-45510, train loss-0.3635, acc-0.8800, valid loss-0.2927, acc-0.9210, test loss-0.3031, acc-0.9180\n",
      "Iter-45520, train loss-0.2398, acc-0.9200, valid loss-0.2926, acc-0.9212, test loss-0.3030, acc-0.9179\n",
      "Iter-45530, train loss-0.3107, acc-0.9400, valid loss-0.2926, acc-0.9212, test loss-0.3029, acc-0.9178\n",
      "Iter-45540, train loss-0.1786, acc-0.9800, valid loss-0.2925, acc-0.9210, test loss-0.3029, acc-0.9177\n",
      "Iter-45550, train loss-0.2106, acc-0.9400, valid loss-0.2925, acc-0.9212, test loss-0.3029, acc-0.9176\n",
      "Iter-45560, train loss-0.2343, acc-0.9400, valid loss-0.2925, acc-0.9212, test loss-0.3028, acc-0.9179\n",
      "Iter-45570, train loss-0.2722, acc-0.9200, valid loss-0.2924, acc-0.9212, test loss-0.3028, acc-0.9178\n",
      "Iter-45580, train loss-0.2778, acc-0.9200, valid loss-0.2924, acc-0.9210, test loss-0.3027, acc-0.9176\n",
      "Iter-45590, train loss-0.3708, acc-0.8800, valid loss-0.2924, acc-0.9212, test loss-0.3027, acc-0.9177\n",
      "Iter-45600, train loss-0.3597, acc-0.9200, valid loss-0.2924, acc-0.9214, test loss-0.3027, acc-0.9176\n",
      "Iter-45610, train loss-0.4777, acc-0.8400, valid loss-0.2923, acc-0.9214, test loss-0.3027, acc-0.9178\n",
      "Iter-45620, train loss-0.2256, acc-0.9400, valid loss-0.2923, acc-0.9212, test loss-0.3027, acc-0.9178\n",
      "Iter-45630, train loss-0.2001, acc-0.9400, valid loss-0.2923, acc-0.9210, test loss-0.3026, acc-0.9176\n",
      "Iter-45640, train loss-0.2690, acc-0.9200, valid loss-0.2922, acc-0.9212, test loss-0.3026, acc-0.9176\n",
      "Iter-45650, train loss-0.2628, acc-0.8800, valid loss-0.2922, acc-0.9212, test loss-0.3025, acc-0.9174\n",
      "Iter-45660, train loss-0.2803, acc-0.9200, valid loss-0.2922, acc-0.9212, test loss-0.3025, acc-0.9175\n",
      "Iter-45670, train loss-0.2618, acc-0.9400, valid loss-0.2921, acc-0.9214, test loss-0.3026, acc-0.9175\n",
      "Iter-45680, train loss-0.4141, acc-0.9200, valid loss-0.2921, acc-0.9214, test loss-0.3025, acc-0.9176\n",
      "Iter-45690, train loss-0.2487, acc-0.9200, valid loss-0.2920, acc-0.9214, test loss-0.3025, acc-0.9176\n",
      "Iter-45700, train loss-0.3470, acc-0.9400, valid loss-0.2920, acc-0.9212, test loss-0.3025, acc-0.9175\n",
      "Iter-45710, train loss-0.1989, acc-0.9400, valid loss-0.2920, acc-0.9212, test loss-0.3025, acc-0.9174\n",
      "Iter-45720, train loss-0.2670, acc-0.9200, valid loss-0.2920, acc-0.9208, test loss-0.3024, acc-0.9175\n",
      "Iter-45730, train loss-0.2062, acc-0.9600, valid loss-0.2920, acc-0.9212, test loss-0.3024, acc-0.9172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-45740, train loss-0.2275, acc-0.9400, valid loss-0.2919, acc-0.9212, test loss-0.3024, acc-0.9172\n",
      "Iter-45750, train loss-0.2655, acc-0.9400, valid loss-0.2919, acc-0.9214, test loss-0.3023, acc-0.9173\n",
      "Iter-45760, train loss-0.1996, acc-0.9400, valid loss-0.2919, acc-0.9212, test loss-0.3023, acc-0.9175\n",
      "Iter-45770, train loss-0.4074, acc-0.9000, valid loss-0.2919, acc-0.9212, test loss-0.3023, acc-0.9177\n",
      "Iter-45780, train loss-0.2696, acc-0.9400, valid loss-0.2918, acc-0.9212, test loss-0.3023, acc-0.9175\n",
      "Iter-45790, train loss-0.4033, acc-0.9000, valid loss-0.2918, acc-0.9210, test loss-0.3023, acc-0.9173\n",
      "Iter-45800, train loss-0.1258, acc-0.9800, valid loss-0.2917, acc-0.9210, test loss-0.3022, acc-0.9176\n",
      "Iter-45810, train loss-0.3883, acc-0.9200, valid loss-0.2916, acc-0.9210, test loss-0.3022, acc-0.9176\n",
      "Iter-45820, train loss-0.2350, acc-0.9200, valid loss-0.2917, acc-0.9214, test loss-0.3022, acc-0.9175\n",
      "Iter-45830, train loss-0.1022, acc-0.9800, valid loss-0.2916, acc-0.9216, test loss-0.3021, acc-0.9174\n",
      "Iter-45840, train loss-0.2282, acc-0.9600, valid loss-0.2916, acc-0.9216, test loss-0.3021, acc-0.9174\n",
      "Iter-45850, train loss-0.3127, acc-0.9400, valid loss-0.2915, acc-0.9216, test loss-0.3021, acc-0.9177\n",
      "Iter-45860, train loss-0.2233, acc-0.9400, valid loss-0.2915, acc-0.9214, test loss-0.3021, acc-0.9178\n",
      "Iter-45870, train loss-0.5195, acc-0.8200, valid loss-0.2915, acc-0.9218, test loss-0.3020, acc-0.9177\n",
      "Iter-45880, train loss-0.2444, acc-0.9400, valid loss-0.2915, acc-0.9216, test loss-0.3020, acc-0.9178\n",
      "Iter-45890, train loss-0.3330, acc-0.9000, valid loss-0.2914, acc-0.9214, test loss-0.3019, acc-0.9178\n",
      "Iter-45900, train loss-0.2356, acc-0.9400, valid loss-0.2914, acc-0.9218, test loss-0.3019, acc-0.9179\n",
      "Iter-45910, train loss-0.4914, acc-0.8400, valid loss-0.2914, acc-0.9214, test loss-0.3019, acc-0.9179\n",
      "Iter-45920, train loss-0.2446, acc-0.9600, valid loss-0.2914, acc-0.9216, test loss-0.3019, acc-0.9177\n",
      "Iter-45930, train loss-0.2889, acc-0.9400, valid loss-0.2913, acc-0.9218, test loss-0.3020, acc-0.9174\n",
      "Iter-45940, train loss-0.3398, acc-0.9400, valid loss-0.2913, acc-0.9214, test loss-0.3019, acc-0.9178\n",
      "Iter-45950, train loss-0.4282, acc-0.8800, valid loss-0.2913, acc-0.9218, test loss-0.3019, acc-0.9181\n",
      "Iter-45960, train loss-0.1823, acc-0.9800, valid loss-0.2913, acc-0.9216, test loss-0.3019, acc-0.9183\n",
      "Iter-45970, train loss-0.1422, acc-1.0000, valid loss-0.2913, acc-0.9218, test loss-0.3019, acc-0.9185\n",
      "Iter-45980, train loss-0.2931, acc-0.9000, valid loss-0.2912, acc-0.9216, test loss-0.3020, acc-0.9182\n",
      "Iter-45990, train loss-0.2116, acc-0.9800, valid loss-0.2912, acc-0.9216, test loss-0.3019, acc-0.9184\n",
      "Iter-46000, train loss-0.1645, acc-0.9800, valid loss-0.2912, acc-0.9220, test loss-0.3019, acc-0.9183\n",
      "Iter-46010, train loss-0.2747, acc-0.9400, valid loss-0.2911, acc-0.9216, test loss-0.3019, acc-0.9183\n",
      "Iter-46020, train loss-0.2026, acc-0.9400, valid loss-0.2911, acc-0.9216, test loss-0.3019, acc-0.9185\n",
      "Iter-46030, train loss-0.3733, acc-0.8800, valid loss-0.2911, acc-0.9218, test loss-0.3019, acc-0.9187\n",
      "Iter-46040, train loss-0.1921, acc-0.9600, valid loss-0.2911, acc-0.9220, test loss-0.3018, acc-0.9187\n",
      "Iter-46050, train loss-0.3002, acc-0.9000, valid loss-0.2910, acc-0.9222, test loss-0.3018, acc-0.9184\n",
      "Iter-46060, train loss-0.2296, acc-0.9600, valid loss-0.2910, acc-0.9222, test loss-0.3018, acc-0.9184\n",
      "Iter-46070, train loss-0.4294, acc-0.8800, valid loss-0.2909, acc-0.9222, test loss-0.3018, acc-0.9184\n",
      "Iter-46080, train loss-0.4166, acc-0.8800, valid loss-0.2909, acc-0.9218, test loss-0.3017, acc-0.9185\n",
      "Iter-46090, train loss-0.3104, acc-0.9200, valid loss-0.2909, acc-0.9218, test loss-0.3017, acc-0.9185\n",
      "Iter-46100, train loss-0.2736, acc-0.9000, valid loss-0.2908, acc-0.9222, test loss-0.3016, acc-0.9184\n",
      "Iter-46110, train loss-0.6127, acc-0.8600, valid loss-0.2908, acc-0.9218, test loss-0.3016, acc-0.9183\n",
      "Iter-46120, train loss-0.1531, acc-0.9600, valid loss-0.2908, acc-0.9220, test loss-0.3015, acc-0.9186\n",
      "Iter-46130, train loss-0.3181, acc-0.9200, valid loss-0.2907, acc-0.9220, test loss-0.3015, acc-0.9182\n",
      "Iter-46140, train loss-0.2390, acc-0.9600, valid loss-0.2907, acc-0.9220, test loss-0.3015, acc-0.9182\n",
      "Iter-46150, train loss-0.1896, acc-0.9400, valid loss-0.2906, acc-0.9216, test loss-0.3014, acc-0.9184\n",
      "Iter-46160, train loss-0.2858, acc-0.9000, valid loss-0.2906, acc-0.9218, test loss-0.3014, acc-0.9183\n",
      "Iter-46170, train loss-0.2112, acc-0.9400, valid loss-0.2906, acc-0.9218, test loss-0.3014, acc-0.9182\n",
      "Iter-46180, train loss-0.4695, acc-0.9000, valid loss-0.2906, acc-0.9218, test loss-0.3014, acc-0.9183\n",
      "Iter-46190, train loss-0.4201, acc-0.9000, valid loss-0.2906, acc-0.9218, test loss-0.3013, acc-0.9184\n",
      "Iter-46200, train loss-0.3652, acc-0.8800, valid loss-0.2906, acc-0.9218, test loss-0.3013, acc-0.9184\n",
      "Iter-46210, train loss-0.3436, acc-0.8800, valid loss-0.2905, acc-0.9218, test loss-0.3013, acc-0.9180\n",
      "Iter-46220, train loss-0.3640, acc-0.9000, valid loss-0.2906, acc-0.9222, test loss-0.3012, acc-0.9176\n",
      "Iter-46230, train loss-0.3120, acc-0.9400, valid loss-0.2905, acc-0.9220, test loss-0.3012, acc-0.9177\n",
      "Iter-46240, train loss-0.2753, acc-0.9400, valid loss-0.2905, acc-0.9222, test loss-0.3012, acc-0.9179\n",
      "Iter-46250, train loss-0.1884, acc-0.9400, valid loss-0.2904, acc-0.9220, test loss-0.3012, acc-0.9181\n",
      "Iter-46260, train loss-0.4009, acc-0.9000, valid loss-0.2904, acc-0.9222, test loss-0.3012, acc-0.9182\n",
      "Iter-46270, train loss-0.2108, acc-0.9800, valid loss-0.2903, acc-0.9222, test loss-0.3012, acc-0.9180\n",
      "Iter-46280, train loss-0.4629, acc-0.9000, valid loss-0.2903, acc-0.9224, test loss-0.3012, acc-0.9177\n",
      "Iter-46290, train loss-0.3181, acc-0.8800, valid loss-0.2903, acc-0.9224, test loss-0.3011, acc-0.9182\n",
      "Iter-46300, train loss-0.3770, acc-0.8800, valid loss-0.2902, acc-0.9224, test loss-0.3011, acc-0.9179\n",
      "Iter-46310, train loss-0.4728, acc-0.8400, valid loss-0.2902, acc-0.9226, test loss-0.3011, acc-0.9178\n",
      "Iter-46320, train loss-0.4673, acc-0.7800, valid loss-0.2902, acc-0.9224, test loss-0.3011, acc-0.9178\n",
      "Iter-46330, train loss-0.2264, acc-0.9400, valid loss-0.2902, acc-0.9224, test loss-0.3010, acc-0.9178\n",
      "Iter-46340, train loss-0.3195, acc-0.9200, valid loss-0.2901, acc-0.9224, test loss-0.3010, acc-0.9177\n",
      "Iter-46350, train loss-0.4524, acc-0.8400, valid loss-0.2901, acc-0.9224, test loss-0.3010, acc-0.9176\n",
      "Iter-46360, train loss-0.1276, acc-0.9600, valid loss-0.2902, acc-0.9224, test loss-0.3010, acc-0.9175\n",
      "Iter-46370, train loss-0.1626, acc-0.9600, valid loss-0.2901, acc-0.9224, test loss-0.3010, acc-0.9174\n",
      "Iter-46380, train loss-0.2377, acc-0.9000, valid loss-0.2901, acc-0.9224, test loss-0.3009, acc-0.9176\n",
      "Iter-46390, train loss-0.3116, acc-0.8600, valid loss-0.2901, acc-0.9224, test loss-0.3009, acc-0.9180\n",
      "Iter-46400, train loss-0.3255, acc-0.9200, valid loss-0.2901, acc-0.9222, test loss-0.3009, acc-0.9178\n",
      "Iter-46410, train loss-0.1906, acc-0.9400, valid loss-0.2901, acc-0.9224, test loss-0.3009, acc-0.9179\n",
      "Iter-46420, train loss-0.3226, acc-0.8800, valid loss-0.2901, acc-0.9222, test loss-0.3010, acc-0.9179\n",
      "Iter-46430, train loss-0.3110, acc-0.9000, valid loss-0.2900, acc-0.9224, test loss-0.3009, acc-0.9178\n",
      "Iter-46440, train loss-0.3331, acc-0.8600, valid loss-0.2900, acc-0.9224, test loss-0.3009, acc-0.9181\n",
      "Iter-46450, train loss-0.2014, acc-0.9200, valid loss-0.2900, acc-0.9224, test loss-0.3009, acc-0.9181\n",
      "Iter-46460, train loss-0.2258, acc-0.9000, valid loss-0.2900, acc-0.9224, test loss-0.3009, acc-0.9179\n",
      "Iter-46470, train loss-0.3286, acc-0.9000, valid loss-0.2900, acc-0.9220, test loss-0.3008, acc-0.9177\n",
      "Iter-46480, train loss-0.1880, acc-0.9400, valid loss-0.2899, acc-0.9220, test loss-0.3008, acc-0.9180\n",
      "Iter-46490, train loss-0.1969, acc-0.9400, valid loss-0.2899, acc-0.9224, test loss-0.3007, acc-0.9181\n",
      "Iter-46500, train loss-0.4554, acc-0.8800, valid loss-0.2898, acc-0.9220, test loss-0.3007, acc-0.9181\n",
      "Iter-46510, train loss-0.4005, acc-0.9000, valid loss-0.2897, acc-0.9220, test loss-0.3007, acc-0.9179\n",
      "Iter-46520, train loss-0.2485, acc-0.9600, valid loss-0.2898, acc-0.9220, test loss-0.3006, acc-0.9180\n",
      "Iter-46530, train loss-0.3688, acc-0.9200, valid loss-0.2897, acc-0.9220, test loss-0.3006, acc-0.9180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-46540, train loss-0.5421, acc-0.8000, valid loss-0.2897, acc-0.9220, test loss-0.3006, acc-0.9179\n",
      "Iter-46550, train loss-0.3445, acc-0.9000, valid loss-0.2898, acc-0.9220, test loss-0.3006, acc-0.9176\n",
      "Iter-46560, train loss-0.2191, acc-0.9600, valid loss-0.2898, acc-0.9222, test loss-0.3005, acc-0.9177\n",
      "Iter-46570, train loss-0.4780, acc-0.8200, valid loss-0.2898, acc-0.9220, test loss-0.3006, acc-0.9177\n",
      "Iter-46580, train loss-0.4340, acc-0.8200, valid loss-0.2898, acc-0.9222, test loss-0.3006, acc-0.9179\n",
      "Iter-46590, train loss-0.2241, acc-0.9600, valid loss-0.2897, acc-0.9222, test loss-0.3006, acc-0.9179\n",
      "Iter-46600, train loss-0.3234, acc-0.9000, valid loss-0.2897, acc-0.9222, test loss-0.3005, acc-0.9180\n",
      "Iter-46610, train loss-0.2635, acc-0.9200, valid loss-0.2896, acc-0.9224, test loss-0.3005, acc-0.9176\n",
      "Iter-46620, train loss-0.2361, acc-0.9400, valid loss-0.2897, acc-0.9222, test loss-0.3004, acc-0.9175\n",
      "Iter-46630, train loss-0.3722, acc-0.9200, valid loss-0.2896, acc-0.9220, test loss-0.3004, acc-0.9177\n",
      "Iter-46640, train loss-0.4732, acc-0.8800, valid loss-0.2896, acc-0.9220, test loss-0.3004, acc-0.9176\n",
      "Iter-46650, train loss-0.2414, acc-0.9400, valid loss-0.2896, acc-0.9220, test loss-0.3004, acc-0.9177\n",
      "Iter-46660, train loss-0.2323, acc-0.9200, valid loss-0.2895, acc-0.9220, test loss-0.3003, acc-0.9174\n",
      "Iter-46670, train loss-0.4639, acc-0.8800, valid loss-0.2895, acc-0.9220, test loss-0.3003, acc-0.9177\n",
      "Iter-46680, train loss-0.2804, acc-0.9400, valid loss-0.2895, acc-0.9220, test loss-0.3003, acc-0.9180\n",
      "Iter-46690, train loss-0.3049, acc-0.9400, valid loss-0.2894, acc-0.9222, test loss-0.3002, acc-0.9180\n",
      "Iter-46700, train loss-0.3115, acc-0.9200, valid loss-0.2894, acc-0.9220, test loss-0.3003, acc-0.9179\n",
      "Iter-46710, train loss-0.2698, acc-0.9200, valid loss-0.2893, acc-0.9222, test loss-0.3002, acc-0.9180\n",
      "Iter-46720, train loss-0.2269, acc-0.9000, valid loss-0.2893, acc-0.9222, test loss-0.3002, acc-0.9179\n",
      "Iter-46730, train loss-0.1398, acc-0.9800, valid loss-0.2892, acc-0.9220, test loss-0.3003, acc-0.9178\n",
      "Iter-46740, train loss-0.1972, acc-0.9400, valid loss-0.2892, acc-0.9222, test loss-0.3003, acc-0.9181\n",
      "Iter-46750, train loss-0.3501, acc-0.9200, valid loss-0.2892, acc-0.9222, test loss-0.3002, acc-0.9181\n",
      "Iter-46760, train loss-0.2705, acc-0.9200, valid loss-0.2891, acc-0.9220, test loss-0.3003, acc-0.9178\n",
      "Iter-46770, train loss-0.2648, acc-0.9000, valid loss-0.2891, acc-0.9220, test loss-0.3002, acc-0.9180\n",
      "Iter-46780, train loss-0.3187, acc-0.9200, valid loss-0.2890, acc-0.9218, test loss-0.3002, acc-0.9178\n",
      "Iter-46790, train loss-0.1974, acc-0.9600, valid loss-0.2890, acc-0.9220, test loss-0.3002, acc-0.9178\n",
      "Iter-46800, train loss-0.4059, acc-0.8200, valid loss-0.2890, acc-0.9220, test loss-0.3001, acc-0.9179\n",
      "Iter-46810, train loss-0.4015, acc-0.8600, valid loss-0.2890, acc-0.9222, test loss-0.3001, acc-0.9180\n",
      "Iter-46820, train loss-0.3544, acc-0.9000, valid loss-0.2890, acc-0.9220, test loss-0.3000, acc-0.9178\n",
      "Iter-46830, train loss-0.2272, acc-0.9400, valid loss-0.2890, acc-0.9220, test loss-0.3000, acc-0.9179\n",
      "Iter-46840, train loss-0.1569, acc-0.9600, valid loss-0.2890, acc-0.9220, test loss-0.2999, acc-0.9180\n",
      "Iter-46850, train loss-0.3077, acc-0.9200, valid loss-0.2889, acc-0.9224, test loss-0.2999, acc-0.9179\n",
      "Iter-46860, train loss-0.2459, acc-0.9200, valid loss-0.2890, acc-0.9220, test loss-0.2998, acc-0.9181\n",
      "Iter-46870, train loss-0.2323, acc-0.9400, valid loss-0.2890, acc-0.9214, test loss-0.2998, acc-0.9180\n",
      "Iter-46880, train loss-0.2055, acc-0.9800, valid loss-0.2890, acc-0.9214, test loss-0.2997, acc-0.9182\n",
      "Iter-46890, train loss-0.1918, acc-0.9400, valid loss-0.2890, acc-0.9214, test loss-0.2997, acc-0.9182\n",
      "Iter-46900, train loss-0.2171, acc-0.9800, valid loss-0.2889, acc-0.9210, test loss-0.2997, acc-0.9180\n",
      "Iter-46910, train loss-0.3847, acc-0.9000, valid loss-0.2889, acc-0.9210, test loss-0.2997, acc-0.9181\n",
      "Iter-46920, train loss-0.4028, acc-0.9000, valid loss-0.2889, acc-0.9212, test loss-0.2996, acc-0.9181\n",
      "Iter-46930, train loss-0.3442, acc-0.8600, valid loss-0.2889, acc-0.9212, test loss-0.2996, acc-0.9182\n",
      "Iter-46940, train loss-0.2840, acc-0.9200, valid loss-0.2888, acc-0.9210, test loss-0.2996, acc-0.9181\n",
      "Iter-46950, train loss-0.4136, acc-0.8800, valid loss-0.2888, acc-0.9212, test loss-0.2996, acc-0.9183\n",
      "Iter-46960, train loss-0.2344, acc-0.9000, valid loss-0.2887, acc-0.9214, test loss-0.2996, acc-0.9183\n",
      "Iter-46970, train loss-0.2357, acc-0.9200, valid loss-0.2887, acc-0.9212, test loss-0.2996, acc-0.9184\n",
      "Iter-46980, train loss-0.3216, acc-0.9000, valid loss-0.2887, acc-0.9208, test loss-0.2995, acc-0.9183\n",
      "Iter-46990, train loss-0.3110, acc-0.9000, valid loss-0.2887, acc-0.9208, test loss-0.2996, acc-0.9182\n",
      "Iter-47000, train loss-0.3651, acc-0.8800, valid loss-0.2887, acc-0.9208, test loss-0.2996, acc-0.9181\n",
      "Iter-47010, train loss-0.2423, acc-0.9400, valid loss-0.2886, acc-0.9210, test loss-0.2995, acc-0.9182\n",
      "Iter-47020, train loss-0.1883, acc-0.9400, valid loss-0.2886, acc-0.9210, test loss-0.2995, acc-0.9180\n",
      "Iter-47030, train loss-0.4539, acc-0.8800, valid loss-0.2886, acc-0.9214, test loss-0.2995, acc-0.9178\n",
      "Iter-47040, train loss-0.3218, acc-0.9200, valid loss-0.2886, acc-0.9218, test loss-0.2995, acc-0.9178\n",
      "Iter-47050, train loss-0.2600, acc-0.9000, valid loss-0.2886, acc-0.9218, test loss-0.2994, acc-0.9176\n",
      "Iter-47060, train loss-0.3711, acc-0.9200, valid loss-0.2885, acc-0.9212, test loss-0.2994, acc-0.9176\n",
      "Iter-47070, train loss-0.2340, acc-0.9000, valid loss-0.2885, acc-0.9218, test loss-0.2994, acc-0.9177\n",
      "Iter-47080, train loss-0.2187, acc-0.9400, valid loss-0.2884, acc-0.9220, test loss-0.2993, acc-0.9176\n",
      "Iter-47090, train loss-0.3280, acc-0.8800, valid loss-0.2884, acc-0.9222, test loss-0.2993, acc-0.9176\n",
      "Iter-47100, train loss-0.2823, acc-0.9400, valid loss-0.2884, acc-0.9222, test loss-0.2992, acc-0.9177\n",
      "Iter-47110, train loss-0.1591, acc-1.0000, valid loss-0.2884, acc-0.9220, test loss-0.2992, acc-0.9176\n",
      "Iter-47120, train loss-0.3112, acc-0.8800, valid loss-0.2884, acc-0.9220, test loss-0.2992, acc-0.9176\n",
      "Iter-47130, train loss-0.5402, acc-0.8600, valid loss-0.2884, acc-0.9220, test loss-0.2991, acc-0.9172\n",
      "Iter-47140, train loss-0.2780, acc-0.9200, valid loss-0.2884, acc-0.9220, test loss-0.2991, acc-0.9173\n",
      "Iter-47150, train loss-0.3887, acc-0.8400, valid loss-0.2884, acc-0.9218, test loss-0.2991, acc-0.9176\n",
      "Iter-47160, train loss-0.1594, acc-0.9800, valid loss-0.2883, acc-0.9218, test loss-0.2991, acc-0.9172\n",
      "Iter-47170, train loss-0.2051, acc-0.9600, valid loss-0.2883, acc-0.9218, test loss-0.2991, acc-0.9175\n",
      "Iter-47180, train loss-0.4747, acc-0.9000, valid loss-0.2883, acc-0.9218, test loss-0.2991, acc-0.9176\n",
      "Iter-47190, train loss-0.2626, acc-0.9200, valid loss-0.2883, acc-0.9218, test loss-0.2991, acc-0.9179\n",
      "Iter-47200, train loss-0.4727, acc-0.9000, valid loss-0.2883, acc-0.9218, test loss-0.2990, acc-0.9177\n",
      "Iter-47210, train loss-0.1454, acc-0.9800, valid loss-0.2883, acc-0.9218, test loss-0.2989, acc-0.9175\n",
      "Iter-47220, train loss-0.2085, acc-0.9400, valid loss-0.2882, acc-0.9220, test loss-0.2988, acc-0.9176\n",
      "Iter-47230, train loss-0.2121, acc-0.9400, valid loss-0.2882, acc-0.9218, test loss-0.2989, acc-0.9175\n",
      "Iter-47240, train loss-0.4088, acc-0.9200, valid loss-0.2882, acc-0.9216, test loss-0.2988, acc-0.9176\n",
      "Iter-47250, train loss-0.2964, acc-0.9200, valid loss-0.2881, acc-0.9216, test loss-0.2988, acc-0.9176\n",
      "Iter-47260, train loss-0.3027, acc-0.9000, valid loss-0.2881, acc-0.9212, test loss-0.2988, acc-0.9175\n",
      "Iter-47270, train loss-0.1495, acc-0.9600, valid loss-0.2881, acc-0.9214, test loss-0.2988, acc-0.9175\n",
      "Iter-47280, train loss-0.2141, acc-0.9400, valid loss-0.2881, acc-0.9214, test loss-0.2987, acc-0.9174\n",
      "Iter-47290, train loss-0.2522, acc-0.9400, valid loss-0.2881, acc-0.9212, test loss-0.2987, acc-0.9178\n",
      "Iter-47300, train loss-0.2174, acc-0.9400, valid loss-0.2881, acc-0.9212, test loss-0.2987, acc-0.9179\n",
      "Iter-47310, train loss-0.3650, acc-0.9000, valid loss-0.2880, acc-0.9212, test loss-0.2986, acc-0.9181\n",
      "Iter-47320, train loss-0.3089, acc-0.9000, valid loss-0.2880, acc-0.9214, test loss-0.2985, acc-0.9182\n",
      "Iter-47330, train loss-0.3216, acc-0.9400, valid loss-0.2880, acc-0.9216, test loss-0.2985, acc-0.9182\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-47340, train loss-0.4239, acc-0.9000, valid loss-0.2880, acc-0.9216, test loss-0.2985, acc-0.9181\n",
      "Iter-47350, train loss-0.2362, acc-0.9400, valid loss-0.2880, acc-0.9212, test loss-0.2985, acc-0.9182\n",
      "Iter-47360, train loss-0.3714, acc-0.8600, valid loss-0.2880, acc-0.9214, test loss-0.2985, acc-0.9184\n",
      "Iter-47370, train loss-0.4189, acc-0.8600, valid loss-0.2879, acc-0.9212, test loss-0.2984, acc-0.9182\n",
      "Iter-47380, train loss-0.2085, acc-0.9400, valid loss-0.2879, acc-0.9212, test loss-0.2984, acc-0.9185\n",
      "Iter-47390, train loss-0.4352, acc-0.9200, valid loss-0.2878, acc-0.9212, test loss-0.2983, acc-0.9180\n",
      "Iter-47400, train loss-0.3966, acc-0.9000, valid loss-0.2877, acc-0.9212, test loss-0.2984, acc-0.9183\n",
      "Iter-47410, train loss-0.3466, acc-0.8800, valid loss-0.2878, acc-0.9212, test loss-0.2984, acc-0.9183\n",
      "Iter-47420, train loss-0.2726, acc-0.9000, valid loss-0.2877, acc-0.9210, test loss-0.2984, acc-0.9184\n",
      "Iter-47430, train loss-0.3196, acc-0.8600, valid loss-0.2877, acc-0.9212, test loss-0.2984, acc-0.9180\n",
      "Iter-47440, train loss-0.2639, acc-0.9000, valid loss-0.2876, acc-0.9210, test loss-0.2983, acc-0.9182\n",
      "Iter-47450, train loss-0.3049, acc-0.9200, valid loss-0.2876, acc-0.9212, test loss-0.2983, acc-0.9180\n",
      "Iter-47460, train loss-0.2859, acc-0.9200, valid loss-0.2877, acc-0.9210, test loss-0.2982, acc-0.9178\n",
      "Iter-47470, train loss-0.3260, acc-0.9200, valid loss-0.2876, acc-0.9210, test loss-0.2982, acc-0.9181\n",
      "Iter-47480, train loss-0.1770, acc-0.9800, valid loss-0.2876, acc-0.9212, test loss-0.2982, acc-0.9182\n",
      "Iter-47490, train loss-0.2106, acc-0.9400, valid loss-0.2877, acc-0.9214, test loss-0.2982, acc-0.9180\n",
      "Iter-47500, train loss-0.3110, acc-0.8800, valid loss-0.2876, acc-0.9214, test loss-0.2982, acc-0.9178\n",
      "Iter-47510, train loss-0.4806, acc-0.8800, valid loss-0.2875, acc-0.9212, test loss-0.2981, acc-0.9176\n",
      "Iter-47520, train loss-0.1850, acc-0.9200, valid loss-0.2875, acc-0.9210, test loss-0.2981, acc-0.9178\n",
      "Iter-47530, train loss-0.2867, acc-0.9400, valid loss-0.2874, acc-0.9210, test loss-0.2980, acc-0.9178\n",
      "Iter-47540, train loss-0.3928, acc-0.8600, valid loss-0.2874, acc-0.9214, test loss-0.2981, acc-0.9176\n",
      "Iter-47550, train loss-0.1895, acc-0.9600, valid loss-0.2874, acc-0.9214, test loss-0.2980, acc-0.9178\n",
      "Iter-47560, train loss-0.1632, acc-0.9600, valid loss-0.2873, acc-0.9214, test loss-0.2980, acc-0.9177\n",
      "Iter-47570, train loss-0.4203, acc-0.8800, valid loss-0.2873, acc-0.9216, test loss-0.2980, acc-0.9180\n",
      "Iter-47580, train loss-0.2935, acc-0.9400, valid loss-0.2873, acc-0.9214, test loss-0.2980, acc-0.9178\n",
      "Iter-47590, train loss-0.2015, acc-0.9400, valid loss-0.2873, acc-0.9216, test loss-0.2980, acc-0.9179\n",
      "Iter-47600, train loss-0.5197, acc-0.8200, valid loss-0.2872, acc-0.9218, test loss-0.2979, acc-0.9178\n",
      "Iter-47610, train loss-0.2381, acc-0.9000, valid loss-0.2872, acc-0.9216, test loss-0.2979, acc-0.9179\n",
      "Iter-47620, train loss-0.2002, acc-0.9600, valid loss-0.2872, acc-0.9214, test loss-0.2979, acc-0.9177\n",
      "Iter-47630, train loss-0.4544, acc-0.9200, valid loss-0.2872, acc-0.9216, test loss-0.2979, acc-0.9179\n",
      "Iter-47640, train loss-0.4628, acc-0.8800, valid loss-0.2872, acc-0.9216, test loss-0.2978, acc-0.9182\n",
      "Iter-47650, train loss-0.2598, acc-0.9200, valid loss-0.2872, acc-0.9214, test loss-0.2979, acc-0.9180\n",
      "Iter-47660, train loss-0.3483, acc-0.9200, valid loss-0.2872, acc-0.9216, test loss-0.2978, acc-0.9181\n",
      "Iter-47670, train loss-0.4563, acc-0.9000, valid loss-0.2872, acc-0.9214, test loss-0.2978, acc-0.9180\n",
      "Iter-47680, train loss-0.2038, acc-0.9200, valid loss-0.2871, acc-0.9214, test loss-0.2978, acc-0.9178\n",
      "Iter-47690, train loss-0.1810, acc-0.9600, valid loss-0.2871, acc-0.9216, test loss-0.2978, acc-0.9179\n",
      "Iter-47700, train loss-0.1895, acc-0.9800, valid loss-0.2871, acc-0.9216, test loss-0.2978, acc-0.9180\n",
      "Iter-47710, train loss-0.2594, acc-0.9400, valid loss-0.2871, acc-0.9214, test loss-0.2978, acc-0.9181\n",
      "Iter-47720, train loss-0.2725, acc-0.9600, valid loss-0.2871, acc-0.9216, test loss-0.2977, acc-0.9182\n",
      "Iter-47730, train loss-0.2662, acc-0.9200, valid loss-0.2871, acc-0.9214, test loss-0.2977, acc-0.9183\n",
      "Iter-47740, train loss-0.3526, acc-0.9400, valid loss-0.2870, acc-0.9218, test loss-0.2977, acc-0.9182\n",
      "Iter-47750, train loss-0.5870, acc-0.8000, valid loss-0.2871, acc-0.9220, test loss-0.2976, acc-0.9182\n",
      "Iter-47760, train loss-0.2221, acc-0.9400, valid loss-0.2871, acc-0.9212, test loss-0.2976, acc-0.9182\n",
      "Iter-47770, train loss-0.3457, acc-0.9200, valid loss-0.2870, acc-0.9212, test loss-0.2976, acc-0.9182\n",
      "Iter-47780, train loss-0.2108, acc-0.9400, valid loss-0.2870, acc-0.9216, test loss-0.2976, acc-0.9182\n",
      "Iter-47790, train loss-0.2345, acc-0.9200, valid loss-0.2870, acc-0.9216, test loss-0.2976, acc-0.9182\n",
      "Iter-47800, train loss-0.2149, acc-0.9200, valid loss-0.2869, acc-0.9216, test loss-0.2976, acc-0.9183\n",
      "Iter-47810, train loss-0.2237, acc-0.9600, valid loss-0.2869, acc-0.9216, test loss-0.2976, acc-0.9181\n",
      "Iter-47820, train loss-0.4088, acc-0.9000, valid loss-0.2869, acc-0.9216, test loss-0.2975, acc-0.9181\n",
      "Iter-47830, train loss-0.2167, acc-0.9400, valid loss-0.2869, acc-0.9214, test loss-0.2975, acc-0.9180\n",
      "Iter-47840, train loss-0.2384, acc-0.9400, valid loss-0.2869, acc-0.9214, test loss-0.2974, acc-0.9182\n",
      "Iter-47850, train loss-0.4302, acc-0.8800, valid loss-0.2869, acc-0.9214, test loss-0.2973, acc-0.9183\n",
      "Iter-47860, train loss-0.2509, acc-0.9200, valid loss-0.2869, acc-0.9216, test loss-0.2973, acc-0.9181\n",
      "Iter-47870, train loss-0.1826, acc-0.9600, valid loss-0.2868, acc-0.9216, test loss-0.2973, acc-0.9182\n",
      "Iter-47880, train loss-0.3047, acc-0.9000, valid loss-0.2868, acc-0.9216, test loss-0.2973, acc-0.9183\n",
      "Iter-47890, train loss-0.3781, acc-0.8800, valid loss-0.2867, acc-0.9216, test loss-0.2973, acc-0.9184\n",
      "Iter-47900, train loss-0.1298, acc-0.9800, valid loss-0.2867, acc-0.9216, test loss-0.2972, acc-0.9183\n",
      "Iter-47910, train loss-0.2693, acc-0.9000, valid loss-0.2867, acc-0.9218, test loss-0.2973, acc-0.9183\n",
      "Iter-47920, train loss-0.4770, acc-0.8200, valid loss-0.2867, acc-0.9220, test loss-0.2972, acc-0.9181\n",
      "Iter-47930, train loss-0.3527, acc-0.9400, valid loss-0.2867, acc-0.9222, test loss-0.2972, acc-0.9184\n",
      "Iter-47940, train loss-0.4333, acc-0.8400, valid loss-0.2866, acc-0.9220, test loss-0.2972, acc-0.9184\n",
      "Iter-47950, train loss-0.4929, acc-0.8800, valid loss-0.2866, acc-0.9220, test loss-0.2972, acc-0.9185\n",
      "Iter-47960, train loss-0.2264, acc-0.9400, valid loss-0.2866, acc-0.9220, test loss-0.2971, acc-0.9185\n",
      "Iter-47970, train loss-0.2320, acc-0.9000, valid loss-0.2866, acc-0.9218, test loss-0.2971, acc-0.9184\n",
      "Iter-47980, train loss-0.2462, acc-0.9600, valid loss-0.2866, acc-0.9220, test loss-0.2971, acc-0.9183\n",
      "Iter-47990, train loss-0.2314, acc-0.9400, valid loss-0.2865, acc-0.9224, test loss-0.2971, acc-0.9183\n",
      "Iter-48000, train loss-0.3101, acc-0.9400, valid loss-0.2865, acc-0.9218, test loss-0.2971, acc-0.9184\n",
      "Iter-48010, train loss-0.4229, acc-0.8200, valid loss-0.2864, acc-0.9220, test loss-0.2970, acc-0.9184\n",
      "Iter-48020, train loss-0.3125, acc-0.9400, valid loss-0.2864, acc-0.9222, test loss-0.2970, acc-0.9184\n",
      "Iter-48030, train loss-0.5099, acc-0.8800, valid loss-0.2864, acc-0.9226, test loss-0.2969, acc-0.9182\n",
      "Iter-48040, train loss-0.2833, acc-0.9200, valid loss-0.2863, acc-0.9228, test loss-0.2969, acc-0.9185\n",
      "Iter-48050, train loss-0.3724, acc-0.8800, valid loss-0.2864, acc-0.9224, test loss-0.2969, acc-0.9183\n",
      "Iter-48060, train loss-0.4852, acc-0.8400, valid loss-0.2864, acc-0.9224, test loss-0.2969, acc-0.9184\n",
      "Iter-48070, train loss-0.2725, acc-0.9400, valid loss-0.2864, acc-0.9224, test loss-0.2969, acc-0.9185\n",
      "Iter-48080, train loss-0.3211, acc-0.8600, valid loss-0.2863, acc-0.9224, test loss-0.2969, acc-0.9183\n",
      "Iter-48090, train loss-0.3213, acc-0.9200, valid loss-0.2864, acc-0.9224, test loss-0.2969, acc-0.9185\n",
      "Iter-48100, train loss-0.2413, acc-0.9400, valid loss-0.2864, acc-0.9222, test loss-0.2969, acc-0.9186\n",
      "Iter-48110, train loss-0.2838, acc-0.9200, valid loss-0.2863, acc-0.9220, test loss-0.2969, acc-0.9185\n",
      "Iter-48120, train loss-0.3201, acc-0.9200, valid loss-0.2863, acc-0.9220, test loss-0.2969, acc-0.9183\n",
      "Iter-48130, train loss-0.2590, acc-0.9000, valid loss-0.2864, acc-0.9220, test loss-0.2968, acc-0.9183\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48140, train loss-0.3768, acc-0.9200, valid loss-0.2863, acc-0.9222, test loss-0.2968, acc-0.9183\n",
      "Iter-48150, train loss-0.1701, acc-0.9400, valid loss-0.2862, acc-0.9222, test loss-0.2968, acc-0.9184\n",
      "Iter-48160, train loss-0.1623, acc-0.9800, valid loss-0.2862, acc-0.9222, test loss-0.2968, acc-0.9185\n",
      "Iter-48170, train loss-0.2309, acc-0.9200, valid loss-0.2862, acc-0.9222, test loss-0.2967, acc-0.9184\n",
      "Iter-48180, train loss-0.3669, acc-0.9400, valid loss-0.2861, acc-0.9220, test loss-0.2967, acc-0.9183\n",
      "Iter-48190, train loss-0.2502, acc-0.9400, valid loss-0.2860, acc-0.9220, test loss-0.2967, acc-0.9183\n",
      "Iter-48200, train loss-0.2573, acc-0.9000, valid loss-0.2860, acc-0.9220, test loss-0.2967, acc-0.9186\n",
      "Iter-48210, train loss-0.2434, acc-0.9600, valid loss-0.2861, acc-0.9216, test loss-0.2966, acc-0.9186\n",
      "Iter-48220, train loss-0.1151, acc-1.0000, valid loss-0.2860, acc-0.9218, test loss-0.2966, acc-0.9187\n",
      "Iter-48230, train loss-0.2515, acc-0.9000, valid loss-0.2860, acc-0.9220, test loss-0.2965, acc-0.9186\n",
      "Iter-48240, train loss-0.2347, acc-0.9000, valid loss-0.2860, acc-0.9216, test loss-0.2965, acc-0.9186\n",
      "Iter-48250, train loss-0.1849, acc-0.9600, valid loss-0.2859, acc-0.9218, test loss-0.2965, acc-0.9186\n",
      "Iter-48260, train loss-0.3130, acc-0.9400, valid loss-0.2858, acc-0.9218, test loss-0.2964, acc-0.9186\n",
      "Iter-48270, train loss-0.2298, acc-0.9400, valid loss-0.2857, acc-0.9218, test loss-0.2964, acc-0.9186\n",
      "Iter-48280, train loss-0.3365, acc-0.8800, valid loss-0.2857, acc-0.9218, test loss-0.2964, acc-0.9187\n",
      "Iter-48290, train loss-0.3014, acc-0.9200, valid loss-0.2857, acc-0.9218, test loss-0.2963, acc-0.9187\n",
      "Iter-48300, train loss-0.2172, acc-0.9400, valid loss-0.2856, acc-0.9218, test loss-0.2963, acc-0.9185\n",
      "Iter-48310, train loss-0.2799, acc-0.9000, valid loss-0.2856, acc-0.9218, test loss-0.2963, acc-0.9185\n",
      "Iter-48320, train loss-0.1714, acc-0.9600, valid loss-0.2856, acc-0.9216, test loss-0.2963, acc-0.9186\n",
      "Iter-48330, train loss-0.1921, acc-0.9800, valid loss-0.2855, acc-0.9218, test loss-0.2962, acc-0.9184\n",
      "Iter-48340, train loss-0.2492, acc-0.9200, valid loss-0.2855, acc-0.9216, test loss-0.2962, acc-0.9184\n",
      "Iter-48350, train loss-0.3930, acc-0.9200, valid loss-0.2855, acc-0.9216, test loss-0.2962, acc-0.9184\n",
      "Iter-48360, train loss-0.4133, acc-0.8800, valid loss-0.2855, acc-0.9216, test loss-0.2961, acc-0.9185\n",
      "Iter-48370, train loss-0.2752, acc-0.9400, valid loss-0.2855, acc-0.9218, test loss-0.2961, acc-0.9184\n",
      "Iter-48380, train loss-0.3353, acc-0.9200, valid loss-0.2855, acc-0.9216, test loss-0.2960, acc-0.9185\n",
      "Iter-48390, train loss-0.3079, acc-0.9200, valid loss-0.2854, acc-0.9220, test loss-0.2960, acc-0.9184\n",
      "Iter-48400, train loss-0.4250, acc-0.9000, valid loss-0.2853, acc-0.9226, test loss-0.2959, acc-0.9185\n",
      "Iter-48410, train loss-0.4467, acc-0.8600, valid loss-0.2853, acc-0.9230, test loss-0.2959, acc-0.9186\n",
      "Iter-48420, train loss-0.3713, acc-0.9000, valid loss-0.2853, acc-0.9228, test loss-0.2960, acc-0.9186\n",
      "Iter-48430, train loss-0.3639, acc-0.8800, valid loss-0.2853, acc-0.9228, test loss-0.2959, acc-0.9186\n",
      "Iter-48440, train loss-0.2345, acc-0.9400, valid loss-0.2852, acc-0.9226, test loss-0.2959, acc-0.9186\n",
      "Iter-48450, train loss-0.3067, acc-0.9000, valid loss-0.2853, acc-0.9222, test loss-0.2959, acc-0.9185\n",
      "Iter-48460, train loss-0.3561, acc-0.8800, valid loss-0.2852, acc-0.9226, test loss-0.2959, acc-0.9183\n",
      "Iter-48470, train loss-0.4100, acc-0.8600, valid loss-0.2852, acc-0.9222, test loss-0.2959, acc-0.9184\n",
      "Iter-48480, train loss-0.3794, acc-0.9200, valid loss-0.2851, acc-0.9228, test loss-0.2959, acc-0.9186\n",
      "Iter-48490, train loss-0.2455, acc-0.9400, valid loss-0.2851, acc-0.9228, test loss-0.2959, acc-0.9186\n",
      "Iter-48500, train loss-0.3398, acc-0.8800, valid loss-0.2851, acc-0.9230, test loss-0.2959, acc-0.9187\n",
      "Iter-48510, train loss-0.3230, acc-0.9200, valid loss-0.2850, acc-0.9230, test loss-0.2959, acc-0.9186\n",
      "Iter-48520, train loss-0.2774, acc-0.9200, valid loss-0.2850, acc-0.9230, test loss-0.2958, acc-0.9187\n",
      "Iter-48530, train loss-0.2935, acc-0.9200, valid loss-0.2850, acc-0.9230, test loss-0.2958, acc-0.9188\n",
      "Iter-48540, train loss-0.2666, acc-0.9000, valid loss-0.2850, acc-0.9230, test loss-0.2957, acc-0.9189\n",
      "Iter-48550, train loss-0.1449, acc-0.9400, valid loss-0.2850, acc-0.9226, test loss-0.2957, acc-0.9187\n",
      "Iter-48560, train loss-0.2397, acc-0.9400, valid loss-0.2850, acc-0.9228, test loss-0.2957, acc-0.9187\n",
      "Iter-48570, train loss-0.2392, acc-0.9400, valid loss-0.2850, acc-0.9228, test loss-0.2957, acc-0.9188\n",
      "Iter-48580, train loss-0.2584, acc-0.9200, valid loss-0.2850, acc-0.9226, test loss-0.2957, acc-0.9188\n",
      "Iter-48590, train loss-0.2056, acc-0.9800, valid loss-0.2849, acc-0.9228, test loss-0.2956, acc-0.9186\n",
      "Iter-48600, train loss-0.3075, acc-0.8800, valid loss-0.2849, acc-0.9226, test loss-0.2956, acc-0.9187\n",
      "Iter-48610, train loss-0.4003, acc-0.9000, valid loss-0.2849, acc-0.9224, test loss-0.2955, acc-0.9188\n",
      "Iter-48620, train loss-0.3731, acc-0.8600, valid loss-0.2848, acc-0.9222, test loss-0.2955, acc-0.9189\n",
      "Iter-48630, train loss-0.1603, acc-0.9600, valid loss-0.2848, acc-0.9224, test loss-0.2955, acc-0.9186\n",
      "Iter-48640, train loss-0.3125, acc-0.9200, valid loss-0.2848, acc-0.9224, test loss-0.2955, acc-0.9186\n",
      "Iter-48650, train loss-0.3286, acc-0.9200, valid loss-0.2848, acc-0.9224, test loss-0.2954, acc-0.9184\n",
      "Iter-48660, train loss-0.3270, acc-0.8800, valid loss-0.2847, acc-0.9228, test loss-0.2954, acc-0.9187\n",
      "Iter-48670, train loss-0.1448, acc-1.0000, valid loss-0.2847, acc-0.9226, test loss-0.2954, acc-0.9187\n",
      "Iter-48680, train loss-0.4457, acc-0.8800, valid loss-0.2847, acc-0.9226, test loss-0.2953, acc-0.9185\n",
      "Iter-48690, train loss-0.1406, acc-0.9600, valid loss-0.2846, acc-0.9224, test loss-0.2953, acc-0.9185\n",
      "Iter-48700, train loss-0.3314, acc-0.8600, valid loss-0.2846, acc-0.9228, test loss-0.2953, acc-0.9184\n",
      "Iter-48710, train loss-0.3198, acc-0.9200, valid loss-0.2846, acc-0.9230, test loss-0.2953, acc-0.9184\n",
      "Iter-48720, train loss-0.4035, acc-0.8800, valid loss-0.2846, acc-0.9230, test loss-0.2952, acc-0.9185\n",
      "Iter-48730, train loss-0.3791, acc-0.9000, valid loss-0.2845, acc-0.9230, test loss-0.2952, acc-0.9185\n",
      "Iter-48740, train loss-0.3188, acc-0.9200, valid loss-0.2845, acc-0.9230, test loss-0.2952, acc-0.9184\n",
      "Iter-48750, train loss-0.2416, acc-0.9000, valid loss-0.2845, acc-0.9232, test loss-0.2952, acc-0.9187\n",
      "Iter-48760, train loss-0.3747, acc-0.9200, valid loss-0.2845, acc-0.9230, test loss-0.2952, acc-0.9184\n",
      "Iter-48770, train loss-0.2984, acc-0.9200, valid loss-0.2845, acc-0.9230, test loss-0.2952, acc-0.9187\n",
      "Iter-48780, train loss-0.4428, acc-0.8600, valid loss-0.2844, acc-0.9234, test loss-0.2951, acc-0.9185\n",
      "Iter-48790, train loss-0.3159, acc-0.9000, valid loss-0.2844, acc-0.9236, test loss-0.2951, acc-0.9184\n",
      "Iter-48800, train loss-0.3919, acc-0.8800, valid loss-0.2844, acc-0.9230, test loss-0.2951, acc-0.9183\n",
      "Iter-48810, train loss-0.2525, acc-0.9400, valid loss-0.2844, acc-0.9236, test loss-0.2951, acc-0.9183\n",
      "Iter-48820, train loss-0.3228, acc-0.9200, valid loss-0.2844, acc-0.9232, test loss-0.2951, acc-0.9183\n",
      "Iter-48830, train loss-0.2446, acc-0.9400, valid loss-0.2844, acc-0.9234, test loss-0.2951, acc-0.9184\n",
      "Iter-48840, train loss-0.3366, acc-0.8800, valid loss-0.2843, acc-0.9236, test loss-0.2950, acc-0.9183\n",
      "Iter-48850, train loss-0.2458, acc-0.9400, valid loss-0.2843, acc-0.9234, test loss-0.2950, acc-0.9186\n",
      "Iter-48860, train loss-0.5048, acc-0.8600, valid loss-0.2843, acc-0.9234, test loss-0.2950, acc-0.9185\n",
      "Iter-48870, train loss-0.5158, acc-0.9000, valid loss-0.2843, acc-0.9234, test loss-0.2950, acc-0.9187\n",
      "Iter-48880, train loss-0.2088, acc-0.9200, valid loss-0.2843, acc-0.9234, test loss-0.2949, acc-0.9189\n",
      "Iter-48890, train loss-0.2333, acc-0.9200, valid loss-0.2843, acc-0.9232, test loss-0.2949, acc-0.9189\n",
      "Iter-48900, train loss-0.3751, acc-0.8800, valid loss-0.2842, acc-0.9234, test loss-0.2949, acc-0.9191\n",
      "Iter-48910, train loss-0.2619, acc-0.9400, valid loss-0.2841, acc-0.9236, test loss-0.2949, acc-0.9190\n",
      "Iter-48920, train loss-0.2798, acc-0.9200, valid loss-0.2842, acc-0.9234, test loss-0.2949, acc-0.9187\n",
      "Iter-48930, train loss-0.1873, acc-0.9600, valid loss-0.2841, acc-0.9232, test loss-0.2948, acc-0.9184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48940, train loss-0.2131, acc-0.9400, valid loss-0.2841, acc-0.9232, test loss-0.2948, acc-0.9185\n",
      "Iter-48950, train loss-0.4180, acc-0.8400, valid loss-0.2841, acc-0.9228, test loss-0.2947, acc-0.9185\n",
      "Iter-48960, train loss-0.3743, acc-0.8800, valid loss-0.2841, acc-0.9232, test loss-0.2947, acc-0.9186\n",
      "Iter-48970, train loss-0.3275, acc-0.9400, valid loss-0.2841, acc-0.9226, test loss-0.2947, acc-0.9186\n",
      "Iter-48980, train loss-0.2754, acc-0.9400, valid loss-0.2841, acc-0.9228, test loss-0.2947, acc-0.9187\n",
      "Iter-48990, train loss-0.2332, acc-0.9600, valid loss-0.2841, acc-0.9228, test loss-0.2947, acc-0.9187\n",
      "Iter-49000, train loss-0.1766, acc-0.9600, valid loss-0.2842, acc-0.9224, test loss-0.2946, acc-0.9186\n",
      "Iter-49010, train loss-0.2641, acc-0.9400, valid loss-0.2841, acc-0.9222, test loss-0.2946, acc-0.9187\n",
      "Iter-49020, train loss-0.5234, acc-0.8200, valid loss-0.2841, acc-0.9226, test loss-0.2947, acc-0.9189\n",
      "Iter-49030, train loss-0.2708, acc-0.9400, valid loss-0.2841, acc-0.9228, test loss-0.2946, acc-0.9186\n",
      "Iter-49040, train loss-0.3289, acc-0.8800, valid loss-0.2841, acc-0.9226, test loss-0.2946, acc-0.9186\n",
      "Iter-49050, train loss-0.4501, acc-0.8400, valid loss-0.2841, acc-0.9224, test loss-0.2946, acc-0.9184\n",
      "Iter-49060, train loss-0.2792, acc-0.9000, valid loss-0.2841, acc-0.9224, test loss-0.2946, acc-0.9184\n",
      "Iter-49070, train loss-0.2835, acc-0.9000, valid loss-0.2841, acc-0.9222, test loss-0.2946, acc-0.9185\n",
      "Iter-49080, train loss-0.3033, acc-0.9400, valid loss-0.2841, acc-0.9220, test loss-0.2945, acc-0.9185\n",
      "Iter-49090, train loss-0.2163, acc-0.9600, valid loss-0.2840, acc-0.9224, test loss-0.2945, acc-0.9184\n",
      "Iter-49100, train loss-0.1826, acc-0.9400, valid loss-0.2841, acc-0.9230, test loss-0.2945, acc-0.9185\n",
      "Iter-49110, train loss-0.2417, acc-0.9400, valid loss-0.2841, acc-0.9230, test loss-0.2945, acc-0.9186\n",
      "Iter-49120, train loss-0.2679, acc-0.9400, valid loss-0.2840, acc-0.9230, test loss-0.2945, acc-0.9188\n",
      "Iter-49130, train loss-0.3215, acc-0.9200, valid loss-0.2840, acc-0.9224, test loss-0.2945, acc-0.9187\n",
      "Iter-49140, train loss-0.1834, acc-0.9800, valid loss-0.2840, acc-0.9226, test loss-0.2944, acc-0.9186\n",
      "Iter-49150, train loss-0.3688, acc-0.9000, valid loss-0.2840, acc-0.9228, test loss-0.2944, acc-0.9188\n",
      "Iter-49160, train loss-0.3364, acc-0.8800, valid loss-0.2840, acc-0.9228, test loss-0.2943, acc-0.9184\n",
      "Iter-49170, train loss-0.2611, acc-0.9400, valid loss-0.2839, acc-0.9224, test loss-0.2943, acc-0.9185\n",
      "Iter-49180, train loss-0.2931, acc-0.9200, valid loss-0.2839, acc-0.9222, test loss-0.2943, acc-0.9187\n",
      "Iter-49190, train loss-0.2518, acc-0.9200, valid loss-0.2838, acc-0.9230, test loss-0.2943, acc-0.9188\n",
      "Iter-49200, train loss-0.2517, acc-0.9800, valid loss-0.2837, acc-0.9230, test loss-0.2942, acc-0.9188\n",
      "Iter-49210, train loss-0.2726, acc-0.9200, valid loss-0.2838, acc-0.9224, test loss-0.2942, acc-0.9190\n",
      "Iter-49220, train loss-0.2648, acc-0.9000, valid loss-0.2837, acc-0.9230, test loss-0.2942, acc-0.9184\n",
      "Iter-49230, train loss-0.2764, acc-0.9600, valid loss-0.2837, acc-0.9232, test loss-0.2942, acc-0.9185\n",
      "Iter-49240, train loss-0.2294, acc-0.9200, valid loss-0.2837, acc-0.9226, test loss-0.2941, acc-0.9186\n",
      "Iter-49250, train loss-0.3217, acc-0.9000, valid loss-0.2836, acc-0.9226, test loss-0.2941, acc-0.9187\n",
      "Iter-49260, train loss-0.2345, acc-0.9600, valid loss-0.2836, acc-0.9228, test loss-0.2941, acc-0.9185\n",
      "Iter-49270, train loss-0.2679, acc-0.9200, valid loss-0.2836, acc-0.9228, test loss-0.2941, acc-0.9185\n",
      "Iter-49280, train loss-0.4370, acc-0.8400, valid loss-0.2837, acc-0.9228, test loss-0.2941, acc-0.9186\n",
      "Iter-49290, train loss-0.2949, acc-0.9200, valid loss-0.2836, acc-0.9230, test loss-0.2941, acc-0.9185\n",
      "Iter-49300, train loss-0.1704, acc-0.9800, valid loss-0.2836, acc-0.9232, test loss-0.2940, acc-0.9184\n",
      "Iter-49310, train loss-0.3778, acc-0.8800, valid loss-0.2836, acc-0.9232, test loss-0.2939, acc-0.9184\n",
      "Iter-49320, train loss-0.1107, acc-0.9800, valid loss-0.2836, acc-0.9232, test loss-0.2939, acc-0.9184\n",
      "Iter-49330, train loss-0.3916, acc-0.8800, valid loss-0.2836, acc-0.9228, test loss-0.2939, acc-0.9185\n",
      "Iter-49340, train loss-0.4082, acc-0.8600, valid loss-0.2836, acc-0.9228, test loss-0.2938, acc-0.9184\n",
      "Iter-49350, train loss-0.1799, acc-0.9800, valid loss-0.2836, acc-0.9226, test loss-0.2938, acc-0.9185\n",
      "Iter-49360, train loss-0.2107, acc-0.9400, valid loss-0.2836, acc-0.9224, test loss-0.2938, acc-0.9188\n",
      "Iter-49370, train loss-0.2515, acc-0.9000, valid loss-0.2836, acc-0.9228, test loss-0.2938, acc-0.9187\n",
      "Iter-49380, train loss-0.3194, acc-0.9200, valid loss-0.2836, acc-0.9226, test loss-0.2938, acc-0.9189\n",
      "Iter-49390, train loss-0.5380, acc-0.8400, valid loss-0.2835, acc-0.9230, test loss-0.2938, acc-0.9188\n",
      "Iter-49400, train loss-0.4696, acc-0.9400, valid loss-0.2835, acc-0.9228, test loss-0.2937, acc-0.9190\n",
      "Iter-49410, train loss-0.2876, acc-0.9200, valid loss-0.2835, acc-0.9228, test loss-0.2938, acc-0.9190\n",
      "Iter-49420, train loss-0.3366, acc-0.9200, valid loss-0.2835, acc-0.9232, test loss-0.2938, acc-0.9191\n",
      "Iter-49430, train loss-0.2318, acc-0.9400, valid loss-0.2835, acc-0.9232, test loss-0.2938, acc-0.9191\n",
      "Iter-49440, train loss-0.4224, acc-0.8800, valid loss-0.2835, acc-0.9232, test loss-0.2938, acc-0.9191\n",
      "Iter-49450, train loss-0.3510, acc-0.9000, valid loss-0.2835, acc-0.9232, test loss-0.2937, acc-0.9191\n",
      "Iter-49460, train loss-0.2602, acc-0.9000, valid loss-0.2835, acc-0.9232, test loss-0.2937, acc-0.9192\n",
      "Iter-49470, train loss-0.2392, acc-0.9600, valid loss-0.2835, acc-0.9232, test loss-0.2937, acc-0.9193\n",
      "Iter-49480, train loss-0.2374, acc-0.9400, valid loss-0.2834, acc-0.9232, test loss-0.2937, acc-0.9194\n",
      "Iter-49490, train loss-0.3581, acc-0.9000, valid loss-0.2834, acc-0.9230, test loss-0.2937, acc-0.9194\n",
      "Iter-49500, train loss-0.5588, acc-0.8000, valid loss-0.2834, acc-0.9232, test loss-0.2936, acc-0.9193\n",
      "Iter-49510, train loss-0.4541, acc-0.9200, valid loss-0.2834, acc-0.9230, test loss-0.2936, acc-0.9194\n",
      "Iter-49520, train loss-0.5562, acc-0.8000, valid loss-0.2834, acc-0.9228, test loss-0.2936, acc-0.9192\n",
      "Iter-49530, train loss-0.2653, acc-0.9400, valid loss-0.2833, acc-0.9228, test loss-0.2935, acc-0.9192\n",
      "Iter-49540, train loss-0.2201, acc-0.9000, valid loss-0.2833, acc-0.9228, test loss-0.2935, acc-0.9193\n",
      "Iter-49550, train loss-0.3141, acc-0.9000, valid loss-0.2833, acc-0.9234, test loss-0.2934, acc-0.9193\n",
      "Iter-49560, train loss-0.2744, acc-0.9000, valid loss-0.2832, acc-0.9236, test loss-0.2934, acc-0.9193\n",
      "Iter-49570, train loss-0.2310, acc-0.9400, valid loss-0.2832, acc-0.9236, test loss-0.2933, acc-0.9195\n",
      "Iter-49580, train loss-0.3039, acc-0.9000, valid loss-0.2832, acc-0.9236, test loss-0.2933, acc-0.9196\n",
      "Iter-49590, train loss-0.4451, acc-0.8800, valid loss-0.2831, acc-0.9234, test loss-0.2932, acc-0.9195\n",
      "Iter-49600, train loss-0.1229, acc-0.9800, valid loss-0.2831, acc-0.9234, test loss-0.2932, acc-0.9198\n",
      "Iter-49610, train loss-0.2612, acc-0.9600, valid loss-0.2831, acc-0.9234, test loss-0.2932, acc-0.9195\n",
      "Iter-49620, train loss-0.3147, acc-0.9200, valid loss-0.2831, acc-0.9234, test loss-0.2931, acc-0.9197\n",
      "Iter-49630, train loss-0.2609, acc-0.9000, valid loss-0.2831, acc-0.9232, test loss-0.2931, acc-0.9198\n",
      "Iter-49640, train loss-0.3119, acc-0.9000, valid loss-0.2831, acc-0.9236, test loss-0.2931, acc-0.9198\n",
      "Iter-49650, train loss-0.3551, acc-0.9200, valid loss-0.2830, acc-0.9234, test loss-0.2930, acc-0.9196\n",
      "Iter-49660, train loss-0.2109, acc-0.9200, valid loss-0.2830, acc-0.9234, test loss-0.2930, acc-0.9196\n",
      "Iter-49670, train loss-0.3142, acc-0.9400, valid loss-0.2829, acc-0.9230, test loss-0.2930, acc-0.9196\n",
      "Iter-49680, train loss-0.3178, acc-0.9400, valid loss-0.2829, acc-0.9236, test loss-0.2930, acc-0.9197\n",
      "Iter-49690, train loss-0.4344, acc-0.8600, valid loss-0.2829, acc-0.9234, test loss-0.2930, acc-0.9196\n",
      "Iter-49700, train loss-0.2200, acc-0.9000, valid loss-0.2829, acc-0.9232, test loss-0.2930, acc-0.9197\n",
      "Iter-49710, train loss-0.3968, acc-0.8800, valid loss-0.2829, acc-0.9234, test loss-0.2930, acc-0.9197\n",
      "Iter-49720, train loss-0.3167, acc-0.8600, valid loss-0.2828, acc-0.9228, test loss-0.2930, acc-0.9198\n",
      "Iter-49730, train loss-0.1473, acc-0.9600, valid loss-0.2828, acc-0.9232, test loss-0.2930, acc-0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-49740, train loss-0.2969, acc-0.9400, valid loss-0.2828, acc-0.9232, test loss-0.2929, acc-0.9198\n",
      "Iter-49750, train loss-0.2767, acc-0.9200, valid loss-0.2828, acc-0.9232, test loss-0.2929, acc-0.9198\n",
      "Iter-49760, train loss-0.2189, acc-0.9600, valid loss-0.2828, acc-0.9232, test loss-0.2928, acc-0.9196\n",
      "Iter-49770, train loss-0.3312, acc-0.9000, valid loss-0.2827, acc-0.9234, test loss-0.2927, acc-0.9198\n",
      "Iter-49780, train loss-0.2914, acc-0.9400, valid loss-0.2827, acc-0.9232, test loss-0.2927, acc-0.9198\n",
      "Iter-49790, train loss-0.2542, acc-0.9400, valid loss-0.2828, acc-0.9230, test loss-0.2927, acc-0.9198\n",
      "Iter-49800, train loss-0.2819, acc-0.9000, valid loss-0.2827, acc-0.9230, test loss-0.2927, acc-0.9196\n",
      "Iter-49810, train loss-0.4060, acc-0.9000, valid loss-0.2828, acc-0.9230, test loss-0.2927, acc-0.9197\n",
      "Iter-49820, train loss-0.1494, acc-0.9600, valid loss-0.2827, acc-0.9230, test loss-0.2927, acc-0.9196\n",
      "Iter-49830, train loss-0.2432, acc-0.8800, valid loss-0.2827, acc-0.9234, test loss-0.2927, acc-0.9197\n",
      "Iter-49840, train loss-0.4007, acc-0.8800, valid loss-0.2827, acc-0.9236, test loss-0.2927, acc-0.9198\n",
      "Iter-49850, train loss-0.2007, acc-0.9600, valid loss-0.2827, acc-0.9234, test loss-0.2926, acc-0.9199\n",
      "Iter-49860, train loss-0.3810, acc-0.9000, valid loss-0.2827, acc-0.9232, test loss-0.2926, acc-0.9197\n",
      "Iter-49870, train loss-0.1360, acc-0.9800, valid loss-0.2826, acc-0.9234, test loss-0.2926, acc-0.9199\n",
      "Iter-49880, train loss-0.3524, acc-0.9200, valid loss-0.2825, acc-0.9232, test loss-0.2926, acc-0.9199\n",
      "Iter-49890, train loss-0.2648, acc-0.9400, valid loss-0.2825, acc-0.9234, test loss-0.2925, acc-0.9200\n",
      "Iter-49900, train loss-0.1864, acc-0.9400, valid loss-0.2825, acc-0.9234, test loss-0.2925, acc-0.9201\n",
      "Iter-49910, train loss-0.3090, acc-0.9000, valid loss-0.2825, acc-0.9234, test loss-0.2924, acc-0.9200\n",
      "Iter-49920, train loss-0.2638, acc-0.9600, valid loss-0.2824, acc-0.9232, test loss-0.2925, acc-0.9198\n",
      "Iter-49930, train loss-0.2702, acc-0.9200, valid loss-0.2824, acc-0.9232, test loss-0.2925, acc-0.9198\n",
      "Iter-49940, train loss-0.2180, acc-0.9400, valid loss-0.2824, acc-0.9230, test loss-0.2925, acc-0.9198\n",
      "Iter-49950, train loss-0.3843, acc-0.9200, valid loss-0.2823, acc-0.9234, test loss-0.2925, acc-0.9199\n",
      "Iter-49960, train loss-0.2051, acc-0.9400, valid loss-0.2824, acc-0.9234, test loss-0.2925, acc-0.9199\n",
      "Iter-49970, train loss-0.1125, acc-1.0000, valid loss-0.2824, acc-0.9238, test loss-0.2925, acc-0.9199\n",
      "Iter-49980, train loss-0.6445, acc-0.8000, valid loss-0.2823, acc-0.9238, test loss-0.2925, acc-0.9198\n",
      "Iter-49990, train loss-0.3151, acc-0.9200, valid loss-0.2823, acc-0.9236, test loss-0.2924, acc-0.9196\n",
      "Iter-50000, train loss-0.3156, acc-0.9200, valid loss-0.2823, acc-0.9236, test loss-0.2924, acc-0.9197\n",
      "Iter-50010, train loss-0.2776, acc-0.9200, valid loss-0.2823, acc-0.9234, test loss-0.2924, acc-0.9198\n",
      "Iter-50020, train loss-0.3564, acc-0.9000, valid loss-0.2823, acc-0.9236, test loss-0.2924, acc-0.9196\n",
      "Iter-50030, train loss-0.3215, acc-0.9000, valid loss-0.2823, acc-0.9236, test loss-0.2924, acc-0.9199\n",
      "Iter-50040, train loss-0.1976, acc-0.9400, valid loss-0.2823, acc-0.9236, test loss-0.2924, acc-0.9203\n",
      "Iter-50050, train loss-0.1636, acc-0.9600, valid loss-0.2823, acc-0.9234, test loss-0.2923, acc-0.9200\n",
      "Iter-50060, train loss-0.2457, acc-0.9400, valid loss-0.2822, acc-0.9236, test loss-0.2924, acc-0.9201\n",
      "Iter-50070, train loss-0.2274, acc-0.9600, valid loss-0.2822, acc-0.9238, test loss-0.2923, acc-0.9201\n",
      "Iter-50080, train loss-0.2241, acc-0.9800, valid loss-0.2821, acc-0.9238, test loss-0.2923, acc-0.9197\n",
      "Iter-50090, train loss-0.2784, acc-0.9200, valid loss-0.2821, acc-0.9236, test loss-0.2923, acc-0.9197\n",
      "Iter-50100, train loss-0.2485, acc-0.9000, valid loss-0.2821, acc-0.9236, test loss-0.2923, acc-0.9199\n",
      "Iter-50110, train loss-0.1230, acc-0.9800, valid loss-0.2821, acc-0.9234, test loss-0.2923, acc-0.9200\n",
      "Iter-50120, train loss-0.2306, acc-0.9200, valid loss-0.2821, acc-0.9236, test loss-0.2923, acc-0.9201\n",
      "Iter-50130, train loss-0.2299, acc-0.9400, valid loss-0.2820, acc-0.9236, test loss-0.2923, acc-0.9199\n",
      "Iter-50140, train loss-0.2506, acc-0.9600, valid loss-0.2820, acc-0.9236, test loss-0.2922, acc-0.9199\n",
      "Iter-50150, train loss-0.1916, acc-0.9400, valid loss-0.2820, acc-0.9236, test loss-0.2923, acc-0.9197\n",
      "Iter-50160, train loss-0.1504, acc-0.9600, valid loss-0.2819, acc-0.9234, test loss-0.2922, acc-0.9199\n",
      "Iter-50170, train loss-0.2900, acc-0.8800, valid loss-0.2819, acc-0.9232, test loss-0.2921, acc-0.9198\n",
      "Iter-50180, train loss-0.2209, acc-0.9400, valid loss-0.2818, acc-0.9234, test loss-0.2921, acc-0.9201\n",
      "Iter-50190, train loss-0.2425, acc-0.9400, valid loss-0.2818, acc-0.9232, test loss-0.2921, acc-0.9199\n",
      "Iter-50200, train loss-0.3711, acc-0.8800, valid loss-0.2818, acc-0.9232, test loss-0.2921, acc-0.9199\n",
      "Iter-50210, train loss-0.1818, acc-0.9600, valid loss-0.2818, acc-0.9236, test loss-0.2920, acc-0.9196\n",
      "Iter-50220, train loss-0.4694, acc-0.8800, valid loss-0.2818, acc-0.9230, test loss-0.2920, acc-0.9198\n",
      "Iter-50230, train loss-0.3175, acc-0.9000, valid loss-0.2818, acc-0.9232, test loss-0.2920, acc-0.9199\n",
      "Iter-50240, train loss-0.2198, acc-0.9600, valid loss-0.2817, acc-0.9232, test loss-0.2919, acc-0.9199\n",
      "Iter-50250, train loss-0.2466, acc-0.9400, valid loss-0.2817, acc-0.9228, test loss-0.2918, acc-0.9199\n",
      "Iter-50260, train loss-0.4533, acc-0.9000, valid loss-0.2816, acc-0.9228, test loss-0.2918, acc-0.9199\n",
      "Iter-50270, train loss-0.5154, acc-0.8400, valid loss-0.2816, acc-0.9228, test loss-0.2918, acc-0.9200\n",
      "Iter-50280, train loss-0.4409, acc-0.8000, valid loss-0.2815, acc-0.9228, test loss-0.2918, acc-0.9199\n",
      "Iter-50290, train loss-0.3556, acc-0.8400, valid loss-0.2816, acc-0.9230, test loss-0.2918, acc-0.9199\n",
      "Iter-50300, train loss-0.3899, acc-0.9200, valid loss-0.2815, acc-0.9230, test loss-0.2918, acc-0.9198\n",
      "Iter-50310, train loss-0.3713, acc-0.8800, valid loss-0.2815, acc-0.9230, test loss-0.2917, acc-0.9199\n",
      "Iter-50320, train loss-0.3167, acc-0.8800, valid loss-0.2815, acc-0.9234, test loss-0.2917, acc-0.9198\n",
      "Iter-50330, train loss-0.3082, acc-0.9200, valid loss-0.2814, acc-0.9232, test loss-0.2917, acc-0.9199\n",
      "Iter-50340, train loss-0.2111, acc-0.9600, valid loss-0.2813, acc-0.9234, test loss-0.2917, acc-0.9197\n",
      "Iter-50350, train loss-0.4405, acc-0.8600, valid loss-0.2813, acc-0.9234, test loss-0.2916, acc-0.9193\n",
      "Iter-50360, train loss-0.4895, acc-0.8600, valid loss-0.2812, acc-0.9236, test loss-0.2916, acc-0.9194\n",
      "Iter-50370, train loss-0.3499, acc-0.9200, valid loss-0.2813, acc-0.9236, test loss-0.2916, acc-0.9197\n",
      "Iter-50380, train loss-0.3469, acc-0.9200, valid loss-0.2812, acc-0.9238, test loss-0.2916, acc-0.9197\n",
      "Iter-50390, train loss-0.1340, acc-0.9600, valid loss-0.2812, acc-0.9234, test loss-0.2915, acc-0.9197\n",
      "Iter-50400, train loss-0.3514, acc-0.9400, valid loss-0.2811, acc-0.9236, test loss-0.2915, acc-0.9196\n",
      "Iter-50410, train loss-0.2815, acc-0.9400, valid loss-0.2811, acc-0.9238, test loss-0.2915, acc-0.9197\n",
      "Iter-50420, train loss-0.3637, acc-0.8800, valid loss-0.2811, acc-0.9238, test loss-0.2915, acc-0.9196\n",
      "Iter-50430, train loss-0.2247, acc-0.9600, valid loss-0.2810, acc-0.9242, test loss-0.2914, acc-0.9196\n",
      "Iter-50440, train loss-0.2006, acc-0.9400, valid loss-0.2809, acc-0.9240, test loss-0.2914, acc-0.9196\n",
      "Iter-50450, train loss-0.2421, acc-0.8800, valid loss-0.2809, acc-0.9240, test loss-0.2913, acc-0.9196\n",
      "Iter-50460, train loss-0.2871, acc-0.9000, valid loss-0.2809, acc-0.9236, test loss-0.2913, acc-0.9194\n",
      "Iter-50470, train loss-0.6236, acc-0.8200, valid loss-0.2809, acc-0.9236, test loss-0.2913, acc-0.9194\n",
      "Iter-50480, train loss-0.2363, acc-0.9400, valid loss-0.2809, acc-0.9236, test loss-0.2912, acc-0.9195\n",
      "Iter-50490, train loss-0.3197, acc-0.9000, valid loss-0.2809, acc-0.9234, test loss-0.2913, acc-0.9194\n",
      "Iter-50500, train loss-0.2782, acc-0.9200, valid loss-0.2809, acc-0.9236, test loss-0.2913, acc-0.9197\n",
      "Iter-50510, train loss-0.3341, acc-0.9000, valid loss-0.2809, acc-0.9236, test loss-0.2913, acc-0.9197\n",
      "Iter-50520, train loss-0.3584, acc-0.9400, valid loss-0.2809, acc-0.9234, test loss-0.2914, acc-0.9198\n",
      "Iter-50530, train loss-0.4122, acc-0.8800, valid loss-0.2809, acc-0.9234, test loss-0.2914, acc-0.9197\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-50540, train loss-0.6840, acc-0.8400, valid loss-0.2808, acc-0.9234, test loss-0.2914, acc-0.9197\n",
      "Iter-50550, train loss-0.4437, acc-0.8400, valid loss-0.2808, acc-0.9234, test loss-0.2914, acc-0.9197\n",
      "Iter-50560, train loss-0.2100, acc-0.9600, valid loss-0.2808, acc-0.9232, test loss-0.2913, acc-0.9198\n",
      "Iter-50570, train loss-0.3730, acc-0.8400, valid loss-0.2808, acc-0.9234, test loss-0.2913, acc-0.9196\n",
      "Iter-50580, train loss-0.1642, acc-0.9800, valid loss-0.2807, acc-0.9228, test loss-0.2913, acc-0.9195\n",
      "Iter-50590, train loss-0.2284, acc-0.9200, valid loss-0.2807, acc-0.9228, test loss-0.2913, acc-0.9197\n",
      "Iter-50600, train loss-0.2437, acc-0.9600, valid loss-0.2807, acc-0.9230, test loss-0.2913, acc-0.9195\n",
      "Iter-50610, train loss-0.2511, acc-0.9200, valid loss-0.2807, acc-0.9228, test loss-0.2912, acc-0.9198\n",
      "Iter-50620, train loss-0.1834, acc-0.9600, valid loss-0.2807, acc-0.9228, test loss-0.2913, acc-0.9197\n",
      "Iter-50630, train loss-0.3981, acc-0.8800, valid loss-0.2807, acc-0.9230, test loss-0.2912, acc-0.9195\n",
      "Iter-50640, train loss-0.3290, acc-0.9000, valid loss-0.2807, acc-0.9234, test loss-0.2912, acc-0.9196\n",
      "Iter-50650, train loss-0.1707, acc-0.9600, valid loss-0.2806, acc-0.9234, test loss-0.2912, acc-0.9193\n",
      "Iter-50660, train loss-0.1930, acc-0.9400, valid loss-0.2806, acc-0.9234, test loss-0.2912, acc-0.9196\n",
      "Iter-50670, train loss-0.3125, acc-0.8800, valid loss-0.2806, acc-0.9236, test loss-0.2912, acc-0.9195\n",
      "Iter-50680, train loss-0.2960, acc-0.9400, valid loss-0.2805, acc-0.9234, test loss-0.2911, acc-0.9193\n",
      "Iter-50690, train loss-0.2272, acc-0.9600, valid loss-0.2805, acc-0.9236, test loss-0.2910, acc-0.9193\n",
      "Iter-50700, train loss-0.3158, acc-0.9200, valid loss-0.2805, acc-0.9236, test loss-0.2910, acc-0.9194\n",
      "Iter-50710, train loss-0.2653, acc-0.9000, valid loss-0.2805, acc-0.9238, test loss-0.2910, acc-0.9192\n",
      "Iter-50720, train loss-0.2428, acc-0.9400, valid loss-0.2804, acc-0.9234, test loss-0.2910, acc-0.9194\n",
      "Iter-50730, train loss-0.3933, acc-0.8800, valid loss-0.2804, acc-0.9228, test loss-0.2910, acc-0.9192\n",
      "Iter-50740, train loss-0.2502, acc-0.9400, valid loss-0.2803, acc-0.9228, test loss-0.2910, acc-0.9195\n",
      "Iter-50750, train loss-0.2004, acc-0.9600, valid loss-0.2802, acc-0.9230, test loss-0.2910, acc-0.9192\n",
      "Iter-50760, train loss-0.3821, acc-0.9200, valid loss-0.2803, acc-0.9230, test loss-0.2909, acc-0.9193\n",
      "Iter-50770, train loss-0.4816, acc-0.8800, valid loss-0.2802, acc-0.9230, test loss-0.2909, acc-0.9193\n",
      "Iter-50780, train loss-0.3109, acc-0.9200, valid loss-0.2803, acc-0.9230, test loss-0.2909, acc-0.9191\n",
      "Iter-50790, train loss-0.2743, acc-0.9000, valid loss-0.2803, acc-0.9230, test loss-0.2909, acc-0.9193\n",
      "Iter-50800, train loss-0.2629, acc-0.8800, valid loss-0.2802, acc-0.9232, test loss-0.2909, acc-0.9194\n",
      "Iter-50810, train loss-0.3388, acc-0.8800, valid loss-0.2802, acc-0.9234, test loss-0.2909, acc-0.9194\n",
      "Iter-50820, train loss-0.3279, acc-0.9000, valid loss-0.2802, acc-0.9232, test loss-0.2909, acc-0.9194\n",
      "Iter-50830, train loss-0.1392, acc-0.9800, valid loss-0.2801, acc-0.9230, test loss-0.2908, acc-0.9196\n",
      "Iter-50840, train loss-0.3841, acc-0.8600, valid loss-0.2802, acc-0.9230, test loss-0.2908, acc-0.9199\n",
      "Iter-50850, train loss-0.2655, acc-0.9200, valid loss-0.2801, acc-0.9230, test loss-0.2908, acc-0.9201\n",
      "Iter-50860, train loss-0.1641, acc-0.9600, valid loss-0.2800, acc-0.9230, test loss-0.2908, acc-0.9201\n",
      "Iter-50870, train loss-0.2920, acc-0.9200, valid loss-0.2800, acc-0.9232, test loss-0.2908, acc-0.9197\n",
      "Iter-50880, train loss-0.2025, acc-0.9800, valid loss-0.2800, acc-0.9234, test loss-0.2907, acc-0.9201\n",
      "Iter-50890, train loss-0.3326, acc-0.9200, valid loss-0.2800, acc-0.9234, test loss-0.2907, acc-0.9198\n",
      "Iter-50900, train loss-0.3040, acc-0.9000, valid loss-0.2800, acc-0.9234, test loss-0.2906, acc-0.9199\n",
      "Iter-50910, train loss-0.3723, acc-0.9000, valid loss-0.2799, acc-0.9232, test loss-0.2906, acc-0.9198\n",
      "Iter-50920, train loss-0.3239, acc-0.9200, valid loss-0.2799, acc-0.9234, test loss-0.2906, acc-0.9199\n",
      "Iter-50930, train loss-0.2427, acc-0.9200, valid loss-0.2799, acc-0.9238, test loss-0.2905, acc-0.9198\n",
      "Iter-50940, train loss-0.3238, acc-0.9200, valid loss-0.2798, acc-0.9238, test loss-0.2905, acc-0.9200\n",
      "Iter-50950, train loss-0.4374, acc-0.8200, valid loss-0.2799, acc-0.9236, test loss-0.2904, acc-0.9198\n",
      "Iter-50960, train loss-0.1542, acc-0.9600, valid loss-0.2799, acc-0.9234, test loss-0.2904, acc-0.9200\n",
      "Iter-50970, train loss-0.2381, acc-0.9000, valid loss-0.2798, acc-0.9238, test loss-0.2904, acc-0.9201\n",
      "Iter-50980, train loss-0.1055, acc-0.9800, valid loss-0.2797, acc-0.9236, test loss-0.2904, acc-0.9200\n",
      "Iter-50990, train loss-0.3590, acc-0.9000, valid loss-0.2796, acc-0.9240, test loss-0.2904, acc-0.9201\n",
      "Iter-51000, train loss-0.2912, acc-0.9000, valid loss-0.2796, acc-0.9240, test loss-0.2904, acc-0.9202\n",
      "Iter-51010, train loss-0.2257, acc-0.9600, valid loss-0.2796, acc-0.9240, test loss-0.2903, acc-0.9201\n",
      "Iter-51020, train loss-0.2588, acc-0.9000, valid loss-0.2796, acc-0.9236, test loss-0.2903, acc-0.9201\n",
      "Iter-51030, train loss-0.1838, acc-0.9600, valid loss-0.2795, acc-0.9232, test loss-0.2903, acc-0.9202\n",
      "Iter-51040, train loss-0.2069, acc-0.9400, valid loss-0.2795, acc-0.9236, test loss-0.2903, acc-0.9200\n",
      "Iter-51050, train loss-0.3814, acc-0.8600, valid loss-0.2795, acc-0.9238, test loss-0.2902, acc-0.9201\n",
      "Iter-51060, train loss-0.2104, acc-0.9400, valid loss-0.2795, acc-0.9236, test loss-0.2902, acc-0.9200\n",
      "Iter-51070, train loss-0.4799, acc-0.8600, valid loss-0.2795, acc-0.9236, test loss-0.2902, acc-0.9202\n",
      "Iter-51080, train loss-0.3063, acc-0.8800, valid loss-0.2795, acc-0.9238, test loss-0.2901, acc-0.9204\n",
      "Iter-51090, train loss-0.3021, acc-0.8800, valid loss-0.2795, acc-0.9234, test loss-0.2901, acc-0.9203\n",
      "Iter-51100, train loss-0.2130, acc-0.9400, valid loss-0.2794, acc-0.9234, test loss-0.2900, acc-0.9201\n",
      "Iter-51110, train loss-0.4675, acc-0.9000, valid loss-0.2795, acc-0.9234, test loss-0.2900, acc-0.9202\n",
      "Iter-51120, train loss-0.2306, acc-0.9400, valid loss-0.2795, acc-0.9234, test loss-0.2900, acc-0.9205\n",
      "Iter-51130, train loss-0.4604, acc-0.8600, valid loss-0.2794, acc-0.9234, test loss-0.2900, acc-0.9202\n",
      "Iter-51140, train loss-0.1275, acc-0.9600, valid loss-0.2794, acc-0.9232, test loss-0.2900, acc-0.9201\n",
      "Iter-51150, train loss-0.3117, acc-0.9000, valid loss-0.2793, acc-0.9234, test loss-0.2900, acc-0.9200\n",
      "Iter-51160, train loss-0.3564, acc-0.8600, valid loss-0.2793, acc-0.9236, test loss-0.2900, acc-0.9203\n",
      "Iter-51170, train loss-0.4188, acc-0.8200, valid loss-0.2793, acc-0.9236, test loss-0.2899, acc-0.9202\n",
      "Iter-51180, train loss-0.2198, acc-0.9200, valid loss-0.2793, acc-0.9236, test loss-0.2899, acc-0.9202\n",
      "Iter-51190, train loss-0.4793, acc-0.8800, valid loss-0.2793, acc-0.9236, test loss-0.2900, acc-0.9205\n",
      "Iter-51200, train loss-0.1589, acc-0.9800, valid loss-0.2793, acc-0.9240, test loss-0.2900, acc-0.9204\n",
      "Iter-51210, train loss-0.3001, acc-0.8800, valid loss-0.2792, acc-0.9236, test loss-0.2899, acc-0.9203\n",
      "Iter-51220, train loss-0.4319, acc-0.8600, valid loss-0.2793, acc-0.9234, test loss-0.2899, acc-0.9200\n",
      "Iter-51230, train loss-0.5912, acc-0.8200, valid loss-0.2792, acc-0.9236, test loss-0.2899, acc-0.9202\n",
      "Iter-51240, train loss-0.2814, acc-0.9400, valid loss-0.2792, acc-0.9234, test loss-0.2899, acc-0.9204\n",
      "Iter-51250, train loss-0.4697, acc-0.8800, valid loss-0.2792, acc-0.9238, test loss-0.2899, acc-0.9204\n",
      "Iter-51260, train loss-0.4262, acc-0.8800, valid loss-0.2792, acc-0.9238, test loss-0.2899, acc-0.9204\n",
      "Iter-51270, train loss-0.3457, acc-0.9200, valid loss-0.2793, acc-0.9234, test loss-0.2898, acc-0.9205\n",
      "Iter-51280, train loss-0.2486, acc-0.9400, valid loss-0.2792, acc-0.9236, test loss-0.2898, acc-0.9206\n",
      "Iter-51290, train loss-0.2717, acc-0.9200, valid loss-0.2793, acc-0.9238, test loss-0.2898, acc-0.9206\n",
      "Iter-51300, train loss-0.2798, acc-0.9000, valid loss-0.2792, acc-0.9234, test loss-0.2897, acc-0.9203\n",
      "Iter-51310, train loss-0.2623, acc-0.9400, valid loss-0.2792, acc-0.9234, test loss-0.2897, acc-0.9205\n",
      "Iter-51320, train loss-0.1797, acc-0.9800, valid loss-0.2792, acc-0.9232, test loss-0.2897, acc-0.9209\n",
      "Iter-51330, train loss-0.2208, acc-0.9400, valid loss-0.2791, acc-0.9234, test loss-0.2897, acc-0.9206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-51340, train loss-0.2205, acc-0.9400, valid loss-0.2791, acc-0.9232, test loss-0.2897, acc-0.9207\n",
      "Iter-51350, train loss-0.3368, acc-0.9200, valid loss-0.2791, acc-0.9236, test loss-0.2897, acc-0.9206\n",
      "Iter-51360, train loss-0.1762, acc-0.9600, valid loss-0.2792, acc-0.9236, test loss-0.2897, acc-0.9205\n",
      "Iter-51370, train loss-0.2748, acc-0.9000, valid loss-0.2792, acc-0.9236, test loss-0.2897, acc-0.9206\n",
      "Iter-51380, train loss-0.3765, acc-0.8800, valid loss-0.2791, acc-0.9236, test loss-0.2897, acc-0.9203\n",
      "Iter-51390, train loss-0.5546, acc-0.8200, valid loss-0.2791, acc-0.9234, test loss-0.2897, acc-0.9205\n",
      "Iter-51400, train loss-0.2418, acc-0.9000, valid loss-0.2791, acc-0.9234, test loss-0.2896, acc-0.9205\n",
      "Iter-51410, train loss-0.3123, acc-0.9000, valid loss-0.2790, acc-0.9234, test loss-0.2896, acc-0.9206\n",
      "Iter-51420, train loss-0.1995, acc-0.9600, valid loss-0.2790, acc-0.9232, test loss-0.2896, acc-0.9206\n",
      "Iter-51430, train loss-0.2169, acc-0.9400, valid loss-0.2790, acc-0.9228, test loss-0.2896, acc-0.9205\n",
      "Iter-51440, train loss-0.4020, acc-0.9000, valid loss-0.2789, acc-0.9230, test loss-0.2896, acc-0.9204\n",
      "Iter-51450, train loss-0.1479, acc-0.9800, valid loss-0.2789, acc-0.9232, test loss-0.2896, acc-0.9205\n",
      "Iter-51460, train loss-0.2233, acc-0.9200, valid loss-0.2788, acc-0.9230, test loss-0.2896, acc-0.9204\n",
      "Iter-51470, train loss-0.2545, acc-0.9200, valid loss-0.2788, acc-0.9230, test loss-0.2895, acc-0.9205\n",
      "Iter-51480, train loss-0.3360, acc-0.9200, valid loss-0.2788, acc-0.9232, test loss-0.2894, acc-0.9204\n",
      "Iter-51490, train loss-0.2830, acc-0.9000, valid loss-0.2788, acc-0.9230, test loss-0.2895, acc-0.9205\n",
      "Iter-51500, train loss-0.4278, acc-0.8600, valid loss-0.2788, acc-0.9230, test loss-0.2894, acc-0.9204\n",
      "Iter-51510, train loss-0.2453, acc-0.9600, valid loss-0.2788, acc-0.9232, test loss-0.2894, acc-0.9204\n",
      "Iter-51520, train loss-0.2643, acc-0.9200, valid loss-0.2787, acc-0.9234, test loss-0.2893, acc-0.9204\n",
      "Iter-51530, train loss-0.4285, acc-0.8800, valid loss-0.2786, acc-0.9232, test loss-0.2893, acc-0.9206\n",
      "Iter-51540, train loss-0.4101, acc-0.8800, valid loss-0.2786, acc-0.9232, test loss-0.2893, acc-0.9207\n",
      "Iter-51550, train loss-0.2764, acc-0.9200, valid loss-0.2786, acc-0.9232, test loss-0.2892, acc-0.9206\n",
      "Iter-51560, train loss-0.2493, acc-0.9400, valid loss-0.2786, acc-0.9232, test loss-0.2893, acc-0.9206\n",
      "Iter-51570, train loss-0.3017, acc-0.9000, valid loss-0.2786, acc-0.9232, test loss-0.2893, acc-0.9206\n",
      "Iter-51580, train loss-0.2031, acc-0.9200, valid loss-0.2786, acc-0.9234, test loss-0.2892, acc-0.9207\n",
      "Iter-51590, train loss-0.2813, acc-0.9400, valid loss-0.2786, acc-0.9232, test loss-0.2892, acc-0.9207\n",
      "Iter-51600, train loss-0.2112, acc-0.9600, valid loss-0.2786, acc-0.9230, test loss-0.2892, acc-0.9203\n",
      "Iter-51610, train loss-0.2290, acc-0.9000, valid loss-0.2785, acc-0.9234, test loss-0.2892, acc-0.9204\n",
      "Iter-51620, train loss-0.2077, acc-0.9400, valid loss-0.2785, acc-0.9234, test loss-0.2892, acc-0.9205\n",
      "Iter-51630, train loss-0.4188, acc-0.9200, valid loss-0.2786, acc-0.9238, test loss-0.2891, acc-0.9210\n",
      "Iter-51640, train loss-0.2654, acc-0.9200, valid loss-0.2785, acc-0.9236, test loss-0.2891, acc-0.9208\n",
      "Iter-51650, train loss-0.1626, acc-0.9600, valid loss-0.2785, acc-0.9236, test loss-0.2891, acc-0.9209\n",
      "Iter-51660, train loss-0.2128, acc-0.9800, valid loss-0.2784, acc-0.9234, test loss-0.2890, acc-0.9207\n",
      "Iter-51670, train loss-0.2013, acc-0.9400, valid loss-0.2784, acc-0.9234, test loss-0.2890, acc-0.9207\n",
      "Iter-51680, train loss-0.1993, acc-0.9400, valid loss-0.2784, acc-0.9234, test loss-0.2890, acc-0.9209\n",
      "Iter-51690, train loss-0.2025, acc-0.9600, valid loss-0.2784, acc-0.9234, test loss-0.2890, acc-0.9209\n",
      "Iter-51700, train loss-0.1973, acc-0.9600, valid loss-0.2784, acc-0.9232, test loss-0.2890, acc-0.9207\n",
      "Iter-51710, train loss-0.4510, acc-0.8600, valid loss-0.2784, acc-0.9236, test loss-0.2890, acc-0.9207\n",
      "Iter-51720, train loss-0.4926, acc-0.8800, valid loss-0.2784, acc-0.9232, test loss-0.2890, acc-0.9208\n",
      "Iter-51730, train loss-0.3081, acc-0.9000, valid loss-0.2784, acc-0.9236, test loss-0.2890, acc-0.9210\n",
      "Iter-51740, train loss-0.3050, acc-0.9400, valid loss-0.2784, acc-0.9236, test loss-0.2889, acc-0.9210\n",
      "Iter-51750, train loss-0.3145, acc-0.8800, valid loss-0.2783, acc-0.9234, test loss-0.2889, acc-0.9210\n",
      "Iter-51760, train loss-0.2833, acc-0.9400, valid loss-0.2782, acc-0.9236, test loss-0.2889, acc-0.9208\n",
      "Iter-51770, train loss-0.4706, acc-0.8600, valid loss-0.2782, acc-0.9236, test loss-0.2888, acc-0.9207\n",
      "Iter-51780, train loss-0.1692, acc-0.9400, valid loss-0.2781, acc-0.9234, test loss-0.2888, acc-0.9206\n",
      "Iter-51790, train loss-0.4481, acc-0.9200, valid loss-0.2782, acc-0.9234, test loss-0.2888, acc-0.9207\n",
      "Iter-51800, train loss-0.2955, acc-0.9200, valid loss-0.2781, acc-0.9234, test loss-0.2888, acc-0.9206\n",
      "Iter-51810, train loss-0.5760, acc-0.8200, valid loss-0.2781, acc-0.9238, test loss-0.2888, acc-0.9208\n",
      "Iter-51820, train loss-0.2297, acc-0.9200, valid loss-0.2780, acc-0.9238, test loss-0.2888, acc-0.9209\n",
      "Iter-51830, train loss-0.3973, acc-0.9000, valid loss-0.2780, acc-0.9238, test loss-0.2888, acc-0.9210\n",
      "Iter-51840, train loss-0.4316, acc-0.9000, valid loss-0.2780, acc-0.9234, test loss-0.2888, acc-0.9209\n",
      "Iter-51850, train loss-0.1899, acc-0.9200, valid loss-0.2779, acc-0.9234, test loss-0.2887, acc-0.9210\n",
      "Iter-51860, train loss-0.2459, acc-0.9200, valid loss-0.2778, acc-0.9236, test loss-0.2887, acc-0.9208\n",
      "Iter-51870, train loss-0.2864, acc-0.9400, valid loss-0.2778, acc-0.9236, test loss-0.2887, acc-0.9208\n",
      "Iter-51880, train loss-0.2837, acc-0.9000, valid loss-0.2777, acc-0.9236, test loss-0.2887, acc-0.9206\n",
      "Iter-51890, train loss-0.1803, acc-0.9400, valid loss-0.2776, acc-0.9234, test loss-0.2887, acc-0.9208\n",
      "Iter-51900, train loss-0.3228, acc-0.9200, valid loss-0.2776, acc-0.9234, test loss-0.2887, acc-0.9212\n",
      "Iter-51910, train loss-0.2733, acc-0.9600, valid loss-0.2776, acc-0.9234, test loss-0.2887, acc-0.9209\n",
      "Iter-51920, train loss-0.2899, acc-0.8800, valid loss-0.2776, acc-0.9236, test loss-0.2886, acc-0.9208\n",
      "Iter-51930, train loss-0.3034, acc-0.9200, valid loss-0.2776, acc-0.9234, test loss-0.2886, acc-0.9209\n",
      "Iter-51940, train loss-0.3684, acc-0.9200, valid loss-0.2776, acc-0.9232, test loss-0.2885, acc-0.9206\n",
      "Iter-51950, train loss-0.3948, acc-0.8600, valid loss-0.2776, acc-0.9232, test loss-0.2885, acc-0.9206\n",
      "Iter-51960, train loss-0.1306, acc-1.0000, valid loss-0.2776, acc-0.9232, test loss-0.2884, acc-0.9207\n",
      "Iter-51970, train loss-0.1424, acc-0.9600, valid loss-0.2775, acc-0.9232, test loss-0.2883, acc-0.9207\n",
      "Iter-51980, train loss-0.2989, acc-0.8800, valid loss-0.2775, acc-0.9234, test loss-0.2883, acc-0.9208\n",
      "Iter-51990, train loss-0.1395, acc-0.9800, valid loss-0.2775, acc-0.9238, test loss-0.2883, acc-0.9208\n",
      "Iter-52000, train loss-0.2886, acc-0.9600, valid loss-0.2774, acc-0.9238, test loss-0.2883, acc-0.9211\n",
      "Iter-52010, train loss-0.2215, acc-0.9400, valid loss-0.2774, acc-0.9236, test loss-0.2882, acc-0.9214\n",
      "Iter-52020, train loss-0.2215, acc-0.9400, valid loss-0.2775, acc-0.9236, test loss-0.2881, acc-0.9212\n",
      "Iter-52030, train loss-0.2778, acc-0.9200, valid loss-0.2775, acc-0.9236, test loss-0.2881, acc-0.9211\n",
      "Iter-52040, train loss-0.4088, acc-0.8800, valid loss-0.2775, acc-0.9236, test loss-0.2881, acc-0.9211\n",
      "Iter-52050, train loss-0.2697, acc-0.8800, valid loss-0.2774, acc-0.9234, test loss-0.2880, acc-0.9213\n",
      "Iter-52060, train loss-0.1898, acc-0.9600, valid loss-0.2774, acc-0.9234, test loss-0.2881, acc-0.9214\n",
      "Iter-52070, train loss-0.1696, acc-0.9800, valid loss-0.2774, acc-0.9234, test loss-0.2880, acc-0.9213\n",
      "Iter-52080, train loss-0.1421, acc-0.9800, valid loss-0.2773, acc-0.9234, test loss-0.2880, acc-0.9214\n",
      "Iter-52090, train loss-0.2951, acc-0.9000, valid loss-0.2773, acc-0.9234, test loss-0.2880, acc-0.9210\n",
      "Iter-52100, train loss-0.2320, acc-0.9200, valid loss-0.2773, acc-0.9234, test loss-0.2880, acc-0.9209\n",
      "Iter-52110, train loss-0.4685, acc-0.8600, valid loss-0.2773, acc-0.9236, test loss-0.2880, acc-0.9208\n",
      "Iter-52120, train loss-0.3327, acc-0.8800, valid loss-0.2772, acc-0.9236, test loss-0.2880, acc-0.9208\n",
      "Iter-52130, train loss-0.2549, acc-0.9600, valid loss-0.2772, acc-0.9236, test loss-0.2879, acc-0.9209\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52140, train loss-0.4459, acc-0.8800, valid loss-0.2772, acc-0.9236, test loss-0.2879, acc-0.9211\n",
      "Iter-52150, train loss-0.2859, acc-0.9400, valid loss-0.2771, acc-0.9236, test loss-0.2879, acc-0.9208\n",
      "Iter-52160, train loss-0.2312, acc-0.9400, valid loss-0.2771, acc-0.9236, test loss-0.2879, acc-0.9210\n",
      "Iter-52170, train loss-0.3964, acc-0.8400, valid loss-0.2771, acc-0.9236, test loss-0.2879, acc-0.9210\n",
      "Iter-52180, train loss-0.4136, acc-0.9000, valid loss-0.2770, acc-0.9238, test loss-0.2879, acc-0.9209\n",
      "Iter-52190, train loss-0.2494, acc-0.9400, valid loss-0.2770, acc-0.9238, test loss-0.2878, acc-0.9211\n",
      "Iter-52200, train loss-0.1905, acc-0.9400, valid loss-0.2770, acc-0.9238, test loss-0.2878, acc-0.9213\n",
      "Iter-52210, train loss-0.2312, acc-0.9600, valid loss-0.2770, acc-0.9242, test loss-0.2878, acc-0.9213\n",
      "Iter-52220, train loss-0.2295, acc-0.9600, valid loss-0.2770, acc-0.9240, test loss-0.2877, acc-0.9212\n",
      "Iter-52230, train loss-0.1818, acc-0.9400, valid loss-0.2770, acc-0.9242, test loss-0.2877, acc-0.9212\n",
      "Iter-52240, train loss-0.4589, acc-0.8600, valid loss-0.2770, acc-0.9242, test loss-0.2877, acc-0.9212\n",
      "Iter-52250, train loss-0.3579, acc-0.9000, valid loss-0.2770, acc-0.9240, test loss-0.2876, acc-0.9212\n",
      "Iter-52260, train loss-0.1198, acc-0.9800, valid loss-0.2769, acc-0.9240, test loss-0.2876, acc-0.9211\n",
      "Iter-52270, train loss-0.2608, acc-0.9000, valid loss-0.2769, acc-0.9238, test loss-0.2875, acc-0.9210\n",
      "Iter-52280, train loss-0.2824, acc-0.9000, valid loss-0.2769, acc-0.9238, test loss-0.2875, acc-0.9209\n",
      "Iter-52290, train loss-0.4442, acc-0.8600, valid loss-0.2769, acc-0.9236, test loss-0.2875, acc-0.9209\n",
      "Iter-52300, train loss-0.4733, acc-0.8000, valid loss-0.2770, acc-0.9234, test loss-0.2875, acc-0.9210\n",
      "Iter-52310, train loss-0.3052, acc-0.9600, valid loss-0.2769, acc-0.9238, test loss-0.2875, acc-0.9209\n",
      "Iter-52320, train loss-0.3424, acc-0.9000, valid loss-0.2769, acc-0.9238, test loss-0.2875, acc-0.9210\n",
      "Iter-52330, train loss-0.1596, acc-0.9400, valid loss-0.2768, acc-0.9236, test loss-0.2874, acc-0.9211\n",
      "Iter-52340, train loss-0.4021, acc-0.9200, valid loss-0.2767, acc-0.9238, test loss-0.2873, acc-0.9211\n",
      "Iter-52350, train loss-0.1439, acc-1.0000, valid loss-0.2767, acc-0.9236, test loss-0.2873, acc-0.9209\n",
      "Iter-52360, train loss-0.3890, acc-0.9200, valid loss-0.2767, acc-0.9240, test loss-0.2873, acc-0.9210\n",
      "Iter-52370, train loss-0.1951, acc-0.9600, valid loss-0.2768, acc-0.9238, test loss-0.2872, acc-0.9211\n",
      "Iter-52380, train loss-0.3551, acc-0.8600, valid loss-0.2768, acc-0.9236, test loss-0.2872, acc-0.9211\n",
      "Iter-52390, train loss-0.2878, acc-0.9000, valid loss-0.2768, acc-0.9238, test loss-0.2872, acc-0.9210\n",
      "Iter-52400, train loss-0.4051, acc-0.8800, valid loss-0.2767, acc-0.9236, test loss-0.2872, acc-0.9210\n",
      "Iter-52410, train loss-0.5470, acc-0.8200, valid loss-0.2767, acc-0.9236, test loss-0.2872, acc-0.9209\n",
      "Iter-52420, train loss-0.2541, acc-0.9200, valid loss-0.2767, acc-0.9238, test loss-0.2872, acc-0.9208\n",
      "Iter-52430, train loss-0.2357, acc-0.9600, valid loss-0.2766, acc-0.9238, test loss-0.2872, acc-0.9208\n",
      "Iter-52440, train loss-0.1824, acc-0.9400, valid loss-0.2766, acc-0.9238, test loss-0.2872, acc-0.9208\n",
      "Iter-52450, train loss-0.1958, acc-0.9800, valid loss-0.2766, acc-0.9238, test loss-0.2872, acc-0.9208\n",
      "Iter-52460, train loss-0.1160, acc-0.9800, valid loss-0.2765, acc-0.9238, test loss-0.2872, acc-0.9212\n",
      "Iter-52470, train loss-0.1358, acc-0.9800, valid loss-0.2765, acc-0.9236, test loss-0.2872, acc-0.9211\n",
      "Iter-52480, train loss-0.3348, acc-0.9400, valid loss-0.2765, acc-0.9236, test loss-0.2872, acc-0.9212\n",
      "Iter-52490, train loss-0.4440, acc-0.8200, valid loss-0.2765, acc-0.9234, test loss-0.2872, acc-0.9211\n",
      "Iter-52500, train loss-0.4440, acc-0.9000, valid loss-0.2765, acc-0.9234, test loss-0.2871, acc-0.9210\n",
      "Iter-52510, train loss-0.2624, acc-0.9400, valid loss-0.2764, acc-0.9232, test loss-0.2871, acc-0.9209\n",
      "Iter-52520, train loss-0.2804, acc-0.9200, valid loss-0.2764, acc-0.9232, test loss-0.2870, acc-0.9212\n",
      "Iter-52530, train loss-0.5338, acc-0.9200, valid loss-0.2764, acc-0.9232, test loss-0.2870, acc-0.9211\n",
      "Iter-52540, train loss-0.1675, acc-0.9600, valid loss-0.2763, acc-0.9234, test loss-0.2870, acc-0.9210\n",
      "Iter-52550, train loss-0.4850, acc-0.8600, valid loss-0.2763, acc-0.9234, test loss-0.2870, acc-0.9209\n",
      "Iter-52560, train loss-0.2547, acc-0.9400, valid loss-0.2762, acc-0.9234, test loss-0.2870, acc-0.9211\n",
      "Iter-52570, train loss-0.2747, acc-0.9400, valid loss-0.2762, acc-0.9232, test loss-0.2869, acc-0.9211\n",
      "Iter-52580, train loss-0.3722, acc-0.9000, valid loss-0.2761, acc-0.9232, test loss-0.2869, acc-0.9210\n",
      "Iter-52590, train loss-0.1828, acc-0.9800, valid loss-0.2761, acc-0.9238, test loss-0.2869, acc-0.9212\n",
      "Iter-52600, train loss-0.2706, acc-0.9000, valid loss-0.2761, acc-0.9234, test loss-0.2869, acc-0.9211\n",
      "Iter-52610, train loss-0.3895, acc-0.9000, valid loss-0.2761, acc-0.9234, test loss-0.2869, acc-0.9207\n",
      "Iter-52620, train loss-0.2650, acc-0.9000, valid loss-0.2760, acc-0.9234, test loss-0.2868, acc-0.9209\n",
      "Iter-52630, train loss-0.3093, acc-0.9200, valid loss-0.2761, acc-0.9234, test loss-0.2868, acc-0.9211\n",
      "Iter-52640, train loss-0.3334, acc-0.9400, valid loss-0.2761, acc-0.9230, test loss-0.2868, acc-0.9213\n",
      "Iter-52650, train loss-0.1869, acc-0.9600, valid loss-0.2760, acc-0.9232, test loss-0.2868, acc-0.9212\n",
      "Iter-52660, train loss-0.2789, acc-0.9000, valid loss-0.2761, acc-0.9234, test loss-0.2868, acc-0.9212\n",
      "Iter-52670, train loss-0.1711, acc-0.9600, valid loss-0.2761, acc-0.9234, test loss-0.2867, acc-0.9212\n",
      "Iter-52680, train loss-0.2302, acc-0.9400, valid loss-0.2761, acc-0.9234, test loss-0.2867, acc-0.9211\n",
      "Iter-52690, train loss-0.4640, acc-0.9400, valid loss-0.2761, acc-0.9232, test loss-0.2867, acc-0.9208\n",
      "Iter-52700, train loss-0.2329, acc-0.9600, valid loss-0.2760, acc-0.9234, test loss-0.2866, acc-0.9210\n",
      "Iter-52710, train loss-0.2878, acc-0.9400, valid loss-0.2760, acc-0.9236, test loss-0.2866, acc-0.9210\n",
      "Iter-52720, train loss-0.2458, acc-0.9400, valid loss-0.2760, acc-0.9236, test loss-0.2866, acc-0.9209\n",
      "Iter-52730, train loss-0.1763, acc-0.9600, valid loss-0.2759, acc-0.9236, test loss-0.2866, acc-0.9209\n",
      "Iter-52740, train loss-0.1599, acc-0.9600, valid loss-0.2759, acc-0.9236, test loss-0.2866, acc-0.9209\n",
      "Iter-52750, train loss-0.1382, acc-1.0000, valid loss-0.2759, acc-0.9236, test loss-0.2866, acc-0.9211\n",
      "Iter-52760, train loss-0.2154, acc-0.9200, valid loss-0.2758, acc-0.9236, test loss-0.2866, acc-0.9209\n",
      "Iter-52770, train loss-0.2352, acc-0.9000, valid loss-0.2758, acc-0.9236, test loss-0.2866, acc-0.9210\n",
      "Iter-52780, train loss-0.3254, acc-0.9600, valid loss-0.2758, acc-0.9238, test loss-0.2866, acc-0.9208\n",
      "Iter-52790, train loss-0.2869, acc-0.9600, valid loss-0.2757, acc-0.9240, test loss-0.2865, acc-0.9210\n",
      "Iter-52800, train loss-0.2793, acc-0.9200, valid loss-0.2757, acc-0.9242, test loss-0.2865, acc-0.9210\n",
      "Iter-52810, train loss-0.4024, acc-0.8600, valid loss-0.2758, acc-0.9242, test loss-0.2865, acc-0.9210\n",
      "Iter-52820, train loss-0.6311, acc-0.8400, valid loss-0.2758, acc-0.9240, test loss-0.2865, acc-0.9214\n",
      "Iter-52830, train loss-0.1793, acc-0.9400, valid loss-0.2758, acc-0.9240, test loss-0.2864, acc-0.9212\n",
      "Iter-52840, train loss-0.2777, acc-0.9200, valid loss-0.2757, acc-0.9240, test loss-0.2864, acc-0.9213\n",
      "Iter-52850, train loss-0.2167, acc-0.9600, valid loss-0.2757, acc-0.9242, test loss-0.2864, acc-0.9214\n",
      "Iter-52860, train loss-0.3568, acc-0.8600, valid loss-0.2757, acc-0.9240, test loss-0.2863, acc-0.9215\n",
      "Iter-52870, train loss-0.2337, acc-0.9400, valid loss-0.2757, acc-0.9242, test loss-0.2863, acc-0.9214\n",
      "Iter-52880, train loss-0.5187, acc-0.8800, valid loss-0.2756, acc-0.9242, test loss-0.2863, acc-0.9213\n",
      "Iter-52890, train loss-0.3768, acc-0.8600, valid loss-0.2756, acc-0.9242, test loss-0.2862, acc-0.9213\n",
      "Iter-52900, train loss-0.2486, acc-0.9200, valid loss-0.2756, acc-0.9240, test loss-0.2862, acc-0.9213\n",
      "Iter-52910, train loss-0.2748, acc-0.9400, valid loss-0.2756, acc-0.9240, test loss-0.2862, acc-0.9213\n",
      "Iter-52920, train loss-0.2370, acc-0.9400, valid loss-0.2756, acc-0.9240, test loss-0.2862, acc-0.9213\n",
      "Iter-52930, train loss-0.5294, acc-0.8000, valid loss-0.2756, acc-0.9236, test loss-0.2862, acc-0.9213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52940, train loss-0.2316, acc-0.9400, valid loss-0.2756, acc-0.9236, test loss-0.2862, acc-0.9213\n",
      "Iter-52950, train loss-0.6225, acc-0.8200, valid loss-0.2756, acc-0.9232, test loss-0.2862, acc-0.9215\n",
      "Iter-52960, train loss-0.5407, acc-0.8400, valid loss-0.2755, acc-0.9236, test loss-0.2861, acc-0.9214\n",
      "Iter-52970, train loss-0.2012, acc-0.9600, valid loss-0.2755, acc-0.9238, test loss-0.2861, acc-0.9214\n",
      "Iter-52980, train loss-0.2598, acc-0.9400, valid loss-0.2754, acc-0.9238, test loss-0.2861, acc-0.9216\n",
      "Iter-52990, train loss-0.3325, acc-0.8800, valid loss-0.2754, acc-0.9236, test loss-0.2861, acc-0.9217\n",
      "Iter-53000, train loss-0.1886, acc-0.9400, valid loss-0.2754, acc-0.9234, test loss-0.2861, acc-0.9217\n",
      "Iter-53010, train loss-0.2868, acc-0.9200, valid loss-0.2753, acc-0.9234, test loss-0.2861, acc-0.9219\n",
      "Iter-53020, train loss-0.2840, acc-0.9400, valid loss-0.2753, acc-0.9236, test loss-0.2860, acc-0.9217\n",
      "Iter-53030, train loss-0.2453, acc-0.9200, valid loss-0.2753, acc-0.9236, test loss-0.2860, acc-0.9218\n",
      "Iter-53040, train loss-0.1767, acc-0.9600, valid loss-0.2753, acc-0.9236, test loss-0.2860, acc-0.9218\n",
      "Iter-53050, train loss-0.1832, acc-0.9400, valid loss-0.2752, acc-0.9234, test loss-0.2860, acc-0.9217\n",
      "Iter-53060, train loss-0.3056, acc-0.9200, valid loss-0.2751, acc-0.9242, test loss-0.2860, acc-0.9214\n",
      "Iter-53070, train loss-0.1668, acc-0.9800, valid loss-0.2751, acc-0.9240, test loss-0.2860, acc-0.9217\n",
      "Iter-53080, train loss-0.2648, acc-0.9000, valid loss-0.2751, acc-0.9240, test loss-0.2860, acc-0.9216\n",
      "Iter-53090, train loss-0.4393, acc-0.8400, valid loss-0.2751, acc-0.9238, test loss-0.2859, acc-0.9215\n",
      "Iter-53100, train loss-0.2055, acc-0.9400, valid loss-0.2751, acc-0.9242, test loss-0.2859, acc-0.9214\n",
      "Iter-53110, train loss-0.2651, acc-0.9000, valid loss-0.2750, acc-0.9240, test loss-0.2859, acc-0.9214\n",
      "Iter-53120, train loss-0.3909, acc-0.9400, valid loss-0.2750, acc-0.9240, test loss-0.2859, acc-0.9216\n",
      "Iter-53130, train loss-0.2644, acc-0.9200, valid loss-0.2750, acc-0.9240, test loss-0.2858, acc-0.9217\n",
      "Iter-53140, train loss-0.4058, acc-0.8600, valid loss-0.2750, acc-0.9240, test loss-0.2858, acc-0.9217\n",
      "Iter-53150, train loss-0.1937, acc-0.9400, valid loss-0.2750, acc-0.9238, test loss-0.2858, acc-0.9217\n",
      "Iter-53160, train loss-0.5777, acc-0.8800, valid loss-0.2750, acc-0.9242, test loss-0.2857, acc-0.9215\n",
      "Iter-53170, train loss-0.2125, acc-0.9200, valid loss-0.2750, acc-0.9240, test loss-0.2857, acc-0.9215\n",
      "Iter-53180, train loss-0.1710, acc-0.9600, valid loss-0.2749, acc-0.9238, test loss-0.2857, acc-0.9215\n",
      "Iter-53190, train loss-0.1809, acc-0.9400, valid loss-0.2749, acc-0.9238, test loss-0.2856, acc-0.9215\n",
      "Iter-53200, train loss-0.4423, acc-0.9000, valid loss-0.2749, acc-0.9240, test loss-0.2856, acc-0.9215\n",
      "Iter-53210, train loss-0.1571, acc-0.9600, valid loss-0.2749, acc-0.9238, test loss-0.2856, acc-0.9213\n",
      "Iter-53220, train loss-0.2375, acc-0.9000, valid loss-0.2748, acc-0.9240, test loss-0.2855, acc-0.9216\n",
      "Iter-53230, train loss-0.1800, acc-0.9400, valid loss-0.2748, acc-0.9240, test loss-0.2855, acc-0.9215\n",
      "Iter-53240, train loss-0.3075, acc-0.9200, valid loss-0.2747, acc-0.9240, test loss-0.2855, acc-0.9213\n",
      "Iter-53250, train loss-0.2997, acc-0.9200, valid loss-0.2747, acc-0.9240, test loss-0.2855, acc-0.9213\n",
      "Iter-53260, train loss-0.3298, acc-0.9400, valid loss-0.2747, acc-0.9240, test loss-0.2855, acc-0.9215\n",
      "Iter-53270, train loss-0.3550, acc-0.9200, valid loss-0.2747, acc-0.9238, test loss-0.2855, acc-0.9211\n",
      "Iter-53280, train loss-0.3002, acc-0.9200, valid loss-0.2746, acc-0.9240, test loss-0.2855, acc-0.9212\n",
      "Iter-53290, train loss-0.2572, acc-0.9200, valid loss-0.2747, acc-0.9238, test loss-0.2855, acc-0.9214\n",
      "Iter-53300, train loss-0.1233, acc-0.9800, valid loss-0.2746, acc-0.9238, test loss-0.2854, acc-0.9212\n",
      "Iter-53310, train loss-0.1593, acc-0.9600, valid loss-0.2746, acc-0.9238, test loss-0.2854, acc-0.9214\n",
      "Iter-53320, train loss-0.2413, acc-0.9200, valid loss-0.2746, acc-0.9238, test loss-0.2854, acc-0.9213\n",
      "Iter-53330, train loss-0.2658, acc-0.9600, valid loss-0.2746, acc-0.9238, test loss-0.2853, acc-0.9214\n",
      "Iter-53340, train loss-0.2267, acc-0.9400, valid loss-0.2746, acc-0.9236, test loss-0.2853, acc-0.9214\n",
      "Iter-53350, train loss-0.2539, acc-0.9200, valid loss-0.2746, acc-0.9234, test loss-0.2852, acc-0.9214\n",
      "Iter-53360, train loss-0.4078, acc-0.9200, valid loss-0.2746, acc-0.9238, test loss-0.2853, acc-0.9213\n",
      "Iter-53370, train loss-0.3656, acc-0.9000, valid loss-0.2746, acc-0.9236, test loss-0.2853, acc-0.9213\n",
      "Iter-53380, train loss-0.4819, acc-0.8800, valid loss-0.2747, acc-0.9238, test loss-0.2853, acc-0.9213\n",
      "Iter-53390, train loss-0.2761, acc-0.9600, valid loss-0.2746, acc-0.9234, test loss-0.2853, acc-0.9211\n",
      "Iter-53400, train loss-0.2772, acc-0.9200, valid loss-0.2746, acc-0.9238, test loss-0.2853, acc-0.9211\n",
      "Iter-53410, train loss-0.5663, acc-0.8600, valid loss-0.2746, acc-0.9236, test loss-0.2853, acc-0.9210\n",
      "Iter-53420, train loss-0.3705, acc-0.8800, valid loss-0.2746, acc-0.9242, test loss-0.2852, acc-0.9209\n",
      "Iter-53430, train loss-0.2651, acc-0.9600, valid loss-0.2746, acc-0.9240, test loss-0.2852, acc-0.9210\n",
      "Iter-53440, train loss-0.2537, acc-0.9200, valid loss-0.2746, acc-0.9242, test loss-0.2852, acc-0.9210\n",
      "Iter-53450, train loss-0.2406, acc-0.9200, valid loss-0.2745, acc-0.9240, test loss-0.2851, acc-0.9211\n",
      "Iter-53460, train loss-0.3940, acc-0.9000, valid loss-0.2745, acc-0.9240, test loss-0.2851, acc-0.9211\n",
      "Iter-53470, train loss-0.1203, acc-0.9800, valid loss-0.2745, acc-0.9242, test loss-0.2851, acc-0.9211\n",
      "Iter-53480, train loss-0.1490, acc-0.9600, valid loss-0.2745, acc-0.9244, test loss-0.2851, acc-0.9208\n",
      "Iter-53490, train loss-0.3100, acc-0.9000, valid loss-0.2745, acc-0.9244, test loss-0.2851, acc-0.9207\n",
      "Iter-53500, train loss-0.3636, acc-0.8800, valid loss-0.2744, acc-0.9246, test loss-0.2851, acc-0.9206\n",
      "Iter-53510, train loss-0.1339, acc-0.9600, valid loss-0.2744, acc-0.9248, test loss-0.2851, acc-0.9208\n",
      "Iter-53520, train loss-0.3968, acc-0.9000, valid loss-0.2744, acc-0.9244, test loss-0.2851, acc-0.9209\n",
      "Iter-53530, train loss-0.3301, acc-0.9000, valid loss-0.2744, acc-0.9240, test loss-0.2850, acc-0.9208\n",
      "Iter-53540, train loss-0.1863, acc-0.9600, valid loss-0.2744, acc-0.9242, test loss-0.2850, acc-0.9209\n",
      "Iter-53550, train loss-0.2259, acc-0.9200, valid loss-0.2744, acc-0.9240, test loss-0.2850, acc-0.9209\n",
      "Iter-53560, train loss-0.3582, acc-0.8600, valid loss-0.2744, acc-0.9240, test loss-0.2849, acc-0.9207\n",
      "Iter-53570, train loss-0.4200, acc-0.8400, valid loss-0.2743, acc-0.9240, test loss-0.2849, acc-0.9208\n",
      "Iter-53580, train loss-0.2625, acc-0.9200, valid loss-0.2743, acc-0.9238, test loss-0.2849, acc-0.9207\n",
      "Iter-53590, train loss-0.2241, acc-0.9600, valid loss-0.2742, acc-0.9236, test loss-0.2848, acc-0.9206\n",
      "Iter-53600, train loss-0.1957, acc-0.9400, valid loss-0.2742, acc-0.9238, test loss-0.2849, acc-0.9208\n",
      "Iter-53610, train loss-0.3006, acc-0.8600, valid loss-0.2742, acc-0.9244, test loss-0.2849, acc-0.9208\n",
      "Iter-53620, train loss-0.2998, acc-0.9400, valid loss-0.2742, acc-0.9240, test loss-0.2849, acc-0.9211\n",
      "Iter-53630, train loss-0.2544, acc-0.9000, valid loss-0.2741, acc-0.9242, test loss-0.2848, acc-0.9212\n",
      "Iter-53640, train loss-0.2183, acc-0.9400, valid loss-0.2741, acc-0.9240, test loss-0.2848, acc-0.9212\n",
      "Iter-53650, train loss-0.3448, acc-0.8600, valid loss-0.2740, acc-0.9240, test loss-0.2848, acc-0.9212\n",
      "Iter-53660, train loss-0.3215, acc-0.9400, valid loss-0.2740, acc-0.9238, test loss-0.2848, acc-0.9213\n",
      "Iter-53670, train loss-0.2242, acc-0.9600, valid loss-0.2740, acc-0.9238, test loss-0.2847, acc-0.9214\n",
      "Iter-53680, train loss-0.2209, acc-0.9400, valid loss-0.2740, acc-0.9240, test loss-0.2847, acc-0.9214\n",
      "Iter-53690, train loss-0.2462, acc-0.9400, valid loss-0.2740, acc-0.9240, test loss-0.2847, acc-0.9213\n",
      "Iter-53700, train loss-0.1630, acc-0.9600, valid loss-0.2739, acc-0.9234, test loss-0.2846, acc-0.9214\n",
      "Iter-53710, train loss-0.3253, acc-0.9200, valid loss-0.2739, acc-0.9230, test loss-0.2846, acc-0.9214\n",
      "Iter-53720, train loss-0.5046, acc-0.8600, valid loss-0.2739, acc-0.9232, test loss-0.2846, acc-0.9216\n",
      "Iter-53730, train loss-0.2171, acc-0.9000, valid loss-0.2739, acc-0.9234, test loss-0.2846, acc-0.9215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-53740, train loss-0.2971, acc-0.9000, valid loss-0.2739, acc-0.9236, test loss-0.2846, acc-0.9217\n",
      "Iter-53750, train loss-0.1307, acc-1.0000, valid loss-0.2739, acc-0.9234, test loss-0.2846, acc-0.9215\n",
      "Iter-53760, train loss-0.4266, acc-0.8600, valid loss-0.2738, acc-0.9234, test loss-0.2845, acc-0.9216\n",
      "Iter-53770, train loss-0.3291, acc-0.9400, valid loss-0.2738, acc-0.9240, test loss-0.2846, acc-0.9214\n",
      "Iter-53780, train loss-0.2763, acc-0.9000, valid loss-0.2738, acc-0.9240, test loss-0.2846, acc-0.9214\n",
      "Iter-53790, train loss-0.1909, acc-0.9600, valid loss-0.2737, acc-0.9242, test loss-0.2845, acc-0.9216\n",
      "Iter-53800, train loss-0.2485, acc-0.9400, valid loss-0.2737, acc-0.9238, test loss-0.2845, acc-0.9210\n",
      "Iter-53810, train loss-0.3276, acc-0.8600, valid loss-0.2736, acc-0.9240, test loss-0.2846, acc-0.9213\n",
      "Iter-53820, train loss-0.2511, acc-0.9000, valid loss-0.2736, acc-0.9240, test loss-0.2845, acc-0.9214\n",
      "Iter-53830, train loss-0.1867, acc-0.9600, valid loss-0.2736, acc-0.9240, test loss-0.2845, acc-0.9214\n",
      "Iter-53840, train loss-0.1654, acc-1.0000, valid loss-0.2735, acc-0.9240, test loss-0.2845, acc-0.9215\n",
      "Iter-53850, train loss-0.2827, acc-0.9000, valid loss-0.2735, acc-0.9244, test loss-0.2845, acc-0.9216\n",
      "Iter-53860, train loss-0.1374, acc-0.9800, valid loss-0.2735, acc-0.9240, test loss-0.2845, acc-0.9215\n",
      "Iter-53870, train loss-0.1819, acc-0.9400, valid loss-0.2734, acc-0.9240, test loss-0.2845, acc-0.9214\n",
      "Iter-53880, train loss-0.2988, acc-0.8800, valid loss-0.2734, acc-0.9244, test loss-0.2845, acc-0.9213\n",
      "Iter-53890, train loss-0.2609, acc-0.9200, valid loss-0.2734, acc-0.9242, test loss-0.2844, acc-0.9213\n",
      "Iter-53900, train loss-0.3514, acc-0.9400, valid loss-0.2733, acc-0.9242, test loss-0.2844, acc-0.9212\n",
      "Iter-53910, train loss-0.2212, acc-0.9400, valid loss-0.2733, acc-0.9242, test loss-0.2843, acc-0.9216\n",
      "Iter-53920, train loss-0.1675, acc-0.9600, valid loss-0.2733, acc-0.9240, test loss-0.2843, acc-0.9219\n",
      "Iter-53930, train loss-0.1782, acc-0.9600, valid loss-0.2733, acc-0.9238, test loss-0.2843, acc-0.9217\n",
      "Iter-53940, train loss-0.2875, acc-0.9600, valid loss-0.2733, acc-0.9240, test loss-0.2842, acc-0.9219\n",
      "Iter-53950, train loss-0.2758, acc-0.9200, valid loss-0.2733, acc-0.9240, test loss-0.2842, acc-0.9218\n",
      "Iter-53960, train loss-0.2649, acc-0.9200, valid loss-0.2732, acc-0.9242, test loss-0.2842, acc-0.9216\n",
      "Iter-53970, train loss-0.2111, acc-0.9400, valid loss-0.2732, acc-0.9244, test loss-0.2841, acc-0.9214\n",
      "Iter-53980, train loss-0.1227, acc-0.9800, valid loss-0.2732, acc-0.9240, test loss-0.2841, acc-0.9214\n",
      "Iter-53990, train loss-0.3785, acc-0.8800, valid loss-0.2732, acc-0.9240, test loss-0.2841, acc-0.9213\n",
      "Iter-54000, train loss-0.1866, acc-0.9200, valid loss-0.2732, acc-0.9246, test loss-0.2840, acc-0.9214\n",
      "Iter-54010, train loss-0.1477, acc-0.9800, valid loss-0.2732, acc-0.9244, test loss-0.2840, acc-0.9213\n",
      "Iter-54020, train loss-0.4068, acc-0.8800, valid loss-0.2732, acc-0.9242, test loss-0.2840, acc-0.9215\n",
      "Iter-54030, train loss-0.3957, acc-0.9200, valid loss-0.2732, acc-0.9242, test loss-0.2840, acc-0.9218\n",
      "Iter-54040, train loss-0.3281, acc-0.9400, valid loss-0.2733, acc-0.9242, test loss-0.2839, acc-0.9215\n",
      "Iter-54050, train loss-0.4544, acc-0.9000, valid loss-0.2733, acc-0.9238, test loss-0.2839, acc-0.9215\n",
      "Iter-54060, train loss-0.2465, acc-0.9400, valid loss-0.2733, acc-0.9238, test loss-0.2839, acc-0.9213\n",
      "Iter-54070, train loss-0.3971, acc-0.8800, valid loss-0.2733, acc-0.9240, test loss-0.2838, acc-0.9213\n",
      "Iter-54080, train loss-0.1440, acc-0.9800, valid loss-0.2733, acc-0.9242, test loss-0.2837, acc-0.9213\n",
      "Iter-54090, train loss-0.3305, acc-0.9200, valid loss-0.2733, acc-0.9242, test loss-0.2837, acc-0.9213\n",
      "Iter-54100, train loss-0.2851, acc-0.9200, valid loss-0.2733, acc-0.9240, test loss-0.2837, acc-0.9215\n",
      "Iter-54110, train loss-0.3200, acc-0.9200, valid loss-0.2733, acc-0.9236, test loss-0.2836, acc-0.9216\n",
      "Iter-54120, train loss-0.2711, acc-0.9000, valid loss-0.2733, acc-0.9236, test loss-0.2836, acc-0.9214\n",
      "Iter-54130, train loss-0.3922, acc-0.8800, valid loss-0.2733, acc-0.9234, test loss-0.2836, acc-0.9216\n",
      "Iter-54140, train loss-0.2206, acc-0.9600, valid loss-0.2733, acc-0.9234, test loss-0.2836, acc-0.9217\n",
      "Iter-54150, train loss-0.2380, acc-0.9800, valid loss-0.2733, acc-0.9236, test loss-0.2836, acc-0.9218\n",
      "Iter-54160, train loss-0.2496, acc-0.9400, valid loss-0.2733, acc-0.9234, test loss-0.2836, acc-0.9217\n",
      "Iter-54170, train loss-0.3943, acc-0.8800, valid loss-0.2733, acc-0.9236, test loss-0.2836, acc-0.9219\n",
      "Iter-54180, train loss-0.3238, acc-0.9000, valid loss-0.2732, acc-0.9238, test loss-0.2835, acc-0.9218\n",
      "Iter-54190, train loss-0.1461, acc-0.9800, valid loss-0.2732, acc-0.9240, test loss-0.2835, acc-0.9219\n",
      "Iter-54200, train loss-0.2392, acc-0.9000, valid loss-0.2733, acc-0.9236, test loss-0.2835, acc-0.9219\n",
      "Iter-54210, train loss-0.2981, acc-0.8800, valid loss-0.2733, acc-0.9238, test loss-0.2835, acc-0.9221\n",
      "Iter-54220, train loss-0.3398, acc-0.9400, valid loss-0.2733, acc-0.9240, test loss-0.2835, acc-0.9217\n",
      "Iter-54230, train loss-0.3087, acc-0.9400, valid loss-0.2733, acc-0.9238, test loss-0.2835, acc-0.9217\n",
      "Iter-54240, train loss-0.3676, acc-0.9000, valid loss-0.2733, acc-0.9236, test loss-0.2835, acc-0.9219\n",
      "Iter-54250, train loss-0.1674, acc-0.9600, valid loss-0.2732, acc-0.9238, test loss-0.2834, acc-0.9218\n",
      "Iter-54260, train loss-0.4144, acc-0.8400, valid loss-0.2732, acc-0.9240, test loss-0.2835, acc-0.9216\n",
      "Iter-54270, train loss-0.2630, acc-0.9000, valid loss-0.2732, acc-0.9240, test loss-0.2835, acc-0.9216\n",
      "Iter-54280, train loss-0.2435, acc-0.9200, valid loss-0.2732, acc-0.9242, test loss-0.2835, acc-0.9214\n",
      "Iter-54290, train loss-0.3943, acc-0.8600, valid loss-0.2732, acc-0.9242, test loss-0.2835, acc-0.9213\n",
      "Iter-54300, train loss-0.2274, acc-0.9400, valid loss-0.2731, acc-0.9244, test loss-0.2835, acc-0.9211\n",
      "Iter-54310, train loss-0.2529, acc-0.9000, valid loss-0.2730, acc-0.9242, test loss-0.2835, acc-0.9212\n",
      "Iter-54320, train loss-0.4692, acc-0.8800, valid loss-0.2731, acc-0.9242, test loss-0.2835, acc-0.9213\n",
      "Iter-54330, train loss-0.3854, acc-0.9000, valid loss-0.2731, acc-0.9244, test loss-0.2834, acc-0.9211\n",
      "Iter-54340, train loss-0.1209, acc-0.9800, valid loss-0.2731, acc-0.9240, test loss-0.2834, acc-0.9215\n",
      "Iter-54350, train loss-0.1869, acc-0.9400, valid loss-0.2730, acc-0.9240, test loss-0.2833, acc-0.9219\n",
      "Iter-54360, train loss-0.2470, acc-0.9400, valid loss-0.2730, acc-0.9238, test loss-0.2832, acc-0.9219\n",
      "Iter-54370, train loss-0.3486, acc-0.9000, valid loss-0.2731, acc-0.9236, test loss-0.2832, acc-0.9219\n",
      "Iter-54380, train loss-0.1747, acc-0.9600, valid loss-0.2730, acc-0.9242, test loss-0.2832, acc-0.9219\n",
      "Iter-54390, train loss-0.1263, acc-0.9600, valid loss-0.2730, acc-0.9240, test loss-0.2832, acc-0.9219\n",
      "Iter-54400, train loss-0.1682, acc-0.9800, valid loss-0.2729, acc-0.9238, test loss-0.2832, acc-0.9217\n",
      "Iter-54410, train loss-0.3323, acc-0.8800, valid loss-0.2729, acc-0.9242, test loss-0.2831, acc-0.9216\n",
      "Iter-54420, train loss-0.2380, acc-0.9600, valid loss-0.2728, acc-0.9240, test loss-0.2832, acc-0.9218\n",
      "Iter-54430, train loss-0.2298, acc-0.9200, valid loss-0.2727, acc-0.9242, test loss-0.2831, acc-0.9220\n",
      "Iter-54440, train loss-0.1905, acc-0.9800, valid loss-0.2726, acc-0.9246, test loss-0.2831, acc-0.9220\n",
      "Iter-54450, train loss-0.2657, acc-0.9400, valid loss-0.2726, acc-0.9246, test loss-0.2831, acc-0.9220\n",
      "Iter-54460, train loss-0.2436, acc-0.9400, valid loss-0.2726, acc-0.9242, test loss-0.2831, acc-0.9216\n",
      "Iter-54470, train loss-0.2577, acc-0.9200, valid loss-0.2726, acc-0.9242, test loss-0.2830, acc-0.9218\n",
      "Iter-54480, train loss-0.3294, acc-0.9000, valid loss-0.2725, acc-0.9238, test loss-0.2830, acc-0.9217\n",
      "Iter-54490, train loss-0.2753, acc-0.9000, valid loss-0.2725, acc-0.9240, test loss-0.2829, acc-0.9220\n",
      "Iter-54500, train loss-0.2312, acc-0.9200, valid loss-0.2725, acc-0.9238, test loss-0.2829, acc-0.9220\n",
      "Iter-54510, train loss-0.1613, acc-0.9200, valid loss-0.2725, acc-0.9238, test loss-0.2829, acc-0.9219\n",
      "Iter-54520, train loss-0.3423, acc-0.9200, valid loss-0.2724, acc-0.9240, test loss-0.2829, acc-0.9220\n",
      "Iter-54530, train loss-0.1469, acc-1.0000, valid loss-0.2725, acc-0.9242, test loss-0.2829, acc-0.9218\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-54540, train loss-0.2370, acc-0.9200, valid loss-0.2725, acc-0.9240, test loss-0.2829, acc-0.9217\n",
      "Iter-54550, train loss-0.4714, acc-0.8400, valid loss-0.2724, acc-0.9238, test loss-0.2829, acc-0.9219\n",
      "Iter-54560, train loss-0.1482, acc-0.9600, valid loss-0.2724, acc-0.9236, test loss-0.2828, acc-0.9218\n",
      "Iter-54570, train loss-0.1796, acc-0.9600, valid loss-0.2723, acc-0.9242, test loss-0.2828, acc-0.9220\n",
      "Iter-54580, train loss-0.2950, acc-0.9000, valid loss-0.2723, acc-0.9242, test loss-0.2828, acc-0.9219\n",
      "Iter-54590, train loss-0.2948, acc-0.9400, valid loss-0.2723, acc-0.9242, test loss-0.2828, acc-0.9219\n",
      "Iter-54600, train loss-0.3432, acc-0.9200, valid loss-0.2723, acc-0.9248, test loss-0.2828, acc-0.9217\n",
      "Iter-54610, train loss-0.2892, acc-0.9000, valid loss-0.2722, acc-0.9246, test loss-0.2828, acc-0.9218\n",
      "Iter-54620, train loss-0.5435, acc-0.8800, valid loss-0.2722, acc-0.9248, test loss-0.2827, acc-0.9219\n",
      "Iter-54630, train loss-0.5343, acc-0.8000, valid loss-0.2722, acc-0.9244, test loss-0.2827, acc-0.9219\n",
      "Iter-54640, train loss-0.3902, acc-0.8800, valid loss-0.2722, acc-0.9242, test loss-0.2827, acc-0.9218\n",
      "Iter-54650, train loss-0.2986, acc-0.9200, valid loss-0.2723, acc-0.9242, test loss-0.2827, acc-0.9220\n",
      "Iter-54660, train loss-0.3558, acc-0.8800, valid loss-0.2723, acc-0.9238, test loss-0.2827, acc-0.9221\n",
      "Iter-54670, train loss-0.1516, acc-0.9600, valid loss-0.2722, acc-0.9246, test loss-0.2826, acc-0.9219\n",
      "Iter-54680, train loss-0.5966, acc-0.9000, valid loss-0.2722, acc-0.9244, test loss-0.2826, acc-0.9220\n",
      "Iter-54690, train loss-0.1579, acc-0.9600, valid loss-0.2722, acc-0.9244, test loss-0.2826, acc-0.9219\n",
      "Iter-54700, train loss-0.1469, acc-0.9400, valid loss-0.2722, acc-0.9242, test loss-0.2826, acc-0.9220\n",
      "Iter-54710, train loss-0.1114, acc-0.9800, valid loss-0.2722, acc-0.9242, test loss-0.2826, acc-0.9221\n",
      "Iter-54720, train loss-0.2394, acc-0.9200, valid loss-0.2723, acc-0.9236, test loss-0.2826, acc-0.9223\n",
      "Iter-54730, train loss-0.3856, acc-0.8800, valid loss-0.2723, acc-0.9238, test loss-0.2825, acc-0.9224\n",
      "Iter-54740, train loss-0.2160, acc-0.9600, valid loss-0.2723, acc-0.9238, test loss-0.2825, acc-0.9224\n",
      "Iter-54750, train loss-0.2109, acc-0.9400, valid loss-0.2724, acc-0.9242, test loss-0.2825, acc-0.9222\n",
      "Iter-54760, train loss-0.3774, acc-0.9000, valid loss-0.2723, acc-0.9244, test loss-0.2825, acc-0.9226\n",
      "Iter-54770, train loss-0.3581, acc-0.9000, valid loss-0.2724, acc-0.9244, test loss-0.2825, acc-0.9225\n",
      "Iter-54780, train loss-0.4166, acc-0.8600, valid loss-0.2724, acc-0.9244, test loss-0.2824, acc-0.9227\n",
      "Iter-54790, train loss-0.2938, acc-0.9000, valid loss-0.2724, acc-0.9244, test loss-0.2824, acc-0.9224\n",
      "Iter-54800, train loss-0.1560, acc-0.9800, valid loss-0.2723, acc-0.9244, test loss-0.2824, acc-0.9223\n",
      "Iter-54810, train loss-0.3191, acc-0.9200, valid loss-0.2723, acc-0.9244, test loss-0.2823, acc-0.9225\n",
      "Iter-54820, train loss-0.3957, acc-0.8600, valid loss-0.2723, acc-0.9244, test loss-0.2823, acc-0.9226\n",
      "Iter-54830, train loss-0.2355, acc-0.9200, valid loss-0.2722, acc-0.9244, test loss-0.2824, acc-0.9225\n",
      "Iter-54840, train loss-0.2617, acc-0.9200, valid loss-0.2721, acc-0.9242, test loss-0.2823, acc-0.9223\n",
      "Iter-54850, train loss-0.2643, acc-0.9200, valid loss-0.2721, acc-0.9242, test loss-0.2823, acc-0.9224\n",
      "Iter-54860, train loss-0.3841, acc-0.8800, valid loss-0.2721, acc-0.9242, test loss-0.2823, acc-0.9224\n",
      "Iter-54870, train loss-0.3723, acc-0.8800, valid loss-0.2720, acc-0.9242, test loss-0.2823, acc-0.9227\n",
      "Iter-54880, train loss-0.2029, acc-0.9600, valid loss-0.2720, acc-0.9242, test loss-0.2822, acc-0.9227\n",
      "Iter-54890, train loss-0.2363, acc-0.9400, valid loss-0.2720, acc-0.9242, test loss-0.2822, acc-0.9227\n",
      "Iter-54900, train loss-0.3096, acc-0.9400, valid loss-0.2720, acc-0.9242, test loss-0.2822, acc-0.9228\n",
      "Iter-54910, train loss-0.2458, acc-0.9200, valid loss-0.2719, acc-0.9240, test loss-0.2822, acc-0.9227\n",
      "Iter-54920, train loss-0.1623, acc-0.9600, valid loss-0.2719, acc-0.9240, test loss-0.2822, acc-0.9227\n",
      "Iter-54930, train loss-0.3271, acc-0.9200, valid loss-0.2719, acc-0.9244, test loss-0.2821, acc-0.9226\n",
      "Iter-54940, train loss-0.3090, acc-0.9200, valid loss-0.2718, acc-0.9244, test loss-0.2821, acc-0.9226\n",
      "Iter-54950, train loss-0.3246, acc-0.9000, valid loss-0.2718, acc-0.9244, test loss-0.2821, acc-0.9226\n",
      "Iter-54960, train loss-0.2026, acc-0.9600, valid loss-0.2718, acc-0.9244, test loss-0.2821, acc-0.9224\n",
      "Iter-54970, train loss-0.3907, acc-0.9000, valid loss-0.2718, acc-0.9244, test loss-0.2821, acc-0.9226\n",
      "Iter-54980, train loss-0.1819, acc-0.9400, valid loss-0.2718, acc-0.9244, test loss-0.2821, acc-0.9226\n",
      "Iter-54990, train loss-0.2835, acc-0.9200, valid loss-0.2718, acc-0.9244, test loss-0.2820, acc-0.9228\n",
      "Iter-55000, train loss-0.1513, acc-0.9800, valid loss-0.2718, acc-0.9244, test loss-0.2820, acc-0.9225\n",
      "Iter-55010, train loss-0.1780, acc-0.9600, valid loss-0.2718, acc-0.9244, test loss-0.2819, acc-0.9226\n",
      "Iter-55020, train loss-0.1625, acc-0.9600, valid loss-0.2717, acc-0.9244, test loss-0.2819, acc-0.9227\n",
      "Iter-55030, train loss-0.2574, acc-0.9200, valid loss-0.2717, acc-0.9246, test loss-0.2819, acc-0.9228\n",
      "Iter-55040, train loss-0.3447, acc-0.9200, valid loss-0.2717, acc-0.9244, test loss-0.2818, acc-0.9228\n",
      "Iter-55050, train loss-0.3061, acc-0.9000, valid loss-0.2716, acc-0.9246, test loss-0.2818, acc-0.9227\n",
      "Iter-55060, train loss-0.5530, acc-0.8600, valid loss-0.2717, acc-0.9246, test loss-0.2818, acc-0.9228\n",
      "Iter-55070, train loss-0.1791, acc-0.9400, valid loss-0.2717, acc-0.9248, test loss-0.2818, acc-0.9227\n",
      "Iter-55080, train loss-0.1455, acc-0.9400, valid loss-0.2717, acc-0.9248, test loss-0.2818, acc-0.9227\n",
      "Iter-55090, train loss-0.4039, acc-0.9000, valid loss-0.2717, acc-0.9250, test loss-0.2818, acc-0.9225\n",
      "Iter-55100, train loss-0.1671, acc-0.9400, valid loss-0.2717, acc-0.9250, test loss-0.2818, acc-0.9226\n",
      "Iter-55110, train loss-0.6283, acc-0.8400, valid loss-0.2717, acc-0.9254, test loss-0.2818, acc-0.9227\n",
      "Iter-55120, train loss-0.1546, acc-0.9600, valid loss-0.2717, acc-0.9252, test loss-0.2818, acc-0.9227\n",
      "Iter-55130, train loss-0.2533, acc-0.9600, valid loss-0.2716, acc-0.9250, test loss-0.2817, acc-0.9227\n",
      "Iter-55140, train loss-0.1967, acc-0.9200, valid loss-0.2717, acc-0.9254, test loss-0.2818, acc-0.9225\n",
      "Iter-55150, train loss-0.3043, acc-0.9600, valid loss-0.2717, acc-0.9256, test loss-0.2818, acc-0.9226\n",
      "Iter-55160, train loss-0.3817, acc-0.8600, valid loss-0.2717, acc-0.9260, test loss-0.2819, acc-0.9222\n",
      "Iter-55170, train loss-0.2984, acc-0.9400, valid loss-0.2716, acc-0.9254, test loss-0.2818, acc-0.9222\n",
      "Iter-55180, train loss-0.2644, acc-0.9400, valid loss-0.2715, acc-0.9258, test loss-0.2817, acc-0.9224\n",
      "Iter-55190, train loss-0.2662, acc-0.9400, valid loss-0.2715, acc-0.9258, test loss-0.2817, acc-0.9222\n",
      "Iter-55200, train loss-0.2514, acc-0.9400, valid loss-0.2715, acc-0.9256, test loss-0.2816, acc-0.9223\n",
      "Iter-55210, train loss-0.3547, acc-0.9200, valid loss-0.2714, acc-0.9254, test loss-0.2816, acc-0.9225\n",
      "Iter-55220, train loss-0.2129, acc-0.9400, valid loss-0.2714, acc-0.9254, test loss-0.2816, acc-0.9225\n",
      "Iter-55230, train loss-0.3513, acc-0.9200, valid loss-0.2713, acc-0.9258, test loss-0.2815, acc-0.9226\n",
      "Iter-55240, train loss-0.2757, acc-0.9000, valid loss-0.2712, acc-0.9260, test loss-0.2816, acc-0.9224\n",
      "Iter-55250, train loss-0.1995, acc-0.9400, valid loss-0.2712, acc-0.9260, test loss-0.2816, acc-0.9224\n",
      "Iter-55260, train loss-0.1668, acc-0.9800, valid loss-0.2711, acc-0.9260, test loss-0.2816, acc-0.9224\n",
      "Iter-55270, train loss-0.2851, acc-0.9200, valid loss-0.2711, acc-0.9260, test loss-0.2816, acc-0.9225\n",
      "Iter-55280, train loss-0.3395, acc-0.9000, valid loss-0.2710, acc-0.9260, test loss-0.2816, acc-0.9225\n",
      "Iter-55290, train loss-0.4478, acc-0.8000, valid loss-0.2710, acc-0.9260, test loss-0.2815, acc-0.9225\n",
      "Iter-55300, train loss-0.3488, acc-0.8800, valid loss-0.2710, acc-0.9260, test loss-0.2816, acc-0.9225\n",
      "Iter-55310, train loss-0.2755, acc-0.9200, valid loss-0.2710, acc-0.9260, test loss-0.2815, acc-0.9225\n",
      "Iter-55320, train loss-0.2066, acc-0.9600, valid loss-0.2710, acc-0.9260, test loss-0.2815, acc-0.9225\n",
      "Iter-55330, train loss-0.1756, acc-0.9600, valid loss-0.2710, acc-0.9260, test loss-0.2816, acc-0.9224\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-55340, train loss-0.1419, acc-0.9800, valid loss-0.2711, acc-0.9260, test loss-0.2815, acc-0.9228\n",
      "Iter-55350, train loss-0.4538, acc-0.8600, valid loss-0.2710, acc-0.9260, test loss-0.2814, acc-0.9229\n",
      "Iter-55360, train loss-0.3266, acc-0.8800, valid loss-0.2710, acc-0.9260, test loss-0.2814, acc-0.9230\n",
      "Iter-55370, train loss-0.3474, acc-0.8800, valid loss-0.2709, acc-0.9256, test loss-0.2814, acc-0.9229\n",
      "Iter-55380, train loss-0.2548, acc-0.9200, valid loss-0.2709, acc-0.9256, test loss-0.2813, acc-0.9228\n",
      "Iter-55390, train loss-0.9581, acc-0.7000, valid loss-0.2709, acc-0.9258, test loss-0.2813, acc-0.9227\n",
      "Iter-55400, train loss-0.3571, acc-0.9400, valid loss-0.2709, acc-0.9260, test loss-0.2813, acc-0.9228\n",
      "Iter-55410, train loss-0.0991, acc-1.0000, valid loss-0.2708, acc-0.9262, test loss-0.2813, acc-0.9228\n",
      "Iter-55420, train loss-0.2087, acc-0.9200, valid loss-0.2707, acc-0.9260, test loss-0.2812, acc-0.9227\n",
      "Iter-55430, train loss-0.6279, acc-0.8400, valid loss-0.2708, acc-0.9260, test loss-0.2812, acc-0.9228\n",
      "Iter-55440, train loss-0.1427, acc-0.9600, valid loss-0.2707, acc-0.9262, test loss-0.2813, acc-0.9228\n",
      "Iter-55450, train loss-0.4204, acc-0.8800, valid loss-0.2707, acc-0.9260, test loss-0.2813, acc-0.9228\n",
      "Iter-55460, train loss-0.3785, acc-0.8200, valid loss-0.2707, acc-0.9260, test loss-0.2812, acc-0.9227\n",
      "Iter-55470, train loss-0.2520, acc-0.9200, valid loss-0.2707, acc-0.9258, test loss-0.2811, acc-0.9229\n",
      "Iter-55480, train loss-0.2289, acc-0.9000, valid loss-0.2707, acc-0.9256, test loss-0.2812, acc-0.9228\n",
      "Iter-55490, train loss-0.4723, acc-0.8800, valid loss-0.2706, acc-0.9258, test loss-0.2811, acc-0.9228\n",
      "Iter-55500, train loss-0.2627, acc-0.8600, valid loss-0.2706, acc-0.9260, test loss-0.2812, acc-0.9227\n",
      "Iter-55510, train loss-0.3367, acc-0.8800, valid loss-0.2706, acc-0.9260, test loss-0.2812, acc-0.9228\n",
      "Iter-55520, train loss-0.3525, acc-0.9200, valid loss-0.2705, acc-0.9262, test loss-0.2812, acc-0.9228\n",
      "Iter-55530, train loss-0.3074, acc-0.9000, valid loss-0.2704, acc-0.9262, test loss-0.2812, acc-0.9229\n",
      "Iter-55540, train loss-0.2395, acc-0.9400, valid loss-0.2705, acc-0.9262, test loss-0.2811, acc-0.9228\n",
      "Iter-55550, train loss-0.2334, acc-0.9400, valid loss-0.2705, acc-0.9260, test loss-0.2811, acc-0.9227\n",
      "Iter-55560, train loss-0.2379, acc-0.9200, valid loss-0.2705, acc-0.9260, test loss-0.2811, acc-0.9227\n",
      "Iter-55570, train loss-0.2602, acc-0.9400, valid loss-0.2705, acc-0.9260, test loss-0.2811, acc-0.9229\n",
      "Iter-55580, train loss-0.3030, acc-0.9400, valid loss-0.2705, acc-0.9258, test loss-0.2810, acc-0.9226\n",
      "Iter-55590, train loss-0.2539, acc-0.9400, valid loss-0.2705, acc-0.9260, test loss-0.2810, acc-0.9228\n",
      "Iter-55600, train loss-0.2033, acc-0.9400, valid loss-0.2705, acc-0.9260, test loss-0.2810, acc-0.9229\n",
      "Iter-55610, train loss-0.2283, acc-0.9200, valid loss-0.2705, acc-0.9258, test loss-0.2809, acc-0.9225\n",
      "Iter-55620, train loss-0.3003, acc-0.9000, valid loss-0.2704, acc-0.9258, test loss-0.2809, acc-0.9222\n",
      "Iter-55630, train loss-0.1636, acc-0.9600, valid loss-0.2704, acc-0.9258, test loss-0.2808, acc-0.9222\n",
      "Iter-55640, train loss-0.4629, acc-0.9000, valid loss-0.2704, acc-0.9258, test loss-0.2808, acc-0.9222\n",
      "Iter-55650, train loss-0.3468, acc-0.9200, valid loss-0.2703, acc-0.9260, test loss-0.2809, acc-0.9223\n",
      "Iter-55660, train loss-0.2426, acc-0.9200, valid loss-0.2703, acc-0.9256, test loss-0.2808, acc-0.9226\n",
      "Iter-55670, train loss-0.3204, acc-0.9000, valid loss-0.2703, acc-0.9258, test loss-0.2808, acc-0.9227\n",
      "Iter-55680, train loss-0.3034, acc-0.9000, valid loss-0.2703, acc-0.9256, test loss-0.2808, acc-0.9228\n",
      "Iter-55690, train loss-0.3619, acc-0.8600, valid loss-0.2703, acc-0.9252, test loss-0.2808, acc-0.9228\n",
      "Iter-55700, train loss-0.3091, acc-0.9200, valid loss-0.2702, acc-0.9254, test loss-0.2808, acc-0.9228\n",
      "Iter-55710, train loss-0.4070, acc-0.9000, valid loss-0.2702, acc-0.9252, test loss-0.2808, acc-0.9230\n",
      "Iter-55720, train loss-0.2075, acc-0.9600, valid loss-0.2702, acc-0.9256, test loss-0.2808, acc-0.9230\n",
      "Iter-55730, train loss-0.2244, acc-0.9000, valid loss-0.2701, acc-0.9250, test loss-0.2807, acc-0.9228\n",
      "Iter-55740, train loss-0.2963, acc-0.9000, valid loss-0.2701, acc-0.9254, test loss-0.2807, acc-0.9230\n",
      "Iter-55750, train loss-0.4401, acc-0.8800, valid loss-0.2701, acc-0.9256, test loss-0.2807, acc-0.9229\n",
      "Iter-55760, train loss-0.3004, acc-0.9000, valid loss-0.2701, acc-0.9256, test loss-0.2806, acc-0.9228\n",
      "Iter-55770, train loss-0.3514, acc-0.9200, valid loss-0.2701, acc-0.9256, test loss-0.2806, acc-0.9230\n",
      "Iter-55780, train loss-0.5531, acc-0.8400, valid loss-0.2701, acc-0.9254, test loss-0.2806, acc-0.9231\n",
      "Iter-55790, train loss-0.4570, acc-0.8800, valid loss-0.2701, acc-0.9250, test loss-0.2806, acc-0.9230\n",
      "Iter-55800, train loss-0.2585, acc-0.9600, valid loss-0.2700, acc-0.9258, test loss-0.2806, acc-0.9229\n",
      "Iter-55810, train loss-0.1570, acc-0.9600, valid loss-0.2700, acc-0.9258, test loss-0.2806, acc-0.9229\n",
      "Iter-55820, train loss-0.2648, acc-0.9400, valid loss-0.2700, acc-0.9258, test loss-0.2806, acc-0.9231\n",
      "Iter-55830, train loss-0.2571, acc-0.9600, valid loss-0.2700, acc-0.9258, test loss-0.2806, acc-0.9229\n",
      "Iter-55840, train loss-0.2243, acc-0.9400, valid loss-0.2699, acc-0.9260, test loss-0.2806, acc-0.9231\n",
      "Iter-55850, train loss-0.2246, acc-0.9200, valid loss-0.2699, acc-0.9258, test loss-0.2806, acc-0.9230\n",
      "Iter-55860, train loss-0.2858, acc-0.9000, valid loss-0.2698, acc-0.9256, test loss-0.2805, acc-0.9230\n",
      "Iter-55870, train loss-0.3200, acc-0.8800, valid loss-0.2698, acc-0.9256, test loss-0.2804, acc-0.9229\n",
      "Iter-55880, train loss-0.2235, acc-0.9400, valid loss-0.2698, acc-0.9260, test loss-0.2805, acc-0.9226\n",
      "Iter-55890, train loss-0.2052, acc-0.9400, valid loss-0.2698, acc-0.9258, test loss-0.2805, acc-0.9227\n",
      "Iter-55900, train loss-0.2852, acc-0.9000, valid loss-0.2698, acc-0.9258, test loss-0.2805, acc-0.9227\n",
      "Iter-55910, train loss-0.3140, acc-0.9400, valid loss-0.2698, acc-0.9260, test loss-0.2804, acc-0.9227\n",
      "Iter-55920, train loss-0.3508, acc-0.9200, valid loss-0.2698, acc-0.9252, test loss-0.2804, acc-0.9226\n",
      "Iter-55930, train loss-0.4167, acc-0.8800, valid loss-0.2698, acc-0.9254, test loss-0.2804, acc-0.9226\n",
      "Iter-55940, train loss-0.3323, acc-0.9000, valid loss-0.2698, acc-0.9246, test loss-0.2803, acc-0.9224\n",
      "Iter-55950, train loss-0.2630, acc-0.9200, valid loss-0.2697, acc-0.9252, test loss-0.2803, acc-0.9225\n",
      "Iter-55960, train loss-0.1374, acc-0.9800, valid loss-0.2697, acc-0.9254, test loss-0.2803, acc-0.9226\n",
      "Iter-55970, train loss-0.3114, acc-0.9200, valid loss-0.2696, acc-0.9252, test loss-0.2802, acc-0.9225\n",
      "Iter-55980, train loss-0.3193, acc-0.8800, valid loss-0.2696, acc-0.9250, test loss-0.2802, acc-0.9228\n",
      "Iter-55990, train loss-0.3491, acc-0.8600, valid loss-0.2695, acc-0.9248, test loss-0.2803, acc-0.9226\n",
      "Iter-56000, train loss-0.2783, acc-0.9000, valid loss-0.2696, acc-0.9246, test loss-0.2802, acc-0.9226\n",
      "Iter-56010, train loss-0.5400, acc-0.8600, valid loss-0.2695, acc-0.9244, test loss-0.2802, acc-0.9226\n",
      "Iter-56020, train loss-0.2565, acc-0.9200, valid loss-0.2695, acc-0.9244, test loss-0.2802, acc-0.9226\n",
      "Iter-56030, train loss-0.3672, acc-0.9200, valid loss-0.2695, acc-0.9242, test loss-0.2802, acc-0.9226\n",
      "Iter-56040, train loss-0.1052, acc-0.9800, valid loss-0.2696, acc-0.9246, test loss-0.2802, acc-0.9227\n",
      "Iter-56050, train loss-0.2992, acc-0.9000, valid loss-0.2695, acc-0.9244, test loss-0.2802, acc-0.9225\n",
      "Iter-56060, train loss-0.1366, acc-0.9800, valid loss-0.2694, acc-0.9248, test loss-0.2801, acc-0.9227\n",
      "Iter-56070, train loss-0.1312, acc-1.0000, valid loss-0.2694, acc-0.9246, test loss-0.2801, acc-0.9227\n",
      "Iter-56080, train loss-0.1586, acc-0.9600, valid loss-0.2695, acc-0.9246, test loss-0.2800, acc-0.9227\n",
      "Iter-56090, train loss-0.1890, acc-0.9400, valid loss-0.2695, acc-0.9242, test loss-0.2801, acc-0.9226\n",
      "Iter-56100, train loss-0.2268, acc-0.9000, valid loss-0.2694, acc-0.9246, test loss-0.2800, acc-0.9225\n",
      "Iter-56110, train loss-0.3739, acc-0.9000, valid loss-0.2694, acc-0.9244, test loss-0.2800, acc-0.9230\n",
      "Iter-56120, train loss-0.1277, acc-0.9800, valid loss-0.2694, acc-0.9248, test loss-0.2800, acc-0.9229\n",
      "Iter-56130, train loss-0.3770, acc-0.8800, valid loss-0.2694, acc-0.9250, test loss-0.2800, acc-0.9230\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56140, train loss-0.2916, acc-0.9400, valid loss-0.2694, acc-0.9246, test loss-0.2800, acc-0.9229\n",
      "Iter-56150, train loss-0.2084, acc-0.9400, valid loss-0.2693, acc-0.9248, test loss-0.2800, acc-0.9230\n",
      "Iter-56160, train loss-0.2033, acc-0.9800, valid loss-0.2694, acc-0.9252, test loss-0.2800, acc-0.9230\n",
      "Iter-56170, train loss-0.3368, acc-0.9000, valid loss-0.2693, acc-0.9252, test loss-0.2799, acc-0.9229\n",
      "Iter-56180, train loss-0.4799, acc-0.9000, valid loss-0.2693, acc-0.9254, test loss-0.2799, acc-0.9228\n",
      "Iter-56190, train loss-0.1562, acc-0.9400, valid loss-0.2693, acc-0.9252, test loss-0.2799, acc-0.9228\n",
      "Iter-56200, train loss-0.3370, acc-0.9200, valid loss-0.2692, acc-0.9252, test loss-0.2799, acc-0.9229\n",
      "Iter-56210, train loss-0.5148, acc-0.8800, valid loss-0.2693, acc-0.9250, test loss-0.2798, acc-0.9230\n",
      "Iter-56220, train loss-0.3326, acc-0.9200, valid loss-0.2693, acc-0.9248, test loss-0.2798, acc-0.9231\n",
      "Iter-56230, train loss-0.4517, acc-0.8800, valid loss-0.2693, acc-0.9248, test loss-0.2798, acc-0.9227\n",
      "Iter-56240, train loss-0.3130, acc-0.9200, valid loss-0.2693, acc-0.9246, test loss-0.2798, acc-0.9229\n",
      "Iter-56250, train loss-0.3629, acc-0.8800, valid loss-0.2693, acc-0.9250, test loss-0.2798, acc-0.9229\n",
      "Iter-56260, train loss-0.3121, acc-0.9400, valid loss-0.2693, acc-0.9252, test loss-0.2798, acc-0.9230\n",
      "Iter-56270, train loss-0.3158, acc-0.9000, valid loss-0.2693, acc-0.9252, test loss-0.2798, acc-0.9231\n",
      "Iter-56280, train loss-0.2077, acc-0.9600, valid loss-0.2693, acc-0.9250, test loss-0.2798, acc-0.9229\n",
      "Iter-56290, train loss-0.2683, acc-0.9200, valid loss-0.2693, acc-0.9250, test loss-0.2798, acc-0.9229\n",
      "Iter-56300, train loss-0.1894, acc-0.9200, valid loss-0.2692, acc-0.9252, test loss-0.2798, acc-0.9230\n",
      "Iter-56310, train loss-0.1923, acc-0.9400, valid loss-0.2692, acc-0.9252, test loss-0.2797, acc-0.9232\n",
      "Iter-56320, train loss-0.2771, acc-0.9200, valid loss-0.2691, acc-0.9250, test loss-0.2797, acc-0.9232\n",
      "Iter-56330, train loss-0.3404, acc-0.9000, valid loss-0.2692, acc-0.9252, test loss-0.2796, acc-0.9230\n",
      "Iter-56340, train loss-0.2637, acc-0.9200, valid loss-0.2691, acc-0.9252, test loss-0.2796, acc-0.9228\n",
      "Iter-56350, train loss-0.2549, acc-0.9200, valid loss-0.2691, acc-0.9252, test loss-0.2796, acc-0.9229\n",
      "Iter-56360, train loss-0.1758, acc-0.9400, valid loss-0.2691, acc-0.9254, test loss-0.2796, acc-0.9229\n",
      "Iter-56370, train loss-0.3299, acc-0.9000, valid loss-0.2691, acc-0.9256, test loss-0.2796, acc-0.9230\n",
      "Iter-56380, train loss-0.1606, acc-0.9800, valid loss-0.2690, acc-0.9252, test loss-0.2795, acc-0.9230\n",
      "Iter-56390, train loss-0.2900, acc-0.9000, valid loss-0.2691, acc-0.9256, test loss-0.2794, acc-0.9231\n",
      "Iter-56400, train loss-0.2768, acc-0.9200, valid loss-0.2690, acc-0.9256, test loss-0.2794, acc-0.9232\n",
      "Iter-56410, train loss-0.1763, acc-0.9400, valid loss-0.2690, acc-0.9256, test loss-0.2794, acc-0.9232\n",
      "Iter-56420, train loss-0.2987, acc-0.8800, valid loss-0.2690, acc-0.9258, test loss-0.2794, acc-0.9230\n",
      "Iter-56430, train loss-0.3762, acc-0.9200, valid loss-0.2690, acc-0.9256, test loss-0.2793, acc-0.9231\n",
      "Iter-56440, train loss-0.3114, acc-0.9000, valid loss-0.2689, acc-0.9258, test loss-0.2793, acc-0.9232\n",
      "Iter-56450, train loss-0.3026, acc-0.9000, valid loss-0.2688, acc-0.9254, test loss-0.2793, acc-0.9232\n",
      "Iter-56460, train loss-0.2129, acc-0.9400, valid loss-0.2687, acc-0.9254, test loss-0.2793, acc-0.9229\n",
      "Iter-56470, train loss-0.4214, acc-0.8600, valid loss-0.2686, acc-0.9260, test loss-0.2792, acc-0.9230\n",
      "Iter-56480, train loss-0.1456, acc-0.9800, valid loss-0.2686, acc-0.9260, test loss-0.2792, acc-0.9230\n",
      "Iter-56490, train loss-0.2324, acc-0.9400, valid loss-0.2686, acc-0.9258, test loss-0.2791, acc-0.9231\n",
      "Iter-56500, train loss-0.2558, acc-0.9000, valid loss-0.2686, acc-0.9256, test loss-0.2791, acc-0.9231\n",
      "Iter-56510, train loss-0.2131, acc-0.9200, valid loss-0.2685, acc-0.9256, test loss-0.2791, acc-0.9229\n",
      "Iter-56520, train loss-0.3462, acc-0.8800, valid loss-0.2685, acc-0.9256, test loss-0.2791, acc-0.9228\n",
      "Iter-56530, train loss-0.2273, acc-0.9200, valid loss-0.2684, acc-0.9258, test loss-0.2790, acc-0.9229\n",
      "Iter-56540, train loss-0.1387, acc-0.9600, valid loss-0.2684, acc-0.9258, test loss-0.2790, acc-0.9227\n",
      "Iter-56550, train loss-0.2355, acc-0.9200, valid loss-0.2684, acc-0.9258, test loss-0.2790, acc-0.9225\n",
      "Iter-56560, train loss-0.3453, acc-0.9200, valid loss-0.2684, acc-0.9258, test loss-0.2789, acc-0.9229\n",
      "Iter-56570, train loss-0.2109, acc-0.9600, valid loss-0.2684, acc-0.9258, test loss-0.2789, acc-0.9230\n",
      "Iter-56580, train loss-0.2470, acc-0.9400, valid loss-0.2684, acc-0.9260, test loss-0.2789, acc-0.9230\n",
      "Iter-56590, train loss-0.4207, acc-0.9200, valid loss-0.2684, acc-0.9260, test loss-0.2789, acc-0.9230\n",
      "Iter-56600, train loss-0.2058, acc-0.9600, valid loss-0.2684, acc-0.9260, test loss-0.2788, acc-0.9227\n",
      "Iter-56610, train loss-0.2812, acc-0.9000, valid loss-0.2684, acc-0.9262, test loss-0.2788, acc-0.9228\n",
      "Iter-56620, train loss-0.3230, acc-0.8600, valid loss-0.2684, acc-0.9262, test loss-0.2788, acc-0.9229\n",
      "Iter-56630, train loss-0.3012, acc-0.8800, valid loss-0.2683, acc-0.9264, test loss-0.2789, acc-0.9230\n",
      "Iter-56640, train loss-0.2488, acc-0.9400, valid loss-0.2683, acc-0.9262, test loss-0.2789, acc-0.9229\n",
      "Iter-56650, train loss-0.2210, acc-0.9600, valid loss-0.2682, acc-0.9262, test loss-0.2789, acc-0.9229\n",
      "Iter-56660, train loss-0.1063, acc-1.0000, valid loss-0.2682, acc-0.9260, test loss-0.2789, acc-0.9229\n",
      "Iter-56670, train loss-0.2645, acc-0.9200, valid loss-0.2682, acc-0.9260, test loss-0.2789, acc-0.9229\n",
      "Iter-56680, train loss-0.1259, acc-0.9800, valid loss-0.2681, acc-0.9260, test loss-0.2789, acc-0.9229\n",
      "Iter-56690, train loss-0.2792, acc-0.9400, valid loss-0.2681, acc-0.9260, test loss-0.2788, acc-0.9229\n",
      "Iter-56700, train loss-0.1563, acc-0.9600, valid loss-0.2681, acc-0.9262, test loss-0.2788, acc-0.9230\n",
      "Iter-56710, train loss-0.2466, acc-0.9200, valid loss-0.2681, acc-0.9258, test loss-0.2788, acc-0.9230\n",
      "Iter-56720, train loss-0.1446, acc-1.0000, valid loss-0.2681, acc-0.9260, test loss-0.2788, acc-0.9230\n",
      "Iter-56730, train loss-0.3400, acc-0.9000, valid loss-0.2681, acc-0.9258, test loss-0.2788, acc-0.9230\n",
      "Iter-56740, train loss-0.3375, acc-0.9000, valid loss-0.2682, acc-0.9258, test loss-0.2788, acc-0.9232\n",
      "Iter-56750, train loss-0.2627, acc-0.9400, valid loss-0.2682, acc-0.9258, test loss-0.2788, acc-0.9233\n",
      "Iter-56760, train loss-0.1832, acc-0.9800, valid loss-0.2681, acc-0.9258, test loss-0.2788, acc-0.9231\n",
      "Iter-56770, train loss-0.3886, acc-0.8200, valid loss-0.2681, acc-0.9258, test loss-0.2788, acc-0.9231\n",
      "Iter-56780, train loss-0.2666, acc-0.8600, valid loss-0.2681, acc-0.9258, test loss-0.2787, acc-0.9230\n",
      "Iter-56790, train loss-0.2539, acc-0.8800, valid loss-0.2681, acc-0.9258, test loss-0.2787, acc-0.9230\n",
      "Iter-56800, train loss-0.2092, acc-0.9000, valid loss-0.2681, acc-0.9260, test loss-0.2787, acc-0.9231\n",
      "Iter-56810, train loss-0.3151, acc-0.9200, valid loss-0.2681, acc-0.9260, test loss-0.2787, acc-0.9230\n",
      "Iter-56820, train loss-0.2919, acc-0.9200, valid loss-0.2682, acc-0.9258, test loss-0.2787, acc-0.9230\n",
      "Iter-56830, train loss-0.2897, acc-0.9400, valid loss-0.2682, acc-0.9258, test loss-0.2786, acc-0.9229\n",
      "Iter-56840, train loss-0.1982, acc-0.9400, valid loss-0.2681, acc-0.9258, test loss-0.2786, acc-0.9228\n",
      "Iter-56850, train loss-0.1964, acc-0.9000, valid loss-0.2681, acc-0.9260, test loss-0.2786, acc-0.9230\n",
      "Iter-56860, train loss-0.3430, acc-0.9200, valid loss-0.2681, acc-0.9262, test loss-0.2786, acc-0.9229\n",
      "Iter-56870, train loss-0.1758, acc-0.9400, valid loss-0.2681, acc-0.9262, test loss-0.2786, acc-0.9228\n",
      "Iter-56880, train loss-0.3260, acc-0.8800, valid loss-0.2681, acc-0.9260, test loss-0.2786, acc-0.9229\n",
      "Iter-56890, train loss-0.3939, acc-0.9000, valid loss-0.2682, acc-0.9256, test loss-0.2786, acc-0.9229\n",
      "Iter-56900, train loss-0.3527, acc-0.9200, valid loss-0.2681, acc-0.9256, test loss-0.2785, acc-0.9230\n",
      "Iter-56910, train loss-0.1548, acc-0.9800, valid loss-0.2681, acc-0.9256, test loss-0.2785, acc-0.9229\n",
      "Iter-56920, train loss-0.2527, acc-0.9000, valid loss-0.2681, acc-0.9256, test loss-0.2785, acc-0.9231\n",
      "Iter-56930, train loss-0.2064, acc-0.9400, valid loss-0.2681, acc-0.9256, test loss-0.2785, acc-0.9232\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56940, train loss-0.3340, acc-0.9000, valid loss-0.2681, acc-0.9258, test loss-0.2784, acc-0.9232\n",
      "Iter-56950, train loss-0.2199, acc-0.9200, valid loss-0.2680, acc-0.9258, test loss-0.2784, acc-0.9231\n",
      "Iter-56960, train loss-0.1311, acc-0.9800, valid loss-0.2680, acc-0.9256, test loss-0.2784, acc-0.9232\n",
      "Iter-56970, train loss-0.4167, acc-0.8600, valid loss-0.2679, acc-0.9258, test loss-0.2784, acc-0.9231\n",
      "Iter-56980, train loss-0.2556, acc-0.9200, valid loss-0.2679, acc-0.9258, test loss-0.2784, acc-0.9230\n",
      "Iter-56990, train loss-0.2515, acc-0.9200, valid loss-0.2679, acc-0.9258, test loss-0.2783, acc-0.9232\n",
      "Iter-57000, train loss-0.2519, acc-0.9400, valid loss-0.2679, acc-0.9258, test loss-0.2783, acc-0.9232\n",
      "Iter-57010, train loss-0.3334, acc-0.9000, valid loss-0.2679, acc-0.9258, test loss-0.2783, acc-0.9232\n",
      "Iter-57020, train loss-0.3148, acc-0.8800, valid loss-0.2678, acc-0.9258, test loss-0.2783, acc-0.9233\n",
      "Iter-57030, train loss-0.2310, acc-0.9200, valid loss-0.2678, acc-0.9258, test loss-0.2783, acc-0.9233\n",
      "Iter-57040, train loss-0.1919, acc-0.9400, valid loss-0.2677, acc-0.9258, test loss-0.2782, acc-0.9233\n",
      "Iter-57050, train loss-0.3567, acc-0.9000, valid loss-0.2677, acc-0.9258, test loss-0.2783, acc-0.9231\n",
      "Iter-57060, train loss-0.2410, acc-0.9200, valid loss-0.2676, acc-0.9258, test loss-0.2782, acc-0.9230\n",
      "Iter-57070, train loss-0.3788, acc-0.9000, valid loss-0.2676, acc-0.9258, test loss-0.2782, acc-0.9232\n",
      "Iter-57080, train loss-0.3814, acc-0.8400, valid loss-0.2676, acc-0.9258, test loss-0.2782, acc-0.9231\n",
      "Iter-57090, train loss-0.4237, acc-0.8800, valid loss-0.2675, acc-0.9258, test loss-0.2782, acc-0.9230\n",
      "Iter-57100, train loss-0.2792, acc-0.9200, valid loss-0.2676, acc-0.9258, test loss-0.2782, acc-0.9231\n",
      "Iter-57110, train loss-0.2783, acc-0.9200, valid loss-0.2675, acc-0.9258, test loss-0.2782, acc-0.9232\n",
      "Iter-57120, train loss-0.1717, acc-0.9200, valid loss-0.2675, acc-0.9258, test loss-0.2782, acc-0.9234\n",
      "Iter-57130, train loss-0.2768, acc-0.9000, valid loss-0.2675, acc-0.9258, test loss-0.2781, acc-0.9234\n",
      "Iter-57140, train loss-0.2157, acc-0.9200, valid loss-0.2674, acc-0.9258, test loss-0.2781, acc-0.9236\n",
      "Iter-57150, train loss-0.1763, acc-0.9800, valid loss-0.2674, acc-0.9260, test loss-0.2781, acc-0.9234\n",
      "Iter-57160, train loss-0.2516, acc-0.9600, valid loss-0.2673, acc-0.9260, test loss-0.2780, acc-0.9234\n",
      "Iter-57170, train loss-0.1760, acc-0.9800, valid loss-0.2673, acc-0.9260, test loss-0.2780, acc-0.9233\n",
      "Iter-57180, train loss-0.1541, acc-0.9600, valid loss-0.2672, acc-0.9260, test loss-0.2780, acc-0.9230\n",
      "Iter-57190, train loss-0.3217, acc-0.9000, valid loss-0.2672, acc-0.9260, test loss-0.2780, acc-0.9231\n",
      "Iter-57200, train loss-0.2384, acc-0.9200, valid loss-0.2672, acc-0.9260, test loss-0.2779, acc-0.9232\n",
      "Iter-57210, train loss-0.1698, acc-0.9600, valid loss-0.2672, acc-0.9260, test loss-0.2779, acc-0.9234\n",
      "Iter-57220, train loss-0.1808, acc-0.9400, valid loss-0.2671, acc-0.9260, test loss-0.2778, acc-0.9234\n",
      "Iter-57230, train loss-0.2057, acc-0.9600, valid loss-0.2671, acc-0.9260, test loss-0.2778, acc-0.9233\n",
      "Iter-57240, train loss-0.2093, acc-0.9600, valid loss-0.2671, acc-0.9260, test loss-0.2778, acc-0.9232\n",
      "Iter-57250, train loss-0.3059, acc-0.9000, valid loss-0.2670, acc-0.9258, test loss-0.2778, acc-0.9232\n",
      "Iter-57260, train loss-0.1742, acc-0.9400, valid loss-0.2670, acc-0.9258, test loss-0.2777, acc-0.9232\n",
      "Iter-57270, train loss-0.2232, acc-0.9000, valid loss-0.2670, acc-0.9262, test loss-0.2777, acc-0.9234\n",
      "Iter-57280, train loss-0.2070, acc-0.9200, valid loss-0.2670, acc-0.9262, test loss-0.2776, acc-0.9233\n",
      "Iter-57290, train loss-0.1307, acc-0.9800, valid loss-0.2671, acc-0.9262, test loss-0.2776, acc-0.9232\n",
      "Iter-57300, train loss-0.1859, acc-0.9400, valid loss-0.2670, acc-0.9262, test loss-0.2776, acc-0.9233\n",
      "Iter-57310, train loss-0.2807, acc-0.9200, valid loss-0.2670, acc-0.9262, test loss-0.2775, acc-0.9235\n",
      "Iter-57320, train loss-0.3431, acc-0.8800, valid loss-0.2669, acc-0.9266, test loss-0.2775, acc-0.9232\n",
      "Iter-57330, train loss-0.2449, acc-0.9400, valid loss-0.2670, acc-0.9264, test loss-0.2774, acc-0.9232\n",
      "Iter-57340, train loss-0.3432, acc-0.8800, valid loss-0.2670, acc-0.9258, test loss-0.2774, acc-0.9236\n",
      "Iter-57350, train loss-0.5174, acc-0.9000, valid loss-0.2670, acc-0.9260, test loss-0.2774, acc-0.9236\n",
      "Iter-57360, train loss-0.3833, acc-0.8800, valid loss-0.2669, acc-0.9260, test loss-0.2773, acc-0.9235\n",
      "Iter-57370, train loss-0.4602, acc-0.8600, valid loss-0.2669, acc-0.9262, test loss-0.2773, acc-0.9235\n",
      "Iter-57380, train loss-0.2943, acc-0.9200, valid loss-0.2669, acc-0.9262, test loss-0.2773, acc-0.9235\n",
      "Iter-57390, train loss-0.1767, acc-0.9200, valid loss-0.2669, acc-0.9256, test loss-0.2773, acc-0.9235\n",
      "Iter-57400, train loss-0.3332, acc-0.8800, valid loss-0.2668, acc-0.9256, test loss-0.2772, acc-0.9236\n",
      "Iter-57410, train loss-0.1370, acc-0.9800, valid loss-0.2668, acc-0.9262, test loss-0.2772, acc-0.9237\n",
      "Iter-57420, train loss-0.5095, acc-0.8000, valid loss-0.2668, acc-0.9258, test loss-0.2772, acc-0.9237\n",
      "Iter-57430, train loss-0.1994, acc-0.9600, valid loss-0.2668, acc-0.9256, test loss-0.2772, acc-0.9238\n",
      "Iter-57440, train loss-0.2749, acc-0.8600, valid loss-0.2668, acc-0.9258, test loss-0.2772, acc-0.9234\n",
      "Iter-57450, train loss-0.2505, acc-0.9400, valid loss-0.2668, acc-0.9260, test loss-0.2772, acc-0.9235\n",
      "Iter-57460, train loss-0.2914, acc-0.9200, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9237\n",
      "Iter-57470, train loss-0.6278, acc-0.8400, valid loss-0.2667, acc-0.9254, test loss-0.2772, acc-0.9237\n",
      "Iter-57480, train loss-0.3286, acc-0.8800, valid loss-0.2667, acc-0.9256, test loss-0.2772, acc-0.9235\n",
      "Iter-57490, train loss-0.2076, acc-0.9400, valid loss-0.2667, acc-0.9256, test loss-0.2771, acc-0.9235\n",
      "Iter-57500, train loss-0.2458, acc-0.9200, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9236\n",
      "Iter-57510, train loss-0.2312, acc-0.9200, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9235\n",
      "Iter-57520, train loss-0.1601, acc-0.9400, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9236\n",
      "Iter-57530, train loss-0.1837, acc-0.9600, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9236\n",
      "Iter-57540, train loss-0.2630, acc-0.9000, valid loss-0.2668, acc-0.9258, test loss-0.2771, acc-0.9236\n",
      "Iter-57550, train loss-0.4074, acc-0.8800, valid loss-0.2668, acc-0.9256, test loss-0.2770, acc-0.9237\n",
      "Iter-57560, train loss-0.1605, acc-0.9400, valid loss-0.2667, acc-0.9256, test loss-0.2771, acc-0.9234\n",
      "Iter-57570, train loss-0.3941, acc-0.9200, valid loss-0.2667, acc-0.9256, test loss-0.2770, acc-0.9236\n",
      "Iter-57580, train loss-0.3153, acc-0.9200, valid loss-0.2667, acc-0.9258, test loss-0.2770, acc-0.9233\n",
      "Iter-57590, train loss-0.3395, acc-0.9400, valid loss-0.2667, acc-0.9256, test loss-0.2769, acc-0.9233\n",
      "Iter-57600, train loss-0.2253, acc-0.9400, valid loss-0.2666, acc-0.9260, test loss-0.2769, acc-0.9232\n",
      "Iter-57610, train loss-0.3178, acc-0.9400, valid loss-0.2666, acc-0.9260, test loss-0.2769, acc-0.9235\n",
      "Iter-57620, train loss-0.3241, acc-0.9000, valid loss-0.2666, acc-0.9260, test loss-0.2769, acc-0.9238\n",
      "Iter-57630, train loss-0.1895, acc-0.9400, valid loss-0.2667, acc-0.9260, test loss-0.2768, acc-0.9237\n",
      "Iter-57640, train loss-0.2321, acc-0.9600, valid loss-0.2667, acc-0.9260, test loss-0.2769, acc-0.9237\n",
      "Iter-57650, train loss-0.4595, acc-0.8800, valid loss-0.2667, acc-0.9260, test loss-0.2769, acc-0.9234\n",
      "Iter-57660, train loss-0.3522, acc-0.9200, valid loss-0.2666, acc-0.9256, test loss-0.2769, acc-0.9232\n",
      "Iter-57670, train loss-0.2379, acc-0.9000, valid loss-0.2667, acc-0.9260, test loss-0.2768, acc-0.9232\n",
      "Iter-57680, train loss-0.3192, acc-0.9400, valid loss-0.2667, acc-0.9258, test loss-0.2768, acc-0.9235\n",
      "Iter-57690, train loss-0.2338, acc-0.9400, valid loss-0.2666, acc-0.9258, test loss-0.2768, acc-0.9233\n",
      "Iter-57700, train loss-0.1501, acc-0.9800, valid loss-0.2666, acc-0.9258, test loss-0.2767, acc-0.9232\n",
      "Iter-57710, train loss-0.2959, acc-0.9200, valid loss-0.2666, acc-0.9258, test loss-0.2767, acc-0.9232\n",
      "Iter-57720, train loss-0.3570, acc-0.8800, valid loss-0.2666, acc-0.9258, test loss-0.2767, acc-0.9236\n",
      "Iter-57730, train loss-0.3569, acc-0.8600, valid loss-0.2666, acc-0.9256, test loss-0.2767, acc-0.9234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-57740, train loss-0.2321, acc-0.9200, valid loss-0.2666, acc-0.9258, test loss-0.2767, acc-0.9233\n",
      "Iter-57750, train loss-0.1774, acc-0.9800, valid loss-0.2666, acc-0.9262, test loss-0.2767, acc-0.9233\n",
      "Iter-57760, train loss-0.1673, acc-0.9800, valid loss-0.2666, acc-0.9260, test loss-0.2767, acc-0.9234\n",
      "Iter-57770, train loss-0.1457, acc-0.9600, valid loss-0.2665, acc-0.9258, test loss-0.2767, acc-0.9233\n",
      "Iter-57780, train loss-0.3403, acc-0.9200, valid loss-0.2666, acc-0.9260, test loss-0.2767, acc-0.9233\n",
      "Iter-57790, train loss-0.2854, acc-0.9000, valid loss-0.2665, acc-0.9260, test loss-0.2767, acc-0.9235\n",
      "Iter-57800, train loss-0.3128, acc-0.9000, valid loss-0.2665, acc-0.9260, test loss-0.2768, acc-0.9232\n",
      "Iter-57810, train loss-0.4916, acc-0.8600, valid loss-0.2664, acc-0.9258, test loss-0.2768, acc-0.9234\n",
      "Iter-57820, train loss-0.2829, acc-0.8800, valid loss-0.2663, acc-0.9258, test loss-0.2768, acc-0.9234\n",
      "Iter-57830, train loss-0.2569, acc-0.9200, valid loss-0.2663, acc-0.9258, test loss-0.2768, acc-0.9234\n",
      "Iter-57840, train loss-0.3613, acc-0.8600, valid loss-0.2663, acc-0.9258, test loss-0.2767, acc-0.9230\n",
      "Iter-57850, train loss-0.1302, acc-0.9800, valid loss-0.2663, acc-0.9258, test loss-0.2767, acc-0.9231\n",
      "Iter-57860, train loss-0.2252, acc-0.9400, valid loss-0.2662, acc-0.9258, test loss-0.2767, acc-0.9232\n",
      "Iter-57870, train loss-0.2227, acc-0.9000, valid loss-0.2663, acc-0.9260, test loss-0.2767, acc-0.9230\n",
      "Iter-57880, train loss-0.3419, acc-0.8800, valid loss-0.2662, acc-0.9260, test loss-0.2767, acc-0.9231\n",
      "Iter-57890, train loss-0.2100, acc-0.9200, valid loss-0.2662, acc-0.9260, test loss-0.2767, acc-0.9230\n",
      "Iter-57900, train loss-0.1959, acc-0.9400, valid loss-0.2662, acc-0.9260, test loss-0.2767, acc-0.9230\n",
      "Iter-57910, train loss-0.3099, acc-0.8800, valid loss-0.2662, acc-0.9262, test loss-0.2767, acc-0.9232\n",
      "Iter-57920, train loss-0.1859, acc-0.9600, valid loss-0.2662, acc-0.9264, test loss-0.2766, acc-0.9229\n",
      "Iter-57930, train loss-0.2273, acc-0.8800, valid loss-0.2662, acc-0.9262, test loss-0.2766, acc-0.9231\n",
      "Iter-57940, train loss-0.1814, acc-0.9600, valid loss-0.2661, acc-0.9260, test loss-0.2766, acc-0.9229\n",
      "Iter-57950, train loss-0.2748, acc-0.9200, valid loss-0.2661, acc-0.9264, test loss-0.2766, acc-0.9231\n",
      "Iter-57960, train loss-0.3131, acc-0.9200, valid loss-0.2661, acc-0.9264, test loss-0.2766, acc-0.9231\n",
      "Iter-57970, train loss-0.3760, acc-0.9000, valid loss-0.2662, acc-0.9262, test loss-0.2766, acc-0.9231\n",
      "Iter-57980, train loss-0.2510, acc-0.9200, valid loss-0.2661, acc-0.9264, test loss-0.2766, acc-0.9231\n",
      "Iter-57990, train loss-0.2829, acc-0.9200, valid loss-0.2661, acc-0.9262, test loss-0.2766, acc-0.9231\n",
      "Iter-58000, train loss-0.2170, acc-0.9200, valid loss-0.2661, acc-0.9264, test loss-0.2766, acc-0.9231\n",
      "Iter-58010, train loss-0.3935, acc-0.8800, valid loss-0.2660, acc-0.9266, test loss-0.2765, acc-0.9235\n",
      "Iter-58020, train loss-0.2182, acc-0.9200, valid loss-0.2660, acc-0.9266, test loss-0.2766, acc-0.9234\n",
      "Iter-58030, train loss-0.2959, acc-0.9200, valid loss-0.2660, acc-0.9266, test loss-0.2765, acc-0.9235\n",
      "Iter-58040, train loss-0.2465, acc-0.9600, valid loss-0.2659, acc-0.9266, test loss-0.2765, acc-0.9233\n",
      "Iter-58050, train loss-0.2676, acc-0.9400, valid loss-0.2660, acc-0.9264, test loss-0.2765, acc-0.9235\n",
      "Iter-58060, train loss-0.2427, acc-0.9400, valid loss-0.2659, acc-0.9266, test loss-0.2765, acc-0.9234\n",
      "Iter-58070, train loss-0.0676, acc-1.0000, valid loss-0.2659, acc-0.9266, test loss-0.2765, acc-0.9233\n",
      "Iter-58080, train loss-0.1704, acc-0.9600, valid loss-0.2658, acc-0.9264, test loss-0.2765, acc-0.9234\n",
      "Iter-58090, train loss-0.3782, acc-0.8400, valid loss-0.2658, acc-0.9264, test loss-0.2765, acc-0.9233\n",
      "Iter-58100, train loss-0.2403, acc-0.9400, valid loss-0.2657, acc-0.9262, test loss-0.2764, acc-0.9232\n",
      "Iter-58110, train loss-0.3848, acc-0.9000, valid loss-0.2657, acc-0.9260, test loss-0.2764, acc-0.9232\n",
      "Iter-58120, train loss-0.1617, acc-0.9800, valid loss-0.2657, acc-0.9262, test loss-0.2764, acc-0.9234\n",
      "Iter-58130, train loss-0.2666, acc-0.9600, valid loss-0.2656, acc-0.9262, test loss-0.2764, acc-0.9236\n",
      "Iter-58140, train loss-0.1786, acc-0.9400, valid loss-0.2655, acc-0.9260, test loss-0.2763, acc-0.9236\n",
      "Iter-58150, train loss-0.2707, acc-0.9200, valid loss-0.2655, acc-0.9262, test loss-0.2763, acc-0.9233\n",
      "Iter-58160, train loss-0.2037, acc-0.9600, valid loss-0.2655, acc-0.9262, test loss-0.2762, acc-0.9232\n",
      "Iter-58170, train loss-0.2589, acc-0.9200, valid loss-0.2654, acc-0.9260, test loss-0.2763, acc-0.9232\n",
      "Iter-58180, train loss-0.1825, acc-0.9400, valid loss-0.2654, acc-0.9260, test loss-0.2763, acc-0.9235\n",
      "Iter-58190, train loss-0.2766, acc-0.9000, valid loss-0.2654, acc-0.9262, test loss-0.2762, acc-0.9231\n",
      "Iter-58200, train loss-0.1628, acc-0.9600, valid loss-0.2654, acc-0.9264, test loss-0.2762, acc-0.9233\n",
      "Iter-58210, train loss-0.3580, acc-0.8800, valid loss-0.2654, acc-0.9264, test loss-0.2762, acc-0.9234\n",
      "Iter-58220, train loss-0.3135, acc-0.9200, valid loss-0.2654, acc-0.9262, test loss-0.2762, acc-0.9232\n",
      "Iter-58230, train loss-0.3723, acc-0.9000, valid loss-0.2654, acc-0.9262, test loss-0.2762, acc-0.9232\n",
      "Iter-58240, train loss-0.1837, acc-0.9800, valid loss-0.2653, acc-0.9262, test loss-0.2762, acc-0.9232\n",
      "Iter-58250, train loss-0.3160, acc-0.9000, valid loss-0.2653, acc-0.9262, test loss-0.2762, acc-0.9230\n",
      "Iter-58260, train loss-0.2720, acc-0.9200, valid loss-0.2652, acc-0.9262, test loss-0.2761, acc-0.9231\n",
      "Iter-58270, train loss-0.1748, acc-0.9400, valid loss-0.2652, acc-0.9262, test loss-0.2761, acc-0.9231\n",
      "Iter-58280, train loss-0.2973, acc-0.9200, valid loss-0.2651, acc-0.9260, test loss-0.2761, acc-0.9230\n",
      "Iter-58290, train loss-0.1998, acc-0.9400, valid loss-0.2651, acc-0.9258, test loss-0.2761, acc-0.9233\n",
      "Iter-58300, train loss-0.3486, acc-0.9000, valid loss-0.2651, acc-0.9258, test loss-0.2761, acc-0.9230\n",
      "Iter-58310, train loss-0.2034, acc-0.9400, valid loss-0.2651, acc-0.9258, test loss-0.2760, acc-0.9227\n",
      "Iter-58320, train loss-0.3069, acc-0.9200, valid loss-0.2651, acc-0.9258, test loss-0.2761, acc-0.9227\n",
      "Iter-58330, train loss-0.4972, acc-0.8800, valid loss-0.2651, acc-0.9258, test loss-0.2760, acc-0.9228\n",
      "Iter-58340, train loss-0.2296, acc-0.9400, valid loss-0.2650, acc-0.9258, test loss-0.2760, acc-0.9230\n",
      "Iter-58350, train loss-0.2757, acc-0.9200, valid loss-0.2650, acc-0.9262, test loss-0.2760, acc-0.9228\n",
      "Iter-58360, train loss-0.2467, acc-0.9000, valid loss-0.2650, acc-0.9260, test loss-0.2760, acc-0.9228\n",
      "Iter-58370, train loss-0.2281, acc-0.9600, valid loss-0.2650, acc-0.9260, test loss-0.2760, acc-0.9229\n",
      "Iter-58380, train loss-0.2535, acc-0.9000, valid loss-0.2649, acc-0.9262, test loss-0.2760, acc-0.9228\n",
      "Iter-58390, train loss-0.2459, acc-0.9400, valid loss-0.2650, acc-0.9262, test loss-0.2760, acc-0.9232\n",
      "Iter-58400, train loss-0.2307, acc-0.9400, valid loss-0.2649, acc-0.9262, test loss-0.2760, acc-0.9229\n",
      "Iter-58410, train loss-0.2484, acc-0.9400, valid loss-0.2649, acc-0.9266, test loss-0.2760, acc-0.9228\n",
      "Iter-58420, train loss-0.2903, acc-0.9200, valid loss-0.2649, acc-0.9264, test loss-0.2760, acc-0.9228\n",
      "Iter-58430, train loss-0.1743, acc-0.9400, valid loss-0.2648, acc-0.9262, test loss-0.2760, acc-0.9233\n",
      "Iter-58440, train loss-0.1950, acc-0.9600, valid loss-0.2648, acc-0.9260, test loss-0.2759, acc-0.9233\n",
      "Iter-58450, train loss-0.2551, acc-0.9200, valid loss-0.2648, acc-0.9260, test loss-0.2759, acc-0.9231\n",
      "Iter-58460, train loss-0.2529, acc-0.9400, valid loss-0.2648, acc-0.9260, test loss-0.2759, acc-0.9231\n",
      "Iter-58470, train loss-0.3484, acc-0.8800, valid loss-0.2648, acc-0.9258, test loss-0.2759, acc-0.9229\n",
      "Iter-58480, train loss-0.2320, acc-0.9200, valid loss-0.2648, acc-0.9258, test loss-0.2759, acc-0.9232\n",
      "Iter-58490, train loss-0.1441, acc-0.9800, valid loss-0.2647, acc-0.9260, test loss-0.2759, acc-0.9231\n",
      "Iter-58500, train loss-0.3728, acc-0.9000, valid loss-0.2647, acc-0.9258, test loss-0.2759, acc-0.9235\n",
      "Iter-58510, train loss-0.2517, acc-0.9400, valid loss-0.2647, acc-0.9254, test loss-0.2758, acc-0.9232\n",
      "Iter-58520, train loss-0.2198, acc-0.9400, valid loss-0.2647, acc-0.9256, test loss-0.2757, acc-0.9234\n",
      "Iter-58530, train loss-0.3397, acc-0.8600, valid loss-0.2646, acc-0.9256, test loss-0.2757, acc-0.9234\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-58540, train loss-0.4494, acc-0.8400, valid loss-0.2646, acc-0.9252, test loss-0.2757, acc-0.9237\n",
      "Iter-58550, train loss-0.3168, acc-0.9000, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9236\n",
      "Iter-58560, train loss-0.3638, acc-0.9000, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9236\n",
      "Iter-58570, train loss-0.4842, acc-0.9000, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9236\n",
      "Iter-58580, train loss-0.2864, acc-0.9600, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9236\n",
      "Iter-58590, train loss-0.3302, acc-0.9000, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9235\n",
      "Iter-58600, train loss-0.2580, acc-0.9200, valid loss-0.2646, acc-0.9252, test loss-0.2756, acc-0.9239\n",
      "Iter-58610, train loss-0.4272, acc-0.9000, valid loss-0.2646, acc-0.9256, test loss-0.2755, acc-0.9238\n",
      "Iter-58620, train loss-0.2465, acc-0.9400, valid loss-0.2646, acc-0.9254, test loss-0.2756, acc-0.9239\n",
      "Iter-58630, train loss-0.1145, acc-0.9600, valid loss-0.2646, acc-0.9250, test loss-0.2756, acc-0.9240\n",
      "Iter-58640, train loss-0.3921, acc-0.9000, valid loss-0.2646, acc-0.9250, test loss-0.2756, acc-0.9240\n",
      "Iter-58650, train loss-0.2112, acc-0.9400, valid loss-0.2646, acc-0.9254, test loss-0.2756, acc-0.9237\n",
      "Iter-58660, train loss-0.3943, acc-0.9200, valid loss-0.2646, acc-0.9250, test loss-0.2756, acc-0.9235\n",
      "Iter-58670, train loss-0.3540, acc-0.8400, valid loss-0.2645, acc-0.9252, test loss-0.2756, acc-0.9238\n",
      "Iter-58680, train loss-0.1816, acc-0.9600, valid loss-0.2645, acc-0.9252, test loss-0.2755, acc-0.9239\n",
      "Iter-58690, train loss-0.2559, acc-0.9800, valid loss-0.2645, acc-0.9250, test loss-0.2755, acc-0.9239\n",
      "Iter-58700, train loss-0.4319, acc-0.8400, valid loss-0.2645, acc-0.9250, test loss-0.2755, acc-0.9240\n",
      "Iter-58710, train loss-0.2695, acc-0.9200, valid loss-0.2644, acc-0.9250, test loss-0.2755, acc-0.9240\n",
      "Iter-58720, train loss-0.4349, acc-0.8800, valid loss-0.2644, acc-0.9250, test loss-0.2755, acc-0.9238\n",
      "Iter-58730, train loss-0.2313, acc-0.9600, valid loss-0.2644, acc-0.9246, test loss-0.2755, acc-0.9240\n",
      "Iter-58740, train loss-0.4068, acc-0.8400, valid loss-0.2644, acc-0.9254, test loss-0.2755, acc-0.9238\n",
      "Iter-58750, train loss-0.3747, acc-0.9000, valid loss-0.2644, acc-0.9252, test loss-0.2754, acc-0.9238\n",
      "Iter-58760, train loss-0.2473, acc-0.9000, valid loss-0.2644, acc-0.9252, test loss-0.2754, acc-0.9239\n",
      "Iter-58770, train loss-0.4449, acc-0.8800, valid loss-0.2644, acc-0.9250, test loss-0.2754, acc-0.9239\n",
      "Iter-58780, train loss-0.3051, acc-0.9400, valid loss-0.2643, acc-0.9252, test loss-0.2753, acc-0.9240\n",
      "Iter-58790, train loss-0.1190, acc-0.9800, valid loss-0.2643, acc-0.9254, test loss-0.2753, acc-0.9238\n",
      "Iter-58800, train loss-0.1481, acc-0.9800, valid loss-0.2643, acc-0.9248, test loss-0.2754, acc-0.9239\n",
      "Iter-58810, train loss-0.3288, acc-0.9200, valid loss-0.2643, acc-0.9252, test loss-0.2754, acc-0.9239\n",
      "Iter-58820, train loss-0.2063, acc-0.9200, valid loss-0.2643, acc-0.9252, test loss-0.2753, acc-0.9237\n",
      "Iter-58830, train loss-0.4079, acc-0.9200, valid loss-0.2643, acc-0.9254, test loss-0.2753, acc-0.9237\n",
      "Iter-58840, train loss-0.4017, acc-0.9200, valid loss-0.2642, acc-0.9250, test loss-0.2753, acc-0.9236\n",
      "Iter-58850, train loss-0.2837, acc-0.8400, valid loss-0.2642, acc-0.9252, test loss-0.2753, acc-0.9237\n",
      "Iter-58860, train loss-0.2717, acc-0.9000, valid loss-0.2641, acc-0.9254, test loss-0.2752, acc-0.9237\n",
      "Iter-58870, train loss-0.4546, acc-0.8800, valid loss-0.2641, acc-0.9254, test loss-0.2752, acc-0.9237\n",
      "Iter-58880, train loss-0.2669, acc-0.9000, valid loss-0.2641, acc-0.9258, test loss-0.2752, acc-0.9237\n",
      "Iter-58890, train loss-0.3814, acc-0.9400, valid loss-0.2641, acc-0.9258, test loss-0.2752, acc-0.9238\n",
      "Iter-58900, train loss-0.2372, acc-0.9200, valid loss-0.2641, acc-0.9258, test loss-0.2752, acc-0.9237\n",
      "Iter-58910, train loss-0.1965, acc-0.9400, valid loss-0.2640, acc-0.9258, test loss-0.2752, acc-0.9239\n",
      "Iter-58920, train loss-0.2808, acc-0.9600, valid loss-0.2640, acc-0.9258, test loss-0.2751, acc-0.9238\n",
      "Iter-58930, train loss-0.2872, acc-0.8800, valid loss-0.2641, acc-0.9258, test loss-0.2751, acc-0.9237\n",
      "Iter-58940, train loss-0.3664, acc-0.8400, valid loss-0.2640, acc-0.9258, test loss-0.2751, acc-0.9235\n",
      "Iter-58950, train loss-0.2464, acc-0.9400, valid loss-0.2641, acc-0.9258, test loss-0.2751, acc-0.9235\n",
      "Iter-58960, train loss-0.4000, acc-0.8400, valid loss-0.2641, acc-0.9256, test loss-0.2751, acc-0.9236\n",
      "Iter-58970, train loss-0.3180, acc-0.8800, valid loss-0.2641, acc-0.9256, test loss-0.2750, acc-0.9236\n",
      "Iter-58980, train loss-0.3086, acc-0.9000, valid loss-0.2640, acc-0.9258, test loss-0.2751, acc-0.9237\n",
      "Iter-58990, train loss-0.4606, acc-0.9000, valid loss-0.2641, acc-0.9256, test loss-0.2751, acc-0.9237\n",
      "Iter-59000, train loss-0.2972, acc-0.9000, valid loss-0.2640, acc-0.9260, test loss-0.2751, acc-0.9237\n",
      "Iter-59010, train loss-0.4158, acc-0.8800, valid loss-0.2640, acc-0.9262, test loss-0.2751, acc-0.9235\n",
      "Iter-59020, train loss-0.2380, acc-0.9400, valid loss-0.2640, acc-0.9262, test loss-0.2751, acc-0.9238\n",
      "Iter-59030, train loss-0.1682, acc-0.9800, valid loss-0.2640, acc-0.9264, test loss-0.2751, acc-0.9238\n",
      "Iter-59040, train loss-0.3742, acc-0.8600, valid loss-0.2640, acc-0.9262, test loss-0.2751, acc-0.9236\n",
      "Iter-59050, train loss-0.2354, acc-0.9200, valid loss-0.2639, acc-0.9264, test loss-0.2751, acc-0.9236\n",
      "Iter-59060, train loss-0.2901, acc-0.9200, valid loss-0.2639, acc-0.9264, test loss-0.2751, acc-0.9236\n",
      "Iter-59070, train loss-0.2169, acc-0.9400, valid loss-0.2639, acc-0.9264, test loss-0.2750, acc-0.9237\n",
      "Iter-59080, train loss-0.4636, acc-0.8800, valid loss-0.2639, acc-0.9264, test loss-0.2750, acc-0.9233\n",
      "Iter-59090, train loss-0.2259, acc-0.9200, valid loss-0.2639, acc-0.9264, test loss-0.2750, acc-0.9237\n",
      "Iter-59100, train loss-0.2687, acc-0.9200, valid loss-0.2639, acc-0.9264, test loss-0.2750, acc-0.9238\n",
      "Iter-59110, train loss-0.2347, acc-0.9400, valid loss-0.2639, acc-0.9264, test loss-0.2749, acc-0.9238\n",
      "Iter-59120, train loss-0.3650, acc-0.8600, valid loss-0.2638, acc-0.9264, test loss-0.2749, acc-0.9241\n",
      "Iter-59130, train loss-0.2705, acc-0.9400, valid loss-0.2637, acc-0.9264, test loss-0.2749, acc-0.9240\n",
      "Iter-59140, train loss-0.3256, acc-0.9600, valid loss-0.2637, acc-0.9264, test loss-0.2748, acc-0.9239\n",
      "Iter-59150, train loss-0.1942, acc-0.9600, valid loss-0.2637, acc-0.9264, test loss-0.2748, acc-0.9236\n",
      "Iter-59160, train loss-0.3043, acc-0.9000, valid loss-0.2637, acc-0.9264, test loss-0.2748, acc-0.9235\n",
      "Iter-59170, train loss-0.1626, acc-0.9400, valid loss-0.2637, acc-0.9262, test loss-0.2748, acc-0.9236\n",
      "Iter-59180, train loss-0.2936, acc-0.9400, valid loss-0.2637, acc-0.9264, test loss-0.2748, acc-0.9236\n",
      "Iter-59190, train loss-0.2550, acc-0.9400, valid loss-0.2637, acc-0.9264, test loss-0.2748, acc-0.9237\n",
      "Iter-59200, train loss-0.3683, acc-0.8800, valid loss-0.2636, acc-0.9264, test loss-0.2748, acc-0.9237\n",
      "Iter-59210, train loss-0.3701, acc-0.9000, valid loss-0.2635, acc-0.9268, test loss-0.2748, acc-0.9237\n",
      "Iter-59220, train loss-0.5092, acc-0.8000, valid loss-0.2636, acc-0.9268, test loss-0.2748, acc-0.9237\n",
      "Iter-59230, train loss-0.2464, acc-0.9200, valid loss-0.2636, acc-0.9266, test loss-0.2747, acc-0.9237\n",
      "Iter-59240, train loss-0.1630, acc-0.9800, valid loss-0.2635, acc-0.9264, test loss-0.2747, acc-0.9238\n",
      "Iter-59250, train loss-0.3840, acc-0.9200, valid loss-0.2635, acc-0.9266, test loss-0.2748, acc-0.9238\n",
      "Iter-59260, train loss-0.3194, acc-0.8600, valid loss-0.2636, acc-0.9260, test loss-0.2747, acc-0.9237\n",
      "Iter-59270, train loss-0.2172, acc-0.9400, valid loss-0.2635, acc-0.9266, test loss-0.2747, acc-0.9240\n",
      "Iter-59280, train loss-0.1564, acc-0.9400, valid loss-0.2636, acc-0.9264, test loss-0.2747, acc-0.9237\n",
      "Iter-59290, train loss-0.1270, acc-0.9800, valid loss-0.2635, acc-0.9260, test loss-0.2747, acc-0.9237\n",
      "Iter-59300, train loss-0.4099, acc-0.8800, valid loss-0.2635, acc-0.9264, test loss-0.2747, acc-0.9236\n",
      "Iter-59310, train loss-0.3646, acc-0.8600, valid loss-0.2636, acc-0.9262, test loss-0.2746, acc-0.9236\n",
      "Iter-59320, train loss-0.4963, acc-0.8800, valid loss-0.2635, acc-0.9262, test loss-0.2746, acc-0.9236\n",
      "Iter-59330, train loss-0.0996, acc-0.9800, valid loss-0.2635, acc-0.9262, test loss-0.2746, acc-0.9240\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-59340, train loss-0.3636, acc-0.9200, valid loss-0.2634, acc-0.9262, test loss-0.2746, acc-0.9238\n",
      "Iter-59350, train loss-0.1556, acc-0.9800, valid loss-0.2634, acc-0.9266, test loss-0.2746, acc-0.9237\n",
      "Iter-59360, train loss-0.2609, acc-0.9200, valid loss-0.2635, acc-0.9264, test loss-0.2745, acc-0.9239\n",
      "Iter-59370, train loss-0.4048, acc-0.9200, valid loss-0.2635, acc-0.9264, test loss-0.2745, acc-0.9240\n",
      "Iter-59380, train loss-0.2057, acc-0.9600, valid loss-0.2634, acc-0.9270, test loss-0.2745, acc-0.9240\n",
      "Iter-59390, train loss-0.2029, acc-0.9600, valid loss-0.2634, acc-0.9268, test loss-0.2745, acc-0.9242\n",
      "Iter-59400, train loss-0.3542, acc-0.8800, valid loss-0.2634, acc-0.9274, test loss-0.2745, acc-0.9243\n",
      "Iter-59410, train loss-0.2851, acc-0.9200, valid loss-0.2634, acc-0.9272, test loss-0.2745, acc-0.9242\n",
      "Iter-59420, train loss-0.4460, acc-0.8800, valid loss-0.2633, acc-0.9272, test loss-0.2745, acc-0.9244\n",
      "Iter-59430, train loss-0.2042, acc-0.9400, valid loss-0.2633, acc-0.9272, test loss-0.2744, acc-0.9241\n",
      "Iter-59440, train loss-0.3603, acc-0.9000, valid loss-0.2633, acc-0.9278, test loss-0.2744, acc-0.9241\n",
      "Iter-59450, train loss-0.3918, acc-0.8600, valid loss-0.2633, acc-0.9276, test loss-0.2744, acc-0.9240\n",
      "Iter-59460, train loss-0.1614, acc-0.9400, valid loss-0.2632, acc-0.9276, test loss-0.2744, acc-0.9240\n",
      "Iter-59470, train loss-0.4908, acc-0.8800, valid loss-0.2632, acc-0.9276, test loss-0.2743, acc-0.9240\n",
      "Iter-59480, train loss-0.3152, acc-0.8800, valid loss-0.2632, acc-0.9278, test loss-0.2743, acc-0.9240\n",
      "Iter-59490, train loss-0.1897, acc-0.9800, valid loss-0.2632, acc-0.9276, test loss-0.2743, acc-0.9239\n",
      "Iter-59500, train loss-0.1464, acc-0.9600, valid loss-0.2632, acc-0.9274, test loss-0.2742, acc-0.9240\n",
      "Iter-59510, train loss-0.2720, acc-0.9400, valid loss-0.2632, acc-0.9274, test loss-0.2742, acc-0.9241\n",
      "Iter-59520, train loss-0.3218, acc-0.8800, valid loss-0.2631, acc-0.9274, test loss-0.2742, acc-0.9242\n",
      "Iter-59530, train loss-0.2511, acc-0.9400, valid loss-0.2631, acc-0.9276, test loss-0.2742, acc-0.9241\n",
      "Iter-59540, train loss-0.3514, acc-0.8800, valid loss-0.2631, acc-0.9276, test loss-0.2742, acc-0.9241\n",
      "Iter-59550, train loss-0.3828, acc-0.8400, valid loss-0.2630, acc-0.9274, test loss-0.2742, acc-0.9243\n",
      "Iter-59560, train loss-0.3814, acc-0.8600, valid loss-0.2630, acc-0.9272, test loss-0.2741, acc-0.9243\n",
      "Iter-59570, train loss-0.4481, acc-0.9200, valid loss-0.2629, acc-0.9272, test loss-0.2741, acc-0.9243\n",
      "Iter-59580, train loss-0.2539, acc-0.9000, valid loss-0.2629, acc-0.9274, test loss-0.2742, acc-0.9241\n",
      "Iter-59590, train loss-0.4242, acc-0.8400, valid loss-0.2629, acc-0.9272, test loss-0.2742, acc-0.9243\n",
      "Iter-59600, train loss-0.1789, acc-0.9600, valid loss-0.2629, acc-0.9270, test loss-0.2742, acc-0.9242\n",
      "Iter-59610, train loss-0.2051, acc-0.9400, valid loss-0.2629, acc-0.9272, test loss-0.2741, acc-0.9244\n",
      "Iter-59620, train loss-0.1354, acc-0.9600, valid loss-0.2629, acc-0.9268, test loss-0.2740, acc-0.9242\n",
      "Iter-59630, train loss-0.1977, acc-0.9600, valid loss-0.2629, acc-0.9268, test loss-0.2740, acc-0.9244\n",
      "Iter-59640, train loss-0.3830, acc-0.8800, valid loss-0.2629, acc-0.9272, test loss-0.2740, acc-0.9245\n",
      "Iter-59650, train loss-0.2163, acc-0.9200, valid loss-0.2628, acc-0.9270, test loss-0.2740, acc-0.9245\n",
      "Iter-59660, train loss-0.3135, acc-0.9200, valid loss-0.2628, acc-0.9272, test loss-0.2739, acc-0.9244\n",
      "Iter-59670, train loss-0.2215, acc-0.9200, valid loss-0.2628, acc-0.9270, test loss-0.2739, acc-0.9245\n",
      "Iter-59680, train loss-0.3421, acc-0.9000, valid loss-0.2628, acc-0.9272, test loss-0.2738, acc-0.9246\n",
      "Iter-59690, train loss-0.5921, acc-0.9000, valid loss-0.2628, acc-0.9272, test loss-0.2738, acc-0.9247\n",
      "Iter-59700, train loss-0.1371, acc-0.9800, valid loss-0.2628, acc-0.9268, test loss-0.2737, acc-0.9246\n",
      "Iter-59710, train loss-0.1761, acc-0.9600, valid loss-0.2628, acc-0.9266, test loss-0.2737, acc-0.9240\n",
      "Iter-59720, train loss-0.4599, acc-0.8400, valid loss-0.2627, acc-0.9266, test loss-0.2737, acc-0.9242\n",
      "Iter-59730, train loss-0.2055, acc-0.9200, valid loss-0.2627, acc-0.9268, test loss-0.2737, acc-0.9241\n",
      "Iter-59740, train loss-0.1278, acc-0.9200, valid loss-0.2627, acc-0.9268, test loss-0.2737, acc-0.9241\n",
      "Iter-59750, train loss-0.2574, acc-0.9000, valid loss-0.2627, acc-0.9266, test loss-0.2737, acc-0.9242\n",
      "Iter-59760, train loss-0.2177, acc-0.9400, valid loss-0.2627, acc-0.9266, test loss-0.2736, acc-0.9244\n",
      "Iter-59770, train loss-0.2102, acc-0.9400, valid loss-0.2628, acc-0.9270, test loss-0.2736, acc-0.9244\n",
      "Iter-59780, train loss-0.0919, acc-0.9800, valid loss-0.2627, acc-0.9268, test loss-0.2736, acc-0.9241\n",
      "Iter-59790, train loss-0.2808, acc-0.9200, valid loss-0.2627, acc-0.9268, test loss-0.2737, acc-0.9242\n",
      "Iter-59800, train loss-0.4855, acc-0.9000, valid loss-0.2627, acc-0.9268, test loss-0.2737, acc-0.9241\n",
      "Iter-59810, train loss-0.1544, acc-0.9600, valid loss-0.2627, acc-0.9262, test loss-0.2737, acc-0.9243\n",
      "Iter-59820, train loss-0.3431, acc-0.9200, valid loss-0.2627, acc-0.9268, test loss-0.2736, acc-0.9243\n",
      "Iter-59830, train loss-0.1946, acc-0.9400, valid loss-0.2626, acc-0.9264, test loss-0.2736, acc-0.9243\n",
      "Iter-59840, train loss-0.2779, acc-0.9200, valid loss-0.2627, acc-0.9264, test loss-0.2736, acc-0.9242\n",
      "Iter-59850, train loss-0.2960, acc-0.9000, valid loss-0.2627, acc-0.9266, test loss-0.2736, acc-0.9241\n",
      "Iter-59860, train loss-0.1503, acc-0.9400, valid loss-0.2626, acc-0.9264, test loss-0.2736, acc-0.9242\n",
      "Iter-59870, train loss-0.3400, acc-0.8800, valid loss-0.2626, acc-0.9262, test loss-0.2736, acc-0.9242\n",
      "Iter-59880, train loss-0.2124, acc-0.9400, valid loss-0.2626, acc-0.9262, test loss-0.2736, acc-0.9241\n",
      "Iter-59890, train loss-0.1413, acc-1.0000, valid loss-0.2625, acc-0.9266, test loss-0.2736, acc-0.9242\n",
      "Iter-59900, train loss-0.1383, acc-0.9600, valid loss-0.2625, acc-0.9266, test loss-0.2736, acc-0.9243\n",
      "Iter-59910, train loss-0.1309, acc-0.9800, valid loss-0.2624, acc-0.9264, test loss-0.2736, acc-0.9242\n",
      "Iter-59920, train loss-0.1438, acc-0.9800, valid loss-0.2624, acc-0.9268, test loss-0.2735, acc-0.9241\n",
      "Iter-59930, train loss-0.2744, acc-0.9400, valid loss-0.2624, acc-0.9266, test loss-0.2735, acc-0.9243\n",
      "Iter-59940, train loss-0.2102, acc-0.9600, valid loss-0.2624, acc-0.9266, test loss-0.2735, acc-0.9242\n",
      "Iter-59950, train loss-0.3273, acc-0.9200, valid loss-0.2624, acc-0.9260, test loss-0.2734, acc-0.9244\n",
      "Iter-59960, train loss-0.2320, acc-0.9000, valid loss-0.2624, acc-0.9262, test loss-0.2734, acc-0.9244\n",
      "Iter-59970, train loss-0.2895, acc-0.9400, valid loss-0.2623, acc-0.9262, test loss-0.2734, acc-0.9244\n",
      "Iter-59980, train loss-0.2308, acc-0.9000, valid loss-0.2624, acc-0.9262, test loss-0.2734, acc-0.9243\n",
      "Iter-59990, train loss-0.2576, acc-0.9000, valid loss-0.2624, acc-0.9258, test loss-0.2733, acc-0.9246\n",
      "Iter-60000, train loss-0.1870, acc-0.9400, valid loss-0.2624, acc-0.9256, test loss-0.2733, acc-0.9247\n",
      "Iter-60010, train loss-0.1636, acc-0.9800, valid loss-0.2623, acc-0.9264, test loss-0.2733, acc-0.9246\n",
      "Iter-60020, train loss-0.2892, acc-0.9200, valid loss-0.2624, acc-0.9260, test loss-0.2733, acc-0.9246\n",
      "Iter-60030, train loss-0.3684, acc-0.9000, valid loss-0.2624, acc-0.9258, test loss-0.2733, acc-0.9243\n",
      "Iter-60040, train loss-0.2525, acc-0.9200, valid loss-0.2624, acc-0.9260, test loss-0.2733, acc-0.9244\n",
      "Iter-60050, train loss-0.2565, acc-0.9400, valid loss-0.2623, acc-0.9264, test loss-0.2733, acc-0.9245\n",
      "Iter-60060, train loss-0.1676, acc-0.9400, valid loss-0.2623, acc-0.9260, test loss-0.2732, acc-0.9246\n",
      "Iter-60070, train loss-0.2122, acc-0.9600, valid loss-0.2623, acc-0.9260, test loss-0.2732, acc-0.9246\n",
      "Iter-60080, train loss-0.4992, acc-0.8600, valid loss-0.2622, acc-0.9256, test loss-0.2732, acc-0.9245\n",
      "Iter-60090, train loss-0.2096, acc-0.9200, valid loss-0.2621, acc-0.9260, test loss-0.2732, acc-0.9247\n",
      "Iter-60100, train loss-0.2264, acc-0.9200, valid loss-0.2621, acc-0.9266, test loss-0.2732, acc-0.9247\n",
      "Iter-60110, train loss-0.2505, acc-0.9200, valid loss-0.2620, acc-0.9264, test loss-0.2732, acc-0.9245\n",
      "Iter-60120, train loss-0.2448, acc-0.9000, valid loss-0.2620, acc-0.9266, test loss-0.2731, acc-0.9246\n",
      "Iter-60130, train loss-0.5027, acc-0.8400, valid loss-0.2620, acc-0.9264, test loss-0.2731, acc-0.9246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60140, train loss-0.1956, acc-0.9600, valid loss-0.2620, acc-0.9268, test loss-0.2731, acc-0.9244\n",
      "Iter-60150, train loss-0.3002, acc-0.8600, valid loss-0.2620, acc-0.9264, test loss-0.2731, acc-0.9247\n",
      "Iter-60160, train loss-0.2154, acc-0.9200, valid loss-0.2620, acc-0.9264, test loss-0.2731, acc-0.9247\n",
      "Iter-60170, train loss-0.2166, acc-0.9400, valid loss-0.2621, acc-0.9262, test loss-0.2731, acc-0.9248\n",
      "Iter-60180, train loss-0.2675, acc-0.9000, valid loss-0.2621, acc-0.9264, test loss-0.2730, acc-0.9250\n",
      "Iter-60190, train loss-0.2749, acc-0.9200, valid loss-0.2621, acc-0.9266, test loss-0.2731, acc-0.9250\n",
      "Iter-60200, train loss-0.2727, acc-0.9200, valid loss-0.2621, acc-0.9264, test loss-0.2730, acc-0.9248\n",
      "Iter-60210, train loss-0.1992, acc-0.9600, valid loss-0.2620, acc-0.9268, test loss-0.2730, acc-0.9247\n",
      "Iter-60220, train loss-0.1547, acc-0.9400, valid loss-0.2620, acc-0.9266, test loss-0.2730, acc-0.9248\n",
      "Iter-60230, train loss-0.1568, acc-0.9800, valid loss-0.2620, acc-0.9266, test loss-0.2729, acc-0.9249\n",
      "Iter-60240, train loss-0.3664, acc-0.9200, valid loss-0.2619, acc-0.9264, test loss-0.2729, acc-0.9247\n",
      "Iter-60250, train loss-0.2284, acc-0.9400, valid loss-0.2619, acc-0.9264, test loss-0.2729, acc-0.9248\n",
      "Iter-60260, train loss-0.3080, acc-0.9000, valid loss-0.2618, acc-0.9266, test loss-0.2729, acc-0.9244\n",
      "Iter-60270, train loss-0.2455, acc-0.9400, valid loss-0.2618, acc-0.9264, test loss-0.2729, acc-0.9246\n",
      "Iter-60280, train loss-0.3561, acc-0.9200, valid loss-0.2617, acc-0.9268, test loss-0.2728, acc-0.9246\n",
      "Iter-60290, train loss-0.1449, acc-0.9400, valid loss-0.2617, acc-0.9264, test loss-0.2728, acc-0.9245\n",
      "Iter-60300, train loss-0.2843, acc-0.9200, valid loss-0.2617, acc-0.9264, test loss-0.2728, acc-0.9246\n",
      "Iter-60310, train loss-0.3284, acc-0.9200, valid loss-0.2617, acc-0.9264, test loss-0.2728, acc-0.9248\n",
      "Iter-60320, train loss-0.3302, acc-0.9000, valid loss-0.2617, acc-0.9264, test loss-0.2727, acc-0.9246\n",
      "Iter-60330, train loss-0.2702, acc-0.9200, valid loss-0.2616, acc-0.9262, test loss-0.2727, acc-0.9250\n",
      "Iter-60340, train loss-0.3968, acc-0.9200, valid loss-0.2616, acc-0.9266, test loss-0.2727, acc-0.9250\n",
      "Iter-60350, train loss-0.1893, acc-0.9600, valid loss-0.2616, acc-0.9264, test loss-0.2728, acc-0.9248\n",
      "Iter-60360, train loss-0.3411, acc-0.9400, valid loss-0.2616, acc-0.9266, test loss-0.2727, acc-0.9250\n",
      "Iter-60370, train loss-0.5238, acc-0.8800, valid loss-0.2616, acc-0.9264, test loss-0.2727, acc-0.9250\n",
      "Iter-60380, train loss-0.3266, acc-0.8800, valid loss-0.2616, acc-0.9264, test loss-0.2726, acc-0.9249\n",
      "Iter-60390, train loss-0.3880, acc-0.8200, valid loss-0.2615, acc-0.9264, test loss-0.2727, acc-0.9250\n",
      "Iter-60400, train loss-0.3117, acc-0.9600, valid loss-0.2615, acc-0.9264, test loss-0.2727, acc-0.9249\n",
      "Iter-60410, train loss-0.5183, acc-0.8800, valid loss-0.2615, acc-0.9264, test loss-0.2726, acc-0.9251\n",
      "Iter-60420, train loss-0.4147, acc-0.9000, valid loss-0.2614, acc-0.9260, test loss-0.2726, acc-0.9251\n",
      "Iter-60430, train loss-0.4827, acc-0.8400, valid loss-0.2615, acc-0.9262, test loss-0.2726, acc-0.9250\n",
      "Iter-60440, train loss-0.2486, acc-0.9200, valid loss-0.2615, acc-0.9260, test loss-0.2726, acc-0.9249\n",
      "Iter-60450, train loss-0.2413, acc-0.9400, valid loss-0.2615, acc-0.9260, test loss-0.2725, acc-0.9250\n",
      "Iter-60460, train loss-0.2762, acc-0.9200, valid loss-0.2614, acc-0.9260, test loss-0.2726, acc-0.9249\n",
      "Iter-60470, train loss-0.2304, acc-0.9000, valid loss-0.2614, acc-0.9260, test loss-0.2725, acc-0.9249\n",
      "Iter-60480, train loss-0.2074, acc-0.9200, valid loss-0.2613, acc-0.9260, test loss-0.2725, acc-0.9250\n",
      "Iter-60490, train loss-0.1999, acc-0.9000, valid loss-0.2614, acc-0.9260, test loss-0.2725, acc-0.9250\n",
      "Iter-60500, train loss-0.3087, acc-0.9200, valid loss-0.2614, acc-0.9258, test loss-0.2725, acc-0.9250\n",
      "Iter-60510, train loss-0.2729, acc-0.9400, valid loss-0.2614, acc-0.9260, test loss-0.2726, acc-0.9249\n",
      "Iter-60520, train loss-0.3268, acc-0.9000, valid loss-0.2613, acc-0.9262, test loss-0.2725, acc-0.9248\n",
      "Iter-60530, train loss-0.2382, acc-0.9200, valid loss-0.2613, acc-0.9256, test loss-0.2725, acc-0.9249\n",
      "Iter-60540, train loss-0.2778, acc-0.9200, valid loss-0.2613, acc-0.9258, test loss-0.2725, acc-0.9249\n",
      "Iter-60550, train loss-0.2867, acc-0.9200, valid loss-0.2613, acc-0.9258, test loss-0.2725, acc-0.9251\n",
      "Iter-60560, train loss-0.2723, acc-0.9000, valid loss-0.2613, acc-0.9260, test loss-0.2724, acc-0.9249\n",
      "Iter-60570, train loss-0.1076, acc-0.9800, valid loss-0.2612, acc-0.9266, test loss-0.2724, acc-0.9249\n",
      "Iter-60580, train loss-0.2812, acc-0.9000, valid loss-0.2612, acc-0.9266, test loss-0.2724, acc-0.9249\n",
      "Iter-60590, train loss-0.2617, acc-0.9200, valid loss-0.2611, acc-0.9266, test loss-0.2724, acc-0.9248\n",
      "Iter-60600, train loss-0.2707, acc-0.9400, valid loss-0.2611, acc-0.9266, test loss-0.2723, acc-0.9249\n",
      "Iter-60610, train loss-0.2118, acc-0.9600, valid loss-0.2611, acc-0.9268, test loss-0.2724, acc-0.9251\n",
      "Iter-60620, train loss-0.2308, acc-0.9200, valid loss-0.2611, acc-0.9264, test loss-0.2724, acc-0.9249\n",
      "Iter-60630, train loss-0.2794, acc-0.9200, valid loss-0.2611, acc-0.9266, test loss-0.2724, acc-0.9249\n",
      "Iter-60640, train loss-0.2011, acc-0.9600, valid loss-0.2612, acc-0.9264, test loss-0.2723, acc-0.9249\n",
      "Iter-60650, train loss-0.3515, acc-0.9000, valid loss-0.2611, acc-0.9270, test loss-0.2724, acc-0.9252\n",
      "Iter-60660, train loss-0.2107, acc-0.9600, valid loss-0.2611, acc-0.9268, test loss-0.2723, acc-0.9253\n",
      "Iter-60670, train loss-0.3447, acc-0.9000, valid loss-0.2610, acc-0.9266, test loss-0.2723, acc-0.9252\n",
      "Iter-60680, train loss-0.1072, acc-0.9800, valid loss-0.2610, acc-0.9268, test loss-0.2723, acc-0.9253\n",
      "Iter-60690, train loss-0.4072, acc-0.8600, valid loss-0.2610, acc-0.9266, test loss-0.2723, acc-0.9254\n",
      "Iter-60700, train loss-0.1939, acc-0.9600, valid loss-0.2610, acc-0.9266, test loss-0.2723, acc-0.9254\n",
      "Iter-60710, train loss-0.2914, acc-0.9000, valid loss-0.2609, acc-0.9266, test loss-0.2723, acc-0.9253\n",
      "Iter-60720, train loss-0.2944, acc-0.9200, valid loss-0.2609, acc-0.9268, test loss-0.2723, acc-0.9253\n",
      "Iter-60730, train loss-0.2232, acc-0.9400, valid loss-0.2609, acc-0.9270, test loss-0.2722, acc-0.9253\n",
      "Iter-60740, train loss-0.1572, acc-0.9600, valid loss-0.2608, acc-0.9272, test loss-0.2722, acc-0.9254\n",
      "Iter-60750, train loss-0.2104, acc-0.9200, valid loss-0.2608, acc-0.9270, test loss-0.2722, acc-0.9252\n",
      "Iter-60760, train loss-0.2170, acc-0.9600, valid loss-0.2608, acc-0.9272, test loss-0.2722, acc-0.9254\n",
      "Iter-60770, train loss-0.2134, acc-0.9000, valid loss-0.2607, acc-0.9270, test loss-0.2722, acc-0.9254\n",
      "Iter-60780, train loss-0.1655, acc-0.9600, valid loss-0.2607, acc-0.9268, test loss-0.2722, acc-0.9253\n",
      "Iter-60790, train loss-0.1563, acc-0.9600, valid loss-0.2606, acc-0.9270, test loss-0.2722, acc-0.9254\n",
      "Iter-60800, train loss-0.4678, acc-0.8800, valid loss-0.2605, acc-0.9272, test loss-0.2721, acc-0.9252\n",
      "Iter-60810, train loss-0.2811, acc-0.9200, valid loss-0.2605, acc-0.9272, test loss-0.2721, acc-0.9250\n",
      "Iter-60820, train loss-0.1412, acc-0.9600, valid loss-0.2605, acc-0.9272, test loss-0.2721, acc-0.9250\n",
      "Iter-60830, train loss-0.2738, acc-0.9000, valid loss-0.2605, acc-0.9272, test loss-0.2721, acc-0.9252\n",
      "Iter-60840, train loss-0.1804, acc-0.9400, valid loss-0.2605, acc-0.9272, test loss-0.2722, acc-0.9250\n",
      "Iter-60850, train loss-0.2674, acc-0.9400, valid loss-0.2605, acc-0.9276, test loss-0.2721, acc-0.9251\n",
      "Iter-60860, train loss-0.2654, acc-0.9200, valid loss-0.2604, acc-0.9278, test loss-0.2721, acc-0.9251\n",
      "Iter-60870, train loss-0.1643, acc-0.9600, valid loss-0.2604, acc-0.9274, test loss-0.2721, acc-0.9251\n",
      "Iter-60880, train loss-0.2155, acc-0.9400, valid loss-0.2604, acc-0.9272, test loss-0.2721, acc-0.9251\n",
      "Iter-60890, train loss-0.1881, acc-0.9400, valid loss-0.2604, acc-0.9272, test loss-0.2721, acc-0.9251\n",
      "Iter-60900, train loss-0.2314, acc-0.9200, valid loss-0.2604, acc-0.9272, test loss-0.2721, acc-0.9251\n",
      "Iter-60910, train loss-0.2367, acc-0.9400, valid loss-0.2603, acc-0.9274, test loss-0.2721, acc-0.9251\n",
      "Iter-60920, train loss-0.2974, acc-0.9200, valid loss-0.2604, acc-0.9276, test loss-0.2721, acc-0.9251\n",
      "Iter-60930, train loss-0.3287, acc-0.8800, valid loss-0.2603, acc-0.9274, test loss-0.2721, acc-0.9251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60940, train loss-0.6134, acc-0.8200, valid loss-0.2603, acc-0.9276, test loss-0.2721, acc-0.9250\n",
      "Iter-60950, train loss-0.2919, acc-0.8600, valid loss-0.2603, acc-0.9276, test loss-0.2720, acc-0.9250\n",
      "Iter-60960, train loss-0.1658, acc-0.9600, valid loss-0.2602, acc-0.9274, test loss-0.2720, acc-0.9250\n",
      "Iter-60970, train loss-0.1588, acc-0.9600, valid loss-0.2602, acc-0.9274, test loss-0.2720, acc-0.9253\n",
      "Iter-60980, train loss-0.3757, acc-0.8600, valid loss-0.2602, acc-0.9272, test loss-0.2720, acc-0.9253\n",
      "Iter-60990, train loss-0.3357, acc-0.9200, valid loss-0.2601, acc-0.9276, test loss-0.2720, acc-0.9250\n",
      "Iter-61000, train loss-0.5032, acc-0.8600, valid loss-0.2601, acc-0.9276, test loss-0.2719, acc-0.9252\n",
      "Iter-61010, train loss-0.3088, acc-0.9400, valid loss-0.2602, acc-0.9274, test loss-0.2719, acc-0.9252\n",
      "Iter-61020, train loss-0.3623, acc-0.9000, valid loss-0.2602, acc-0.9272, test loss-0.2719, acc-0.9253\n",
      "Iter-61030, train loss-0.1706, acc-0.9600, valid loss-0.2602, acc-0.9274, test loss-0.2719, acc-0.9258\n",
      "Iter-61040, train loss-0.1615, acc-0.9600, valid loss-0.2601, acc-0.9274, test loss-0.2719, acc-0.9259\n",
      "Iter-61050, train loss-0.2341, acc-0.9200, valid loss-0.2601, acc-0.9272, test loss-0.2719, acc-0.9257\n",
      "Iter-61060, train loss-0.3252, acc-0.9000, valid loss-0.2601, acc-0.9274, test loss-0.2719, acc-0.9257\n",
      "Iter-61070, train loss-0.3255, acc-0.8600, valid loss-0.2601, acc-0.9276, test loss-0.2718, acc-0.9254\n",
      "Iter-61080, train loss-0.1405, acc-0.9800, valid loss-0.2601, acc-0.9276, test loss-0.2718, acc-0.9254\n",
      "Iter-61090, train loss-0.1611, acc-0.9400, valid loss-0.2601, acc-0.9276, test loss-0.2718, acc-0.9253\n",
      "Iter-61100, train loss-0.1405, acc-0.9800, valid loss-0.2601, acc-0.9274, test loss-0.2718, acc-0.9252\n",
      "Iter-61110, train loss-0.1180, acc-1.0000, valid loss-0.2601, acc-0.9274, test loss-0.2718, acc-0.9252\n",
      "Iter-61120, train loss-0.3317, acc-0.9000, valid loss-0.2601, acc-0.9272, test loss-0.2718, acc-0.9253\n",
      "Iter-61130, train loss-0.3886, acc-0.8800, valid loss-0.2601, acc-0.9276, test loss-0.2718, acc-0.9253\n",
      "Iter-61140, train loss-0.2788, acc-0.9200, valid loss-0.2600, acc-0.9274, test loss-0.2718, acc-0.9254\n",
      "Iter-61150, train loss-0.1560, acc-0.9600, valid loss-0.2600, acc-0.9272, test loss-0.2717, acc-0.9256\n",
      "Iter-61160, train loss-0.3048, acc-0.8800, valid loss-0.2600, acc-0.9276, test loss-0.2717, acc-0.9255\n",
      "Iter-61170, train loss-0.3409, acc-0.8600, valid loss-0.2599, acc-0.9274, test loss-0.2717, acc-0.9257\n",
      "Iter-61180, train loss-0.3488, acc-0.8800, valid loss-0.2599, acc-0.9274, test loss-0.2716, acc-0.9257\n",
      "Iter-61190, train loss-0.5107, acc-0.9200, valid loss-0.2600, acc-0.9270, test loss-0.2716, acc-0.9257\n",
      "Iter-61200, train loss-0.3645, acc-0.8800, valid loss-0.2599, acc-0.9272, test loss-0.2715, acc-0.9257\n",
      "Iter-61210, train loss-0.1991, acc-0.9600, valid loss-0.2599, acc-0.9272, test loss-0.2715, acc-0.9257\n",
      "Iter-61220, train loss-0.3218, acc-0.9200, valid loss-0.2599, acc-0.9270, test loss-0.2715, acc-0.9256\n",
      "Iter-61230, train loss-0.2942, acc-0.9200, valid loss-0.2599, acc-0.9270, test loss-0.2715, acc-0.9256\n",
      "Iter-61240, train loss-0.3254, acc-0.9200, valid loss-0.2599, acc-0.9268, test loss-0.2715, acc-0.9256\n",
      "Iter-61250, train loss-0.2576, acc-0.9600, valid loss-0.2599, acc-0.9268, test loss-0.2715, acc-0.9258\n",
      "Iter-61260, train loss-0.1159, acc-0.9600, valid loss-0.2599, acc-0.9270, test loss-0.2715, acc-0.9262\n",
      "Iter-61270, train loss-0.2714, acc-0.9400, valid loss-0.2599, acc-0.9268, test loss-0.2714, acc-0.9260\n",
      "Iter-61280, train loss-0.2991, acc-0.8800, valid loss-0.2599, acc-0.9268, test loss-0.2714, acc-0.9259\n",
      "Iter-61290, train loss-0.2882, acc-0.9200, valid loss-0.2599, acc-0.9272, test loss-0.2714, acc-0.9261\n",
      "Iter-61300, train loss-0.4613, acc-0.8600, valid loss-0.2598, acc-0.9274, test loss-0.2714, acc-0.9258\n",
      "Iter-61310, train loss-0.1985, acc-0.9800, valid loss-0.2598, acc-0.9274, test loss-0.2714, acc-0.9258\n",
      "Iter-61320, train loss-0.4254, acc-0.8800, valid loss-0.2598, acc-0.9270, test loss-0.2714, acc-0.9257\n",
      "Iter-61330, train loss-0.2877, acc-0.9200, valid loss-0.2598, acc-0.9268, test loss-0.2713, acc-0.9256\n",
      "Iter-61340, train loss-0.2905, acc-0.8600, valid loss-0.2598, acc-0.9270, test loss-0.2713, acc-0.9257\n",
      "Iter-61350, train loss-0.3189, acc-0.8800, valid loss-0.2598, acc-0.9270, test loss-0.2713, acc-0.9258\n",
      "Iter-61360, train loss-0.2778, acc-0.9000, valid loss-0.2599, acc-0.9268, test loss-0.2713, acc-0.9255\n",
      "Iter-61370, train loss-0.2833, acc-0.9600, valid loss-0.2599, acc-0.9266, test loss-0.2712, acc-0.9253\n",
      "Iter-61380, train loss-0.2222, acc-0.9400, valid loss-0.2598, acc-0.9266, test loss-0.2712, acc-0.9256\n",
      "Iter-61390, train loss-0.1740, acc-0.9400, valid loss-0.2598, acc-0.9266, test loss-0.2711, acc-0.9254\n",
      "Iter-61400, train loss-0.1406, acc-0.9600, valid loss-0.2598, acc-0.9266, test loss-0.2711, acc-0.9255\n",
      "Iter-61410, train loss-0.1978, acc-0.9400, valid loss-0.2598, acc-0.9266, test loss-0.2711, acc-0.9254\n",
      "Iter-61420, train loss-0.2085, acc-0.9200, valid loss-0.2598, acc-0.9266, test loss-0.2711, acc-0.9253\n",
      "Iter-61430, train loss-0.0965, acc-0.9800, valid loss-0.2598, acc-0.9264, test loss-0.2711, acc-0.9252\n",
      "Iter-61440, train loss-0.2407, acc-0.9400, valid loss-0.2597, acc-0.9264, test loss-0.2711, acc-0.9254\n",
      "Iter-61450, train loss-0.3306, acc-0.9000, valid loss-0.2598, acc-0.9266, test loss-0.2710, acc-0.9254\n",
      "Iter-61460, train loss-0.1428, acc-0.9800, valid loss-0.2597, acc-0.9266, test loss-0.2710, acc-0.9253\n",
      "Iter-61470, train loss-0.2874, acc-0.9400, valid loss-0.2598, acc-0.9266, test loss-0.2710, acc-0.9253\n",
      "Iter-61480, train loss-0.1860, acc-0.9400, valid loss-0.2597, acc-0.9268, test loss-0.2710, acc-0.9252\n",
      "Iter-61490, train loss-0.2932, acc-0.9000, valid loss-0.2597, acc-0.9268, test loss-0.2710, acc-0.9255\n",
      "Iter-61500, train loss-0.3533, acc-0.8600, valid loss-0.2597, acc-0.9268, test loss-0.2710, acc-0.9253\n",
      "Iter-61510, train loss-0.2289, acc-0.9400, valid loss-0.2597, acc-0.9270, test loss-0.2710, acc-0.9253\n",
      "Iter-61520, train loss-0.2739, acc-0.9400, valid loss-0.2597, acc-0.9270, test loss-0.2710, acc-0.9252\n",
      "Iter-61530, train loss-0.1488, acc-0.9800, valid loss-0.2597, acc-0.9270, test loss-0.2711, acc-0.9253\n",
      "Iter-61540, train loss-0.2499, acc-0.9000, valid loss-0.2596, acc-0.9268, test loss-0.2711, acc-0.9252\n",
      "Iter-61550, train loss-0.2873, acc-0.9200, valid loss-0.2596, acc-0.9268, test loss-0.2710, acc-0.9253\n",
      "Iter-61560, train loss-0.2983, acc-0.8600, valid loss-0.2596, acc-0.9268, test loss-0.2710, acc-0.9254\n",
      "Iter-61570, train loss-0.2245, acc-0.9200, valid loss-0.2596, acc-0.9270, test loss-0.2709, acc-0.9252\n",
      "Iter-61580, train loss-0.1799, acc-0.9600, valid loss-0.2596, acc-0.9268, test loss-0.2709, acc-0.9254\n",
      "Iter-61590, train loss-0.2121, acc-0.9200, valid loss-0.2595, acc-0.9270, test loss-0.2709, acc-0.9254\n",
      "Iter-61600, train loss-0.4586, acc-0.8600, valid loss-0.2595, acc-0.9268, test loss-0.2709, acc-0.9255\n",
      "Iter-61610, train loss-0.4663, acc-0.9000, valid loss-0.2595, acc-0.9270, test loss-0.2709, acc-0.9252\n",
      "Iter-61620, train loss-0.2763, acc-0.9200, valid loss-0.2595, acc-0.9272, test loss-0.2708, acc-0.9252\n",
      "Iter-61630, train loss-0.2352, acc-0.9200, valid loss-0.2594, acc-0.9268, test loss-0.2709, acc-0.9254\n",
      "Iter-61640, train loss-0.2123, acc-0.9400, valid loss-0.2594, acc-0.9272, test loss-0.2708, acc-0.9256\n",
      "Iter-61650, train loss-0.2226, acc-0.9400, valid loss-0.2593, acc-0.9276, test loss-0.2708, acc-0.9255\n",
      "Iter-61660, train loss-0.2757, acc-0.9600, valid loss-0.2593, acc-0.9276, test loss-0.2708, acc-0.9253\n",
      "Iter-61670, train loss-0.3487, acc-0.9400, valid loss-0.2592, acc-0.9276, test loss-0.2708, acc-0.9253\n",
      "Iter-61680, train loss-0.2597, acc-0.9200, valid loss-0.2592, acc-0.9272, test loss-0.2708, acc-0.9254\n",
      "Iter-61690, train loss-0.2197, acc-0.9600, valid loss-0.2593, acc-0.9270, test loss-0.2707, acc-0.9251\n",
      "Iter-61700, train loss-0.1561, acc-0.9600, valid loss-0.2593, acc-0.9266, test loss-0.2706, acc-0.9256\n",
      "Iter-61710, train loss-0.4378, acc-0.8200, valid loss-0.2592, acc-0.9268, test loss-0.2707, acc-0.9256\n",
      "Iter-61720, train loss-0.3142, acc-0.9200, valid loss-0.2592, acc-0.9270, test loss-0.2706, acc-0.9252\n",
      "Iter-61730, train loss-0.3831, acc-0.8800, valid loss-0.2591, acc-0.9274, test loss-0.2706, acc-0.9255\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-61740, train loss-0.2664, acc-0.9400, valid loss-0.2590, acc-0.9274, test loss-0.2705, acc-0.9255\n",
      "Iter-61750, train loss-0.3530, acc-0.9200, valid loss-0.2590, acc-0.9274, test loss-0.2705, acc-0.9259\n",
      "Iter-61760, train loss-0.1562, acc-0.9800, valid loss-0.2590, acc-0.9274, test loss-0.2705, acc-0.9257\n",
      "Iter-61770, train loss-0.1587, acc-0.9600, valid loss-0.2591, acc-0.9274, test loss-0.2705, acc-0.9254\n",
      "Iter-61780, train loss-0.3259, acc-0.9000, valid loss-0.2590, acc-0.9274, test loss-0.2704, acc-0.9256\n",
      "Iter-61790, train loss-0.4403, acc-0.9000, valid loss-0.2590, acc-0.9276, test loss-0.2704, acc-0.9257\n",
      "Iter-61800, train loss-0.2402, acc-0.9800, valid loss-0.2591, acc-0.9276, test loss-0.2704, acc-0.9257\n",
      "Iter-61810, train loss-0.2633, acc-0.9400, valid loss-0.2590, acc-0.9276, test loss-0.2704, acc-0.9257\n",
      "Iter-61820, train loss-0.2867, acc-0.9200, valid loss-0.2590, acc-0.9274, test loss-0.2704, acc-0.9254\n",
      "Iter-61830, train loss-0.1732, acc-0.9800, valid loss-0.2590, acc-0.9276, test loss-0.2704, acc-0.9256\n",
      "Iter-61840, train loss-0.1946, acc-0.9600, valid loss-0.2591, acc-0.9274, test loss-0.2704, acc-0.9256\n",
      "Iter-61850, train loss-0.1473, acc-0.9800, valid loss-0.2591, acc-0.9274, test loss-0.2704, acc-0.9260\n",
      "Iter-61860, train loss-0.1751, acc-0.9600, valid loss-0.2591, acc-0.9272, test loss-0.2705, acc-0.9256\n",
      "Iter-61870, train loss-0.2533, acc-0.9400, valid loss-0.2591, acc-0.9274, test loss-0.2704, acc-0.9255\n",
      "Iter-61880, train loss-0.3031, acc-0.9200, valid loss-0.2591, acc-0.9274, test loss-0.2705, acc-0.9258\n",
      "Iter-61890, train loss-0.2857, acc-0.9000, valid loss-0.2591, acc-0.9272, test loss-0.2704, acc-0.9260\n",
      "Iter-61900, train loss-0.1849, acc-0.9600, valid loss-0.2591, acc-0.9270, test loss-0.2704, acc-0.9259\n",
      "Iter-61910, train loss-0.2321, acc-0.9600, valid loss-0.2592, acc-0.9274, test loss-0.2704, acc-0.9256\n",
      "Iter-61920, train loss-0.1251, acc-0.9800, valid loss-0.2592, acc-0.9276, test loss-0.2704, acc-0.9256\n",
      "Iter-61930, train loss-0.2570, acc-0.8800, valid loss-0.2591, acc-0.9276, test loss-0.2703, acc-0.9256\n",
      "Iter-61940, train loss-0.3718, acc-0.9000, valid loss-0.2591, acc-0.9272, test loss-0.2703, acc-0.9255\n",
      "Iter-61950, train loss-0.4172, acc-0.8600, valid loss-0.2591, acc-0.9278, test loss-0.2702, acc-0.9253\n",
      "Iter-61960, train loss-0.3440, acc-0.9000, valid loss-0.2591, acc-0.9274, test loss-0.2702, acc-0.9252\n",
      "Iter-61970, train loss-0.3042, acc-0.9000, valid loss-0.2590, acc-0.9276, test loss-0.2703, acc-0.9255\n",
      "Iter-61980, train loss-0.2456, acc-0.9400, valid loss-0.2590, acc-0.9278, test loss-0.2702, acc-0.9255\n",
      "Iter-61990, train loss-0.1742, acc-0.9600, valid loss-0.2590, acc-0.9276, test loss-0.2702, acc-0.9255\n",
      "Iter-62000, train loss-0.2209, acc-0.9400, valid loss-0.2590, acc-0.9274, test loss-0.2702, acc-0.9253\n",
      "Iter-62010, train loss-0.2265, acc-0.9400, valid loss-0.2590, acc-0.9274, test loss-0.2701, acc-0.9258\n",
      "Iter-62020, train loss-0.3754, acc-0.8400, valid loss-0.2590, acc-0.9276, test loss-0.2701, acc-0.9258\n",
      "Iter-62030, train loss-0.2734, acc-0.9200, valid loss-0.2589, acc-0.9272, test loss-0.2700, acc-0.9257\n",
      "Iter-62040, train loss-0.2223, acc-0.8800, valid loss-0.2588, acc-0.9274, test loss-0.2700, acc-0.9256\n",
      "Iter-62050, train loss-0.1724, acc-0.9600, valid loss-0.2588, acc-0.9274, test loss-0.2700, acc-0.9253\n",
      "Iter-62060, train loss-0.3469, acc-0.9000, valid loss-0.2587, acc-0.9274, test loss-0.2699, acc-0.9255\n",
      "Iter-62070, train loss-0.2544, acc-0.8800, valid loss-0.2587, acc-0.9272, test loss-0.2699, acc-0.9257\n",
      "Iter-62080, train loss-0.3121, acc-0.8800, valid loss-0.2586, acc-0.9276, test loss-0.2699, acc-0.9258\n",
      "Iter-62090, train loss-0.7287, acc-0.8000, valid loss-0.2586, acc-0.9274, test loss-0.2698, acc-0.9259\n",
      "Iter-62100, train loss-0.2111, acc-0.9400, valid loss-0.2586, acc-0.9274, test loss-0.2698, acc-0.9258\n",
      "Iter-62110, train loss-0.1722, acc-0.9400, valid loss-0.2586, acc-0.9272, test loss-0.2698, acc-0.9258\n",
      "Iter-62120, train loss-0.2816, acc-0.9600, valid loss-0.2587, acc-0.9272, test loss-0.2698, acc-0.9260\n",
      "Iter-62130, train loss-0.1746, acc-0.9800, valid loss-0.2586, acc-0.9272, test loss-0.2698, acc-0.9259\n",
      "Iter-62140, train loss-0.2892, acc-0.9200, valid loss-0.2586, acc-0.9272, test loss-0.2697, acc-0.9260\n",
      "Iter-62150, train loss-0.2876, acc-0.9400, valid loss-0.2586, acc-0.9272, test loss-0.2697, acc-0.9260\n",
      "Iter-62160, train loss-0.2750, acc-0.9200, valid loss-0.2585, acc-0.9272, test loss-0.2697, acc-0.9258\n",
      "Iter-62170, train loss-0.3447, acc-0.8600, valid loss-0.2585, acc-0.9272, test loss-0.2697, acc-0.9259\n",
      "Iter-62180, train loss-0.2947, acc-0.9000, valid loss-0.2585, acc-0.9272, test loss-0.2697, acc-0.9259\n",
      "Iter-62190, train loss-0.1894, acc-0.9400, valid loss-0.2586, acc-0.9272, test loss-0.2697, acc-0.9260\n",
      "Iter-62200, train loss-0.1629, acc-0.9600, valid loss-0.2586, acc-0.9272, test loss-0.2697, acc-0.9257\n",
      "Iter-62210, train loss-0.4064, acc-0.8400, valid loss-0.2586, acc-0.9270, test loss-0.2697, acc-0.9258\n",
      "Iter-62220, train loss-0.5046, acc-0.8200, valid loss-0.2585, acc-0.9272, test loss-0.2697, acc-0.9256\n",
      "Iter-62230, train loss-0.2050, acc-0.9400, valid loss-0.2585, acc-0.9274, test loss-0.2697, acc-0.9256\n",
      "Iter-62240, train loss-0.1827, acc-0.9200, valid loss-0.2584, acc-0.9274, test loss-0.2697, acc-0.9256\n",
      "Iter-62250, train loss-0.3839, acc-0.9000, valid loss-0.2584, acc-0.9274, test loss-0.2697, acc-0.9256\n",
      "Iter-62260, train loss-0.2871, acc-0.9400, valid loss-0.2584, acc-0.9274, test loss-0.2696, acc-0.9256\n",
      "Iter-62270, train loss-0.2665, acc-0.9200, valid loss-0.2584, acc-0.9272, test loss-0.2697, acc-0.9255\n",
      "Iter-62280, train loss-0.5711, acc-0.8400, valid loss-0.2584, acc-0.9272, test loss-0.2697, acc-0.9253\n",
      "Iter-62290, train loss-0.2732, acc-0.9000, valid loss-0.2584, acc-0.9272, test loss-0.2697, acc-0.9256\n",
      "Iter-62300, train loss-0.2001, acc-0.9200, valid loss-0.2583, acc-0.9276, test loss-0.2696, acc-0.9256\n",
      "Iter-62310, train loss-0.1805, acc-0.9800, valid loss-0.2583, acc-0.9276, test loss-0.2696, acc-0.9253\n",
      "Iter-62320, train loss-0.1959, acc-0.9600, valid loss-0.2584, acc-0.9278, test loss-0.2696, acc-0.9253\n",
      "Iter-62330, train loss-0.2990, acc-0.8800, valid loss-0.2584, acc-0.9282, test loss-0.2696, acc-0.9254\n",
      "Iter-62340, train loss-0.2438, acc-0.9400, valid loss-0.2583, acc-0.9282, test loss-0.2696, acc-0.9251\n",
      "Iter-62350, train loss-0.1818, acc-0.9200, valid loss-0.2583, acc-0.9282, test loss-0.2696, acc-0.9255\n",
      "Iter-62360, train loss-0.2287, acc-0.9200, valid loss-0.2584, acc-0.9280, test loss-0.2696, acc-0.9254\n",
      "Iter-62370, train loss-0.3856, acc-0.9000, valid loss-0.2584, acc-0.9276, test loss-0.2696, acc-0.9255\n",
      "Iter-62380, train loss-0.2211, acc-0.9200, valid loss-0.2583, acc-0.9276, test loss-0.2695, acc-0.9255\n",
      "Iter-62390, train loss-0.2061, acc-0.9400, valid loss-0.2583, acc-0.9282, test loss-0.2695, acc-0.9255\n",
      "Iter-62400, train loss-0.2910, acc-0.9200, valid loss-0.2582, acc-0.9276, test loss-0.2694, acc-0.9255\n",
      "Iter-62410, train loss-0.2375, acc-0.9000, valid loss-0.2582, acc-0.9278, test loss-0.2694, acc-0.9257\n",
      "Iter-62420, train loss-0.3641, acc-0.8600, valid loss-0.2582, acc-0.9276, test loss-0.2694, acc-0.9258\n",
      "Iter-62430, train loss-0.3548, acc-0.9200, valid loss-0.2581, acc-0.9278, test loss-0.2693, acc-0.9256\n",
      "Iter-62440, train loss-0.3195, acc-0.9200, valid loss-0.2580, acc-0.9276, test loss-0.2694, acc-0.9257\n",
      "Iter-62450, train loss-0.3085, acc-0.8800, valid loss-0.2580, acc-0.9274, test loss-0.2694, acc-0.9257\n",
      "Iter-62460, train loss-0.3438, acc-0.9200, valid loss-0.2579, acc-0.9272, test loss-0.2694, acc-0.9258\n",
      "Iter-62470, train loss-0.1978, acc-0.9200, valid loss-0.2580, acc-0.9272, test loss-0.2693, acc-0.9262\n",
      "Iter-62480, train loss-0.2676, acc-0.9400, valid loss-0.2579, acc-0.9274, test loss-0.2693, acc-0.9259\n",
      "Iter-62490, train loss-0.3668, acc-0.9400, valid loss-0.2579, acc-0.9272, test loss-0.2693, acc-0.9260\n",
      "Iter-62500, train loss-0.4841, acc-0.8200, valid loss-0.2578, acc-0.9276, test loss-0.2693, acc-0.9263\n",
      "Iter-62510, train loss-0.2259, acc-0.8800, valid loss-0.2578, acc-0.9272, test loss-0.2692, acc-0.9262\n",
      "Iter-62520, train loss-0.4514, acc-0.8600, valid loss-0.2579, acc-0.9272, test loss-0.2691, acc-0.9259\n",
      "Iter-62530, train loss-0.2321, acc-0.9200, valid loss-0.2578, acc-0.9272, test loss-0.2691, acc-0.9259\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-62540, train loss-0.3295, acc-0.8400, valid loss-0.2579, acc-0.9276, test loss-0.2691, acc-0.9261\n",
      "Iter-62550, train loss-0.3091, acc-0.8600, valid loss-0.2579, acc-0.9276, test loss-0.2690, acc-0.9262\n",
      "Iter-62560, train loss-0.2115, acc-0.9600, valid loss-0.2578, acc-0.9272, test loss-0.2691, acc-0.9261\n",
      "Iter-62570, train loss-0.1658, acc-0.9600, valid loss-0.2577, acc-0.9272, test loss-0.2690, acc-0.9262\n",
      "Iter-62580, train loss-0.2740, acc-0.9000, valid loss-0.2577, acc-0.9272, test loss-0.2690, acc-0.9262\n",
      "Iter-62590, train loss-0.1520, acc-0.9600, valid loss-0.2577, acc-0.9274, test loss-0.2690, acc-0.9263\n",
      "Iter-62600, train loss-0.2870, acc-0.9000, valid loss-0.2577, acc-0.9272, test loss-0.2691, acc-0.9262\n",
      "Iter-62610, train loss-0.3343, acc-0.8800, valid loss-0.2577, acc-0.9272, test loss-0.2691, acc-0.9261\n",
      "Iter-62620, train loss-0.3434, acc-0.8800, valid loss-0.2576, acc-0.9276, test loss-0.2691, acc-0.9263\n",
      "Iter-62630, train loss-0.1063, acc-1.0000, valid loss-0.2576, acc-0.9272, test loss-0.2691, acc-0.9264\n",
      "Iter-62640, train loss-0.3418, acc-0.8800, valid loss-0.2576, acc-0.9272, test loss-0.2691, acc-0.9260\n",
      "Iter-62650, train loss-0.2452, acc-0.9200, valid loss-0.2576, acc-0.9272, test loss-0.2691, acc-0.9261\n",
      "Iter-62660, train loss-0.2401, acc-0.9400, valid loss-0.2576, acc-0.9272, test loss-0.2691, acc-0.9262\n",
      "Iter-62670, train loss-0.3529, acc-0.9400, valid loss-0.2575, acc-0.9274, test loss-0.2691, acc-0.9261\n",
      "Iter-62680, train loss-0.2380, acc-0.9200, valid loss-0.2575, acc-0.9272, test loss-0.2690, acc-0.9262\n",
      "Iter-62690, train loss-0.1904, acc-0.9600, valid loss-0.2575, acc-0.9276, test loss-0.2690, acc-0.9261\n",
      "Iter-62700, train loss-0.2353, acc-0.9200, valid loss-0.2575, acc-0.9272, test loss-0.2690, acc-0.9265\n",
      "Iter-62710, train loss-0.1391, acc-0.9600, valid loss-0.2575, acc-0.9274, test loss-0.2690, acc-0.9265\n",
      "Iter-62720, train loss-0.2212, acc-0.9400, valid loss-0.2575, acc-0.9276, test loss-0.2690, acc-0.9264\n",
      "Iter-62730, train loss-0.3295, acc-0.9200, valid loss-0.2575, acc-0.9276, test loss-0.2690, acc-0.9264\n",
      "Iter-62740, train loss-0.3341, acc-0.9400, valid loss-0.2575, acc-0.9276, test loss-0.2689, acc-0.9264\n",
      "Iter-62750, train loss-0.3776, acc-0.8800, valid loss-0.2575, acc-0.9272, test loss-0.2690, acc-0.9263\n",
      "Iter-62760, train loss-0.2005, acc-0.9400, valid loss-0.2575, acc-0.9274, test loss-0.2689, acc-0.9264\n",
      "Iter-62770, train loss-0.2581, acc-0.9000, valid loss-0.2575, acc-0.9270, test loss-0.2689, acc-0.9266\n",
      "Iter-62780, train loss-0.1297, acc-0.9800, valid loss-0.2575, acc-0.9272, test loss-0.2689, acc-0.9266\n",
      "Iter-62790, train loss-0.2631, acc-0.9200, valid loss-0.2575, acc-0.9272, test loss-0.2688, acc-0.9265\n",
      "Iter-62800, train loss-0.2212, acc-0.9600, valid loss-0.2575, acc-0.9270, test loss-0.2688, acc-0.9264\n",
      "Iter-62810, train loss-0.4061, acc-0.8800, valid loss-0.2575, acc-0.9272, test loss-0.2688, acc-0.9265\n",
      "Iter-62820, train loss-0.2568, acc-0.9600, valid loss-0.2574, acc-0.9274, test loss-0.2688, acc-0.9265\n",
      "Iter-62830, train loss-0.2665, acc-0.9400, valid loss-0.2574, acc-0.9272, test loss-0.2688, acc-0.9265\n",
      "Iter-62840, train loss-0.2034, acc-0.9400, valid loss-0.2574, acc-0.9272, test loss-0.2687, acc-0.9265\n",
      "Iter-62850, train loss-0.1263, acc-0.9600, valid loss-0.2574, acc-0.9270, test loss-0.2688, acc-0.9265\n",
      "Iter-62860, train loss-0.3397, acc-0.9000, valid loss-0.2574, acc-0.9270, test loss-0.2687, acc-0.9264\n",
      "Iter-62870, train loss-0.2051, acc-0.9200, valid loss-0.2574, acc-0.9272, test loss-0.2687, acc-0.9267\n",
      "Iter-62880, train loss-0.3310, acc-0.9200, valid loss-0.2574, acc-0.9272, test loss-0.2687, acc-0.9268\n",
      "Iter-62890, train loss-0.2958, acc-0.8600, valid loss-0.2574, acc-0.9272, test loss-0.2686, acc-0.9268\n",
      "Iter-62900, train loss-0.1894, acc-0.9600, valid loss-0.2575, acc-0.9272, test loss-0.2686, acc-0.9270\n",
      "Iter-62910, train loss-0.5394, acc-0.8600, valid loss-0.2574, acc-0.9272, test loss-0.2686, acc-0.9268\n",
      "Iter-62920, train loss-0.1764, acc-0.9600, valid loss-0.2574, acc-0.9272, test loss-0.2686, acc-0.9269\n",
      "Iter-62930, train loss-0.2780, acc-0.9000, valid loss-0.2573, acc-0.9272, test loss-0.2686, acc-0.9267\n",
      "Iter-62940, train loss-0.4311, acc-0.8400, valid loss-0.2573, acc-0.9270, test loss-0.2686, acc-0.9268\n",
      "Iter-62950, train loss-0.0685, acc-1.0000, valid loss-0.2573, acc-0.9270, test loss-0.2686, acc-0.9269\n",
      "Iter-62960, train loss-0.2640, acc-0.9000, valid loss-0.2573, acc-0.9270, test loss-0.2686, acc-0.9269\n",
      "Iter-62970, train loss-0.1888, acc-0.9400, valid loss-0.2573, acc-0.9272, test loss-0.2685, acc-0.9270\n",
      "Iter-62980, train loss-0.1598, acc-0.9800, valid loss-0.2573, acc-0.9270, test loss-0.2685, acc-0.9269\n",
      "Iter-62990, train loss-0.3741, acc-0.9000, valid loss-0.2573, acc-0.9272, test loss-0.2685, acc-0.9266\n",
      "Iter-63000, train loss-0.3130, acc-0.9000, valid loss-0.2573, acc-0.9274, test loss-0.2685, acc-0.9266\n",
      "Iter-63010, train loss-0.3586, acc-0.9000, valid loss-0.2573, acc-0.9272, test loss-0.2685, acc-0.9266\n",
      "Iter-63020, train loss-0.2475, acc-0.9400, valid loss-0.2572, acc-0.9272, test loss-0.2686, acc-0.9264\n",
      "Iter-63030, train loss-0.1778, acc-0.9800, valid loss-0.2572, acc-0.9272, test loss-0.2685, acc-0.9264\n",
      "Iter-63040, train loss-0.1999, acc-0.9600, valid loss-0.2573, acc-0.9274, test loss-0.2685, acc-0.9263\n",
      "Iter-63050, train loss-0.3702, acc-0.9000, valid loss-0.2573, acc-0.9274, test loss-0.2685, acc-0.9263\n",
      "Iter-63060, train loss-0.3675, acc-0.8800, valid loss-0.2573, acc-0.9272, test loss-0.2685, acc-0.9263\n",
      "Iter-63070, train loss-0.1421, acc-0.9800, valid loss-0.2573, acc-0.9274, test loss-0.2685, acc-0.9262\n",
      "Iter-63080, train loss-0.2058, acc-0.9600, valid loss-0.2572, acc-0.9270, test loss-0.2684, acc-0.9266\n",
      "Iter-63090, train loss-0.3896, acc-0.8800, valid loss-0.2572, acc-0.9272, test loss-0.2684, acc-0.9265\n",
      "Iter-63100, train loss-0.3064, acc-0.9400, valid loss-0.2572, acc-0.9272, test loss-0.2684, acc-0.9268\n",
      "Iter-63110, train loss-0.4029, acc-0.8800, valid loss-0.2572, acc-0.9272, test loss-0.2684, acc-0.9269\n",
      "Iter-63120, train loss-0.3043, acc-0.9000, valid loss-0.2571, acc-0.9274, test loss-0.2683, acc-0.9270\n",
      "Iter-63130, train loss-0.3012, acc-0.8800, valid loss-0.2571, acc-0.9274, test loss-0.2683, acc-0.9267\n",
      "Iter-63140, train loss-0.1925, acc-0.9600, valid loss-0.2571, acc-0.9276, test loss-0.2682, acc-0.9267\n",
      "Iter-63150, train loss-0.0916, acc-0.9800, valid loss-0.2571, acc-0.9272, test loss-0.2682, acc-0.9269\n",
      "Iter-63160, train loss-0.2734, acc-0.9000, valid loss-0.2571, acc-0.9276, test loss-0.2682, acc-0.9269\n",
      "Iter-63170, train loss-0.2044, acc-0.9200, valid loss-0.2570, acc-0.9276, test loss-0.2682, acc-0.9270\n",
      "Iter-63180, train loss-0.2739, acc-0.8800, valid loss-0.2569, acc-0.9276, test loss-0.2682, acc-0.9270\n",
      "Iter-63190, train loss-0.2055, acc-0.9400, valid loss-0.2570, acc-0.9274, test loss-0.2682, acc-0.9266\n",
      "Iter-63200, train loss-0.1517, acc-0.9400, valid loss-0.2569, acc-0.9272, test loss-0.2682, acc-0.9267\n",
      "Iter-63210, train loss-0.2056, acc-0.9600, valid loss-0.2569, acc-0.9274, test loss-0.2681, acc-0.9266\n",
      "Iter-63220, train loss-0.4124, acc-0.8600, valid loss-0.2568, acc-0.9272, test loss-0.2681, acc-0.9267\n",
      "Iter-63230, train loss-0.2654, acc-0.9200, valid loss-0.2569, acc-0.9276, test loss-0.2681, acc-0.9268\n",
      "Iter-63240, train loss-0.1921, acc-0.9200, valid loss-0.2569, acc-0.9274, test loss-0.2681, acc-0.9269\n",
      "Iter-63250, train loss-0.1291, acc-0.9600, valid loss-0.2569, acc-0.9276, test loss-0.2680, acc-0.9266\n",
      "Iter-63260, train loss-0.3933, acc-0.9000, valid loss-0.2569, acc-0.9272, test loss-0.2680, acc-0.9267\n",
      "Iter-63270, train loss-0.1602, acc-0.9400, valid loss-0.2569, acc-0.9276, test loss-0.2680, acc-0.9267\n",
      "Iter-63280, train loss-0.2287, acc-0.9000, valid loss-0.2569, acc-0.9278, test loss-0.2680, acc-0.9265\n",
      "Iter-63290, train loss-0.3011, acc-0.8600, valid loss-0.2568, acc-0.9276, test loss-0.2680, acc-0.9266\n",
      "Iter-63300, train loss-0.1833, acc-0.9200, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9264\n",
      "Iter-63310, train loss-0.2932, acc-0.9400, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9265\n",
      "Iter-63320, train loss-0.1801, acc-0.9600, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9261\n",
      "Iter-63330, train loss-0.3092, acc-0.9400, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-63340, train loss-0.1585, acc-0.9600, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9262\n",
      "Iter-63350, train loss-0.1308, acc-0.9800, valid loss-0.2568, acc-0.9276, test loss-0.2679, acc-0.9260\n",
      "Iter-63360, train loss-0.3288, acc-0.9000, valid loss-0.2568, acc-0.9272, test loss-0.2679, acc-0.9263\n",
      "Iter-63370, train loss-0.3012, acc-0.9200, valid loss-0.2567, acc-0.9274, test loss-0.2679, acc-0.9261\n",
      "Iter-63380, train loss-0.2853, acc-0.9200, valid loss-0.2568, acc-0.9274, test loss-0.2679, acc-0.9263\n",
      "Iter-63390, train loss-0.1573, acc-0.9800, valid loss-0.2568, acc-0.9274, test loss-0.2679, acc-0.9260\n",
      "Iter-63400, train loss-0.3012, acc-0.9200, valid loss-0.2568, acc-0.9272, test loss-0.2679, acc-0.9263\n",
      "Iter-63410, train loss-0.2566, acc-0.9000, valid loss-0.2567, acc-0.9276, test loss-0.2679, acc-0.9261\n",
      "Iter-63420, train loss-0.1584, acc-0.9800, valid loss-0.2567, acc-0.9274, test loss-0.2679, acc-0.9262\n",
      "Iter-63430, train loss-0.3419, acc-0.9200, valid loss-0.2567, acc-0.9274, test loss-0.2679, acc-0.9261\n",
      "Iter-63440, train loss-0.3014, acc-0.9200, valid loss-0.2567, acc-0.9274, test loss-0.2679, acc-0.9260\n",
      "Iter-63450, train loss-0.2188, acc-0.9200, valid loss-0.2567, acc-0.9272, test loss-0.2679, acc-0.9258\n",
      "Iter-63460, train loss-0.3000, acc-0.9200, valid loss-0.2567, acc-0.9274, test loss-0.2678, acc-0.9257\n",
      "Iter-63470, train loss-0.2349, acc-0.9600, valid loss-0.2566, acc-0.9276, test loss-0.2678, acc-0.9259\n",
      "Iter-63480, train loss-0.3925, acc-0.8800, valid loss-0.2566, acc-0.9274, test loss-0.2678, acc-0.9259\n",
      "Iter-63490, train loss-0.3161, acc-0.8800, valid loss-0.2566, acc-0.9272, test loss-0.2678, acc-0.9259\n",
      "Iter-63500, train loss-0.1919, acc-0.9800, valid loss-0.2566, acc-0.9272, test loss-0.2677, acc-0.9259\n",
      "Iter-63510, train loss-0.3924, acc-0.8800, valid loss-0.2566, acc-0.9276, test loss-0.2677, acc-0.9261\n",
      "Iter-63520, train loss-0.2789, acc-0.8800, valid loss-0.2566, acc-0.9272, test loss-0.2677, acc-0.9261\n",
      "Iter-63530, train loss-0.3318, acc-0.9200, valid loss-0.2565, acc-0.9272, test loss-0.2677, acc-0.9261\n",
      "Iter-63540, train loss-0.2122, acc-0.9200, valid loss-0.2565, acc-0.9276, test loss-0.2677, acc-0.9264\n",
      "Iter-63550, train loss-0.2490, acc-0.9200, valid loss-0.2564, acc-0.9276, test loss-0.2677, acc-0.9265\n",
      "Iter-63560, train loss-0.3145, acc-0.9200, valid loss-0.2564, acc-0.9278, test loss-0.2677, acc-0.9265\n",
      "Iter-63570, train loss-0.1324, acc-0.9600, valid loss-0.2564, acc-0.9276, test loss-0.2677, acc-0.9264\n",
      "Iter-63580, train loss-0.2964, acc-0.9200, valid loss-0.2564, acc-0.9278, test loss-0.2677, acc-0.9264\n",
      "Iter-63590, train loss-0.4369, acc-0.8400, valid loss-0.2564, acc-0.9278, test loss-0.2677, acc-0.9265\n",
      "Iter-63600, train loss-0.2220, acc-0.9400, valid loss-0.2564, acc-0.9280, test loss-0.2677, acc-0.9266\n",
      "Iter-63610, train loss-0.2645, acc-0.9200, valid loss-0.2564, acc-0.9278, test loss-0.2676, acc-0.9266\n",
      "Iter-63620, train loss-0.2244, acc-0.9600, valid loss-0.2565, acc-0.9278, test loss-0.2676, acc-0.9270\n",
      "Iter-63630, train loss-0.3308, acc-0.9200, valid loss-0.2565, acc-0.9274, test loss-0.2676, acc-0.9268\n",
      "Iter-63640, train loss-0.3825, acc-0.8800, valid loss-0.2565, acc-0.9272, test loss-0.2675, acc-0.9265\n",
      "Iter-63650, train loss-0.2342, acc-0.9400, valid loss-0.2564, acc-0.9276, test loss-0.2675, acc-0.9264\n",
      "Iter-63660, train loss-0.2867, acc-0.9200, valid loss-0.2564, acc-0.9272, test loss-0.2675, acc-0.9264\n",
      "Iter-63670, train loss-0.3121, acc-0.9400, valid loss-0.2565, acc-0.9278, test loss-0.2675, acc-0.9265\n",
      "Iter-63680, train loss-0.1700, acc-0.9800, valid loss-0.2565, acc-0.9276, test loss-0.2675, acc-0.9264\n",
      "Iter-63690, train loss-0.1036, acc-1.0000, valid loss-0.2565, acc-0.9276, test loss-0.2675, acc-0.9263\n",
      "Iter-63700, train loss-0.2039, acc-0.9600, valid loss-0.2565, acc-0.9270, test loss-0.2674, acc-0.9267\n",
      "Iter-63710, train loss-0.4227, acc-0.9000, valid loss-0.2564, acc-0.9272, test loss-0.2674, acc-0.9266\n",
      "Iter-63720, train loss-0.2018, acc-0.9600, valid loss-0.2564, acc-0.9272, test loss-0.2673, acc-0.9266\n",
      "Iter-63730, train loss-0.2997, acc-0.9000, valid loss-0.2563, acc-0.9274, test loss-0.2672, acc-0.9267\n",
      "Iter-63740, train loss-0.1992, acc-0.9600, valid loss-0.2563, acc-0.9272, test loss-0.2672, acc-0.9266\n",
      "Iter-63750, train loss-0.3248, acc-0.9000, valid loss-0.2563, acc-0.9270, test loss-0.2671, acc-0.9266\n",
      "Iter-63760, train loss-0.2254, acc-0.9400, valid loss-0.2563, acc-0.9274, test loss-0.2671, acc-0.9267\n",
      "Iter-63770, train loss-0.2964, acc-0.9000, valid loss-0.2563, acc-0.9272, test loss-0.2671, acc-0.9266\n",
      "Iter-63780, train loss-0.1843, acc-0.9400, valid loss-0.2562, acc-0.9270, test loss-0.2671, acc-0.9270\n",
      "Iter-63790, train loss-0.2148, acc-0.9400, valid loss-0.2562, acc-0.9272, test loss-0.2671, acc-0.9266\n",
      "Iter-63800, train loss-0.4373, acc-0.8400, valid loss-0.2562, acc-0.9272, test loss-0.2670, acc-0.9268\n",
      "Iter-63810, train loss-0.1746, acc-0.9600, valid loss-0.2562, acc-0.9270, test loss-0.2670, acc-0.9268\n",
      "Iter-63820, train loss-0.4627, acc-0.8400, valid loss-0.2562, acc-0.9270, test loss-0.2670, acc-0.9269\n",
      "Iter-63830, train loss-0.3092, acc-0.8800, valid loss-0.2561, acc-0.9272, test loss-0.2670, acc-0.9268\n",
      "Iter-63840, train loss-0.2190, acc-0.9200, valid loss-0.2561, acc-0.9272, test loss-0.2670, acc-0.9269\n",
      "Iter-63850, train loss-0.4538, acc-0.8800, valid loss-0.2561, acc-0.9272, test loss-0.2670, acc-0.9269\n",
      "Iter-63860, train loss-0.2511, acc-0.9200, valid loss-0.2561, acc-0.9274, test loss-0.2670, acc-0.9268\n",
      "Iter-63870, train loss-0.5390, acc-0.8400, valid loss-0.2561, acc-0.9272, test loss-0.2670, acc-0.9268\n",
      "Iter-63880, train loss-0.2522, acc-0.9200, valid loss-0.2561, acc-0.9270, test loss-0.2670, acc-0.9265\n",
      "Iter-63890, train loss-0.2823, acc-0.9400, valid loss-0.2560, acc-0.9272, test loss-0.2671, acc-0.9267\n",
      "Iter-63900, train loss-0.1465, acc-0.9600, valid loss-0.2561, acc-0.9274, test loss-0.2671, acc-0.9268\n",
      "Iter-63910, train loss-0.3252, acc-0.8600, valid loss-0.2561, acc-0.9274, test loss-0.2671, acc-0.9267\n",
      "Iter-63920, train loss-0.4800, acc-0.8800, valid loss-0.2561, acc-0.9270, test loss-0.2671, acc-0.9266\n",
      "Iter-63930, train loss-0.2412, acc-0.9000, valid loss-0.2560, acc-0.9274, test loss-0.2670, acc-0.9266\n",
      "Iter-63940, train loss-0.3119, acc-0.9000, valid loss-0.2560, acc-0.9276, test loss-0.2670, acc-0.9262\n",
      "Iter-63950, train loss-0.1454, acc-0.9600, valid loss-0.2560, acc-0.9274, test loss-0.2670, acc-0.9263\n",
      "Iter-63960, train loss-0.1615, acc-0.9800, valid loss-0.2560, acc-0.9270, test loss-0.2670, acc-0.9265\n",
      "Iter-63970, train loss-0.3233, acc-0.8800, valid loss-0.2559, acc-0.9274, test loss-0.2670, acc-0.9265\n",
      "Iter-63980, train loss-0.4412, acc-0.8800, valid loss-0.2559, acc-0.9272, test loss-0.2670, acc-0.9266\n",
      "Iter-63990, train loss-0.2310, acc-0.9400, valid loss-0.2559, acc-0.9270, test loss-0.2669, acc-0.9264\n",
      "Iter-64000, train loss-0.3026, acc-0.9400, valid loss-0.2558, acc-0.9270, test loss-0.2669, acc-0.9261\n",
      "Iter-64010, train loss-0.2362, acc-0.9000, valid loss-0.2558, acc-0.9270, test loss-0.2669, acc-0.9264\n",
      "Iter-64020, train loss-0.4007, acc-0.8800, valid loss-0.2558, acc-0.9268, test loss-0.2669, acc-0.9266\n",
      "Iter-64030, train loss-0.3148, acc-0.9000, valid loss-0.2558, acc-0.9270, test loss-0.2668, acc-0.9264\n",
      "Iter-64040, train loss-0.1347, acc-0.9800, valid loss-0.2558, acc-0.9274, test loss-0.2668, acc-0.9265\n",
      "Iter-64050, train loss-0.3170, acc-0.9000, valid loss-0.2558, acc-0.9274, test loss-0.2668, acc-0.9269\n",
      "Iter-64060, train loss-0.3160, acc-0.9200, valid loss-0.2558, acc-0.9272, test loss-0.2668, acc-0.9268\n",
      "Iter-64070, train loss-0.1907, acc-0.9600, valid loss-0.2558, acc-0.9270, test loss-0.2668, acc-0.9263\n",
      "Iter-64080, train loss-0.1636, acc-0.9400, valid loss-0.2558, acc-0.9268, test loss-0.2668, acc-0.9265\n",
      "Iter-64090, train loss-0.1677, acc-0.9400, valid loss-0.2558, acc-0.9274, test loss-0.2667, acc-0.9268\n",
      "Iter-64100, train loss-0.2426, acc-0.9400, valid loss-0.2558, acc-0.9274, test loss-0.2667, acc-0.9270\n",
      "Iter-64110, train loss-0.3293, acc-0.9200, valid loss-0.2558, acc-0.9276, test loss-0.2667, acc-0.9269\n",
      "Iter-64120, train loss-0.1980, acc-0.9200, valid loss-0.2558, acc-0.9278, test loss-0.2667, acc-0.9270\n",
      "Iter-64130, train loss-0.1759, acc-0.9600, valid loss-0.2558, acc-0.9274, test loss-0.2666, acc-0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-64140, train loss-0.3432, acc-0.9600, valid loss-0.2558, acc-0.9276, test loss-0.2666, acc-0.9271\n",
      "Iter-64150, train loss-0.2715, acc-0.9200, valid loss-0.2558, acc-0.9276, test loss-0.2666, acc-0.9271\n",
      "Iter-64160, train loss-0.4481, acc-0.9000, valid loss-0.2558, acc-0.9276, test loss-0.2666, acc-0.9272\n",
      "Iter-64170, train loss-0.1188, acc-1.0000, valid loss-0.2557, acc-0.9280, test loss-0.2666, acc-0.9271\n",
      "Iter-64180, train loss-0.3566, acc-0.8800, valid loss-0.2557, acc-0.9280, test loss-0.2666, acc-0.9271\n",
      "Iter-64190, train loss-0.1257, acc-0.9600, valid loss-0.2557, acc-0.9280, test loss-0.2666, acc-0.9272\n",
      "Iter-64200, train loss-0.1731, acc-0.9600, valid loss-0.2556, acc-0.9282, test loss-0.2666, acc-0.9272\n",
      "Iter-64210, train loss-0.1622, acc-0.9600, valid loss-0.2556, acc-0.9282, test loss-0.2665, acc-0.9275\n",
      "Iter-64220, train loss-0.4329, acc-0.9000, valid loss-0.2556, acc-0.9280, test loss-0.2665, acc-0.9273\n",
      "Iter-64230, train loss-0.1095, acc-0.9600, valid loss-0.2556, acc-0.9280, test loss-0.2665, acc-0.9270\n",
      "Iter-64240, train loss-0.1924, acc-0.9600, valid loss-0.2556, acc-0.9280, test loss-0.2665, acc-0.9271\n",
      "Iter-64250, train loss-0.2889, acc-0.9400, valid loss-0.2556, acc-0.9280, test loss-0.2665, acc-0.9268\n",
      "Iter-64260, train loss-0.2741, acc-0.9000, valid loss-0.2556, acc-0.9282, test loss-0.2665, acc-0.9267\n",
      "Iter-64270, train loss-0.1171, acc-0.9800, valid loss-0.2556, acc-0.9280, test loss-0.2665, acc-0.9264\n",
      "Iter-64280, train loss-0.3655, acc-0.9200, valid loss-0.2556, acc-0.9284, test loss-0.2665, acc-0.9267\n",
      "Iter-64290, train loss-0.3739, acc-0.9000, valid loss-0.2556, acc-0.9284, test loss-0.2664, acc-0.9267\n",
      "Iter-64300, train loss-0.1687, acc-0.9800, valid loss-0.2555, acc-0.9284, test loss-0.2664, acc-0.9270\n",
      "Iter-64310, train loss-0.1267, acc-1.0000, valid loss-0.2555, acc-0.9282, test loss-0.2663, acc-0.9270\n",
      "Iter-64320, train loss-0.1928, acc-0.9600, valid loss-0.2555, acc-0.9286, test loss-0.2663, acc-0.9270\n",
      "Iter-64330, train loss-0.1363, acc-0.9400, valid loss-0.2555, acc-0.9284, test loss-0.2663, acc-0.9269\n",
      "Iter-64340, train loss-0.2876, acc-0.8600, valid loss-0.2554, acc-0.9286, test loss-0.2663, acc-0.9268\n",
      "Iter-64350, train loss-0.2535, acc-0.9000, valid loss-0.2554, acc-0.9284, test loss-0.2662, acc-0.9269\n",
      "Iter-64360, train loss-0.2105, acc-0.9400, valid loss-0.2554, acc-0.9284, test loss-0.2662, acc-0.9268\n",
      "Iter-64370, train loss-0.2728, acc-0.9000, valid loss-0.2554, acc-0.9284, test loss-0.2662, acc-0.9269\n",
      "Iter-64380, train loss-0.2482, acc-0.9000, valid loss-0.2553, acc-0.9284, test loss-0.2662, acc-0.9268\n",
      "Iter-64390, train loss-0.2086, acc-0.9600, valid loss-0.2553, acc-0.9288, test loss-0.2662, acc-0.9269\n",
      "Iter-64400, train loss-0.1704, acc-0.9600, valid loss-0.2553, acc-0.9288, test loss-0.2662, acc-0.9269\n",
      "Iter-64410, train loss-0.1858, acc-0.9400, valid loss-0.2552, acc-0.9286, test loss-0.2662, acc-0.9268\n",
      "Iter-64420, train loss-0.1211, acc-0.9800, valid loss-0.2552, acc-0.9282, test loss-0.2662, acc-0.9265\n",
      "Iter-64430, train loss-0.2417, acc-0.9000, valid loss-0.2551, acc-0.9284, test loss-0.2662, acc-0.9266\n",
      "Iter-64440, train loss-0.2370, acc-0.9200, valid loss-0.2551, acc-0.9286, test loss-0.2662, acc-0.9267\n",
      "Iter-64450, train loss-0.1454, acc-0.9600, valid loss-0.2551, acc-0.9286, test loss-0.2662, acc-0.9265\n",
      "Iter-64460, train loss-0.1828, acc-0.9600, valid loss-0.2550, acc-0.9288, test loss-0.2662, acc-0.9265\n",
      "Iter-64470, train loss-0.1887, acc-0.9600, valid loss-0.2550, acc-0.9286, test loss-0.2662, acc-0.9266\n",
      "Iter-64480, train loss-0.3484, acc-0.8800, valid loss-0.2550, acc-0.9288, test loss-0.2662, acc-0.9266\n",
      "Iter-64490, train loss-0.2733, acc-0.8800, valid loss-0.2550, acc-0.9284, test loss-0.2662, acc-0.9265\n",
      "Iter-64500, train loss-0.1660, acc-0.9600, valid loss-0.2549, acc-0.9284, test loss-0.2662, acc-0.9265\n",
      "Iter-64510, train loss-0.2000, acc-0.9600, valid loss-0.2549, acc-0.9282, test loss-0.2662, acc-0.9267\n",
      "Iter-64520, train loss-0.2357, acc-0.9000, valid loss-0.2549, acc-0.9280, test loss-0.2661, acc-0.9266\n",
      "Iter-64530, train loss-0.3665, acc-0.8800, valid loss-0.2548, acc-0.9282, test loss-0.2661, acc-0.9265\n",
      "Iter-64540, train loss-0.2458, acc-0.9200, valid loss-0.2549, acc-0.9284, test loss-0.2661, acc-0.9266\n",
      "Iter-64550, train loss-0.2541, acc-0.9400, valid loss-0.2549, acc-0.9282, test loss-0.2661, acc-0.9265\n",
      "Iter-64560, train loss-0.5368, acc-0.8800, valid loss-0.2549, acc-0.9282, test loss-0.2661, acc-0.9266\n",
      "Iter-64570, train loss-0.1054, acc-0.9800, valid loss-0.2548, acc-0.9282, test loss-0.2660, acc-0.9267\n",
      "Iter-64580, train loss-0.3466, acc-0.9400, valid loss-0.2549, acc-0.9278, test loss-0.2660, acc-0.9268\n",
      "Iter-64590, train loss-0.1720, acc-0.9800, valid loss-0.2549, acc-0.9276, test loss-0.2659, acc-0.9269\n",
      "Iter-64600, train loss-0.3157, acc-0.9000, valid loss-0.2549, acc-0.9278, test loss-0.2659, acc-0.9267\n",
      "Iter-64610, train loss-0.2722, acc-0.9400, valid loss-0.2549, acc-0.9278, test loss-0.2659, acc-0.9269\n",
      "Iter-64620, train loss-0.2894, acc-0.9200, valid loss-0.2550, acc-0.9278, test loss-0.2659, acc-0.9267\n",
      "Iter-64630, train loss-0.1882, acc-0.9400, valid loss-0.2550, acc-0.9276, test loss-0.2659, acc-0.9267\n",
      "Iter-64640, train loss-0.1752, acc-0.9600, valid loss-0.2549, acc-0.9276, test loss-0.2658, acc-0.9268\n",
      "Iter-64650, train loss-0.2624, acc-0.9200, valid loss-0.2549, acc-0.9276, test loss-0.2658, acc-0.9267\n",
      "Iter-64660, train loss-0.2059, acc-0.9600, valid loss-0.2549, acc-0.9276, test loss-0.2658, acc-0.9267\n",
      "Iter-64670, train loss-0.3080, acc-0.9000, valid loss-0.2549, acc-0.9276, test loss-0.2658, acc-0.9267\n",
      "Iter-64680, train loss-0.3434, acc-0.8600, valid loss-0.2549, acc-0.9280, test loss-0.2658, acc-0.9268\n",
      "Iter-64690, train loss-0.1718, acc-0.9800, valid loss-0.2549, acc-0.9276, test loss-0.2658, acc-0.9266\n",
      "Iter-64700, train loss-0.3553, acc-0.9000, valid loss-0.2548, acc-0.9278, test loss-0.2658, acc-0.9268\n",
      "Iter-64710, train loss-0.1258, acc-0.9600, valid loss-0.2548, acc-0.9278, test loss-0.2658, acc-0.9267\n",
      "Iter-64720, train loss-0.3643, acc-0.8800, valid loss-0.2548, acc-0.9274, test loss-0.2657, acc-0.9269\n",
      "Iter-64730, train loss-0.1424, acc-0.9800, valid loss-0.2548, acc-0.9278, test loss-0.2657, acc-0.9273\n",
      "Iter-64740, train loss-0.1776, acc-0.9800, valid loss-0.2547, acc-0.9278, test loss-0.2657, acc-0.9271\n",
      "Iter-64750, train loss-0.4778, acc-0.8600, valid loss-0.2548, acc-0.9278, test loss-0.2658, acc-0.9269\n",
      "Iter-64760, train loss-0.1573, acc-0.9600, valid loss-0.2547, acc-0.9280, test loss-0.2658, acc-0.9265\n",
      "Iter-64770, train loss-0.2720, acc-0.9400, valid loss-0.2547, acc-0.9280, test loss-0.2658, acc-0.9267\n",
      "Iter-64780, train loss-0.3845, acc-0.8800, valid loss-0.2547, acc-0.9280, test loss-0.2658, acc-0.9268\n",
      "Iter-64790, train loss-0.2858, acc-0.9000, valid loss-0.2546, acc-0.9278, test loss-0.2658, acc-0.9267\n",
      "Iter-64800, train loss-0.2043, acc-0.9200, valid loss-0.2545, acc-0.9280, test loss-0.2658, acc-0.9270\n",
      "Iter-64810, train loss-0.2941, acc-0.8800, valid loss-0.2545, acc-0.9280, test loss-0.2657, acc-0.9267\n",
      "Iter-64820, train loss-0.1841, acc-0.9600, valid loss-0.2545, acc-0.9278, test loss-0.2657, acc-0.9269\n",
      "Iter-64830, train loss-0.3385, acc-0.8800, valid loss-0.2545, acc-0.9278, test loss-0.2657, acc-0.9270\n",
      "Iter-64840, train loss-0.2831, acc-0.9400, valid loss-0.2545, acc-0.9282, test loss-0.2656, acc-0.9266\n",
      "Iter-64850, train loss-0.1747, acc-0.9800, valid loss-0.2545, acc-0.9282, test loss-0.2656, acc-0.9265\n",
      "Iter-64860, train loss-0.3462, acc-0.8800, valid loss-0.2545, acc-0.9278, test loss-0.2656, acc-0.9268\n",
      "Iter-64870, train loss-0.2005, acc-0.9800, valid loss-0.2544, acc-0.9280, test loss-0.2656, acc-0.9268\n",
      "Iter-64880, train loss-0.4455, acc-0.8400, valid loss-0.2544, acc-0.9280, test loss-0.2656, acc-0.9269\n",
      "Iter-64890, train loss-0.3779, acc-0.9000, valid loss-0.2543, acc-0.9280, test loss-0.2655, acc-0.9268\n",
      "Iter-64900, train loss-0.1777, acc-0.9600, valid loss-0.2543, acc-0.9280, test loss-0.2655, acc-0.9269\n",
      "Iter-64910, train loss-0.2528, acc-0.9200, valid loss-0.2543, acc-0.9284, test loss-0.2655, acc-0.9270\n",
      "Iter-64920, train loss-0.3386, acc-0.9200, valid loss-0.2543, acc-0.9282, test loss-0.2655, acc-0.9272\n",
      "Iter-64930, train loss-0.0974, acc-1.0000, valid loss-0.2543, acc-0.9282, test loss-0.2654, acc-0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-64940, train loss-0.3196, acc-0.9000, valid loss-0.2543, acc-0.9280, test loss-0.2654, acc-0.9274\n",
      "Iter-64950, train loss-0.2061, acc-0.9600, valid loss-0.2543, acc-0.9282, test loss-0.2654, acc-0.9271\n",
      "Iter-64960, train loss-0.2775, acc-0.8800, valid loss-0.2543, acc-0.9282, test loss-0.2654, acc-0.9271\n",
      "Iter-64970, train loss-0.2133, acc-0.9400, valid loss-0.2543, acc-0.9280, test loss-0.2654, acc-0.9270\n",
      "Iter-64980, train loss-0.1461, acc-0.9800, valid loss-0.2543, acc-0.9280, test loss-0.2654, acc-0.9270\n",
      "Iter-64990, train loss-0.1692, acc-0.9400, valid loss-0.2543, acc-0.9282, test loss-0.2653, acc-0.9269\n",
      "Iter-65000, train loss-0.2818, acc-0.9200, valid loss-0.2542, acc-0.9284, test loss-0.2653, acc-0.9269\n",
      "Iter-65010, train loss-0.2882, acc-0.9600, valid loss-0.2542, acc-0.9284, test loss-0.2653, acc-0.9269\n",
      "Iter-65020, train loss-0.1848, acc-0.9400, valid loss-0.2542, acc-0.9280, test loss-0.2653, acc-0.9267\n",
      "Iter-65030, train loss-0.3326, acc-0.9000, valid loss-0.2542, acc-0.9280, test loss-0.2653, acc-0.9268\n",
      "Iter-65040, train loss-0.2773, acc-0.9200, valid loss-0.2542, acc-0.9282, test loss-0.2653, acc-0.9269\n",
      "Iter-65050, train loss-0.2463, acc-0.9400, valid loss-0.2541, acc-0.9282, test loss-0.2653, acc-0.9267\n",
      "Iter-65060, train loss-0.2663, acc-0.9200, valid loss-0.2541, acc-0.9282, test loss-0.2653, acc-0.9265\n",
      "Iter-65070, train loss-0.4753, acc-0.8800, valid loss-0.2540, acc-0.9282, test loss-0.2653, acc-0.9267\n",
      "Iter-65080, train loss-0.1302, acc-0.9800, valid loss-0.2540, acc-0.9282, test loss-0.2652, acc-0.9267\n",
      "Iter-65090, train loss-0.3645, acc-0.9000, valid loss-0.2540, acc-0.9282, test loss-0.2652, acc-0.9264\n",
      "Iter-65100, train loss-0.2916, acc-0.9200, valid loss-0.2540, acc-0.9282, test loss-0.2652, acc-0.9269\n",
      "Iter-65110, train loss-0.4015, acc-0.9000, valid loss-0.2540, acc-0.9282, test loss-0.2652, acc-0.9271\n",
      "Iter-65120, train loss-0.2805, acc-0.8800, valid loss-0.2540, acc-0.9282, test loss-0.2651, acc-0.9271\n",
      "Iter-65130, train loss-0.1721, acc-0.9600, valid loss-0.2540, acc-0.9282, test loss-0.2651, acc-0.9272\n",
      "Iter-65140, train loss-0.2638, acc-0.9400, valid loss-0.2539, acc-0.9282, test loss-0.2651, acc-0.9273\n",
      "Iter-65150, train loss-0.2796, acc-0.9000, valid loss-0.2539, acc-0.9282, test loss-0.2651, acc-0.9271\n",
      "Iter-65160, train loss-0.4415, acc-0.8400, valid loss-0.2539, acc-0.9284, test loss-0.2650, acc-0.9269\n",
      "Iter-65170, train loss-0.3268, acc-0.9400, valid loss-0.2538, acc-0.9284, test loss-0.2650, acc-0.9272\n",
      "Iter-65180, train loss-0.1134, acc-0.9800, valid loss-0.2539, acc-0.9284, test loss-0.2650, acc-0.9272\n",
      "Iter-65190, train loss-0.2514, acc-0.9200, valid loss-0.2538, acc-0.9284, test loss-0.2650, acc-0.9272\n",
      "Iter-65200, train loss-0.1487, acc-0.9400, valid loss-0.2538, acc-0.9280, test loss-0.2650, acc-0.9270\n",
      "Iter-65210, train loss-0.3759, acc-0.8600, valid loss-0.2538, acc-0.9280, test loss-0.2650, acc-0.9269\n",
      "Iter-65220, train loss-0.2799, acc-0.9200, valid loss-0.2538, acc-0.9278, test loss-0.2650, acc-0.9269\n",
      "Iter-65230, train loss-0.3227, acc-0.8800, valid loss-0.2538, acc-0.9280, test loss-0.2649, acc-0.9269\n",
      "Iter-65240, train loss-0.2033, acc-0.9200, valid loss-0.2537, acc-0.9276, test loss-0.2649, acc-0.9271\n",
      "Iter-65250, train loss-0.2308, acc-0.9600, valid loss-0.2537, acc-0.9278, test loss-0.2649, acc-0.9271\n",
      "Iter-65260, train loss-0.3548, acc-0.9000, valid loss-0.2537, acc-0.9278, test loss-0.2649, acc-0.9269\n",
      "Iter-65270, train loss-0.3432, acc-0.9200, valid loss-0.2537, acc-0.9278, test loss-0.2649, acc-0.9269\n",
      "Iter-65280, train loss-0.3011, acc-0.9000, valid loss-0.2537, acc-0.9280, test loss-0.2648, acc-0.9268\n",
      "Iter-65290, train loss-0.4533, acc-0.8600, valid loss-0.2536, acc-0.9278, test loss-0.2648, acc-0.9268\n",
      "Iter-65300, train loss-0.1219, acc-0.9600, valid loss-0.2535, acc-0.9280, test loss-0.2648, acc-0.9268\n",
      "Iter-65310, train loss-0.4010, acc-0.9200, valid loss-0.2535, acc-0.9278, test loss-0.2648, acc-0.9270\n",
      "Iter-65320, train loss-0.2437, acc-0.9000, valid loss-0.2535, acc-0.9278, test loss-0.2647, acc-0.9269\n",
      "Iter-65330, train loss-0.2165, acc-0.9600, valid loss-0.2535, acc-0.9280, test loss-0.2647, acc-0.9268\n",
      "Iter-65340, train loss-0.2999, acc-0.9200, valid loss-0.2534, acc-0.9282, test loss-0.2647, acc-0.9268\n",
      "Iter-65350, train loss-0.2726, acc-0.9000, valid loss-0.2534, acc-0.9282, test loss-0.2647, acc-0.9264\n",
      "Iter-65360, train loss-0.2932, acc-0.9400, valid loss-0.2534, acc-0.9284, test loss-0.2647, acc-0.9267\n",
      "Iter-65370, train loss-0.2946, acc-0.9200, valid loss-0.2533, acc-0.9284, test loss-0.2647, acc-0.9266\n",
      "Iter-65380, train loss-0.3402, acc-0.9000, valid loss-0.2533, acc-0.9280, test loss-0.2646, acc-0.9267\n",
      "Iter-65390, train loss-0.3038, acc-0.9400, valid loss-0.2533, acc-0.9282, test loss-0.2646, acc-0.9267\n",
      "Iter-65400, train loss-0.1737, acc-0.9600, valid loss-0.2533, acc-0.9280, test loss-0.2646, acc-0.9267\n",
      "Iter-65410, train loss-0.3077, acc-0.8800, valid loss-0.2533, acc-0.9282, test loss-0.2645, acc-0.9267\n",
      "Iter-65420, train loss-0.5681, acc-0.8200, valid loss-0.2532, acc-0.9280, test loss-0.2645, acc-0.9265\n",
      "Iter-65430, train loss-0.2638, acc-0.9200, valid loss-0.2531, acc-0.9282, test loss-0.2645, acc-0.9265\n",
      "Iter-65440, train loss-0.1947, acc-0.9400, valid loss-0.2531, acc-0.9282, test loss-0.2644, acc-0.9266\n",
      "Iter-65450, train loss-0.1994, acc-0.9000, valid loss-0.2531, acc-0.9282, test loss-0.2644, acc-0.9266\n",
      "Iter-65460, train loss-0.2067, acc-0.9200, valid loss-0.2531, acc-0.9282, test loss-0.2644, acc-0.9266\n",
      "Iter-65470, train loss-0.3586, acc-0.9200, valid loss-0.2532, acc-0.9284, test loss-0.2644, acc-0.9268\n",
      "Iter-65480, train loss-0.2266, acc-0.9000, valid loss-0.2532, acc-0.9286, test loss-0.2643, acc-0.9267\n",
      "Iter-65490, train loss-0.2244, acc-0.9400, valid loss-0.2532, acc-0.9280, test loss-0.2643, acc-0.9267\n",
      "Iter-65500, train loss-0.2150, acc-0.9200, valid loss-0.2532, acc-0.9280, test loss-0.2643, acc-0.9268\n",
      "Iter-65510, train loss-0.2778, acc-0.9000, valid loss-0.2532, acc-0.9280, test loss-0.2642, acc-0.9269\n",
      "Iter-65520, train loss-0.2480, acc-0.9200, valid loss-0.2532, acc-0.9278, test loss-0.2642, acc-0.9270\n",
      "Iter-65530, train loss-0.3855, acc-0.8800, valid loss-0.2532, acc-0.9280, test loss-0.2643, acc-0.9266\n",
      "Iter-65540, train loss-0.3353, acc-0.9000, valid loss-0.2532, acc-0.9280, test loss-0.2643, acc-0.9267\n",
      "Iter-65550, train loss-0.1450, acc-0.9800, valid loss-0.2532, acc-0.9282, test loss-0.2643, acc-0.9266\n",
      "Iter-65560, train loss-0.4997, acc-0.8600, valid loss-0.2532, acc-0.9280, test loss-0.2643, acc-0.9267\n",
      "Iter-65570, train loss-0.1170, acc-0.9800, valid loss-0.2531, acc-0.9280, test loss-0.2643, acc-0.9267\n",
      "Iter-65580, train loss-0.3171, acc-0.9000, valid loss-0.2531, acc-0.9280, test loss-0.2643, acc-0.9271\n",
      "Iter-65590, train loss-0.2234, acc-0.9400, valid loss-0.2531, acc-0.9282, test loss-0.2642, acc-0.9271\n",
      "Iter-65600, train loss-0.3712, acc-0.8600, valid loss-0.2530, acc-0.9280, test loss-0.2642, acc-0.9270\n",
      "Iter-65610, train loss-0.1021, acc-0.9800, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9271\n",
      "Iter-65620, train loss-0.1991, acc-0.9400, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9273\n",
      "Iter-65630, train loss-0.2061, acc-0.9600, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9274\n",
      "Iter-65640, train loss-0.4301, acc-0.8000, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9273\n",
      "Iter-65650, train loss-0.3387, acc-0.9200, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9272\n",
      "Iter-65660, train loss-0.2489, acc-0.9600, valid loss-0.2530, acc-0.9282, test loss-0.2641, acc-0.9273\n",
      "Iter-65670, train loss-0.1490, acc-0.9600, valid loss-0.2530, acc-0.9284, test loss-0.2641, acc-0.9273\n",
      "Iter-65680, train loss-0.2562, acc-0.9200, valid loss-0.2529, acc-0.9284, test loss-0.2641, acc-0.9270\n",
      "Iter-65690, train loss-0.2260, acc-0.9600, valid loss-0.2530, acc-0.9282, test loss-0.2641, acc-0.9273\n",
      "Iter-65700, train loss-0.2198, acc-0.9600, valid loss-0.2530, acc-0.9284, test loss-0.2641, acc-0.9274\n",
      "Iter-65710, train loss-0.2319, acc-0.9400, valid loss-0.2531, acc-0.9282, test loss-0.2641, acc-0.9273\n",
      "Iter-65720, train loss-0.4296, acc-0.8000, valid loss-0.2531, acc-0.9282, test loss-0.2642, acc-0.9274\n",
      "Iter-65730, train loss-0.2262, acc-0.9200, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9272\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-65740, train loss-0.2732, acc-0.9400, valid loss-0.2530, acc-0.9282, test loss-0.2642, acc-0.9272\n",
      "Iter-65750, train loss-0.3014, acc-0.9000, valid loss-0.2529, acc-0.9282, test loss-0.2642, acc-0.9272\n",
      "Iter-65760, train loss-0.2072, acc-0.9200, valid loss-0.2530, acc-0.9280, test loss-0.2642, acc-0.9271\n",
      "Iter-65770, train loss-0.4151, acc-0.8600, valid loss-0.2530, acc-0.9284, test loss-0.2642, acc-0.9272\n",
      "Iter-65780, train loss-0.1491, acc-0.9600, valid loss-0.2530, acc-0.9284, test loss-0.2642, acc-0.9271\n",
      "Iter-65790, train loss-0.3197, acc-0.9000, valid loss-0.2529, acc-0.9284, test loss-0.2641, acc-0.9274\n",
      "Iter-65800, train loss-0.2552, acc-0.8800, valid loss-0.2529, acc-0.9284, test loss-0.2641, acc-0.9273\n",
      "Iter-65810, train loss-0.2623, acc-0.9600, valid loss-0.2529, acc-0.9282, test loss-0.2640, acc-0.9272\n",
      "Iter-65820, train loss-0.1368, acc-0.9800, valid loss-0.2529, acc-0.9282, test loss-0.2641, acc-0.9270\n",
      "Iter-65830, train loss-0.3791, acc-0.9000, valid loss-0.2529, acc-0.9284, test loss-0.2640, acc-0.9272\n",
      "Iter-65840, train loss-0.2779, acc-0.9200, valid loss-0.2529, acc-0.9284, test loss-0.2640, acc-0.9272\n",
      "Iter-65850, train loss-0.4348, acc-0.9000, valid loss-0.2528, acc-0.9282, test loss-0.2640, acc-0.9271\n",
      "Iter-65860, train loss-0.3736, acc-0.9200, valid loss-0.2528, acc-0.9282, test loss-0.2639, acc-0.9271\n",
      "Iter-65870, train loss-0.1759, acc-0.9600, valid loss-0.2529, acc-0.9282, test loss-0.2639, acc-0.9272\n",
      "Iter-65880, train loss-0.2685, acc-0.9600, valid loss-0.2528, acc-0.9282, test loss-0.2639, acc-0.9273\n",
      "Iter-65890, train loss-0.2186, acc-0.9400, valid loss-0.2528, acc-0.9284, test loss-0.2639, acc-0.9270\n",
      "Iter-65900, train loss-0.4530, acc-0.8800, valid loss-0.2528, acc-0.9284, test loss-0.2639, acc-0.9269\n",
      "Iter-65910, train loss-0.3494, acc-0.8800, valid loss-0.2528, acc-0.9286, test loss-0.2639, acc-0.9270\n",
      "Iter-65920, train loss-0.1970, acc-0.9200, valid loss-0.2528, acc-0.9286, test loss-0.2639, acc-0.9269\n",
      "Iter-65930, train loss-0.1183, acc-0.9600, valid loss-0.2528, acc-0.9282, test loss-0.2638, acc-0.9268\n",
      "Iter-65940, train loss-0.2797, acc-0.8800, valid loss-0.2528, acc-0.9280, test loss-0.2638, acc-0.9269\n",
      "Iter-65950, train loss-0.2398, acc-0.9200, valid loss-0.2528, acc-0.9280, test loss-0.2637, acc-0.9269\n",
      "Iter-65960, train loss-0.0987, acc-1.0000, valid loss-0.2527, acc-0.9280, test loss-0.2636, acc-0.9271\n",
      "Iter-65970, train loss-0.2693, acc-0.9400, valid loss-0.2527, acc-0.9280, test loss-0.2636, acc-0.9272\n",
      "Iter-65980, train loss-0.2799, acc-0.9000, valid loss-0.2526, acc-0.9280, test loss-0.2636, acc-0.9271\n",
      "Iter-65990, train loss-0.3037, acc-0.9200, valid loss-0.2526, acc-0.9280, test loss-0.2635, acc-0.9271\n",
      "Iter-66000, train loss-0.3459, acc-0.9200, valid loss-0.2527, acc-0.9280, test loss-0.2636, acc-0.9271\n",
      "Iter-66010, train loss-0.2196, acc-0.9200, valid loss-0.2527, acc-0.9280, test loss-0.2635, acc-0.9272\n",
      "Iter-66020, train loss-0.1813, acc-0.9400, valid loss-0.2526, acc-0.9280, test loss-0.2635, acc-0.9271\n",
      "Iter-66030, train loss-0.1552, acc-0.9400, valid loss-0.2526, acc-0.9278, test loss-0.2635, acc-0.9271\n",
      "Iter-66040, train loss-0.3352, acc-0.9000, valid loss-0.2526, acc-0.9280, test loss-0.2635, acc-0.9271\n",
      "Iter-66050, train loss-0.2006, acc-0.9600, valid loss-0.2526, acc-0.9276, test loss-0.2635, acc-0.9268\n",
      "Iter-66060, train loss-0.1767, acc-0.9400, valid loss-0.2526, acc-0.9276, test loss-0.2634, acc-0.9272\n",
      "Iter-66070, train loss-0.3957, acc-0.8600, valid loss-0.2526, acc-0.9278, test loss-0.2634, acc-0.9272\n",
      "Iter-66080, train loss-0.2409, acc-0.9400, valid loss-0.2526, acc-0.9276, test loss-0.2634, acc-0.9270\n",
      "Iter-66090, train loss-0.5928, acc-0.8600, valid loss-0.2525, acc-0.9276, test loss-0.2634, acc-0.9271\n",
      "Iter-66100, train loss-0.3500, acc-0.8800, valid loss-0.2525, acc-0.9276, test loss-0.2633, acc-0.9271\n",
      "Iter-66110, train loss-0.2379, acc-0.9200, valid loss-0.2525, acc-0.9276, test loss-0.2633, acc-0.9270\n",
      "Iter-66120, train loss-0.1801, acc-0.9800, valid loss-0.2525, acc-0.9276, test loss-0.2633, acc-0.9270\n",
      "Iter-66130, train loss-0.2638, acc-0.9000, valid loss-0.2525, acc-0.9276, test loss-0.2634, acc-0.9268\n",
      "Iter-66140, train loss-0.2431, acc-0.9400, valid loss-0.2524, acc-0.9276, test loss-0.2633, acc-0.9267\n",
      "Iter-66150, train loss-0.1188, acc-0.9800, valid loss-0.2523, acc-0.9276, test loss-0.2633, acc-0.9267\n",
      "Iter-66160, train loss-0.2813, acc-0.9200, valid loss-0.2523, acc-0.9274, test loss-0.2633, acc-0.9269\n",
      "Iter-66170, train loss-0.2974, acc-0.9000, valid loss-0.2522, acc-0.9274, test loss-0.2633, acc-0.9271\n",
      "Iter-66180, train loss-0.2461, acc-0.9400, valid loss-0.2522, acc-0.9276, test loss-0.2633, acc-0.9270\n",
      "Iter-66190, train loss-0.3152, acc-0.9400, valid loss-0.2522, acc-0.9276, test loss-0.2633, acc-0.9269\n",
      "Iter-66200, train loss-0.1487, acc-0.9600, valid loss-0.2521, acc-0.9278, test loss-0.2633, acc-0.9271\n",
      "Iter-66210, train loss-0.2778, acc-0.9200, valid loss-0.2521, acc-0.9276, test loss-0.2633, acc-0.9270\n",
      "Iter-66220, train loss-0.0908, acc-0.9800, valid loss-0.2521, acc-0.9278, test loss-0.2633, acc-0.9271\n",
      "Iter-66230, train loss-0.3285, acc-0.8800, valid loss-0.2521, acc-0.9276, test loss-0.2633, acc-0.9269\n",
      "Iter-66240, train loss-0.1502, acc-0.9800, valid loss-0.2521, acc-0.9276, test loss-0.2633, acc-0.9269\n",
      "Iter-66250, train loss-0.2197, acc-0.9400, valid loss-0.2521, acc-0.9274, test loss-0.2632, acc-0.9272\n",
      "Iter-66260, train loss-0.2613, acc-0.9000, valid loss-0.2521, acc-0.9276, test loss-0.2632, acc-0.9271\n",
      "Iter-66270, train loss-0.2216, acc-0.9000, valid loss-0.2521, acc-0.9276, test loss-0.2632, acc-0.9271\n",
      "Iter-66280, train loss-0.3200, acc-0.8800, valid loss-0.2521, acc-0.9278, test loss-0.2631, acc-0.9271\n",
      "Iter-66290, train loss-0.3154, acc-0.8600, valid loss-0.2520, acc-0.9276, test loss-0.2631, acc-0.9274\n",
      "Iter-66300, train loss-0.2165, acc-0.9400, valid loss-0.2520, acc-0.9276, test loss-0.2631, acc-0.9274\n",
      "Iter-66310, train loss-0.1893, acc-0.9200, valid loss-0.2520, acc-0.9278, test loss-0.2631, acc-0.9274\n",
      "Iter-66320, train loss-0.2243, acc-0.9400, valid loss-0.2520, acc-0.9276, test loss-0.2631, acc-0.9274\n",
      "Iter-66330, train loss-0.1636, acc-0.9600, valid loss-0.2520, acc-0.9276, test loss-0.2630, acc-0.9274\n",
      "Iter-66340, train loss-0.2555, acc-0.9000, valid loss-0.2520, acc-0.9276, test loss-0.2630, acc-0.9269\n",
      "Iter-66350, train loss-0.4447, acc-0.8800, valid loss-0.2519, acc-0.9276, test loss-0.2630, acc-0.9271\n",
      "Iter-66360, train loss-0.2393, acc-0.9000, valid loss-0.2519, acc-0.9274, test loss-0.2630, acc-0.9270\n",
      "Iter-66370, train loss-0.4273, acc-0.8800, valid loss-0.2519, acc-0.9278, test loss-0.2630, acc-0.9269\n",
      "Iter-66380, train loss-0.1767, acc-0.9800, valid loss-0.2518, acc-0.9278, test loss-0.2630, acc-0.9270\n",
      "Iter-66390, train loss-0.2440, acc-0.9800, valid loss-0.2518, acc-0.9278, test loss-0.2629, acc-0.9269\n",
      "Iter-66400, train loss-0.2090, acc-0.9400, valid loss-0.2518, acc-0.9278, test loss-0.2629, acc-0.9268\n",
      "Iter-66410, train loss-0.1733, acc-0.9600, valid loss-0.2518, acc-0.9278, test loss-0.2628, acc-0.9268\n",
      "Iter-66420, train loss-0.2421, acc-0.9400, valid loss-0.2517, acc-0.9280, test loss-0.2628, acc-0.9270\n",
      "Iter-66430, train loss-0.4957, acc-0.8600, valid loss-0.2517, acc-0.9278, test loss-0.2628, acc-0.9268\n",
      "Iter-66440, train loss-0.2798, acc-0.9000, valid loss-0.2517, acc-0.9280, test loss-0.2628, acc-0.9269\n",
      "Iter-66450, train loss-0.4690, acc-0.8600, valid loss-0.2516, acc-0.9278, test loss-0.2628, acc-0.9270\n",
      "Iter-66460, train loss-0.1610, acc-0.9600, valid loss-0.2517, acc-0.9278, test loss-0.2627, acc-0.9272\n",
      "Iter-66470, train loss-0.2082, acc-0.9400, valid loss-0.2516, acc-0.9282, test loss-0.2627, acc-0.9274\n",
      "Iter-66480, train loss-0.3220, acc-0.9000, valid loss-0.2516, acc-0.9284, test loss-0.2627, acc-0.9275\n",
      "Iter-66490, train loss-0.2493, acc-0.9400, valid loss-0.2516, acc-0.9280, test loss-0.2626, acc-0.9273\n",
      "Iter-66500, train loss-0.3125, acc-0.8800, valid loss-0.2516, acc-0.9278, test loss-0.2626, acc-0.9275\n",
      "Iter-66510, train loss-0.3273, acc-0.9000, valid loss-0.2516, acc-0.9278, test loss-0.2626, acc-0.9274\n",
      "Iter-66520, train loss-0.3455, acc-0.8600, valid loss-0.2515, acc-0.9272, test loss-0.2626, acc-0.9274\n",
      "Iter-66530, train loss-0.2072, acc-0.9600, valid loss-0.2514, acc-0.9282, test loss-0.2626, acc-0.9280\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-66540, train loss-0.2744, acc-0.8800, valid loss-0.2514, acc-0.9276, test loss-0.2625, acc-0.9278\n",
      "Iter-66550, train loss-0.2217, acc-0.9200, valid loss-0.2514, acc-0.9276, test loss-0.2625, acc-0.9278\n",
      "Iter-66560, train loss-0.3591, acc-0.8800, valid loss-0.2514, acc-0.9272, test loss-0.2624, acc-0.9279\n",
      "Iter-66570, train loss-0.4566, acc-0.8200, valid loss-0.2514, acc-0.9282, test loss-0.2625, acc-0.9277\n",
      "Iter-66580, train loss-0.3552, acc-0.9200, valid loss-0.2514, acc-0.9276, test loss-0.2624, acc-0.9276\n",
      "Iter-66590, train loss-0.4130, acc-0.9000, valid loss-0.2514, acc-0.9276, test loss-0.2624, acc-0.9278\n",
      "Iter-66600, train loss-0.2511, acc-0.9600, valid loss-0.2514, acc-0.9276, test loss-0.2624, acc-0.9276\n",
      "Iter-66610, train loss-0.3899, acc-0.8600, valid loss-0.2513, acc-0.9274, test loss-0.2624, acc-0.9277\n",
      "Iter-66620, train loss-0.3139, acc-0.9400, valid loss-0.2514, acc-0.9272, test loss-0.2624, acc-0.9274\n",
      "Iter-66630, train loss-0.1902, acc-0.9400, valid loss-0.2513, acc-0.9276, test loss-0.2624, acc-0.9271\n",
      "Iter-66640, train loss-0.4677, acc-0.8600, valid loss-0.2513, acc-0.9274, test loss-0.2624, acc-0.9272\n",
      "Iter-66650, train loss-0.2567, acc-0.9200, valid loss-0.2512, acc-0.9280, test loss-0.2623, acc-0.9271\n",
      "Iter-66660, train loss-0.1461, acc-0.9600, valid loss-0.2512, acc-0.9278, test loss-0.2623, acc-0.9270\n",
      "Iter-66670, train loss-0.2943, acc-0.9400, valid loss-0.2512, acc-0.9278, test loss-0.2623, acc-0.9270\n",
      "Iter-66680, train loss-0.1831, acc-0.9600, valid loss-0.2512, acc-0.9276, test loss-0.2623, acc-0.9272\n",
      "Iter-66690, train loss-0.1836, acc-0.9400, valid loss-0.2511, acc-0.9280, test loss-0.2623, acc-0.9270\n",
      "Iter-66700, train loss-0.2287, acc-0.9400, valid loss-0.2511, acc-0.9280, test loss-0.2622, acc-0.9271\n",
      "Iter-66710, train loss-0.3306, acc-0.8800, valid loss-0.2511, acc-0.9280, test loss-0.2622, acc-0.9272\n",
      "Iter-66720, train loss-0.2149, acc-0.9400, valid loss-0.2510, acc-0.9280, test loss-0.2622, acc-0.9274\n",
      "Iter-66730, train loss-0.1574, acc-0.9600, valid loss-0.2510, acc-0.9280, test loss-0.2621, acc-0.9275\n",
      "Iter-66740, train loss-0.2041, acc-0.9400, valid loss-0.2509, acc-0.9284, test loss-0.2621, acc-0.9274\n",
      "Iter-66750, train loss-0.1179, acc-0.9800, valid loss-0.2509, acc-0.9284, test loss-0.2621, acc-0.9276\n",
      "Iter-66760, train loss-0.1553, acc-0.9800, valid loss-0.2510, acc-0.9286, test loss-0.2621, acc-0.9277\n",
      "Iter-66770, train loss-0.2224, acc-0.9200, valid loss-0.2510, acc-0.9286, test loss-0.2621, acc-0.9277\n",
      "Iter-66780, train loss-0.3496, acc-0.9000, valid loss-0.2510, acc-0.9286, test loss-0.2621, acc-0.9275\n",
      "Iter-66790, train loss-0.1365, acc-0.9800, valid loss-0.2509, acc-0.9284, test loss-0.2621, acc-0.9276\n",
      "Iter-66800, train loss-0.2555, acc-0.9200, valid loss-0.2509, acc-0.9280, test loss-0.2621, acc-0.9275\n",
      "Iter-66810, train loss-0.1892, acc-0.9400, valid loss-0.2509, acc-0.9278, test loss-0.2621, acc-0.9277\n",
      "Iter-66820, train loss-0.3113, acc-0.9200, valid loss-0.2510, acc-0.9278, test loss-0.2620, acc-0.9276\n",
      "Iter-66830, train loss-0.3227, acc-0.9200, valid loss-0.2510, acc-0.9280, test loss-0.2620, acc-0.9275\n",
      "Iter-66840, train loss-0.1243, acc-0.9600, valid loss-0.2510, acc-0.9276, test loss-0.2620, acc-0.9274\n",
      "Iter-66850, train loss-0.4096, acc-0.8200, valid loss-0.2510, acc-0.9280, test loss-0.2619, acc-0.9274\n",
      "Iter-66860, train loss-0.4040, acc-0.9000, valid loss-0.2510, acc-0.9284, test loss-0.2619, acc-0.9276\n",
      "Iter-66870, train loss-0.1602, acc-0.9600, valid loss-0.2509, acc-0.9278, test loss-0.2619, acc-0.9275\n",
      "Iter-66880, train loss-0.2648, acc-0.9200, valid loss-0.2509, acc-0.9282, test loss-0.2619, acc-0.9273\n",
      "Iter-66890, train loss-0.2931, acc-0.9200, valid loss-0.2509, acc-0.9282, test loss-0.2619, acc-0.9273\n",
      "Iter-66900, train loss-0.2638, acc-0.9600, valid loss-0.2508, acc-0.9280, test loss-0.2619, acc-0.9276\n",
      "Iter-66910, train loss-0.1683, acc-0.9600, valid loss-0.2508, acc-0.9278, test loss-0.2619, acc-0.9274\n",
      "Iter-66920, train loss-0.4015, acc-0.9000, valid loss-0.2508, acc-0.9278, test loss-0.2618, acc-0.9276\n",
      "Iter-66930, train loss-0.4696, acc-0.8800, valid loss-0.2507, acc-0.9280, test loss-0.2618, acc-0.9276\n",
      "Iter-66940, train loss-0.2367, acc-0.9400, valid loss-0.2507, acc-0.9282, test loss-0.2618, acc-0.9278\n",
      "Iter-66950, train loss-0.3508, acc-0.9000, valid loss-0.2507, acc-0.9282, test loss-0.2618, acc-0.9279\n",
      "Iter-66960, train loss-0.1196, acc-1.0000, valid loss-0.2508, acc-0.9282, test loss-0.2618, acc-0.9275\n",
      "Iter-66970, train loss-0.1738, acc-0.9600, valid loss-0.2508, acc-0.9280, test loss-0.2618, acc-0.9274\n",
      "Iter-66980, train loss-0.1297, acc-0.9800, valid loss-0.2507, acc-0.9280, test loss-0.2618, acc-0.9276\n",
      "Iter-66990, train loss-0.2618, acc-0.9400, valid loss-0.2507, acc-0.9282, test loss-0.2618, acc-0.9277\n",
      "Iter-67000, train loss-0.2968, acc-0.9400, valid loss-0.2507, acc-0.9282, test loss-0.2617, acc-0.9275\n",
      "Iter-67010, train loss-0.3200, acc-0.8800, valid loss-0.2507, acc-0.9282, test loss-0.2618, acc-0.9275\n",
      "Iter-67020, train loss-0.1696, acc-0.9600, valid loss-0.2507, acc-0.9280, test loss-0.2618, acc-0.9275\n",
      "Iter-67030, train loss-0.2081, acc-0.9600, valid loss-0.2507, acc-0.9280, test loss-0.2617, acc-0.9275\n",
      "Iter-67040, train loss-0.2753, acc-0.8800, valid loss-0.2506, acc-0.9280, test loss-0.2618, acc-0.9275\n",
      "Iter-67050, train loss-0.3228, acc-0.9200, valid loss-0.2506, acc-0.9278, test loss-0.2617, acc-0.9277\n",
      "Iter-67060, train loss-0.1379, acc-0.9800, valid loss-0.2507, acc-0.9280, test loss-0.2617, acc-0.9277\n",
      "Iter-67070, train loss-0.1778, acc-0.9600, valid loss-0.2507, acc-0.9278, test loss-0.2617, acc-0.9274\n",
      "Iter-67080, train loss-0.1888, acc-0.9400, valid loss-0.2506, acc-0.9278, test loss-0.2617, acc-0.9277\n",
      "Iter-67090, train loss-0.3527, acc-0.8800, valid loss-0.2507, acc-0.9278, test loss-0.2617, acc-0.9277\n",
      "Iter-67100, train loss-0.2971, acc-0.9400, valid loss-0.2506, acc-0.9276, test loss-0.2617, acc-0.9278\n",
      "Iter-67110, train loss-0.0754, acc-0.9800, valid loss-0.2507, acc-0.9280, test loss-0.2618, acc-0.9278\n",
      "Iter-67120, train loss-0.1749, acc-0.9400, valid loss-0.2506, acc-0.9278, test loss-0.2617, acc-0.9276\n",
      "Iter-67130, train loss-0.3189, acc-0.8800, valid loss-0.2505, acc-0.9276, test loss-0.2617, acc-0.9275\n",
      "Iter-67140, train loss-0.1524, acc-1.0000, valid loss-0.2505, acc-0.9278, test loss-0.2617, acc-0.9278\n",
      "Iter-67150, train loss-0.1904, acc-0.9400, valid loss-0.2505, acc-0.9280, test loss-0.2617, acc-0.9276\n",
      "Iter-67160, train loss-0.2428, acc-0.9600, valid loss-0.2505, acc-0.9278, test loss-0.2617, acc-0.9275\n",
      "Iter-67170, train loss-0.5068, acc-0.8600, valid loss-0.2504, acc-0.9280, test loss-0.2617, acc-0.9276\n",
      "Iter-67180, train loss-0.2166, acc-0.9000, valid loss-0.2504, acc-0.9282, test loss-0.2617, acc-0.9275\n",
      "Iter-67190, train loss-0.1446, acc-0.9400, valid loss-0.2504, acc-0.9282, test loss-0.2617, acc-0.9275\n",
      "Iter-67200, train loss-0.3370, acc-0.9200, valid loss-0.2504, acc-0.9284, test loss-0.2616, acc-0.9275\n",
      "Iter-67210, train loss-0.1431, acc-0.9600, valid loss-0.2504, acc-0.9282, test loss-0.2616, acc-0.9276\n",
      "Iter-67220, train loss-0.4301, acc-0.8800, valid loss-0.2504, acc-0.9280, test loss-0.2616, acc-0.9274\n",
      "Iter-67230, train loss-0.1906, acc-0.9200, valid loss-0.2504, acc-0.9278, test loss-0.2616, acc-0.9275\n",
      "Iter-67240, train loss-0.5347, acc-0.8600, valid loss-0.2505, acc-0.9278, test loss-0.2616, acc-0.9278\n",
      "Iter-67250, train loss-0.2016, acc-0.9800, valid loss-0.2505, acc-0.9276, test loss-0.2616, acc-0.9273\n",
      "Iter-67260, train loss-0.2392, acc-0.8800, valid loss-0.2504, acc-0.9276, test loss-0.2616, acc-0.9275\n",
      "Iter-67270, train loss-0.2839, acc-0.9000, valid loss-0.2505, acc-0.9278, test loss-0.2616, acc-0.9276\n",
      "Iter-67280, train loss-0.2883, acc-0.9200, valid loss-0.2504, acc-0.9276, test loss-0.2616, acc-0.9278\n",
      "Iter-67290, train loss-0.2153, acc-0.9200, valid loss-0.2504, acc-0.9280, test loss-0.2616, acc-0.9276\n",
      "Iter-67300, train loss-0.3899, acc-0.8400, valid loss-0.2504, acc-0.9278, test loss-0.2615, acc-0.9276\n",
      "Iter-67310, train loss-0.1015, acc-1.0000, valid loss-0.2504, acc-0.9276, test loss-0.2616, acc-0.9275\n",
      "Iter-67320, train loss-0.3498, acc-0.9400, valid loss-0.2503, acc-0.9278, test loss-0.2615, acc-0.9277\n",
      "Iter-67330, train loss-0.2427, acc-0.9800, valid loss-0.2503, acc-0.9280, test loss-0.2615, acc-0.9277\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-67340, train loss-0.3795, acc-0.8600, valid loss-0.2503, acc-0.9276, test loss-0.2615, acc-0.9277\n",
      "Iter-67350, train loss-0.3500, acc-0.9400, valid loss-0.2503, acc-0.9278, test loss-0.2615, acc-0.9276\n",
      "Iter-67360, train loss-0.1947, acc-0.9400, valid loss-0.2502, acc-0.9276, test loss-0.2615, acc-0.9279\n",
      "Iter-67370, train loss-0.1366, acc-0.9800, valid loss-0.2503, acc-0.9278, test loss-0.2615, acc-0.9278\n",
      "Iter-67380, train loss-0.1772, acc-0.9600, valid loss-0.2502, acc-0.9278, test loss-0.2615, acc-0.9279\n",
      "Iter-67390, train loss-0.2045, acc-0.9600, valid loss-0.2503, acc-0.9278, test loss-0.2614, acc-0.9280\n",
      "Iter-67400, train loss-0.3495, acc-0.8800, valid loss-0.2503, acc-0.9280, test loss-0.2614, acc-0.9281\n",
      "Iter-67410, train loss-0.3727, acc-0.8800, valid loss-0.2503, acc-0.9280, test loss-0.2614, acc-0.9276\n",
      "Iter-67420, train loss-0.3189, acc-0.9200, valid loss-0.2503, acc-0.9280, test loss-0.2613, acc-0.9277\n",
      "Iter-67430, train loss-0.1438, acc-0.9800, valid loss-0.2502, acc-0.9280, test loss-0.2613, acc-0.9277\n",
      "Iter-67440, train loss-0.2600, acc-0.9000, valid loss-0.2502, acc-0.9282, test loss-0.2612, acc-0.9276\n",
      "Iter-67450, train loss-0.2277, acc-0.9600, valid loss-0.2501, acc-0.9282, test loss-0.2612, acc-0.9275\n",
      "Iter-67460, train loss-0.2303, acc-0.9600, valid loss-0.2501, acc-0.9280, test loss-0.2612, acc-0.9275\n",
      "Iter-67470, train loss-0.5025, acc-0.9000, valid loss-0.2502, acc-0.9280, test loss-0.2612, acc-0.9275\n",
      "Iter-67480, train loss-0.0830, acc-0.9800, valid loss-0.2501, acc-0.9280, test loss-0.2612, acc-0.9275\n",
      "Iter-67490, train loss-0.2182, acc-0.9600, valid loss-0.2501, acc-0.9278, test loss-0.2612, acc-0.9275\n",
      "Iter-67500, train loss-0.2354, acc-0.9200, valid loss-0.2500, acc-0.9278, test loss-0.2611, acc-0.9279\n",
      "Iter-67510, train loss-0.2492, acc-0.9000, valid loss-0.2500, acc-0.9278, test loss-0.2611, acc-0.9280\n",
      "Iter-67520, train loss-0.1947, acc-0.9600, valid loss-0.2500, acc-0.9280, test loss-0.2611, acc-0.9278\n",
      "Iter-67530, train loss-0.4159, acc-0.8400, valid loss-0.2500, acc-0.9278, test loss-0.2611, acc-0.9280\n",
      "Iter-67540, train loss-0.2489, acc-0.9200, valid loss-0.2500, acc-0.9284, test loss-0.2611, acc-0.9279\n",
      "Iter-67550, train loss-0.2179, acc-0.9600, valid loss-0.2501, acc-0.9282, test loss-0.2611, acc-0.9279\n",
      "Iter-67560, train loss-0.1803, acc-0.9600, valid loss-0.2501, acc-0.9280, test loss-0.2610, acc-0.9279\n",
      "Iter-67570, train loss-0.6092, acc-0.8200, valid loss-0.2500, acc-0.9282, test loss-0.2611, acc-0.9278\n",
      "Iter-67580, train loss-0.2089, acc-0.9400, valid loss-0.2500, acc-0.9282, test loss-0.2611, acc-0.9278\n",
      "Iter-67590, train loss-0.4247, acc-0.9000, valid loss-0.2499, acc-0.9282, test loss-0.2611, acc-0.9283\n",
      "Iter-67600, train loss-0.1607, acc-0.9800, valid loss-0.2499, acc-0.9282, test loss-0.2610, acc-0.9281\n",
      "Iter-67610, train loss-0.1969, acc-0.9600, valid loss-0.2498, acc-0.9282, test loss-0.2610, acc-0.9282\n",
      "Iter-67620, train loss-0.3589, acc-0.8800, valid loss-0.2498, acc-0.9282, test loss-0.2610, acc-0.9283\n",
      "Iter-67630, train loss-0.3111, acc-0.9200, valid loss-0.2497, acc-0.9282, test loss-0.2610, acc-0.9280\n",
      "Iter-67640, train loss-0.3316, acc-0.9000, valid loss-0.2496, acc-0.9282, test loss-0.2610, acc-0.9279\n",
      "Iter-67650, train loss-0.3553, acc-0.9000, valid loss-0.2497, acc-0.9282, test loss-0.2609, acc-0.9280\n",
      "Iter-67660, train loss-0.1366, acc-0.9600, valid loss-0.2497, acc-0.9282, test loss-0.2609, acc-0.9278\n",
      "Iter-67670, train loss-0.2873, acc-0.9200, valid loss-0.2497, acc-0.9282, test loss-0.2609, acc-0.9277\n",
      "Iter-67680, train loss-0.1537, acc-0.9600, valid loss-0.2497, acc-0.9286, test loss-0.2609, acc-0.9278\n",
      "Iter-67690, train loss-0.2065, acc-0.9400, valid loss-0.2497, acc-0.9284, test loss-0.2609, acc-0.9278\n",
      "Iter-67700, train loss-0.1693, acc-0.9400, valid loss-0.2498, acc-0.9286, test loss-0.2609, acc-0.9281\n",
      "Iter-67710, train loss-0.1729, acc-0.9200, valid loss-0.2498, acc-0.9282, test loss-0.2609, acc-0.9280\n",
      "Iter-67720, train loss-0.4235, acc-0.8600, valid loss-0.2499, acc-0.9280, test loss-0.2609, acc-0.9282\n",
      "Iter-67730, train loss-0.2642, acc-0.9400, valid loss-0.2499, acc-0.9282, test loss-0.2608, acc-0.9281\n",
      "Iter-67740, train loss-0.2529, acc-0.9200, valid loss-0.2498, acc-0.9282, test loss-0.2609, acc-0.9279\n",
      "Iter-67750, train loss-0.2544, acc-0.8800, valid loss-0.2498, acc-0.9284, test loss-0.2608, acc-0.9277\n",
      "Iter-67760, train loss-0.2579, acc-0.9200, valid loss-0.2498, acc-0.9286, test loss-0.2608, acc-0.9277\n",
      "Iter-67770, train loss-0.1781, acc-0.9400, valid loss-0.2498, acc-0.9280, test loss-0.2607, acc-0.9274\n",
      "Iter-67780, train loss-0.1685, acc-0.9600, valid loss-0.2498, acc-0.9280, test loss-0.2607, acc-0.9275\n",
      "Iter-67790, train loss-0.4357, acc-0.8400, valid loss-0.2498, acc-0.9282, test loss-0.2607, acc-0.9276\n",
      "Iter-67800, train loss-0.3418, acc-0.9200, valid loss-0.2498, acc-0.9282, test loss-0.2607, acc-0.9279\n",
      "Iter-67810, train loss-0.2289, acc-0.9200, valid loss-0.2498, acc-0.9282, test loss-0.2607, acc-0.9278\n",
      "Iter-67820, train loss-0.2566, acc-0.9200, valid loss-0.2497, acc-0.9284, test loss-0.2607, acc-0.9281\n",
      "Iter-67830, train loss-0.1890, acc-0.9400, valid loss-0.2497, acc-0.9282, test loss-0.2607, acc-0.9278\n",
      "Iter-67840, train loss-0.2015, acc-0.9600, valid loss-0.2497, acc-0.9288, test loss-0.2607, acc-0.9281\n",
      "Iter-67850, train loss-0.4191, acc-0.8600, valid loss-0.2497, acc-0.9288, test loss-0.2606, acc-0.9279\n",
      "Iter-67860, train loss-0.2986, acc-0.9200, valid loss-0.2496, acc-0.9288, test loss-0.2606, acc-0.9282\n",
      "Iter-67870, train loss-0.3779, acc-0.8600, valid loss-0.2495, acc-0.9284, test loss-0.2606, acc-0.9281\n",
      "Iter-67880, train loss-0.3933, acc-0.9200, valid loss-0.2496, acc-0.9286, test loss-0.2606, acc-0.9278\n",
      "Iter-67890, train loss-0.2051, acc-0.9400, valid loss-0.2496, acc-0.9290, test loss-0.2606, acc-0.9280\n",
      "Iter-67900, train loss-0.2442, acc-0.9400, valid loss-0.2495, acc-0.9290, test loss-0.2607, acc-0.9277\n",
      "Iter-67910, train loss-0.3463, acc-0.9200, valid loss-0.2495, acc-0.9288, test loss-0.2607, acc-0.9279\n",
      "Iter-67920, train loss-0.1592, acc-0.9600, valid loss-0.2495, acc-0.9286, test loss-0.2607, acc-0.9279\n",
      "Iter-67930, train loss-0.2030, acc-0.9200, valid loss-0.2495, acc-0.9284, test loss-0.2607, acc-0.9281\n",
      "Iter-67940, train loss-0.2115, acc-0.9400, valid loss-0.2495, acc-0.9286, test loss-0.2607, acc-0.9281\n",
      "Iter-67950, train loss-0.4332, acc-0.8200, valid loss-0.2494, acc-0.9286, test loss-0.2607, acc-0.9281\n",
      "Iter-67960, train loss-0.1948, acc-0.9600, valid loss-0.2494, acc-0.9290, test loss-0.2607, acc-0.9279\n",
      "Iter-67970, train loss-0.1198, acc-0.9800, valid loss-0.2493, acc-0.9294, test loss-0.2607, acc-0.9281\n",
      "Iter-67980, train loss-0.2028, acc-0.9400, valid loss-0.2493, acc-0.9292, test loss-0.2607, acc-0.9279\n",
      "Iter-67990, train loss-0.3441, acc-0.9200, valid loss-0.2492, acc-0.9294, test loss-0.2607, acc-0.9278\n",
      "Iter-68000, train loss-0.2428, acc-0.9400, valid loss-0.2492, acc-0.9290, test loss-0.2607, acc-0.9278\n",
      "Iter-68010, train loss-0.1994, acc-0.9400, valid loss-0.2491, acc-0.9290, test loss-0.2607, acc-0.9279\n",
      "Iter-68020, train loss-0.2950, acc-0.9000, valid loss-0.2491, acc-0.9294, test loss-0.2606, acc-0.9278\n",
      "Iter-68030, train loss-0.2543, acc-0.9000, valid loss-0.2491, acc-0.9290, test loss-0.2606, acc-0.9278\n",
      "Iter-68040, train loss-0.1467, acc-0.9800, valid loss-0.2491, acc-0.9292, test loss-0.2606, acc-0.9279\n",
      "Iter-68050, train loss-0.1228, acc-0.9400, valid loss-0.2491, acc-0.9294, test loss-0.2606, acc-0.9279\n",
      "Iter-68060, train loss-0.1809, acc-0.9400, valid loss-0.2491, acc-0.9292, test loss-0.2605, acc-0.9280\n",
      "Iter-68070, train loss-0.2500, acc-0.9600, valid loss-0.2491, acc-0.9294, test loss-0.2605, acc-0.9281\n",
      "Iter-68080, train loss-0.3141, acc-0.8800, valid loss-0.2490, acc-0.9292, test loss-0.2606, acc-0.9279\n",
      "Iter-68090, train loss-0.1747, acc-0.9400, valid loss-0.2490, acc-0.9292, test loss-0.2605, acc-0.9280\n",
      "Iter-68100, train loss-0.3022, acc-0.9200, valid loss-0.2490, acc-0.9290, test loss-0.2605, acc-0.9281\n",
      "Iter-68110, train loss-0.1616, acc-0.9400, valid loss-0.2490, acc-0.9292, test loss-0.2605, acc-0.9279\n",
      "Iter-68120, train loss-0.1541, acc-0.9600, valid loss-0.2490, acc-0.9292, test loss-0.2605, acc-0.9279\n",
      "Iter-68130, train loss-0.1643, acc-0.9800, valid loss-0.2490, acc-0.9292, test loss-0.2605, acc-0.9281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-68140, train loss-0.2922, acc-0.8600, valid loss-0.2490, acc-0.9294, test loss-0.2605, acc-0.9278\n",
      "Iter-68150, train loss-0.2552, acc-0.9000, valid loss-0.2489, acc-0.9298, test loss-0.2604, acc-0.9283\n",
      "Iter-68160, train loss-0.3502, acc-0.9000, valid loss-0.2489, acc-0.9296, test loss-0.2604, acc-0.9283\n",
      "Iter-68170, train loss-0.1906, acc-0.9600, valid loss-0.2490, acc-0.9296, test loss-0.2603, acc-0.9283\n",
      "Iter-68180, train loss-0.2060, acc-0.9600, valid loss-0.2490, acc-0.9294, test loss-0.2603, acc-0.9281\n",
      "Iter-68190, train loss-0.1702, acc-0.9800, valid loss-0.2490, acc-0.9294, test loss-0.2603, acc-0.9281\n",
      "Iter-68200, train loss-0.2700, acc-0.9400, valid loss-0.2490, acc-0.9294, test loss-0.2603, acc-0.9279\n",
      "Iter-68210, train loss-0.2781, acc-0.9000, valid loss-0.2490, acc-0.9292, test loss-0.2603, acc-0.9279\n",
      "Iter-68220, train loss-0.3748, acc-0.9200, valid loss-0.2490, acc-0.9292, test loss-0.2602, acc-0.9280\n",
      "Iter-68230, train loss-0.2813, acc-0.8800, valid loss-0.2491, acc-0.9288, test loss-0.2602, acc-0.9283\n",
      "Iter-68240, train loss-0.2578, acc-0.9200, valid loss-0.2491, acc-0.9290, test loss-0.2602, acc-0.9281\n",
      "Iter-68250, train loss-0.3595, acc-0.9200, valid loss-0.2491, acc-0.9290, test loss-0.2602, acc-0.9283\n",
      "Iter-68260, train loss-0.3515, acc-0.8800, valid loss-0.2490, acc-0.9284, test loss-0.2602, acc-0.9282\n",
      "Iter-68270, train loss-0.2410, acc-0.9200, valid loss-0.2491, acc-0.9286, test loss-0.2602, acc-0.9283\n",
      "Iter-68280, train loss-0.2569, acc-0.8800, valid loss-0.2491, acc-0.9282, test loss-0.2602, acc-0.9281\n",
      "Iter-68290, train loss-0.2556, acc-0.9400, valid loss-0.2491, acc-0.9280, test loss-0.2602, acc-0.9284\n",
      "Iter-68300, train loss-0.3722, acc-0.8800, valid loss-0.2490, acc-0.9282, test loss-0.2602, acc-0.9282\n",
      "Iter-68310, train loss-0.4503, acc-0.8400, valid loss-0.2491, acc-0.9280, test loss-0.2602, acc-0.9283\n",
      "Iter-68320, train loss-0.1614, acc-0.9400, valid loss-0.2490, acc-0.9286, test loss-0.2601, acc-0.9284\n",
      "Iter-68330, train loss-0.2920, acc-0.9800, valid loss-0.2490, acc-0.9286, test loss-0.2601, acc-0.9283\n",
      "Iter-68340, train loss-0.3647, acc-0.8800, valid loss-0.2490, acc-0.9286, test loss-0.2601, acc-0.9283\n",
      "Iter-68350, train loss-0.3093, acc-0.9200, valid loss-0.2490, acc-0.9284, test loss-0.2601, acc-0.9282\n",
      "Iter-68360, train loss-0.3290, acc-0.8800, valid loss-0.2490, acc-0.9286, test loss-0.2601, acc-0.9278\n",
      "Iter-68370, train loss-0.2417, acc-0.9200, valid loss-0.2490, acc-0.9286, test loss-0.2601, acc-0.9280\n",
      "Iter-68380, train loss-0.3821, acc-0.9200, valid loss-0.2490, acc-0.9284, test loss-0.2600, acc-0.9279\n",
      "Iter-68390, train loss-0.3233, acc-0.9200, valid loss-0.2490, acc-0.9286, test loss-0.2600, acc-0.9279\n",
      "Iter-68400, train loss-0.1155, acc-0.9800, valid loss-0.2490, acc-0.9284, test loss-0.2599, acc-0.9276\n",
      "Iter-68410, train loss-0.1015, acc-0.9800, valid loss-0.2490, acc-0.9282, test loss-0.2599, acc-0.9279\n",
      "Iter-68420, train loss-0.2052, acc-0.9400, valid loss-0.2490, acc-0.9286, test loss-0.2599, acc-0.9276\n",
      "Iter-68430, train loss-0.2357, acc-0.9400, valid loss-0.2490, acc-0.9282, test loss-0.2600, acc-0.9279\n",
      "Iter-68440, train loss-0.2150, acc-0.9200, valid loss-0.2490, acc-0.9286, test loss-0.2599, acc-0.9279\n",
      "Iter-68450, train loss-0.2444, acc-0.9600, valid loss-0.2490, acc-0.9284, test loss-0.2599, acc-0.9280\n",
      "Iter-68460, train loss-0.2004, acc-0.9600, valid loss-0.2489, acc-0.9284, test loss-0.2598, acc-0.9281\n",
      "Iter-68470, train loss-0.1591, acc-0.9400, valid loss-0.2489, acc-0.9284, test loss-0.2597, acc-0.9282\n",
      "Iter-68480, train loss-0.4314, acc-0.8600, valid loss-0.2489, acc-0.9282, test loss-0.2597, acc-0.9279\n",
      "Iter-68490, train loss-0.2318, acc-0.9800, valid loss-0.2490, acc-0.9284, test loss-0.2597, acc-0.9279\n",
      "Iter-68500, train loss-0.2545, acc-0.9400, valid loss-0.2490, acc-0.9278, test loss-0.2597, acc-0.9280\n",
      "Iter-68510, train loss-0.2088, acc-0.9200, valid loss-0.2489, acc-0.9282, test loss-0.2597, acc-0.9281\n",
      "Iter-68520, train loss-0.3039, acc-0.9000, valid loss-0.2488, acc-0.9280, test loss-0.2596, acc-0.9280\n",
      "Iter-68530, train loss-0.1702, acc-0.9200, valid loss-0.2488, acc-0.9282, test loss-0.2596, acc-0.9279\n",
      "Iter-68540, train loss-0.5616, acc-0.8600, valid loss-0.2488, acc-0.9284, test loss-0.2597, acc-0.9281\n",
      "Iter-68550, train loss-0.2507, acc-0.9000, valid loss-0.2488, acc-0.9286, test loss-0.2597, acc-0.9282\n",
      "Iter-68560, train loss-0.1517, acc-0.9400, valid loss-0.2488, acc-0.9282, test loss-0.2597, acc-0.9280\n",
      "Iter-68570, train loss-0.2868, acc-0.9200, valid loss-0.2488, acc-0.9282, test loss-0.2598, acc-0.9280\n",
      "Iter-68580, train loss-0.2701, acc-0.9200, valid loss-0.2487, acc-0.9284, test loss-0.2597, acc-0.9279\n",
      "Iter-68590, train loss-0.0996, acc-0.9800, valid loss-0.2487, acc-0.9286, test loss-0.2597, acc-0.9279\n",
      "Iter-68600, train loss-0.2368, acc-0.9400, valid loss-0.2487, acc-0.9286, test loss-0.2597, acc-0.9278\n",
      "Iter-68610, train loss-0.2867, acc-0.9400, valid loss-0.2487, acc-0.9286, test loss-0.2597, acc-0.9277\n",
      "Iter-68620, train loss-0.2213, acc-0.9400, valid loss-0.2487, acc-0.9284, test loss-0.2597, acc-0.9278\n",
      "Iter-68630, train loss-0.3998, acc-0.9000, valid loss-0.2487, acc-0.9286, test loss-0.2597, acc-0.9278\n",
      "Iter-68640, train loss-0.3155, acc-0.9400, valid loss-0.2486, acc-0.9286, test loss-0.2597, acc-0.9277\n",
      "Iter-68650, train loss-0.2703, acc-0.9400, valid loss-0.2486, acc-0.9286, test loss-0.2597, acc-0.9278\n",
      "Iter-68660, train loss-0.2675, acc-0.9200, valid loss-0.2485, acc-0.9286, test loss-0.2596, acc-0.9279\n",
      "Iter-68670, train loss-0.2508, acc-0.9200, valid loss-0.2485, acc-0.9286, test loss-0.2596, acc-0.9280\n",
      "Iter-68680, train loss-0.1997, acc-0.9400, valid loss-0.2484, acc-0.9288, test loss-0.2596, acc-0.9279\n",
      "Iter-68690, train loss-0.1963, acc-0.9200, valid loss-0.2485, acc-0.9290, test loss-0.2596, acc-0.9279\n",
      "Iter-68700, train loss-0.1903, acc-0.9400, valid loss-0.2484, acc-0.9290, test loss-0.2596, acc-0.9279\n",
      "Iter-68710, train loss-0.1768, acc-0.9200, valid loss-0.2485, acc-0.9290, test loss-0.2596, acc-0.9281\n",
      "Iter-68720, train loss-0.4108, acc-0.8600, valid loss-0.2484, acc-0.9294, test loss-0.2596, acc-0.9281\n",
      "Iter-68730, train loss-0.1800, acc-0.9600, valid loss-0.2484, acc-0.9292, test loss-0.2595, acc-0.9281\n",
      "Iter-68740, train loss-0.2791, acc-0.8800, valid loss-0.2483, acc-0.9292, test loss-0.2595, acc-0.9280\n",
      "Iter-68750, train loss-0.3219, acc-0.9200, valid loss-0.2483, acc-0.9290, test loss-0.2594, acc-0.9282\n",
      "Iter-68760, train loss-0.2378, acc-0.9400, valid loss-0.2482, acc-0.9294, test loss-0.2595, acc-0.9280\n",
      "Iter-68770, train loss-0.1794, acc-0.9400, valid loss-0.2482, acc-0.9290, test loss-0.2594, acc-0.9282\n",
      "Iter-68780, train loss-0.2065, acc-0.9000, valid loss-0.2482, acc-0.9286, test loss-0.2594, acc-0.9279\n",
      "Iter-68790, train loss-0.3447, acc-0.8800, valid loss-0.2482, acc-0.9288, test loss-0.2595, acc-0.9277\n",
      "Iter-68800, train loss-0.2711, acc-0.9400, valid loss-0.2483, acc-0.9286, test loss-0.2595, acc-0.9278\n",
      "Iter-68810, train loss-0.1696, acc-0.9000, valid loss-0.2482, acc-0.9284, test loss-0.2595, acc-0.9281\n",
      "Iter-68820, train loss-0.3359, acc-0.9000, valid loss-0.2482, acc-0.9286, test loss-0.2595, acc-0.9281\n",
      "Iter-68830, train loss-0.1539, acc-0.9800, valid loss-0.2482, acc-0.9294, test loss-0.2595, acc-0.9280\n",
      "Iter-68840, train loss-0.3598, acc-0.9000, valid loss-0.2482, acc-0.9292, test loss-0.2594, acc-0.9280\n",
      "Iter-68850, train loss-0.3681, acc-0.9000, valid loss-0.2482, acc-0.9292, test loss-0.2595, acc-0.9280\n",
      "Iter-68860, train loss-0.3130, acc-0.9200, valid loss-0.2481, acc-0.9290, test loss-0.2594, acc-0.9279\n",
      "Iter-68870, train loss-0.2174, acc-0.9600, valid loss-0.2481, acc-0.9290, test loss-0.2594, acc-0.9278\n",
      "Iter-68880, train loss-0.2070, acc-0.9400, valid loss-0.2480, acc-0.9292, test loss-0.2594, acc-0.9276\n",
      "Iter-68890, train loss-0.1386, acc-0.9600, valid loss-0.2480, acc-0.9290, test loss-0.2594, acc-0.9277\n",
      "Iter-68900, train loss-0.1654, acc-0.9600, valid loss-0.2480, acc-0.9294, test loss-0.2594, acc-0.9277\n",
      "Iter-68910, train loss-0.1737, acc-0.9600, valid loss-0.2481, acc-0.9288, test loss-0.2594, acc-0.9278\n",
      "Iter-68920, train loss-0.2208, acc-0.9200, valid loss-0.2480, acc-0.9290, test loss-0.2593, acc-0.9277\n",
      "Iter-68930, train loss-0.2410, acc-0.9000, valid loss-0.2480, acc-0.9290, test loss-0.2593, acc-0.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-68940, train loss-0.2132, acc-0.9200, valid loss-0.2480, acc-0.9290, test loss-0.2593, acc-0.9278\n",
      "Iter-68950, train loss-0.3220, acc-0.9000, valid loss-0.2480, acc-0.9292, test loss-0.2593, acc-0.9280\n",
      "Iter-68960, train loss-0.2357, acc-0.9400, valid loss-0.2480, acc-0.9290, test loss-0.2592, acc-0.9281\n",
      "Iter-68970, train loss-0.3883, acc-0.8800, valid loss-0.2480, acc-0.9288, test loss-0.2592, acc-0.9280\n",
      "Iter-68980, train loss-0.2638, acc-0.9200, valid loss-0.2480, acc-0.9290, test loss-0.2592, acc-0.9282\n",
      "Iter-68990, train loss-0.2045, acc-0.9400, valid loss-0.2479, acc-0.9288, test loss-0.2591, acc-0.9280\n",
      "Iter-69000, train loss-0.3679, acc-0.9200, valid loss-0.2479, acc-0.9288, test loss-0.2591, acc-0.9280\n",
      "Iter-69010, train loss-0.5868, acc-0.8600, valid loss-0.2478, acc-0.9292, test loss-0.2592, acc-0.9279\n",
      "Iter-69020, train loss-0.3308, acc-0.8800, valid loss-0.2478, acc-0.9292, test loss-0.2591, acc-0.9277\n",
      "Iter-69030, train loss-0.2049, acc-0.9400, valid loss-0.2478, acc-0.9288, test loss-0.2591, acc-0.9275\n",
      "Iter-69040, train loss-0.1777, acc-0.9400, valid loss-0.2478, acc-0.9294, test loss-0.2591, acc-0.9277\n",
      "Iter-69050, train loss-0.4019, acc-0.8800, valid loss-0.2476, acc-0.9294, test loss-0.2591, acc-0.9277\n",
      "Iter-69060, train loss-0.1461, acc-0.9600, valid loss-0.2477, acc-0.9292, test loss-0.2590, acc-0.9279\n",
      "Iter-69070, train loss-0.2373, acc-0.9000, valid loss-0.2477, acc-0.9294, test loss-0.2590, acc-0.9280\n",
      "Iter-69080, train loss-0.1100, acc-0.9800, valid loss-0.2477, acc-0.9290, test loss-0.2590, acc-0.9279\n",
      "Iter-69090, train loss-0.3531, acc-0.8400, valid loss-0.2477, acc-0.9294, test loss-0.2590, acc-0.9280\n",
      "Iter-69100, train loss-0.1906, acc-0.9400, valid loss-0.2477, acc-0.9290, test loss-0.2589, acc-0.9280\n",
      "Iter-69110, train loss-0.1668, acc-0.9800, valid loss-0.2476, acc-0.9290, test loss-0.2589, acc-0.9281\n",
      "Iter-69120, train loss-0.2347, acc-0.9400, valid loss-0.2476, acc-0.9292, test loss-0.2589, acc-0.9279\n",
      "Iter-69130, train loss-0.2623, acc-0.9400, valid loss-0.2476, acc-0.9290, test loss-0.2588, acc-0.9278\n",
      "Iter-69140, train loss-0.1528, acc-0.9400, valid loss-0.2476, acc-0.9288, test loss-0.2588, acc-0.9279\n",
      "Iter-69150, train loss-0.0719, acc-1.0000, valid loss-0.2475, acc-0.9286, test loss-0.2588, acc-0.9280\n",
      "Iter-69160, train loss-0.4062, acc-0.8600, valid loss-0.2476, acc-0.9288, test loss-0.2588, acc-0.9283\n",
      "Iter-69170, train loss-0.3134, acc-0.8800, valid loss-0.2475, acc-0.9286, test loss-0.2588, acc-0.9282\n",
      "Iter-69180, train loss-0.2902, acc-0.9200, valid loss-0.2475, acc-0.9290, test loss-0.2588, acc-0.9280\n",
      "Iter-69190, train loss-0.2671, acc-0.9400, valid loss-0.2476, acc-0.9290, test loss-0.2588, acc-0.9283\n",
      "Iter-69200, train loss-0.1522, acc-0.9600, valid loss-0.2476, acc-0.9290, test loss-0.2588, acc-0.9282\n",
      "Iter-69210, train loss-0.3643, acc-0.9000, valid loss-0.2476, acc-0.9292, test loss-0.2587, acc-0.9281\n",
      "Iter-69220, train loss-0.2516, acc-0.9600, valid loss-0.2476, acc-0.9290, test loss-0.2587, acc-0.9280\n",
      "Iter-69230, train loss-0.4634, acc-0.8800, valid loss-0.2476, acc-0.9288, test loss-0.2587, acc-0.9282\n",
      "Iter-69240, train loss-0.2888, acc-0.9200, valid loss-0.2476, acc-0.9288, test loss-0.2587, acc-0.9284\n",
      "Iter-69250, train loss-0.1901, acc-0.9400, valid loss-0.2475, acc-0.9288, test loss-0.2587, acc-0.9284\n",
      "Iter-69260, train loss-0.1283, acc-0.9600, valid loss-0.2476, acc-0.9286, test loss-0.2587, acc-0.9284\n",
      "Iter-69270, train loss-0.2691, acc-0.9400, valid loss-0.2475, acc-0.9288, test loss-0.2587, acc-0.9284\n",
      "Iter-69280, train loss-0.2632, acc-0.9200, valid loss-0.2475, acc-0.9288, test loss-0.2587, acc-0.9286\n",
      "Iter-69290, train loss-0.2542, acc-0.9200, valid loss-0.2475, acc-0.9286, test loss-0.2587, acc-0.9284\n",
      "Iter-69300, train loss-0.2690, acc-0.9600, valid loss-0.2475, acc-0.9286, test loss-0.2587, acc-0.9287\n",
      "Iter-69310, train loss-0.1680, acc-0.9400, valid loss-0.2474, acc-0.9286, test loss-0.2587, acc-0.9282\n",
      "Iter-69320, train loss-0.2308, acc-0.9400, valid loss-0.2474, acc-0.9286, test loss-0.2587, acc-0.9282\n",
      "Iter-69330, train loss-0.1772, acc-0.9200, valid loss-0.2475, acc-0.9290, test loss-0.2587, acc-0.9282\n",
      "Iter-69340, train loss-0.1557, acc-0.9800, valid loss-0.2475, acc-0.9288, test loss-0.2586, acc-0.9283\n",
      "Iter-69350, train loss-0.5036, acc-0.8400, valid loss-0.2475, acc-0.9286, test loss-0.2586, acc-0.9281\n",
      "Iter-69360, train loss-0.1351, acc-0.9800, valid loss-0.2475, acc-0.9284, test loss-0.2586, acc-0.9278\n",
      "Iter-69370, train loss-0.2008, acc-0.9600, valid loss-0.2475, acc-0.9286, test loss-0.2586, acc-0.9278\n",
      "Iter-69380, train loss-0.1136, acc-0.9800, valid loss-0.2475, acc-0.9288, test loss-0.2586, acc-0.9279\n",
      "Iter-69390, train loss-0.2710, acc-0.9600, valid loss-0.2475, acc-0.9290, test loss-0.2586, acc-0.9276\n",
      "Iter-69400, train loss-0.2759, acc-0.9400, valid loss-0.2474, acc-0.9288, test loss-0.2586, acc-0.9274\n",
      "Iter-69410, train loss-0.1875, acc-0.9400, valid loss-0.2474, acc-0.9284, test loss-0.2586, acc-0.9276\n",
      "Iter-69420, train loss-0.1657, acc-0.9600, valid loss-0.2473, acc-0.9284, test loss-0.2585, acc-0.9278\n",
      "Iter-69430, train loss-0.3360, acc-0.9200, valid loss-0.2473, acc-0.9286, test loss-0.2585, acc-0.9279\n",
      "Iter-69440, train loss-0.1039, acc-0.9400, valid loss-0.2473, acc-0.9284, test loss-0.2585, acc-0.9278\n",
      "Iter-69450, train loss-0.2204, acc-0.9200, valid loss-0.2473, acc-0.9284, test loss-0.2585, acc-0.9280\n",
      "Iter-69460, train loss-0.3110, acc-0.9000, valid loss-0.2473, acc-0.9284, test loss-0.2585, acc-0.9282\n",
      "Iter-69470, train loss-0.2869, acc-0.8800, valid loss-0.2473, acc-0.9286, test loss-0.2584, acc-0.9279\n",
      "Iter-69480, train loss-0.1073, acc-0.9800, valid loss-0.2473, acc-0.9288, test loss-0.2584, acc-0.9281\n",
      "Iter-69490, train loss-0.2608, acc-0.9400, valid loss-0.2473, acc-0.9286, test loss-0.2585, acc-0.9281\n",
      "Iter-69500, train loss-0.2033, acc-0.9600, valid loss-0.2473, acc-0.9286, test loss-0.2585, acc-0.9282\n",
      "Iter-69510, train loss-0.1502, acc-0.9600, valid loss-0.2473, acc-0.9284, test loss-0.2584, acc-0.9282\n",
      "Iter-69520, train loss-0.2105, acc-0.9400, valid loss-0.2473, acc-0.9284, test loss-0.2583, acc-0.9285\n",
      "Iter-69530, train loss-0.2583, acc-0.9000, valid loss-0.2473, acc-0.9286, test loss-0.2583, acc-0.9283\n",
      "Iter-69540, train loss-0.2139, acc-0.9200, valid loss-0.2473, acc-0.9286, test loss-0.2583, acc-0.9284\n",
      "Iter-69550, train loss-0.5007, acc-0.8800, valid loss-0.2473, acc-0.9284, test loss-0.2583, acc-0.9285\n",
      "Iter-69560, train loss-0.1794, acc-0.9400, valid loss-0.2473, acc-0.9288, test loss-0.2583, acc-0.9285\n",
      "Iter-69570, train loss-0.3649, acc-0.8800, valid loss-0.2472, acc-0.9288, test loss-0.2582, acc-0.9284\n",
      "Iter-69580, train loss-0.4227, acc-0.9000, valid loss-0.2473, acc-0.9284, test loss-0.2582, acc-0.9284\n",
      "Iter-69590, train loss-0.1895, acc-0.9600, valid loss-0.2472, acc-0.9280, test loss-0.2582, acc-0.9284\n",
      "Iter-69600, train loss-0.1230, acc-0.9600, valid loss-0.2472, acc-0.9286, test loss-0.2582, acc-0.9288\n",
      "Iter-69610, train loss-0.1228, acc-0.9600, valid loss-0.2471, acc-0.9286, test loss-0.2582, acc-0.9288\n",
      "Iter-69620, train loss-0.3077, acc-0.9200, valid loss-0.2471, acc-0.9284, test loss-0.2581, acc-0.9288\n",
      "Iter-69630, train loss-0.2497, acc-0.9400, valid loss-0.2471, acc-0.9286, test loss-0.2580, acc-0.9286\n",
      "Iter-69640, train loss-0.2299, acc-0.9200, valid loss-0.2471, acc-0.9288, test loss-0.2580, acc-0.9286\n",
      "Iter-69650, train loss-0.2951, acc-0.9400, valid loss-0.2470, acc-0.9284, test loss-0.2580, acc-0.9283\n",
      "Iter-69660, train loss-0.3190, acc-0.9200, valid loss-0.2471, acc-0.9288, test loss-0.2580, acc-0.9284\n",
      "Iter-69670, train loss-0.4177, acc-0.8800, valid loss-0.2470, acc-0.9288, test loss-0.2580, acc-0.9285\n",
      "Iter-69680, train loss-0.2745, acc-0.9400, valid loss-0.2470, acc-0.9290, test loss-0.2580, acc-0.9285\n",
      "Iter-69690, train loss-0.1975, acc-0.9200, valid loss-0.2470, acc-0.9290, test loss-0.2579, acc-0.9284\n",
      "Iter-69700, train loss-0.2790, acc-0.8600, valid loss-0.2470, acc-0.9288, test loss-0.2579, acc-0.9285\n",
      "Iter-69710, train loss-0.2539, acc-0.9200, valid loss-0.2470, acc-0.9286, test loss-0.2579, acc-0.9285\n",
      "Iter-69720, train loss-0.1291, acc-0.9800, valid loss-0.2470, acc-0.9286, test loss-0.2579, acc-0.9285\n",
      "Iter-69730, train loss-0.2069, acc-0.9600, valid loss-0.2469, acc-0.9286, test loss-0.2579, acc-0.9284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-69740, train loss-0.1503, acc-0.9800, valid loss-0.2469, acc-0.9286, test loss-0.2579, acc-0.9283\n",
      "Iter-69750, train loss-0.2622, acc-0.9000, valid loss-0.2468, acc-0.9288, test loss-0.2579, acc-0.9283\n",
      "Iter-69760, train loss-0.2754, acc-0.8800, valid loss-0.2468, acc-0.9286, test loss-0.2578, acc-0.9285\n",
      "Iter-69770, train loss-0.3076, acc-0.9200, valid loss-0.2468, acc-0.9286, test loss-0.2578, acc-0.9288\n",
      "Iter-69780, train loss-0.3137, acc-0.9400, valid loss-0.2468, acc-0.9288, test loss-0.2578, acc-0.9284\n",
      "Iter-69790, train loss-0.3545, acc-0.9600, valid loss-0.2468, acc-0.9286, test loss-0.2579, acc-0.9284\n",
      "Iter-69800, train loss-0.3060, acc-0.8800, valid loss-0.2468, acc-0.9284, test loss-0.2578, acc-0.9284\n",
      "Iter-69810, train loss-0.2754, acc-0.8600, valid loss-0.2468, acc-0.9286, test loss-0.2579, acc-0.9284\n",
      "Iter-69820, train loss-0.1624, acc-0.9600, valid loss-0.2468, acc-0.9290, test loss-0.2579, acc-0.9285\n",
      "Iter-69830, train loss-0.2757, acc-0.9000, valid loss-0.2468, acc-0.9286, test loss-0.2579, acc-0.9285\n",
      "Iter-69840, train loss-0.2891, acc-0.9200, valid loss-0.2468, acc-0.9284, test loss-0.2579, acc-0.9286\n",
      "Iter-69850, train loss-0.2534, acc-0.9600, valid loss-0.2468, acc-0.9282, test loss-0.2578, acc-0.9285\n",
      "Iter-69860, train loss-0.2916, acc-0.9400, valid loss-0.2467, acc-0.9282, test loss-0.2579, acc-0.9286\n",
      "Iter-69870, train loss-0.2499, acc-0.9000, valid loss-0.2467, acc-0.9282, test loss-0.2579, acc-0.9285\n",
      "Iter-69880, train loss-0.3332, acc-0.9000, valid loss-0.2467, acc-0.9280, test loss-0.2578, acc-0.9285\n",
      "Iter-69890, train loss-0.2321, acc-0.9200, valid loss-0.2468, acc-0.9280, test loss-0.2579, acc-0.9283\n",
      "Iter-69900, train loss-0.1922, acc-0.9200, valid loss-0.2467, acc-0.9280, test loss-0.2578, acc-0.9283\n",
      "Iter-69910, train loss-0.3475, acc-0.8600, valid loss-0.2467, acc-0.9284, test loss-0.2578, acc-0.9285\n",
      "Iter-69920, train loss-0.3754, acc-0.8600, valid loss-0.2466, acc-0.9286, test loss-0.2577, acc-0.9284\n",
      "Iter-69930, train loss-0.3149, acc-0.8600, valid loss-0.2466, acc-0.9284, test loss-0.2577, acc-0.9286\n",
      "Iter-69940, train loss-0.1237, acc-0.9600, valid loss-0.2466, acc-0.9284, test loss-0.2577, acc-0.9287\n",
      "Iter-69950, train loss-0.1710, acc-0.9800, valid loss-0.2466, acc-0.9284, test loss-0.2577, acc-0.9287\n",
      "Iter-69960, train loss-0.1752, acc-0.9400, valid loss-0.2466, acc-0.9284, test loss-0.2578, acc-0.9286\n",
      "Iter-69970, train loss-0.2312, acc-0.9200, valid loss-0.2465, acc-0.9284, test loss-0.2578, acc-0.9287\n",
      "Iter-69980, train loss-0.1918, acc-0.9400, valid loss-0.2466, acc-0.9284, test loss-0.2578, acc-0.9286\n",
      "Iter-69990, train loss-0.1788, acc-0.9400, valid loss-0.2466, acc-0.9282, test loss-0.2578, acc-0.9287\n",
      "Iter-70000, train loss-0.4086, acc-0.8600, valid loss-0.2465, acc-0.9284, test loss-0.2578, acc-0.9287\n",
      "Iter-70010, train loss-0.2131, acc-0.9400, valid loss-0.2465, acc-0.9284, test loss-0.2578, acc-0.9286\n",
      "Iter-70020, train loss-0.0718, acc-1.0000, valid loss-0.2465, acc-0.9286, test loss-0.2578, acc-0.9287\n",
      "Iter-70030, train loss-0.4524, acc-0.8400, valid loss-0.2464, acc-0.9288, test loss-0.2577, acc-0.9287\n",
      "Iter-70040, train loss-0.2150, acc-0.9200, valid loss-0.2464, acc-0.9286, test loss-0.2577, acc-0.9289\n",
      "Iter-70050, train loss-0.2545, acc-0.9000, valid loss-0.2464, acc-0.9286, test loss-0.2577, acc-0.9286\n",
      "Iter-70060, train loss-0.3784, acc-0.9000, valid loss-0.2464, acc-0.9284, test loss-0.2577, acc-0.9288\n",
      "Iter-70070, train loss-0.4115, acc-0.9200, valid loss-0.2464, acc-0.9284, test loss-0.2576, acc-0.9288\n",
      "Iter-70080, train loss-0.2170, acc-0.9400, valid loss-0.2465, acc-0.9288, test loss-0.2576, acc-0.9289\n",
      "Iter-70090, train loss-0.2126, acc-0.8800, valid loss-0.2465, acc-0.9288, test loss-0.2576, acc-0.9286\n",
      "Iter-70100, train loss-0.1841, acc-0.9800, valid loss-0.2464, acc-0.9288, test loss-0.2576, acc-0.9287\n",
      "Iter-70110, train loss-0.1304, acc-0.9800, valid loss-0.2464, acc-0.9284, test loss-0.2576, acc-0.9288\n",
      "Iter-70120, train loss-0.0937, acc-1.0000, valid loss-0.2464, acc-0.9284, test loss-0.2575, acc-0.9288\n",
      "Iter-70130, train loss-0.3253, acc-0.9200, valid loss-0.2464, acc-0.9282, test loss-0.2575, acc-0.9289\n",
      "Iter-70140, train loss-0.2439, acc-0.9400, valid loss-0.2464, acc-0.9286, test loss-0.2575, acc-0.9291\n",
      "Iter-70150, train loss-0.1592, acc-0.9600, valid loss-0.2464, acc-0.9284, test loss-0.2575, acc-0.9290\n",
      "Iter-70160, train loss-0.3880, acc-0.9000, valid loss-0.2464, acc-0.9288, test loss-0.2575, acc-0.9290\n",
      "Iter-70170, train loss-0.1970, acc-0.9600, valid loss-0.2464, acc-0.9290, test loss-0.2575, acc-0.9289\n",
      "Iter-70180, train loss-0.1372, acc-0.9800, valid loss-0.2464, acc-0.9286, test loss-0.2575, acc-0.9289\n",
      "Iter-70190, train loss-0.2317, acc-0.9600, valid loss-0.2463, acc-0.9284, test loss-0.2575, acc-0.9290\n",
      "Iter-70200, train loss-0.1814, acc-0.9600, valid loss-0.2464, acc-0.9290, test loss-0.2575, acc-0.9290\n",
      "Iter-70210, train loss-0.3124, acc-0.9200, valid loss-0.2464, acc-0.9284, test loss-0.2575, acc-0.9294\n",
      "Iter-70220, train loss-0.2637, acc-0.8600, valid loss-0.2464, acc-0.9286, test loss-0.2575, acc-0.9291\n",
      "Iter-70230, train loss-0.3629, acc-0.9000, valid loss-0.2464, acc-0.9286, test loss-0.2574, acc-0.9292\n",
      "Iter-70240, train loss-0.2640, acc-0.9200, valid loss-0.2464, acc-0.9286, test loss-0.2574, acc-0.9291\n",
      "Iter-70250, train loss-0.2158, acc-0.9200, valid loss-0.2464, acc-0.9290, test loss-0.2574, acc-0.9291\n",
      "Iter-70260, train loss-0.1386, acc-0.9800, valid loss-0.2464, acc-0.9288, test loss-0.2574, acc-0.9291\n",
      "Iter-70270, train loss-0.2151, acc-0.9600, valid loss-0.2464, acc-0.9284, test loss-0.2574, acc-0.9291\n",
      "Iter-70280, train loss-0.2245, acc-0.9200, valid loss-0.2463, acc-0.9284, test loss-0.2573, acc-0.9290\n",
      "Iter-70290, train loss-0.1540, acc-0.9800, valid loss-0.2463, acc-0.9286, test loss-0.2573, acc-0.9288\n",
      "Iter-70300, train loss-0.3301, acc-0.9000, valid loss-0.2464, acc-0.9282, test loss-0.2573, acc-0.9292\n",
      "Iter-70310, train loss-0.4287, acc-0.8800, valid loss-0.2464, acc-0.9286, test loss-0.2573, acc-0.9291\n",
      "Iter-70320, train loss-0.1949, acc-0.9600, valid loss-0.2463, acc-0.9282, test loss-0.2572, acc-0.9290\n",
      "Iter-70330, train loss-0.2555, acc-0.9200, valid loss-0.2463, acc-0.9286, test loss-0.2573, acc-0.9291\n",
      "Iter-70340, train loss-0.4268, acc-0.8800, valid loss-0.2462, acc-0.9290, test loss-0.2572, acc-0.9293\n",
      "Iter-70350, train loss-0.3679, acc-0.9000, valid loss-0.2462, acc-0.9290, test loss-0.2572, acc-0.9292\n",
      "Iter-70360, train loss-0.1198, acc-0.9800, valid loss-0.2462, acc-0.9288, test loss-0.2572, acc-0.9291\n",
      "Iter-70370, train loss-0.2495, acc-0.9200, valid loss-0.2462, acc-0.9290, test loss-0.2571, acc-0.9290\n",
      "Iter-70380, train loss-0.4980, acc-0.8400, valid loss-0.2462, acc-0.9292, test loss-0.2571, acc-0.9289\n",
      "Iter-70390, train loss-0.1935, acc-0.9200, valid loss-0.2463, acc-0.9290, test loss-0.2571, acc-0.9290\n",
      "Iter-70400, train loss-0.1025, acc-0.9800, valid loss-0.2462, acc-0.9288, test loss-0.2571, acc-0.9286\n",
      "Iter-70410, train loss-0.2787, acc-0.9000, valid loss-0.2462, acc-0.9292, test loss-0.2571, acc-0.9286\n",
      "Iter-70420, train loss-0.3849, acc-0.8600, valid loss-0.2462, acc-0.9288, test loss-0.2571, acc-0.9288\n",
      "Iter-70430, train loss-0.2188, acc-0.9200, valid loss-0.2461, acc-0.9290, test loss-0.2570, acc-0.9286\n",
      "Iter-70440, train loss-0.2192, acc-0.9400, valid loss-0.2461, acc-0.9290, test loss-0.2571, acc-0.9287\n",
      "Iter-70450, train loss-0.1262, acc-0.9800, valid loss-0.2461, acc-0.9292, test loss-0.2571, acc-0.9286\n",
      "Iter-70460, train loss-0.1993, acc-0.9400, valid loss-0.2461, acc-0.9288, test loss-0.2570, acc-0.9288\n",
      "Iter-70470, train loss-0.2519, acc-0.9200, valid loss-0.2461, acc-0.9284, test loss-0.2570, acc-0.9285\n",
      "Iter-70480, train loss-0.1904, acc-0.9200, valid loss-0.2461, acc-0.9288, test loss-0.2570, acc-0.9284\n",
      "Iter-70490, train loss-0.3325, acc-0.9200, valid loss-0.2461, acc-0.9292, test loss-0.2570, acc-0.9287\n",
      "Iter-70500, train loss-0.4679, acc-0.8400, valid loss-0.2460, acc-0.9290, test loss-0.2570, acc-0.9285\n",
      "Iter-70510, train loss-0.3238, acc-0.9000, valid loss-0.2460, acc-0.9288, test loss-0.2570, acc-0.9290\n",
      "Iter-70520, train loss-0.2905, acc-0.9000, valid loss-0.2459, acc-0.9286, test loss-0.2570, acc-0.9288\n",
      "Iter-70530, train loss-0.2989, acc-0.9400, valid loss-0.2459, acc-0.9288, test loss-0.2570, acc-0.9290\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-70540, train loss-0.3193, acc-0.9200, valid loss-0.2459, acc-0.9286, test loss-0.2570, acc-0.9288\n",
      "Iter-70550, train loss-0.2887, acc-0.9200, valid loss-0.2459, acc-0.9288, test loss-0.2569, acc-0.9289\n",
      "Iter-70560, train loss-0.2814, acc-0.9600, valid loss-0.2458, acc-0.9288, test loss-0.2569, acc-0.9288\n",
      "Iter-70570, train loss-0.1589, acc-0.9600, valid loss-0.2458, acc-0.9290, test loss-0.2569, acc-0.9289\n",
      "Iter-70580, train loss-0.2444, acc-0.9600, valid loss-0.2459, acc-0.9288, test loss-0.2568, acc-0.9289\n",
      "Iter-70590, train loss-0.1684, acc-0.9600, valid loss-0.2458, acc-0.9288, test loss-0.2568, acc-0.9286\n",
      "Iter-70600, train loss-0.2149, acc-0.9600, valid loss-0.2458, acc-0.9290, test loss-0.2568, acc-0.9286\n",
      "Iter-70610, train loss-0.2248, acc-0.9200, valid loss-0.2458, acc-0.9290, test loss-0.2569, acc-0.9287\n",
      "Iter-70620, train loss-0.1855, acc-0.9600, valid loss-0.2458, acc-0.9286, test loss-0.2569, acc-0.9281\n",
      "Iter-70630, train loss-0.0959, acc-0.9800, valid loss-0.2458, acc-0.9286, test loss-0.2569, acc-0.9283\n",
      "Iter-70640, train loss-0.2301, acc-0.9400, valid loss-0.2458, acc-0.9286, test loss-0.2568, acc-0.9284\n",
      "Iter-70650, train loss-0.2730, acc-0.8800, valid loss-0.2458, acc-0.9288, test loss-0.2569, acc-0.9285\n",
      "Iter-70660, train loss-0.3278, acc-0.9400, valid loss-0.2458, acc-0.9290, test loss-0.2568, acc-0.9285\n",
      "Iter-70670, train loss-0.1970, acc-0.9800, valid loss-0.2457, acc-0.9290, test loss-0.2568, acc-0.9285\n",
      "Iter-70680, train loss-0.2417, acc-0.9200, valid loss-0.2457, acc-0.9294, test loss-0.2568, acc-0.9281\n",
      "Iter-70690, train loss-0.3145, acc-0.9000, valid loss-0.2457, acc-0.9292, test loss-0.2568, acc-0.9283\n",
      "Iter-70700, train loss-0.1002, acc-1.0000, valid loss-0.2457, acc-0.9292, test loss-0.2568, acc-0.9284\n",
      "Iter-70710, train loss-0.0781, acc-1.0000, valid loss-0.2457, acc-0.9294, test loss-0.2567, acc-0.9282\n",
      "Iter-70720, train loss-0.2221, acc-0.9200, valid loss-0.2457, acc-0.9290, test loss-0.2567, acc-0.9285\n",
      "Iter-70730, train loss-0.3414, acc-0.8600, valid loss-0.2457, acc-0.9288, test loss-0.2567, acc-0.9284\n",
      "Iter-70740, train loss-0.1984, acc-0.9400, valid loss-0.2457, acc-0.9290, test loss-0.2567, acc-0.9284\n",
      "Iter-70750, train loss-0.3546, acc-0.8600, valid loss-0.2457, acc-0.9286, test loss-0.2567, acc-0.9283\n",
      "Iter-70760, train loss-0.2732, acc-0.9000, valid loss-0.2456, acc-0.9286, test loss-0.2567, acc-0.9286\n",
      "Iter-70770, train loss-0.3072, acc-0.9400, valid loss-0.2456, acc-0.9290, test loss-0.2567, acc-0.9283\n",
      "Iter-70780, train loss-0.2202, acc-0.9600, valid loss-0.2456, acc-0.9292, test loss-0.2567, acc-0.9286\n",
      "Iter-70790, train loss-0.4989, acc-0.9000, valid loss-0.2456, acc-0.9292, test loss-0.2567, acc-0.9284\n",
      "Iter-70800, train loss-0.3014, acc-0.8800, valid loss-0.2455, acc-0.9292, test loss-0.2567, acc-0.9286\n",
      "Iter-70810, train loss-0.3316, acc-0.9200, valid loss-0.2455, acc-0.9294, test loss-0.2567, acc-0.9283\n",
      "Iter-70820, train loss-0.2729, acc-0.9600, valid loss-0.2455, acc-0.9294, test loss-0.2567, acc-0.9286\n",
      "Iter-70830, train loss-0.2396, acc-0.9600, valid loss-0.2455, acc-0.9294, test loss-0.2567, acc-0.9286\n",
      "Iter-70840, train loss-0.2652, acc-0.9400, valid loss-0.2455, acc-0.9294, test loss-0.2567, acc-0.9287\n",
      "Iter-70850, train loss-0.3250, acc-0.9200, valid loss-0.2454, acc-0.9294, test loss-0.2567, acc-0.9287\n",
      "Iter-70860, train loss-0.2314, acc-0.9200, valid loss-0.2455, acc-0.9294, test loss-0.2567, acc-0.9285\n",
      "Iter-70870, train loss-0.1171, acc-1.0000, valid loss-0.2454, acc-0.9292, test loss-0.2568, acc-0.9287\n",
      "Iter-70880, train loss-0.1395, acc-0.9600, valid loss-0.2454, acc-0.9294, test loss-0.2567, acc-0.9286\n",
      "Iter-70890, train loss-0.1944, acc-0.9200, valid loss-0.2453, acc-0.9296, test loss-0.2568, acc-0.9287\n",
      "Iter-70900, train loss-0.1453, acc-0.9400, valid loss-0.2453, acc-0.9296, test loss-0.2567, acc-0.9286\n",
      "Iter-70910, train loss-0.2977, acc-0.9000, valid loss-0.2452, acc-0.9294, test loss-0.2567, acc-0.9287\n",
      "Iter-70920, train loss-0.3228, acc-0.9000, valid loss-0.2452, acc-0.9298, test loss-0.2567, acc-0.9287\n",
      "Iter-70930, train loss-0.1807, acc-0.9600, valid loss-0.2451, acc-0.9296, test loss-0.2566, acc-0.9287\n",
      "Iter-70940, train loss-0.2561, acc-0.9000, valid loss-0.2451, acc-0.9298, test loss-0.2566, acc-0.9289\n",
      "Iter-70950, train loss-0.4523, acc-0.8800, valid loss-0.2450, acc-0.9296, test loss-0.2567, acc-0.9286\n",
      "Iter-70960, train loss-0.5009, acc-0.8600, valid loss-0.2450, acc-0.9294, test loss-0.2567, acc-0.9287\n",
      "Iter-70970, train loss-0.1706, acc-0.9200, valid loss-0.2450, acc-0.9296, test loss-0.2567, acc-0.9289\n",
      "Iter-70980, train loss-0.2269, acc-0.9400, valid loss-0.2451, acc-0.9292, test loss-0.2567, acc-0.9288\n",
      "Iter-70990, train loss-0.2702, acc-0.9600, valid loss-0.2451, acc-0.9296, test loss-0.2567, acc-0.9289\n",
      "Iter-71000, train loss-0.2949, acc-0.9000, valid loss-0.2451, acc-0.9298, test loss-0.2567, acc-0.9290\n",
      "Iter-71010, train loss-0.2812, acc-0.9000, valid loss-0.2450, acc-0.9298, test loss-0.2567, acc-0.9289\n",
      "Iter-71020, train loss-0.3132, acc-0.8400, valid loss-0.2450, acc-0.9294, test loss-0.2567, acc-0.9288\n",
      "Iter-71030, train loss-0.3713, acc-0.8800, valid loss-0.2451, acc-0.9296, test loss-0.2567, acc-0.9290\n",
      "Iter-71040, train loss-0.2515, acc-0.9200, valid loss-0.2451, acc-0.9296, test loss-0.2567, acc-0.9291\n",
      "Iter-71050, train loss-0.1515, acc-0.9400, valid loss-0.2450, acc-0.9300, test loss-0.2566, acc-0.9292\n",
      "Iter-71060, train loss-0.2114, acc-0.9400, valid loss-0.2450, acc-0.9298, test loss-0.2566, acc-0.9284\n",
      "Iter-71070, train loss-0.2654, acc-0.9400, valid loss-0.2450, acc-0.9298, test loss-0.2566, acc-0.9288\n",
      "Iter-71080, train loss-0.4538, acc-0.8600, valid loss-0.2450, acc-0.9298, test loss-0.2565, acc-0.9285\n",
      "Iter-71090, train loss-0.2264, acc-0.9400, valid loss-0.2451, acc-0.9298, test loss-0.2565, acc-0.9289\n",
      "Iter-71100, train loss-0.2764, acc-0.9000, valid loss-0.2450, acc-0.9298, test loss-0.2565, acc-0.9290\n",
      "Iter-71110, train loss-0.3319, acc-0.8800, valid loss-0.2450, acc-0.9296, test loss-0.2565, acc-0.9288\n",
      "Iter-71120, train loss-0.2399, acc-0.9200, valid loss-0.2450, acc-0.9294, test loss-0.2565, acc-0.9286\n",
      "Iter-71130, train loss-0.1747, acc-0.9600, valid loss-0.2450, acc-0.9298, test loss-0.2565, acc-0.9287\n",
      "Iter-71140, train loss-0.1428, acc-0.9600, valid loss-0.2450, acc-0.9298, test loss-0.2564, acc-0.9288\n",
      "Iter-71150, train loss-0.2858, acc-0.9400, valid loss-0.2450, acc-0.9298, test loss-0.2564, acc-0.9288\n",
      "Iter-71160, train loss-0.1287, acc-0.9800, valid loss-0.2450, acc-0.9298, test loss-0.2564, acc-0.9291\n",
      "Iter-71170, train loss-0.1586, acc-0.9400, valid loss-0.2450, acc-0.9298, test loss-0.2564, acc-0.9291\n",
      "Iter-71180, train loss-0.2443, acc-0.9400, valid loss-0.2449, acc-0.9294, test loss-0.2564, acc-0.9293\n",
      "Iter-71190, train loss-0.2729, acc-0.9000, valid loss-0.2449, acc-0.9294, test loss-0.2563, acc-0.9293\n",
      "Iter-71200, train loss-0.3403, acc-0.8800, valid loss-0.2449, acc-0.9296, test loss-0.2563, acc-0.9291\n",
      "Iter-71210, train loss-0.2095, acc-0.9600, valid loss-0.2450, acc-0.9296, test loss-0.2563, acc-0.9292\n",
      "Iter-71220, train loss-0.3317, acc-0.9200, valid loss-0.2449, acc-0.9298, test loss-0.2563, acc-0.9291\n",
      "Iter-71230, train loss-0.1225, acc-0.9800, valid loss-0.2448, acc-0.9298, test loss-0.2563, acc-0.9288\n",
      "Iter-71240, train loss-0.1480, acc-0.9400, valid loss-0.2448, acc-0.9298, test loss-0.2563, acc-0.9287\n",
      "Iter-71250, train loss-0.1047, acc-0.9800, valid loss-0.2447, acc-0.9296, test loss-0.2563, acc-0.9286\n",
      "Iter-71260, train loss-0.3203, acc-0.9000, valid loss-0.2447, acc-0.9298, test loss-0.2562, acc-0.9287\n",
      "Iter-71270, train loss-0.1066, acc-0.9800, valid loss-0.2446, acc-0.9298, test loss-0.2562, acc-0.9289\n",
      "Iter-71280, train loss-0.3205, acc-0.9600, valid loss-0.2446, acc-0.9300, test loss-0.2562, acc-0.9289\n",
      "Iter-71290, train loss-0.1907, acc-0.9400, valid loss-0.2446, acc-0.9302, test loss-0.2562, acc-0.9292\n",
      "Iter-71300, train loss-0.3692, acc-0.8600, valid loss-0.2445, acc-0.9300, test loss-0.2562, acc-0.9287\n",
      "Iter-71310, train loss-0.2430, acc-0.9200, valid loss-0.2444, acc-0.9302, test loss-0.2562, acc-0.9287\n",
      "Iter-71320, train loss-0.2234, acc-0.9600, valid loss-0.2444, acc-0.9304, test loss-0.2562, acc-0.9285\n",
      "Iter-71330, train loss-0.1945, acc-0.9400, valid loss-0.2445, acc-0.9304, test loss-0.2562, acc-0.9284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-71340, train loss-0.2537, acc-0.9000, valid loss-0.2444, acc-0.9304, test loss-0.2562, acc-0.9288\n",
      "Iter-71350, train loss-0.1924, acc-0.9600, valid loss-0.2444, acc-0.9306, test loss-0.2562, acc-0.9288\n",
      "Iter-71360, train loss-0.2121, acc-0.9400, valid loss-0.2444, acc-0.9300, test loss-0.2562, acc-0.9288\n",
      "Iter-71370, train loss-0.2102, acc-0.9400, valid loss-0.2444, acc-0.9300, test loss-0.2562, acc-0.9288\n",
      "Iter-71380, train loss-0.2245, acc-0.9600, valid loss-0.2443, acc-0.9302, test loss-0.2562, acc-0.9289\n",
      "Iter-71390, train loss-0.3018, acc-0.8800, valid loss-0.2443, acc-0.9306, test loss-0.2562, acc-0.9288\n",
      "Iter-71400, train loss-0.2481, acc-0.9200, valid loss-0.2442, acc-0.9304, test loss-0.2562, acc-0.9288\n",
      "Iter-71410, train loss-0.2718, acc-0.9200, valid loss-0.2443, acc-0.9304, test loss-0.2561, acc-0.9287\n",
      "Iter-71420, train loss-0.2917, acc-0.9200, valid loss-0.2443, acc-0.9304, test loss-0.2561, acc-0.9288\n",
      "Iter-71430, train loss-0.3851, acc-0.9200, valid loss-0.2443, acc-0.9304, test loss-0.2561, acc-0.9288\n",
      "Iter-71440, train loss-0.3593, acc-0.8800, valid loss-0.2443, acc-0.9304, test loss-0.2561, acc-0.9287\n",
      "Iter-71450, train loss-0.2277, acc-0.9400, valid loss-0.2442, acc-0.9304, test loss-0.2561, acc-0.9288\n",
      "Iter-71460, train loss-0.2436, acc-0.9400, valid loss-0.2442, acc-0.9302, test loss-0.2561, acc-0.9287\n",
      "Iter-71470, train loss-0.1757, acc-0.9400, valid loss-0.2442, acc-0.9306, test loss-0.2561, acc-0.9287\n",
      "Iter-71480, train loss-0.3138, acc-0.9200, valid loss-0.2442, acc-0.9300, test loss-0.2561, acc-0.9286\n",
      "Iter-71490, train loss-0.4226, acc-0.8400, valid loss-0.2442, acc-0.9300, test loss-0.2560, acc-0.9287\n",
      "Iter-71500, train loss-0.2332, acc-0.9200, valid loss-0.2442, acc-0.9302, test loss-0.2560, acc-0.9288\n",
      "Iter-71510, train loss-0.1640, acc-0.9600, valid loss-0.2442, acc-0.9302, test loss-0.2560, acc-0.9288\n",
      "Iter-71520, train loss-0.2052, acc-0.9600, valid loss-0.2442, acc-0.9302, test loss-0.2560, acc-0.9289\n",
      "Iter-71530, train loss-0.2858, acc-0.9200, valid loss-0.2442, acc-0.9300, test loss-0.2560, acc-0.9290\n",
      "Iter-71540, train loss-0.2840, acc-0.9400, valid loss-0.2441, acc-0.9302, test loss-0.2559, acc-0.9289\n",
      "Iter-71550, train loss-0.1621, acc-0.9400, valid loss-0.2441, acc-0.9304, test loss-0.2559, acc-0.9289\n",
      "Iter-71560, train loss-0.1302, acc-0.9800, valid loss-0.2441, acc-0.9304, test loss-0.2559, acc-0.9288\n",
      "Iter-71570, train loss-0.2537, acc-0.9400, valid loss-0.2441, acc-0.9302, test loss-0.2559, acc-0.9289\n",
      "Iter-71580, train loss-0.2211, acc-0.9000, valid loss-0.2441, acc-0.9300, test loss-0.2559, acc-0.9288\n",
      "Iter-71590, train loss-0.2292, acc-0.9000, valid loss-0.2441, acc-0.9300, test loss-0.2559, acc-0.9289\n",
      "Iter-71600, train loss-0.2527, acc-0.9000, valid loss-0.2440, acc-0.9302, test loss-0.2559, acc-0.9290\n",
      "Iter-71610, train loss-0.1191, acc-0.9800, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9290\n",
      "Iter-71620, train loss-0.2466, acc-0.9200, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9289\n",
      "Iter-71630, train loss-0.2729, acc-0.9600, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9287\n",
      "Iter-71640, train loss-0.2730, acc-0.9200, valid loss-0.2441, acc-0.9298, test loss-0.2560, acc-0.9287\n",
      "Iter-71650, train loss-0.1716, acc-0.9200, valid loss-0.2441, acc-0.9298, test loss-0.2560, acc-0.9288\n",
      "Iter-71660, train loss-0.3606, acc-0.9200, valid loss-0.2440, acc-0.9300, test loss-0.2560, acc-0.9289\n",
      "Iter-71670, train loss-0.2195, acc-0.9400, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9289\n",
      "Iter-71680, train loss-0.2637, acc-0.9400, valid loss-0.2440, acc-0.9298, test loss-0.2560, acc-0.9288\n",
      "Iter-71690, train loss-0.5056, acc-0.8800, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9290\n",
      "Iter-71700, train loss-0.1973, acc-0.9600, valid loss-0.2441, acc-0.9300, test loss-0.2560, acc-0.9290\n",
      "Iter-71710, train loss-0.4558, acc-0.8200, valid loss-0.2440, acc-0.9302, test loss-0.2559, acc-0.9290\n",
      "Iter-71720, train loss-0.1819, acc-0.9400, valid loss-0.2440, acc-0.9300, test loss-0.2559, acc-0.9290\n",
      "Iter-71730, train loss-0.3988, acc-0.9200, valid loss-0.2440, acc-0.9296, test loss-0.2559, acc-0.9290\n",
      "Iter-71740, train loss-0.1573, acc-0.9600, valid loss-0.2440, acc-0.9304, test loss-0.2559, acc-0.9292\n",
      "Iter-71750, train loss-0.1901, acc-0.9200, valid loss-0.2440, acc-0.9302, test loss-0.2558, acc-0.9294\n",
      "Iter-71760, train loss-0.2542, acc-0.9200, valid loss-0.2440, acc-0.9306, test loss-0.2558, acc-0.9292\n",
      "Iter-71770, train loss-0.3463, acc-0.9200, valid loss-0.2440, acc-0.9300, test loss-0.2558, acc-0.9294\n",
      "Iter-71780, train loss-0.2407, acc-0.9000, valid loss-0.2440, acc-0.9298, test loss-0.2557, acc-0.9289\n",
      "Iter-71790, train loss-0.1449, acc-0.9800, valid loss-0.2439, acc-0.9302, test loss-0.2557, acc-0.9290\n",
      "Iter-71800, train loss-0.2843, acc-0.9000, valid loss-0.2439, acc-0.9300, test loss-0.2557, acc-0.9291\n",
      "Iter-71810, train loss-0.2723, acc-0.9200, valid loss-0.2440, acc-0.9302, test loss-0.2556, acc-0.9293\n",
      "Iter-71820, train loss-0.2638, acc-0.9000, valid loss-0.2440, acc-0.9298, test loss-0.2556, acc-0.9296\n",
      "Iter-71830, train loss-0.1254, acc-0.9800, valid loss-0.2439, acc-0.9300, test loss-0.2556, acc-0.9295\n",
      "Iter-71840, train loss-0.4909, acc-0.9200, valid loss-0.2438, acc-0.9302, test loss-0.2556, acc-0.9296\n",
      "Iter-71850, train loss-0.2174, acc-0.9200, valid loss-0.2438, acc-0.9300, test loss-0.2556, acc-0.9295\n",
      "Iter-71860, train loss-0.2948, acc-0.9000, valid loss-0.2439, acc-0.9302, test loss-0.2556, acc-0.9296\n",
      "Iter-71870, train loss-0.2125, acc-0.9200, valid loss-0.2438, acc-0.9300, test loss-0.2556, acc-0.9295\n",
      "Iter-71880, train loss-0.2779, acc-0.9200, valid loss-0.2439, acc-0.9298, test loss-0.2556, acc-0.9295\n",
      "Iter-71890, train loss-0.3642, acc-0.8800, valid loss-0.2439, acc-0.9296, test loss-0.2556, acc-0.9296\n",
      "Iter-71900, train loss-0.2401, acc-0.9200, valid loss-0.2438, acc-0.9296, test loss-0.2555, acc-0.9297\n",
      "Iter-71910, train loss-0.4075, acc-0.8800, valid loss-0.2439, acc-0.9298, test loss-0.2555, acc-0.9294\n",
      "Iter-71920, train loss-0.2641, acc-0.9200, valid loss-0.2439, acc-0.9304, test loss-0.2555, acc-0.9297\n",
      "Iter-71930, train loss-0.2336, acc-0.9200, valid loss-0.2438, acc-0.9304, test loss-0.2555, acc-0.9295\n",
      "Iter-71940, train loss-0.2012, acc-0.9400, valid loss-0.2438, acc-0.9306, test loss-0.2555, acc-0.9295\n",
      "Iter-71950, train loss-0.2175, acc-0.9200, valid loss-0.2438, acc-0.9304, test loss-0.2555, acc-0.9294\n",
      "Iter-71960, train loss-0.2989, acc-0.9000, valid loss-0.2438, acc-0.9304, test loss-0.2556, acc-0.9295\n",
      "Iter-71970, train loss-0.1809, acc-0.9800, valid loss-0.2438, acc-0.9306, test loss-0.2555, acc-0.9293\n",
      "Iter-71980, train loss-0.1254, acc-0.9600, valid loss-0.2438, acc-0.9306, test loss-0.2556, acc-0.9292\n",
      "Iter-71990, train loss-0.1781, acc-0.9600, valid loss-0.2438, acc-0.9306, test loss-0.2555, acc-0.9294\n",
      "Iter-72000, train loss-0.3450, acc-0.8800, valid loss-0.2438, acc-0.9304, test loss-0.2555, acc-0.9293\n",
      "Iter-72010, train loss-0.2509, acc-0.9600, valid loss-0.2438, acc-0.9304, test loss-0.2555, acc-0.9293\n",
      "Iter-72020, train loss-0.2044, acc-0.9600, valid loss-0.2437, acc-0.9302, test loss-0.2554, acc-0.9292\n",
      "Iter-72030, train loss-0.2206, acc-0.9400, valid loss-0.2437, acc-0.9304, test loss-0.2554, acc-0.9289\n",
      "Iter-72040, train loss-0.2275, acc-0.9400, valid loss-0.2437, acc-0.9300, test loss-0.2554, acc-0.9291\n",
      "Iter-72050, train loss-0.1466, acc-0.9800, valid loss-0.2437, acc-0.9298, test loss-0.2555, acc-0.9289\n",
      "Iter-72060, train loss-0.3181, acc-0.9000, valid loss-0.2437, acc-0.9302, test loss-0.2554, acc-0.9290\n",
      "Iter-72070, train loss-0.1832, acc-0.9600, valid loss-0.2437, acc-0.9298, test loss-0.2553, acc-0.9291\n",
      "Iter-72080, train loss-0.1297, acc-0.9600, valid loss-0.2436, acc-0.9296, test loss-0.2553, acc-0.9293\n",
      "Iter-72090, train loss-0.2386, acc-0.9400, valid loss-0.2436, acc-0.9296, test loss-0.2553, acc-0.9291\n",
      "Iter-72100, train loss-0.1407, acc-0.9600, valid loss-0.2436, acc-0.9300, test loss-0.2552, acc-0.9291\n",
      "Iter-72110, train loss-0.2125, acc-0.9000, valid loss-0.2435, acc-0.9302, test loss-0.2552, acc-0.9291\n",
      "Iter-72120, train loss-0.3415, acc-0.9000, valid loss-0.2435, acc-0.9308, test loss-0.2552, acc-0.9293\n",
      "Iter-72130, train loss-0.2170, acc-0.9200, valid loss-0.2434, acc-0.9306, test loss-0.2551, acc-0.9294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-72140, train loss-0.4633, acc-0.9000, valid loss-0.2434, acc-0.9308, test loss-0.2551, acc-0.9293\n",
      "Iter-72150, train loss-0.4177, acc-0.8400, valid loss-0.2434, acc-0.9304, test loss-0.2551, acc-0.9290\n",
      "Iter-72160, train loss-0.2051, acc-0.9200, valid loss-0.2434, acc-0.9304, test loss-0.2551, acc-0.9290\n",
      "Iter-72170, train loss-0.2914, acc-0.9200, valid loss-0.2434, acc-0.9304, test loss-0.2551, acc-0.9290\n",
      "Iter-72180, train loss-0.2134, acc-0.9200, valid loss-0.2434, acc-0.9302, test loss-0.2551, acc-0.9293\n",
      "Iter-72190, train loss-0.1638, acc-0.9400, valid loss-0.2434, acc-0.9304, test loss-0.2550, acc-0.9293\n",
      "Iter-72200, train loss-0.3321, acc-0.9200, valid loss-0.2434, acc-0.9304, test loss-0.2550, acc-0.9295\n",
      "Iter-72210, train loss-0.2442, acc-0.9000, valid loss-0.2433, acc-0.9302, test loss-0.2550, acc-0.9292\n",
      "Iter-72220, train loss-0.1711, acc-0.9400, valid loss-0.2433, acc-0.9298, test loss-0.2550, acc-0.9293\n",
      "Iter-72230, train loss-0.2703, acc-0.9600, valid loss-0.2433, acc-0.9300, test loss-0.2550, acc-0.9294\n",
      "Iter-72240, train loss-0.2359, acc-0.9000, valid loss-0.2433, acc-0.9300, test loss-0.2550, acc-0.9293\n",
      "Iter-72250, train loss-0.1262, acc-0.9800, valid loss-0.2433, acc-0.9298, test loss-0.2550, acc-0.9294\n",
      "Iter-72260, train loss-0.2963, acc-0.8800, valid loss-0.2433, acc-0.9296, test loss-0.2549, acc-0.9294\n",
      "Iter-72270, train loss-0.1041, acc-1.0000, valid loss-0.2432, acc-0.9298, test loss-0.2548, acc-0.9294\n",
      "Iter-72280, train loss-0.4041, acc-0.8600, valid loss-0.2432, acc-0.9298, test loss-0.2548, acc-0.9294\n",
      "Iter-72290, train loss-0.2581, acc-0.9200, valid loss-0.2432, acc-0.9298, test loss-0.2547, acc-0.9296\n",
      "Iter-72300, train loss-0.1057, acc-0.9800, valid loss-0.2432, acc-0.9298, test loss-0.2548, acc-0.9293\n",
      "Iter-72310, train loss-0.2816, acc-0.9000, valid loss-0.2433, acc-0.9300, test loss-0.2547, acc-0.9297\n",
      "Iter-72320, train loss-0.2337, acc-0.8800, valid loss-0.2432, acc-0.9306, test loss-0.2548, acc-0.9295\n",
      "Iter-72330, train loss-0.3305, acc-0.8800, valid loss-0.2432, acc-0.9306, test loss-0.2547, acc-0.9295\n",
      "Iter-72340, train loss-0.2521, acc-0.9600, valid loss-0.2432, acc-0.9300, test loss-0.2547, acc-0.9295\n",
      "Iter-72350, train loss-0.2616, acc-0.9600, valid loss-0.2432, acc-0.9300, test loss-0.2547, acc-0.9293\n",
      "Iter-72360, train loss-0.3195, acc-0.9000, valid loss-0.2431, acc-0.9300, test loss-0.2547, acc-0.9298\n",
      "Iter-72370, train loss-0.3560, acc-0.9400, valid loss-0.2431, acc-0.9298, test loss-0.2547, acc-0.9294\n",
      "Iter-72380, train loss-0.3822, acc-0.9000, valid loss-0.2431, acc-0.9302, test loss-0.2546, acc-0.9299\n",
      "Iter-72390, train loss-0.1674, acc-0.9600, valid loss-0.2431, acc-0.9302, test loss-0.2546, acc-0.9299\n",
      "Iter-72400, train loss-0.1450, acc-0.9800, valid loss-0.2431, acc-0.9304, test loss-0.2546, acc-0.9296\n",
      "Iter-72410, train loss-0.2128, acc-0.9200, valid loss-0.2430, acc-0.9306, test loss-0.2546, acc-0.9297\n",
      "Iter-72420, train loss-0.3013, acc-0.9200, valid loss-0.2430, acc-0.9306, test loss-0.2546, acc-0.9298\n",
      "Iter-72430, train loss-0.2165, acc-0.9600, valid loss-0.2430, acc-0.9304, test loss-0.2545, acc-0.9299\n",
      "Iter-72440, train loss-0.2631, acc-0.9000, valid loss-0.2430, acc-0.9304, test loss-0.2545, acc-0.9299\n",
      "Iter-72450, train loss-0.1560, acc-0.9800, valid loss-0.2430, acc-0.9304, test loss-0.2545, acc-0.9298\n",
      "Iter-72460, train loss-0.0718, acc-0.9800, valid loss-0.2430, acc-0.9308, test loss-0.2544, acc-0.9301\n",
      "Iter-72470, train loss-0.2590, acc-0.9200, valid loss-0.2429, acc-0.9308, test loss-0.2544, acc-0.9299\n",
      "Iter-72480, train loss-0.2276, acc-0.9200, valid loss-0.2430, acc-0.9308, test loss-0.2544, acc-0.9300\n",
      "Iter-72490, train loss-0.1225, acc-0.9600, valid loss-0.2429, acc-0.9306, test loss-0.2544, acc-0.9299\n",
      "Iter-72500, train loss-0.1442, acc-0.9400, valid loss-0.2429, acc-0.9308, test loss-0.2544, acc-0.9300\n",
      "Iter-72510, train loss-0.1672, acc-0.9600, valid loss-0.2429, acc-0.9308, test loss-0.2544, acc-0.9299\n",
      "Iter-72520, train loss-0.1356, acc-0.9800, valid loss-0.2429, acc-0.9306, test loss-0.2544, acc-0.9296\n",
      "Iter-72530, train loss-0.2272, acc-0.9200, valid loss-0.2428, acc-0.9304, test loss-0.2544, acc-0.9297\n",
      "Iter-72540, train loss-0.2032, acc-0.9200, valid loss-0.2428, acc-0.9308, test loss-0.2544, acc-0.9298\n",
      "Iter-72550, train loss-0.1053, acc-0.9800, valid loss-0.2428, acc-0.9308, test loss-0.2543, acc-0.9298\n",
      "Iter-72560, train loss-0.3546, acc-0.8800, valid loss-0.2428, acc-0.9310, test loss-0.2543, acc-0.9301\n",
      "Iter-72570, train loss-0.1687, acc-0.9400, valid loss-0.2428, acc-0.9308, test loss-0.2543, acc-0.9302\n",
      "Iter-72580, train loss-0.2601, acc-0.9400, valid loss-0.2428, acc-0.9306, test loss-0.2543, acc-0.9301\n",
      "Iter-72590, train loss-0.2352, acc-0.9000, valid loss-0.2427, acc-0.9308, test loss-0.2543, acc-0.9298\n",
      "Iter-72600, train loss-0.4278, acc-0.8400, valid loss-0.2427, acc-0.9308, test loss-0.2543, acc-0.9299\n",
      "Iter-72610, train loss-0.1049, acc-0.9600, valid loss-0.2427, acc-0.9308, test loss-0.2543, acc-0.9298\n",
      "Iter-72620, train loss-0.3007, acc-0.8600, valid loss-0.2426, acc-0.9310, test loss-0.2543, acc-0.9298\n",
      "Iter-72630, train loss-0.3124, acc-0.9000, valid loss-0.2426, acc-0.9310, test loss-0.2543, acc-0.9297\n",
      "Iter-72640, train loss-0.2141, acc-0.9200, valid loss-0.2427, acc-0.9308, test loss-0.2543, acc-0.9297\n",
      "Iter-72650, train loss-0.3069, acc-0.8800, valid loss-0.2427, acc-0.9312, test loss-0.2544, acc-0.9297\n",
      "Iter-72660, train loss-0.1379, acc-0.9800, valid loss-0.2427, acc-0.9312, test loss-0.2544, acc-0.9297\n",
      "Iter-72670, train loss-0.1748, acc-0.9600, valid loss-0.2426, acc-0.9306, test loss-0.2544, acc-0.9296\n",
      "Iter-72680, train loss-0.3056, acc-0.8800, valid loss-0.2426, acc-0.9306, test loss-0.2543, acc-0.9296\n",
      "Iter-72690, train loss-0.3022, acc-0.8600, valid loss-0.2426, acc-0.9306, test loss-0.2543, acc-0.9298\n",
      "Iter-72700, train loss-0.1908, acc-0.9200, valid loss-0.2426, acc-0.9308, test loss-0.2543, acc-0.9298\n",
      "Iter-72710, train loss-0.1923, acc-0.9400, valid loss-0.2425, acc-0.9310, test loss-0.2543, acc-0.9297\n",
      "Iter-72720, train loss-0.3568, acc-0.9000, valid loss-0.2425, acc-0.9310, test loss-0.2543, acc-0.9294\n",
      "Iter-72730, train loss-0.2928, acc-0.9400, valid loss-0.2425, acc-0.9308, test loss-0.2543, acc-0.9293\n",
      "Iter-72740, train loss-0.1529, acc-0.9400, valid loss-0.2425, acc-0.9306, test loss-0.2543, acc-0.9293\n",
      "Iter-72750, train loss-0.2181, acc-0.9200, valid loss-0.2425, acc-0.9304, test loss-0.2542, acc-0.9294\n",
      "Iter-72760, train loss-0.2117, acc-0.9200, valid loss-0.2425, acc-0.9302, test loss-0.2542, acc-0.9294\n",
      "Iter-72770, train loss-0.2628, acc-0.9000, valid loss-0.2425, acc-0.9302, test loss-0.2542, acc-0.9295\n",
      "Iter-72780, train loss-0.1645, acc-0.9600, valid loss-0.2426, acc-0.9300, test loss-0.2542, acc-0.9298\n",
      "Iter-72790, train loss-0.2157, acc-0.9200, valid loss-0.2426, acc-0.9298, test loss-0.2542, acc-0.9295\n",
      "Iter-72800, train loss-0.2483, acc-0.9000, valid loss-0.2425, acc-0.9296, test loss-0.2541, acc-0.9295\n",
      "Iter-72810, train loss-0.2657, acc-0.9000, valid loss-0.2425, acc-0.9304, test loss-0.2541, acc-0.9296\n",
      "Iter-72820, train loss-0.1511, acc-0.9800, valid loss-0.2425, acc-0.9300, test loss-0.2541, acc-0.9295\n",
      "Iter-72830, train loss-0.2177, acc-0.9200, valid loss-0.2425, acc-0.9302, test loss-0.2540, acc-0.9294\n",
      "Iter-72840, train loss-0.1463, acc-0.9600, valid loss-0.2425, acc-0.9302, test loss-0.2540, acc-0.9293\n",
      "Iter-72850, train loss-0.1189, acc-0.9600, valid loss-0.2424, acc-0.9302, test loss-0.2540, acc-0.9296\n",
      "Iter-72860, train loss-0.3595, acc-0.9200, valid loss-0.2424, acc-0.9302, test loss-0.2539, acc-0.9295\n",
      "Iter-72870, train loss-0.2033, acc-0.9200, valid loss-0.2424, acc-0.9300, test loss-0.2539, acc-0.9291\n",
      "Iter-72880, train loss-0.4341, acc-0.8800, valid loss-0.2424, acc-0.9302, test loss-0.2539, acc-0.9293\n",
      "Iter-72890, train loss-0.2058, acc-0.9000, valid loss-0.2424, acc-0.9304, test loss-0.2539, acc-0.9292\n",
      "Iter-72900, train loss-0.3619, acc-0.8800, valid loss-0.2424, acc-0.9302, test loss-0.2539, acc-0.9294\n",
      "Iter-72910, train loss-0.2862, acc-0.8800, valid loss-0.2424, acc-0.9300, test loss-0.2539, acc-0.9293\n",
      "Iter-72920, train loss-0.3024, acc-0.9200, valid loss-0.2424, acc-0.9300, test loss-0.2539, acc-0.9294\n",
      "Iter-72930, train loss-0.1992, acc-0.9200, valid loss-0.2424, acc-0.9302, test loss-0.2539, acc-0.9293\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-72940, train loss-0.5461, acc-0.8400, valid loss-0.2424, acc-0.9302, test loss-0.2539, acc-0.9289\n",
      "Iter-72950, train loss-0.5518, acc-0.8000, valid loss-0.2425, acc-0.9302, test loss-0.2539, acc-0.9288\n",
      "Iter-72960, train loss-0.1429, acc-0.9600, valid loss-0.2424, acc-0.9300, test loss-0.2539, acc-0.9288\n",
      "Iter-72970, train loss-0.1163, acc-0.9800, valid loss-0.2424, acc-0.9300, test loss-0.2538, acc-0.9289\n",
      "Iter-72980, train loss-0.2950, acc-0.9200, valid loss-0.2424, acc-0.9300, test loss-0.2539, acc-0.9292\n",
      "Iter-72990, train loss-0.2350, acc-0.9400, valid loss-0.2424, acc-0.9304, test loss-0.2538, acc-0.9293\n",
      "Iter-73000, train loss-0.1455, acc-0.9600, valid loss-0.2423, acc-0.9302, test loss-0.2538, acc-0.9292\n",
      "Iter-73010, train loss-0.3884, acc-0.8600, valid loss-0.2423, acc-0.9302, test loss-0.2538, acc-0.9292\n",
      "Iter-73020, train loss-0.3921, acc-0.9000, valid loss-0.2423, acc-0.9302, test loss-0.2538, acc-0.9287\n",
      "Iter-73030, train loss-0.1954, acc-0.9600, valid loss-0.2422, acc-0.9304, test loss-0.2538, acc-0.9291\n",
      "Iter-73040, train loss-0.1780, acc-0.9600, valid loss-0.2422, acc-0.9306, test loss-0.2538, acc-0.9293\n",
      "Iter-73050, train loss-0.2860, acc-0.9000, valid loss-0.2421, acc-0.9302, test loss-0.2538, acc-0.9294\n",
      "Iter-73060, train loss-0.4354, acc-0.9000, valid loss-0.2421, acc-0.9306, test loss-0.2538, acc-0.9294\n",
      "Iter-73070, train loss-0.1440, acc-0.9800, valid loss-0.2421, acc-0.9306, test loss-0.2537, acc-0.9295\n",
      "Iter-73080, train loss-0.1959, acc-0.9400, valid loss-0.2421, acc-0.9306, test loss-0.2537, acc-0.9292\n",
      "Iter-73090, train loss-0.3005, acc-0.9200, valid loss-0.2421, acc-0.9304, test loss-0.2537, acc-0.9293\n",
      "Iter-73100, train loss-0.2584, acc-0.9200, valid loss-0.2421, acc-0.9304, test loss-0.2537, acc-0.9293\n",
      "Iter-73110, train loss-0.2786, acc-0.9400, valid loss-0.2421, acc-0.9302, test loss-0.2538, acc-0.9295\n",
      "Iter-73120, train loss-0.3114, acc-0.8600, valid loss-0.2422, acc-0.9304, test loss-0.2537, acc-0.9294\n",
      "Iter-73130, train loss-0.4217, acc-0.8600, valid loss-0.2421, acc-0.9302, test loss-0.2537, acc-0.9293\n",
      "Iter-73140, train loss-0.1467, acc-0.9800, valid loss-0.2421, acc-0.9308, test loss-0.2537, acc-0.9295\n",
      "Iter-73150, train loss-0.2019, acc-0.9400, valid loss-0.2421, acc-0.9306, test loss-0.2537, acc-0.9295\n",
      "Iter-73160, train loss-0.1855, acc-0.9600, valid loss-0.2422, acc-0.9306, test loss-0.2537, acc-0.9293\n",
      "Iter-73170, train loss-0.2126, acc-0.9400, valid loss-0.2422, acc-0.9302, test loss-0.2537, acc-0.9291\n",
      "Iter-73180, train loss-0.2140, acc-0.9200, valid loss-0.2421, acc-0.9306, test loss-0.2537, acc-0.9294\n",
      "Iter-73190, train loss-0.2647, acc-0.9400, valid loss-0.2421, acc-0.9304, test loss-0.2536, acc-0.9298\n",
      "Iter-73200, train loss-0.1100, acc-0.9800, valid loss-0.2421, acc-0.9304, test loss-0.2537, acc-0.9293\n",
      "Iter-73210, train loss-0.3248, acc-0.9400, valid loss-0.2421, acc-0.9304, test loss-0.2536, acc-0.9295\n",
      "Iter-73220, train loss-0.3233, acc-0.9200, valid loss-0.2420, acc-0.9308, test loss-0.2536, acc-0.9296\n",
      "Iter-73230, train loss-0.2668, acc-0.9200, valid loss-0.2421, acc-0.9308, test loss-0.2536, acc-0.9297\n",
      "Iter-73240, train loss-0.1538, acc-0.9600, valid loss-0.2420, acc-0.9304, test loss-0.2535, acc-0.9297\n",
      "Iter-73250, train loss-0.2198, acc-0.9400, valid loss-0.2420, acc-0.9302, test loss-0.2535, acc-0.9299\n",
      "Iter-73260, train loss-0.2141, acc-0.9200, valid loss-0.2420, acc-0.9302, test loss-0.2535, acc-0.9298\n",
      "Iter-73270, train loss-0.1725, acc-0.9400, valid loss-0.2419, acc-0.9306, test loss-0.2535, acc-0.9296\n",
      "Iter-73280, train loss-0.2663, acc-0.9000, valid loss-0.2419, acc-0.9304, test loss-0.2535, acc-0.9298\n",
      "Iter-73290, train loss-0.2120, acc-0.9200, valid loss-0.2419, acc-0.9300, test loss-0.2534, acc-0.9294\n",
      "Iter-73300, train loss-0.0881, acc-0.9800, valid loss-0.2419, acc-0.9300, test loss-0.2534, acc-0.9295\n",
      "Iter-73310, train loss-0.3790, acc-0.8800, valid loss-0.2419, acc-0.9298, test loss-0.2534, acc-0.9295\n",
      "Iter-73320, train loss-0.2787, acc-0.9400, valid loss-0.2419, acc-0.9296, test loss-0.2534, acc-0.9295\n",
      "Iter-73330, train loss-0.1604, acc-0.9800, valid loss-0.2418, acc-0.9298, test loss-0.2534, acc-0.9296\n",
      "Iter-73340, train loss-0.3297, acc-0.9000, valid loss-0.2418, acc-0.9298, test loss-0.2534, acc-0.9296\n",
      "Iter-73350, train loss-0.2272, acc-0.9600, valid loss-0.2417, acc-0.9302, test loss-0.2534, acc-0.9294\n",
      "Iter-73360, train loss-0.1502, acc-0.9600, valid loss-0.2416, acc-0.9302, test loss-0.2533, acc-0.9298\n",
      "Iter-73370, train loss-0.3286, acc-0.9400, valid loss-0.2416, acc-0.9300, test loss-0.2533, acc-0.9300\n",
      "Iter-73380, train loss-0.2878, acc-0.9000, valid loss-0.2416, acc-0.9298, test loss-0.2533, acc-0.9297\n",
      "Iter-73390, train loss-0.2200, acc-0.9800, valid loss-0.2416, acc-0.9298, test loss-0.2533, acc-0.9294\n",
      "Iter-73400, train loss-0.2934, acc-0.8800, valid loss-0.2416, acc-0.9302, test loss-0.2533, acc-0.9292\n",
      "Iter-73410, train loss-0.2137, acc-0.9200, valid loss-0.2415, acc-0.9300, test loss-0.2533, acc-0.9292\n",
      "Iter-73420, train loss-0.2122, acc-0.9400, valid loss-0.2415, acc-0.9302, test loss-0.2532, acc-0.9291\n",
      "Iter-73430, train loss-0.2255, acc-0.9200, valid loss-0.2415, acc-0.9302, test loss-0.2532, acc-0.9291\n",
      "Iter-73440, train loss-0.2469, acc-0.9000, valid loss-0.2415, acc-0.9308, test loss-0.2532, acc-0.9295\n",
      "Iter-73450, train loss-0.2386, acc-0.9200, valid loss-0.2414, acc-0.9304, test loss-0.2532, acc-0.9292\n",
      "Iter-73460, train loss-0.1369, acc-0.9800, valid loss-0.2415, acc-0.9308, test loss-0.2532, acc-0.9292\n",
      "Iter-73470, train loss-0.3859, acc-0.8600, valid loss-0.2415, acc-0.9310, test loss-0.2532, acc-0.9292\n",
      "Iter-73480, train loss-0.3271, acc-0.8800, valid loss-0.2415, acc-0.9308, test loss-0.2532, acc-0.9291\n",
      "Iter-73490, train loss-0.3705, acc-0.9000, valid loss-0.2415, acc-0.9308, test loss-0.2532, acc-0.9293\n",
      "Iter-73500, train loss-0.1995, acc-0.9400, valid loss-0.2415, acc-0.9306, test loss-0.2532, acc-0.9292\n",
      "Iter-73510, train loss-0.2449, acc-0.9200, valid loss-0.2415, acc-0.9310, test loss-0.2531, acc-0.9295\n",
      "Iter-73520, train loss-0.2686, acc-0.9200, valid loss-0.2415, acc-0.9310, test loss-0.2531, acc-0.9295\n",
      "Iter-73530, train loss-0.1271, acc-0.9400, valid loss-0.2415, acc-0.9306, test loss-0.2531, acc-0.9294\n",
      "Iter-73540, train loss-0.1672, acc-0.9800, valid loss-0.2414, acc-0.9310, test loss-0.2531, acc-0.9292\n",
      "Iter-73550, train loss-0.1649, acc-0.9800, valid loss-0.2414, acc-0.9314, test loss-0.2531, acc-0.9295\n",
      "Iter-73560, train loss-0.1630, acc-0.9600, valid loss-0.2414, acc-0.9310, test loss-0.2531, acc-0.9295\n",
      "Iter-73570, train loss-0.2032, acc-0.9600, valid loss-0.2414, acc-0.9312, test loss-0.2531, acc-0.9296\n",
      "Iter-73580, train loss-0.2072, acc-0.9400, valid loss-0.2414, acc-0.9318, test loss-0.2530, acc-0.9292\n",
      "Iter-73590, train loss-0.3303, acc-0.9200, valid loss-0.2414, acc-0.9316, test loss-0.2530, acc-0.9292\n",
      "Iter-73600, train loss-0.2926, acc-0.8800, valid loss-0.2414, acc-0.9316, test loss-0.2530, acc-0.9295\n",
      "Iter-73610, train loss-0.3532, acc-0.9400, valid loss-0.2413, acc-0.9316, test loss-0.2530, acc-0.9297\n",
      "Iter-73620, train loss-0.3152, acc-0.8800, valid loss-0.2414, acc-0.9314, test loss-0.2529, acc-0.9298\n",
      "Iter-73630, train loss-0.2471, acc-0.9400, valid loss-0.2413, acc-0.9316, test loss-0.2529, acc-0.9294\n",
      "Iter-73640, train loss-0.1455, acc-0.9600, valid loss-0.2413, acc-0.9314, test loss-0.2529, acc-0.9293\n",
      "Iter-73650, train loss-0.4068, acc-0.9000, valid loss-0.2413, acc-0.9316, test loss-0.2529, acc-0.9293\n",
      "Iter-73660, train loss-0.2738, acc-0.9000, valid loss-0.2413, acc-0.9314, test loss-0.2529, acc-0.9294\n",
      "Iter-73670, train loss-0.1912, acc-0.9400, valid loss-0.2414, acc-0.9314, test loss-0.2529, acc-0.9295\n",
      "Iter-73680, train loss-0.1215, acc-0.9600, valid loss-0.2413, acc-0.9310, test loss-0.2529, acc-0.9296\n",
      "Iter-73690, train loss-0.0951, acc-1.0000, valid loss-0.2413, acc-0.9310, test loss-0.2529, acc-0.9296\n",
      "Iter-73700, train loss-0.3303, acc-0.9200, valid loss-0.2413, acc-0.9310, test loss-0.2529, acc-0.9295\n",
      "Iter-73710, train loss-0.3348, acc-0.9200, valid loss-0.2413, acc-0.9314, test loss-0.2529, acc-0.9295\n",
      "Iter-73720, train loss-0.3177, acc-0.9000, valid loss-0.2413, acc-0.9314, test loss-0.2529, acc-0.9296\n",
      "Iter-73730, train loss-0.1735, acc-0.9600, valid loss-0.2413, acc-0.9314, test loss-0.2529, acc-0.9296\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-73740, train loss-0.1643, acc-0.9400, valid loss-0.2412, acc-0.9316, test loss-0.2528, acc-0.9298\n",
      "Iter-73750, train loss-0.3572, acc-0.9200, valid loss-0.2412, acc-0.9312, test loss-0.2528, acc-0.9299\n",
      "Iter-73760, train loss-0.2849, acc-0.9200, valid loss-0.2411, acc-0.9314, test loss-0.2528, acc-0.9296\n",
      "Iter-73770, train loss-0.2340, acc-0.9200, valid loss-0.2411, acc-0.9312, test loss-0.2527, acc-0.9297\n",
      "Iter-73780, train loss-0.2032, acc-0.9800, valid loss-0.2411, acc-0.9310, test loss-0.2527, acc-0.9299\n",
      "Iter-73790, train loss-0.2870, acc-0.9000, valid loss-0.2411, acc-0.9312, test loss-0.2527, acc-0.9300\n",
      "Iter-73800, train loss-0.1923, acc-0.9200, valid loss-0.2411, acc-0.9312, test loss-0.2527, acc-0.9301\n",
      "Iter-73810, train loss-0.1743, acc-0.9600, valid loss-0.2411, acc-0.9312, test loss-0.2526, acc-0.9299\n",
      "Iter-73820, train loss-0.2854, acc-0.9000, valid loss-0.2410, acc-0.9312, test loss-0.2526, acc-0.9297\n",
      "Iter-73830, train loss-0.3901, acc-0.8600, valid loss-0.2410, acc-0.9312, test loss-0.2526, acc-0.9299\n",
      "Iter-73840, train loss-0.2194, acc-0.9200, valid loss-0.2410, acc-0.9310, test loss-0.2526, acc-0.9298\n",
      "Iter-73850, train loss-0.3305, acc-0.9400, valid loss-0.2410, acc-0.9312, test loss-0.2526, acc-0.9299\n",
      "Iter-73860, train loss-0.3074, acc-0.9200, valid loss-0.2410, acc-0.9310, test loss-0.2526, acc-0.9299\n",
      "Iter-73870, train loss-0.3330, acc-0.9000, valid loss-0.2410, acc-0.9310, test loss-0.2526, acc-0.9301\n",
      "Iter-73880, train loss-0.1692, acc-0.9400, valid loss-0.2410, acc-0.9308, test loss-0.2526, acc-0.9299\n",
      "Iter-73890, train loss-0.3557, acc-0.9400, valid loss-0.2410, acc-0.9308, test loss-0.2526, acc-0.9299\n",
      "Iter-73900, train loss-0.3763, acc-0.9200, valid loss-0.2410, acc-0.9308, test loss-0.2526, acc-0.9299\n",
      "Iter-73910, train loss-0.2853, acc-0.8600, valid loss-0.2410, acc-0.9310, test loss-0.2526, acc-0.9301\n",
      "Iter-73920, train loss-0.2437, acc-0.9200, valid loss-0.2409, acc-0.9310, test loss-0.2525, acc-0.9300\n",
      "Iter-73930, train loss-0.2664, acc-0.8800, valid loss-0.2410, acc-0.9310, test loss-0.2525, acc-0.9300\n",
      "Iter-73940, train loss-0.0969, acc-1.0000, valid loss-0.2409, acc-0.9308, test loss-0.2525, acc-0.9301\n",
      "Iter-73950, train loss-0.1262, acc-0.9600, valid loss-0.2410, acc-0.9308, test loss-0.2525, acc-0.9301\n",
      "Iter-73960, train loss-0.2511, acc-0.9200, valid loss-0.2410, acc-0.9312, test loss-0.2525, acc-0.9301\n",
      "Iter-73970, train loss-0.1283, acc-0.9800, valid loss-0.2409, acc-0.9310, test loss-0.2525, acc-0.9302\n",
      "Iter-73980, train loss-0.3091, acc-0.9200, valid loss-0.2410, acc-0.9310, test loss-0.2525, acc-0.9301\n",
      "Iter-73990, train loss-0.3805, acc-0.8400, valid loss-0.2410, acc-0.9310, test loss-0.2525, acc-0.9300\n",
      "Iter-74000, train loss-0.4012, acc-0.9600, valid loss-0.2410, acc-0.9310, test loss-0.2525, acc-0.9301\n",
      "Iter-74010, train loss-0.1136, acc-0.9800, valid loss-0.2409, acc-0.9312, test loss-0.2525, acc-0.9300\n",
      "Iter-74020, train loss-0.1459, acc-0.9400, valid loss-0.2409, acc-0.9312, test loss-0.2525, acc-0.9299\n",
      "Iter-74030, train loss-0.4640, acc-0.8800, valid loss-0.2409, acc-0.9312, test loss-0.2524, acc-0.9299\n",
      "Iter-74040, train loss-0.2260, acc-0.9400, valid loss-0.2409, acc-0.9312, test loss-0.2524, acc-0.9300\n",
      "Iter-74050, train loss-0.1637, acc-0.9600, valid loss-0.2408, acc-0.9314, test loss-0.2525, acc-0.9302\n",
      "Iter-74060, train loss-0.2359, acc-0.9200, valid loss-0.2408, acc-0.9312, test loss-0.2524, acc-0.9299\n",
      "Iter-74070, train loss-0.3200, acc-0.9400, valid loss-0.2408, acc-0.9314, test loss-0.2524, acc-0.9299\n",
      "Iter-74080, train loss-0.2414, acc-0.9000, valid loss-0.2408, acc-0.9314, test loss-0.2524, acc-0.9296\n",
      "Iter-74090, train loss-0.4832, acc-0.8600, valid loss-0.2407, acc-0.9310, test loss-0.2524, acc-0.9296\n",
      "Iter-74100, train loss-0.2565, acc-0.8800, valid loss-0.2408, acc-0.9310, test loss-0.2524, acc-0.9297\n",
      "Iter-74110, train loss-0.2530, acc-0.9000, valid loss-0.2407, acc-0.9312, test loss-0.2523, acc-0.9298\n",
      "Iter-74120, train loss-0.3054, acc-0.9000, valid loss-0.2408, acc-0.9312, test loss-0.2523, acc-0.9297\n",
      "Iter-74130, train loss-0.3087, acc-0.9200, valid loss-0.2407, acc-0.9312, test loss-0.2523, acc-0.9297\n",
      "Iter-74140, train loss-0.1459, acc-0.9600, valid loss-0.2407, acc-0.9312, test loss-0.2522, acc-0.9298\n",
      "Iter-74150, train loss-0.1792, acc-0.9600, valid loss-0.2406, acc-0.9312, test loss-0.2522, acc-0.9297\n",
      "Iter-74160, train loss-0.1007, acc-1.0000, valid loss-0.2406, acc-0.9312, test loss-0.2521, acc-0.9297\n",
      "Iter-74170, train loss-0.2404, acc-0.9600, valid loss-0.2406, acc-0.9310, test loss-0.2522, acc-0.9298\n",
      "Iter-74180, train loss-0.1644, acc-0.9600, valid loss-0.2406, acc-0.9312, test loss-0.2522, acc-0.9297\n",
      "Iter-74190, train loss-0.2462, acc-0.9000, valid loss-0.2407, acc-0.9312, test loss-0.2521, acc-0.9297\n",
      "Iter-74200, train loss-0.1266, acc-0.9800, valid loss-0.2407, acc-0.9314, test loss-0.2521, acc-0.9298\n",
      "Iter-74210, train loss-0.2139, acc-0.9600, valid loss-0.2407, acc-0.9312, test loss-0.2521, acc-0.9298\n",
      "Iter-74220, train loss-0.3472, acc-0.9400, valid loss-0.2407, acc-0.9312, test loss-0.2521, acc-0.9297\n",
      "Iter-74230, train loss-0.2118, acc-0.9800, valid loss-0.2407, acc-0.9310, test loss-0.2521, acc-0.9299\n",
      "Iter-74240, train loss-0.2918, acc-0.9000, valid loss-0.2407, acc-0.9312, test loss-0.2520, acc-0.9300\n",
      "Iter-74250, train loss-0.2509, acc-0.9600, valid loss-0.2407, acc-0.9312, test loss-0.2520, acc-0.9300\n",
      "Iter-74260, train loss-0.1525, acc-0.9400, valid loss-0.2407, acc-0.9312, test loss-0.2520, acc-0.9300\n",
      "Iter-74270, train loss-0.3174, acc-0.9200, valid loss-0.2406, acc-0.9314, test loss-0.2520, acc-0.9301\n",
      "Iter-74280, train loss-0.1401, acc-0.9600, valid loss-0.2405, acc-0.9314, test loss-0.2519, acc-0.9298\n",
      "Iter-74290, train loss-0.1400, acc-0.9600, valid loss-0.2405, acc-0.9316, test loss-0.2519, acc-0.9300\n",
      "Iter-74300, train loss-0.2011, acc-0.9400, valid loss-0.2405, acc-0.9316, test loss-0.2519, acc-0.9301\n",
      "Iter-74310, train loss-0.2171, acc-0.8800, valid loss-0.2405, acc-0.9320, test loss-0.2519, acc-0.9299\n",
      "Iter-74320, train loss-0.3262, acc-0.9400, valid loss-0.2404, acc-0.9318, test loss-0.2519, acc-0.9297\n",
      "Iter-74330, train loss-0.1976, acc-0.9200, valid loss-0.2404, acc-0.9318, test loss-0.2519, acc-0.9299\n",
      "Iter-74340, train loss-0.2678, acc-0.8800, valid loss-0.2404, acc-0.9316, test loss-0.2519, acc-0.9299\n",
      "Iter-74350, train loss-0.4407, acc-0.9200, valid loss-0.2404, acc-0.9316, test loss-0.2518, acc-0.9300\n",
      "Iter-74360, train loss-0.1532, acc-0.9800, valid loss-0.2403, acc-0.9312, test loss-0.2518, acc-0.9298\n",
      "Iter-74370, train loss-0.3306, acc-0.9200, valid loss-0.2404, acc-0.9310, test loss-0.2517, acc-0.9300\n",
      "Iter-74380, train loss-0.2077, acc-0.9600, valid loss-0.2403, acc-0.9312, test loss-0.2517, acc-0.9298\n",
      "Iter-74390, train loss-0.2340, acc-0.8800, valid loss-0.2403, acc-0.9314, test loss-0.2518, acc-0.9298\n",
      "Iter-74400, train loss-0.1706, acc-0.9600, valid loss-0.2403, acc-0.9314, test loss-0.2517, acc-0.9298\n",
      "Iter-74410, train loss-0.1854, acc-0.9600, valid loss-0.2403, acc-0.9314, test loss-0.2517, acc-0.9299\n",
      "Iter-74420, train loss-0.1491, acc-0.9600, valid loss-0.2403, acc-0.9314, test loss-0.2517, acc-0.9298\n",
      "Iter-74430, train loss-0.2581, acc-0.9000, valid loss-0.2403, acc-0.9314, test loss-0.2516, acc-0.9297\n",
      "Iter-74440, train loss-0.2937, acc-0.8600, valid loss-0.2403, acc-0.9316, test loss-0.2516, acc-0.9297\n",
      "Iter-74450, train loss-0.1795, acc-0.9400, valid loss-0.2403, acc-0.9314, test loss-0.2516, acc-0.9299\n",
      "Iter-74460, train loss-0.3653, acc-0.9200, valid loss-0.2403, acc-0.9314, test loss-0.2516, acc-0.9299\n",
      "Iter-74470, train loss-0.1859, acc-0.9400, valid loss-0.2403, acc-0.9314, test loss-0.2516, acc-0.9297\n",
      "Iter-74480, train loss-0.1106, acc-0.9800, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9298\n",
      "Iter-74490, train loss-0.1245, acc-0.9600, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9296\n",
      "Iter-74500, train loss-0.2777, acc-0.9400, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9297\n",
      "Iter-74510, train loss-0.3346, acc-0.9200, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9298\n",
      "Iter-74520, train loss-0.1658, acc-0.9600, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9298\n",
      "Iter-74530, train loss-0.1825, acc-0.9400, valid loss-0.2402, acc-0.9314, test loss-0.2515, acc-0.9297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-74540, train loss-0.2119, acc-0.9400, valid loss-0.2402, acc-0.9314, test loss-0.2515, acc-0.9296\n",
      "Iter-74550, train loss-0.2279, acc-0.9200, valid loss-0.2402, acc-0.9314, test loss-0.2515, acc-0.9296\n",
      "Iter-74560, train loss-0.2948, acc-0.8800, valid loss-0.2402, acc-0.9314, test loss-0.2516, acc-0.9297\n",
      "Iter-74570, train loss-0.3866, acc-0.8600, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9296\n",
      "Iter-74580, train loss-0.2457, acc-0.9400, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9296\n",
      "Iter-74590, train loss-0.1240, acc-0.9600, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9296\n",
      "Iter-74600, train loss-0.2918, acc-0.9000, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9296\n",
      "Iter-74610, train loss-0.3534, acc-0.9200, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9297\n",
      "Iter-74620, train loss-0.2650, acc-0.9400, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9296\n",
      "Iter-74630, train loss-0.2575, acc-0.9400, valid loss-0.2401, acc-0.9316, test loss-0.2515, acc-0.9297\n",
      "Iter-74640, train loss-0.2255, acc-0.9400, valid loss-0.2402, acc-0.9316, test loss-0.2515, acc-0.9297\n",
      "Iter-74650, train loss-0.3295, acc-0.8200, valid loss-0.2402, acc-0.9316, test loss-0.2515, acc-0.9297\n",
      "Iter-74660, train loss-0.2824, acc-0.8800, valid loss-0.2402, acc-0.9314, test loss-0.2514, acc-0.9297\n",
      "Iter-74670, train loss-0.3611, acc-0.9200, valid loss-0.2402, acc-0.9316, test loss-0.2514, acc-0.9296\n",
      "Iter-74680, train loss-0.2419, acc-0.9200, valid loss-0.2403, acc-0.9316, test loss-0.2514, acc-0.9297\n",
      "Iter-74690, train loss-0.3005, acc-0.9000, valid loss-0.2402, acc-0.9316, test loss-0.2514, acc-0.9296\n",
      "Iter-74700, train loss-0.1906, acc-0.9600, valid loss-0.2402, acc-0.9314, test loss-0.2514, acc-0.9296\n",
      "Iter-74710, train loss-0.3471, acc-0.9000, valid loss-0.2402, acc-0.9314, test loss-0.2514, acc-0.9294\n",
      "Iter-74720, train loss-0.1829, acc-0.9600, valid loss-0.2402, acc-0.9314, test loss-0.2514, acc-0.9296\n",
      "Iter-74730, train loss-0.2278, acc-0.9400, valid loss-0.2403, acc-0.9314, test loss-0.2514, acc-0.9297\n",
      "Iter-74740, train loss-0.2828, acc-0.9000, valid loss-0.2403, acc-0.9314, test loss-0.2514, acc-0.9299\n",
      "Iter-74750, train loss-0.2395, acc-0.9200, valid loss-0.2402, acc-0.9314, test loss-0.2513, acc-0.9296\n",
      "Iter-74760, train loss-0.1816, acc-0.9600, valid loss-0.2402, acc-0.9316, test loss-0.2513, acc-0.9299\n",
      "Iter-74770, train loss-0.3596, acc-0.9000, valid loss-0.2402, acc-0.9316, test loss-0.2513, acc-0.9299\n",
      "Iter-74780, train loss-0.2171, acc-0.9000, valid loss-0.2402, acc-0.9314, test loss-0.2513, acc-0.9299\n",
      "Iter-74790, train loss-0.3286, acc-0.9400, valid loss-0.2402, acc-0.9316, test loss-0.2513, acc-0.9302\n",
      "Iter-74800, train loss-0.3258, acc-0.9000, valid loss-0.2402, acc-0.9316, test loss-0.2513, acc-0.9302\n",
      "Iter-74810, train loss-0.2975, acc-0.9200, valid loss-0.2401, acc-0.9316, test loss-0.2514, acc-0.9300\n",
      "Iter-74820, train loss-0.3343, acc-0.9200, valid loss-0.2401, acc-0.9316, test loss-0.2513, acc-0.9296\n",
      "Iter-74830, train loss-0.4054, acc-0.8400, valid loss-0.2401, acc-0.9316, test loss-0.2513, acc-0.9300\n",
      "Iter-74840, train loss-0.2424, acc-0.9400, valid loss-0.2402, acc-0.9316, test loss-0.2512, acc-0.9300\n",
      "Iter-74850, train loss-0.2504, acc-0.9400, valid loss-0.2401, acc-0.9316, test loss-0.2512, acc-0.9299\n",
      "Iter-74860, train loss-0.2264, acc-0.9600, valid loss-0.2401, acc-0.9316, test loss-0.2512, acc-0.9299\n",
      "Iter-74870, train loss-0.2095, acc-0.9400, valid loss-0.2401, acc-0.9318, test loss-0.2513, acc-0.9296\n",
      "Iter-74880, train loss-0.4046, acc-0.8800, valid loss-0.2400, acc-0.9318, test loss-0.2512, acc-0.9300\n",
      "Iter-74890, train loss-0.1687, acc-0.9400, valid loss-0.2400, acc-0.9316, test loss-0.2513, acc-0.9298\n",
      "Iter-74900, train loss-0.3944, acc-0.8800, valid loss-0.2400, acc-0.9316, test loss-0.2513, acc-0.9298\n",
      "Iter-74910, train loss-0.2255, acc-0.9200, valid loss-0.2401, acc-0.9316, test loss-0.2513, acc-0.9298\n",
      "Iter-74920, train loss-0.3625, acc-0.9000, valid loss-0.2400, acc-0.9316, test loss-0.2512, acc-0.9299\n",
      "Iter-74930, train loss-0.3310, acc-0.9400, valid loss-0.2400, acc-0.9316, test loss-0.2512, acc-0.9299\n",
      "Iter-74940, train loss-0.1591, acc-0.9200, valid loss-0.2400, acc-0.9314, test loss-0.2512, acc-0.9298\n",
      "Iter-74950, train loss-0.2098, acc-0.9600, valid loss-0.2400, acc-0.9314, test loss-0.2512, acc-0.9299\n",
      "Iter-74960, train loss-0.4241, acc-0.8600, valid loss-0.2400, acc-0.9316, test loss-0.2511, acc-0.9299\n",
      "Iter-74970, train loss-0.3713, acc-0.9200, valid loss-0.2400, acc-0.9316, test loss-0.2511, acc-0.9299\n",
      "Iter-74980, train loss-0.1481, acc-0.9200, valid loss-0.2400, acc-0.9318, test loss-0.2511, acc-0.9297\n",
      "Iter-74990, train loss-0.3249, acc-0.8800, valid loss-0.2399, acc-0.9318, test loss-0.2512, acc-0.9297\n",
      "Iter-75000, train loss-0.3146, acc-0.9200, valid loss-0.2399, acc-0.9318, test loss-0.2511, acc-0.9298\n",
      "Iter-75010, train loss-0.4196, acc-0.8800, valid loss-0.2399, acc-0.9318, test loss-0.2511, acc-0.9296\n",
      "Iter-75020, train loss-0.2718, acc-0.9400, valid loss-0.2399, acc-0.9316, test loss-0.2511, acc-0.9298\n",
      "Iter-75030, train loss-0.2002, acc-0.9400, valid loss-0.2399, acc-0.9318, test loss-0.2510, acc-0.9296\n",
      "Iter-75040, train loss-0.1459, acc-0.9600, valid loss-0.2398, acc-0.9318, test loss-0.2510, acc-0.9296\n",
      "Iter-75050, train loss-0.2586, acc-0.9400, valid loss-0.2398, acc-0.9320, test loss-0.2509, acc-0.9299\n",
      "Iter-75060, train loss-0.3133, acc-0.9200, valid loss-0.2399, acc-0.9316, test loss-0.2509, acc-0.9297\n",
      "Iter-75070, train loss-0.3051, acc-0.9200, valid loss-0.2398, acc-0.9316, test loss-0.2509, acc-0.9299\n",
      "Iter-75080, train loss-0.4261, acc-0.9000, valid loss-0.2398, acc-0.9316, test loss-0.2509, acc-0.9295\n",
      "Iter-75090, train loss-0.1867, acc-0.9200, valid loss-0.2397, acc-0.9318, test loss-0.2508, acc-0.9295\n",
      "Iter-75100, train loss-0.4017, acc-0.9000, valid loss-0.2397, acc-0.9316, test loss-0.2508, acc-0.9297\n",
      "Iter-75110, train loss-0.2439, acc-0.9000, valid loss-0.2397, acc-0.9314, test loss-0.2508, acc-0.9299\n",
      "Iter-75120, train loss-0.2426, acc-0.9400, valid loss-0.2397, acc-0.9314, test loss-0.2508, acc-0.9298\n",
      "Iter-75130, train loss-0.2141, acc-0.9800, valid loss-0.2396, acc-0.9314, test loss-0.2507, acc-0.9297\n",
      "Iter-75140, train loss-0.2776, acc-0.9200, valid loss-0.2397, acc-0.9314, test loss-0.2507, acc-0.9296\n",
      "Iter-75150, train loss-0.1611, acc-0.9400, valid loss-0.2397, acc-0.9314, test loss-0.2507, acc-0.9297\n",
      "Iter-75160, train loss-0.2086, acc-0.9200, valid loss-0.2397, acc-0.9316, test loss-0.2507, acc-0.9297\n",
      "Iter-75170, train loss-0.3746, acc-0.9000, valid loss-0.2397, acc-0.9318, test loss-0.2507, acc-0.9297\n",
      "Iter-75180, train loss-0.1505, acc-0.9800, valid loss-0.2397, acc-0.9318, test loss-0.2507, acc-0.9297\n",
      "Iter-75190, train loss-0.2434, acc-0.9400, valid loss-0.2397, acc-0.9314, test loss-0.2507, acc-0.9296\n",
      "Iter-75200, train loss-0.1237, acc-0.9800, valid loss-0.2396, acc-0.9314, test loss-0.2507, acc-0.9295\n",
      "Iter-75210, train loss-0.1777, acc-0.9600, valid loss-0.2397, acc-0.9316, test loss-0.2507, acc-0.9297\n",
      "Iter-75220, train loss-0.5404, acc-0.8600, valid loss-0.2397, acc-0.9316, test loss-0.2507, acc-0.9297\n",
      "Iter-75230, train loss-0.3143, acc-0.9000, valid loss-0.2398, acc-0.9316, test loss-0.2507, acc-0.9297\n",
      "Iter-75240, train loss-0.3940, acc-0.8800, valid loss-0.2397, acc-0.9314, test loss-0.2507, acc-0.9296\n",
      "Iter-75250, train loss-0.1555, acc-0.9800, valid loss-0.2397, acc-0.9314, test loss-0.2507, acc-0.9298\n",
      "Iter-75260, train loss-0.2345, acc-0.9400, valid loss-0.2396, acc-0.9314, test loss-0.2507, acc-0.9297\n",
      "Iter-75270, train loss-0.0877, acc-0.9800, valid loss-0.2396, acc-0.9314, test loss-0.2506, acc-0.9298\n",
      "Iter-75280, train loss-0.2159, acc-0.9200, valid loss-0.2396, acc-0.9316, test loss-0.2507, acc-0.9296\n",
      "Iter-75290, train loss-0.2504, acc-0.9400, valid loss-0.2395, acc-0.9318, test loss-0.2506, acc-0.9297\n",
      "Iter-75300, train loss-0.1857, acc-0.9400, valid loss-0.2395, acc-0.9320, test loss-0.2506, acc-0.9295\n",
      "Iter-75310, train loss-0.1311, acc-0.9600, valid loss-0.2395, acc-0.9320, test loss-0.2506, acc-0.9296\n",
      "Iter-75320, train loss-0.2860, acc-0.9200, valid loss-0.2395, acc-0.9322, test loss-0.2505, acc-0.9299\n",
      "Iter-75330, train loss-0.1595, acc-0.9600, valid loss-0.2395, acc-0.9322, test loss-0.2505, acc-0.9298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-75340, train loss-0.3639, acc-0.9200, valid loss-0.2395, acc-0.9322, test loss-0.2505, acc-0.9297\n",
      "Iter-75350, train loss-0.0916, acc-1.0000, valid loss-0.2394, acc-0.9320, test loss-0.2505, acc-0.9299\n",
      "Iter-75360, train loss-0.2028, acc-0.9400, valid loss-0.2395, acc-0.9320, test loss-0.2505, acc-0.9300\n",
      "Iter-75370, train loss-0.2950, acc-0.8400, valid loss-0.2394, acc-0.9320, test loss-0.2505, acc-0.9300\n",
      "Iter-75380, train loss-0.2888, acc-0.9400, valid loss-0.2394, acc-0.9320, test loss-0.2505, acc-0.9301\n",
      "Iter-75390, train loss-0.3835, acc-0.8800, valid loss-0.2394, acc-0.9320, test loss-0.2505, acc-0.9301\n",
      "Iter-75400, train loss-0.2480, acc-0.9400, valid loss-0.2394, acc-0.9322, test loss-0.2505, acc-0.9300\n",
      "Iter-75410, train loss-0.2987, acc-0.8800, valid loss-0.2395, acc-0.9320, test loss-0.2505, acc-0.9299\n",
      "Iter-75420, train loss-0.3122, acc-0.9200, valid loss-0.2394, acc-0.9316, test loss-0.2504, acc-0.9302\n",
      "Iter-75430, train loss-0.2970, acc-0.9200, valid loss-0.2395, acc-0.9320, test loss-0.2504, acc-0.9302\n",
      "Iter-75440, train loss-0.2989, acc-0.8800, valid loss-0.2394, acc-0.9318, test loss-0.2504, acc-0.9302\n",
      "Iter-75450, train loss-0.0927, acc-0.9800, valid loss-0.2394, acc-0.9316, test loss-0.2504, acc-0.9303\n",
      "Iter-75460, train loss-0.1502, acc-0.9800, valid loss-0.2394, acc-0.9318, test loss-0.2503, acc-0.9301\n",
      "Iter-75470, train loss-0.3650, acc-0.8400, valid loss-0.2394, acc-0.9320, test loss-0.2503, acc-0.9303\n",
      "Iter-75480, train loss-0.3208, acc-0.9200, valid loss-0.2394, acc-0.9316, test loss-0.2503, acc-0.9301\n",
      "Iter-75490, train loss-0.1113, acc-0.9800, valid loss-0.2394, acc-0.9312, test loss-0.2503, acc-0.9301\n",
      "Iter-75500, train loss-0.2017, acc-0.9600, valid loss-0.2394, acc-0.9316, test loss-0.2502, acc-0.9298\n",
      "Iter-75510, train loss-0.1556, acc-0.9800, valid loss-0.2394, acc-0.9316, test loss-0.2502, acc-0.9300\n",
      "Iter-75520, train loss-0.2393, acc-0.9400, valid loss-0.2393, acc-0.9312, test loss-0.2502, acc-0.9299\n",
      "Iter-75530, train loss-0.1238, acc-0.9800, valid loss-0.2393, acc-0.9314, test loss-0.2503, acc-0.9301\n",
      "Iter-75540, train loss-0.2238, acc-0.9200, valid loss-0.2393, acc-0.9314, test loss-0.2502, acc-0.9300\n",
      "Iter-75550, train loss-0.1284, acc-0.9600, valid loss-0.2393, acc-0.9312, test loss-0.2503, acc-0.9300\n",
      "Iter-75560, train loss-0.4073, acc-0.9400, valid loss-0.2394, acc-0.9316, test loss-0.2502, acc-0.9303\n",
      "Iter-75570, train loss-0.3363, acc-0.9400, valid loss-0.2394, acc-0.9314, test loss-0.2503, acc-0.9302\n",
      "Iter-75580, train loss-0.3768, acc-0.9000, valid loss-0.2393, acc-0.9316, test loss-0.2502, acc-0.9301\n",
      "Iter-75590, train loss-0.2228, acc-0.9200, valid loss-0.2394, acc-0.9316, test loss-0.2503, acc-0.9303\n",
      "Iter-75600, train loss-0.3971, acc-0.9400, valid loss-0.2394, acc-0.9316, test loss-0.2502, acc-0.9303\n",
      "Iter-75610, train loss-0.1863, acc-0.9200, valid loss-0.2394, acc-0.9316, test loss-0.2503, acc-0.9301\n",
      "Iter-75620, train loss-0.1506, acc-0.9600, valid loss-0.2394, acc-0.9320, test loss-0.2502, acc-0.9300\n",
      "Iter-75630, train loss-0.3665, acc-0.8800, valid loss-0.2394, acc-0.9322, test loss-0.2502, acc-0.9302\n",
      "Iter-75640, train loss-0.2799, acc-0.9200, valid loss-0.2393, acc-0.9318, test loss-0.2502, acc-0.9302\n",
      "Iter-75650, train loss-0.1782, acc-0.9400, valid loss-0.2393, acc-0.9318, test loss-0.2502, acc-0.9303\n",
      "Iter-75660, train loss-0.1927, acc-0.9600, valid loss-0.2393, acc-0.9318, test loss-0.2501, acc-0.9302\n",
      "Iter-75670, train loss-0.2839, acc-0.9200, valid loss-0.2392, acc-0.9320, test loss-0.2502, acc-0.9301\n",
      "Iter-75680, train loss-0.1996, acc-0.9400, valid loss-0.2392, acc-0.9316, test loss-0.2501, acc-0.9302\n",
      "Iter-75690, train loss-0.1054, acc-0.9600, valid loss-0.2392, acc-0.9320, test loss-0.2501, acc-0.9301\n",
      "Iter-75700, train loss-0.2706, acc-0.9200, valid loss-0.2391, acc-0.9320, test loss-0.2501, acc-0.9303\n",
      "Iter-75710, train loss-0.5137, acc-0.8600, valid loss-0.2391, acc-0.9320, test loss-0.2501, acc-0.9303\n",
      "Iter-75720, train loss-0.1624, acc-0.9400, valid loss-0.2392, acc-0.9318, test loss-0.2501, acc-0.9302\n",
      "Iter-75730, train loss-0.1777, acc-0.9200, valid loss-0.2391, acc-0.9314, test loss-0.2501, acc-0.9302\n",
      "Iter-75740, train loss-0.4429, acc-0.8400, valid loss-0.2391, acc-0.9316, test loss-0.2500, acc-0.9302\n",
      "Iter-75750, train loss-0.1958, acc-0.9400, valid loss-0.2391, acc-0.9314, test loss-0.2500, acc-0.9303\n",
      "Iter-75760, train loss-0.1497, acc-0.9400, valid loss-0.2391, acc-0.9314, test loss-0.2500, acc-0.9303\n",
      "Iter-75770, train loss-0.3845, acc-0.9000, valid loss-0.2391, acc-0.9314, test loss-0.2500, acc-0.9303\n",
      "Iter-75780, train loss-0.1609, acc-0.9600, valid loss-0.2391, acc-0.9316, test loss-0.2499, acc-0.9303\n",
      "Iter-75790, train loss-0.2905, acc-0.9000, valid loss-0.2391, acc-0.9312, test loss-0.2499, acc-0.9304\n",
      "Iter-75800, train loss-0.0819, acc-0.9800, valid loss-0.2391, acc-0.9316, test loss-0.2499, acc-0.9303\n",
      "Iter-75810, train loss-0.1265, acc-0.9800, valid loss-0.2391, acc-0.9318, test loss-0.2499, acc-0.9304\n",
      "Iter-75820, train loss-0.2708, acc-0.9000, valid loss-0.2391, acc-0.9320, test loss-0.2499, acc-0.9304\n",
      "Iter-75830, train loss-0.0891, acc-1.0000, valid loss-0.2391, acc-0.9318, test loss-0.2499, acc-0.9303\n",
      "Iter-75840, train loss-0.4272, acc-0.9000, valid loss-0.2391, acc-0.9314, test loss-0.2499, acc-0.9303\n",
      "Iter-75850, train loss-0.3109, acc-0.9000, valid loss-0.2391, acc-0.9326, test loss-0.2499, acc-0.9304\n",
      "Iter-75860, train loss-0.2639, acc-0.9000, valid loss-0.2391, acc-0.9316, test loss-0.2499, acc-0.9304\n",
      "Iter-75870, train loss-0.2339, acc-0.9400, valid loss-0.2391, acc-0.9322, test loss-0.2499, acc-0.9304\n",
      "Iter-75880, train loss-0.3902, acc-0.8600, valid loss-0.2390, acc-0.9324, test loss-0.2498, acc-0.9304\n",
      "Iter-75890, train loss-0.2236, acc-0.9400, valid loss-0.2389, acc-0.9320, test loss-0.2498, acc-0.9302\n",
      "Iter-75900, train loss-0.1731, acc-0.9800, valid loss-0.2389, acc-0.9324, test loss-0.2499, acc-0.9303\n",
      "Iter-75910, train loss-0.1689, acc-0.9400, valid loss-0.2389, acc-0.9320, test loss-0.2498, acc-0.9303\n",
      "Iter-75920, train loss-0.1610, acc-0.9600, valid loss-0.2389, acc-0.9320, test loss-0.2499, acc-0.9302\n",
      "Iter-75930, train loss-0.2751, acc-0.9000, valid loss-0.2389, acc-0.9318, test loss-0.2499, acc-0.9302\n",
      "Iter-75940, train loss-0.2303, acc-0.9000, valid loss-0.2389, acc-0.9316, test loss-0.2499, acc-0.9300\n",
      "Iter-75950, train loss-0.3567, acc-0.9000, valid loss-0.2388, acc-0.9316, test loss-0.2499, acc-0.9300\n",
      "Iter-75960, train loss-0.2212, acc-0.9400, valid loss-0.2388, acc-0.9314, test loss-0.2498, acc-0.9301\n",
      "Iter-75970, train loss-0.2605, acc-0.9600, valid loss-0.2388, acc-0.9314, test loss-0.2498, acc-0.9301\n",
      "Iter-75980, train loss-0.2600, acc-0.9200, valid loss-0.2388, acc-0.9312, test loss-0.2498, acc-0.9302\n",
      "Iter-75990, train loss-0.1066, acc-0.9800, valid loss-0.2388, acc-0.9312, test loss-0.2498, acc-0.9303\n",
      "Iter-76000, train loss-0.2389, acc-0.9200, valid loss-0.2388, acc-0.9312, test loss-0.2498, acc-0.9304\n",
      "Iter-76010, train loss-0.1728, acc-0.9400, valid loss-0.2389, acc-0.9312, test loss-0.2498, acc-0.9305\n",
      "Iter-76020, train loss-0.2983, acc-0.8800, valid loss-0.2388, acc-0.9310, test loss-0.2497, acc-0.9305\n",
      "Iter-76030, train loss-0.2854, acc-0.9200, valid loss-0.2388, acc-0.9310, test loss-0.2497, acc-0.9306\n",
      "Iter-76040, train loss-0.2281, acc-0.9200, valid loss-0.2388, acc-0.9308, test loss-0.2497, acc-0.9306\n",
      "Iter-76050, train loss-0.3325, acc-0.9200, valid loss-0.2389, acc-0.9312, test loss-0.2497, acc-0.9306\n",
      "Iter-76060, train loss-0.3492, acc-0.9400, valid loss-0.2389, acc-0.9310, test loss-0.2497, acc-0.9307\n",
      "Iter-76070, train loss-0.1374, acc-0.9600, valid loss-0.2388, acc-0.9310, test loss-0.2497, acc-0.9307\n",
      "Iter-76080, train loss-0.2823, acc-0.9400, valid loss-0.2389, acc-0.9310, test loss-0.2496, acc-0.9308\n",
      "Iter-76090, train loss-0.1487, acc-0.9600, valid loss-0.2389, acc-0.9308, test loss-0.2497, acc-0.9307\n",
      "Iter-76100, train loss-0.0913, acc-1.0000, valid loss-0.2389, acc-0.9308, test loss-0.2497, acc-0.9311\n",
      "Iter-76110, train loss-0.4208, acc-0.8800, valid loss-0.2389, acc-0.9308, test loss-0.2496, acc-0.9307\n",
      "Iter-76120, train loss-0.2153, acc-0.9000, valid loss-0.2389, acc-0.9308, test loss-0.2497, acc-0.9308\n",
      "Iter-76130, train loss-0.2167, acc-0.9600, valid loss-0.2389, acc-0.9312, test loss-0.2497, acc-0.9309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-76140, train loss-0.2056, acc-0.9600, valid loss-0.2389, acc-0.9306, test loss-0.2496, acc-0.9309\n",
      "Iter-76150, train loss-0.1625, acc-0.9400, valid loss-0.2388, acc-0.9312, test loss-0.2497, acc-0.9308\n",
      "Iter-76160, train loss-0.4390, acc-0.8800, valid loss-0.2387, acc-0.9312, test loss-0.2497, acc-0.9306\n",
      "Iter-76170, train loss-0.3029, acc-0.9000, valid loss-0.2388, acc-0.9312, test loss-0.2497, acc-0.9307\n",
      "Iter-76180, train loss-0.2709, acc-0.9000, valid loss-0.2388, acc-0.9312, test loss-0.2497, acc-0.9307\n",
      "Iter-76190, train loss-0.2409, acc-0.9000, valid loss-0.2388, acc-0.9310, test loss-0.2497, acc-0.9307\n",
      "Iter-76200, train loss-0.2459, acc-0.9600, valid loss-0.2388, acc-0.9310, test loss-0.2497, acc-0.9307\n",
      "Iter-76210, train loss-0.4479, acc-0.8600, valid loss-0.2387, acc-0.9312, test loss-0.2496, acc-0.9308\n",
      "Iter-76220, train loss-0.5639, acc-0.8400, valid loss-0.2387, acc-0.9312, test loss-0.2496, acc-0.9307\n",
      "Iter-76230, train loss-0.2400, acc-0.9200, valid loss-0.2388, acc-0.9314, test loss-0.2496, acc-0.9307\n",
      "Iter-76240, train loss-0.2174, acc-0.9200, valid loss-0.2387, acc-0.9314, test loss-0.2495, acc-0.9308\n",
      "Iter-76250, train loss-0.2214, acc-0.9400, valid loss-0.2387, acc-0.9316, test loss-0.2495, acc-0.9309\n",
      "Iter-76260, train loss-0.2671, acc-0.8600, valid loss-0.2388, acc-0.9314, test loss-0.2494, acc-0.9310\n",
      "Iter-76270, train loss-0.1335, acc-0.9600, valid loss-0.2388, acc-0.9314, test loss-0.2494, acc-0.9310\n",
      "Iter-76280, train loss-0.3435, acc-0.9400, valid loss-0.2386, acc-0.9316, test loss-0.2494, acc-0.9310\n",
      "Iter-76290, train loss-0.1754, acc-0.9400, valid loss-0.2386, acc-0.9314, test loss-0.2494, acc-0.9308\n",
      "Iter-76300, train loss-0.2768, acc-0.9000, valid loss-0.2385, acc-0.9316, test loss-0.2494, acc-0.9314\n",
      "Iter-76310, train loss-0.4367, acc-0.8800, valid loss-0.2386, acc-0.9318, test loss-0.2494, acc-0.9314\n",
      "Iter-76320, train loss-0.3592, acc-0.8800, valid loss-0.2385, acc-0.9316, test loss-0.2493, acc-0.9311\n",
      "Iter-76330, train loss-0.2531, acc-0.9600, valid loss-0.2385, acc-0.9318, test loss-0.2493, acc-0.9313\n",
      "Iter-76340, train loss-0.1784, acc-0.9600, valid loss-0.2386, acc-0.9318, test loss-0.2493, acc-0.9311\n",
      "Iter-76350, train loss-0.2083, acc-0.9400, valid loss-0.2386, acc-0.9316, test loss-0.2493, acc-0.9313\n",
      "Iter-76360, train loss-0.2119, acc-0.9200, valid loss-0.2385, acc-0.9316, test loss-0.2492, acc-0.9312\n",
      "Iter-76370, train loss-0.1908, acc-0.9400, valid loss-0.2385, acc-0.9318, test loss-0.2492, acc-0.9311\n",
      "Iter-76380, train loss-0.1317, acc-1.0000, valid loss-0.2384, acc-0.9318, test loss-0.2492, acc-0.9309\n",
      "Iter-76390, train loss-0.2182, acc-0.9400, valid loss-0.2385, acc-0.9314, test loss-0.2492, acc-0.9309\n",
      "Iter-76400, train loss-0.1378, acc-0.9600, valid loss-0.2386, acc-0.9316, test loss-0.2492, acc-0.9308\n",
      "Iter-76410, train loss-0.2177, acc-0.9200, valid loss-0.2386, acc-0.9314, test loss-0.2492, acc-0.9311\n",
      "Iter-76420, train loss-0.2764, acc-0.9200, valid loss-0.2386, acc-0.9316, test loss-0.2492, acc-0.9309\n",
      "Iter-76430, train loss-0.2086, acc-0.9600, valid loss-0.2386, acc-0.9316, test loss-0.2492, acc-0.9310\n",
      "Iter-76440, train loss-0.3991, acc-0.8400, valid loss-0.2386, acc-0.9312, test loss-0.2492, acc-0.9308\n",
      "Iter-76450, train loss-0.3156, acc-0.8600, valid loss-0.2386, acc-0.9314, test loss-0.2491, acc-0.9308\n",
      "Iter-76460, train loss-0.3224, acc-0.9200, valid loss-0.2385, acc-0.9316, test loss-0.2491, acc-0.9309\n",
      "Iter-76470, train loss-0.1048, acc-0.9800, valid loss-0.2385, acc-0.9314, test loss-0.2490, acc-0.9309\n",
      "Iter-76480, train loss-0.2376, acc-0.8800, valid loss-0.2385, acc-0.9312, test loss-0.2490, acc-0.9309\n",
      "Iter-76490, train loss-0.1545, acc-0.9200, valid loss-0.2384, acc-0.9316, test loss-0.2490, acc-0.9308\n",
      "Iter-76500, train loss-0.1599, acc-0.9600, valid loss-0.2385, acc-0.9316, test loss-0.2490, acc-0.9309\n",
      "Iter-76510, train loss-0.3536, acc-0.8400, valid loss-0.2384, acc-0.9318, test loss-0.2490, acc-0.9310\n",
      "Iter-76520, train loss-0.2998, acc-0.9200, valid loss-0.2384, acc-0.9318, test loss-0.2490, acc-0.9310\n",
      "Iter-76530, train loss-0.2342, acc-0.9400, valid loss-0.2384, acc-0.9318, test loss-0.2489, acc-0.9310\n",
      "Iter-76540, train loss-0.3518, acc-0.9200, valid loss-0.2384, acc-0.9318, test loss-0.2489, acc-0.9310\n",
      "Iter-76550, train loss-0.1883, acc-0.9200, valid loss-0.2384, acc-0.9316, test loss-0.2488, acc-0.9311\n",
      "Iter-76560, train loss-0.2560, acc-0.9600, valid loss-0.2383, acc-0.9316, test loss-0.2488, acc-0.9311\n",
      "Iter-76570, train loss-0.1317, acc-0.9600, valid loss-0.2384, acc-0.9314, test loss-0.2488, acc-0.9312\n",
      "Iter-76580, train loss-0.1563, acc-0.9600, valid loss-0.2384, acc-0.9312, test loss-0.2488, acc-0.9311\n",
      "Iter-76590, train loss-0.2955, acc-0.9400, valid loss-0.2385, acc-0.9310, test loss-0.2487, acc-0.9312\n",
      "Iter-76600, train loss-0.2724, acc-0.9000, valid loss-0.2385, acc-0.9314, test loss-0.2487, acc-0.9313\n",
      "Iter-76610, train loss-0.2731, acc-0.9200, valid loss-0.2384, acc-0.9316, test loss-0.2486, acc-0.9311\n",
      "Iter-76620, train loss-0.2041, acc-0.9600, valid loss-0.2384, acc-0.9314, test loss-0.2487, acc-0.9310\n",
      "Iter-76630, train loss-0.2664, acc-0.9200, valid loss-0.2384, acc-0.9316, test loss-0.2487, acc-0.9310\n",
      "Iter-76640, train loss-0.2325, acc-0.9400, valid loss-0.2384, acc-0.9314, test loss-0.2487, acc-0.9312\n",
      "Iter-76650, train loss-0.1082, acc-1.0000, valid loss-0.2383, acc-0.9316, test loss-0.2487, acc-0.9311\n",
      "Iter-76660, train loss-0.5674, acc-0.8000, valid loss-0.2383, acc-0.9316, test loss-0.2486, acc-0.9312\n",
      "Iter-76670, train loss-0.4049, acc-0.8800, valid loss-0.2382, acc-0.9316, test loss-0.2486, acc-0.9313\n",
      "Iter-76680, train loss-0.2273, acc-0.9400, valid loss-0.2383, acc-0.9318, test loss-0.2486, acc-0.9313\n",
      "Iter-76690, train loss-0.1960, acc-0.9400, valid loss-0.2383, acc-0.9316, test loss-0.2486, acc-0.9313\n",
      "Iter-76700, train loss-0.1564, acc-0.9600, valid loss-0.2382, acc-0.9316, test loss-0.2486, acc-0.9312\n",
      "Iter-76710, train loss-0.1505, acc-0.9800, valid loss-0.2381, acc-0.9322, test loss-0.2486, acc-0.9311\n",
      "Iter-76720, train loss-0.2031, acc-0.9200, valid loss-0.2381, acc-0.9320, test loss-0.2485, acc-0.9311\n",
      "Iter-76730, train loss-0.2447, acc-0.9400, valid loss-0.2381, acc-0.9322, test loss-0.2485, acc-0.9312\n",
      "Iter-76740, train loss-0.1474, acc-0.9800, valid loss-0.2381, acc-0.9324, test loss-0.2485, acc-0.9314\n",
      "Iter-76750, train loss-0.2375, acc-0.9400, valid loss-0.2381, acc-0.9322, test loss-0.2485, acc-0.9313\n",
      "Iter-76760, train loss-0.1452, acc-0.9600, valid loss-0.2381, acc-0.9322, test loss-0.2484, acc-0.9312\n",
      "Iter-76770, train loss-0.2014, acc-0.9400, valid loss-0.2381, acc-0.9320, test loss-0.2484, acc-0.9313\n",
      "Iter-76780, train loss-0.2300, acc-0.9200, valid loss-0.2381, acc-0.9320, test loss-0.2484, acc-0.9313\n",
      "Iter-76790, train loss-0.2972, acc-0.9000, valid loss-0.2381, acc-0.9322, test loss-0.2483, acc-0.9312\n",
      "Iter-76800, train loss-0.2779, acc-0.9200, valid loss-0.2381, acc-0.9318, test loss-0.2483, acc-0.9315\n",
      "Iter-76810, train loss-0.1716, acc-0.9400, valid loss-0.2381, acc-0.9320, test loss-0.2482, acc-0.9314\n",
      "Iter-76820, train loss-0.4513, acc-0.8400, valid loss-0.2381, acc-0.9322, test loss-0.2482, acc-0.9315\n",
      "Iter-76830, train loss-0.1176, acc-0.9600, valid loss-0.2381, acc-0.9318, test loss-0.2482, acc-0.9316\n",
      "Iter-76840, train loss-0.2015, acc-0.9400, valid loss-0.2381, acc-0.9318, test loss-0.2482, acc-0.9317\n",
      "Iter-76850, train loss-0.3368, acc-0.9200, valid loss-0.2381, acc-0.9318, test loss-0.2482, acc-0.9317\n",
      "Iter-76860, train loss-0.1233, acc-0.9600, valid loss-0.2380, acc-0.9316, test loss-0.2482, acc-0.9318\n",
      "Iter-76870, train loss-0.2055, acc-0.9000, valid loss-0.2380, acc-0.9314, test loss-0.2481, acc-0.9318\n",
      "Iter-76880, train loss-0.2077, acc-0.9400, valid loss-0.2380, acc-0.9316, test loss-0.2481, acc-0.9315\n",
      "Iter-76890, train loss-0.1602, acc-0.9600, valid loss-0.2381, acc-0.9316, test loss-0.2481, acc-0.9318\n",
      "Iter-76900, train loss-0.2071, acc-0.9600, valid loss-0.2381, acc-0.9316, test loss-0.2481, acc-0.9315\n",
      "Iter-76910, train loss-0.3495, acc-0.9200, valid loss-0.2381, acc-0.9316, test loss-0.2481, acc-0.9316\n",
      "Iter-76920, train loss-0.3253, acc-0.9000, valid loss-0.2381, acc-0.9316, test loss-0.2480, acc-0.9315\n",
      "Iter-76930, train loss-0.1307, acc-0.9800, valid loss-0.2380, acc-0.9316, test loss-0.2480, acc-0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-76940, train loss-0.3350, acc-0.9200, valid loss-0.2380, acc-0.9316, test loss-0.2480, acc-0.9318\n",
      "Iter-76950, train loss-0.2906, acc-0.9200, valid loss-0.2380, acc-0.9316, test loss-0.2480, acc-0.9317\n",
      "Iter-76960, train loss-0.0958, acc-0.9800, valid loss-0.2379, acc-0.9320, test loss-0.2480, acc-0.9317\n",
      "Iter-76970, train loss-0.1532, acc-0.9600, valid loss-0.2379, acc-0.9322, test loss-0.2480, acc-0.9315\n",
      "Iter-76980, train loss-0.3122, acc-0.8800, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9316\n",
      "Iter-76990, train loss-0.2440, acc-0.8800, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9317\n",
      "Iter-77000, train loss-0.0678, acc-0.9800, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9317\n",
      "Iter-77010, train loss-0.2589, acc-0.9200, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9318\n",
      "Iter-77020, train loss-0.1732, acc-0.9400, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9318\n",
      "Iter-77030, train loss-0.3057, acc-0.8800, valid loss-0.2379, acc-0.9318, test loss-0.2480, acc-0.9319\n",
      "Iter-77040, train loss-0.2142, acc-0.9200, valid loss-0.2379, acc-0.9316, test loss-0.2480, acc-0.9320\n",
      "Iter-77050, train loss-0.5010, acc-0.8400, valid loss-0.2379, acc-0.9316, test loss-0.2479, acc-0.9318\n",
      "Iter-77060, train loss-0.2578, acc-0.8800, valid loss-0.2380, acc-0.9318, test loss-0.2480, acc-0.9319\n",
      "Iter-77070, train loss-0.2317, acc-0.9800, valid loss-0.2379, acc-0.9320, test loss-0.2479, acc-0.9318\n",
      "Iter-77080, train loss-0.1962, acc-0.9800, valid loss-0.2380, acc-0.9320, test loss-0.2479, acc-0.9319\n",
      "Iter-77090, train loss-0.2550, acc-0.9200, valid loss-0.2380, acc-0.9318, test loss-0.2479, acc-0.9321\n",
      "Iter-77100, train loss-0.1833, acc-0.9600, valid loss-0.2379, acc-0.9318, test loss-0.2479, acc-0.9319\n",
      "Iter-77110, train loss-0.3447, acc-0.9200, valid loss-0.2379, acc-0.9318, test loss-0.2479, acc-0.9316\n",
      "Iter-77120, train loss-0.1445, acc-0.9600, valid loss-0.2379, acc-0.9316, test loss-0.2479, acc-0.9318\n",
      "Iter-77130, train loss-0.3812, acc-0.8600, valid loss-0.2379, acc-0.9316, test loss-0.2479, acc-0.9319\n",
      "Iter-77140, train loss-0.2200, acc-0.9200, valid loss-0.2378, acc-0.9318, test loss-0.2479, acc-0.9318\n",
      "Iter-77150, train loss-0.1307, acc-0.9400, valid loss-0.2377, acc-0.9320, test loss-0.2479, acc-0.9321\n",
      "Iter-77160, train loss-0.1907, acc-0.9600, valid loss-0.2377, acc-0.9324, test loss-0.2479, acc-0.9318\n",
      "Iter-77170, train loss-0.3044, acc-0.9200, valid loss-0.2376, acc-0.9328, test loss-0.2479, acc-0.9316\n",
      "Iter-77180, train loss-0.2155, acc-0.9400, valid loss-0.2376, acc-0.9328, test loss-0.2479, acc-0.9317\n",
      "Iter-77190, train loss-0.1878, acc-0.9000, valid loss-0.2376, acc-0.9328, test loss-0.2479, acc-0.9318\n",
      "Iter-77200, train loss-0.3162, acc-0.8800, valid loss-0.2375, acc-0.9326, test loss-0.2479, acc-0.9316\n",
      "Iter-77210, train loss-0.2041, acc-0.9600, valid loss-0.2375, acc-0.9326, test loss-0.2479, acc-0.9317\n",
      "Iter-77220, train loss-0.4274, acc-0.9000, valid loss-0.2375, acc-0.9326, test loss-0.2479, acc-0.9316\n",
      "Iter-77230, train loss-0.2979, acc-0.9200, valid loss-0.2375, acc-0.9326, test loss-0.2479, acc-0.9314\n",
      "Iter-77240, train loss-0.0858, acc-0.9800, valid loss-0.2375, acc-0.9326, test loss-0.2478, acc-0.9314\n",
      "Iter-77250, train loss-0.2804, acc-0.9400, valid loss-0.2375, acc-0.9326, test loss-0.2478, acc-0.9313\n",
      "Iter-77260, train loss-0.1485, acc-0.9400, valid loss-0.2376, acc-0.9322, test loss-0.2477, acc-0.9315\n",
      "Iter-77270, train loss-0.1021, acc-0.9800, valid loss-0.2376, acc-0.9320, test loss-0.2477, acc-0.9315\n",
      "Iter-77280, train loss-0.1707, acc-0.9400, valid loss-0.2376, acc-0.9328, test loss-0.2477, acc-0.9315\n",
      "Iter-77290, train loss-0.2099, acc-0.9400, valid loss-0.2375, acc-0.9322, test loss-0.2477, acc-0.9316\n",
      "Iter-77300, train loss-0.2803, acc-0.9400, valid loss-0.2375, acc-0.9324, test loss-0.2477, acc-0.9314\n",
      "Iter-77310, train loss-0.4927, acc-0.8400, valid loss-0.2375, acc-0.9322, test loss-0.2477, acc-0.9315\n",
      "Iter-77320, train loss-0.2181, acc-0.9400, valid loss-0.2375, acc-0.9322, test loss-0.2476, acc-0.9318\n",
      "Iter-77330, train loss-0.2830, acc-0.9000, valid loss-0.2375, acc-0.9324, test loss-0.2477, acc-0.9315\n",
      "Iter-77340, train loss-0.3042, acc-0.9200, valid loss-0.2374, acc-0.9322, test loss-0.2477, acc-0.9314\n",
      "Iter-77350, train loss-0.4196, acc-0.8800, valid loss-0.2374, acc-0.9322, test loss-0.2477, acc-0.9315\n",
      "Iter-77360, train loss-0.2403, acc-0.9600, valid loss-0.2375, acc-0.9322, test loss-0.2477, acc-0.9320\n",
      "Iter-77370, train loss-0.1948, acc-0.9200, valid loss-0.2375, acc-0.9322, test loss-0.2476, acc-0.9319\n",
      "Iter-77380, train loss-0.2281, acc-0.9400, valid loss-0.2376, acc-0.9320, test loss-0.2476, acc-0.9318\n",
      "Iter-77390, train loss-0.1804, acc-0.9400, valid loss-0.2376, acc-0.9322, test loss-0.2476, acc-0.9316\n",
      "Iter-77400, train loss-0.3535, acc-0.8800, valid loss-0.2376, acc-0.9324, test loss-0.2476, acc-0.9315\n",
      "Iter-77410, train loss-0.1667, acc-0.9600, valid loss-0.2376, acc-0.9326, test loss-0.2476, acc-0.9316\n",
      "Iter-77420, train loss-0.2691, acc-0.9400, valid loss-0.2375, acc-0.9326, test loss-0.2476, acc-0.9313\n",
      "Iter-77430, train loss-0.2730, acc-0.9000, valid loss-0.2375, acc-0.9324, test loss-0.2477, acc-0.9316\n",
      "Iter-77440, train loss-0.2254, acc-0.9200, valid loss-0.2376, acc-0.9324, test loss-0.2476, acc-0.9319\n",
      "Iter-77450, train loss-0.0772, acc-1.0000, valid loss-0.2375, acc-0.9326, test loss-0.2476, acc-0.9315\n",
      "Iter-77460, train loss-0.2012, acc-0.9600, valid loss-0.2376, acc-0.9324, test loss-0.2476, acc-0.9315\n",
      "Iter-77470, train loss-0.4098, acc-0.9000, valid loss-0.2375, acc-0.9326, test loss-0.2475, acc-0.9314\n",
      "Iter-77480, train loss-0.3740, acc-0.9000, valid loss-0.2375, acc-0.9326, test loss-0.2476, acc-0.9315\n",
      "Iter-77490, train loss-0.2255, acc-0.8800, valid loss-0.2376, acc-0.9324, test loss-0.2476, acc-0.9314\n",
      "Iter-77500, train loss-0.2432, acc-0.9400, valid loss-0.2375, acc-0.9324, test loss-0.2476, acc-0.9316\n",
      "Iter-77510, train loss-0.1948, acc-0.9400, valid loss-0.2375, acc-0.9324, test loss-0.2475, acc-0.9316\n",
      "Iter-77520, train loss-0.1394, acc-0.9800, valid loss-0.2375, acc-0.9322, test loss-0.2475, acc-0.9315\n",
      "Iter-77530, train loss-0.1473, acc-0.9800, valid loss-0.2375, acc-0.9320, test loss-0.2475, acc-0.9316\n",
      "Iter-77540, train loss-0.3939, acc-0.9200, valid loss-0.2376, acc-0.9322, test loss-0.2476, acc-0.9314\n",
      "Iter-77550, train loss-0.1992, acc-0.9400, valid loss-0.2375, acc-0.9320, test loss-0.2476, acc-0.9314\n",
      "Iter-77560, train loss-0.7189, acc-0.8000, valid loss-0.2374, acc-0.9322, test loss-0.2476, acc-0.9314\n",
      "Iter-77570, train loss-0.3456, acc-0.9000, valid loss-0.2374, acc-0.9322, test loss-0.2475, acc-0.9315\n",
      "Iter-77580, train loss-0.4571, acc-0.9000, valid loss-0.2374, acc-0.9322, test loss-0.2475, acc-0.9317\n",
      "Iter-77590, train loss-0.1549, acc-0.9600, valid loss-0.2373, acc-0.9320, test loss-0.2475, acc-0.9313\n",
      "Iter-77600, train loss-0.1762, acc-0.9400, valid loss-0.2373, acc-0.9318, test loss-0.2475, acc-0.9316\n",
      "Iter-77610, train loss-0.3078, acc-0.9000, valid loss-0.2373, acc-0.9318, test loss-0.2474, acc-0.9315\n",
      "Iter-77620, train loss-0.1534, acc-0.9800, valid loss-0.2373, acc-0.9318, test loss-0.2474, acc-0.9315\n",
      "Iter-77630, train loss-0.1453, acc-0.9600, valid loss-0.2373, acc-0.9320, test loss-0.2474, acc-0.9314\n",
      "Iter-77640, train loss-0.1614, acc-0.9400, valid loss-0.2373, acc-0.9320, test loss-0.2474, acc-0.9313\n",
      "Iter-77650, train loss-0.2503, acc-0.9400, valid loss-0.2372, acc-0.9320, test loss-0.2474, acc-0.9313\n",
      "Iter-77660, train loss-0.2406, acc-0.9000, valid loss-0.2373, acc-0.9318, test loss-0.2474, acc-0.9316\n",
      "Iter-77670, train loss-0.2106, acc-0.9200, valid loss-0.2373, acc-0.9320, test loss-0.2473, acc-0.9317\n",
      "Iter-77680, train loss-0.3015, acc-0.9400, valid loss-0.2372, acc-0.9322, test loss-0.2474, acc-0.9319\n",
      "Iter-77690, train loss-0.1524, acc-0.9600, valid loss-0.2372, acc-0.9320, test loss-0.2474, acc-0.9318\n",
      "Iter-77700, train loss-0.2038, acc-0.9600, valid loss-0.2372, acc-0.9324, test loss-0.2474, acc-0.9317\n",
      "Iter-77710, train loss-0.0992, acc-1.0000, valid loss-0.2371, acc-0.9324, test loss-0.2474, acc-0.9317\n",
      "Iter-77720, train loss-0.2170, acc-0.9600, valid loss-0.2371, acc-0.9324, test loss-0.2473, acc-0.9315\n",
      "Iter-77730, train loss-0.3561, acc-0.9000, valid loss-0.2371, acc-0.9326, test loss-0.2473, acc-0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-77740, train loss-0.2986, acc-0.9000, valid loss-0.2371, acc-0.9326, test loss-0.2473, acc-0.9317\n",
      "Iter-77750, train loss-0.2567, acc-0.9200, valid loss-0.2370, acc-0.9326, test loss-0.2473, acc-0.9317\n",
      "Iter-77760, train loss-0.2008, acc-0.9200, valid loss-0.2369, acc-0.9328, test loss-0.2473, acc-0.9316\n",
      "Iter-77770, train loss-0.4453, acc-0.8600, valid loss-0.2369, acc-0.9326, test loss-0.2472, acc-0.9318\n",
      "Iter-77780, train loss-0.3437, acc-0.8400, valid loss-0.2370, acc-0.9328, test loss-0.2472, acc-0.9319\n",
      "Iter-77790, train loss-0.1792, acc-0.9600, valid loss-0.2370, acc-0.9322, test loss-0.2472, acc-0.9318\n",
      "Iter-77800, train loss-0.1381, acc-0.9600, valid loss-0.2368, acc-0.9326, test loss-0.2472, acc-0.9317\n",
      "Iter-77810, train loss-0.2185, acc-0.8800, valid loss-0.2368, acc-0.9328, test loss-0.2472, acc-0.9318\n",
      "Iter-77820, train loss-0.2608, acc-0.9400, valid loss-0.2368, acc-0.9330, test loss-0.2473, acc-0.9317\n",
      "Iter-77830, train loss-0.3141, acc-0.9000, valid loss-0.2367, acc-0.9328, test loss-0.2472, acc-0.9316\n",
      "Iter-77840, train loss-0.2077, acc-0.9600, valid loss-0.2368, acc-0.9328, test loss-0.2472, acc-0.9316\n",
      "Iter-77850, train loss-0.2991, acc-0.9000, valid loss-0.2368, acc-0.9330, test loss-0.2472, acc-0.9315\n",
      "Iter-77860, train loss-0.2974, acc-0.8800, valid loss-0.2368, acc-0.9332, test loss-0.2471, acc-0.9316\n",
      "Iter-77870, train loss-0.3413, acc-0.9200, valid loss-0.2368, acc-0.9330, test loss-0.2472, acc-0.9317\n",
      "Iter-77880, train loss-0.2951, acc-0.9200, valid loss-0.2369, acc-0.9328, test loss-0.2472, acc-0.9317\n",
      "Iter-77890, train loss-0.3468, acc-0.8800, valid loss-0.2368, acc-0.9330, test loss-0.2471, acc-0.9317\n",
      "Iter-77900, train loss-0.2217, acc-0.9200, valid loss-0.2368, acc-0.9330, test loss-0.2471, acc-0.9316\n",
      "Iter-77910, train loss-0.1359, acc-0.9800, valid loss-0.2368, acc-0.9328, test loss-0.2471, acc-0.9316\n",
      "Iter-77920, train loss-0.2579, acc-0.9000, valid loss-0.2368, acc-0.9326, test loss-0.2471, acc-0.9315\n",
      "Iter-77930, train loss-0.1216, acc-1.0000, valid loss-0.2369, acc-0.9326, test loss-0.2471, acc-0.9316\n",
      "Iter-77940, train loss-0.2519, acc-0.9200, valid loss-0.2368, acc-0.9332, test loss-0.2471, acc-0.9316\n",
      "Iter-77950, train loss-0.2248, acc-0.9600, valid loss-0.2368, acc-0.9328, test loss-0.2471, acc-0.9317\n",
      "Iter-77960, train loss-0.2878, acc-0.9600, valid loss-0.2368, acc-0.9328, test loss-0.2471, acc-0.9320\n",
      "Iter-77970, train loss-0.0746, acc-0.9800, valid loss-0.2368, acc-0.9326, test loss-0.2471, acc-0.9318\n",
      "Iter-77980, train loss-0.2327, acc-0.9600, valid loss-0.2367, acc-0.9326, test loss-0.2471, acc-0.9315\n",
      "Iter-77990, train loss-0.2929, acc-0.9600, valid loss-0.2367, acc-0.9332, test loss-0.2470, acc-0.9316\n",
      "Iter-78000, train loss-0.1148, acc-0.9600, valid loss-0.2367, acc-0.9330, test loss-0.2470, acc-0.9317\n",
      "Iter-78010, train loss-0.3950, acc-0.8600, valid loss-0.2366, acc-0.9328, test loss-0.2470, acc-0.9315\n",
      "Iter-78020, train loss-0.4331, acc-0.8600, valid loss-0.2367, acc-0.9330, test loss-0.2470, acc-0.9316\n",
      "Iter-78030, train loss-0.1748, acc-0.9200, valid loss-0.2366, acc-0.9330, test loss-0.2470, acc-0.9315\n",
      "Iter-78040, train loss-0.3646, acc-0.9400, valid loss-0.2366, acc-0.9330, test loss-0.2470, acc-0.9317\n",
      "Iter-78050, train loss-0.2825, acc-0.9000, valid loss-0.2365, acc-0.9332, test loss-0.2469, acc-0.9317\n",
      "Iter-78060, train loss-0.4040, acc-0.8800, valid loss-0.2365, acc-0.9332, test loss-0.2469, acc-0.9318\n",
      "Iter-78070, train loss-0.0986, acc-1.0000, valid loss-0.2365, acc-0.9332, test loss-0.2468, acc-0.9318\n",
      "Iter-78080, train loss-0.2573, acc-0.9400, valid loss-0.2365, acc-0.9328, test loss-0.2469, acc-0.9318\n",
      "Iter-78090, train loss-0.4109, acc-0.8800, valid loss-0.2366, acc-0.9324, test loss-0.2468, acc-0.9317\n",
      "Iter-78100, train loss-0.1867, acc-0.9200, valid loss-0.2366, acc-0.9324, test loss-0.2468, acc-0.9316\n",
      "Iter-78110, train loss-0.1820, acc-0.9600, valid loss-0.2366, acc-0.9322, test loss-0.2468, acc-0.9316\n",
      "Iter-78120, train loss-0.2733, acc-0.9600, valid loss-0.2365, acc-0.9320, test loss-0.2468, acc-0.9316\n",
      "Iter-78130, train loss-0.0695, acc-1.0000, valid loss-0.2364, acc-0.9324, test loss-0.2468, acc-0.9314\n",
      "Iter-78140, train loss-0.2951, acc-0.9200, valid loss-0.2365, acc-0.9322, test loss-0.2468, acc-0.9319\n",
      "Iter-78150, train loss-0.2046, acc-0.9400, valid loss-0.2365, acc-0.9322, test loss-0.2468, acc-0.9319\n",
      "Iter-78160, train loss-0.2283, acc-0.9200, valid loss-0.2365, acc-0.9324, test loss-0.2468, acc-0.9317\n",
      "Iter-78170, train loss-0.2266, acc-0.9200, valid loss-0.2365, acc-0.9326, test loss-0.2468, acc-0.9320\n",
      "Iter-78180, train loss-0.1170, acc-0.9800, valid loss-0.2365, acc-0.9324, test loss-0.2468, acc-0.9320\n",
      "Iter-78190, train loss-0.1393, acc-0.9600, valid loss-0.2365, acc-0.9326, test loss-0.2467, acc-0.9319\n",
      "Iter-78200, train loss-0.2176, acc-0.9400, valid loss-0.2364, acc-0.9324, test loss-0.2467, acc-0.9320\n",
      "Iter-78210, train loss-0.1992, acc-0.9600, valid loss-0.2364, acc-0.9326, test loss-0.2467, acc-0.9320\n",
      "Iter-78220, train loss-0.4118, acc-0.8800, valid loss-0.2364, acc-0.9326, test loss-0.2467, acc-0.9319\n",
      "Iter-78230, train loss-0.3287, acc-0.9200, valid loss-0.2364, acc-0.9326, test loss-0.2467, acc-0.9319\n",
      "Iter-78240, train loss-0.2511, acc-0.9200, valid loss-0.2364, acc-0.9324, test loss-0.2467, acc-0.9319\n",
      "Iter-78250, train loss-0.5222, acc-0.8600, valid loss-0.2364, acc-0.9324, test loss-0.2466, acc-0.9317\n",
      "Iter-78260, train loss-0.5534, acc-0.8600, valid loss-0.2364, acc-0.9324, test loss-0.2467, acc-0.9316\n",
      "Iter-78270, train loss-0.1829, acc-0.9200, valid loss-0.2364, acc-0.9324, test loss-0.2467, acc-0.9317\n",
      "Iter-78280, train loss-0.1176, acc-0.9800, valid loss-0.2364, acc-0.9322, test loss-0.2466, acc-0.9317\n",
      "Iter-78290, train loss-0.1920, acc-0.9400, valid loss-0.2363, acc-0.9322, test loss-0.2466, acc-0.9316\n",
      "Iter-78300, train loss-0.2970, acc-0.9000, valid loss-0.2363, acc-0.9326, test loss-0.2466, acc-0.9315\n",
      "Iter-78310, train loss-0.2743, acc-0.9200, valid loss-0.2362, acc-0.9328, test loss-0.2466, acc-0.9316\n",
      "Iter-78320, train loss-0.1898, acc-0.9600, valid loss-0.2362, acc-0.9326, test loss-0.2465, acc-0.9316\n",
      "Iter-78330, train loss-0.3121, acc-0.8800, valid loss-0.2363, acc-0.9326, test loss-0.2465, acc-0.9316\n",
      "Iter-78340, train loss-0.2858, acc-0.9200, valid loss-0.2363, acc-0.9328, test loss-0.2465, acc-0.9314\n",
      "Iter-78350, train loss-0.1325, acc-0.9200, valid loss-0.2362, acc-0.9328, test loss-0.2465, acc-0.9315\n",
      "Iter-78360, train loss-0.2687, acc-0.9200, valid loss-0.2362, acc-0.9332, test loss-0.2465, acc-0.9314\n",
      "Iter-78370, train loss-0.1764, acc-0.9800, valid loss-0.2361, acc-0.9332, test loss-0.2465, acc-0.9314\n",
      "Iter-78380, train loss-0.2401, acc-0.9400, valid loss-0.2362, acc-0.9330, test loss-0.2465, acc-0.9311\n",
      "Iter-78390, train loss-0.2062, acc-0.9200, valid loss-0.2361, acc-0.9328, test loss-0.2465, acc-0.9309\n",
      "Iter-78400, train loss-0.1821, acc-0.9400, valid loss-0.2361, acc-0.9328, test loss-0.2464, acc-0.9310\n",
      "Iter-78410, train loss-0.1743, acc-0.9400, valid loss-0.2360, acc-0.9330, test loss-0.2464, acc-0.9313\n",
      "Iter-78420, train loss-0.4454, acc-0.9000, valid loss-0.2360, acc-0.9330, test loss-0.2464, acc-0.9311\n",
      "Iter-78430, train loss-0.3242, acc-0.8800, valid loss-0.2360, acc-0.9328, test loss-0.2464, acc-0.9310\n",
      "Iter-78440, train loss-0.2267, acc-0.9600, valid loss-0.2360, acc-0.9328, test loss-0.2464, acc-0.9310\n",
      "Iter-78450, train loss-0.2035, acc-0.9400, valid loss-0.2360, acc-0.9328, test loss-0.2464, acc-0.9308\n",
      "Iter-78460, train loss-0.1777, acc-0.9600, valid loss-0.2360, acc-0.9326, test loss-0.2464, acc-0.9311\n",
      "Iter-78470, train loss-0.2488, acc-0.9600, valid loss-0.2359, acc-0.9330, test loss-0.2464, acc-0.9310\n",
      "Iter-78480, train loss-0.0767, acc-1.0000, valid loss-0.2359, acc-0.9332, test loss-0.2464, acc-0.9313\n",
      "Iter-78490, train loss-0.2698, acc-0.9200, valid loss-0.2359, acc-0.9336, test loss-0.2464, acc-0.9313\n",
      "Iter-78500, train loss-0.2880, acc-0.9400, valid loss-0.2359, acc-0.9334, test loss-0.2464, acc-0.9312\n",
      "Iter-78510, train loss-0.1679, acc-0.9600, valid loss-0.2359, acc-0.9332, test loss-0.2465, acc-0.9313\n",
      "Iter-78520, train loss-0.2979, acc-0.8800, valid loss-0.2359, acc-0.9330, test loss-0.2464, acc-0.9314\n",
      "Iter-78530, train loss-0.1650, acc-0.9600, valid loss-0.2359, acc-0.9330, test loss-0.2464, acc-0.9313\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-78540, train loss-0.2084, acc-0.9400, valid loss-0.2359, acc-0.9330, test loss-0.2463, acc-0.9314\n",
      "Iter-78550, train loss-0.4598, acc-0.9000, valid loss-0.2360, acc-0.9328, test loss-0.2464, acc-0.9314\n",
      "Iter-78560, train loss-0.2431, acc-0.9400, valid loss-0.2360, acc-0.9332, test loss-0.2464, acc-0.9314\n",
      "Iter-78570, train loss-0.1909, acc-0.9200, valid loss-0.2360, acc-0.9328, test loss-0.2464, acc-0.9314\n",
      "Iter-78580, train loss-0.1751, acc-0.9400, valid loss-0.2360, acc-0.9330, test loss-0.2464, acc-0.9311\n",
      "Iter-78590, train loss-0.1352, acc-0.9600, valid loss-0.2359, acc-0.9334, test loss-0.2464, acc-0.9313\n",
      "Iter-78600, train loss-0.1801, acc-0.9200, valid loss-0.2360, acc-0.9330, test loss-0.2464, acc-0.9313\n",
      "Iter-78610, train loss-0.3118, acc-0.9000, valid loss-0.2359, acc-0.9332, test loss-0.2463, acc-0.9315\n",
      "Iter-78620, train loss-0.2380, acc-0.9600, valid loss-0.2360, acc-0.9330, test loss-0.2463, acc-0.9312\n",
      "Iter-78630, train loss-0.1356, acc-0.9800, valid loss-0.2360, acc-0.9328, test loss-0.2463, acc-0.9312\n",
      "Iter-78640, train loss-0.4038, acc-0.8800, valid loss-0.2359, acc-0.9332, test loss-0.2463, acc-0.9312\n",
      "Iter-78650, train loss-0.1480, acc-0.9600, valid loss-0.2359, acc-0.9330, test loss-0.2463, acc-0.9313\n",
      "Iter-78660, train loss-0.1972, acc-0.9400, valid loss-0.2360, acc-0.9328, test loss-0.2463, acc-0.9314\n",
      "Iter-78670, train loss-0.2321, acc-0.9400, valid loss-0.2360, acc-0.9328, test loss-0.2463, acc-0.9316\n",
      "Iter-78680, train loss-0.1707, acc-0.9600, valid loss-0.2359, acc-0.9326, test loss-0.2463, acc-0.9315\n",
      "Iter-78690, train loss-0.2550, acc-0.9000, valid loss-0.2359, acc-0.9326, test loss-0.2462, acc-0.9316\n",
      "Iter-78700, train loss-0.1895, acc-0.9400, valid loss-0.2358, acc-0.9328, test loss-0.2462, acc-0.9315\n",
      "Iter-78710, train loss-0.3198, acc-0.9200, valid loss-0.2358, acc-0.9330, test loss-0.2462, acc-0.9315\n",
      "Iter-78720, train loss-0.2293, acc-0.9000, valid loss-0.2358, acc-0.9326, test loss-0.2461, acc-0.9318\n",
      "Iter-78730, train loss-0.2318, acc-0.9200, valid loss-0.2357, acc-0.9326, test loss-0.2461, acc-0.9315\n",
      "Iter-78740, train loss-0.2283, acc-0.9600, valid loss-0.2357, acc-0.9324, test loss-0.2461, acc-0.9315\n",
      "Iter-78750, train loss-0.1634, acc-0.9800, valid loss-0.2358, acc-0.9322, test loss-0.2461, acc-0.9312\n",
      "Iter-78760, train loss-0.5386, acc-0.8000, valid loss-0.2357, acc-0.9322, test loss-0.2461, acc-0.9310\n",
      "Iter-78770, train loss-0.2108, acc-0.9600, valid loss-0.2357, acc-0.9320, test loss-0.2461, acc-0.9313\n",
      "Iter-78780, train loss-0.1797, acc-0.9600, valid loss-0.2357, acc-0.9320, test loss-0.2461, acc-0.9313\n",
      "Iter-78790, train loss-0.3883, acc-0.8600, valid loss-0.2357, acc-0.9324, test loss-0.2461, acc-0.9315\n",
      "Iter-78800, train loss-0.2333, acc-0.9400, valid loss-0.2357, acc-0.9324, test loss-0.2461, acc-0.9315\n",
      "Iter-78810, train loss-0.3946, acc-0.9000, valid loss-0.2357, acc-0.9324, test loss-0.2461, acc-0.9315\n",
      "Iter-78820, train loss-0.1166, acc-0.9600, valid loss-0.2357, acc-0.9324, test loss-0.2461, acc-0.9316\n",
      "Iter-78830, train loss-0.2817, acc-0.9200, valid loss-0.2357, acc-0.9326, test loss-0.2460, acc-0.9316\n",
      "Iter-78840, train loss-0.2271, acc-0.9200, valid loss-0.2357, acc-0.9322, test loss-0.2461, acc-0.9316\n",
      "Iter-78850, train loss-0.2485, acc-0.9400, valid loss-0.2357, acc-0.9322, test loss-0.2460, acc-0.9317\n",
      "Iter-78860, train loss-0.1920, acc-0.9800, valid loss-0.2356, acc-0.9318, test loss-0.2460, acc-0.9316\n",
      "Iter-78870, train loss-0.2776, acc-0.8600, valid loss-0.2356, acc-0.9320, test loss-0.2460, acc-0.9318\n",
      "Iter-78880, train loss-0.1787, acc-0.9400, valid loss-0.2356, acc-0.9316, test loss-0.2460, acc-0.9317\n",
      "Iter-78890, train loss-0.1809, acc-0.9600, valid loss-0.2356, acc-0.9316, test loss-0.2459, acc-0.9317\n",
      "Iter-78900, train loss-0.3490, acc-0.9200, valid loss-0.2356, acc-0.9318, test loss-0.2459, acc-0.9317\n",
      "Iter-78910, train loss-0.2463, acc-0.9200, valid loss-0.2355, acc-0.9324, test loss-0.2459, acc-0.9316\n",
      "Iter-78920, train loss-0.1440, acc-0.9600, valid loss-0.2355, acc-0.9322, test loss-0.2459, acc-0.9316\n",
      "Iter-78930, train loss-0.0857, acc-0.9800, valid loss-0.2354, acc-0.9324, test loss-0.2459, acc-0.9316\n",
      "Iter-78940, train loss-0.2270, acc-0.9600, valid loss-0.2355, acc-0.9326, test loss-0.2459, acc-0.9316\n",
      "Iter-78950, train loss-0.1628, acc-0.9600, valid loss-0.2355, acc-0.9326, test loss-0.2459, acc-0.9317\n",
      "Iter-78960, train loss-0.1385, acc-0.9600, valid loss-0.2354, acc-0.9328, test loss-0.2459, acc-0.9316\n",
      "Iter-78970, train loss-0.3050, acc-0.9000, valid loss-0.2354, acc-0.9330, test loss-0.2458, acc-0.9314\n",
      "Iter-78980, train loss-0.4186, acc-0.8400, valid loss-0.2354, acc-0.9330, test loss-0.2458, acc-0.9312\n",
      "Iter-78990, train loss-0.3862, acc-0.9400, valid loss-0.2355, acc-0.9326, test loss-0.2458, acc-0.9314\n",
      "Iter-79000, train loss-0.2661, acc-0.9600, valid loss-0.2355, acc-0.9326, test loss-0.2458, acc-0.9315\n",
      "Iter-79010, train loss-0.1319, acc-0.9600, valid loss-0.2354, acc-0.9324, test loss-0.2457, acc-0.9311\n",
      "Iter-79020, train loss-0.3168, acc-0.9600, valid loss-0.2355, acc-0.9322, test loss-0.2457, acc-0.9313\n",
      "Iter-79030, train loss-0.2450, acc-0.9400, valid loss-0.2355, acc-0.9322, test loss-0.2457, acc-0.9313\n",
      "Iter-79040, train loss-0.3032, acc-0.9200, valid loss-0.2355, acc-0.9324, test loss-0.2457, acc-0.9314\n",
      "Iter-79050, train loss-0.3204, acc-0.9200, valid loss-0.2354, acc-0.9324, test loss-0.2457, acc-0.9314\n",
      "Iter-79060, train loss-0.2977, acc-0.9200, valid loss-0.2354, acc-0.9330, test loss-0.2456, acc-0.9316\n",
      "Iter-79070, train loss-0.2936, acc-0.9200, valid loss-0.2354, acc-0.9328, test loss-0.2456, acc-0.9316\n",
      "Iter-79080, train loss-0.2644, acc-0.9200, valid loss-0.2354, acc-0.9328, test loss-0.2456, acc-0.9315\n",
      "Iter-79090, train loss-0.5285, acc-0.8400, valid loss-0.2354, acc-0.9326, test loss-0.2456, acc-0.9315\n",
      "Iter-79100, train loss-0.4774, acc-0.9000, valid loss-0.2354, acc-0.9326, test loss-0.2455, acc-0.9316\n",
      "Iter-79110, train loss-0.1001, acc-1.0000, valid loss-0.2354, acc-0.9324, test loss-0.2455, acc-0.9314\n",
      "Iter-79120, train loss-0.3060, acc-0.9400, valid loss-0.2354, acc-0.9330, test loss-0.2455, acc-0.9314\n",
      "Iter-79130, train loss-0.2124, acc-0.9400, valid loss-0.2354, acc-0.9326, test loss-0.2455, acc-0.9314\n",
      "Iter-79140, train loss-0.4013, acc-0.9000, valid loss-0.2353, acc-0.9328, test loss-0.2455, acc-0.9315\n",
      "Iter-79150, train loss-0.1039, acc-0.9800, valid loss-0.2354, acc-0.9326, test loss-0.2455, acc-0.9316\n",
      "Iter-79160, train loss-0.2115, acc-0.9400, valid loss-0.2353, acc-0.9328, test loss-0.2455, acc-0.9314\n",
      "Iter-79170, train loss-0.1022, acc-0.9800, valid loss-0.2353, acc-0.9326, test loss-0.2455, acc-0.9316\n",
      "Iter-79180, train loss-0.1866, acc-0.9400, valid loss-0.2352, acc-0.9328, test loss-0.2454, acc-0.9314\n",
      "Iter-79190, train loss-0.2902, acc-0.9200, valid loss-0.2352, acc-0.9330, test loss-0.2455, acc-0.9315\n",
      "Iter-79200, train loss-0.3330, acc-0.9000, valid loss-0.2352, acc-0.9328, test loss-0.2455, acc-0.9316\n",
      "Iter-79210, train loss-0.2187, acc-0.9200, valid loss-0.2351, acc-0.9330, test loss-0.2455, acc-0.9315\n",
      "Iter-79220, train loss-0.2975, acc-0.9400, valid loss-0.2351, acc-0.9330, test loss-0.2455, acc-0.9315\n",
      "Iter-79230, train loss-0.3482, acc-0.9000, valid loss-0.2351, acc-0.9330, test loss-0.2455, acc-0.9314\n",
      "Iter-79240, train loss-0.6729, acc-0.8400, valid loss-0.2351, acc-0.9330, test loss-0.2455, acc-0.9315\n",
      "Iter-79250, train loss-0.1837, acc-0.9400, valid loss-0.2350, acc-0.9332, test loss-0.2455, acc-0.9316\n",
      "Iter-79260, train loss-0.2413, acc-0.9400, valid loss-0.2350, acc-0.9332, test loss-0.2454, acc-0.9315\n",
      "Iter-79270, train loss-0.2009, acc-0.9600, valid loss-0.2350, acc-0.9332, test loss-0.2454, acc-0.9316\n",
      "Iter-79280, train loss-0.1596, acc-0.9400, valid loss-0.2349, acc-0.9324, test loss-0.2455, acc-0.9314\n",
      "Iter-79290, train loss-0.2081, acc-0.9400, valid loss-0.2349, acc-0.9330, test loss-0.2455, acc-0.9314\n",
      "Iter-79300, train loss-0.0923, acc-0.9800, valid loss-0.2348, acc-0.9330, test loss-0.2455, acc-0.9311\n",
      "Iter-79310, train loss-0.3194, acc-0.9000, valid loss-0.2348, acc-0.9328, test loss-0.2454, acc-0.9313\n",
      "Iter-79320, train loss-0.2157, acc-0.9400, valid loss-0.2348, acc-0.9328, test loss-0.2454, acc-0.9312\n",
      "Iter-79330, train loss-0.1044, acc-0.9800, valid loss-0.2348, acc-0.9324, test loss-0.2454, acc-0.9312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-79340, train loss-0.1347, acc-0.9600, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9311\n",
      "Iter-79350, train loss-0.2760, acc-0.9400, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9311\n",
      "Iter-79360, train loss-0.1010, acc-0.9600, valid loss-0.2347, acc-0.9330, test loss-0.2454, acc-0.9312\n",
      "Iter-79370, train loss-0.2292, acc-0.9200, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9312\n",
      "Iter-79380, train loss-0.3685, acc-0.8800, valid loss-0.2346, acc-0.9330, test loss-0.2454, acc-0.9312\n",
      "Iter-79390, train loss-0.1437, acc-0.9600, valid loss-0.2347, acc-0.9330, test loss-0.2454, acc-0.9312\n",
      "Iter-79400, train loss-0.2470, acc-0.9200, valid loss-0.2347, acc-0.9328, test loss-0.2455, acc-0.9313\n",
      "Iter-79410, train loss-0.1696, acc-0.9400, valid loss-0.2347, acc-0.9326, test loss-0.2454, acc-0.9313\n",
      "Iter-79420, train loss-0.4634, acc-0.8600, valid loss-0.2347, acc-0.9330, test loss-0.2454, acc-0.9312\n",
      "Iter-79430, train loss-0.3949, acc-0.8800, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9312\n",
      "Iter-79440, train loss-0.3106, acc-0.8800, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9311\n",
      "Iter-79450, train loss-0.3395, acc-0.8800, valid loss-0.2347, acc-0.9328, test loss-0.2454, acc-0.9310\n",
      "Iter-79460, train loss-0.3641, acc-0.8800, valid loss-0.2347, acc-0.9326, test loss-0.2453, acc-0.9310\n",
      "Iter-79470, train loss-0.3424, acc-0.9600, valid loss-0.2347, acc-0.9324, test loss-0.2453, acc-0.9310\n",
      "Iter-79480, train loss-0.2785, acc-0.9400, valid loss-0.2346, acc-0.9332, test loss-0.2453, acc-0.9311\n",
      "Iter-79490, train loss-0.1866, acc-0.9400, valid loss-0.2346, acc-0.9330, test loss-0.2452, acc-0.9311\n",
      "Iter-79500, train loss-0.2856, acc-0.8600, valid loss-0.2345, acc-0.9334, test loss-0.2452, acc-0.9310\n",
      "Iter-79510, train loss-0.1766, acc-0.9600, valid loss-0.2345, acc-0.9332, test loss-0.2452, acc-0.9311\n",
      "Iter-79520, train loss-0.2956, acc-0.8800, valid loss-0.2345, acc-0.9328, test loss-0.2452, acc-0.9312\n",
      "Iter-79530, train loss-0.3526, acc-0.8600, valid loss-0.2344, acc-0.9334, test loss-0.2452, acc-0.9312\n",
      "Iter-79540, train loss-0.3203, acc-0.9000, valid loss-0.2345, acc-0.9332, test loss-0.2451, acc-0.9311\n",
      "Iter-79550, train loss-0.1071, acc-0.9800, valid loss-0.2345, acc-0.9332, test loss-0.2451, acc-0.9311\n",
      "Iter-79560, train loss-0.3738, acc-0.9000, valid loss-0.2345, acc-0.9332, test loss-0.2451, acc-0.9314\n",
      "Iter-79570, train loss-0.2204, acc-0.9000, valid loss-0.2344, acc-0.9328, test loss-0.2451, acc-0.9314\n",
      "Iter-79580, train loss-0.2893, acc-0.9400, valid loss-0.2344, acc-0.9328, test loss-0.2451, acc-0.9314\n",
      "Iter-79590, train loss-0.2118, acc-0.9400, valid loss-0.2345, acc-0.9326, test loss-0.2450, acc-0.9313\n",
      "Iter-79600, train loss-0.2360, acc-0.9600, valid loss-0.2345, acc-0.9324, test loss-0.2450, acc-0.9313\n",
      "Iter-79610, train loss-0.2875, acc-0.9200, valid loss-0.2344, acc-0.9326, test loss-0.2450, acc-0.9313\n",
      "Iter-79620, train loss-0.5022, acc-0.8400, valid loss-0.2344, acc-0.9326, test loss-0.2450, acc-0.9312\n",
      "Iter-79630, train loss-0.2966, acc-0.9400, valid loss-0.2344, acc-0.9326, test loss-0.2450, acc-0.9310\n",
      "Iter-79640, train loss-0.2553, acc-0.8800, valid loss-0.2344, acc-0.9324, test loss-0.2451, acc-0.9311\n",
      "Iter-79650, train loss-0.1068, acc-0.9600, valid loss-0.2344, acc-0.9324, test loss-0.2451, acc-0.9311\n",
      "Iter-79660, train loss-0.3369, acc-0.9000, valid loss-0.2343, acc-0.9328, test loss-0.2450, acc-0.9310\n",
      "Iter-79670, train loss-0.2928, acc-0.9200, valid loss-0.2343, acc-0.9332, test loss-0.2450, acc-0.9312\n",
      "Iter-79680, train loss-0.4042, acc-0.9000, valid loss-0.2343, acc-0.9330, test loss-0.2449, acc-0.9311\n",
      "Iter-79690, train loss-0.2321, acc-0.9200, valid loss-0.2343, acc-0.9330, test loss-0.2449, acc-0.9311\n",
      "Iter-79700, train loss-0.1418, acc-0.9800, valid loss-0.2344, acc-0.9324, test loss-0.2449, acc-0.9311\n",
      "Iter-79710, train loss-0.2250, acc-0.9200, valid loss-0.2344, acc-0.9326, test loss-0.2449, acc-0.9313\n",
      "Iter-79720, train loss-0.2771, acc-0.9400, valid loss-0.2344, acc-0.9328, test loss-0.2449, acc-0.9310\n",
      "Iter-79730, train loss-0.1447, acc-0.9600, valid loss-0.2344, acc-0.9326, test loss-0.2449, acc-0.9313\n",
      "Iter-79740, train loss-0.2378, acc-0.9200, valid loss-0.2344, acc-0.9326, test loss-0.2449, acc-0.9313\n",
      "Iter-79750, train loss-0.1144, acc-0.9800, valid loss-0.2345, acc-0.9326, test loss-0.2449, acc-0.9317\n",
      "Iter-79760, train loss-0.1320, acc-0.9800, valid loss-0.2345, acc-0.9324, test loss-0.2450, acc-0.9315\n",
      "Iter-79770, train loss-0.3384, acc-0.9000, valid loss-0.2345, acc-0.9324, test loss-0.2449, acc-0.9314\n",
      "Iter-79780, train loss-0.2632, acc-0.9200, valid loss-0.2344, acc-0.9324, test loss-0.2449, acc-0.9314\n",
      "Iter-79790, train loss-0.1079, acc-0.9800, valid loss-0.2344, acc-0.9328, test loss-0.2449, acc-0.9313\n",
      "Iter-79800, train loss-0.1587, acc-0.9600, valid loss-0.2344, acc-0.9326, test loss-0.2449, acc-0.9313\n",
      "Iter-79810, train loss-0.2995, acc-0.9000, valid loss-0.2343, acc-0.9326, test loss-0.2448, acc-0.9312\n",
      "Iter-79820, train loss-0.1619, acc-0.9600, valid loss-0.2343, acc-0.9328, test loss-0.2448, acc-0.9310\n",
      "Iter-79830, train loss-0.2621, acc-0.9000, valid loss-0.2342, acc-0.9328, test loss-0.2448, acc-0.9310\n",
      "Iter-79840, train loss-0.1878, acc-0.9600, valid loss-0.2342, acc-0.9328, test loss-0.2447, acc-0.9310\n",
      "Iter-79850, train loss-0.1668, acc-0.9600, valid loss-0.2341, acc-0.9330, test loss-0.2447, acc-0.9313\n",
      "Iter-79860, train loss-0.1294, acc-0.9600, valid loss-0.2341, acc-0.9330, test loss-0.2447, acc-0.9313\n",
      "Iter-79870, train loss-0.2126, acc-0.9200, valid loss-0.2341, acc-0.9330, test loss-0.2447, acc-0.9309\n",
      "Iter-79880, train loss-0.1328, acc-0.9800, valid loss-0.2341, acc-0.9332, test loss-0.2447, acc-0.9311\n",
      "Iter-79890, train loss-0.2177, acc-0.9400, valid loss-0.2342, acc-0.9328, test loss-0.2447, acc-0.9313\n",
      "Iter-79900, train loss-0.2652, acc-0.9600, valid loss-0.2342, acc-0.9326, test loss-0.2447, acc-0.9312\n",
      "Iter-79910, train loss-0.2379, acc-0.9600, valid loss-0.2342, acc-0.9326, test loss-0.2447, acc-0.9310\n",
      "Iter-79920, train loss-0.1506, acc-0.9600, valid loss-0.2343, acc-0.9326, test loss-0.2446, acc-0.9310\n",
      "Iter-79930, train loss-0.4504, acc-0.9000, valid loss-0.2342, acc-0.9326, test loss-0.2446, acc-0.9310\n",
      "Iter-79940, train loss-0.3349, acc-0.9200, valid loss-0.2342, acc-0.9326, test loss-0.2446, acc-0.9312\n",
      "Iter-79950, train loss-0.1729, acc-0.9600, valid loss-0.2342, acc-0.9326, test loss-0.2446, acc-0.9311\n",
      "Iter-79960, train loss-0.1322, acc-0.9800, valid loss-0.2341, acc-0.9324, test loss-0.2445, acc-0.9310\n",
      "Iter-79970, train loss-0.2556, acc-0.9200, valid loss-0.2342, acc-0.9326, test loss-0.2445, acc-0.9311\n",
      "Iter-79980, train loss-0.1945, acc-0.9400, valid loss-0.2342, acc-0.9326, test loss-0.2445, acc-0.9309\n",
      "Iter-79990, train loss-0.2988, acc-0.9000, valid loss-0.2341, acc-0.9326, test loss-0.2445, acc-0.9310\n",
      "Iter-80000, train loss-0.1728, acc-0.9600, valid loss-0.2342, acc-0.9326, test loss-0.2445, acc-0.9313\n",
      "Iter-80010, train loss-0.3281, acc-0.9200, valid loss-0.2342, acc-0.9328, test loss-0.2444, acc-0.9314\n",
      "Iter-80020, train loss-0.3035, acc-0.9200, valid loss-0.2342, acc-0.9328, test loss-0.2445, acc-0.9311\n",
      "Iter-80030, train loss-0.1797, acc-0.9600, valid loss-0.2342, acc-0.9328, test loss-0.2444, acc-0.9314\n",
      "Iter-80040, train loss-0.2167, acc-0.9400, valid loss-0.2342, acc-0.9330, test loss-0.2444, acc-0.9312\n",
      "Iter-80050, train loss-0.2713, acc-0.9600, valid loss-0.2341, acc-0.9328, test loss-0.2444, acc-0.9314\n",
      "Iter-80060, train loss-0.0773, acc-1.0000, valid loss-0.2340, acc-0.9328, test loss-0.2444, acc-0.9314\n",
      "Iter-80070, train loss-0.2536, acc-0.9200, valid loss-0.2340, acc-0.9328, test loss-0.2443, acc-0.9311\n",
      "Iter-80080, train loss-0.2784, acc-0.9200, valid loss-0.2340, acc-0.9326, test loss-0.2443, acc-0.9313\n",
      "Iter-80090, train loss-0.1496, acc-0.9400, valid loss-0.2339, acc-0.9330, test loss-0.2443, acc-0.9313\n",
      "Iter-80100, train loss-0.2811, acc-0.9200, valid loss-0.2339, acc-0.9330, test loss-0.2443, acc-0.9315\n",
      "Iter-80110, train loss-0.5184, acc-0.8400, valid loss-0.2338, acc-0.9330, test loss-0.2443, acc-0.9316\n",
      "Iter-80120, train loss-0.2284, acc-0.9400, valid loss-0.2338, acc-0.9332, test loss-0.2442, acc-0.9314\n",
      "Iter-80130, train loss-0.4002, acc-0.8800, valid loss-0.2338, acc-0.9332, test loss-0.2443, acc-0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-80140, train loss-0.2634, acc-0.9200, valid loss-0.2338, acc-0.9332, test loss-0.2442, acc-0.9312\n",
      "Iter-80150, train loss-0.2246, acc-0.9400, valid loss-0.2338, acc-0.9332, test loss-0.2442, acc-0.9313\n",
      "Iter-80160, train loss-0.1348, acc-0.9600, valid loss-0.2338, acc-0.9334, test loss-0.2442, acc-0.9315\n",
      "Iter-80170, train loss-0.1429, acc-0.9600, valid loss-0.2338, acc-0.9334, test loss-0.2442, acc-0.9316\n",
      "Iter-80180, train loss-0.2188, acc-0.9600, valid loss-0.2338, acc-0.9334, test loss-0.2442, acc-0.9315\n",
      "Iter-80190, train loss-0.2121, acc-0.9200, valid loss-0.2337, acc-0.9332, test loss-0.2442, acc-0.9315\n",
      "Iter-80200, train loss-0.1934, acc-0.9600, valid loss-0.2337, acc-0.9332, test loss-0.2441, acc-0.9315\n",
      "Iter-80210, train loss-0.3940, acc-0.9200, valid loss-0.2336, acc-0.9330, test loss-0.2442, acc-0.9315\n",
      "Iter-80220, train loss-0.2945, acc-0.8600, valid loss-0.2337, acc-0.9332, test loss-0.2441, acc-0.9315\n",
      "Iter-80230, train loss-0.1332, acc-0.9600, valid loss-0.2337, acc-0.9332, test loss-0.2442, acc-0.9316\n",
      "Iter-80240, train loss-0.3922, acc-0.8800, valid loss-0.2337, acc-0.9332, test loss-0.2441, acc-0.9316\n",
      "Iter-80250, train loss-0.1550, acc-0.9600, valid loss-0.2336, acc-0.9330, test loss-0.2441, acc-0.9318\n",
      "Iter-80260, train loss-0.5094, acc-0.8800, valid loss-0.2336, acc-0.9330, test loss-0.2441, acc-0.9316\n",
      "Iter-80270, train loss-0.1995, acc-0.9600, valid loss-0.2336, acc-0.9330, test loss-0.2440, acc-0.9317\n",
      "Iter-80280, train loss-0.2717, acc-0.9400, valid loss-0.2336, acc-0.9326, test loss-0.2440, acc-0.9315\n",
      "Iter-80290, train loss-0.3012, acc-0.9600, valid loss-0.2336, acc-0.9326, test loss-0.2440, acc-0.9316\n",
      "Iter-80300, train loss-0.1476, acc-0.9600, valid loss-0.2336, acc-0.9326, test loss-0.2440, acc-0.9315\n",
      "Iter-80310, train loss-0.2432, acc-0.9400, valid loss-0.2335, acc-0.9324, test loss-0.2440, acc-0.9313\n",
      "Iter-80320, train loss-0.1953, acc-0.9200, valid loss-0.2335, acc-0.9324, test loss-0.2441, acc-0.9314\n",
      "Iter-80330, train loss-0.1301, acc-0.9600, valid loss-0.2334, acc-0.9324, test loss-0.2440, acc-0.9315\n",
      "Iter-80340, train loss-0.1501, acc-0.9600, valid loss-0.2334, acc-0.9326, test loss-0.2440, acc-0.9312\n",
      "Iter-80350, train loss-0.3139, acc-0.9000, valid loss-0.2334, acc-0.9330, test loss-0.2440, acc-0.9313\n",
      "Iter-80360, train loss-0.4041, acc-0.9000, valid loss-0.2334, acc-0.9326, test loss-0.2440, acc-0.9314\n",
      "Iter-80370, train loss-0.3446, acc-0.9200, valid loss-0.2334, acc-0.9324, test loss-0.2440, acc-0.9312\n",
      "Iter-80380, train loss-0.2011, acc-0.9600, valid loss-0.2334, acc-0.9328, test loss-0.2440, acc-0.9313\n",
      "Iter-80390, train loss-0.2646, acc-0.9200, valid loss-0.2333, acc-0.9326, test loss-0.2440, acc-0.9313\n",
      "Iter-80400, train loss-0.2150, acc-0.9400, valid loss-0.2333, acc-0.9326, test loss-0.2440, acc-0.9314\n",
      "Iter-80410, train loss-0.1811, acc-0.9400, valid loss-0.2333, acc-0.9326, test loss-0.2439, acc-0.9311\n",
      "Iter-80420, train loss-0.2078, acc-0.9400, valid loss-0.2333, acc-0.9326, test loss-0.2439, acc-0.9312\n",
      "Iter-80430, train loss-0.1994, acc-0.9600, valid loss-0.2334, acc-0.9326, test loss-0.2440, acc-0.9312\n",
      "Iter-80440, train loss-0.3762, acc-0.8600, valid loss-0.2334, acc-0.9328, test loss-0.2439, acc-0.9313\n",
      "Iter-80450, train loss-0.2329, acc-0.9400, valid loss-0.2334, acc-0.9326, test loss-0.2439, acc-0.9312\n",
      "Iter-80460, train loss-0.2430, acc-0.9400, valid loss-0.2334, acc-0.9326, test loss-0.2439, acc-0.9315\n",
      "Iter-80470, train loss-0.1121, acc-1.0000, valid loss-0.2333, acc-0.9330, test loss-0.2440, acc-0.9317\n",
      "Iter-80480, train loss-0.2675, acc-0.9000, valid loss-0.2333, acc-0.9328, test loss-0.2440, acc-0.9315\n",
      "Iter-80490, train loss-0.1607, acc-0.9800, valid loss-0.2333, acc-0.9332, test loss-0.2439, acc-0.9316\n",
      "Iter-80500, train loss-0.1435, acc-0.9600, valid loss-0.2333, acc-0.9332, test loss-0.2439, acc-0.9314\n",
      "Iter-80510, train loss-0.0902, acc-0.9800, valid loss-0.2333, acc-0.9328, test loss-0.2439, acc-0.9315\n",
      "Iter-80520, train loss-0.2314, acc-0.9200, valid loss-0.2332, acc-0.9326, test loss-0.2439, acc-0.9313\n",
      "Iter-80530, train loss-0.2915, acc-0.9600, valid loss-0.2332, acc-0.9324, test loss-0.2439, acc-0.9311\n",
      "Iter-80540, train loss-0.3177, acc-0.9200, valid loss-0.2332, acc-0.9326, test loss-0.2438, acc-0.9313\n",
      "Iter-80550, train loss-0.2451, acc-0.9200, valid loss-0.2332, acc-0.9326, test loss-0.2438, acc-0.9314\n",
      "Iter-80560, train loss-0.4049, acc-0.8600, valid loss-0.2332, acc-0.9326, test loss-0.2438, acc-0.9313\n",
      "Iter-80570, train loss-0.2565, acc-0.8800, valid loss-0.2332, acc-0.9328, test loss-0.2438, acc-0.9315\n",
      "Iter-80580, train loss-0.3580, acc-0.9000, valid loss-0.2332, acc-0.9330, test loss-0.2437, acc-0.9314\n",
      "Iter-80590, train loss-0.4401, acc-0.9000, valid loss-0.2332, acc-0.9328, test loss-0.2437, acc-0.9313\n",
      "Iter-80600, train loss-0.2974, acc-0.9200, valid loss-0.2331, acc-0.9330, test loss-0.2437, acc-0.9317\n",
      "Iter-80610, train loss-0.1389, acc-0.9800, valid loss-0.2331, acc-0.9326, test loss-0.2437, acc-0.9317\n",
      "Iter-80620, train loss-0.1181, acc-0.9800, valid loss-0.2331, acc-0.9324, test loss-0.2437, acc-0.9316\n",
      "Iter-80630, train loss-0.1239, acc-1.0000, valid loss-0.2331, acc-0.9324, test loss-0.2436, acc-0.9316\n",
      "Iter-80640, train loss-0.3023, acc-0.9000, valid loss-0.2330, acc-0.9326, test loss-0.2436, acc-0.9316\n",
      "Iter-80650, train loss-0.1603, acc-0.9400, valid loss-0.2330, acc-0.9328, test loss-0.2435, acc-0.9315\n",
      "Iter-80660, train loss-0.4479, acc-0.8400, valid loss-0.2330, acc-0.9326, test loss-0.2435, acc-0.9316\n",
      "Iter-80670, train loss-0.0891, acc-0.9800, valid loss-0.2330, acc-0.9330, test loss-0.2435, acc-0.9315\n",
      "Iter-80680, train loss-0.1351, acc-0.9800, valid loss-0.2330, acc-0.9328, test loss-0.2435, acc-0.9313\n",
      "Iter-80690, train loss-0.3838, acc-0.9000, valid loss-0.2330, acc-0.9326, test loss-0.2435, acc-0.9315\n",
      "Iter-80700, train loss-0.1855, acc-0.9400, valid loss-0.2330, acc-0.9328, test loss-0.2435, acc-0.9315\n",
      "Iter-80710, train loss-0.4832, acc-0.8800, valid loss-0.2329, acc-0.9328, test loss-0.2434, acc-0.9314\n",
      "Iter-80720, train loss-0.2778, acc-0.9200, valid loss-0.2329, acc-0.9328, test loss-0.2434, acc-0.9316\n",
      "Iter-80730, train loss-0.2580, acc-0.9200, valid loss-0.2330, acc-0.9326, test loss-0.2434, acc-0.9317\n",
      "Iter-80740, train loss-0.3643, acc-0.9200, valid loss-0.2329, acc-0.9328, test loss-0.2434, acc-0.9318\n",
      "Iter-80750, train loss-0.1710, acc-0.9600, valid loss-0.2329, acc-0.9328, test loss-0.2433, acc-0.9317\n",
      "Iter-80760, train loss-0.3259, acc-0.9000, valid loss-0.2329, acc-0.9328, test loss-0.2433, acc-0.9316\n",
      "Iter-80770, train loss-0.1561, acc-0.9400, valid loss-0.2329, acc-0.9332, test loss-0.2433, acc-0.9316\n",
      "Iter-80780, train loss-0.2186, acc-0.9400, valid loss-0.2329, acc-0.9334, test loss-0.2433, acc-0.9316\n",
      "Iter-80790, train loss-0.2882, acc-0.9200, valid loss-0.2329, acc-0.9334, test loss-0.2432, acc-0.9316\n",
      "Iter-80800, train loss-0.1912, acc-0.9600, valid loss-0.2329, acc-0.9334, test loss-0.2432, acc-0.9317\n",
      "Iter-80810, train loss-0.2450, acc-0.9200, valid loss-0.2328, acc-0.9336, test loss-0.2432, acc-0.9317\n",
      "Iter-80820, train loss-0.1025, acc-1.0000, valid loss-0.2328, acc-0.9336, test loss-0.2433, acc-0.9314\n",
      "Iter-80830, train loss-0.1664, acc-0.9400, valid loss-0.2328, acc-0.9336, test loss-0.2433, acc-0.9316\n",
      "Iter-80840, train loss-0.2133, acc-0.9400, valid loss-0.2328, acc-0.9334, test loss-0.2433, acc-0.9317\n",
      "Iter-80850, train loss-0.1836, acc-0.9600, valid loss-0.2327, acc-0.9334, test loss-0.2433, acc-0.9316\n",
      "Iter-80860, train loss-0.2750, acc-0.9400, valid loss-0.2327, acc-0.9334, test loss-0.2432, acc-0.9316\n",
      "Iter-80870, train loss-0.1832, acc-0.9600, valid loss-0.2327, acc-0.9332, test loss-0.2432, acc-0.9315\n",
      "Iter-80880, train loss-0.2232, acc-0.9400, valid loss-0.2327, acc-0.9332, test loss-0.2432, acc-0.9316\n",
      "Iter-80890, train loss-0.1210, acc-0.9800, valid loss-0.2326, acc-0.9332, test loss-0.2432, acc-0.9316\n",
      "Iter-80900, train loss-0.3637, acc-0.9200, valid loss-0.2327, acc-0.9330, test loss-0.2432, acc-0.9313\n",
      "Iter-80910, train loss-0.1648, acc-0.9800, valid loss-0.2328, acc-0.9332, test loss-0.2432, acc-0.9314\n",
      "Iter-80920, train loss-0.3343, acc-0.9000, valid loss-0.2327, acc-0.9334, test loss-0.2432, acc-0.9313\n",
      "Iter-80930, train loss-0.3794, acc-0.9000, valid loss-0.2327, acc-0.9334, test loss-0.2432, acc-0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-80940, train loss-0.1647, acc-0.9400, valid loss-0.2327, acc-0.9336, test loss-0.2431, acc-0.9318\n",
      "Iter-80950, train loss-0.1860, acc-0.9400, valid loss-0.2327, acc-0.9336, test loss-0.2431, acc-0.9316\n",
      "Iter-80960, train loss-0.1788, acc-0.9600, valid loss-0.2327, acc-0.9336, test loss-0.2431, acc-0.9316\n",
      "Iter-80970, train loss-0.1421, acc-0.9600, valid loss-0.2327, acc-0.9332, test loss-0.2431, acc-0.9316\n",
      "Iter-80980, train loss-0.5194, acc-0.8800, valid loss-0.2327, acc-0.9330, test loss-0.2431, acc-0.9317\n",
      "Iter-80990, train loss-0.2037, acc-0.9000, valid loss-0.2327, acc-0.9330, test loss-0.2430, acc-0.9316\n",
      "Iter-81000, train loss-0.2016, acc-0.9400, valid loss-0.2327, acc-0.9336, test loss-0.2431, acc-0.9316\n",
      "Iter-81010, train loss-0.4590, acc-0.8400, valid loss-0.2327, acc-0.9338, test loss-0.2431, acc-0.9317\n",
      "Iter-81020, train loss-0.2244, acc-0.9400, valid loss-0.2326, acc-0.9338, test loss-0.2431, acc-0.9316\n",
      "Iter-81030, train loss-0.1215, acc-0.9600, valid loss-0.2327, acc-0.9338, test loss-0.2431, acc-0.9317\n",
      "Iter-81040, train loss-0.2360, acc-0.9600, valid loss-0.2327, acc-0.9334, test loss-0.2431, acc-0.9315\n",
      "Iter-81050, train loss-0.3229, acc-0.9200, valid loss-0.2327, acc-0.9334, test loss-0.2432, acc-0.9312\n",
      "Iter-81060, train loss-0.3365, acc-0.8800, valid loss-0.2328, acc-0.9334, test loss-0.2432, acc-0.9314\n",
      "Iter-81070, train loss-0.1034, acc-1.0000, valid loss-0.2328, acc-0.9334, test loss-0.2432, acc-0.9314\n",
      "Iter-81080, train loss-0.2691, acc-0.9000, valid loss-0.2327, acc-0.9334, test loss-0.2431, acc-0.9317\n",
      "Iter-81090, train loss-0.1667, acc-0.9600, valid loss-0.2327, acc-0.9336, test loss-0.2431, acc-0.9315\n",
      "Iter-81100, train loss-0.2777, acc-0.8600, valid loss-0.2327, acc-0.9334, test loss-0.2431, acc-0.9315\n",
      "Iter-81110, train loss-0.3238, acc-0.8800, valid loss-0.2327, acc-0.9332, test loss-0.2431, acc-0.9312\n",
      "Iter-81120, train loss-0.1206, acc-0.9800, valid loss-0.2327, acc-0.9328, test loss-0.2431, acc-0.9313\n",
      "Iter-81130, train loss-0.2124, acc-0.9200, valid loss-0.2328, acc-0.9328, test loss-0.2431, acc-0.9312\n",
      "Iter-81140, train loss-0.2390, acc-0.9400, valid loss-0.2327, acc-0.9328, test loss-0.2430, acc-0.9314\n",
      "Iter-81150, train loss-0.3174, acc-0.9000, valid loss-0.2327, acc-0.9328, test loss-0.2430, acc-0.9314\n",
      "Iter-81160, train loss-0.1178, acc-0.9600, valid loss-0.2326, acc-0.9326, test loss-0.2430, acc-0.9314\n",
      "Iter-81170, train loss-0.2531, acc-0.9000, valid loss-0.2327, acc-0.9328, test loss-0.2430, acc-0.9314\n",
      "Iter-81180, train loss-0.1758, acc-0.9400, valid loss-0.2327, acc-0.9328, test loss-0.2431, acc-0.9316\n",
      "Iter-81190, train loss-0.2272, acc-0.9000, valid loss-0.2326, acc-0.9328, test loss-0.2430, acc-0.9312\n",
      "Iter-81200, train loss-0.2137, acc-0.9600, valid loss-0.2327, acc-0.9326, test loss-0.2430, acc-0.9314\n",
      "Iter-81210, train loss-0.1952, acc-0.9400, valid loss-0.2326, acc-0.9328, test loss-0.2431, acc-0.9313\n",
      "Iter-81220, train loss-0.1241, acc-0.9600, valid loss-0.2326, acc-0.9330, test loss-0.2431, acc-0.9313\n",
      "Iter-81230, train loss-0.4671, acc-0.9200, valid loss-0.2326, acc-0.9330, test loss-0.2431, acc-0.9315\n",
      "Iter-81240, train loss-0.1203, acc-0.9600, valid loss-0.2325, acc-0.9330, test loss-0.2431, acc-0.9316\n",
      "Iter-81250, train loss-0.2945, acc-0.8600, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9318\n",
      "Iter-81260, train loss-0.2071, acc-0.9200, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9317\n",
      "Iter-81270, train loss-0.2674, acc-0.9000, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9317\n",
      "Iter-81280, train loss-0.1374, acc-0.9400, valid loss-0.2324, acc-0.9332, test loss-0.2431, acc-0.9317\n",
      "Iter-81290, train loss-0.3024, acc-0.9400, valid loss-0.2325, acc-0.9332, test loss-0.2431, acc-0.9316\n",
      "Iter-81300, train loss-0.2316, acc-0.9200, valid loss-0.2325, acc-0.9332, test loss-0.2431, acc-0.9316\n",
      "Iter-81310, train loss-0.2177, acc-0.9000, valid loss-0.2325, acc-0.9332, test loss-0.2431, acc-0.9317\n",
      "Iter-81320, train loss-0.4580, acc-0.9000, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9318\n",
      "Iter-81330, train loss-0.4363, acc-0.8800, valid loss-0.2324, acc-0.9330, test loss-0.2430, acc-0.9317\n",
      "Iter-81340, train loss-0.1118, acc-0.9800, valid loss-0.2324, acc-0.9330, test loss-0.2430, acc-0.9318\n",
      "Iter-81350, train loss-0.1938, acc-0.9200, valid loss-0.2324, acc-0.9332, test loss-0.2431, acc-0.9320\n",
      "Iter-81360, train loss-0.2117, acc-0.9200, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9317\n",
      "Iter-81370, train loss-0.2082, acc-0.9600, valid loss-0.2324, acc-0.9330, test loss-0.2431, acc-0.9319\n",
      "Iter-81380, train loss-0.2482, acc-0.9200, valid loss-0.2323, acc-0.9328, test loss-0.2431, acc-0.9320\n",
      "Iter-81390, train loss-0.0910, acc-0.9800, valid loss-0.2323, acc-0.9328, test loss-0.2431, acc-0.9318\n",
      "Iter-81400, train loss-0.1225, acc-0.9800, valid loss-0.2323, acc-0.9328, test loss-0.2431, acc-0.9319\n",
      "Iter-81410, train loss-0.2709, acc-0.9400, valid loss-0.2322, acc-0.9330, test loss-0.2431, acc-0.9319\n",
      "Iter-81420, train loss-0.1326, acc-0.9600, valid loss-0.2322, acc-0.9330, test loss-0.2431, acc-0.9319\n",
      "Iter-81430, train loss-0.4398, acc-0.8400, valid loss-0.2322, acc-0.9332, test loss-0.2430, acc-0.9315\n",
      "Iter-81440, train loss-0.1415, acc-0.9800, valid loss-0.2321, acc-0.9330, test loss-0.2429, acc-0.9314\n",
      "Iter-81450, train loss-0.4007, acc-0.9200, valid loss-0.2321, acc-0.9332, test loss-0.2429, acc-0.9315\n",
      "Iter-81460, train loss-0.2663, acc-0.9400, valid loss-0.2320, acc-0.9332, test loss-0.2429, acc-0.9315\n",
      "Iter-81470, train loss-0.1867, acc-0.9600, valid loss-0.2320, acc-0.9334, test loss-0.2428, acc-0.9316\n",
      "Iter-81480, train loss-0.3256, acc-0.8800, valid loss-0.2320, acc-0.9334, test loss-0.2429, acc-0.9315\n",
      "Iter-81490, train loss-0.3179, acc-0.9000, valid loss-0.2320, acc-0.9336, test loss-0.2429, acc-0.9314\n",
      "Iter-81500, train loss-0.3278, acc-0.8800, valid loss-0.2319, acc-0.9334, test loss-0.2429, acc-0.9316\n",
      "Iter-81510, train loss-0.1266, acc-0.9600, valid loss-0.2319, acc-0.9338, test loss-0.2429, acc-0.9315\n",
      "Iter-81520, train loss-0.2341, acc-0.9200, valid loss-0.2319, acc-0.9338, test loss-0.2429, acc-0.9312\n",
      "Iter-81530, train loss-0.2068, acc-0.9400, valid loss-0.2319, acc-0.9338, test loss-0.2429, acc-0.9311\n",
      "Iter-81540, train loss-0.2869, acc-0.8800, valid loss-0.2318, acc-0.9338, test loss-0.2428, acc-0.9315\n",
      "Iter-81550, train loss-0.0839, acc-1.0000, valid loss-0.2317, acc-0.9336, test loss-0.2428, acc-0.9315\n",
      "Iter-81560, train loss-0.1842, acc-0.9400, valid loss-0.2317, acc-0.9336, test loss-0.2428, acc-0.9314\n",
      "Iter-81570, train loss-0.3023, acc-0.8600, valid loss-0.2318, acc-0.9336, test loss-0.2428, acc-0.9315\n",
      "Iter-81580, train loss-0.3156, acc-0.9000, valid loss-0.2317, acc-0.9336, test loss-0.2427, acc-0.9311\n",
      "Iter-81590, train loss-0.3843, acc-0.8800, valid loss-0.2318, acc-0.9334, test loss-0.2428, acc-0.9314\n",
      "Iter-81600, train loss-0.5173, acc-0.8800, valid loss-0.2318, acc-0.9334, test loss-0.2428, acc-0.9313\n",
      "Iter-81610, train loss-0.1841, acc-0.9400, valid loss-0.2317, acc-0.9334, test loss-0.2428, acc-0.9313\n",
      "Iter-81620, train loss-0.0967, acc-0.9800, valid loss-0.2318, acc-0.9334, test loss-0.2428, acc-0.9313\n",
      "Iter-81630, train loss-0.6522, acc-0.8800, valid loss-0.2318, acc-0.9334, test loss-0.2428, acc-0.9312\n",
      "Iter-81640, train loss-0.1293, acc-0.9800, valid loss-0.2319, acc-0.9334, test loss-0.2428, acc-0.9313\n",
      "Iter-81650, train loss-0.2101, acc-0.9400, valid loss-0.2319, acc-0.9334, test loss-0.2427, acc-0.9314\n",
      "Iter-81660, train loss-0.1954, acc-0.9200, valid loss-0.2319, acc-0.9336, test loss-0.2427, acc-0.9317\n",
      "Iter-81670, train loss-0.2011, acc-0.9200, valid loss-0.2319, acc-0.9336, test loss-0.2427, acc-0.9317\n",
      "Iter-81680, train loss-0.2672, acc-0.9400, valid loss-0.2319, acc-0.9338, test loss-0.2427, acc-0.9317\n",
      "Iter-81690, train loss-0.2174, acc-0.9400, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9317\n",
      "Iter-81700, train loss-0.4342, acc-0.9000, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9318\n",
      "Iter-81710, train loss-0.0854, acc-0.9800, valid loss-0.2318, acc-0.9334, test loss-0.2427, acc-0.9317\n",
      "Iter-81720, train loss-0.2702, acc-0.9200, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9315\n",
      "Iter-81730, train loss-0.2250, acc-0.9400, valid loss-0.2317, acc-0.9336, test loss-0.2427, acc-0.9316\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-81740, train loss-0.1383, acc-0.9600, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9316\n",
      "Iter-81750, train loss-0.2175, acc-0.9200, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9320\n",
      "Iter-81760, train loss-0.3309, acc-0.9000, valid loss-0.2319, acc-0.9334, test loss-0.2427, acc-0.9319\n",
      "Iter-81770, train loss-0.1680, acc-0.9400, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9319\n",
      "Iter-81780, train loss-0.1650, acc-0.9600, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9318\n",
      "Iter-81790, train loss-0.2208, acc-0.9200, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9319\n",
      "Iter-81800, train loss-0.1635, acc-0.9600, valid loss-0.2318, acc-0.9336, test loss-0.2427, acc-0.9320\n",
      "Iter-81810, train loss-0.1980, acc-0.9600, valid loss-0.2319, acc-0.9336, test loss-0.2426, acc-0.9322\n",
      "Iter-81820, train loss-0.1785, acc-0.9600, valid loss-0.2318, acc-0.9336, test loss-0.2426, acc-0.9319\n",
      "Iter-81830, train loss-0.3902, acc-0.8800, valid loss-0.2318, acc-0.9336, test loss-0.2426, acc-0.9316\n",
      "Iter-81840, train loss-0.2317, acc-0.9000, valid loss-0.2318, acc-0.9334, test loss-0.2426, acc-0.9317\n",
      "Iter-81850, train loss-0.1552, acc-0.9600, valid loss-0.2318, acc-0.9336, test loss-0.2426, acc-0.9316\n",
      "Iter-81860, train loss-0.2413, acc-0.9400, valid loss-0.2319, acc-0.9338, test loss-0.2427, acc-0.9318\n",
      "Iter-81870, train loss-0.2946, acc-0.8800, valid loss-0.2318, acc-0.9338, test loss-0.2427, acc-0.9319\n",
      "Iter-81880, train loss-0.3345, acc-0.8600, valid loss-0.2318, acc-0.9338, test loss-0.2426, acc-0.9318\n",
      "Iter-81890, train loss-0.2275, acc-0.9400, valid loss-0.2317, acc-0.9338, test loss-0.2426, acc-0.9318\n",
      "Iter-81900, train loss-0.1667, acc-0.9800, valid loss-0.2318, acc-0.9336, test loss-0.2426, acc-0.9316\n",
      "Iter-81910, train loss-0.3921, acc-0.9200, valid loss-0.2318, acc-0.9336, test loss-0.2425, acc-0.9318\n",
      "Iter-81920, train loss-0.4010, acc-0.8600, valid loss-0.2317, acc-0.9338, test loss-0.2425, acc-0.9315\n",
      "Iter-81930, train loss-0.1431, acc-0.9400, valid loss-0.2317, acc-0.9336, test loss-0.2425, acc-0.9314\n",
      "Iter-81940, train loss-0.0981, acc-0.9800, valid loss-0.2317, acc-0.9336, test loss-0.2424, acc-0.9316\n",
      "Iter-81950, train loss-0.2912, acc-0.9000, valid loss-0.2317, acc-0.9336, test loss-0.2425, acc-0.9315\n",
      "Iter-81960, train loss-0.1074, acc-0.9600, valid loss-0.2317, acc-0.9336, test loss-0.2424, acc-0.9317\n",
      "Iter-81970, train loss-0.4526, acc-0.8400, valid loss-0.2317, acc-0.9336, test loss-0.2424, acc-0.9316\n",
      "Iter-81980, train loss-0.1940, acc-0.9600, valid loss-0.2317, acc-0.9336, test loss-0.2424, acc-0.9317\n",
      "Iter-81990, train loss-0.1493, acc-0.9600, valid loss-0.2318, acc-0.9334, test loss-0.2424, acc-0.9317\n",
      "Iter-82000, train loss-0.4605, acc-0.9000, valid loss-0.2319, acc-0.9336, test loss-0.2424, acc-0.9317\n",
      "Iter-82010, train loss-0.5821, acc-0.8200, valid loss-0.2319, acc-0.9336, test loss-0.2424, acc-0.9318\n",
      "Iter-82020, train loss-0.3346, acc-0.9000, valid loss-0.2319, acc-0.9334, test loss-0.2424, acc-0.9316\n",
      "Iter-82030, train loss-0.2146, acc-0.9200, valid loss-0.2319, acc-0.9334, test loss-0.2424, acc-0.9317\n",
      "Iter-82040, train loss-0.2182, acc-0.9200, valid loss-0.2318, acc-0.9334, test loss-0.2425, acc-0.9316\n",
      "Iter-82050, train loss-0.1524, acc-0.9400, valid loss-0.2318, acc-0.9332, test loss-0.2425, acc-0.9315\n",
      "Iter-82060, train loss-0.2187, acc-0.9400, valid loss-0.2318, acc-0.9330, test loss-0.2425, acc-0.9316\n",
      "Iter-82070, train loss-0.2443, acc-0.9000, valid loss-0.2318, acc-0.9330, test loss-0.2424, acc-0.9317\n",
      "Iter-82080, train loss-0.3798, acc-0.8800, valid loss-0.2318, acc-0.9328, test loss-0.2424, acc-0.9317\n",
      "Iter-82090, train loss-0.2273, acc-0.9400, valid loss-0.2318, acc-0.9328, test loss-0.2424, acc-0.9318\n",
      "Iter-82100, train loss-0.3410, acc-0.9200, valid loss-0.2318, acc-0.9328, test loss-0.2423, acc-0.9318\n",
      "Iter-82110, train loss-0.1851, acc-0.9200, valid loss-0.2317, acc-0.9328, test loss-0.2423, acc-0.9317\n",
      "Iter-82120, train loss-0.3747, acc-0.9200, valid loss-0.2317, acc-0.9330, test loss-0.2423, acc-0.9318\n",
      "Iter-82130, train loss-0.0751, acc-1.0000, valid loss-0.2317, acc-0.9328, test loss-0.2423, acc-0.9319\n",
      "Iter-82140, train loss-0.5618, acc-0.8000, valid loss-0.2317, acc-0.9330, test loss-0.2423, acc-0.9318\n",
      "Iter-82150, train loss-0.2215, acc-0.9200, valid loss-0.2317, acc-0.9330, test loss-0.2423, acc-0.9319\n",
      "Iter-82160, train loss-0.2506, acc-0.9400, valid loss-0.2317, acc-0.9330, test loss-0.2424, acc-0.9318\n",
      "Iter-82170, train loss-0.0805, acc-1.0000, valid loss-0.2317, acc-0.9330, test loss-0.2424, acc-0.9319\n",
      "Iter-82180, train loss-0.3302, acc-0.9000, valid loss-0.2317, acc-0.9332, test loss-0.2423, acc-0.9319\n",
      "Iter-82190, train loss-0.2359, acc-0.9600, valid loss-0.2318, acc-0.9338, test loss-0.2424, acc-0.9319\n",
      "Iter-82200, train loss-0.1267, acc-0.9800, valid loss-0.2317, acc-0.9334, test loss-0.2423, acc-0.9319\n",
      "Iter-82210, train loss-0.2130, acc-0.9000, valid loss-0.2317, acc-0.9330, test loss-0.2423, acc-0.9319\n",
      "Iter-82220, train loss-0.1219, acc-0.9800, valid loss-0.2317, acc-0.9332, test loss-0.2422, acc-0.9320\n",
      "Iter-82230, train loss-0.1853, acc-0.9600, valid loss-0.2316, acc-0.9332, test loss-0.2422, acc-0.9317\n",
      "Iter-82240, train loss-0.2138, acc-0.9200, valid loss-0.2316, acc-0.9330, test loss-0.2422, acc-0.9319\n",
      "Iter-82250, train loss-0.1661, acc-0.9400, valid loss-0.2315, acc-0.9330, test loss-0.2422, acc-0.9320\n",
      "Iter-82260, train loss-0.1791, acc-0.9400, valid loss-0.2315, acc-0.9334, test loss-0.2421, acc-0.9319\n",
      "Iter-82270, train loss-0.2677, acc-0.9000, valid loss-0.2315, acc-0.9332, test loss-0.2421, acc-0.9321\n",
      "Iter-82280, train loss-0.2388, acc-0.9000, valid loss-0.2315, acc-0.9334, test loss-0.2421, acc-0.9319\n",
      "Iter-82290, train loss-0.3075, acc-0.9400, valid loss-0.2315, acc-0.9334, test loss-0.2420, acc-0.9322\n",
      "Iter-82300, train loss-0.4116, acc-0.9400, valid loss-0.2314, acc-0.9336, test loss-0.2420, acc-0.9324\n",
      "Iter-82310, train loss-0.1475, acc-0.9800, valid loss-0.2313, acc-0.9340, test loss-0.2421, acc-0.9324\n",
      "Iter-82320, train loss-0.4269, acc-0.9000, valid loss-0.2313, acc-0.9334, test loss-0.2421, acc-0.9324\n",
      "Iter-82330, train loss-0.3518, acc-0.9000, valid loss-0.2313, acc-0.9336, test loss-0.2420, acc-0.9322\n",
      "Iter-82340, train loss-0.3008, acc-0.9000, valid loss-0.2313, acc-0.9336, test loss-0.2420, acc-0.9322\n",
      "Iter-82350, train loss-0.4821, acc-0.8800, valid loss-0.2313, acc-0.9332, test loss-0.2419, acc-0.9323\n",
      "Iter-82360, train loss-0.2376, acc-0.9400, valid loss-0.2313, acc-0.9334, test loss-0.2419, acc-0.9323\n",
      "Iter-82370, train loss-0.0879, acc-0.9600, valid loss-0.2313, acc-0.9336, test loss-0.2419, acc-0.9322\n",
      "Iter-82380, train loss-0.3358, acc-0.9000, valid loss-0.2312, acc-0.9336, test loss-0.2419, acc-0.9322\n",
      "Iter-82390, train loss-0.0910, acc-1.0000, valid loss-0.2312, acc-0.9334, test loss-0.2420, acc-0.9321\n",
      "Iter-82400, train loss-0.0793, acc-0.9800, valid loss-0.2311, acc-0.9334, test loss-0.2420, acc-0.9322\n",
      "Iter-82410, train loss-0.1567, acc-0.9600, valid loss-0.2311, acc-0.9332, test loss-0.2419, acc-0.9323\n",
      "Iter-82420, train loss-0.3147, acc-0.8400, valid loss-0.2311, acc-0.9332, test loss-0.2419, acc-0.9322\n",
      "Iter-82430, train loss-0.3288, acc-0.9000, valid loss-0.2312, acc-0.9334, test loss-0.2419, acc-0.9321\n",
      "Iter-82440, train loss-0.4057, acc-0.9200, valid loss-0.2311, acc-0.9334, test loss-0.2419, acc-0.9320\n",
      "Iter-82450, train loss-0.4174, acc-0.9000, valid loss-0.2311, acc-0.9336, test loss-0.2419, acc-0.9322\n",
      "Iter-82460, train loss-0.0617, acc-1.0000, valid loss-0.2310, acc-0.9338, test loss-0.2419, acc-0.9320\n",
      "Iter-82470, train loss-0.4157, acc-0.9000, valid loss-0.2310, acc-0.9338, test loss-0.2419, acc-0.9321\n",
      "Iter-82480, train loss-0.2780, acc-0.9400, valid loss-0.2310, acc-0.9336, test loss-0.2418, acc-0.9321\n",
      "Iter-82490, train loss-0.4515, acc-0.9000, valid loss-0.2309, acc-0.9336, test loss-0.2418, acc-0.9321\n",
      "Iter-82500, train loss-0.1064, acc-0.9800, valid loss-0.2309, acc-0.9334, test loss-0.2418, acc-0.9320\n",
      "Iter-82510, train loss-0.2283, acc-0.9400, valid loss-0.2309, acc-0.9334, test loss-0.2418, acc-0.9320\n",
      "Iter-82520, train loss-0.1170, acc-0.9800, valid loss-0.2309, acc-0.9336, test loss-0.2418, acc-0.9318\n",
      "Iter-82530, train loss-0.4395, acc-0.8600, valid loss-0.2309, acc-0.9334, test loss-0.2418, acc-0.9318\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-82540, train loss-0.1292, acc-0.9600, valid loss-0.2309, acc-0.9334, test loss-0.2418, acc-0.9319\n",
      "Iter-82550, train loss-0.1451, acc-0.9600, valid loss-0.2309, acc-0.9336, test loss-0.2418, acc-0.9317\n",
      "Iter-82560, train loss-0.2030, acc-0.9400, valid loss-0.2309, acc-0.9338, test loss-0.2418, acc-0.9319\n",
      "Iter-82570, train loss-0.3826, acc-0.8800, valid loss-0.2309, acc-0.9340, test loss-0.2418, acc-0.9320\n",
      "Iter-82580, train loss-0.2113, acc-0.9400, valid loss-0.2308, acc-0.9338, test loss-0.2418, acc-0.9318\n",
      "Iter-82590, train loss-0.1681, acc-0.9800, valid loss-0.2308, acc-0.9338, test loss-0.2417, acc-0.9317\n",
      "Iter-82600, train loss-0.1620, acc-0.9600, valid loss-0.2308, acc-0.9338, test loss-0.2417, acc-0.9318\n",
      "Iter-82610, train loss-0.3347, acc-0.9200, valid loss-0.2307, acc-0.9338, test loss-0.2417, acc-0.9318\n",
      "Iter-82620, train loss-0.3093, acc-0.9000, valid loss-0.2307, acc-0.9338, test loss-0.2416, acc-0.9318\n",
      "Iter-82630, train loss-0.2645, acc-0.9200, valid loss-0.2307, acc-0.9338, test loss-0.2416, acc-0.9317\n",
      "Iter-82640, train loss-0.1394, acc-0.9800, valid loss-0.2306, acc-0.9340, test loss-0.2416, acc-0.9317\n",
      "Iter-82650, train loss-0.3736, acc-0.9000, valid loss-0.2305, acc-0.9338, test loss-0.2415, acc-0.9317\n",
      "Iter-82660, train loss-0.1772, acc-0.9600, valid loss-0.2305, acc-0.9338, test loss-0.2415, acc-0.9317\n",
      "Iter-82670, train loss-0.2905, acc-0.9400, valid loss-0.2305, acc-0.9336, test loss-0.2415, acc-0.9317\n",
      "Iter-82680, train loss-0.2987, acc-0.9200, valid loss-0.2305, acc-0.9336, test loss-0.2415, acc-0.9316\n",
      "Iter-82690, train loss-0.1305, acc-0.9800, valid loss-0.2306, acc-0.9336, test loss-0.2416, acc-0.9316\n",
      "Iter-82700, train loss-0.1673, acc-0.9600, valid loss-0.2306, acc-0.9336, test loss-0.2415, acc-0.9316\n",
      "Iter-82710, train loss-0.1047, acc-1.0000, valid loss-0.2305, acc-0.9336, test loss-0.2415, acc-0.9316\n",
      "Iter-82720, train loss-0.3605, acc-0.8800, valid loss-0.2306, acc-0.9336, test loss-0.2415, acc-0.9318\n",
      "Iter-82730, train loss-0.2101, acc-0.9400, valid loss-0.2306, acc-0.9338, test loss-0.2415, acc-0.9317\n",
      "Iter-82740, train loss-0.1535, acc-0.9400, valid loss-0.2306, acc-0.9334, test loss-0.2414, acc-0.9317\n",
      "Iter-82750, train loss-0.1299, acc-0.9600, valid loss-0.2306, acc-0.9334, test loss-0.2415, acc-0.9317\n",
      "Iter-82760, train loss-0.3571, acc-0.9200, valid loss-0.2306, acc-0.9336, test loss-0.2414, acc-0.9319\n",
      "Iter-82770, train loss-0.2029, acc-0.9600, valid loss-0.2305, acc-0.9332, test loss-0.2414, acc-0.9315\n",
      "Iter-82780, train loss-0.1822, acc-0.9400, valid loss-0.2306, acc-0.9332, test loss-0.2414, acc-0.9316\n",
      "Iter-82790, train loss-0.2807, acc-0.9000, valid loss-0.2306, acc-0.9332, test loss-0.2414, acc-0.9318\n",
      "Iter-82800, train loss-0.3295, acc-0.8800, valid loss-0.2306, acc-0.9332, test loss-0.2414, acc-0.9319\n",
      "Iter-82810, train loss-0.3231, acc-0.8800, valid loss-0.2304, acc-0.9336, test loss-0.2414, acc-0.9316\n",
      "Iter-82820, train loss-0.3408, acc-0.9000, valid loss-0.2304, acc-0.9334, test loss-0.2414, acc-0.9316\n",
      "Iter-82830, train loss-0.2030, acc-0.9400, valid loss-0.2305, acc-0.9334, test loss-0.2414, acc-0.9317\n",
      "Iter-82840, train loss-0.0909, acc-1.0000, valid loss-0.2304, acc-0.9336, test loss-0.2414, acc-0.9316\n",
      "Iter-82850, train loss-0.0909, acc-0.9800, valid loss-0.2303, acc-0.9340, test loss-0.2413, acc-0.9315\n",
      "Iter-82860, train loss-0.2318, acc-0.9200, valid loss-0.2303, acc-0.9340, test loss-0.2413, acc-0.9316\n",
      "Iter-82870, train loss-0.2247, acc-0.9400, valid loss-0.2304, acc-0.9340, test loss-0.2413, acc-0.9317\n",
      "Iter-82880, train loss-0.3511, acc-0.9000, valid loss-0.2303, acc-0.9338, test loss-0.2413, acc-0.9316\n",
      "Iter-82890, train loss-0.2596, acc-0.8600, valid loss-0.2303, acc-0.9338, test loss-0.2413, acc-0.9314\n",
      "Iter-82900, train loss-0.1718, acc-0.9400, valid loss-0.2303, acc-0.9336, test loss-0.2413, acc-0.9316\n",
      "Iter-82910, train loss-0.1898, acc-0.9400, valid loss-0.2303, acc-0.9336, test loss-0.2413, acc-0.9316\n",
      "Iter-82920, train loss-0.1686, acc-0.9600, valid loss-0.2303, acc-0.9336, test loss-0.2412, acc-0.9316\n",
      "Iter-82930, train loss-0.3629, acc-0.9600, valid loss-0.2303, acc-0.9340, test loss-0.2412, acc-0.9319\n",
      "Iter-82940, train loss-0.3079, acc-0.9400, valid loss-0.2303, acc-0.9340, test loss-0.2412, acc-0.9315\n",
      "Iter-82950, train loss-0.3427, acc-0.8800, valid loss-0.2303, acc-0.9338, test loss-0.2412, acc-0.9316\n",
      "Iter-82960, train loss-0.0893, acc-0.9800, valid loss-0.2303, acc-0.9340, test loss-0.2411, acc-0.9318\n",
      "Iter-82970, train loss-0.2231, acc-0.9200, valid loss-0.2303, acc-0.9338, test loss-0.2411, acc-0.9319\n",
      "Iter-82980, train loss-0.1106, acc-1.0000, valid loss-0.2303, acc-0.9338, test loss-0.2411, acc-0.9320\n",
      "Iter-82990, train loss-0.2182, acc-0.9600, valid loss-0.2303, acc-0.9338, test loss-0.2412, acc-0.9317\n",
      "Iter-83000, train loss-0.1422, acc-0.9600, valid loss-0.2302, acc-0.9338, test loss-0.2411, acc-0.9316\n",
      "Iter-83010, train loss-0.1985, acc-0.9400, valid loss-0.2303, acc-0.9336, test loss-0.2411, acc-0.9316\n",
      "Iter-83020, train loss-0.2097, acc-0.9400, valid loss-0.2302, acc-0.9334, test loss-0.2410, acc-0.9316\n",
      "Iter-83030, train loss-0.4578, acc-0.9000, valid loss-0.2302, acc-0.9332, test loss-0.2410, acc-0.9316\n",
      "Iter-83040, train loss-0.1552, acc-0.9400, valid loss-0.2301, acc-0.9334, test loss-0.2410, acc-0.9316\n",
      "Iter-83050, train loss-0.1489, acc-0.9800, valid loss-0.2301, acc-0.9340, test loss-0.2410, acc-0.9315\n",
      "Iter-83060, train loss-0.1435, acc-0.9600, valid loss-0.2301, acc-0.9340, test loss-0.2410, acc-0.9315\n",
      "Iter-83070, train loss-0.2270, acc-0.9400, valid loss-0.2301, acc-0.9340, test loss-0.2409, acc-0.9315\n",
      "Iter-83080, train loss-0.5876, acc-0.8400, valid loss-0.2301, acc-0.9340, test loss-0.2409, acc-0.9314\n",
      "Iter-83090, train loss-0.2668, acc-0.9400, valid loss-0.2301, acc-0.9338, test loss-0.2408, acc-0.9314\n",
      "Iter-83100, train loss-0.1197, acc-0.9600, valid loss-0.2301, acc-0.9338, test loss-0.2408, acc-0.9317\n",
      "Iter-83110, train loss-0.1213, acc-0.9800, valid loss-0.2301, acc-0.9340, test loss-0.2408, acc-0.9316\n",
      "Iter-83120, train loss-0.2042, acc-0.9200, valid loss-0.2301, acc-0.9344, test loss-0.2408, acc-0.9315\n",
      "Iter-83130, train loss-0.1154, acc-0.9600, valid loss-0.2301, acc-0.9342, test loss-0.2408, acc-0.9316\n",
      "Iter-83140, train loss-0.3038, acc-0.9200, valid loss-0.2300, acc-0.9342, test loss-0.2408, acc-0.9316\n",
      "Iter-83150, train loss-0.2226, acc-0.9000, valid loss-0.2300, acc-0.9346, test loss-0.2408, acc-0.9316\n",
      "Iter-83160, train loss-0.1610, acc-0.9800, valid loss-0.2300, acc-0.9346, test loss-0.2408, acc-0.9315\n",
      "Iter-83170, train loss-0.2087, acc-0.9200, valid loss-0.2300, acc-0.9346, test loss-0.2407, acc-0.9315\n",
      "Iter-83180, train loss-0.3016, acc-0.9000, valid loss-0.2300, acc-0.9344, test loss-0.2408, acc-0.9315\n",
      "Iter-83190, train loss-0.4344, acc-0.8800, valid loss-0.2300, acc-0.9348, test loss-0.2407, acc-0.9316\n",
      "Iter-83200, train loss-0.1487, acc-0.9600, valid loss-0.2299, acc-0.9346, test loss-0.2407, acc-0.9313\n",
      "Iter-83210, train loss-0.1546, acc-0.9600, valid loss-0.2299, acc-0.9344, test loss-0.2408, acc-0.9313\n",
      "Iter-83220, train loss-0.2775, acc-0.9000, valid loss-0.2299, acc-0.9346, test loss-0.2407, acc-0.9313\n",
      "Iter-83230, train loss-0.1963, acc-0.9400, valid loss-0.2299, acc-0.9346, test loss-0.2406, acc-0.9315\n",
      "Iter-83240, train loss-0.2609, acc-0.8800, valid loss-0.2299, acc-0.9346, test loss-0.2406, acc-0.9314\n",
      "Iter-83250, train loss-0.2002, acc-0.9200, valid loss-0.2299, acc-0.9346, test loss-0.2406, acc-0.9314\n",
      "Iter-83260, train loss-0.1359, acc-1.0000, valid loss-0.2299, acc-0.9348, test loss-0.2406, acc-0.9313\n",
      "Iter-83270, train loss-0.1826, acc-0.9600, valid loss-0.2300, acc-0.9348, test loss-0.2406, acc-0.9316\n",
      "Iter-83280, train loss-0.2912, acc-0.9000, valid loss-0.2299, acc-0.9350, test loss-0.2406, acc-0.9315\n",
      "Iter-83290, train loss-0.2322, acc-0.9000, valid loss-0.2299, acc-0.9354, test loss-0.2406, acc-0.9313\n",
      "Iter-83300, train loss-0.2319, acc-0.9000, valid loss-0.2299, acc-0.9352, test loss-0.2406, acc-0.9313\n",
      "Iter-83310, train loss-0.3641, acc-0.9000, valid loss-0.2299, acc-0.9352, test loss-0.2405, acc-0.9314\n",
      "Iter-83320, train loss-0.3057, acc-0.9400, valid loss-0.2299, acc-0.9350, test loss-0.2405, acc-0.9314\n",
      "Iter-83330, train loss-0.1823, acc-0.9800, valid loss-0.2299, acc-0.9352, test loss-0.2405, acc-0.9315\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-83340, train loss-0.0971, acc-0.9800, valid loss-0.2298, acc-0.9350, test loss-0.2405, acc-0.9313\n",
      "Iter-83350, train loss-0.4970, acc-0.8800, valid loss-0.2298, acc-0.9350, test loss-0.2405, acc-0.9314\n",
      "Iter-83360, train loss-0.1998, acc-0.9600, valid loss-0.2298, acc-0.9348, test loss-0.2405, acc-0.9314\n",
      "Iter-83370, train loss-0.2463, acc-0.8800, valid loss-0.2298, acc-0.9344, test loss-0.2405, acc-0.9316\n",
      "Iter-83380, train loss-0.3019, acc-0.8800, valid loss-0.2297, acc-0.9344, test loss-0.2405, acc-0.9313\n",
      "Iter-83390, train loss-0.2294, acc-0.9400, valid loss-0.2297, acc-0.9346, test loss-0.2405, acc-0.9315\n",
      "Iter-83400, train loss-0.2152, acc-0.9200, valid loss-0.2297, acc-0.9346, test loss-0.2405, acc-0.9316\n",
      "Iter-83410, train loss-0.1925, acc-0.9600, valid loss-0.2296, acc-0.9346, test loss-0.2405, acc-0.9317\n",
      "Iter-83420, train loss-0.5300, acc-0.8400, valid loss-0.2297, acc-0.9346, test loss-0.2404, acc-0.9316\n",
      "Iter-83430, train loss-0.1879, acc-0.9600, valid loss-0.2297, acc-0.9344, test loss-0.2404, acc-0.9316\n",
      "Iter-83440, train loss-0.2781, acc-0.9200, valid loss-0.2297, acc-0.9342, test loss-0.2404, acc-0.9319\n",
      "Iter-83450, train loss-0.2307, acc-0.9200, valid loss-0.2297, acc-0.9342, test loss-0.2404, acc-0.9319\n",
      "Iter-83460, train loss-0.1253, acc-0.9800, valid loss-0.2296, acc-0.9340, test loss-0.2403, acc-0.9319\n",
      "Iter-83470, train loss-0.3939, acc-0.8800, valid loss-0.2296, acc-0.9340, test loss-0.2403, acc-0.9317\n",
      "Iter-83480, train loss-0.3034, acc-0.9200, valid loss-0.2296, acc-0.9342, test loss-0.2404, acc-0.9319\n",
      "Iter-83490, train loss-0.2933, acc-0.9200, valid loss-0.2295, acc-0.9338, test loss-0.2403, acc-0.9317\n",
      "Iter-83500, train loss-0.1566, acc-0.9800, valid loss-0.2295, acc-0.9340, test loss-0.2403, acc-0.9315\n",
      "Iter-83510, train loss-0.2057, acc-0.9400, valid loss-0.2294, acc-0.9338, test loss-0.2403, acc-0.9317\n",
      "Iter-83520, train loss-0.3927, acc-0.8600, valid loss-0.2293, acc-0.9336, test loss-0.2403, acc-0.9315\n",
      "Iter-83530, train loss-0.1804, acc-0.9600, valid loss-0.2293, acc-0.9334, test loss-0.2404, acc-0.9317\n",
      "Iter-83540, train loss-0.2760, acc-0.9200, valid loss-0.2294, acc-0.9336, test loss-0.2403, acc-0.9316\n",
      "Iter-83550, train loss-0.3723, acc-0.9000, valid loss-0.2293, acc-0.9336, test loss-0.2403, acc-0.9317\n",
      "Iter-83560, train loss-0.1537, acc-0.9800, valid loss-0.2293, acc-0.9336, test loss-0.2402, acc-0.9316\n",
      "Iter-83570, train loss-0.2811, acc-0.9200, valid loss-0.2293, acc-0.9336, test loss-0.2403, acc-0.9317\n",
      "Iter-83580, train loss-0.1115, acc-1.0000, valid loss-0.2293, acc-0.9336, test loss-0.2403, acc-0.9316\n",
      "Iter-83590, train loss-0.2668, acc-0.9000, valid loss-0.2293, acc-0.9336, test loss-0.2403, acc-0.9315\n",
      "Iter-83600, train loss-0.3142, acc-0.9000, valid loss-0.2293, acc-0.9336, test loss-0.2402, acc-0.9317\n",
      "Iter-83610, train loss-0.3116, acc-0.9000, valid loss-0.2293, acc-0.9336, test loss-0.2402, acc-0.9318\n",
      "Iter-83620, train loss-0.2136, acc-0.9600, valid loss-0.2293, acc-0.9336, test loss-0.2402, acc-0.9316\n",
      "Iter-83630, train loss-0.3014, acc-0.9000, valid loss-0.2294, acc-0.9334, test loss-0.2402, acc-0.9314\n",
      "Iter-83640, train loss-0.1877, acc-0.9400, valid loss-0.2295, acc-0.9334, test loss-0.2402, acc-0.9315\n",
      "Iter-83650, train loss-0.3383, acc-0.8600, valid loss-0.2294, acc-0.9332, test loss-0.2402, acc-0.9313\n",
      "Iter-83660, train loss-0.5884, acc-0.8800, valid loss-0.2294, acc-0.9334, test loss-0.2401, acc-0.9312\n",
      "Iter-83670, train loss-0.2583, acc-0.9200, valid loss-0.2294, acc-0.9332, test loss-0.2401, acc-0.9313\n",
      "Iter-83680, train loss-0.1240, acc-0.9600, valid loss-0.2293, acc-0.9334, test loss-0.2401, acc-0.9315\n",
      "Iter-83690, train loss-0.2310, acc-0.9200, valid loss-0.2293, acc-0.9336, test loss-0.2401, acc-0.9315\n",
      "Iter-83700, train loss-0.3156, acc-0.9000, valid loss-0.2294, acc-0.9334, test loss-0.2402, acc-0.9315\n",
      "Iter-83710, train loss-0.1921, acc-0.9400, valid loss-0.2294, acc-0.9336, test loss-0.2402, acc-0.9312\n",
      "Iter-83720, train loss-0.2853, acc-0.9400, valid loss-0.2293, acc-0.9336, test loss-0.2401, acc-0.9313\n",
      "Iter-83730, train loss-0.2366, acc-0.9200, valid loss-0.2293, acc-0.9338, test loss-0.2401, acc-0.9315\n",
      "Iter-83740, train loss-0.1981, acc-0.9600, valid loss-0.2293, acc-0.9338, test loss-0.2401, acc-0.9314\n",
      "Iter-83750, train loss-0.2407, acc-0.9600, valid loss-0.2292, acc-0.9338, test loss-0.2400, acc-0.9315\n",
      "Iter-83760, train loss-0.1256, acc-0.9800, valid loss-0.2292, acc-0.9336, test loss-0.2400, acc-0.9315\n",
      "Iter-83770, train loss-0.1358, acc-0.9800, valid loss-0.2291, acc-0.9334, test loss-0.2400, acc-0.9317\n",
      "Iter-83780, train loss-0.1105, acc-0.9600, valid loss-0.2291, acc-0.9338, test loss-0.2400, acc-0.9316\n",
      "Iter-83790, train loss-0.1787, acc-0.9600, valid loss-0.2291, acc-0.9338, test loss-0.2399, acc-0.9318\n",
      "Iter-83800, train loss-0.1969, acc-0.9200, valid loss-0.2290, acc-0.9340, test loss-0.2399, acc-0.9317\n",
      "Iter-83810, train loss-0.2333, acc-0.9600, valid loss-0.2290, acc-0.9340, test loss-0.2398, acc-0.9318\n",
      "Iter-83820, train loss-0.2417, acc-0.9400, valid loss-0.2290, acc-0.9340, test loss-0.2398, acc-0.9319\n",
      "Iter-83830, train loss-0.2443, acc-0.9000, valid loss-0.2290, acc-0.9338, test loss-0.2398, acc-0.9319\n",
      "Iter-83840, train loss-0.1347, acc-0.9800, valid loss-0.2290, acc-0.9338, test loss-0.2399, acc-0.9316\n",
      "Iter-83850, train loss-0.2248, acc-0.9400, valid loss-0.2289, acc-0.9344, test loss-0.2398, acc-0.9317\n",
      "Iter-83860, train loss-0.5746, acc-0.8200, valid loss-0.2290, acc-0.9342, test loss-0.2398, acc-0.9317\n",
      "Iter-83870, train loss-0.3587, acc-0.8800, valid loss-0.2289, acc-0.9342, test loss-0.2398, acc-0.9317\n",
      "Iter-83880, train loss-0.0953, acc-1.0000, valid loss-0.2289, acc-0.9342, test loss-0.2399, acc-0.9316\n",
      "Iter-83890, train loss-0.1427, acc-0.9600, valid loss-0.2290, acc-0.9336, test loss-0.2398, acc-0.9316\n",
      "Iter-83900, train loss-0.3682, acc-0.8800, valid loss-0.2289, acc-0.9340, test loss-0.2398, acc-0.9317\n",
      "Iter-83910, train loss-0.3011, acc-0.9200, valid loss-0.2288, acc-0.9344, test loss-0.2398, acc-0.9316\n",
      "Iter-83920, train loss-0.3742, acc-0.9200, valid loss-0.2288, acc-0.9342, test loss-0.2397, acc-0.9320\n",
      "Iter-83930, train loss-0.1826, acc-0.9800, valid loss-0.2288, acc-0.9342, test loss-0.2397, acc-0.9321\n",
      "Iter-83940, train loss-0.2097, acc-0.9400, valid loss-0.2288, acc-0.9340, test loss-0.2397, acc-0.9318\n",
      "Iter-83950, train loss-0.2057, acc-0.9400, valid loss-0.2287, acc-0.9342, test loss-0.2398, acc-0.9319\n",
      "Iter-83960, train loss-0.1338, acc-0.9600, valid loss-0.2288, acc-0.9340, test loss-0.2397, acc-0.9318\n",
      "Iter-83970, train loss-0.2039, acc-0.9200, valid loss-0.2288, acc-0.9338, test loss-0.2397, acc-0.9319\n",
      "Iter-83980, train loss-0.2603, acc-0.8800, valid loss-0.2288, acc-0.9336, test loss-0.2398, acc-0.9319\n",
      "Iter-83990, train loss-0.3198, acc-0.8800, valid loss-0.2288, acc-0.9334, test loss-0.2397, acc-0.9322\n",
      "Iter-84000, train loss-0.2463, acc-0.9200, valid loss-0.2288, acc-0.9332, test loss-0.2397, acc-0.9320\n",
      "Iter-84010, train loss-0.2485, acc-0.9200, valid loss-0.2287, acc-0.9338, test loss-0.2397, acc-0.9320\n",
      "Iter-84020, train loss-0.1046, acc-0.9800, valid loss-0.2287, acc-0.9334, test loss-0.2396, acc-0.9318\n",
      "Iter-84030, train loss-0.1667, acc-0.9600, valid loss-0.2287, acc-0.9336, test loss-0.2395, acc-0.9321\n",
      "Iter-84040, train loss-0.1409, acc-0.9600, valid loss-0.2287, acc-0.9334, test loss-0.2395, acc-0.9320\n",
      "Iter-84050, train loss-0.4117, acc-0.8800, valid loss-0.2287, acc-0.9336, test loss-0.2396, acc-0.9322\n",
      "Iter-84060, train loss-0.3427, acc-0.9000, valid loss-0.2286, acc-0.9336, test loss-0.2395, acc-0.9322\n",
      "Iter-84070, train loss-0.2499, acc-0.9600, valid loss-0.2287, acc-0.9334, test loss-0.2395, acc-0.9321\n",
      "Iter-84080, train loss-0.2967, acc-0.8600, valid loss-0.2287, acc-0.9338, test loss-0.2395, acc-0.9321\n",
      "Iter-84090, train loss-0.2010, acc-0.9400, valid loss-0.2286, acc-0.9336, test loss-0.2395, acc-0.9321\n",
      "Iter-84100, train loss-0.3154, acc-0.9400, valid loss-0.2286, acc-0.9340, test loss-0.2395, acc-0.9321\n",
      "Iter-84110, train loss-0.3335, acc-0.8800, valid loss-0.2285, acc-0.9340, test loss-0.2395, acc-0.9318\n",
      "Iter-84120, train loss-0.4296, acc-0.9200, valid loss-0.2285, acc-0.9340, test loss-0.2395, acc-0.9321\n",
      "Iter-84130, train loss-0.2376, acc-0.8800, valid loss-0.2285, acc-0.9340, test loss-0.2395, acc-0.9320\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-84140, train loss-0.2435, acc-0.9400, valid loss-0.2286, acc-0.9342, test loss-0.2395, acc-0.9320\n",
      "Iter-84150, train loss-0.2379, acc-0.9600, valid loss-0.2286, acc-0.9344, test loss-0.2395, acc-0.9319\n",
      "Iter-84160, train loss-0.1637, acc-0.9600, valid loss-0.2285, acc-0.9340, test loss-0.2395, acc-0.9319\n",
      "Iter-84170, train loss-0.3888, acc-0.9200, valid loss-0.2285, acc-0.9338, test loss-0.2395, acc-0.9319\n",
      "Iter-84180, train loss-0.1674, acc-0.9400, valid loss-0.2285, acc-0.9338, test loss-0.2395, acc-0.9316\n",
      "Iter-84190, train loss-0.2600, acc-0.9200, valid loss-0.2285, acc-0.9338, test loss-0.2395, acc-0.9318\n",
      "Iter-84200, train loss-0.3438, acc-0.9000, valid loss-0.2285, acc-0.9338, test loss-0.2395, acc-0.9317\n",
      "Iter-84210, train loss-0.1524, acc-0.9800, valid loss-0.2286, acc-0.9338, test loss-0.2395, acc-0.9318\n",
      "Iter-84220, train loss-0.2796, acc-0.8800, valid loss-0.2285, acc-0.9338, test loss-0.2395, acc-0.9319\n",
      "Iter-84230, train loss-0.1627, acc-0.9600, valid loss-0.2285, acc-0.9340, test loss-0.2394, acc-0.9319\n",
      "Iter-84240, train loss-0.1593, acc-0.9400, valid loss-0.2285, acc-0.9338, test loss-0.2394, acc-0.9318\n",
      "Iter-84250, train loss-0.1705, acc-0.9600, valid loss-0.2285, acc-0.9336, test loss-0.2394, acc-0.9317\n",
      "Iter-84260, train loss-0.1531, acc-0.9800, valid loss-0.2285, acc-0.9338, test loss-0.2394, acc-0.9320\n",
      "Iter-84270, train loss-0.2576, acc-0.9200, valid loss-0.2286, acc-0.9336, test loss-0.2394, acc-0.9319\n",
      "Iter-84280, train loss-0.2366, acc-0.9200, valid loss-0.2286, acc-0.9336, test loss-0.2394, acc-0.9320\n",
      "Iter-84290, train loss-0.4071, acc-0.8800, valid loss-0.2286, acc-0.9336, test loss-0.2394, acc-0.9319\n",
      "Iter-84300, train loss-0.1457, acc-0.9800, valid loss-0.2286, acc-0.9338, test loss-0.2394, acc-0.9319\n",
      "Iter-84310, train loss-0.3089, acc-0.9600, valid loss-0.2286, acc-0.9336, test loss-0.2393, acc-0.9319\n",
      "Iter-84320, train loss-0.3814, acc-0.8800, valid loss-0.2285, acc-0.9340, test loss-0.2393, acc-0.9320\n",
      "Iter-84330, train loss-0.1496, acc-0.9800, valid loss-0.2286, acc-0.9338, test loss-0.2393, acc-0.9320\n",
      "Iter-84340, train loss-0.0936, acc-1.0000, valid loss-0.2286, acc-0.9340, test loss-0.2393, acc-0.9321\n",
      "Iter-84350, train loss-0.4254, acc-0.8600, valid loss-0.2285, acc-0.9342, test loss-0.2393, acc-0.9323\n",
      "Iter-84360, train loss-0.2683, acc-0.9000, valid loss-0.2286, acc-0.9342, test loss-0.2392, acc-0.9322\n",
      "Iter-84370, train loss-0.3036, acc-0.8600, valid loss-0.2286, acc-0.9344, test loss-0.2392, acc-0.9323\n",
      "Iter-84380, train loss-0.3500, acc-0.9200, valid loss-0.2286, acc-0.9342, test loss-0.2392, acc-0.9324\n",
      "Iter-84390, train loss-0.0811, acc-0.9800, valid loss-0.2286, acc-0.9342, test loss-0.2392, acc-0.9325\n",
      "Iter-84400, train loss-0.3295, acc-0.8600, valid loss-0.2285, acc-0.9344, test loss-0.2392, acc-0.9322\n",
      "Iter-84410, train loss-0.1068, acc-0.9800, valid loss-0.2285, acc-0.9342, test loss-0.2392, acc-0.9320\n",
      "Iter-84420, train loss-0.1475, acc-0.9600, valid loss-0.2285, acc-0.9342, test loss-0.2392, acc-0.9321\n",
      "Iter-84430, train loss-0.3272, acc-0.8800, valid loss-0.2285, acc-0.9342, test loss-0.2392, acc-0.9320\n",
      "Iter-84440, train loss-0.1287, acc-0.9600, valid loss-0.2285, acc-0.9342, test loss-0.2392, acc-0.9318\n",
      "Iter-84450, train loss-0.2001, acc-0.9400, valid loss-0.2286, acc-0.9342, test loss-0.2392, acc-0.9321\n",
      "Iter-84460, train loss-0.1417, acc-0.9600, valid loss-0.2286, acc-0.9342, test loss-0.2393, acc-0.9319\n",
      "Iter-84470, train loss-0.2934, acc-0.9400, valid loss-0.2286, acc-0.9340, test loss-0.2392, acc-0.9320\n",
      "Iter-84480, train loss-0.0805, acc-1.0000, valid loss-0.2286, acc-0.9336, test loss-0.2392, acc-0.9318\n",
      "Iter-84490, train loss-0.1208, acc-0.9800, valid loss-0.2286, acc-0.9338, test loss-0.2392, acc-0.9318\n",
      "Iter-84500, train loss-0.3724, acc-0.9000, valid loss-0.2286, acc-0.9338, test loss-0.2392, acc-0.9317\n",
      "Iter-84510, train loss-0.1859, acc-0.9000, valid loss-0.2285, acc-0.9340, test loss-0.2391, acc-0.9319\n",
      "Iter-84520, train loss-0.2323, acc-0.9800, valid loss-0.2285, acc-0.9340, test loss-0.2391, acc-0.9320\n",
      "Iter-84530, train loss-0.2449, acc-0.9200, valid loss-0.2285, acc-0.9338, test loss-0.2390, acc-0.9321\n",
      "Iter-84540, train loss-0.3605, acc-0.9000, valid loss-0.2285, acc-0.9338, test loss-0.2390, acc-0.9319\n",
      "Iter-84550, train loss-0.2921, acc-0.8800, valid loss-0.2285, acc-0.9342, test loss-0.2390, acc-0.9320\n",
      "Iter-84560, train loss-0.1700, acc-0.9600, valid loss-0.2285, acc-0.9346, test loss-0.2390, acc-0.9320\n",
      "Iter-84570, train loss-0.2851, acc-0.9200, valid loss-0.2285, acc-0.9346, test loss-0.2390, acc-0.9321\n",
      "Iter-84580, train loss-0.2537, acc-0.9200, valid loss-0.2285, acc-0.9344, test loss-0.2390, acc-0.9323\n",
      "Iter-84590, train loss-0.2023, acc-0.9200, valid loss-0.2284, acc-0.9346, test loss-0.2389, acc-0.9323\n",
      "Iter-84600, train loss-0.1377, acc-0.9800, valid loss-0.2285, acc-0.9346, test loss-0.2389, acc-0.9323\n",
      "Iter-84610, train loss-0.2243, acc-0.9200, valid loss-0.2285, acc-0.9344, test loss-0.2389, acc-0.9324\n",
      "Iter-84620, train loss-0.1616, acc-0.9600, valid loss-0.2285, acc-0.9344, test loss-0.2389, acc-0.9325\n",
      "Iter-84630, train loss-0.1913, acc-0.9200, valid loss-0.2284, acc-0.9348, test loss-0.2389, acc-0.9325\n",
      "Iter-84640, train loss-0.3470, acc-0.9200, valid loss-0.2285, acc-0.9346, test loss-0.2389, acc-0.9327\n",
      "Iter-84650, train loss-0.1027, acc-0.9800, valid loss-0.2285, acc-0.9348, test loss-0.2389, acc-0.9326\n",
      "Iter-84660, train loss-0.1839, acc-0.9800, valid loss-0.2284, acc-0.9340, test loss-0.2388, acc-0.9326\n",
      "Iter-84670, train loss-0.1276, acc-0.9800, valid loss-0.2284, acc-0.9342, test loss-0.2388, acc-0.9324\n",
      "Iter-84680, train loss-0.4395, acc-0.9200, valid loss-0.2283, acc-0.9346, test loss-0.2387, acc-0.9323\n",
      "Iter-84690, train loss-0.2347, acc-0.9400, valid loss-0.2283, acc-0.9346, test loss-0.2387, acc-0.9322\n",
      "Iter-84700, train loss-0.2998, acc-0.9000, valid loss-0.2282, acc-0.9352, test loss-0.2388, acc-0.9321\n",
      "Iter-84710, train loss-0.2740, acc-0.8600, valid loss-0.2283, acc-0.9346, test loss-0.2388, acc-0.9322\n",
      "Iter-84720, train loss-0.1569, acc-0.9600, valid loss-0.2283, acc-0.9348, test loss-0.2388, acc-0.9321\n",
      "Iter-84730, train loss-0.1715, acc-0.9800, valid loss-0.2283, acc-0.9350, test loss-0.2387, acc-0.9322\n",
      "Iter-84740, train loss-0.3124, acc-0.9200, valid loss-0.2283, acc-0.9348, test loss-0.2387, acc-0.9322\n",
      "Iter-84750, train loss-0.1131, acc-0.9800, valid loss-0.2282, acc-0.9348, test loss-0.2387, acc-0.9324\n",
      "Iter-84760, train loss-0.1981, acc-0.9400, valid loss-0.2282, acc-0.9348, test loss-0.2387, acc-0.9323\n",
      "Iter-84770, train loss-0.1288, acc-0.9600, valid loss-0.2282, acc-0.9348, test loss-0.2387, acc-0.9323\n",
      "Iter-84780, train loss-0.0988, acc-0.9800, valid loss-0.2281, acc-0.9346, test loss-0.2387, acc-0.9319\n",
      "Iter-84790, train loss-0.2047, acc-0.9600, valid loss-0.2281, acc-0.9348, test loss-0.2388, acc-0.9322\n",
      "Iter-84800, train loss-0.2217, acc-0.9400, valid loss-0.2281, acc-0.9346, test loss-0.2387, acc-0.9322\n",
      "Iter-84810, train loss-0.1804, acc-0.9400, valid loss-0.2280, acc-0.9348, test loss-0.2387, acc-0.9322\n",
      "Iter-84820, train loss-0.3803, acc-0.9200, valid loss-0.2280, acc-0.9354, test loss-0.2387, acc-0.9322\n",
      "Iter-84830, train loss-0.2134, acc-0.9400, valid loss-0.2280, acc-0.9352, test loss-0.2388, acc-0.9323\n",
      "Iter-84840, train loss-0.2489, acc-0.9400, valid loss-0.2280, acc-0.9348, test loss-0.2387, acc-0.9323\n",
      "Iter-84850, train loss-0.2503, acc-0.9200, valid loss-0.2280, acc-0.9348, test loss-0.2388, acc-0.9325\n",
      "Iter-84860, train loss-0.1920, acc-0.9200, valid loss-0.2279, acc-0.9350, test loss-0.2387, acc-0.9325\n",
      "Iter-84870, train loss-0.2830, acc-0.9000, valid loss-0.2279, acc-0.9352, test loss-0.2387, acc-0.9324\n",
      "Iter-84880, train loss-0.1598, acc-0.9600, valid loss-0.2279, acc-0.9352, test loss-0.2387, acc-0.9323\n",
      "Iter-84890, train loss-0.1874, acc-0.9400, valid loss-0.2280, acc-0.9348, test loss-0.2387, acc-0.9325\n",
      "Iter-84900, train loss-0.2894, acc-0.9200, valid loss-0.2279, acc-0.9350, test loss-0.2386, acc-0.9326\n",
      "Iter-84910, train loss-0.4426, acc-0.8600, valid loss-0.2278, acc-0.9346, test loss-0.2386, acc-0.9324\n",
      "Iter-84920, train loss-0.1922, acc-0.9200, valid loss-0.2279, acc-0.9348, test loss-0.2386, acc-0.9327\n",
      "Iter-84930, train loss-0.1097, acc-1.0000, valid loss-0.2278, acc-0.9348, test loss-0.2386, acc-0.9326\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-84940, train loss-0.2654, acc-0.9000, valid loss-0.2277, acc-0.9348, test loss-0.2386, acc-0.9324\n",
      "Iter-84950, train loss-0.2622, acc-0.9200, valid loss-0.2277, acc-0.9350, test loss-0.2386, acc-0.9324\n",
      "Iter-84960, train loss-0.1827, acc-0.9600, valid loss-0.2277, acc-0.9350, test loss-0.2386, acc-0.9324\n",
      "Iter-84970, train loss-0.1993, acc-0.9400, valid loss-0.2277, acc-0.9352, test loss-0.2386, acc-0.9325\n",
      "Iter-84980, train loss-0.2924, acc-0.9400, valid loss-0.2277, acc-0.9352, test loss-0.2386, acc-0.9322\n",
      "Iter-84990, train loss-0.2827, acc-0.9200, valid loss-0.2277, acc-0.9354, test loss-0.2386, acc-0.9322\n",
      "Iter-85000, train loss-0.1692, acc-0.9400, valid loss-0.2277, acc-0.9354, test loss-0.2385, acc-0.9325\n",
      "Iter-85010, train loss-0.3125, acc-0.9400, valid loss-0.2276, acc-0.9348, test loss-0.2385, acc-0.9327\n",
      "Iter-85020, train loss-0.2266, acc-0.9200, valid loss-0.2276, acc-0.9354, test loss-0.2385, acc-0.9325\n",
      "Iter-85030, train loss-0.3217, acc-0.9200, valid loss-0.2275, acc-0.9352, test loss-0.2384, acc-0.9322\n",
      "Iter-85040, train loss-0.2022, acc-0.9400, valid loss-0.2275, acc-0.9352, test loss-0.2384, acc-0.9322\n",
      "Iter-85050, train loss-0.1595, acc-0.9600, valid loss-0.2275, acc-0.9344, test loss-0.2384, acc-0.9324\n",
      "Iter-85060, train loss-0.2060, acc-0.9600, valid loss-0.2275, acc-0.9348, test loss-0.2385, acc-0.9323\n",
      "Iter-85070, train loss-0.1267, acc-0.9800, valid loss-0.2275, acc-0.9346, test loss-0.2385, acc-0.9325\n",
      "Iter-85080, train loss-0.1893, acc-0.9200, valid loss-0.2275, acc-0.9352, test loss-0.2385, acc-0.9324\n",
      "Iter-85090, train loss-0.1101, acc-0.9800, valid loss-0.2275, acc-0.9350, test loss-0.2385, acc-0.9325\n",
      "Iter-85100, train loss-0.2234, acc-0.9200, valid loss-0.2274, acc-0.9352, test loss-0.2384, acc-0.9327\n",
      "Iter-85110, train loss-0.1413, acc-0.9600, valid loss-0.2275, acc-0.9356, test loss-0.2385, acc-0.9327\n",
      "Iter-85120, train loss-0.1689, acc-0.9400, valid loss-0.2275, acc-0.9354, test loss-0.2385, acc-0.9328\n",
      "Iter-85130, train loss-0.1245, acc-0.9800, valid loss-0.2274, acc-0.9354, test loss-0.2384, acc-0.9325\n",
      "Iter-85140, train loss-0.1591, acc-0.9400, valid loss-0.2274, acc-0.9350, test loss-0.2384, acc-0.9325\n",
      "Iter-85150, train loss-0.1132, acc-0.9800, valid loss-0.2274, acc-0.9348, test loss-0.2384, acc-0.9325\n",
      "Iter-85160, train loss-0.2331, acc-0.9800, valid loss-0.2275, acc-0.9350, test loss-0.2384, acc-0.9325\n",
      "Iter-85170, train loss-0.1022, acc-0.9800, valid loss-0.2274, acc-0.9346, test loss-0.2384, acc-0.9327\n",
      "Iter-85180, train loss-0.2048, acc-0.9600, valid loss-0.2275, acc-0.9346, test loss-0.2383, acc-0.9329\n",
      "Iter-85190, train loss-0.3535, acc-0.8600, valid loss-0.2275, acc-0.9346, test loss-0.2383, acc-0.9331\n",
      "Iter-85200, train loss-0.1331, acc-0.9600, valid loss-0.2275, acc-0.9346, test loss-0.2383, acc-0.9326\n",
      "Iter-85210, train loss-0.2190, acc-0.9400, valid loss-0.2275, acc-0.9348, test loss-0.2382, acc-0.9331\n",
      "Iter-85220, train loss-0.2696, acc-0.9000, valid loss-0.2275, acc-0.9348, test loss-0.2382, acc-0.9330\n",
      "Iter-85230, train loss-0.1544, acc-0.9600, valid loss-0.2274, acc-0.9346, test loss-0.2382, acc-0.9329\n",
      "Iter-85240, train loss-0.1595, acc-0.9200, valid loss-0.2273, acc-0.9348, test loss-0.2382, acc-0.9328\n",
      "Iter-85250, train loss-0.2233, acc-0.9200, valid loss-0.2273, acc-0.9350, test loss-0.2382, acc-0.9327\n",
      "Iter-85260, train loss-0.1505, acc-0.9600, valid loss-0.2273, acc-0.9348, test loss-0.2382, acc-0.9329\n",
      "Iter-85270, train loss-0.4297, acc-0.8800, valid loss-0.2273, acc-0.9356, test loss-0.2382, acc-0.9328\n",
      "Iter-85280, train loss-0.3668, acc-0.9000, valid loss-0.2272, acc-0.9352, test loss-0.2382, acc-0.9329\n",
      "Iter-85290, train loss-0.2465, acc-0.9400, valid loss-0.2272, acc-0.9348, test loss-0.2382, acc-0.9328\n",
      "Iter-85300, train loss-0.1378, acc-0.9800, valid loss-0.2272, acc-0.9350, test loss-0.2381, acc-0.9327\n",
      "Iter-85310, train loss-0.3081, acc-0.8800, valid loss-0.2272, acc-0.9350, test loss-0.2380, acc-0.9326\n",
      "Iter-85320, train loss-0.1654, acc-0.9400, valid loss-0.2272, acc-0.9350, test loss-0.2380, acc-0.9326\n",
      "Iter-85330, train loss-0.2489, acc-0.9400, valid loss-0.2272, acc-0.9348, test loss-0.2380, acc-0.9325\n",
      "Iter-85340, train loss-0.3431, acc-0.8600, valid loss-0.2271, acc-0.9350, test loss-0.2379, acc-0.9327\n",
      "Iter-85350, train loss-0.2445, acc-0.9000, valid loss-0.2271, acc-0.9350, test loss-0.2379, acc-0.9326\n",
      "Iter-85360, train loss-0.3695, acc-0.8600, valid loss-0.2271, acc-0.9352, test loss-0.2379, acc-0.9323\n",
      "Iter-85370, train loss-0.2789, acc-0.9400, valid loss-0.2271, acc-0.9352, test loss-0.2379, acc-0.9324\n",
      "Iter-85380, train loss-0.1508, acc-0.9600, valid loss-0.2270, acc-0.9352, test loss-0.2379, acc-0.9322\n",
      "Iter-85390, train loss-0.1515, acc-0.9800, valid loss-0.2270, acc-0.9356, test loss-0.2378, acc-0.9324\n",
      "Iter-85400, train loss-0.2663, acc-0.9200, valid loss-0.2270, acc-0.9354, test loss-0.2379, acc-0.9322\n",
      "Iter-85410, train loss-0.3819, acc-0.8800, valid loss-0.2269, acc-0.9352, test loss-0.2378, acc-0.9324\n",
      "Iter-85420, train loss-0.5426, acc-0.8600, valid loss-0.2269, acc-0.9352, test loss-0.2378, acc-0.9326\n",
      "Iter-85430, train loss-0.5079, acc-0.8400, valid loss-0.2269, acc-0.9352, test loss-0.2378, acc-0.9326\n",
      "Iter-85440, train loss-0.1295, acc-0.9600, valid loss-0.2270, acc-0.9354, test loss-0.2378, acc-0.9327\n",
      "Iter-85450, train loss-0.2998, acc-0.9000, valid loss-0.2270, acc-0.9352, test loss-0.2378, acc-0.9326\n",
      "Iter-85460, train loss-0.2388, acc-0.9000, valid loss-0.2269, acc-0.9356, test loss-0.2378, acc-0.9326\n",
      "Iter-85470, train loss-0.1786, acc-0.9400, valid loss-0.2269, acc-0.9354, test loss-0.2377, acc-0.9328\n",
      "Iter-85480, train loss-0.1435, acc-0.9600, valid loss-0.2269, acc-0.9354, test loss-0.2377, acc-0.9328\n",
      "Iter-85490, train loss-0.1390, acc-0.9400, valid loss-0.2269, acc-0.9356, test loss-0.2377, acc-0.9327\n",
      "Iter-85500, train loss-0.5426, acc-0.8600, valid loss-0.2269, acc-0.9354, test loss-0.2377, acc-0.9326\n",
      "Iter-85510, train loss-0.2160, acc-0.9400, valid loss-0.2268, acc-0.9354, test loss-0.2377, acc-0.9327\n",
      "Iter-85520, train loss-0.2864, acc-0.9600, valid loss-0.2268, acc-0.9354, test loss-0.2377, acc-0.9328\n",
      "Iter-85530, train loss-0.3905, acc-0.8800, valid loss-0.2268, acc-0.9354, test loss-0.2377, acc-0.9328\n",
      "Iter-85540, train loss-0.3090, acc-0.9200, valid loss-0.2267, acc-0.9352, test loss-0.2377, acc-0.9328\n",
      "Iter-85550, train loss-0.2262, acc-0.9600, valid loss-0.2267, acc-0.9354, test loss-0.2377, acc-0.9326\n",
      "Iter-85560, train loss-0.1897, acc-0.9600, valid loss-0.2268, acc-0.9356, test loss-0.2376, acc-0.9327\n",
      "Iter-85570, train loss-0.2019, acc-0.9000, valid loss-0.2267, acc-0.9354, test loss-0.2376, acc-0.9333\n",
      "Iter-85580, train loss-0.1342, acc-0.9600, valid loss-0.2267, acc-0.9358, test loss-0.2376, acc-0.9330\n",
      "Iter-85590, train loss-0.1872, acc-0.9200, valid loss-0.2267, acc-0.9356, test loss-0.2376, acc-0.9327\n",
      "Iter-85600, train loss-0.1809, acc-0.9200, valid loss-0.2267, acc-0.9356, test loss-0.2376, acc-0.9329\n",
      "Iter-85610, train loss-0.2415, acc-0.9800, valid loss-0.2267, acc-0.9354, test loss-0.2375, acc-0.9331\n",
      "Iter-85620, train loss-0.1535, acc-0.9600, valid loss-0.2267, acc-0.9358, test loss-0.2375, acc-0.9327\n",
      "Iter-85630, train loss-0.1175, acc-0.9800, valid loss-0.2267, acc-0.9358, test loss-0.2374, acc-0.9325\n",
      "Iter-85640, train loss-0.2910, acc-0.8800, valid loss-0.2266, acc-0.9356, test loss-0.2374, acc-0.9325\n",
      "Iter-85650, train loss-0.3958, acc-0.9200, valid loss-0.2266, acc-0.9358, test loss-0.2374, acc-0.9325\n",
      "Iter-85660, train loss-0.1903, acc-0.9400, valid loss-0.2266, acc-0.9358, test loss-0.2374, acc-0.9327\n",
      "Iter-85670, train loss-0.3853, acc-0.8400, valid loss-0.2267, acc-0.9360, test loss-0.2374, acc-0.9329\n",
      "Iter-85680, train loss-0.3658, acc-0.8600, valid loss-0.2266, acc-0.9360, test loss-0.2374, acc-0.9329\n",
      "Iter-85690, train loss-0.3424, acc-0.8800, valid loss-0.2266, acc-0.9362, test loss-0.2374, acc-0.9328\n",
      "Iter-85700, train loss-0.1425, acc-0.9600, valid loss-0.2266, acc-0.9360, test loss-0.2374, acc-0.9326\n",
      "Iter-85710, train loss-0.3762, acc-0.9000, valid loss-0.2266, acc-0.9360, test loss-0.2374, acc-0.9327\n",
      "Iter-85720, train loss-0.2611, acc-0.9200, valid loss-0.2265, acc-0.9360, test loss-0.2374, acc-0.9326\n",
      "Iter-85730, train loss-0.1177, acc-0.9800, valid loss-0.2265, acc-0.9360, test loss-0.2374, acc-0.9324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-85740, train loss-0.2243, acc-0.9200, valid loss-0.2266, acc-0.9362, test loss-0.2374, acc-0.9327\n",
      "Iter-85750, train loss-0.1767, acc-0.9600, valid loss-0.2266, acc-0.9364, test loss-0.2374, acc-0.9326\n",
      "Iter-85760, train loss-0.2549, acc-0.9200, valid loss-0.2266, acc-0.9358, test loss-0.2374, acc-0.9323\n",
      "Iter-85770, train loss-0.3690, acc-0.9200, valid loss-0.2266, acc-0.9358, test loss-0.2374, acc-0.9329\n",
      "Iter-85780, train loss-0.1688, acc-0.9400, valid loss-0.2266, acc-0.9358, test loss-0.2374, acc-0.9325\n",
      "Iter-85790, train loss-0.2655, acc-0.8800, valid loss-0.2266, acc-0.9362, test loss-0.2374, acc-0.9324\n",
      "Iter-85800, train loss-0.4723, acc-0.9000, valid loss-0.2266, acc-0.9358, test loss-0.2373, acc-0.9328\n",
      "Iter-85810, train loss-0.2619, acc-0.8800, valid loss-0.2266, acc-0.9356, test loss-0.2373, acc-0.9327\n",
      "Iter-85820, train loss-0.1645, acc-0.9400, valid loss-0.2266, acc-0.9356, test loss-0.2373, acc-0.9330\n",
      "Iter-85830, train loss-0.2502, acc-0.9000, valid loss-0.2266, acc-0.9360, test loss-0.2373, acc-0.9327\n",
      "Iter-85840, train loss-0.1900, acc-0.9200, valid loss-0.2266, acc-0.9360, test loss-0.2373, acc-0.9328\n",
      "Iter-85850, train loss-0.5041, acc-0.8200, valid loss-0.2266, acc-0.9360, test loss-0.2373, acc-0.9326\n",
      "Iter-85860, train loss-0.2154, acc-0.9400, valid loss-0.2266, acc-0.9360, test loss-0.2373, acc-0.9330\n",
      "Iter-85870, train loss-0.2901, acc-0.9000, valid loss-0.2266, acc-0.9360, test loss-0.2373, acc-0.9326\n",
      "Iter-85880, train loss-0.1134, acc-0.9800, valid loss-0.2265, acc-0.9360, test loss-0.2373, acc-0.9325\n",
      "Iter-85890, train loss-0.2017, acc-0.9800, valid loss-0.2265, acc-0.9364, test loss-0.2373, acc-0.9328\n",
      "Iter-85900, train loss-0.3870, acc-0.8800, valid loss-0.2264, acc-0.9366, test loss-0.2372, acc-0.9330\n",
      "Iter-85910, train loss-0.1734, acc-0.9400, valid loss-0.2264, acc-0.9364, test loss-0.2372, acc-0.9328\n",
      "Iter-85920, train loss-0.1924, acc-0.9200, valid loss-0.2264, acc-0.9362, test loss-0.2372, acc-0.9325\n",
      "Iter-85930, train loss-0.3852, acc-0.9000, valid loss-0.2264, acc-0.9364, test loss-0.2372, acc-0.9327\n",
      "Iter-85940, train loss-0.2378, acc-0.9400, valid loss-0.2264, acc-0.9366, test loss-0.2372, acc-0.9328\n",
      "Iter-85950, train loss-0.4390, acc-0.9200, valid loss-0.2264, acc-0.9364, test loss-0.2372, acc-0.9326\n",
      "Iter-85960, train loss-0.1110, acc-0.9600, valid loss-0.2264, acc-0.9362, test loss-0.2372, acc-0.9326\n",
      "Iter-85970, train loss-0.1097, acc-0.9800, valid loss-0.2264, acc-0.9364, test loss-0.2372, acc-0.9326\n",
      "Iter-85980, train loss-0.4781, acc-0.8600, valid loss-0.2264, acc-0.9364, test loss-0.2371, acc-0.9328\n",
      "Iter-85990, train loss-0.2177, acc-0.9200, valid loss-0.2264, acc-0.9370, test loss-0.2371, acc-0.9329\n",
      "Iter-86000, train loss-0.1257, acc-0.9600, valid loss-0.2264, acc-0.9368, test loss-0.2371, acc-0.9329\n",
      "Iter-86010, train loss-0.2389, acc-0.9400, valid loss-0.2264, acc-0.9366, test loss-0.2371, acc-0.9329\n",
      "Iter-86020, train loss-0.0967, acc-0.9800, valid loss-0.2264, acc-0.9366, test loss-0.2370, acc-0.9331\n",
      "Iter-86030, train loss-0.0886, acc-0.9800, valid loss-0.2264, acc-0.9364, test loss-0.2370, acc-0.9330\n",
      "Iter-86040, train loss-0.1718, acc-0.9400, valid loss-0.2264, acc-0.9364, test loss-0.2370, acc-0.9330\n",
      "Iter-86050, train loss-0.1143, acc-0.9600, valid loss-0.2264, acc-0.9364, test loss-0.2370, acc-0.9330\n",
      "Iter-86060, train loss-0.1956, acc-0.9400, valid loss-0.2264, acc-0.9362, test loss-0.2369, acc-0.9331\n",
      "Iter-86070, train loss-0.2369, acc-0.9400, valid loss-0.2264, acc-0.9364, test loss-0.2369, acc-0.9330\n",
      "Iter-86080, train loss-0.4621, acc-0.8200, valid loss-0.2265, acc-0.9368, test loss-0.2369, acc-0.9330\n",
      "Iter-86090, train loss-0.2873, acc-0.9400, valid loss-0.2265, acc-0.9360, test loss-0.2369, acc-0.9330\n",
      "Iter-86100, train loss-0.1767, acc-0.9000, valid loss-0.2265, acc-0.9348, test loss-0.2369, acc-0.9329\n",
      "Iter-86110, train loss-0.1271, acc-0.9600, valid loss-0.2265, acc-0.9352, test loss-0.2369, acc-0.9330\n",
      "Iter-86120, train loss-0.2691, acc-0.9400, valid loss-0.2265, acc-0.9352, test loss-0.2369, acc-0.9329\n",
      "Iter-86130, train loss-0.1531, acc-0.9800, valid loss-0.2264, acc-0.9354, test loss-0.2369, acc-0.9330\n",
      "Iter-86140, train loss-0.1896, acc-0.9000, valid loss-0.2264, acc-0.9352, test loss-0.2369, acc-0.9327\n",
      "Iter-86150, train loss-0.2544, acc-0.9000, valid loss-0.2264, acc-0.9354, test loss-0.2369, acc-0.9329\n",
      "Iter-86160, train loss-0.3120, acc-0.9400, valid loss-0.2264, acc-0.9356, test loss-0.2368, acc-0.9330\n",
      "Iter-86170, train loss-0.1873, acc-0.9400, valid loss-0.2264, acc-0.9360, test loss-0.2369, acc-0.9329\n",
      "Iter-86180, train loss-0.1928, acc-0.9400, valid loss-0.2264, acc-0.9362, test loss-0.2368, acc-0.9331\n",
      "Iter-86190, train loss-0.3495, acc-0.9000, valid loss-0.2263, acc-0.9362, test loss-0.2368, acc-0.9331\n",
      "Iter-86200, train loss-0.1119, acc-0.9600, valid loss-0.2263, acc-0.9358, test loss-0.2368, acc-0.9330\n",
      "Iter-86210, train loss-0.1520, acc-0.9400, valid loss-0.2263, acc-0.9360, test loss-0.2368, acc-0.9331\n",
      "Iter-86220, train loss-0.1783, acc-0.9600, valid loss-0.2263, acc-0.9358, test loss-0.2367, acc-0.9332\n",
      "Iter-86230, train loss-0.3097, acc-0.8600, valid loss-0.2263, acc-0.9360, test loss-0.2367, acc-0.9330\n",
      "Iter-86240, train loss-0.1888, acc-0.9800, valid loss-0.2262, acc-0.9360, test loss-0.2367, acc-0.9329\n",
      "Iter-86250, train loss-0.2260, acc-0.9400, valid loss-0.2262, acc-0.9360, test loss-0.2366, acc-0.9330\n",
      "Iter-86260, train loss-0.2090, acc-0.9400, valid loss-0.2262, acc-0.9360, test loss-0.2366, acc-0.9331\n",
      "Iter-86270, train loss-0.1419, acc-0.9600, valid loss-0.2262, acc-0.9362, test loss-0.2366, acc-0.9331\n",
      "Iter-86280, train loss-0.1852, acc-0.9400, valid loss-0.2262, acc-0.9358, test loss-0.2366, acc-0.9330\n",
      "Iter-86290, train loss-0.2142, acc-0.9600, valid loss-0.2261, acc-0.9366, test loss-0.2366, acc-0.9333\n",
      "Iter-86300, train loss-0.1598, acc-0.9600, valid loss-0.2261, acc-0.9360, test loss-0.2366, acc-0.9333\n",
      "Iter-86310, train loss-0.2724, acc-0.9400, valid loss-0.2260, acc-0.9362, test loss-0.2365, acc-0.9330\n",
      "Iter-86320, train loss-0.1382, acc-0.9800, valid loss-0.2260, acc-0.9358, test loss-0.2365, acc-0.9333\n",
      "Iter-86330, train loss-0.0956, acc-0.9800, valid loss-0.2261, acc-0.9354, test loss-0.2366, acc-0.9331\n",
      "Iter-86340, train loss-0.1093, acc-0.9800, valid loss-0.2260, acc-0.9356, test loss-0.2365, acc-0.9332\n",
      "Iter-86350, train loss-0.3289, acc-0.9200, valid loss-0.2260, acc-0.9360, test loss-0.2365, acc-0.9333\n",
      "Iter-86360, train loss-0.1870, acc-0.9200, valid loss-0.2260, acc-0.9358, test loss-0.2365, acc-0.9334\n",
      "Iter-86370, train loss-0.2372, acc-0.9400, valid loss-0.2259, acc-0.9356, test loss-0.2365, acc-0.9334\n",
      "Iter-86380, train loss-0.1757, acc-0.9400, valid loss-0.2259, acc-0.9350, test loss-0.2365, acc-0.9334\n",
      "Iter-86390, train loss-0.1807, acc-0.9400, valid loss-0.2259, acc-0.9356, test loss-0.2365, acc-0.9333\n",
      "Iter-86400, train loss-0.2348, acc-0.9200, valid loss-0.2259, acc-0.9358, test loss-0.2365, acc-0.9335\n",
      "Iter-86410, train loss-0.1810, acc-0.9200, valid loss-0.2260, acc-0.9358, test loss-0.2365, acc-0.9334\n",
      "Iter-86420, train loss-0.2932, acc-0.9200, valid loss-0.2259, acc-0.9356, test loss-0.2365, acc-0.9333\n",
      "Iter-86430, train loss-0.1720, acc-0.9600, valid loss-0.2259, acc-0.9356, test loss-0.2364, acc-0.9333\n",
      "Iter-86440, train loss-0.2212, acc-0.9000, valid loss-0.2259, acc-0.9354, test loss-0.2364, acc-0.9333\n",
      "Iter-86450, train loss-0.2781, acc-0.9000, valid loss-0.2259, acc-0.9354, test loss-0.2364, acc-0.9332\n",
      "Iter-86460, train loss-0.1454, acc-0.9600, valid loss-0.2259, acc-0.9358, test loss-0.2364, acc-0.9332\n",
      "Iter-86470, train loss-0.1707, acc-0.9400, valid loss-0.2259, acc-0.9358, test loss-0.2364, acc-0.9332\n",
      "Iter-86480, train loss-0.1613, acc-0.9400, valid loss-0.2259, acc-0.9356, test loss-0.2365, acc-0.9332\n",
      "Iter-86490, train loss-0.0693, acc-1.0000, valid loss-0.2259, acc-0.9358, test loss-0.2364, acc-0.9334\n",
      "Iter-86500, train loss-0.1681, acc-0.9600, valid loss-0.2259, acc-0.9358, test loss-0.2365, acc-0.9332\n",
      "Iter-86510, train loss-0.2259, acc-0.9800, valid loss-0.2259, acc-0.9358, test loss-0.2365, acc-0.9333\n",
      "Iter-86520, train loss-0.3540, acc-0.8800, valid loss-0.2259, acc-0.9354, test loss-0.2364, acc-0.9332\n",
      "Iter-86530, train loss-0.1778, acc-0.9000, valid loss-0.2260, acc-0.9354, test loss-0.2364, acc-0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-86540, train loss-0.1058, acc-0.9800, valid loss-0.2260, acc-0.9356, test loss-0.2364, acc-0.9332\n",
      "Iter-86550, train loss-0.2343, acc-0.9200, valid loss-0.2260, acc-0.9358, test loss-0.2364, acc-0.9333\n",
      "Iter-86560, train loss-0.0865, acc-0.9800, valid loss-0.2259, acc-0.9358, test loss-0.2364, acc-0.9334\n",
      "Iter-86570, train loss-0.1738, acc-0.9600, valid loss-0.2259, acc-0.9356, test loss-0.2363, acc-0.9332\n",
      "Iter-86580, train loss-0.2105, acc-0.9600, valid loss-0.2259, acc-0.9358, test loss-0.2363, acc-0.9337\n",
      "Iter-86590, train loss-0.1917, acc-0.9600, valid loss-0.2259, acc-0.9358, test loss-0.2364, acc-0.9335\n",
      "Iter-86600, train loss-0.4517, acc-0.8400, valid loss-0.2259, acc-0.9356, test loss-0.2364, acc-0.9332\n",
      "Iter-86610, train loss-0.2198, acc-0.9400, valid loss-0.2259, acc-0.9354, test loss-0.2363, acc-0.9335\n",
      "Iter-86620, train loss-0.1582, acc-0.9800, valid loss-0.2258, acc-0.9354, test loss-0.2363, acc-0.9330\n",
      "Iter-86630, train loss-0.2619, acc-0.9200, valid loss-0.2258, acc-0.9358, test loss-0.2363, acc-0.9330\n",
      "Iter-86640, train loss-0.1035, acc-0.9800, valid loss-0.2257, acc-0.9358, test loss-0.2363, acc-0.9327\n",
      "Iter-86650, train loss-0.2120, acc-0.9600, valid loss-0.2258, acc-0.9360, test loss-0.2363, acc-0.9331\n",
      "Iter-86660, train loss-0.2662, acc-0.9200, valid loss-0.2257, acc-0.9358, test loss-0.2363, acc-0.9329\n",
      "Iter-86670, train loss-0.2112, acc-0.9400, valid loss-0.2257, acc-0.9356, test loss-0.2363, acc-0.9331\n",
      "Iter-86680, train loss-0.5192, acc-0.8400, valid loss-0.2257, acc-0.9358, test loss-0.2363, acc-0.9333\n",
      "Iter-86690, train loss-0.4847, acc-0.8800, valid loss-0.2257, acc-0.9356, test loss-0.2363, acc-0.9332\n",
      "Iter-86700, train loss-0.1621, acc-0.9600, valid loss-0.2257, acc-0.9358, test loss-0.2363, acc-0.9332\n",
      "Iter-86710, train loss-0.2490, acc-0.9400, valid loss-0.2257, acc-0.9358, test loss-0.2362, acc-0.9332\n",
      "Iter-86720, train loss-0.3080, acc-0.9000, valid loss-0.2256, acc-0.9360, test loss-0.2362, acc-0.9331\n",
      "Iter-86730, train loss-0.3498, acc-0.8800, valid loss-0.2255, acc-0.9364, test loss-0.2363, acc-0.9330\n",
      "Iter-86740, train loss-0.1953, acc-0.9400, valid loss-0.2256, acc-0.9362, test loss-0.2362, acc-0.9331\n",
      "Iter-86750, train loss-0.1236, acc-0.9600, valid loss-0.2256, acc-0.9360, test loss-0.2362, acc-0.9332\n",
      "Iter-86760, train loss-0.2253, acc-0.9400, valid loss-0.2256, acc-0.9358, test loss-0.2362, acc-0.9332\n",
      "Iter-86770, train loss-0.1067, acc-0.9600, valid loss-0.2256, acc-0.9358, test loss-0.2362, acc-0.9332\n",
      "Iter-86780, train loss-0.3013, acc-0.9000, valid loss-0.2256, acc-0.9356, test loss-0.2362, acc-0.9330\n",
      "Iter-86790, train loss-0.1872, acc-0.9200, valid loss-0.2256, acc-0.9356, test loss-0.2362, acc-0.9330\n",
      "Iter-86800, train loss-0.3010, acc-0.9000, valid loss-0.2257, acc-0.9356, test loss-0.2361, acc-0.9332\n",
      "Iter-86810, train loss-0.2639, acc-0.9000, valid loss-0.2257, acc-0.9352, test loss-0.2361, acc-0.9333\n",
      "Iter-86820, train loss-0.2208, acc-0.9400, valid loss-0.2257, acc-0.9354, test loss-0.2361, acc-0.9335\n",
      "Iter-86830, train loss-0.1884, acc-0.9600, valid loss-0.2257, acc-0.9354, test loss-0.2361, acc-0.9333\n",
      "Iter-86840, train loss-0.3071, acc-0.9200, valid loss-0.2257, acc-0.9356, test loss-0.2361, acc-0.9334\n",
      "Iter-86850, train loss-0.1793, acc-0.9800, valid loss-0.2258, acc-0.9354, test loss-0.2360, acc-0.9334\n",
      "Iter-86860, train loss-0.3112, acc-0.9200, valid loss-0.2258, acc-0.9354, test loss-0.2360, acc-0.9337\n",
      "Iter-86870, train loss-0.2818, acc-0.9000, valid loss-0.2257, acc-0.9354, test loss-0.2360, acc-0.9337\n",
      "Iter-86880, train loss-0.4475, acc-0.9000, valid loss-0.2258, acc-0.9352, test loss-0.2360, acc-0.9339\n",
      "Iter-86890, train loss-0.0716, acc-1.0000, valid loss-0.2258, acc-0.9356, test loss-0.2360, acc-0.9336\n",
      "Iter-86900, train loss-0.2613, acc-0.9000, valid loss-0.2258, acc-0.9352, test loss-0.2359, acc-0.9337\n",
      "Iter-86910, train loss-0.1215, acc-0.9400, valid loss-0.2258, acc-0.9354, test loss-0.2359, acc-0.9337\n",
      "Iter-86920, train loss-0.2256, acc-0.9200, valid loss-0.2257, acc-0.9354, test loss-0.2359, acc-0.9337\n",
      "Iter-86930, train loss-0.2738, acc-0.8600, valid loss-0.2256, acc-0.9356, test loss-0.2358, acc-0.9337\n",
      "Iter-86940, train loss-0.1951, acc-0.9400, valid loss-0.2256, acc-0.9356, test loss-0.2358, acc-0.9338\n",
      "Iter-86950, train loss-0.1800, acc-0.9800, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9339\n",
      "Iter-86960, train loss-0.1705, acc-0.9600, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9340\n",
      "Iter-86970, train loss-0.3719, acc-0.9200, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9340\n",
      "Iter-86980, train loss-0.3564, acc-0.9000, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9342\n",
      "Iter-86990, train loss-0.1166, acc-0.9800, valid loss-0.2256, acc-0.9354, test loss-0.2357, acc-0.9340\n",
      "Iter-87000, train loss-0.3496, acc-0.8800, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9337\n",
      "Iter-87010, train loss-0.2498, acc-0.9200, valid loss-0.2256, acc-0.9352, test loss-0.2357, acc-0.9339\n",
      "Iter-87020, train loss-0.2143, acc-0.9400, valid loss-0.2256, acc-0.9354, test loss-0.2356, acc-0.9338\n",
      "Iter-87030, train loss-0.2582, acc-0.9200, valid loss-0.2255, acc-0.9354, test loss-0.2356, acc-0.9339\n",
      "Iter-87040, train loss-0.2243, acc-0.9600, valid loss-0.2255, acc-0.9356, test loss-0.2355, acc-0.9337\n",
      "Iter-87050, train loss-0.1900, acc-0.9000, valid loss-0.2255, acc-0.9356, test loss-0.2355, acc-0.9337\n",
      "Iter-87060, train loss-0.1637, acc-0.9600, valid loss-0.2255, acc-0.9358, test loss-0.2355, acc-0.9339\n",
      "Iter-87070, train loss-0.1216, acc-0.9800, valid loss-0.2254, acc-0.9360, test loss-0.2355, acc-0.9340\n",
      "Iter-87080, train loss-0.2484, acc-0.9000, valid loss-0.2254, acc-0.9358, test loss-0.2355, acc-0.9338\n",
      "Iter-87090, train loss-0.3481, acc-0.9000, valid loss-0.2254, acc-0.9358, test loss-0.2355, acc-0.9338\n",
      "Iter-87100, train loss-0.0932, acc-0.9800, valid loss-0.2254, acc-0.9356, test loss-0.2355, acc-0.9339\n",
      "Iter-87110, train loss-0.1981, acc-0.9400, valid loss-0.2254, acc-0.9358, test loss-0.2354, acc-0.9339\n",
      "Iter-87120, train loss-0.2260, acc-0.9400, valid loss-0.2254, acc-0.9360, test loss-0.2354, acc-0.9338\n",
      "Iter-87130, train loss-0.3496, acc-0.8800, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9340\n",
      "Iter-87140, train loss-0.1249, acc-0.9600, valid loss-0.2253, acc-0.9362, test loss-0.2353, acc-0.9345\n",
      "Iter-87150, train loss-0.3958, acc-0.8800, valid loss-0.2253, acc-0.9362, test loss-0.2353, acc-0.9343\n",
      "Iter-87160, train loss-0.2516, acc-0.9400, valid loss-0.2254, acc-0.9362, test loss-0.2353, acc-0.9340\n",
      "Iter-87170, train loss-0.2715, acc-0.9200, valid loss-0.2254, acc-0.9360, test loss-0.2353, acc-0.9341\n",
      "Iter-87180, train loss-0.2410, acc-0.9000, valid loss-0.2254, acc-0.9364, test loss-0.2353, acc-0.9339\n",
      "Iter-87190, train loss-0.4941, acc-0.8400, valid loss-0.2253, acc-0.9362, test loss-0.2353, acc-0.9340\n",
      "Iter-87200, train loss-0.1812, acc-0.9800, valid loss-0.2253, acc-0.9360, test loss-0.2352, acc-0.9342\n",
      "Iter-87210, train loss-0.1901, acc-0.9800, valid loss-0.2252, acc-0.9360, test loss-0.2352, acc-0.9342\n",
      "Iter-87220, train loss-0.2997, acc-0.9200, valid loss-0.2252, acc-0.9360, test loss-0.2352, acc-0.9342\n",
      "Iter-87230, train loss-0.4034, acc-0.9000, valid loss-0.2252, acc-0.9360, test loss-0.2352, acc-0.9342\n",
      "Iter-87240, train loss-0.2111, acc-0.9200, valid loss-0.2252, acc-0.9362, test loss-0.2353, acc-0.9339\n",
      "Iter-87250, train loss-0.2249, acc-0.9400, valid loss-0.2252, acc-0.9360, test loss-0.2353, acc-0.9344\n",
      "Iter-87260, train loss-0.0932, acc-0.9800, valid loss-0.2252, acc-0.9362, test loss-0.2353, acc-0.9340\n",
      "Iter-87270, train loss-0.0932, acc-1.0000, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9344\n",
      "Iter-87280, train loss-0.2014, acc-0.9600, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9347\n",
      "Iter-87290, train loss-0.1875, acc-0.9400, valid loss-0.2253, acc-0.9360, test loss-0.2352, acc-0.9346\n",
      "Iter-87300, train loss-0.2971, acc-0.9200, valid loss-0.2253, acc-0.9358, test loss-0.2352, acc-0.9346\n",
      "Iter-87310, train loss-0.2051, acc-0.9400, valid loss-0.2253, acc-0.9362, test loss-0.2353, acc-0.9346\n",
      "Iter-87320, train loss-0.2070, acc-0.9600, valid loss-0.2253, acc-0.9358, test loss-0.2353, acc-0.9348\n",
      "Iter-87330, train loss-0.1627, acc-0.9400, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9343\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-87340, train loss-0.0731, acc-1.0000, valid loss-0.2252, acc-0.9360, test loss-0.2353, acc-0.9343\n",
      "Iter-87350, train loss-0.3099, acc-0.9000, valid loss-0.2253, acc-0.9362, test loss-0.2353, acc-0.9343\n",
      "Iter-87360, train loss-0.2806, acc-0.8800, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9341\n",
      "Iter-87370, train loss-0.1628, acc-0.9400, valid loss-0.2253, acc-0.9360, test loss-0.2353, acc-0.9344\n",
      "Iter-87380, train loss-0.1310, acc-0.9600, valid loss-0.2253, acc-0.9360, test loss-0.2352, acc-0.9344\n",
      "Iter-87390, train loss-0.1887, acc-0.9200, valid loss-0.2253, acc-0.9358, test loss-0.2353, acc-0.9344\n",
      "Iter-87400, train loss-0.0704, acc-1.0000, valid loss-0.2253, acc-0.9358, test loss-0.2353, acc-0.9345\n",
      "Iter-87410, train loss-0.4732, acc-0.8400, valid loss-0.2253, acc-0.9354, test loss-0.2353, acc-0.9345\n",
      "Iter-87420, train loss-0.1244, acc-0.9800, valid loss-0.2253, acc-0.9356, test loss-0.2353, acc-0.9341\n",
      "Iter-87430, train loss-0.1872, acc-0.9400, valid loss-0.2253, acc-0.9356, test loss-0.2352, acc-0.9340\n",
      "Iter-87440, train loss-0.3392, acc-0.9200, valid loss-0.2253, acc-0.9352, test loss-0.2352, acc-0.9338\n",
      "Iter-87450, train loss-0.2308, acc-0.9200, valid loss-0.2253, acc-0.9350, test loss-0.2352, acc-0.9338\n",
      "Iter-87460, train loss-0.0755, acc-1.0000, valid loss-0.2253, acc-0.9352, test loss-0.2352, acc-0.9336\n",
      "Iter-87470, train loss-0.1482, acc-0.9800, valid loss-0.2254, acc-0.9346, test loss-0.2352, acc-0.9340\n",
      "Iter-87480, train loss-0.3103, acc-0.9200, valid loss-0.2254, acc-0.9350, test loss-0.2352, acc-0.9341\n",
      "Iter-87490, train loss-0.1574, acc-0.9600, valid loss-0.2254, acc-0.9350, test loss-0.2352, acc-0.9340\n",
      "Iter-87500, train loss-0.2466, acc-0.9200, valid loss-0.2253, acc-0.9348, test loss-0.2352, acc-0.9336\n",
      "Iter-87510, train loss-0.2471, acc-0.9400, valid loss-0.2254, acc-0.9350, test loss-0.2352, acc-0.9335\n",
      "Iter-87520, train loss-0.2491, acc-0.9600, valid loss-0.2253, acc-0.9348, test loss-0.2352, acc-0.9337\n",
      "Iter-87530, train loss-0.2620, acc-0.9200, valid loss-0.2254, acc-0.9346, test loss-0.2352, acc-0.9340\n",
      "Iter-87540, train loss-0.2437, acc-0.9400, valid loss-0.2254, acc-0.9348, test loss-0.2352, acc-0.9342\n",
      "Iter-87550, train loss-0.3354, acc-0.9000, valid loss-0.2253, acc-0.9348, test loss-0.2352, acc-0.9341\n",
      "Iter-87560, train loss-0.1583, acc-0.9600, valid loss-0.2253, acc-0.9348, test loss-0.2352, acc-0.9341\n",
      "Iter-87570, train loss-0.3136, acc-0.8400, valid loss-0.2253, acc-0.9348, test loss-0.2352, acc-0.9339\n",
      "Iter-87580, train loss-0.2202, acc-0.9400, valid loss-0.2253, acc-0.9346, test loss-0.2351, acc-0.9339\n",
      "Iter-87590, train loss-0.0669, acc-0.9800, valid loss-0.2253, acc-0.9348, test loss-0.2351, acc-0.9338\n",
      "Iter-87600, train loss-0.1976, acc-0.9400, valid loss-0.2253, acc-0.9350, test loss-0.2351, acc-0.9339\n",
      "Iter-87610, train loss-0.2423, acc-0.9200, valid loss-0.2252, acc-0.9348, test loss-0.2351, acc-0.9339\n",
      "Iter-87620, train loss-0.1098, acc-0.9600, valid loss-0.2252, acc-0.9356, test loss-0.2351, acc-0.9338\n",
      "Iter-87630, train loss-0.1518, acc-0.9600, valid loss-0.2251, acc-0.9358, test loss-0.2351, acc-0.9340\n",
      "Iter-87640, train loss-0.2545, acc-0.9400, valid loss-0.2252, acc-0.9354, test loss-0.2351, acc-0.9340\n",
      "Iter-87650, train loss-0.2258, acc-0.9600, valid loss-0.2252, acc-0.9350, test loss-0.2351, acc-0.9339\n",
      "Iter-87660, train loss-0.2137, acc-0.9200, valid loss-0.2252, acc-0.9354, test loss-0.2351, acc-0.9339\n",
      "Iter-87670, train loss-0.3329, acc-0.9200, valid loss-0.2252, acc-0.9352, test loss-0.2351, acc-0.9336\n",
      "Iter-87680, train loss-0.1221, acc-0.9800, valid loss-0.2252, acc-0.9352, test loss-0.2351, acc-0.9342\n",
      "Iter-87690, train loss-0.3061, acc-0.8800, valid loss-0.2252, acc-0.9354, test loss-0.2350, acc-0.9342\n",
      "Iter-87700, train loss-0.3103, acc-0.9200, valid loss-0.2252, acc-0.9354, test loss-0.2350, acc-0.9338\n",
      "Iter-87710, train loss-0.3407, acc-0.9000, valid loss-0.2251, acc-0.9356, test loss-0.2350, acc-0.9339\n",
      "Iter-87720, train loss-0.3026, acc-0.9000, valid loss-0.2251, acc-0.9356, test loss-0.2350, acc-0.9339\n",
      "Iter-87730, train loss-0.1120, acc-0.9800, valid loss-0.2252, acc-0.9356, test loss-0.2349, acc-0.9341\n",
      "Iter-87740, train loss-0.3667, acc-0.9000, valid loss-0.2251, acc-0.9356, test loss-0.2349, acc-0.9342\n",
      "Iter-87750, train loss-0.1617, acc-0.9400, valid loss-0.2251, acc-0.9356, test loss-0.2349, acc-0.9343\n",
      "Iter-87760, train loss-0.1685, acc-0.9400, valid loss-0.2251, acc-0.9350, test loss-0.2349, acc-0.9340\n",
      "Iter-87770, train loss-0.2035, acc-0.9400, valid loss-0.2251, acc-0.9352, test loss-0.2349, acc-0.9342\n",
      "Iter-87780, train loss-0.2752, acc-0.9200, valid loss-0.2251, acc-0.9350, test loss-0.2348, acc-0.9342\n",
      "Iter-87790, train loss-0.2840, acc-0.9600, valid loss-0.2250, acc-0.9350, test loss-0.2348, acc-0.9342\n",
      "Iter-87800, train loss-0.2796, acc-0.9600, valid loss-0.2250, acc-0.9352, test loss-0.2348, acc-0.9346\n",
      "Iter-87810, train loss-0.4513, acc-0.8600, valid loss-0.2250, acc-0.9348, test loss-0.2348, acc-0.9344\n",
      "Iter-87820, train loss-0.2326, acc-0.9600, valid loss-0.2250, acc-0.9350, test loss-0.2347, acc-0.9344\n",
      "Iter-87830, train loss-0.4544, acc-0.8200, valid loss-0.2250, acc-0.9350, test loss-0.2347, acc-0.9341\n",
      "Iter-87840, train loss-0.2992, acc-0.9200, valid loss-0.2249, acc-0.9348, test loss-0.2347, acc-0.9339\n",
      "Iter-87850, train loss-0.3672, acc-0.8800, valid loss-0.2249, acc-0.9350, test loss-0.2347, acc-0.9339\n",
      "Iter-87860, train loss-0.2411, acc-0.9200, valid loss-0.2249, acc-0.9350, test loss-0.2347, acc-0.9339\n",
      "Iter-87870, train loss-0.0800, acc-1.0000, valid loss-0.2249, acc-0.9350, test loss-0.2347, acc-0.9343\n",
      "Iter-87880, train loss-0.2190, acc-0.9600, valid loss-0.2249, acc-0.9350, test loss-0.2347, acc-0.9337\n",
      "Iter-87890, train loss-0.1461, acc-0.9400, valid loss-0.2249, acc-0.9350, test loss-0.2347, acc-0.9339\n",
      "Iter-87900, train loss-0.1378, acc-0.9600, valid loss-0.2250, acc-0.9352, test loss-0.2347, acc-0.9339\n",
      "Iter-87910, train loss-0.2218, acc-0.9200, valid loss-0.2249, acc-0.9352, test loss-0.2347, acc-0.9336\n",
      "Iter-87920, train loss-0.1674, acc-0.9800, valid loss-0.2249, acc-0.9354, test loss-0.2347, acc-0.9340\n",
      "Iter-87930, train loss-0.1429, acc-0.9600, valid loss-0.2249, acc-0.9356, test loss-0.2347, acc-0.9339\n",
      "Iter-87940, train loss-0.3540, acc-0.9200, valid loss-0.2249, acc-0.9352, test loss-0.2347, acc-0.9338\n",
      "Iter-87950, train loss-0.1495, acc-0.9400, valid loss-0.2249, acc-0.9352, test loss-0.2347, acc-0.9339\n",
      "Iter-87960, train loss-0.0823, acc-1.0000, valid loss-0.2250, acc-0.9354, test loss-0.2347, acc-0.9339\n",
      "Iter-87970, train loss-0.4211, acc-0.8600, valid loss-0.2250, acc-0.9354, test loss-0.2347, acc-0.9337\n",
      "Iter-87980, train loss-0.2147, acc-0.9200, valid loss-0.2250, acc-0.9354, test loss-0.2346, acc-0.9340\n",
      "Iter-87990, train loss-0.2685, acc-0.9600, valid loss-0.2249, acc-0.9354, test loss-0.2346, acc-0.9337\n",
      "Iter-88000, train loss-0.1998, acc-0.9400, valid loss-0.2249, acc-0.9354, test loss-0.2346, acc-0.9337\n",
      "Iter-88010, train loss-0.4095, acc-0.8800, valid loss-0.2249, acc-0.9354, test loss-0.2346, acc-0.9336\n",
      "Iter-88020, train loss-0.1204, acc-0.9600, valid loss-0.2249, acc-0.9358, test loss-0.2346, acc-0.9335\n",
      "Iter-88030, train loss-0.1979, acc-0.9600, valid loss-0.2249, acc-0.9356, test loss-0.2346, acc-0.9339\n",
      "Iter-88040, train loss-0.3141, acc-0.9000, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9339\n",
      "Iter-88050, train loss-0.1633, acc-0.9600, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9338\n",
      "Iter-88060, train loss-0.0940, acc-0.9600, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9340\n",
      "Iter-88070, train loss-0.3398, acc-0.8800, valid loss-0.2248, acc-0.9358, test loss-0.2346, acc-0.9339\n",
      "Iter-88080, train loss-0.1581, acc-0.9800, valid loss-0.2248, acc-0.9358, test loss-0.2346, acc-0.9342\n",
      "Iter-88090, train loss-0.0998, acc-0.9400, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9340\n",
      "Iter-88100, train loss-0.1842, acc-0.9000, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9342\n",
      "Iter-88110, train loss-0.1320, acc-0.9600, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9342\n",
      "Iter-88120, train loss-0.3410, acc-0.8800, valid loss-0.2247, acc-0.9358, test loss-0.2346, acc-0.9341\n",
      "Iter-88130, train loss-0.0667, acc-1.0000, valid loss-0.2248, acc-0.9356, test loss-0.2346, acc-0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-88140, train loss-0.2660, acc-0.9400, valid loss-0.2248, acc-0.9358, test loss-0.2346, acc-0.9340\n",
      "Iter-88150, train loss-0.0732, acc-1.0000, valid loss-0.2248, acc-0.9360, test loss-0.2346, acc-0.9342\n",
      "Iter-88160, train loss-0.2281, acc-0.9400, valid loss-0.2247, acc-0.9362, test loss-0.2346, acc-0.9340\n",
      "Iter-88170, train loss-0.1590, acc-0.9600, valid loss-0.2247, acc-0.9360, test loss-0.2345, acc-0.9338\n",
      "Iter-88180, train loss-0.2161, acc-0.9200, valid loss-0.2246, acc-0.9362, test loss-0.2345, acc-0.9340\n",
      "Iter-88190, train loss-0.0700, acc-0.9800, valid loss-0.2247, acc-0.9358, test loss-0.2345, acc-0.9340\n",
      "Iter-88200, train loss-0.1896, acc-0.9600, valid loss-0.2247, acc-0.9360, test loss-0.2345, acc-0.9340\n",
      "Iter-88210, train loss-0.2978, acc-0.9000, valid loss-0.2247, acc-0.9360, test loss-0.2345, acc-0.9342\n",
      "Iter-88220, train loss-0.2983, acc-0.8800, valid loss-0.2246, acc-0.9358, test loss-0.2345, acc-0.9339\n",
      "Iter-88230, train loss-0.2369, acc-0.9400, valid loss-0.2246, acc-0.9358, test loss-0.2344, acc-0.9342\n",
      "Iter-88240, train loss-0.2566, acc-0.9200, valid loss-0.2247, acc-0.9356, test loss-0.2344, acc-0.9343\n",
      "Iter-88250, train loss-0.1570, acc-0.9800, valid loss-0.2247, acc-0.9356, test loss-0.2344, acc-0.9344\n",
      "Iter-88260, train loss-0.1775, acc-0.9600, valid loss-0.2247, acc-0.9360, test loss-0.2344, acc-0.9342\n",
      "Iter-88270, train loss-0.2062, acc-0.9000, valid loss-0.2246, acc-0.9356, test loss-0.2344, acc-0.9343\n",
      "Iter-88280, train loss-0.5156, acc-0.8800, valid loss-0.2247, acc-0.9358, test loss-0.2344, acc-0.9340\n",
      "Iter-88290, train loss-0.2730, acc-0.9000, valid loss-0.2247, acc-0.9360, test loss-0.2344, acc-0.9342\n",
      "Iter-88300, train loss-0.1659, acc-0.9600, valid loss-0.2247, acc-0.9356, test loss-0.2344, acc-0.9343\n",
      "Iter-88310, train loss-0.1613, acc-0.9200, valid loss-0.2247, acc-0.9356, test loss-0.2344, acc-0.9343\n",
      "Iter-88320, train loss-0.2215, acc-0.9600, valid loss-0.2247, acc-0.9358, test loss-0.2344, acc-0.9343\n",
      "Iter-88330, train loss-0.2640, acc-0.9200, valid loss-0.2246, acc-0.9358, test loss-0.2344, acc-0.9340\n",
      "Iter-88340, train loss-0.2445, acc-0.9400, valid loss-0.2246, acc-0.9358, test loss-0.2344, acc-0.9340\n",
      "Iter-88350, train loss-0.3992, acc-0.9000, valid loss-0.2245, acc-0.9358, test loss-0.2344, acc-0.9338\n",
      "Iter-88360, train loss-0.1745, acc-0.9400, valid loss-0.2245, acc-0.9358, test loss-0.2344, acc-0.9336\n",
      "Iter-88370, train loss-0.1625, acc-0.9200, valid loss-0.2245, acc-0.9358, test loss-0.2344, acc-0.9335\n",
      "Iter-88380, train loss-0.1592, acc-0.9800, valid loss-0.2245, acc-0.9358, test loss-0.2344, acc-0.9336\n",
      "Iter-88390, train loss-0.2016, acc-0.9400, valid loss-0.2245, acc-0.9358, test loss-0.2344, acc-0.9333\n",
      "Iter-88400, train loss-0.1725, acc-0.9400, valid loss-0.2245, acc-0.9356, test loss-0.2344, acc-0.9333\n",
      "Iter-88410, train loss-0.2632, acc-0.9200, valid loss-0.2245, acc-0.9354, test loss-0.2344, acc-0.9332\n",
      "Iter-88420, train loss-0.1658, acc-0.9400, valid loss-0.2244, acc-0.9356, test loss-0.2343, acc-0.9333\n",
      "Iter-88430, train loss-0.1248, acc-0.9800, valid loss-0.2244, acc-0.9360, test loss-0.2343, acc-0.9334\n",
      "Iter-88440, train loss-0.2816, acc-0.9200, valid loss-0.2244, acc-0.9362, test loss-0.2343, acc-0.9334\n",
      "Iter-88450, train loss-0.4420, acc-0.8600, valid loss-0.2245, acc-0.9362, test loss-0.2343, acc-0.9335\n",
      "Iter-88460, train loss-0.1476, acc-0.9200, valid loss-0.2245, acc-0.9362, test loss-0.2343, acc-0.9332\n",
      "Iter-88470, train loss-0.2567, acc-0.9400, valid loss-0.2244, acc-0.9358, test loss-0.2343, acc-0.9334\n",
      "Iter-88480, train loss-0.1632, acc-0.9600, valid loss-0.2244, acc-0.9360, test loss-0.2343, acc-0.9340\n",
      "Iter-88490, train loss-0.2184, acc-0.9600, valid loss-0.2245, acc-0.9362, test loss-0.2343, acc-0.9337\n",
      "Iter-88500, train loss-0.1199, acc-0.9800, valid loss-0.2245, acc-0.9366, test loss-0.2342, acc-0.9333\n",
      "Iter-88510, train loss-0.2673, acc-0.9400, valid loss-0.2245, acc-0.9362, test loss-0.2342, acc-0.9336\n",
      "Iter-88520, train loss-0.2251, acc-0.9400, valid loss-0.2245, acc-0.9364, test loss-0.2342, acc-0.9336\n",
      "Iter-88530, train loss-0.2976, acc-0.9000, valid loss-0.2245, acc-0.9362, test loss-0.2342, acc-0.9336\n",
      "Iter-88540, train loss-0.1748, acc-0.9600, valid loss-0.2244, acc-0.9362, test loss-0.2342, acc-0.9337\n",
      "Iter-88550, train loss-0.2241, acc-0.8800, valid loss-0.2244, acc-0.9362, test loss-0.2341, acc-0.9336\n",
      "Iter-88560, train loss-0.2581, acc-0.9400, valid loss-0.2245, acc-0.9360, test loss-0.2341, acc-0.9341\n",
      "Iter-88570, train loss-0.1492, acc-0.9800, valid loss-0.2245, acc-0.9360, test loss-0.2341, acc-0.9340\n",
      "Iter-88580, train loss-0.2789, acc-0.9000, valid loss-0.2244, acc-0.9360, test loss-0.2341, acc-0.9338\n",
      "Iter-88590, train loss-0.3477, acc-0.9400, valid loss-0.2244, acc-0.9358, test loss-0.2341, acc-0.9337\n",
      "Iter-88600, train loss-0.1918, acc-0.9200, valid loss-0.2244, acc-0.9360, test loss-0.2341, acc-0.9338\n",
      "Iter-88610, train loss-0.2882, acc-0.9000, valid loss-0.2244, acc-0.9364, test loss-0.2341, acc-0.9337\n",
      "Iter-88620, train loss-0.1804, acc-0.9600, valid loss-0.2244, acc-0.9362, test loss-0.2341, acc-0.9337\n",
      "Iter-88630, train loss-0.1778, acc-0.9600, valid loss-0.2244, acc-0.9362, test loss-0.2340, acc-0.9337\n",
      "Iter-88640, train loss-0.2278, acc-0.9200, valid loss-0.2244, acc-0.9364, test loss-0.2341, acc-0.9336\n",
      "Iter-88650, train loss-0.1932, acc-0.9400, valid loss-0.2244, acc-0.9362, test loss-0.2340, acc-0.9338\n",
      "Iter-88660, train loss-0.3345, acc-0.8800, valid loss-0.2243, acc-0.9362, test loss-0.2341, acc-0.9336\n",
      "Iter-88670, train loss-0.1631, acc-0.9600, valid loss-0.2243, acc-0.9360, test loss-0.2341, acc-0.9337\n",
      "Iter-88680, train loss-0.3740, acc-0.9400, valid loss-0.2243, acc-0.9362, test loss-0.2341, acc-0.9337\n",
      "Iter-88690, train loss-0.1755, acc-0.9400, valid loss-0.2243, acc-0.9362, test loss-0.2341, acc-0.9337\n",
      "Iter-88700, train loss-0.1943, acc-0.9200, valid loss-0.2242, acc-0.9362, test loss-0.2341, acc-0.9336\n",
      "Iter-88710, train loss-0.1794, acc-0.9600, valid loss-0.2242, acc-0.9360, test loss-0.2341, acc-0.9339\n",
      "Iter-88720, train loss-0.1469, acc-0.9400, valid loss-0.2243, acc-0.9362, test loss-0.2341, acc-0.9335\n",
      "Iter-88730, train loss-0.2606, acc-0.9400, valid loss-0.2243, acc-0.9360, test loss-0.2340, acc-0.9336\n",
      "Iter-88740, train loss-0.1197, acc-0.9600, valid loss-0.2243, acc-0.9360, test loss-0.2340, acc-0.9338\n",
      "Iter-88750, train loss-0.1902, acc-0.9400, valid loss-0.2243, acc-0.9360, test loss-0.2341, acc-0.9337\n",
      "Iter-88760, train loss-0.2704, acc-0.9200, valid loss-0.2243, acc-0.9358, test loss-0.2341, acc-0.9336\n",
      "Iter-88770, train loss-0.2435, acc-0.9000, valid loss-0.2242, acc-0.9360, test loss-0.2340, acc-0.9337\n",
      "Iter-88780, train loss-0.2284, acc-0.9200, valid loss-0.2242, acc-0.9360, test loss-0.2340, acc-0.9335\n",
      "Iter-88790, train loss-0.3721, acc-0.9000, valid loss-0.2243, acc-0.9358, test loss-0.2340, acc-0.9338\n",
      "Iter-88800, train loss-0.2519, acc-0.9200, valid loss-0.2242, acc-0.9360, test loss-0.2340, acc-0.9337\n",
      "Iter-88810, train loss-0.2501, acc-0.9000, valid loss-0.2242, acc-0.9362, test loss-0.2339, acc-0.9338\n",
      "Iter-88820, train loss-0.3204, acc-0.9000, valid loss-0.2241, acc-0.9362, test loss-0.2339, acc-0.9338\n",
      "Iter-88830, train loss-0.1923, acc-0.9600, valid loss-0.2241, acc-0.9362, test loss-0.2339, acc-0.9339\n",
      "Iter-88840, train loss-0.2019, acc-0.9400, valid loss-0.2242, acc-0.9360, test loss-0.2339, acc-0.9339\n",
      "Iter-88850, train loss-0.3118, acc-0.9000, valid loss-0.2241, acc-0.9360, test loss-0.2338, acc-0.9337\n",
      "Iter-88860, train loss-0.1593, acc-0.9800, valid loss-0.2242, acc-0.9360, test loss-0.2338, acc-0.9339\n",
      "Iter-88870, train loss-0.1155, acc-0.9400, valid loss-0.2241, acc-0.9362, test loss-0.2338, acc-0.9340\n",
      "Iter-88880, train loss-0.2236, acc-0.9400, valid loss-0.2241, acc-0.9362, test loss-0.2338, acc-0.9341\n",
      "Iter-88890, train loss-0.2571, acc-0.9400, valid loss-0.2241, acc-0.9358, test loss-0.2338, acc-0.9341\n",
      "Iter-88900, train loss-0.1806, acc-0.9400, valid loss-0.2241, acc-0.9358, test loss-0.2338, acc-0.9338\n",
      "Iter-88910, train loss-0.3321, acc-0.9200, valid loss-0.2241, acc-0.9358, test loss-0.2338, acc-0.9337\n",
      "Iter-88920, train loss-0.2248, acc-0.9400, valid loss-0.2240, acc-0.9356, test loss-0.2338, acc-0.9336\n",
      "Iter-88930, train loss-0.2131, acc-0.9400, valid loss-0.2240, acc-0.9358, test loss-0.2338, acc-0.9333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-88940, train loss-0.1005, acc-0.9800, valid loss-0.2239, acc-0.9356, test loss-0.2337, acc-0.9341\n",
      "Iter-88950, train loss-0.2485, acc-0.9400, valid loss-0.2239, acc-0.9356, test loss-0.2337, acc-0.9339\n",
      "Iter-88960, train loss-0.1625, acc-0.9600, valid loss-0.2238, acc-0.9356, test loss-0.2337, acc-0.9337\n",
      "Iter-88970, train loss-0.1150, acc-0.9600, valid loss-0.2238, acc-0.9356, test loss-0.2337, acc-0.9336\n",
      "Iter-88980, train loss-0.2392, acc-0.8800, valid loss-0.2238, acc-0.9360, test loss-0.2337, acc-0.9334\n",
      "Iter-88990, train loss-0.3013, acc-0.9000, valid loss-0.2237, acc-0.9360, test loss-0.2337, acc-0.9335\n",
      "Iter-89000, train loss-0.2973, acc-0.9000, valid loss-0.2237, acc-0.9356, test loss-0.2337, acc-0.9336\n",
      "Iter-89010, train loss-0.1795, acc-0.9200, valid loss-0.2236, acc-0.9360, test loss-0.2337, acc-0.9335\n",
      "Iter-89020, train loss-0.2063, acc-0.9400, valid loss-0.2235, acc-0.9362, test loss-0.2337, acc-0.9333\n",
      "Iter-89030, train loss-0.2567, acc-0.9200, valid loss-0.2235, acc-0.9356, test loss-0.2336, acc-0.9335\n",
      "Iter-89040, train loss-0.1867, acc-0.9400, valid loss-0.2235, acc-0.9358, test loss-0.2336, acc-0.9336\n",
      "Iter-89050, train loss-0.4039, acc-0.9400, valid loss-0.2235, acc-0.9356, test loss-0.2336, acc-0.9335\n",
      "Iter-89060, train loss-0.3968, acc-0.9200, valid loss-0.2234, acc-0.9356, test loss-0.2335, acc-0.9336\n",
      "Iter-89070, train loss-0.1016, acc-0.9800, valid loss-0.2234, acc-0.9360, test loss-0.2335, acc-0.9337\n",
      "Iter-89080, train loss-0.5212, acc-0.8400, valid loss-0.2234, acc-0.9356, test loss-0.2335, acc-0.9336\n",
      "Iter-89090, train loss-0.1808, acc-0.9400, valid loss-0.2234, acc-0.9358, test loss-0.2335, acc-0.9337\n",
      "Iter-89100, train loss-0.2075, acc-0.9200, valid loss-0.2234, acc-0.9356, test loss-0.2335, acc-0.9337\n",
      "Iter-89110, train loss-0.0980, acc-0.9800, valid loss-0.2234, acc-0.9360, test loss-0.2335, acc-0.9337\n",
      "Iter-89120, train loss-0.2516, acc-0.9400, valid loss-0.2234, acc-0.9362, test loss-0.2334, acc-0.9338\n",
      "Iter-89130, train loss-0.1717, acc-0.9200, valid loss-0.2234, acc-0.9360, test loss-0.2335, acc-0.9338\n",
      "Iter-89140, train loss-0.2431, acc-0.9200, valid loss-0.2233, acc-0.9356, test loss-0.2334, acc-0.9337\n",
      "Iter-89150, train loss-0.2626, acc-0.9200, valid loss-0.2234, acc-0.9358, test loss-0.2335, acc-0.9336\n",
      "Iter-89160, train loss-0.2645, acc-0.9000, valid loss-0.2234, acc-0.9358, test loss-0.2335, acc-0.9337\n",
      "Iter-89170, train loss-0.0901, acc-1.0000, valid loss-0.2234, acc-0.9362, test loss-0.2334, acc-0.9338\n",
      "Iter-89180, train loss-0.3598, acc-0.8800, valid loss-0.2233, acc-0.9362, test loss-0.2334, acc-0.9336\n",
      "Iter-89190, train loss-0.1906, acc-0.9200, valid loss-0.2234, acc-0.9362, test loss-0.2334, acc-0.9337\n",
      "Iter-89200, train loss-0.4448, acc-0.9000, valid loss-0.2233, acc-0.9358, test loss-0.2334, acc-0.9335\n",
      "Iter-89210, train loss-0.4832, acc-0.8600, valid loss-0.2233, acc-0.9358, test loss-0.2334, acc-0.9333\n",
      "Iter-89220, train loss-0.2367, acc-0.9400, valid loss-0.2234, acc-0.9358, test loss-0.2333, acc-0.9334\n",
      "Iter-89230, train loss-0.1936, acc-0.9200, valid loss-0.2233, acc-0.9360, test loss-0.2333, acc-0.9337\n",
      "Iter-89240, train loss-0.2292, acc-0.9000, valid loss-0.2233, acc-0.9360, test loss-0.2333, acc-0.9336\n",
      "Iter-89250, train loss-0.2418, acc-0.9000, valid loss-0.2232, acc-0.9362, test loss-0.2332, acc-0.9336\n",
      "Iter-89260, train loss-0.3209, acc-0.9000, valid loss-0.2231, acc-0.9364, test loss-0.2332, acc-0.9334\n",
      "Iter-89270, train loss-0.1981, acc-0.9400, valid loss-0.2230, acc-0.9360, test loss-0.2332, acc-0.9335\n",
      "Iter-89280, train loss-0.2068, acc-0.9200, valid loss-0.2230, acc-0.9358, test loss-0.2332, acc-0.9332\n",
      "Iter-89290, train loss-0.2697, acc-0.9600, valid loss-0.2229, acc-0.9360, test loss-0.2332, acc-0.9333\n",
      "Iter-89300, train loss-0.1199, acc-0.9800, valid loss-0.2229, acc-0.9360, test loss-0.2332, acc-0.9331\n",
      "Iter-89310, train loss-0.3832, acc-0.9000, valid loss-0.2230, acc-0.9358, test loss-0.2332, acc-0.9331\n",
      "Iter-89320, train loss-0.2799, acc-0.9200, valid loss-0.2230, acc-0.9358, test loss-0.2332, acc-0.9331\n",
      "Iter-89330, train loss-0.3135, acc-0.9200, valid loss-0.2230, acc-0.9362, test loss-0.2333, acc-0.9333\n",
      "Iter-89340, train loss-0.1388, acc-0.9800, valid loss-0.2230, acc-0.9360, test loss-0.2333, acc-0.9332\n",
      "Iter-89350, train loss-0.2101, acc-0.9200, valid loss-0.2230, acc-0.9358, test loss-0.2333, acc-0.9333\n",
      "Iter-89360, train loss-0.3949, acc-0.9000, valid loss-0.2230, acc-0.9358, test loss-0.2332, acc-0.9332\n",
      "Iter-89370, train loss-0.1593, acc-0.9600, valid loss-0.2230, acc-0.9358, test loss-0.2333, acc-0.9331\n",
      "Iter-89380, train loss-0.0917, acc-0.9800, valid loss-0.2230, acc-0.9358, test loss-0.2332, acc-0.9332\n",
      "Iter-89390, train loss-0.2439, acc-0.9200, valid loss-0.2230, acc-0.9360, test loss-0.2332, acc-0.9330\n",
      "Iter-89400, train loss-0.0875, acc-0.9800, valid loss-0.2230, acc-0.9354, test loss-0.2332, acc-0.9329\n",
      "Iter-89410, train loss-0.1749, acc-0.9400, valid loss-0.2230, acc-0.9354, test loss-0.2332, acc-0.9329\n",
      "Iter-89420, train loss-0.3725, acc-0.8800, valid loss-0.2229, acc-0.9356, test loss-0.2332, acc-0.9328\n",
      "Iter-89430, train loss-0.3077, acc-0.9000, valid loss-0.2228, acc-0.9356, test loss-0.2332, acc-0.9328\n",
      "Iter-89440, train loss-0.1372, acc-0.9200, valid loss-0.2229, acc-0.9358, test loss-0.2332, acc-0.9328\n",
      "Iter-89450, train loss-0.1239, acc-1.0000, valid loss-0.2228, acc-0.9354, test loss-0.2332, acc-0.9330\n",
      "Iter-89460, train loss-0.2401, acc-0.9200, valid loss-0.2229, acc-0.9358, test loss-0.2332, acc-0.9332\n",
      "Iter-89470, train loss-0.3096, acc-0.9000, valid loss-0.2229, acc-0.9360, test loss-0.2332, acc-0.9331\n",
      "Iter-89480, train loss-0.1558, acc-0.9800, valid loss-0.2228, acc-0.9358, test loss-0.2331, acc-0.9331\n",
      "Iter-89490, train loss-0.3181, acc-0.9000, valid loss-0.2228, acc-0.9356, test loss-0.2331, acc-0.9333\n",
      "Iter-89500, train loss-0.2946, acc-0.9600, valid loss-0.2228, acc-0.9354, test loss-0.2331, acc-0.9336\n",
      "Iter-89510, train loss-0.1769, acc-0.9800, valid loss-0.2228, acc-0.9354, test loss-0.2330, acc-0.9335\n",
      "Iter-89520, train loss-0.2704, acc-0.9000, valid loss-0.2228, acc-0.9356, test loss-0.2330, acc-0.9333\n",
      "Iter-89530, train loss-0.3203, acc-0.9000, valid loss-0.2227, acc-0.9356, test loss-0.2330, acc-0.9332\n",
      "Iter-89540, train loss-0.3174, acc-0.9200, valid loss-0.2227, acc-0.9352, test loss-0.2330, acc-0.9331\n",
      "Iter-89550, train loss-0.1034, acc-0.9800, valid loss-0.2226, acc-0.9354, test loss-0.2330, acc-0.9328\n",
      "Iter-89560, train loss-0.1624, acc-0.9600, valid loss-0.2226, acc-0.9356, test loss-0.2330, acc-0.9332\n",
      "Iter-89570, train loss-0.2489, acc-0.9400, valid loss-0.2226, acc-0.9358, test loss-0.2330, acc-0.9331\n",
      "Iter-89580, train loss-0.1588, acc-0.9400, valid loss-0.2225, acc-0.9356, test loss-0.2330, acc-0.9330\n",
      "Iter-89590, train loss-0.1805, acc-0.9800, valid loss-0.2225, acc-0.9356, test loss-0.2330, acc-0.9332\n",
      "Iter-89600, train loss-0.2964, acc-0.9000, valid loss-0.2224, acc-0.9356, test loss-0.2330, acc-0.9331\n",
      "Iter-89610, train loss-0.4878, acc-0.8800, valid loss-0.2225, acc-0.9360, test loss-0.2330, acc-0.9331\n",
      "Iter-89620, train loss-0.2113, acc-0.9200, valid loss-0.2224, acc-0.9360, test loss-0.2330, acc-0.9331\n",
      "Iter-89630, train loss-0.2101, acc-0.9400, valid loss-0.2224, acc-0.9360, test loss-0.2330, acc-0.9332\n",
      "Iter-89640, train loss-0.3308, acc-0.8800, valid loss-0.2224, acc-0.9360, test loss-0.2329, acc-0.9331\n",
      "Iter-89650, train loss-0.1359, acc-0.9400, valid loss-0.2224, acc-0.9358, test loss-0.2329, acc-0.9331\n",
      "Iter-89660, train loss-0.2960, acc-0.9400, valid loss-0.2223, acc-0.9358, test loss-0.2330, acc-0.9333\n",
      "Iter-89670, train loss-0.1702, acc-0.9400, valid loss-0.2224, acc-0.9358, test loss-0.2330, acc-0.9332\n",
      "Iter-89680, train loss-0.3396, acc-0.8200, valid loss-0.2224, acc-0.9358, test loss-0.2330, acc-0.9331\n",
      "Iter-89690, train loss-0.3117, acc-0.9000, valid loss-0.2224, acc-0.9360, test loss-0.2330, acc-0.9334\n",
      "Iter-89700, train loss-0.3573, acc-0.9200, valid loss-0.2224, acc-0.9360, test loss-0.2329, acc-0.9335\n",
      "Iter-89710, train loss-0.2416, acc-0.9200, valid loss-0.2224, acc-0.9360, test loss-0.2330, acc-0.9334\n",
      "Iter-89720, train loss-0.3085, acc-0.9000, valid loss-0.2225, acc-0.9364, test loss-0.2330, acc-0.9334\n",
      "Iter-89730, train loss-0.1820, acc-0.9200, valid loss-0.2225, acc-0.9364, test loss-0.2329, acc-0.9335\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-89740, train loss-0.2062, acc-0.9400, valid loss-0.2225, acc-0.9362, test loss-0.2329, acc-0.9334\n",
      "Iter-89750, train loss-0.2977, acc-0.9400, valid loss-0.2225, acc-0.9362, test loss-0.2329, acc-0.9333\n",
      "Iter-89760, train loss-0.3496, acc-0.8800, valid loss-0.2225, acc-0.9362, test loss-0.2328, acc-0.9335\n",
      "Iter-89770, train loss-0.3823, acc-0.9000, valid loss-0.2224, acc-0.9362, test loss-0.2328, acc-0.9337\n",
      "Iter-89780, train loss-0.2040, acc-0.9600, valid loss-0.2224, acc-0.9362, test loss-0.2328, acc-0.9337\n",
      "Iter-89790, train loss-0.1205, acc-0.9600, valid loss-0.2224, acc-0.9360, test loss-0.2328, acc-0.9337\n",
      "Iter-89800, train loss-0.1904, acc-0.9400, valid loss-0.2224, acc-0.9360, test loss-0.2328, acc-0.9336\n",
      "Iter-89810, train loss-0.1929, acc-0.9400, valid loss-0.2224, acc-0.9362, test loss-0.2327, acc-0.9339\n",
      "Iter-89820, train loss-0.1420, acc-0.9400, valid loss-0.2223, acc-0.9364, test loss-0.2327, acc-0.9338\n",
      "Iter-89830, train loss-0.1480, acc-0.9800, valid loss-0.2223, acc-0.9360, test loss-0.2327, acc-0.9337\n",
      "Iter-89840, train loss-0.2686, acc-0.8800, valid loss-0.2223, acc-0.9362, test loss-0.2328, acc-0.9337\n",
      "Iter-89850, train loss-0.3355, acc-0.9200, valid loss-0.2223, acc-0.9362, test loss-0.2327, acc-0.9337\n",
      "Iter-89860, train loss-0.1579, acc-0.9800, valid loss-0.2223, acc-0.9360, test loss-0.2327, acc-0.9337\n",
      "Iter-89870, train loss-0.2452, acc-0.9200, valid loss-0.2223, acc-0.9358, test loss-0.2327, acc-0.9338\n",
      "Iter-89880, train loss-0.2314, acc-0.9400, valid loss-0.2223, acc-0.9360, test loss-0.2327, acc-0.9337\n",
      "Iter-89890, train loss-0.3076, acc-0.9200, valid loss-0.2223, acc-0.9358, test loss-0.2327, acc-0.9337\n",
      "Iter-89900, train loss-0.1681, acc-0.9800, valid loss-0.2223, acc-0.9364, test loss-0.2327, acc-0.9336\n",
      "Iter-89910, train loss-0.1369, acc-0.9600, valid loss-0.2223, acc-0.9364, test loss-0.2327, acc-0.9336\n",
      "Iter-89920, train loss-0.1218, acc-0.9800, valid loss-0.2223, acc-0.9364, test loss-0.2327, acc-0.9338\n",
      "Iter-89930, train loss-0.2123, acc-0.9400, valid loss-0.2222, acc-0.9364, test loss-0.2327, acc-0.9337\n",
      "Iter-89940, train loss-0.3462, acc-0.8800, valid loss-0.2222, acc-0.9368, test loss-0.2327, acc-0.9339\n",
      "Iter-89950, train loss-0.2268, acc-0.9800, valid loss-0.2222, acc-0.9366, test loss-0.2327, acc-0.9338\n",
      "Iter-89960, train loss-0.1744, acc-0.9400, valid loss-0.2222, acc-0.9368, test loss-0.2326, acc-0.9336\n",
      "Iter-89970, train loss-0.1352, acc-0.9800, valid loss-0.2221, acc-0.9364, test loss-0.2327, acc-0.9338\n",
      "Iter-89980, train loss-0.3883, acc-0.8800, valid loss-0.2221, acc-0.9368, test loss-0.2327, acc-0.9335\n",
      "Iter-89990, train loss-0.2380, acc-0.9600, valid loss-0.2221, acc-0.9368, test loss-0.2327, acc-0.9337\n",
      "Iter-90000, train loss-0.1992, acc-0.9400, valid loss-0.2221, acc-0.9364, test loss-0.2327, acc-0.9337\n",
      "Iter-90010, train loss-0.1098, acc-0.9800, valid loss-0.2221, acc-0.9366, test loss-0.2327, acc-0.9337\n",
      "Iter-90020, train loss-0.0695, acc-1.0000, valid loss-0.2221, acc-0.9362, test loss-0.2326, acc-0.9339\n",
      "Iter-90030, train loss-0.2335, acc-0.9400, valid loss-0.2221, acc-0.9364, test loss-0.2327, acc-0.9338\n",
      "Iter-90040, train loss-0.2859, acc-0.9200, valid loss-0.2221, acc-0.9362, test loss-0.2327, acc-0.9339\n",
      "Iter-90050, train loss-0.1445, acc-0.9400, valid loss-0.2221, acc-0.9362, test loss-0.2327, acc-0.9337\n",
      "Iter-90060, train loss-0.2734, acc-0.9400, valid loss-0.2222, acc-0.9360, test loss-0.2327, acc-0.9339\n",
      "Iter-90070, train loss-0.2510, acc-0.9400, valid loss-0.2222, acc-0.9358, test loss-0.2327, acc-0.9340\n",
      "Iter-90080, train loss-0.4876, acc-0.8800, valid loss-0.2222, acc-0.9362, test loss-0.2326, acc-0.9339\n",
      "Iter-90090, train loss-0.2141, acc-0.9600, valid loss-0.2222, acc-0.9360, test loss-0.2326, acc-0.9340\n",
      "Iter-90100, train loss-0.3102, acc-0.8800, valid loss-0.2221, acc-0.9366, test loss-0.2326, acc-0.9340\n",
      "Iter-90110, train loss-0.1204, acc-0.9400, valid loss-0.2220, acc-0.9368, test loss-0.2326, acc-0.9340\n",
      "Iter-90120, train loss-0.2737, acc-0.9400, valid loss-0.2220, acc-0.9366, test loss-0.2326, acc-0.9340\n",
      "Iter-90130, train loss-0.2206, acc-0.9200, valid loss-0.2219, acc-0.9364, test loss-0.2326, acc-0.9337\n",
      "Iter-90140, train loss-0.1523, acc-0.9400, valid loss-0.2219, acc-0.9368, test loss-0.2325, acc-0.9336\n",
      "Iter-90150, train loss-0.2859, acc-0.9600, valid loss-0.2219, acc-0.9368, test loss-0.2325, acc-0.9337\n",
      "Iter-90160, train loss-0.1574, acc-0.9600, valid loss-0.2219, acc-0.9364, test loss-0.2324, acc-0.9338\n",
      "Iter-90170, train loss-0.2790, acc-0.9200, valid loss-0.2218, acc-0.9366, test loss-0.2324, acc-0.9338\n",
      "Iter-90180, train loss-0.1817, acc-0.9600, valid loss-0.2218, acc-0.9364, test loss-0.2324, acc-0.9337\n",
      "Iter-90190, train loss-0.2449, acc-0.8800, valid loss-0.2217, acc-0.9364, test loss-0.2324, acc-0.9334\n",
      "Iter-90200, train loss-0.2905, acc-0.9200, valid loss-0.2217, acc-0.9366, test loss-0.2324, acc-0.9334\n",
      "Iter-90210, train loss-0.1526, acc-0.9400, valid loss-0.2217, acc-0.9364, test loss-0.2324, acc-0.9335\n",
      "Iter-90220, train loss-0.3371, acc-0.8600, valid loss-0.2217, acc-0.9364, test loss-0.2324, acc-0.9337\n",
      "Iter-90230, train loss-0.1756, acc-0.9200, valid loss-0.2217, acc-0.9366, test loss-0.2324, acc-0.9338\n",
      "Iter-90240, train loss-0.1605, acc-0.9200, valid loss-0.2217, acc-0.9366, test loss-0.2323, acc-0.9337\n",
      "Iter-90250, train loss-0.0479, acc-1.0000, valid loss-0.2217, acc-0.9362, test loss-0.2322, acc-0.9335\n",
      "Iter-90260, train loss-0.0878, acc-0.9800, valid loss-0.2217, acc-0.9368, test loss-0.2322, acc-0.9336\n",
      "Iter-90270, train loss-0.4018, acc-0.9200, valid loss-0.2217, acc-0.9364, test loss-0.2322, acc-0.9337\n",
      "Iter-90280, train loss-0.1597, acc-0.9600, valid loss-0.2216, acc-0.9364, test loss-0.2322, acc-0.9335\n",
      "Iter-90290, train loss-0.2067, acc-0.9200, valid loss-0.2216, acc-0.9362, test loss-0.2322, acc-0.9337\n",
      "Iter-90300, train loss-0.1949, acc-0.9400, valid loss-0.2216, acc-0.9366, test loss-0.2322, acc-0.9337\n",
      "Iter-90310, train loss-0.2853, acc-0.9200, valid loss-0.2216, acc-0.9362, test loss-0.2321, acc-0.9339\n",
      "Iter-90320, train loss-0.3394, acc-0.9200, valid loss-0.2216, acc-0.9362, test loss-0.2321, acc-0.9341\n",
      "Iter-90330, train loss-0.1889, acc-0.9400, valid loss-0.2216, acc-0.9362, test loss-0.2321, acc-0.9344\n",
      "Iter-90340, train loss-0.3434, acc-0.9000, valid loss-0.2216, acc-0.9364, test loss-0.2321, acc-0.9342\n",
      "Iter-90350, train loss-0.2187, acc-0.9600, valid loss-0.2217, acc-0.9364, test loss-0.2321, acc-0.9341\n",
      "Iter-90360, train loss-0.3454, acc-0.9000, valid loss-0.2216, acc-0.9362, test loss-0.2320, acc-0.9339\n",
      "Iter-90370, train loss-0.1855, acc-0.9600, valid loss-0.2217, acc-0.9362, test loss-0.2320, acc-0.9343\n",
      "Iter-90380, train loss-0.3376, acc-0.8800, valid loss-0.2217, acc-0.9362, test loss-0.2320, acc-0.9342\n",
      "Iter-90390, train loss-0.0907, acc-1.0000, valid loss-0.2216, acc-0.9362, test loss-0.2319, acc-0.9341\n",
      "Iter-90400, train loss-0.4479, acc-0.8800, valid loss-0.2217, acc-0.9362, test loss-0.2319, acc-0.9341\n",
      "Iter-90410, train loss-0.0820, acc-0.9600, valid loss-0.2217, acc-0.9362, test loss-0.2319, acc-0.9341\n",
      "Iter-90420, train loss-0.1836, acc-0.9400, valid loss-0.2217, acc-0.9364, test loss-0.2319, acc-0.9340\n",
      "Iter-90430, train loss-0.2759, acc-0.9400, valid loss-0.2217, acc-0.9362, test loss-0.2319, acc-0.9340\n",
      "Iter-90440, train loss-0.2076, acc-0.9200, valid loss-0.2217, acc-0.9364, test loss-0.2319, acc-0.9342\n",
      "Iter-90450, train loss-0.1792, acc-0.9600, valid loss-0.2217, acc-0.9364, test loss-0.2319, acc-0.9341\n",
      "Iter-90460, train loss-0.2448, acc-0.9200, valid loss-0.2217, acc-0.9364, test loss-0.2319, acc-0.9343\n",
      "Iter-90470, train loss-0.3724, acc-0.9000, valid loss-0.2217, acc-0.9364, test loss-0.2318, acc-0.9340\n",
      "Iter-90480, train loss-0.2893, acc-0.9000, valid loss-0.2217, acc-0.9366, test loss-0.2318, acc-0.9345\n",
      "Iter-90490, train loss-0.1535, acc-0.9600, valid loss-0.2217, acc-0.9364, test loss-0.2318, acc-0.9343\n",
      "Iter-90500, train loss-0.2344, acc-0.9200, valid loss-0.2217, acc-0.9366, test loss-0.2317, acc-0.9343\n",
      "Iter-90510, train loss-0.3928, acc-0.8400, valid loss-0.2218, acc-0.9362, test loss-0.2318, acc-0.9343\n",
      "Iter-90520, train loss-0.1141, acc-0.9800, valid loss-0.2218, acc-0.9364, test loss-0.2317, acc-0.9342\n",
      "Iter-90530, train loss-0.1149, acc-1.0000, valid loss-0.2218, acc-0.9364, test loss-0.2317, acc-0.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-90540, train loss-0.3020, acc-0.9200, valid loss-0.2217, acc-0.9364, test loss-0.2317, acc-0.9344\n",
      "Iter-90550, train loss-0.1986, acc-0.9600, valid loss-0.2217, acc-0.9366, test loss-0.2317, acc-0.9344\n",
      "Iter-90560, train loss-0.3011, acc-0.9400, valid loss-0.2217, acc-0.9364, test loss-0.2317, acc-0.9344\n",
      "Iter-90570, train loss-0.3007, acc-0.9400, valid loss-0.2217, acc-0.9368, test loss-0.2316, acc-0.9345\n",
      "Iter-90580, train loss-0.4093, acc-0.9400, valid loss-0.2217, acc-0.9362, test loss-0.2316, acc-0.9345\n",
      "Iter-90590, train loss-0.1769, acc-0.9600, valid loss-0.2216, acc-0.9370, test loss-0.2316, acc-0.9343\n",
      "Iter-90600, train loss-0.2972, acc-0.9200, valid loss-0.2216, acc-0.9372, test loss-0.2315, acc-0.9339\n",
      "Iter-90610, train loss-0.2532, acc-0.9000, valid loss-0.2216, acc-0.9372, test loss-0.2315, acc-0.9345\n",
      "Iter-90620, train loss-0.2506, acc-0.9600, valid loss-0.2216, acc-0.9368, test loss-0.2314, acc-0.9342\n",
      "Iter-90630, train loss-0.2558, acc-0.9400, valid loss-0.2215, acc-0.9372, test loss-0.2314, acc-0.9344\n",
      "Iter-90640, train loss-0.2007, acc-0.9400, valid loss-0.2215, acc-0.9368, test loss-0.2315, acc-0.9346\n",
      "Iter-90650, train loss-0.2161, acc-0.9000, valid loss-0.2215, acc-0.9368, test loss-0.2315, acc-0.9345\n",
      "Iter-90660, train loss-0.1469, acc-0.9600, valid loss-0.2215, acc-0.9368, test loss-0.2315, acc-0.9345\n",
      "Iter-90670, train loss-0.3148, acc-0.9000, valid loss-0.2215, acc-0.9366, test loss-0.2315, acc-0.9346\n",
      "Iter-90680, train loss-0.1231, acc-0.9600, valid loss-0.2215, acc-0.9364, test loss-0.2315, acc-0.9347\n",
      "Iter-90690, train loss-0.1822, acc-0.9200, valid loss-0.2214, acc-0.9368, test loss-0.2314, acc-0.9348\n",
      "Iter-90700, train loss-0.3575, acc-0.8800, valid loss-0.2214, acc-0.9368, test loss-0.2314, acc-0.9343\n",
      "Iter-90710, train loss-0.1348, acc-0.9800, valid loss-0.2214, acc-0.9370, test loss-0.2314, acc-0.9343\n",
      "Iter-90720, train loss-0.2406, acc-0.9600, valid loss-0.2214, acc-0.9368, test loss-0.2314, acc-0.9343\n",
      "Iter-90730, train loss-0.5375, acc-0.8600, valid loss-0.2214, acc-0.9368, test loss-0.2314, acc-0.9346\n",
      "Iter-90740, train loss-0.1837, acc-0.9600, valid loss-0.2214, acc-0.9368, test loss-0.2313, acc-0.9346\n",
      "Iter-90750, train loss-0.3301, acc-0.9000, valid loss-0.2213, acc-0.9368, test loss-0.2313, acc-0.9345\n",
      "Iter-90760, train loss-0.1710, acc-0.9600, valid loss-0.2213, acc-0.9368, test loss-0.2313, acc-0.9345\n",
      "Iter-90770, train loss-0.2790, acc-0.9200, valid loss-0.2214, acc-0.9368, test loss-0.2313, acc-0.9346\n",
      "Iter-90780, train loss-0.2483, acc-0.9200, valid loss-0.2213, acc-0.9368, test loss-0.2313, acc-0.9339\n",
      "Iter-90790, train loss-0.1781, acc-0.9400, valid loss-0.2213, acc-0.9364, test loss-0.2313, acc-0.9339\n",
      "Iter-90800, train loss-0.2072, acc-0.9400, valid loss-0.2213, acc-0.9364, test loss-0.2313, acc-0.9341\n",
      "Iter-90810, train loss-0.2922, acc-0.9400, valid loss-0.2213, acc-0.9364, test loss-0.2313, acc-0.9343\n",
      "Iter-90820, train loss-0.3273, acc-0.9600, valid loss-0.2213, acc-0.9364, test loss-0.2313, acc-0.9344\n",
      "Iter-90830, train loss-0.1551, acc-0.9400, valid loss-0.2213, acc-0.9370, test loss-0.2313, acc-0.9342\n",
      "Iter-90840, train loss-0.2248, acc-0.9600, valid loss-0.2212, acc-0.9374, test loss-0.2313, acc-0.9339\n",
      "Iter-90850, train loss-0.1027, acc-0.9800, valid loss-0.2213, acc-0.9376, test loss-0.2313, acc-0.9342\n",
      "Iter-90860, train loss-0.2354, acc-0.9400, valid loss-0.2212, acc-0.9376, test loss-0.2313, acc-0.9340\n",
      "Iter-90870, train loss-0.2520, acc-0.9200, valid loss-0.2212, acc-0.9376, test loss-0.2313, acc-0.9340\n",
      "Iter-90880, train loss-0.1974, acc-0.9800, valid loss-0.2212, acc-0.9376, test loss-0.2314, acc-0.9340\n",
      "Iter-90890, train loss-0.1998, acc-0.9400, valid loss-0.2212, acc-0.9374, test loss-0.2314, acc-0.9339\n",
      "Iter-90900, train loss-0.2169, acc-0.9200, valid loss-0.2211, acc-0.9372, test loss-0.2314, acc-0.9339\n",
      "Iter-90910, train loss-0.1328, acc-1.0000, valid loss-0.2211, acc-0.9368, test loss-0.2314, acc-0.9340\n",
      "Iter-90920, train loss-0.3036, acc-0.9200, valid loss-0.2211, acc-0.9374, test loss-0.2314, acc-0.9338\n",
      "Iter-90930, train loss-0.2472, acc-0.9200, valid loss-0.2210, acc-0.9372, test loss-0.2313, acc-0.9339\n",
      "Iter-90940, train loss-0.1649, acc-0.9600, valid loss-0.2210, acc-0.9368, test loss-0.2314, acc-0.9338\n",
      "Iter-90950, train loss-0.1594, acc-0.9400, valid loss-0.2211, acc-0.9368, test loss-0.2314, acc-0.9338\n",
      "Iter-90960, train loss-0.3808, acc-0.9000, valid loss-0.2211, acc-0.9370, test loss-0.2314, acc-0.9339\n",
      "Iter-90970, train loss-0.2212, acc-0.9200, valid loss-0.2211, acc-0.9370, test loss-0.2313, acc-0.9341\n",
      "Iter-90980, train loss-0.1953, acc-0.9400, valid loss-0.2211, acc-0.9366, test loss-0.2313, acc-0.9340\n",
      "Iter-90990, train loss-0.2692, acc-0.9000, valid loss-0.2211, acc-0.9370, test loss-0.2313, acc-0.9341\n",
      "Iter-91000, train loss-0.1760, acc-0.9200, valid loss-0.2211, acc-0.9370, test loss-0.2313, acc-0.9341\n",
      "Iter-91010, train loss-0.3322, acc-0.9400, valid loss-0.2210, acc-0.9368, test loss-0.2313, acc-0.9341\n",
      "Iter-91020, train loss-0.1209, acc-0.9800, valid loss-0.2210, acc-0.9370, test loss-0.2313, acc-0.9341\n",
      "Iter-91030, train loss-0.1540, acc-0.9600, valid loss-0.2210, acc-0.9368, test loss-0.2313, acc-0.9340\n",
      "Iter-91040, train loss-0.1533, acc-0.9400, valid loss-0.2210, acc-0.9370, test loss-0.2312, acc-0.9342\n",
      "Iter-91050, train loss-0.2760, acc-0.9400, valid loss-0.2210, acc-0.9372, test loss-0.2313, acc-0.9343\n",
      "Iter-91060, train loss-0.1563, acc-0.9800, valid loss-0.2210, acc-0.9374, test loss-0.2313, acc-0.9344\n",
      "Iter-91070, train loss-0.1472, acc-0.9600, valid loss-0.2210, acc-0.9370, test loss-0.2313, acc-0.9344\n",
      "Iter-91080, train loss-0.1925, acc-0.9600, valid loss-0.2210, acc-0.9368, test loss-0.2313, acc-0.9344\n",
      "Iter-91090, train loss-0.4382, acc-0.9000, valid loss-0.2210, acc-0.9368, test loss-0.2313, acc-0.9343\n",
      "Iter-91100, train loss-0.2562, acc-0.8800, valid loss-0.2210, acc-0.9374, test loss-0.2313, acc-0.9342\n",
      "Iter-91110, train loss-0.2559, acc-0.9000, valid loss-0.2210, acc-0.9376, test loss-0.2313, acc-0.9344\n",
      "Iter-91120, train loss-0.1617, acc-0.9000, valid loss-0.2209, acc-0.9376, test loss-0.2313, acc-0.9343\n",
      "Iter-91130, train loss-0.1951, acc-0.9200, valid loss-0.2209, acc-0.9376, test loss-0.2313, acc-0.9346\n",
      "Iter-91140, train loss-0.0692, acc-1.0000, valid loss-0.2209, acc-0.9372, test loss-0.2313, acc-0.9346\n",
      "Iter-91150, train loss-0.1411, acc-0.9600, valid loss-0.2209, acc-0.9376, test loss-0.2313, acc-0.9345\n",
      "Iter-91160, train loss-0.1191, acc-0.9800, valid loss-0.2209, acc-0.9372, test loss-0.2313, acc-0.9345\n",
      "Iter-91170, train loss-0.1678, acc-0.9600, valid loss-0.2209, acc-0.9370, test loss-0.2313, acc-0.9344\n",
      "Iter-91180, train loss-0.2833, acc-0.9400, valid loss-0.2209, acc-0.9370, test loss-0.2313, acc-0.9345\n",
      "Iter-91190, train loss-0.2081, acc-0.9400, valid loss-0.2209, acc-0.9370, test loss-0.2313, acc-0.9347\n",
      "Iter-91200, train loss-0.4834, acc-0.8800, valid loss-0.2209, acc-0.9374, test loss-0.2313, acc-0.9343\n",
      "Iter-91210, train loss-0.1763, acc-0.9600, valid loss-0.2208, acc-0.9376, test loss-0.2313, acc-0.9345\n",
      "Iter-91220, train loss-0.4200, acc-0.9000, valid loss-0.2208, acc-0.9376, test loss-0.2313, acc-0.9343\n",
      "Iter-91230, train loss-0.2265, acc-0.9200, valid loss-0.2208, acc-0.9374, test loss-0.2313, acc-0.9344\n",
      "Iter-91240, train loss-0.2182, acc-0.9400, valid loss-0.2209, acc-0.9374, test loss-0.2312, acc-0.9345\n",
      "Iter-91250, train loss-0.3652, acc-0.8800, valid loss-0.2209, acc-0.9374, test loss-0.2312, acc-0.9343\n",
      "Iter-91260, train loss-0.2350, acc-0.8800, valid loss-0.2209, acc-0.9372, test loss-0.2312, acc-0.9343\n",
      "Iter-91270, train loss-0.2698, acc-0.9000, valid loss-0.2209, acc-0.9372, test loss-0.2312, acc-0.9343\n",
      "Iter-91280, train loss-0.2865, acc-0.9200, valid loss-0.2209, acc-0.9374, test loss-0.2312, acc-0.9346\n",
      "Iter-91290, train loss-0.1388, acc-0.9600, valid loss-0.2209, acc-0.9374, test loss-0.2312, acc-0.9348\n",
      "Iter-91300, train loss-0.2086, acc-0.9400, valid loss-0.2209, acc-0.9372, test loss-0.2312, acc-0.9346\n",
      "Iter-91310, train loss-0.1642, acc-0.9600, valid loss-0.2208, acc-0.9368, test loss-0.2312, acc-0.9346\n",
      "Iter-91320, train loss-0.3336, acc-0.8800, valid loss-0.2207, acc-0.9370, test loss-0.2312, acc-0.9343\n",
      "Iter-91330, train loss-0.1479, acc-0.9400, valid loss-0.2207, acc-0.9372, test loss-0.2311, acc-0.9340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-91340, train loss-0.1609, acc-0.9600, valid loss-0.2207, acc-0.9370, test loss-0.2311, acc-0.9343\n",
      "Iter-91350, train loss-0.3825, acc-0.8800, valid loss-0.2207, acc-0.9372, test loss-0.2311, acc-0.9345\n",
      "Iter-91360, train loss-0.2208, acc-0.9600, valid loss-0.2207, acc-0.9374, test loss-0.2311, acc-0.9347\n",
      "Iter-91370, train loss-0.1269, acc-0.9600, valid loss-0.2206, acc-0.9374, test loss-0.2311, acc-0.9344\n",
      "Iter-91380, train loss-0.2081, acc-0.9400, valid loss-0.2206, acc-0.9376, test loss-0.2311, acc-0.9342\n",
      "Iter-91390, train loss-0.1674, acc-0.9400, valid loss-0.2206, acc-0.9372, test loss-0.2311, acc-0.9345\n",
      "Iter-91400, train loss-0.1290, acc-0.9600, valid loss-0.2206, acc-0.9370, test loss-0.2311, acc-0.9344\n",
      "Iter-91410, train loss-0.2804, acc-0.9000, valid loss-0.2205, acc-0.9368, test loss-0.2311, acc-0.9343\n",
      "Iter-91420, train loss-0.2603, acc-0.9000, valid loss-0.2206, acc-0.9370, test loss-0.2311, acc-0.9342\n",
      "Iter-91430, train loss-0.2424, acc-0.9600, valid loss-0.2206, acc-0.9370, test loss-0.2311, acc-0.9341\n",
      "Iter-91440, train loss-0.1617, acc-0.9400, valid loss-0.2206, acc-0.9370, test loss-0.2311, acc-0.9343\n",
      "Iter-91450, train loss-0.2949, acc-0.9000, valid loss-0.2207, acc-0.9370, test loss-0.2310, acc-0.9344\n",
      "Iter-91460, train loss-0.3236, acc-0.8800, valid loss-0.2207, acc-0.9368, test loss-0.2310, acc-0.9345\n",
      "Iter-91470, train loss-0.1939, acc-0.9400, valid loss-0.2207, acc-0.9370, test loss-0.2310, acc-0.9345\n",
      "Iter-91480, train loss-0.3046, acc-0.9000, valid loss-0.2207, acc-0.9370, test loss-0.2310, acc-0.9340\n",
      "Iter-91490, train loss-0.1369, acc-0.9800, valid loss-0.2207, acc-0.9368, test loss-0.2309, acc-0.9339\n",
      "Iter-91500, train loss-0.4598, acc-0.8400, valid loss-0.2207, acc-0.9368, test loss-0.2309, acc-0.9342\n",
      "Iter-91510, train loss-0.1732, acc-0.9200, valid loss-0.2207, acc-0.9370, test loss-0.2309, acc-0.9338\n",
      "Iter-91520, train loss-0.4106, acc-0.9000, valid loss-0.2207, acc-0.9374, test loss-0.2309, acc-0.9343\n",
      "Iter-91530, train loss-0.2260, acc-0.9400, valid loss-0.2207, acc-0.9364, test loss-0.2309, acc-0.9341\n",
      "Iter-91540, train loss-0.1697, acc-0.9600, valid loss-0.2207, acc-0.9366, test loss-0.2309, acc-0.9339\n",
      "Iter-91550, train loss-0.1383, acc-0.9800, valid loss-0.2208, acc-0.9366, test loss-0.2309, acc-0.9338\n",
      "Iter-91560, train loss-0.2108, acc-0.9400, valid loss-0.2207, acc-0.9366, test loss-0.2309, acc-0.9339\n",
      "Iter-91570, train loss-0.2050, acc-0.9400, valid loss-0.2207, acc-0.9364, test loss-0.2308, acc-0.9340\n",
      "Iter-91580, train loss-0.1492, acc-0.9600, valid loss-0.2206, acc-0.9362, test loss-0.2309, acc-0.9341\n",
      "Iter-91590, train loss-0.2609, acc-0.8800, valid loss-0.2206, acc-0.9362, test loss-0.2309, acc-0.9341\n",
      "Iter-91600, train loss-0.3813, acc-0.9200, valid loss-0.2207, acc-0.9366, test loss-0.2309, acc-0.9342\n",
      "Iter-91610, train loss-0.2622, acc-0.9000, valid loss-0.2206, acc-0.9366, test loss-0.2309, acc-0.9340\n",
      "Iter-91620, train loss-0.3054, acc-0.9000, valid loss-0.2206, acc-0.9366, test loss-0.2309, acc-0.9339\n",
      "Iter-91630, train loss-0.1444, acc-0.9800, valid loss-0.2206, acc-0.9372, test loss-0.2309, acc-0.9339\n",
      "Iter-91640, train loss-0.1341, acc-0.9600, valid loss-0.2206, acc-0.9366, test loss-0.2309, acc-0.9339\n",
      "Iter-91650, train loss-0.2233, acc-0.9400, valid loss-0.2206, acc-0.9368, test loss-0.2309, acc-0.9343\n",
      "Iter-91660, train loss-0.2239, acc-0.9200, valid loss-0.2206, acc-0.9366, test loss-0.2308, acc-0.9339\n",
      "Iter-91670, train loss-0.2446, acc-0.9400, valid loss-0.2206, acc-0.9368, test loss-0.2308, acc-0.9343\n",
      "Iter-91680, train loss-0.1851, acc-0.9800, valid loss-0.2205, acc-0.9374, test loss-0.2308, acc-0.9347\n",
      "Iter-91690, train loss-0.1058, acc-0.9800, valid loss-0.2205, acc-0.9376, test loss-0.2308, acc-0.9344\n",
      "Iter-91700, train loss-0.2293, acc-0.9400, valid loss-0.2205, acc-0.9374, test loss-0.2308, acc-0.9345\n",
      "Iter-91710, train loss-0.1886, acc-0.9600, valid loss-0.2205, acc-0.9372, test loss-0.2308, acc-0.9344\n",
      "Iter-91720, train loss-0.1163, acc-0.9600, valid loss-0.2205, acc-0.9372, test loss-0.2307, acc-0.9339\n",
      "Iter-91730, train loss-0.1638, acc-0.9800, valid loss-0.2204, acc-0.9374, test loss-0.2307, acc-0.9340\n",
      "Iter-91740, train loss-0.2932, acc-0.9200, valid loss-0.2204, acc-0.9374, test loss-0.2307, acc-0.9339\n",
      "Iter-91750, train loss-0.2976, acc-0.9200, valid loss-0.2203, acc-0.9380, test loss-0.2307, acc-0.9339\n",
      "Iter-91760, train loss-0.3357, acc-0.9600, valid loss-0.2203, acc-0.9382, test loss-0.2307, acc-0.9339\n",
      "Iter-91770, train loss-0.1631, acc-0.9400, valid loss-0.2203, acc-0.9380, test loss-0.2307, acc-0.9339\n",
      "Iter-91780, train loss-0.3542, acc-0.9000, valid loss-0.2203, acc-0.9378, test loss-0.2306, acc-0.9342\n",
      "Iter-91790, train loss-0.1379, acc-0.9600, valid loss-0.2203, acc-0.9376, test loss-0.2306, acc-0.9341\n",
      "Iter-91800, train loss-0.2130, acc-0.9200, valid loss-0.2202, acc-0.9378, test loss-0.2306, acc-0.9343\n",
      "Iter-91810, train loss-0.1773, acc-0.9600, valid loss-0.2202, acc-0.9380, test loss-0.2305, acc-0.9345\n",
      "Iter-91820, train loss-0.3117, acc-0.9000, valid loss-0.2203, acc-0.9380, test loss-0.2305, acc-0.9345\n",
      "Iter-91830, train loss-0.2438, acc-0.9000, valid loss-0.2202, acc-0.9380, test loss-0.2305, acc-0.9346\n",
      "Iter-91840, train loss-0.1455, acc-0.9600, valid loss-0.2202, acc-0.9380, test loss-0.2305, acc-0.9345\n",
      "Iter-91850, train loss-0.1273, acc-1.0000, valid loss-0.2202, acc-0.9382, test loss-0.2305, acc-0.9342\n",
      "Iter-91860, train loss-0.2172, acc-0.9600, valid loss-0.2202, acc-0.9384, test loss-0.2305, acc-0.9343\n",
      "Iter-91870, train loss-0.2217, acc-0.9600, valid loss-0.2201, acc-0.9378, test loss-0.2305, acc-0.9344\n",
      "Iter-91880, train loss-0.3219, acc-0.9200, valid loss-0.2200, acc-0.9376, test loss-0.2305, acc-0.9342\n",
      "Iter-91890, train loss-0.1717, acc-0.9400, valid loss-0.2199, acc-0.9378, test loss-0.2304, acc-0.9342\n",
      "Iter-91900, train loss-0.3495, acc-0.9200, valid loss-0.2199, acc-0.9378, test loss-0.2303, acc-0.9343\n",
      "Iter-91910, train loss-0.2100, acc-0.9400, valid loss-0.2198, acc-0.9380, test loss-0.2304, acc-0.9342\n",
      "Iter-91920, train loss-0.3312, acc-0.8800, valid loss-0.2198, acc-0.9380, test loss-0.2304, acc-0.9342\n",
      "Iter-91930, train loss-0.1502, acc-0.9600, valid loss-0.2198, acc-0.9380, test loss-0.2305, acc-0.9341\n",
      "Iter-91940, train loss-0.2100, acc-0.9400, valid loss-0.2198, acc-0.9380, test loss-0.2304, acc-0.9344\n",
      "Iter-91950, train loss-0.2153, acc-0.9400, valid loss-0.2197, acc-0.9380, test loss-0.2304, acc-0.9342\n",
      "Iter-91960, train loss-0.3181, acc-0.8800, valid loss-0.2197, acc-0.9380, test loss-0.2304, acc-0.9344\n",
      "Iter-91970, train loss-0.1847, acc-0.9400, valid loss-0.2197, acc-0.9380, test loss-0.2304, acc-0.9343\n",
      "Iter-91980, train loss-0.2370, acc-0.9200, valid loss-0.2197, acc-0.9378, test loss-0.2304, acc-0.9340\n",
      "Iter-91990, train loss-0.4798, acc-0.8200, valid loss-0.2198, acc-0.9376, test loss-0.2304, acc-0.9342\n",
      "Iter-92000, train loss-0.1521, acc-0.9600, valid loss-0.2198, acc-0.9376, test loss-0.2303, acc-0.9340\n",
      "Iter-92010, train loss-0.1741, acc-0.9800, valid loss-0.2198, acc-0.9378, test loss-0.2304, acc-0.9341\n",
      "Iter-92020, train loss-0.1427, acc-0.9600, valid loss-0.2198, acc-0.9380, test loss-0.2303, acc-0.9342\n",
      "Iter-92030, train loss-0.2462, acc-0.9600, valid loss-0.2199, acc-0.9382, test loss-0.2303, acc-0.9343\n",
      "Iter-92040, train loss-0.1737, acc-0.9600, valid loss-0.2198, acc-0.9380, test loss-0.2303, acc-0.9343\n",
      "Iter-92050, train loss-0.4830, acc-0.8600, valid loss-0.2198, acc-0.9382, test loss-0.2303, acc-0.9342\n",
      "Iter-92060, train loss-0.2721, acc-0.9600, valid loss-0.2198, acc-0.9380, test loss-0.2303, acc-0.9339\n",
      "Iter-92070, train loss-0.2794, acc-0.9200, valid loss-0.2199, acc-0.9380, test loss-0.2303, acc-0.9340\n",
      "Iter-92080, train loss-0.2296, acc-0.9200, valid loss-0.2199, acc-0.9376, test loss-0.2302, acc-0.9340\n",
      "Iter-92090, train loss-0.2392, acc-0.9000, valid loss-0.2199, acc-0.9374, test loss-0.2303, acc-0.9339\n",
      "Iter-92100, train loss-0.2450, acc-0.9200, valid loss-0.2199, acc-0.9376, test loss-0.2303, acc-0.9338\n",
      "Iter-92110, train loss-0.1163, acc-0.9800, valid loss-0.2199, acc-0.9376, test loss-0.2302, acc-0.9342\n",
      "Iter-92120, train loss-0.4070, acc-0.8800, valid loss-0.2199, acc-0.9376, test loss-0.2302, acc-0.9340\n",
      "Iter-92130, train loss-0.1664, acc-0.9000, valid loss-0.2199, acc-0.9374, test loss-0.2302, acc-0.9341\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-92140, train loss-0.1022, acc-1.0000, valid loss-0.2198, acc-0.9376, test loss-0.2302, acc-0.9339\n",
      "Iter-92150, train loss-0.1389, acc-0.9600, valid loss-0.2198, acc-0.9376, test loss-0.2301, acc-0.9339\n",
      "Iter-92160, train loss-0.1105, acc-0.9800, valid loss-0.2199, acc-0.9376, test loss-0.2301, acc-0.9339\n",
      "Iter-92170, train loss-0.2613, acc-0.9400, valid loss-0.2199, acc-0.9374, test loss-0.2301, acc-0.9339\n",
      "Iter-92180, train loss-0.2850, acc-0.8600, valid loss-0.2198, acc-0.9374, test loss-0.2301, acc-0.9339\n",
      "Iter-92190, train loss-0.2598, acc-0.9400, valid loss-0.2198, acc-0.9376, test loss-0.2301, acc-0.9339\n",
      "Iter-92200, train loss-0.3111, acc-0.8800, valid loss-0.2198, acc-0.9372, test loss-0.2301, acc-0.9338\n",
      "Iter-92210, train loss-0.4388, acc-0.8800, valid loss-0.2197, acc-0.9372, test loss-0.2301, acc-0.9339\n",
      "Iter-92220, train loss-0.3301, acc-0.9200, valid loss-0.2198, acc-0.9378, test loss-0.2301, acc-0.9340\n",
      "Iter-92230, train loss-0.1444, acc-0.9800, valid loss-0.2198, acc-0.9380, test loss-0.2301, acc-0.9340\n",
      "Iter-92240, train loss-0.1415, acc-0.9800, valid loss-0.2198, acc-0.9380, test loss-0.2301, acc-0.9341\n",
      "Iter-92250, train loss-0.1499, acc-0.9600, valid loss-0.2198, acc-0.9380, test loss-0.2301, acc-0.9339\n",
      "Iter-92260, train loss-0.2880, acc-0.9600, valid loss-0.2198, acc-0.9378, test loss-0.2301, acc-0.9340\n",
      "Iter-92270, train loss-0.1584, acc-0.9600, valid loss-0.2197, acc-0.9380, test loss-0.2301, acc-0.9340\n",
      "Iter-92280, train loss-0.2042, acc-0.9200, valid loss-0.2197, acc-0.9380, test loss-0.2301, acc-0.9342\n",
      "Iter-92290, train loss-0.3336, acc-0.9000, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9344\n",
      "Iter-92300, train loss-0.1232, acc-0.9800, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9344\n",
      "Iter-92310, train loss-0.1398, acc-0.9600, valid loss-0.2197, acc-0.9376, test loss-0.2301, acc-0.9342\n",
      "Iter-92320, train loss-0.2841, acc-0.9200, valid loss-0.2196, acc-0.9378, test loss-0.2301, acc-0.9343\n",
      "Iter-92330, train loss-0.1307, acc-0.9400, valid loss-0.2197, acc-0.9380, test loss-0.2301, acc-0.9342\n",
      "Iter-92340, train loss-0.1470, acc-0.9600, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9341\n",
      "Iter-92350, train loss-0.1144, acc-0.9800, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9343\n",
      "Iter-92360, train loss-0.1620, acc-0.9400, valid loss-0.2196, acc-0.9376, test loss-0.2301, acc-0.9343\n",
      "Iter-92370, train loss-0.1131, acc-0.9600, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9345\n",
      "Iter-92380, train loss-0.1899, acc-0.9600, valid loss-0.2197, acc-0.9378, test loss-0.2301, acc-0.9346\n",
      "Iter-92390, train loss-0.0933, acc-0.9800, valid loss-0.2197, acc-0.9378, test loss-0.2300, acc-0.9347\n",
      "Iter-92400, train loss-0.2727, acc-0.9000, valid loss-0.2196, acc-0.9376, test loss-0.2300, acc-0.9345\n",
      "Iter-92410, train loss-0.3445, acc-0.9200, valid loss-0.2196, acc-0.9374, test loss-0.2300, acc-0.9345\n",
      "Iter-92420, train loss-0.3209, acc-0.8800, valid loss-0.2196, acc-0.9374, test loss-0.2301, acc-0.9346\n",
      "Iter-92430, train loss-0.1596, acc-0.9600, valid loss-0.2196, acc-0.9372, test loss-0.2300, acc-0.9348\n",
      "Iter-92440, train loss-0.1533, acc-0.9400, valid loss-0.2196, acc-0.9374, test loss-0.2300, acc-0.9348\n",
      "Iter-92450, train loss-0.2188, acc-0.9400, valid loss-0.2196, acc-0.9374, test loss-0.2301, acc-0.9348\n",
      "Iter-92460, train loss-0.1230, acc-0.9800, valid loss-0.2195, acc-0.9372, test loss-0.2301, acc-0.9348\n",
      "Iter-92470, train loss-0.1162, acc-0.9600, valid loss-0.2195, acc-0.9374, test loss-0.2301, acc-0.9347\n",
      "Iter-92480, train loss-0.1373, acc-0.9800, valid loss-0.2194, acc-0.9376, test loss-0.2301, acc-0.9345\n",
      "Iter-92490, train loss-0.1354, acc-0.9600, valid loss-0.2194, acc-0.9376, test loss-0.2301, acc-0.9346\n",
      "Iter-92500, train loss-0.1573, acc-0.9600, valid loss-0.2194, acc-0.9376, test loss-0.2301, acc-0.9345\n",
      "Iter-92510, train loss-0.2406, acc-0.9200, valid loss-0.2195, acc-0.9374, test loss-0.2301, acc-0.9343\n",
      "Iter-92520, train loss-0.1630, acc-0.9600, valid loss-0.2194, acc-0.9374, test loss-0.2301, acc-0.9344\n",
      "Iter-92530, train loss-0.3698, acc-0.8800, valid loss-0.2195, acc-0.9376, test loss-0.2301, acc-0.9344\n",
      "Iter-92540, train loss-0.1807, acc-0.9200, valid loss-0.2195, acc-0.9374, test loss-0.2301, acc-0.9343\n",
      "Iter-92550, train loss-0.5059, acc-0.8400, valid loss-0.2195, acc-0.9376, test loss-0.2301, acc-0.9345\n",
      "Iter-92560, train loss-0.1095, acc-0.9800, valid loss-0.2195, acc-0.9376, test loss-0.2300, acc-0.9345\n",
      "Iter-92570, train loss-0.4082, acc-0.9000, valid loss-0.2195, acc-0.9376, test loss-0.2300, acc-0.9345\n",
      "Iter-92580, train loss-0.1130, acc-0.9800, valid loss-0.2196, acc-0.9376, test loss-0.2299, acc-0.9347\n",
      "Iter-92590, train loss-0.3372, acc-0.8800, valid loss-0.2196, acc-0.9374, test loss-0.2300, acc-0.9347\n",
      "Iter-92600, train loss-0.2287, acc-0.9400, valid loss-0.2196, acc-0.9376, test loss-0.2300, acc-0.9347\n",
      "Iter-92610, train loss-0.3917, acc-0.9200, valid loss-0.2195, acc-0.9372, test loss-0.2299, acc-0.9347\n",
      "Iter-92620, train loss-0.3514, acc-0.9200, valid loss-0.2195, acc-0.9374, test loss-0.2299, acc-0.9347\n",
      "Iter-92630, train loss-0.1965, acc-0.9600, valid loss-0.2194, acc-0.9374, test loss-0.2298, acc-0.9347\n",
      "Iter-92640, train loss-0.2017, acc-0.9200, valid loss-0.2194, acc-0.9372, test loss-0.2298, acc-0.9346\n",
      "Iter-92650, train loss-0.3979, acc-0.9000, valid loss-0.2194, acc-0.9372, test loss-0.2297, acc-0.9347\n",
      "Iter-92660, train loss-0.2340, acc-0.9000, valid loss-0.2194, acc-0.9372, test loss-0.2298, acc-0.9347\n",
      "Iter-92670, train loss-0.2384, acc-0.9400, valid loss-0.2194, acc-0.9370, test loss-0.2298, acc-0.9348\n",
      "Iter-92680, train loss-0.1891, acc-0.9600, valid loss-0.2194, acc-0.9372, test loss-0.2297, acc-0.9348\n",
      "Iter-92690, train loss-0.3672, acc-0.9200, valid loss-0.2194, acc-0.9374, test loss-0.2297, acc-0.9348\n",
      "Iter-92700, train loss-0.1530, acc-0.9800, valid loss-0.2194, acc-0.9374, test loss-0.2297, acc-0.9348\n",
      "Iter-92710, train loss-0.1747, acc-0.9400, valid loss-0.2194, acc-0.9374, test loss-0.2297, acc-0.9348\n",
      "Iter-92720, train loss-0.2236, acc-0.9400, valid loss-0.2194, acc-0.9374, test loss-0.2297, acc-0.9345\n",
      "Iter-92730, train loss-0.2735, acc-0.9400, valid loss-0.2194, acc-0.9376, test loss-0.2297, acc-0.9346\n",
      "Iter-92740, train loss-0.3292, acc-0.9200, valid loss-0.2194, acc-0.9372, test loss-0.2296, acc-0.9346\n",
      "Iter-92750, train loss-0.2543, acc-0.9400, valid loss-0.2194, acc-0.9372, test loss-0.2296, acc-0.9345\n",
      "Iter-92760, train loss-0.3223, acc-0.9000, valid loss-0.2194, acc-0.9370, test loss-0.2296, acc-0.9345\n",
      "Iter-92770, train loss-0.1274, acc-0.9800, valid loss-0.2194, acc-0.9370, test loss-0.2296, acc-0.9347\n",
      "Iter-92780, train loss-0.2803, acc-0.9400, valid loss-0.2194, acc-0.9372, test loss-0.2296, acc-0.9346\n",
      "Iter-92790, train loss-0.2184, acc-0.9600, valid loss-0.2193, acc-0.9374, test loss-0.2296, acc-0.9345\n",
      "Iter-92800, train loss-0.2374, acc-0.9200, valid loss-0.2194, acc-0.9374, test loss-0.2297, acc-0.9345\n",
      "Iter-92810, train loss-0.2763, acc-0.9200, valid loss-0.2193, acc-0.9376, test loss-0.2297, acc-0.9345\n",
      "Iter-92820, train loss-0.2797, acc-0.9000, valid loss-0.2193, acc-0.9372, test loss-0.2296, acc-0.9343\n",
      "Iter-92830, train loss-0.4019, acc-0.8400, valid loss-0.2193, acc-0.9374, test loss-0.2296, acc-0.9344\n",
      "Iter-92840, train loss-0.1587, acc-0.9200, valid loss-0.2193, acc-0.9370, test loss-0.2296, acc-0.9343\n",
      "Iter-92850, train loss-0.2400, acc-0.9200, valid loss-0.2192, acc-0.9372, test loss-0.2296, acc-0.9347\n",
      "Iter-92860, train loss-0.1480, acc-0.9400, valid loss-0.2192, acc-0.9372, test loss-0.2296, acc-0.9347\n",
      "Iter-92870, train loss-0.1996, acc-0.9600, valid loss-0.2193, acc-0.9372, test loss-0.2295, acc-0.9345\n",
      "Iter-92880, train loss-0.2009, acc-0.9400, valid loss-0.2193, acc-0.9372, test loss-0.2295, acc-0.9347\n",
      "Iter-92890, train loss-0.2023, acc-0.9400, valid loss-0.2193, acc-0.9374, test loss-0.2295, acc-0.9347\n",
      "Iter-92900, train loss-0.3770, acc-0.9400, valid loss-0.2192, acc-0.9374, test loss-0.2295, acc-0.9347\n",
      "Iter-92910, train loss-0.0859, acc-1.0000, valid loss-0.2193, acc-0.9374, test loss-0.2294, acc-0.9348\n",
      "Iter-92920, train loss-0.1802, acc-0.9600, valid loss-0.2193, acc-0.9372, test loss-0.2294, acc-0.9348\n",
      "Iter-92930, train loss-0.2342, acc-0.9000, valid loss-0.2193, acc-0.9374, test loss-0.2294, acc-0.9350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-92940, train loss-0.4030, acc-0.8600, valid loss-0.2193, acc-0.9372, test loss-0.2293, acc-0.9349\n",
      "Iter-92950, train loss-0.1730, acc-0.9800, valid loss-0.2194, acc-0.9374, test loss-0.2293, acc-0.9350\n",
      "Iter-92960, train loss-0.1891, acc-0.9400, valid loss-0.2193, acc-0.9374, test loss-0.2293, acc-0.9351\n",
      "Iter-92970, train loss-0.5872, acc-0.8600, valid loss-0.2193, acc-0.9374, test loss-0.2293, acc-0.9352\n",
      "Iter-92980, train loss-0.1252, acc-0.9600, valid loss-0.2193, acc-0.9372, test loss-0.2293, acc-0.9352\n",
      "Iter-92990, train loss-0.2812, acc-0.9200, valid loss-0.2193, acc-0.9374, test loss-0.2293, acc-0.9351\n",
      "Iter-93000, train loss-0.4531, acc-0.8800, valid loss-0.2194, acc-0.9372, test loss-0.2293, acc-0.9351\n",
      "Iter-93010, train loss-0.2549, acc-0.9000, valid loss-0.2194, acc-0.9372, test loss-0.2293, acc-0.9349\n",
      "Iter-93020, train loss-0.1510, acc-0.9600, valid loss-0.2193, acc-0.9374, test loss-0.2293, acc-0.9349\n",
      "Iter-93030, train loss-0.2859, acc-0.9200, valid loss-0.2193, acc-0.9370, test loss-0.2293, acc-0.9348\n",
      "Iter-93040, train loss-0.3493, acc-0.9000, valid loss-0.2193, acc-0.9366, test loss-0.2293, acc-0.9347\n",
      "Iter-93050, train loss-0.1834, acc-0.9200, valid loss-0.2192, acc-0.9372, test loss-0.2293, acc-0.9347\n",
      "Iter-93060, train loss-0.3251, acc-0.8800, valid loss-0.2192, acc-0.9374, test loss-0.2292, acc-0.9350\n",
      "Iter-93070, train loss-0.2045, acc-0.9400, valid loss-0.2191, acc-0.9370, test loss-0.2292, acc-0.9349\n",
      "Iter-93080, train loss-0.1904, acc-0.9600, valid loss-0.2191, acc-0.9370, test loss-0.2292, acc-0.9348\n",
      "Iter-93090, train loss-0.1694, acc-0.9400, valid loss-0.2190, acc-0.9372, test loss-0.2292, acc-0.9348\n",
      "Iter-93100, train loss-0.1549, acc-0.9400, valid loss-0.2190, acc-0.9374, test loss-0.2292, acc-0.9347\n",
      "Iter-93110, train loss-0.2337, acc-0.8800, valid loss-0.2190, acc-0.9374, test loss-0.2291, acc-0.9346\n",
      "Iter-93120, train loss-0.1713, acc-0.9600, valid loss-0.2190, acc-0.9374, test loss-0.2291, acc-0.9346\n",
      "Iter-93130, train loss-0.3696, acc-0.9200, valid loss-0.2190, acc-0.9374, test loss-0.2290, acc-0.9346\n",
      "Iter-93140, train loss-0.3117, acc-0.9400, valid loss-0.2190, acc-0.9374, test loss-0.2290, acc-0.9345\n",
      "Iter-93150, train loss-0.2580, acc-0.9600, valid loss-0.2190, acc-0.9374, test loss-0.2290, acc-0.9347\n",
      "Iter-93160, train loss-0.0746, acc-0.9800, valid loss-0.2191, acc-0.9376, test loss-0.2290, acc-0.9348\n",
      "Iter-93170, train loss-0.3605, acc-0.9200, valid loss-0.2190, acc-0.9378, test loss-0.2290, acc-0.9348\n",
      "Iter-93180, train loss-0.2842, acc-0.9000, valid loss-0.2190, acc-0.9378, test loss-0.2289, acc-0.9348\n",
      "Iter-93190, train loss-0.1897, acc-0.9400, valid loss-0.2190, acc-0.9378, test loss-0.2290, acc-0.9345\n",
      "Iter-93200, train loss-0.3350, acc-0.9400, valid loss-0.2189, acc-0.9378, test loss-0.2289, acc-0.9348\n",
      "Iter-93210, train loss-0.1575, acc-0.9800, valid loss-0.2189, acc-0.9378, test loss-0.2289, acc-0.9345\n",
      "Iter-93220, train loss-0.3693, acc-0.8400, valid loss-0.2189, acc-0.9378, test loss-0.2288, acc-0.9345\n",
      "Iter-93230, train loss-0.1501, acc-0.9800, valid loss-0.2190, acc-0.9380, test loss-0.2288, acc-0.9347\n",
      "Iter-93240, train loss-0.1485, acc-0.9600, valid loss-0.2189, acc-0.9380, test loss-0.2289, acc-0.9346\n",
      "Iter-93250, train loss-0.1457, acc-0.9800, valid loss-0.2189, acc-0.9378, test loss-0.2289, acc-0.9346\n",
      "Iter-93260, train loss-0.0898, acc-0.9600, valid loss-0.2188, acc-0.9380, test loss-0.2288, acc-0.9346\n",
      "Iter-93270, train loss-0.2405, acc-0.8800, valid loss-0.2188, acc-0.9376, test loss-0.2288, acc-0.9347\n",
      "Iter-93280, train loss-0.2063, acc-0.9400, valid loss-0.2189, acc-0.9378, test loss-0.2288, acc-0.9346\n",
      "Iter-93290, train loss-0.3151, acc-0.9600, valid loss-0.2188, acc-0.9380, test loss-0.2288, acc-0.9346\n",
      "Iter-93300, train loss-0.2606, acc-0.9200, valid loss-0.2189, acc-0.9374, test loss-0.2288, acc-0.9345\n",
      "Iter-93310, train loss-0.1089, acc-0.9600, valid loss-0.2188, acc-0.9374, test loss-0.2288, acc-0.9346\n",
      "Iter-93320, train loss-0.1651, acc-0.9800, valid loss-0.2189, acc-0.9374, test loss-0.2288, acc-0.9346\n",
      "Iter-93330, train loss-0.3127, acc-0.9000, valid loss-0.2188, acc-0.9372, test loss-0.2288, acc-0.9346\n",
      "Iter-93340, train loss-0.1605, acc-0.9400, valid loss-0.2188, acc-0.9372, test loss-0.2288, acc-0.9349\n",
      "Iter-93350, train loss-0.3033, acc-0.9200, valid loss-0.2188, acc-0.9372, test loss-0.2288, acc-0.9348\n",
      "Iter-93360, train loss-0.1608, acc-0.9600, valid loss-0.2188, acc-0.9376, test loss-0.2288, acc-0.9348\n",
      "Iter-93370, train loss-0.1088, acc-0.9800, valid loss-0.2188, acc-0.9380, test loss-0.2288, acc-0.9346\n",
      "Iter-93380, train loss-0.3458, acc-0.8800, valid loss-0.2188, acc-0.9378, test loss-0.2288, acc-0.9348\n",
      "Iter-93390, train loss-0.2460, acc-0.9400, valid loss-0.2188, acc-0.9378, test loss-0.2288, acc-0.9345\n",
      "Iter-93400, train loss-0.2135, acc-0.9600, valid loss-0.2187, acc-0.9376, test loss-0.2288, acc-0.9346\n",
      "Iter-93410, train loss-0.1284, acc-0.9800, valid loss-0.2187, acc-0.9372, test loss-0.2288, acc-0.9342\n",
      "Iter-93420, train loss-0.1030, acc-0.9600, valid loss-0.2187, acc-0.9372, test loss-0.2288, acc-0.9343\n",
      "Iter-93430, train loss-0.2185, acc-0.9200, valid loss-0.2187, acc-0.9372, test loss-0.2288, acc-0.9341\n",
      "Iter-93440, train loss-0.2128, acc-0.9200, valid loss-0.2187, acc-0.9374, test loss-0.2288, acc-0.9344\n",
      "Iter-93450, train loss-0.2610, acc-0.9000, valid loss-0.2187, acc-0.9374, test loss-0.2288, acc-0.9347\n",
      "Iter-93460, train loss-0.1020, acc-1.0000, valid loss-0.2187, acc-0.9374, test loss-0.2288, acc-0.9347\n",
      "Iter-93470, train loss-0.1944, acc-0.9600, valid loss-0.2187, acc-0.9374, test loss-0.2288, acc-0.9348\n",
      "Iter-93480, train loss-0.1343, acc-0.9600, valid loss-0.2187, acc-0.9374, test loss-0.2287, acc-0.9343\n",
      "Iter-93490, train loss-0.3514, acc-0.9000, valid loss-0.2187, acc-0.9372, test loss-0.2287, acc-0.9346\n",
      "Iter-93500, train loss-0.2366, acc-0.9200, valid loss-0.2187, acc-0.9376, test loss-0.2287, acc-0.9346\n",
      "Iter-93510, train loss-0.2148, acc-0.9200, valid loss-0.2186, acc-0.9378, test loss-0.2286, acc-0.9345\n",
      "Iter-93520, train loss-0.4291, acc-0.8800, valid loss-0.2186, acc-0.9378, test loss-0.2286, acc-0.9346\n",
      "Iter-93530, train loss-0.2026, acc-0.9400, valid loss-0.2186, acc-0.9376, test loss-0.2286, acc-0.9346\n",
      "Iter-93540, train loss-0.3758, acc-0.8800, valid loss-0.2186, acc-0.9380, test loss-0.2285, acc-0.9349\n",
      "Iter-93550, train loss-0.1029, acc-0.9800, valid loss-0.2186, acc-0.9378, test loss-0.2285, acc-0.9346\n",
      "Iter-93560, train loss-0.2923, acc-0.9000, valid loss-0.2186, acc-0.9380, test loss-0.2285, acc-0.9345\n",
      "Iter-93570, train loss-0.3861, acc-0.8600, valid loss-0.2186, acc-0.9378, test loss-0.2285, acc-0.9345\n",
      "Iter-93580, train loss-0.1409, acc-0.9600, valid loss-0.2185, acc-0.9378, test loss-0.2285, acc-0.9346\n",
      "Iter-93590, train loss-0.1669, acc-0.9800, valid loss-0.2185, acc-0.9380, test loss-0.2284, acc-0.9348\n",
      "Iter-93600, train loss-0.1773, acc-0.9600, valid loss-0.2185, acc-0.9380, test loss-0.2284, acc-0.9348\n",
      "Iter-93610, train loss-0.4456, acc-0.8600, valid loss-0.2185, acc-0.9380, test loss-0.2284, acc-0.9349\n",
      "Iter-93620, train loss-0.1526, acc-0.9800, valid loss-0.2185, acc-0.9380, test loss-0.2284, acc-0.9350\n",
      "Iter-93630, train loss-0.2410, acc-0.9000, valid loss-0.2185, acc-0.9378, test loss-0.2283, acc-0.9350\n",
      "Iter-93640, train loss-0.1677, acc-0.9800, valid loss-0.2185, acc-0.9382, test loss-0.2283, acc-0.9351\n",
      "Iter-93650, train loss-0.1495, acc-0.9800, valid loss-0.2185, acc-0.9382, test loss-0.2282, acc-0.9353\n",
      "Iter-93660, train loss-0.1820, acc-0.9600, valid loss-0.2184, acc-0.9384, test loss-0.2282, acc-0.9348\n",
      "Iter-93670, train loss-0.3882, acc-0.9000, valid loss-0.2184, acc-0.9378, test loss-0.2282, acc-0.9348\n",
      "Iter-93680, train loss-0.2547, acc-0.9400, valid loss-0.2184, acc-0.9380, test loss-0.2281, acc-0.9352\n",
      "Iter-93690, train loss-0.2889, acc-0.9200, valid loss-0.2184, acc-0.9382, test loss-0.2281, acc-0.9351\n",
      "Iter-93700, train loss-0.2767, acc-0.8800, valid loss-0.2183, acc-0.9380, test loss-0.2281, acc-0.9352\n",
      "Iter-93710, train loss-0.3498, acc-0.8600, valid loss-0.2183, acc-0.9384, test loss-0.2281, acc-0.9353\n",
      "Iter-93720, train loss-0.1762, acc-0.9400, valid loss-0.2182, acc-0.9382, test loss-0.2281, acc-0.9353\n",
      "Iter-93730, train loss-0.1965, acc-0.9400, valid loss-0.2182, acc-0.9380, test loss-0.2280, acc-0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-93740, train loss-0.2223, acc-0.9200, valid loss-0.2183, acc-0.9382, test loss-0.2280, acc-0.9355\n",
      "Iter-93750, train loss-0.3806, acc-0.8600, valid loss-0.2182, acc-0.9386, test loss-0.2280, acc-0.9353\n",
      "Iter-93760, train loss-0.1661, acc-0.9400, valid loss-0.2182, acc-0.9382, test loss-0.2280, acc-0.9355\n",
      "Iter-93770, train loss-0.1743, acc-0.9400, valid loss-0.2183, acc-0.9380, test loss-0.2280, acc-0.9353\n",
      "Iter-93780, train loss-0.2409, acc-0.9600, valid loss-0.2183, acc-0.9380, test loss-0.2280, acc-0.9354\n",
      "Iter-93790, train loss-0.2163, acc-0.9400, valid loss-0.2183, acc-0.9380, test loss-0.2280, acc-0.9352\n",
      "Iter-93800, train loss-0.2707, acc-0.9200, valid loss-0.2183, acc-0.9380, test loss-0.2280, acc-0.9349\n",
      "Iter-93810, train loss-0.2424, acc-0.9200, valid loss-0.2182, acc-0.9378, test loss-0.2280, acc-0.9351\n",
      "Iter-93820, train loss-0.1124, acc-0.9600, valid loss-0.2181, acc-0.9380, test loss-0.2280, acc-0.9353\n",
      "Iter-93830, train loss-0.2935, acc-0.9200, valid loss-0.2181, acc-0.9382, test loss-0.2279, acc-0.9353\n",
      "Iter-93840, train loss-0.2297, acc-0.9200, valid loss-0.2181, acc-0.9384, test loss-0.2280, acc-0.9354\n",
      "Iter-93850, train loss-0.1634, acc-0.9400, valid loss-0.2181, acc-0.9384, test loss-0.2279, acc-0.9352\n",
      "Iter-93860, train loss-0.2283, acc-0.9000, valid loss-0.2181, acc-0.9382, test loss-0.2280, acc-0.9352\n",
      "Iter-93870, train loss-0.0576, acc-0.9800, valid loss-0.2181, acc-0.9384, test loss-0.2279, acc-0.9355\n",
      "Iter-93880, train loss-0.3989, acc-0.9000, valid loss-0.2181, acc-0.9382, test loss-0.2279, acc-0.9354\n",
      "Iter-93890, train loss-0.1073, acc-0.9800, valid loss-0.2181, acc-0.9382, test loss-0.2279, acc-0.9356\n",
      "Iter-93900, train loss-0.1568, acc-0.9400, valid loss-0.2182, acc-0.9382, test loss-0.2279, acc-0.9354\n",
      "Iter-93910, train loss-0.2734, acc-0.9000, valid loss-0.2181, acc-0.9382, test loss-0.2278, acc-0.9355\n",
      "Iter-93920, train loss-0.1915, acc-0.9600, valid loss-0.2181, acc-0.9382, test loss-0.2278, acc-0.9351\n",
      "Iter-93930, train loss-0.2616, acc-0.9400, valid loss-0.2180, acc-0.9384, test loss-0.2278, acc-0.9353\n",
      "Iter-93940, train loss-0.1213, acc-0.9600, valid loss-0.2180, acc-0.9382, test loss-0.2278, acc-0.9350\n",
      "Iter-93950, train loss-0.1777, acc-0.9600, valid loss-0.2181, acc-0.9382, test loss-0.2278, acc-0.9350\n",
      "Iter-93960, train loss-0.3534, acc-0.9600, valid loss-0.2181, acc-0.9382, test loss-0.2279, acc-0.9352\n",
      "Iter-93970, train loss-0.2067, acc-0.9400, valid loss-0.2180, acc-0.9382, test loss-0.2279, acc-0.9352\n",
      "Iter-93980, train loss-0.2334, acc-0.9400, valid loss-0.2180, acc-0.9382, test loss-0.2279, acc-0.9351\n",
      "Iter-93990, train loss-0.3606, acc-0.8600, valid loss-0.2180, acc-0.9382, test loss-0.2279, acc-0.9352\n",
      "Iter-94000, train loss-0.1786, acc-0.9600, valid loss-0.2180, acc-0.9382, test loss-0.2280, acc-0.9351\n",
      "Iter-94010, train loss-0.1190, acc-0.9600, valid loss-0.2180, acc-0.9380, test loss-0.2279, acc-0.9350\n",
      "Iter-94020, train loss-0.1567, acc-0.9800, valid loss-0.2180, acc-0.9382, test loss-0.2279, acc-0.9351\n",
      "Iter-94030, train loss-0.3003, acc-0.9200, valid loss-0.2181, acc-0.9380, test loss-0.2279, acc-0.9352\n",
      "Iter-94040, train loss-0.2950, acc-0.9400, valid loss-0.2181, acc-0.9378, test loss-0.2279, acc-0.9351\n",
      "Iter-94050, train loss-0.1752, acc-0.9400, valid loss-0.2181, acc-0.9378, test loss-0.2279, acc-0.9351\n",
      "Iter-94060, train loss-0.3907, acc-0.8800, valid loss-0.2180, acc-0.9378, test loss-0.2279, acc-0.9351\n",
      "Iter-94070, train loss-0.2200, acc-0.9200, valid loss-0.2180, acc-0.9378, test loss-0.2279, acc-0.9353\n",
      "Iter-94080, train loss-0.2523, acc-0.9200, valid loss-0.2180, acc-0.9376, test loss-0.2278, acc-0.9354\n",
      "Iter-94090, train loss-0.1814, acc-0.9400, valid loss-0.2180, acc-0.9376, test loss-0.2278, acc-0.9351\n",
      "Iter-94100, train loss-0.1959, acc-0.9400, valid loss-0.2180, acc-0.9380, test loss-0.2279, acc-0.9351\n",
      "Iter-94110, train loss-0.0966, acc-0.9800, valid loss-0.2179, acc-0.9378, test loss-0.2279, acc-0.9350\n",
      "Iter-94120, train loss-0.1620, acc-0.9600, valid loss-0.2179, acc-0.9378, test loss-0.2279, acc-0.9349\n",
      "Iter-94130, train loss-0.3226, acc-0.9200, valid loss-0.2179, acc-0.9380, test loss-0.2279, acc-0.9352\n",
      "Iter-94140, train loss-0.1609, acc-0.9600, valid loss-0.2180, acc-0.9380, test loss-0.2278, acc-0.9354\n",
      "Iter-94150, train loss-0.2013, acc-0.9400, valid loss-0.2180, acc-0.9380, test loss-0.2279, acc-0.9350\n",
      "Iter-94160, train loss-0.0915, acc-1.0000, valid loss-0.2180, acc-0.9378, test loss-0.2279, acc-0.9352\n",
      "Iter-94170, train loss-0.2581, acc-0.9600, valid loss-0.2179, acc-0.9380, test loss-0.2278, acc-0.9352\n",
      "Iter-94180, train loss-0.1122, acc-0.9800, valid loss-0.2178, acc-0.9380, test loss-0.2278, acc-0.9354\n",
      "Iter-94190, train loss-0.4191, acc-0.9000, valid loss-0.2178, acc-0.9376, test loss-0.2278, acc-0.9358\n",
      "Iter-94200, train loss-0.3208, acc-0.9400, valid loss-0.2177, acc-0.9378, test loss-0.2277, acc-0.9359\n",
      "Iter-94210, train loss-0.1350, acc-0.9600, valid loss-0.2177, acc-0.9378, test loss-0.2276, acc-0.9359\n",
      "Iter-94220, train loss-0.1554, acc-0.9800, valid loss-0.2177, acc-0.9380, test loss-0.2276, acc-0.9360\n",
      "Iter-94230, train loss-0.1744, acc-0.9600, valid loss-0.2177, acc-0.9380, test loss-0.2276, acc-0.9360\n",
      "Iter-94240, train loss-0.3956, acc-0.9000, valid loss-0.2177, acc-0.9378, test loss-0.2276, acc-0.9356\n",
      "Iter-94250, train loss-0.1233, acc-0.9600, valid loss-0.2177, acc-0.9382, test loss-0.2276, acc-0.9355\n",
      "Iter-94260, train loss-0.2558, acc-0.9200, valid loss-0.2177, acc-0.9384, test loss-0.2276, acc-0.9355\n",
      "Iter-94270, train loss-0.1074, acc-0.9800, valid loss-0.2176, acc-0.9386, test loss-0.2276, acc-0.9358\n",
      "Iter-94280, train loss-0.0965, acc-1.0000, valid loss-0.2176, acc-0.9382, test loss-0.2276, acc-0.9355\n",
      "Iter-94290, train loss-0.1063, acc-0.9800, valid loss-0.2176, acc-0.9380, test loss-0.2276, acc-0.9356\n",
      "Iter-94300, train loss-0.1836, acc-0.9400, valid loss-0.2176, acc-0.9382, test loss-0.2276, acc-0.9355\n",
      "Iter-94310, train loss-0.1103, acc-0.9600, valid loss-0.2175, acc-0.9382, test loss-0.2276, acc-0.9356\n",
      "Iter-94320, train loss-0.1591, acc-0.9600, valid loss-0.2175, acc-0.9380, test loss-0.2276, acc-0.9358\n",
      "Iter-94330, train loss-0.2674, acc-0.9200, valid loss-0.2174, acc-0.9382, test loss-0.2276, acc-0.9357\n",
      "Iter-94340, train loss-0.2133, acc-0.9400, valid loss-0.2174, acc-0.9388, test loss-0.2275, acc-0.9358\n",
      "Iter-94350, train loss-0.1307, acc-0.9600, valid loss-0.2174, acc-0.9386, test loss-0.2275, acc-0.9357\n",
      "Iter-94360, train loss-0.2150, acc-0.9000, valid loss-0.2173, acc-0.9386, test loss-0.2275, acc-0.9358\n",
      "Iter-94370, train loss-0.1539, acc-0.9400, valid loss-0.2173, acc-0.9388, test loss-0.2275, acc-0.9357\n",
      "Iter-94380, train loss-0.5327, acc-0.8600, valid loss-0.2173, acc-0.9386, test loss-0.2274, acc-0.9357\n",
      "Iter-94390, train loss-0.1781, acc-0.9200, valid loss-0.2173, acc-0.9386, test loss-0.2274, acc-0.9355\n",
      "Iter-94400, train loss-0.2397, acc-0.9000, valid loss-0.2173, acc-0.9388, test loss-0.2273, acc-0.9355\n",
      "Iter-94410, train loss-0.2152, acc-0.9400, valid loss-0.2173, acc-0.9386, test loss-0.2273, acc-0.9359\n",
      "Iter-94420, train loss-0.1490, acc-0.9800, valid loss-0.2173, acc-0.9384, test loss-0.2273, acc-0.9360\n",
      "Iter-94430, train loss-0.2643, acc-0.9000, valid loss-0.2173, acc-0.9380, test loss-0.2273, acc-0.9359\n",
      "Iter-94440, train loss-0.2355, acc-0.9400, valid loss-0.2172, acc-0.9382, test loss-0.2273, acc-0.9359\n",
      "Iter-94450, train loss-0.3185, acc-0.8800, valid loss-0.2172, acc-0.9380, test loss-0.2273, acc-0.9359\n",
      "Iter-94460, train loss-0.3599, acc-0.9400, valid loss-0.2172, acc-0.9382, test loss-0.2273, acc-0.9357\n",
      "Iter-94470, train loss-0.1238, acc-0.9800, valid loss-0.2171, acc-0.9374, test loss-0.2273, acc-0.9355\n",
      "Iter-94480, train loss-0.1499, acc-0.9800, valid loss-0.2170, acc-0.9380, test loss-0.2274, acc-0.9355\n",
      "Iter-94490, train loss-0.0765, acc-0.9800, valid loss-0.2170, acc-0.9378, test loss-0.2273, acc-0.9353\n",
      "Iter-94500, train loss-0.2070, acc-0.9600, valid loss-0.2170, acc-0.9382, test loss-0.2273, acc-0.9351\n",
      "Iter-94510, train loss-0.2136, acc-0.9400, valid loss-0.2170, acc-0.9378, test loss-0.2273, acc-0.9352\n",
      "Iter-94520, train loss-0.2747, acc-0.9000, valid loss-0.2171, acc-0.9380, test loss-0.2273, acc-0.9353\n",
      "Iter-94530, train loss-0.2529, acc-0.9000, valid loss-0.2171, acc-0.9380, test loss-0.2272, acc-0.9355\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-94540, train loss-0.1884, acc-0.9400, valid loss-0.2171, acc-0.9378, test loss-0.2272, acc-0.9353\n",
      "Iter-94550, train loss-0.2164, acc-0.9200, valid loss-0.2171, acc-0.9376, test loss-0.2272, acc-0.9352\n",
      "Iter-94560, train loss-0.2231, acc-0.9400, valid loss-0.2171, acc-0.9374, test loss-0.2272, acc-0.9352\n",
      "Iter-94570, train loss-0.2981, acc-0.9400, valid loss-0.2171, acc-0.9376, test loss-0.2272, acc-0.9354\n",
      "Iter-94580, train loss-0.3079, acc-0.9000, valid loss-0.2171, acc-0.9374, test loss-0.2272, acc-0.9356\n",
      "Iter-94590, train loss-0.2275, acc-0.9400, valid loss-0.2171, acc-0.9372, test loss-0.2271, acc-0.9357\n",
      "Iter-94600, train loss-0.2720, acc-0.8600, valid loss-0.2171, acc-0.9380, test loss-0.2271, acc-0.9358\n",
      "Iter-94610, train loss-0.2338, acc-0.9400, valid loss-0.2171, acc-0.9380, test loss-0.2271, acc-0.9358\n",
      "Iter-94620, train loss-0.1519, acc-1.0000, valid loss-0.2171, acc-0.9378, test loss-0.2271, acc-0.9360\n",
      "Iter-94630, train loss-0.2508, acc-0.9200, valid loss-0.2172, acc-0.9378, test loss-0.2271, acc-0.9360\n",
      "Iter-94640, train loss-0.2419, acc-0.9600, valid loss-0.2172, acc-0.9378, test loss-0.2271, acc-0.9358\n",
      "Iter-94650, train loss-0.2318, acc-0.9400, valid loss-0.2171, acc-0.9376, test loss-0.2271, acc-0.9358\n",
      "Iter-94660, train loss-0.0765, acc-1.0000, valid loss-0.2171, acc-0.9378, test loss-0.2271, acc-0.9358\n",
      "Iter-94670, train loss-0.2585, acc-0.9000, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9356\n",
      "Iter-94680, train loss-0.1693, acc-0.9200, valid loss-0.2171, acc-0.9376, test loss-0.2271, acc-0.9356\n",
      "Iter-94690, train loss-0.3161, acc-0.9600, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9357\n",
      "Iter-94700, train loss-0.2668, acc-0.9200, valid loss-0.2172, acc-0.9376, test loss-0.2271, acc-0.9358\n",
      "Iter-94710, train loss-0.1071, acc-0.9800, valid loss-0.2172, acc-0.9374, test loss-0.2271, acc-0.9359\n",
      "Iter-94720, train loss-0.2940, acc-0.8800, valid loss-0.2171, acc-0.9374, test loss-0.2270, acc-0.9359\n",
      "Iter-94730, train loss-0.2075, acc-0.9400, valid loss-0.2171, acc-0.9374, test loss-0.2270, acc-0.9357\n",
      "Iter-94740, train loss-0.4488, acc-0.8400, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9357\n",
      "Iter-94750, train loss-0.1357, acc-0.9800, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9354\n",
      "Iter-94760, train loss-0.2233, acc-0.9200, valid loss-0.2171, acc-0.9378, test loss-0.2270, acc-0.9354\n",
      "Iter-94770, train loss-0.1761, acc-0.9400, valid loss-0.2171, acc-0.9380, test loss-0.2270, acc-0.9355\n",
      "Iter-94780, train loss-0.1430, acc-0.9200, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9355\n",
      "Iter-94790, train loss-0.1158, acc-0.9600, valid loss-0.2171, acc-0.9376, test loss-0.2270, acc-0.9355\n",
      "Iter-94800, train loss-0.0940, acc-0.9800, valid loss-0.2172, acc-0.9374, test loss-0.2270, acc-0.9354\n",
      "Iter-94810, train loss-0.2471, acc-0.9200, valid loss-0.2172, acc-0.9376, test loss-0.2270, acc-0.9354\n",
      "Iter-94820, train loss-0.2308, acc-0.9200, valid loss-0.2172, acc-0.9374, test loss-0.2270, acc-0.9353\n",
      "Iter-94830, train loss-0.1982, acc-0.9600, valid loss-0.2171, acc-0.9374, test loss-0.2269, acc-0.9352\n",
      "Iter-94840, train loss-0.3530, acc-0.9000, valid loss-0.2170, acc-0.9374, test loss-0.2269, acc-0.9351\n",
      "Iter-94850, train loss-0.3842, acc-0.9000, valid loss-0.2169, acc-0.9374, test loss-0.2269, acc-0.9350\n",
      "Iter-94860, train loss-0.0502, acc-1.0000, valid loss-0.2170, acc-0.9376, test loss-0.2269, acc-0.9351\n",
      "Iter-94870, train loss-0.1940, acc-0.9600, valid loss-0.2169, acc-0.9378, test loss-0.2269, acc-0.9352\n",
      "Iter-94880, train loss-0.3027, acc-0.9200, valid loss-0.2169, acc-0.9378, test loss-0.2269, acc-0.9352\n",
      "Iter-94890, train loss-0.1045, acc-0.9800, valid loss-0.2170, acc-0.9378, test loss-0.2269, acc-0.9351\n",
      "Iter-94900, train loss-0.1883, acc-0.9400, valid loss-0.2169, acc-0.9380, test loss-0.2269, acc-0.9350\n",
      "Iter-94910, train loss-0.1850, acc-0.9600, valid loss-0.2169, acc-0.9376, test loss-0.2269, acc-0.9350\n",
      "Iter-94920, train loss-0.3447, acc-0.9000, valid loss-0.2169, acc-0.9378, test loss-0.2269, acc-0.9349\n",
      "Iter-94930, train loss-0.0987, acc-0.9800, valid loss-0.2169, acc-0.9372, test loss-0.2269, acc-0.9351\n",
      "Iter-94940, train loss-0.5585, acc-0.8800, valid loss-0.2169, acc-0.9374, test loss-0.2268, acc-0.9352\n",
      "Iter-94950, train loss-0.2447, acc-0.9200, valid loss-0.2169, acc-0.9374, test loss-0.2268, acc-0.9350\n",
      "Iter-94960, train loss-0.2191, acc-0.9400, valid loss-0.2169, acc-0.9374, test loss-0.2268, acc-0.9352\n",
      "Iter-94970, train loss-0.1991, acc-0.9200, valid loss-0.2168, acc-0.9372, test loss-0.2268, acc-0.9349\n",
      "Iter-94980, train loss-0.1694, acc-0.9600, valid loss-0.2168, acc-0.9378, test loss-0.2268, acc-0.9350\n",
      "Iter-94990, train loss-0.2810, acc-0.9400, valid loss-0.2169, acc-0.9378, test loss-0.2268, acc-0.9350\n",
      "Iter-95000, train loss-0.4701, acc-0.9000, valid loss-0.2169, acc-0.9376, test loss-0.2268, acc-0.9350\n",
      "Iter-95010, train loss-0.1999, acc-0.9400, valid loss-0.2169, acc-0.9374, test loss-0.2268, acc-0.9351\n",
      "Iter-95020, train loss-0.0801, acc-1.0000, valid loss-0.2169, acc-0.9372, test loss-0.2268, acc-0.9352\n",
      "Iter-95030, train loss-0.1310, acc-0.9800, valid loss-0.2170, acc-0.9376, test loss-0.2267, acc-0.9354\n",
      "Iter-95040, train loss-0.2372, acc-0.9400, valid loss-0.2170, acc-0.9380, test loss-0.2267, acc-0.9355\n",
      "Iter-95050, train loss-0.1264, acc-0.9600, valid loss-0.2170, acc-0.9382, test loss-0.2267, acc-0.9353\n",
      "Iter-95060, train loss-0.1669, acc-0.9200, valid loss-0.2170, acc-0.9384, test loss-0.2267, acc-0.9352\n",
      "Iter-95070, train loss-0.1185, acc-0.9600, valid loss-0.2170, acc-0.9382, test loss-0.2266, acc-0.9351\n",
      "Iter-95080, train loss-0.2663, acc-0.9200, valid loss-0.2169, acc-0.9384, test loss-0.2266, acc-0.9351\n",
      "Iter-95090, train loss-0.2700, acc-0.9200, valid loss-0.2169, acc-0.9380, test loss-0.2266, acc-0.9351\n",
      "Iter-95100, train loss-0.1912, acc-0.9600, valid loss-0.2169, acc-0.9384, test loss-0.2266, acc-0.9352\n",
      "Iter-95110, train loss-0.0495, acc-1.0000, valid loss-0.2168, acc-0.9384, test loss-0.2266, acc-0.9352\n",
      "Iter-95120, train loss-0.1637, acc-0.9000, valid loss-0.2168, acc-0.9382, test loss-0.2266, acc-0.9351\n",
      "Iter-95130, train loss-0.1288, acc-0.9800, valid loss-0.2167, acc-0.9382, test loss-0.2265, acc-0.9351\n",
      "Iter-95140, train loss-0.0748, acc-1.0000, valid loss-0.2168, acc-0.9382, test loss-0.2265, acc-0.9354\n",
      "Iter-95150, train loss-0.2970, acc-0.9200, valid loss-0.2167, acc-0.9380, test loss-0.2265, acc-0.9352\n",
      "Iter-95160, train loss-0.3233, acc-0.9400, valid loss-0.2168, acc-0.9384, test loss-0.2265, acc-0.9352\n",
      "Iter-95170, train loss-0.1012, acc-0.9800, valid loss-0.2167, acc-0.9382, test loss-0.2264, acc-0.9351\n",
      "Iter-95180, train loss-0.1426, acc-0.9600, valid loss-0.2167, acc-0.9384, test loss-0.2264, acc-0.9351\n",
      "Iter-95190, train loss-0.1642, acc-0.9600, valid loss-0.2167, acc-0.9382, test loss-0.2264, acc-0.9353\n",
      "Iter-95200, train loss-0.0833, acc-1.0000, valid loss-0.2167, acc-0.9384, test loss-0.2264, acc-0.9353\n",
      "Iter-95210, train loss-0.2940, acc-0.9200, valid loss-0.2166, acc-0.9384, test loss-0.2263, acc-0.9353\n",
      "Iter-95220, train loss-0.3058, acc-0.9200, valid loss-0.2166, acc-0.9384, test loss-0.2263, acc-0.9351\n",
      "Iter-95230, train loss-0.2078, acc-0.9400, valid loss-0.2166, acc-0.9382, test loss-0.2263, acc-0.9352\n",
      "Iter-95240, train loss-0.3267, acc-0.8800, valid loss-0.2166, acc-0.9384, test loss-0.2263, acc-0.9351\n",
      "Iter-95250, train loss-0.1310, acc-0.9600, valid loss-0.2166, acc-0.9386, test loss-0.2263, acc-0.9352\n",
      "Iter-95260, train loss-0.1028, acc-0.9800, valid loss-0.2166, acc-0.9384, test loss-0.2263, acc-0.9356\n",
      "Iter-95270, train loss-0.1211, acc-0.9600, valid loss-0.2166, acc-0.9384, test loss-0.2263, acc-0.9358\n",
      "Iter-95280, train loss-0.4379, acc-0.9000, valid loss-0.2166, acc-0.9386, test loss-0.2263, acc-0.9358\n",
      "Iter-95290, train loss-0.5930, acc-0.9000, valid loss-0.2165, acc-0.9382, test loss-0.2263, acc-0.9356\n",
      "Iter-95300, train loss-0.1263, acc-0.9800, valid loss-0.2165, acc-0.9380, test loss-0.2262, acc-0.9356\n",
      "Iter-95310, train loss-0.1788, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2262, acc-0.9356\n",
      "Iter-95320, train loss-0.3492, acc-0.9400, valid loss-0.2165, acc-0.9382, test loss-0.2262, acc-0.9357\n",
      "Iter-95330, train loss-0.2060, acc-0.9200, valid loss-0.2165, acc-0.9384, test loss-0.2262, acc-0.9359\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-95340, train loss-0.2377, acc-0.9000, valid loss-0.2165, acc-0.9382, test loss-0.2262, acc-0.9358\n",
      "Iter-95350, train loss-0.1774, acc-0.9800, valid loss-0.2165, acc-0.9384, test loss-0.2262, acc-0.9354\n",
      "Iter-95360, train loss-0.1373, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2262, acc-0.9356\n",
      "Iter-95370, train loss-0.2554, acc-0.9400, valid loss-0.2165, acc-0.9382, test loss-0.2261, acc-0.9357\n",
      "Iter-95380, train loss-0.2102, acc-0.9400, valid loss-0.2166, acc-0.9382, test loss-0.2261, acc-0.9356\n",
      "Iter-95390, train loss-0.1172, acc-0.9800, valid loss-0.2166, acc-0.9380, test loss-0.2261, acc-0.9356\n",
      "Iter-95400, train loss-0.3243, acc-0.9000, valid loss-0.2165, acc-0.9380, test loss-0.2261, acc-0.9353\n",
      "Iter-95410, train loss-0.2086, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2261, acc-0.9354\n",
      "Iter-95420, train loss-0.3339, acc-0.9000, valid loss-0.2165, acc-0.9388, test loss-0.2261, acc-0.9357\n",
      "Iter-95430, train loss-0.1377, acc-1.0000, valid loss-0.2165, acc-0.9384, test loss-0.2261, acc-0.9357\n",
      "Iter-95440, train loss-0.3037, acc-0.8800, valid loss-0.2165, acc-0.9386, test loss-0.2261, acc-0.9357\n",
      "Iter-95450, train loss-0.3075, acc-0.9400, valid loss-0.2164, acc-0.9386, test loss-0.2261, acc-0.9356\n",
      "Iter-95460, train loss-0.1413, acc-0.9600, valid loss-0.2165, acc-0.9382, test loss-0.2260, acc-0.9356\n",
      "Iter-95470, train loss-0.1524, acc-0.9600, valid loss-0.2166, acc-0.9384, test loss-0.2260, acc-0.9358\n",
      "Iter-95480, train loss-0.1139, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2260, acc-0.9358\n",
      "Iter-95490, train loss-0.2095, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2259, acc-0.9357\n",
      "Iter-95500, train loss-0.1311, acc-0.9600, valid loss-0.2165, acc-0.9384, test loss-0.2259, acc-0.9356\n",
      "Iter-95510, train loss-0.1857, acc-0.9400, valid loss-0.2165, acc-0.9384, test loss-0.2259, acc-0.9356\n",
      "Iter-95520, train loss-0.2624, acc-0.9400, valid loss-0.2165, acc-0.9384, test loss-0.2259, acc-0.9356\n",
      "Iter-95530, train loss-0.2706, acc-0.9000, valid loss-0.2165, acc-0.9384, test loss-0.2259, acc-0.9355\n",
      "Iter-95540, train loss-0.3354, acc-0.9200, valid loss-0.2165, acc-0.9386, test loss-0.2259, acc-0.9353\n",
      "Iter-95550, train loss-0.0969, acc-0.9800, valid loss-0.2164, acc-0.9384, test loss-0.2259, acc-0.9355\n",
      "Iter-95560, train loss-0.1580, acc-0.9800, valid loss-0.2164, acc-0.9384, test loss-0.2260, acc-0.9355\n",
      "Iter-95570, train loss-0.1979, acc-0.9400, valid loss-0.2165, acc-0.9386, test loss-0.2260, acc-0.9353\n",
      "Iter-95580, train loss-0.1086, acc-0.9800, valid loss-0.2165, acc-0.9386, test loss-0.2260, acc-0.9353\n",
      "Iter-95590, train loss-0.0713, acc-0.9800, valid loss-0.2164, acc-0.9386, test loss-0.2260, acc-0.9355\n",
      "Iter-95600, train loss-0.2001, acc-0.9600, valid loss-0.2165, acc-0.9386, test loss-0.2260, acc-0.9355\n",
      "Iter-95610, train loss-0.2612, acc-0.9200, valid loss-0.2165, acc-0.9386, test loss-0.2260, acc-0.9356\n",
      "Iter-95620, train loss-0.2698, acc-0.9400, valid loss-0.2164, acc-0.9386, test loss-0.2260, acc-0.9353\n",
      "Iter-95630, train loss-0.3238, acc-0.9000, valid loss-0.2164, acc-0.9384, test loss-0.2260, acc-0.9352\n",
      "Iter-95640, train loss-0.2280, acc-0.9400, valid loss-0.2163, acc-0.9386, test loss-0.2260, acc-0.9352\n",
      "Iter-95650, train loss-0.1452, acc-0.9600, valid loss-0.2163, acc-0.9386, test loss-0.2260, acc-0.9353\n",
      "Iter-95660, train loss-0.0799, acc-1.0000, valid loss-0.2162, acc-0.9386, test loss-0.2259, acc-0.9358\n",
      "Iter-95670, train loss-0.1795, acc-0.9200, valid loss-0.2162, acc-0.9388, test loss-0.2259, acc-0.9357\n",
      "Iter-95680, train loss-0.1817, acc-0.9000, valid loss-0.2161, acc-0.9388, test loss-0.2259, acc-0.9356\n",
      "Iter-95690, train loss-0.1296, acc-0.9800, valid loss-0.2162, acc-0.9386, test loss-0.2259, acc-0.9355\n",
      "Iter-95700, train loss-0.1814, acc-0.9600, valid loss-0.2161, acc-0.9388, test loss-0.2259, acc-0.9356\n",
      "Iter-95710, train loss-0.1222, acc-0.9800, valid loss-0.2161, acc-0.9388, test loss-0.2259, acc-0.9358\n",
      "Iter-95720, train loss-0.2127, acc-0.9400, valid loss-0.2161, acc-0.9390, test loss-0.2259, acc-0.9359\n",
      "Iter-95730, train loss-0.4035, acc-0.8800, valid loss-0.2161, acc-0.9390, test loss-0.2259, acc-0.9357\n",
      "Iter-95740, train loss-0.3217, acc-0.9600, valid loss-0.2161, acc-0.9388, test loss-0.2259, acc-0.9356\n",
      "Iter-95750, train loss-0.2011, acc-0.9400, valid loss-0.2161, acc-0.9390, test loss-0.2259, acc-0.9356\n",
      "Iter-95760, train loss-0.1187, acc-0.9800, valid loss-0.2162, acc-0.9390, test loss-0.2258, acc-0.9361\n",
      "Iter-95770, train loss-0.2784, acc-0.9200, valid loss-0.2162, acc-0.9390, test loss-0.2258, acc-0.9361\n",
      "Iter-95780, train loss-0.3116, acc-0.9400, valid loss-0.2162, acc-0.9390, test loss-0.2258, acc-0.9363\n",
      "Iter-95790, train loss-0.0975, acc-0.9800, valid loss-0.2162, acc-0.9390, test loss-0.2258, acc-0.9361\n",
      "Iter-95800, train loss-0.1351, acc-0.9400, valid loss-0.2162, acc-0.9384, test loss-0.2258, acc-0.9362\n",
      "Iter-95810, train loss-0.4393, acc-0.9400, valid loss-0.2162, acc-0.9386, test loss-0.2258, acc-0.9361\n",
      "Iter-95820, train loss-0.3502, acc-0.8800, valid loss-0.2162, acc-0.9384, test loss-0.2258, acc-0.9362\n",
      "Iter-95830, train loss-0.2514, acc-0.9400, valid loss-0.2162, acc-0.9384, test loss-0.2258, acc-0.9362\n",
      "Iter-95840, train loss-0.1509, acc-0.9600, valid loss-0.2161, acc-0.9384, test loss-0.2258, acc-0.9361\n",
      "Iter-95850, train loss-0.3391, acc-0.8400, valid loss-0.2162, acc-0.9386, test loss-0.2258, acc-0.9360\n",
      "Iter-95860, train loss-0.0598, acc-1.0000, valid loss-0.2162, acc-0.9392, test loss-0.2258, acc-0.9359\n",
      "Iter-95870, train loss-0.1814, acc-0.9400, valid loss-0.2161, acc-0.9392, test loss-0.2258, acc-0.9359\n",
      "Iter-95880, train loss-0.1046, acc-0.9800, valid loss-0.2161, acc-0.9392, test loss-0.2258, acc-0.9361\n",
      "Iter-95890, train loss-0.3566, acc-0.8600, valid loss-0.2162, acc-0.9390, test loss-0.2258, acc-0.9362\n",
      "Iter-95900, train loss-0.2280, acc-0.9600, valid loss-0.2162, acc-0.9392, test loss-0.2258, acc-0.9361\n",
      "Iter-95910, train loss-0.2863, acc-0.9200, valid loss-0.2162, acc-0.9394, test loss-0.2257, acc-0.9356\n",
      "Iter-95920, train loss-0.1441, acc-0.9800, valid loss-0.2161, acc-0.9394, test loss-0.2257, acc-0.9361\n",
      "Iter-95930, train loss-0.2157, acc-0.9200, valid loss-0.2161, acc-0.9392, test loss-0.2257, acc-0.9363\n",
      "Iter-95940, train loss-0.1093, acc-0.9600, valid loss-0.2161, acc-0.9396, test loss-0.2257, acc-0.9364\n",
      "Iter-95950, train loss-0.3443, acc-0.8400, valid loss-0.2162, acc-0.9394, test loss-0.2257, acc-0.9361\n",
      "Iter-95960, train loss-0.5617, acc-0.8600, valid loss-0.2162, acc-0.9396, test loss-0.2256, acc-0.9360\n",
      "Iter-95970, train loss-0.2567, acc-0.9000, valid loss-0.2162, acc-0.9394, test loss-0.2256, acc-0.9362\n",
      "Iter-95980, train loss-0.3678, acc-0.9200, valid loss-0.2161, acc-0.9394, test loss-0.2256, acc-0.9360\n",
      "Iter-95990, train loss-0.0825, acc-0.9800, valid loss-0.2161, acc-0.9394, test loss-0.2255, acc-0.9362\n",
      "Iter-96000, train loss-0.3232, acc-0.9200, valid loss-0.2161, acc-0.9392, test loss-0.2255, acc-0.9363\n",
      "Iter-96010, train loss-0.3643, acc-0.9200, valid loss-0.2160, acc-0.9392, test loss-0.2255, acc-0.9362\n",
      "Iter-96020, train loss-0.2160, acc-0.9400, valid loss-0.2160, acc-0.9392, test loss-0.2255, acc-0.9362\n",
      "Iter-96030, train loss-0.6235, acc-0.8000, valid loss-0.2161, acc-0.9392, test loss-0.2254, acc-0.9360\n",
      "Iter-96040, train loss-0.1908, acc-0.9400, valid loss-0.2161, acc-0.9392, test loss-0.2255, acc-0.9360\n",
      "Iter-96050, train loss-0.2455, acc-0.9600, valid loss-0.2161, acc-0.9390, test loss-0.2255, acc-0.9362\n",
      "Iter-96060, train loss-0.2818, acc-0.9000, valid loss-0.2161, acc-0.9390, test loss-0.2255, acc-0.9363\n",
      "Iter-96070, train loss-0.1933, acc-0.9200, valid loss-0.2161, acc-0.9394, test loss-0.2255, acc-0.9360\n",
      "Iter-96080, train loss-0.2569, acc-0.9400, valid loss-0.2162, acc-0.9394, test loss-0.2255, acc-0.9361\n",
      "Iter-96090, train loss-0.2236, acc-0.9400, valid loss-0.2161, acc-0.9392, test loss-0.2255, acc-0.9363\n",
      "Iter-96100, train loss-0.1137, acc-0.9800, valid loss-0.2161, acc-0.9388, test loss-0.2254, acc-0.9364\n",
      "Iter-96110, train loss-0.4694, acc-0.8400, valid loss-0.2161, acc-0.9386, test loss-0.2254, acc-0.9363\n",
      "Iter-96120, train loss-0.2891, acc-0.9600, valid loss-0.2160, acc-0.9390, test loss-0.2254, acc-0.9362\n",
      "Iter-96130, train loss-0.1998, acc-0.9400, valid loss-0.2161, acc-0.9388, test loss-0.2254, acc-0.9363\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-96140, train loss-0.2862, acc-0.9200, valid loss-0.2161, acc-0.9392, test loss-0.2254, acc-0.9362\n",
      "Iter-96150, train loss-0.2378, acc-0.9400, valid loss-0.2161, acc-0.9392, test loss-0.2254, acc-0.9364\n",
      "Iter-96160, train loss-0.3581, acc-0.9200, valid loss-0.2161, acc-0.9388, test loss-0.2253, acc-0.9363\n",
      "Iter-96170, train loss-0.2283, acc-0.9400, valid loss-0.2161, acc-0.9396, test loss-0.2253, acc-0.9365\n",
      "Iter-96180, train loss-0.1556, acc-0.9600, valid loss-0.2160, acc-0.9392, test loss-0.2253, acc-0.9364\n",
      "Iter-96190, train loss-0.2856, acc-0.9000, valid loss-0.2161, acc-0.9392, test loss-0.2253, acc-0.9363\n",
      "Iter-96200, train loss-0.3842, acc-0.9000, valid loss-0.2161, acc-0.9390, test loss-0.2253, acc-0.9364\n",
      "Iter-96210, train loss-0.3166, acc-0.8800, valid loss-0.2160, acc-0.9388, test loss-0.2253, acc-0.9363\n",
      "Iter-96220, train loss-0.1752, acc-0.9600, valid loss-0.2160, acc-0.9394, test loss-0.2253, acc-0.9361\n",
      "Iter-96230, train loss-0.3373, acc-0.9400, valid loss-0.2160, acc-0.9390, test loss-0.2253, acc-0.9359\n",
      "Iter-96240, train loss-0.3364, acc-0.9200, valid loss-0.2159, acc-0.9392, test loss-0.2253, acc-0.9360\n",
      "Iter-96250, train loss-0.1719, acc-0.9200, valid loss-0.2160, acc-0.9392, test loss-0.2253, acc-0.9358\n",
      "Iter-96260, train loss-0.1324, acc-1.0000, valid loss-0.2160, acc-0.9392, test loss-0.2252, acc-0.9360\n",
      "Iter-96270, train loss-0.1648, acc-0.9800, valid loss-0.2160, acc-0.9392, test loss-0.2252, acc-0.9361\n",
      "Iter-96280, train loss-0.2108, acc-0.9200, valid loss-0.2160, acc-0.9396, test loss-0.2252, acc-0.9361\n",
      "Iter-96290, train loss-0.1620, acc-0.9600, valid loss-0.2160, acc-0.9394, test loss-0.2253, acc-0.9363\n",
      "Iter-96300, train loss-0.1755, acc-0.9600, valid loss-0.2159, acc-0.9396, test loss-0.2253, acc-0.9363\n",
      "Iter-96310, train loss-0.3002, acc-0.9600, valid loss-0.2159, acc-0.9396, test loss-0.2252, acc-0.9362\n",
      "Iter-96320, train loss-0.2061, acc-0.9400, valid loss-0.2158, acc-0.9394, test loss-0.2252, acc-0.9359\n",
      "Iter-96330, train loss-0.3307, acc-0.8600, valid loss-0.2158, acc-0.9396, test loss-0.2252, acc-0.9361\n",
      "Iter-96340, train loss-0.2750, acc-0.8800, valid loss-0.2158, acc-0.9398, test loss-0.2252, acc-0.9362\n",
      "Iter-96350, train loss-0.1153, acc-0.9800, valid loss-0.2158, acc-0.9394, test loss-0.2251, acc-0.9362\n",
      "Iter-96360, train loss-0.4893, acc-0.8600, valid loss-0.2158, acc-0.9396, test loss-0.2251, acc-0.9361\n",
      "Iter-96370, train loss-0.0950, acc-0.9800, valid loss-0.2158, acc-0.9396, test loss-0.2250, acc-0.9359\n",
      "Iter-96380, train loss-0.3036, acc-0.9400, valid loss-0.2157, acc-0.9398, test loss-0.2251, acc-0.9358\n",
      "Iter-96390, train loss-0.1143, acc-0.9800, valid loss-0.2156, acc-0.9398, test loss-0.2251, acc-0.9353\n",
      "Iter-96400, train loss-0.1682, acc-0.9400, valid loss-0.2156, acc-0.9400, test loss-0.2251, acc-0.9355\n",
      "Iter-96410, train loss-0.3048, acc-0.8800, valid loss-0.2156, acc-0.9400, test loss-0.2252, acc-0.9356\n",
      "Iter-96420, train loss-0.2263, acc-0.9200, valid loss-0.2156, acc-0.9400, test loss-0.2252, acc-0.9356\n",
      "Iter-96430, train loss-0.1520, acc-0.9600, valid loss-0.2156, acc-0.9402, test loss-0.2252, acc-0.9356\n",
      "Iter-96440, train loss-0.1906, acc-0.9400, valid loss-0.2157, acc-0.9400, test loss-0.2251, acc-0.9355\n",
      "Iter-96450, train loss-0.0966, acc-0.9800, valid loss-0.2156, acc-0.9398, test loss-0.2252, acc-0.9355\n",
      "Iter-96460, train loss-0.1958, acc-0.9800, valid loss-0.2156, acc-0.9398, test loss-0.2252, acc-0.9356\n",
      "Iter-96470, train loss-0.3537, acc-0.9000, valid loss-0.2155, acc-0.9400, test loss-0.2251, acc-0.9356\n",
      "Iter-96480, train loss-0.1802, acc-0.9200, valid loss-0.2156, acc-0.9400, test loss-0.2251, acc-0.9356\n",
      "Iter-96490, train loss-0.1603, acc-0.9800, valid loss-0.2156, acc-0.9398, test loss-0.2252, acc-0.9354\n",
      "Iter-96500, train loss-0.2676, acc-0.9200, valid loss-0.2156, acc-0.9400, test loss-0.2252, acc-0.9353\n",
      "Iter-96510, train loss-0.4464, acc-0.9200, valid loss-0.2156, acc-0.9398, test loss-0.2252, acc-0.9355\n",
      "Iter-96520, train loss-0.1736, acc-0.9200, valid loss-0.2156, acc-0.9398, test loss-0.2252, acc-0.9355\n",
      "Iter-96530, train loss-0.3868, acc-0.9000, valid loss-0.2156, acc-0.9396, test loss-0.2251, acc-0.9357\n",
      "Iter-96540, train loss-0.2628, acc-0.9400, valid loss-0.2156, acc-0.9396, test loss-0.2251, acc-0.9357\n",
      "Iter-96550, train loss-0.2178, acc-0.9600, valid loss-0.2156, acc-0.9396, test loss-0.2251, acc-0.9354\n",
      "Iter-96560, train loss-0.2170, acc-0.9400, valid loss-0.2156, acc-0.9398, test loss-0.2251, acc-0.9355\n",
      "Iter-96570, train loss-0.1692, acc-0.9400, valid loss-0.2156, acc-0.9398, test loss-0.2251, acc-0.9358\n",
      "Iter-96580, train loss-0.3592, acc-0.8800, valid loss-0.2156, acc-0.9400, test loss-0.2251, acc-0.9356\n",
      "Iter-96590, train loss-0.1408, acc-0.9800, valid loss-0.2156, acc-0.9398, test loss-0.2250, acc-0.9355\n",
      "Iter-96600, train loss-0.1901, acc-0.9600, valid loss-0.2155, acc-0.9402, test loss-0.2250, acc-0.9356\n",
      "Iter-96610, train loss-0.2535, acc-0.9200, valid loss-0.2155, acc-0.9400, test loss-0.2250, acc-0.9359\n",
      "Iter-96620, train loss-0.0837, acc-1.0000, valid loss-0.2155, acc-0.9396, test loss-0.2250, acc-0.9357\n",
      "Iter-96630, train loss-0.3578, acc-0.9000, valid loss-0.2154, acc-0.9396, test loss-0.2250, acc-0.9357\n",
      "Iter-96640, train loss-0.1999, acc-0.9400, valid loss-0.2154, acc-0.9396, test loss-0.2249, acc-0.9356\n",
      "Iter-96650, train loss-0.1501, acc-0.9400, valid loss-0.2154, acc-0.9396, test loss-0.2249, acc-0.9356\n",
      "Iter-96660, train loss-0.1087, acc-1.0000, valid loss-0.2154, acc-0.9396, test loss-0.2249, acc-0.9358\n",
      "Iter-96670, train loss-0.1704, acc-0.9600, valid loss-0.2154, acc-0.9400, test loss-0.2249, acc-0.9358\n",
      "Iter-96680, train loss-0.5780, acc-0.8600, valid loss-0.2154, acc-0.9396, test loss-0.2249, acc-0.9358\n",
      "Iter-96690, train loss-0.1425, acc-0.9600, valid loss-0.2153, acc-0.9398, test loss-0.2249, acc-0.9361\n",
      "Iter-96700, train loss-0.2521, acc-0.9200, valid loss-0.2153, acc-0.9398, test loss-0.2248, acc-0.9360\n",
      "Iter-96710, train loss-0.1099, acc-0.9600, valid loss-0.2153, acc-0.9396, test loss-0.2249, acc-0.9361\n",
      "Iter-96720, train loss-0.2963, acc-0.9200, valid loss-0.2153, acc-0.9398, test loss-0.2248, acc-0.9359\n",
      "Iter-96730, train loss-0.0952, acc-1.0000, valid loss-0.2152, acc-0.9394, test loss-0.2249, acc-0.9360\n",
      "Iter-96740, train loss-0.1569, acc-0.9600, valid loss-0.2152, acc-0.9394, test loss-0.2249, acc-0.9359\n",
      "Iter-96750, train loss-0.3405, acc-0.8800, valid loss-0.2152, acc-0.9394, test loss-0.2249, acc-0.9361\n",
      "Iter-96760, train loss-0.4559, acc-0.9000, valid loss-0.2153, acc-0.9396, test loss-0.2249, acc-0.9360\n",
      "Iter-96770, train loss-0.1524, acc-0.9600, valid loss-0.2152, acc-0.9396, test loss-0.2248, acc-0.9359\n",
      "Iter-96780, train loss-0.4806, acc-0.8600, valid loss-0.2153, acc-0.9394, test loss-0.2249, acc-0.9359\n",
      "Iter-96790, train loss-0.3052, acc-0.9400, valid loss-0.2153, acc-0.9394, test loss-0.2248, acc-0.9363\n",
      "Iter-96800, train loss-0.2154, acc-0.9200, valid loss-0.2153, acc-0.9392, test loss-0.2248, acc-0.9363\n",
      "Iter-96810, train loss-0.1396, acc-0.9800, valid loss-0.2153, acc-0.9392, test loss-0.2248, acc-0.9364\n",
      "Iter-96820, train loss-0.2525, acc-0.9600, valid loss-0.2153, acc-0.9398, test loss-0.2248, acc-0.9363\n",
      "Iter-96830, train loss-0.3407, acc-0.9000, valid loss-0.2153, acc-0.9398, test loss-0.2248, acc-0.9364\n",
      "Iter-96840, train loss-0.1593, acc-0.9600, valid loss-0.2153, acc-0.9398, test loss-0.2248, acc-0.9362\n",
      "Iter-96850, train loss-0.3526, acc-0.8600, valid loss-0.2153, acc-0.9398, test loss-0.2247, acc-0.9360\n",
      "Iter-96860, train loss-0.3101, acc-0.8400, valid loss-0.2154, acc-0.9398, test loss-0.2247, acc-0.9360\n",
      "Iter-96870, train loss-0.3386, acc-0.8800, valid loss-0.2154, acc-0.9398, test loss-0.2247, acc-0.9360\n",
      "Iter-96880, train loss-0.2959, acc-0.9000, valid loss-0.2154, acc-0.9396, test loss-0.2247, acc-0.9362\n",
      "Iter-96890, train loss-0.2124, acc-0.9600, valid loss-0.2153, acc-0.9396, test loss-0.2246, acc-0.9358\n",
      "Iter-96900, train loss-0.0872, acc-1.0000, valid loss-0.2154, acc-0.9396, test loss-0.2246, acc-0.9359\n",
      "Iter-96910, train loss-0.1948, acc-0.9400, valid loss-0.2153, acc-0.9394, test loss-0.2246, acc-0.9357\n",
      "Iter-96920, train loss-0.3851, acc-0.8800, valid loss-0.2153, acc-0.9398, test loss-0.2247, acc-0.9360\n",
      "Iter-96930, train loss-0.1382, acc-0.9600, valid loss-0.2153, acc-0.9396, test loss-0.2246, acc-0.9361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-96940, train loss-0.1047, acc-0.9600, valid loss-0.2153, acc-0.9392, test loss-0.2246, acc-0.9359\n",
      "Iter-96950, train loss-0.1148, acc-0.9800, valid loss-0.2153, acc-0.9394, test loss-0.2246, acc-0.9360\n",
      "Iter-96960, train loss-0.1842, acc-0.9400, valid loss-0.2153, acc-0.9392, test loss-0.2246, acc-0.9359\n",
      "Iter-96970, train loss-0.4006, acc-0.8800, valid loss-0.2152, acc-0.9390, test loss-0.2246, acc-0.9361\n",
      "Iter-96980, train loss-0.1934, acc-0.9400, valid loss-0.2151, acc-0.9392, test loss-0.2245, acc-0.9361\n",
      "Iter-96990, train loss-0.1382, acc-0.9400, valid loss-0.2151, acc-0.9396, test loss-0.2245, acc-0.9362\n",
      "Iter-97000, train loss-0.2942, acc-0.9000, valid loss-0.2151, acc-0.9396, test loss-0.2245, acc-0.9364\n",
      "Iter-97010, train loss-0.1006, acc-1.0000, valid loss-0.2150, acc-0.9392, test loss-0.2245, acc-0.9363\n",
      "Iter-97020, train loss-0.2895, acc-0.8800, valid loss-0.2150, acc-0.9392, test loss-0.2245, acc-0.9363\n",
      "Iter-97030, train loss-0.2585, acc-0.9400, valid loss-0.2150, acc-0.9392, test loss-0.2245, acc-0.9360\n",
      "Iter-97040, train loss-0.2155, acc-0.9600, valid loss-0.2150, acc-0.9390, test loss-0.2245, acc-0.9361\n",
      "Iter-97050, train loss-0.2071, acc-0.9800, valid loss-0.2149, acc-0.9390, test loss-0.2245, acc-0.9361\n",
      "Iter-97060, train loss-0.1307, acc-0.9400, valid loss-0.2148, acc-0.9396, test loss-0.2245, acc-0.9359\n",
      "Iter-97070, train loss-0.1785, acc-0.9400, valid loss-0.2148, acc-0.9394, test loss-0.2244, acc-0.9359\n",
      "Iter-97080, train loss-0.1336, acc-0.9800, valid loss-0.2148, acc-0.9394, test loss-0.2244, acc-0.9358\n",
      "Iter-97090, train loss-0.1816, acc-0.9600, valid loss-0.2147, acc-0.9394, test loss-0.2244, acc-0.9359\n",
      "Iter-97100, train loss-0.1644, acc-0.9400, valid loss-0.2147, acc-0.9392, test loss-0.2244, acc-0.9356\n",
      "Iter-97110, train loss-0.2039, acc-0.9000, valid loss-0.2146, acc-0.9394, test loss-0.2244, acc-0.9354\n",
      "Iter-97120, train loss-0.2108, acc-0.9400, valid loss-0.2146, acc-0.9394, test loss-0.2243, acc-0.9354\n",
      "Iter-97130, train loss-0.0853, acc-1.0000, valid loss-0.2146, acc-0.9392, test loss-0.2243, acc-0.9356\n",
      "Iter-97140, train loss-0.1579, acc-0.9800, valid loss-0.2145, acc-0.9392, test loss-0.2243, acc-0.9358\n",
      "Iter-97150, train loss-0.2345, acc-0.9200, valid loss-0.2145, acc-0.9390, test loss-0.2243, acc-0.9355\n",
      "Iter-97160, train loss-0.1191, acc-0.9800, valid loss-0.2145, acc-0.9390, test loss-0.2243, acc-0.9356\n",
      "Iter-97170, train loss-0.1904, acc-0.9600, valid loss-0.2145, acc-0.9392, test loss-0.2243, acc-0.9353\n",
      "Iter-97180, train loss-0.1267, acc-0.9800, valid loss-0.2145, acc-0.9392, test loss-0.2243, acc-0.9353\n",
      "Iter-97190, train loss-0.1995, acc-0.9200, valid loss-0.2146, acc-0.9394, test loss-0.2243, acc-0.9354\n",
      "Iter-97200, train loss-0.2100, acc-0.9400, valid loss-0.2146, acc-0.9394, test loss-0.2243, acc-0.9355\n",
      "Iter-97210, train loss-0.2356, acc-0.9200, valid loss-0.2146, acc-0.9394, test loss-0.2243, acc-0.9354\n",
      "Iter-97220, train loss-0.0935, acc-0.9600, valid loss-0.2146, acc-0.9392, test loss-0.2242, acc-0.9353\n",
      "Iter-97230, train loss-0.2446, acc-0.9200, valid loss-0.2145, acc-0.9392, test loss-0.2242, acc-0.9354\n",
      "Iter-97240, train loss-0.3522, acc-0.8600, valid loss-0.2145, acc-0.9396, test loss-0.2241, acc-0.9356\n",
      "Iter-97250, train loss-0.1917, acc-0.9200, valid loss-0.2145, acc-0.9396, test loss-0.2241, acc-0.9358\n",
      "Iter-97260, train loss-0.2584, acc-0.9200, valid loss-0.2146, acc-0.9390, test loss-0.2241, acc-0.9357\n",
      "Iter-97270, train loss-0.1030, acc-0.9800, valid loss-0.2145, acc-0.9390, test loss-0.2241, acc-0.9360\n",
      "Iter-97280, train loss-0.2364, acc-0.9600, valid loss-0.2145, acc-0.9390, test loss-0.2241, acc-0.9359\n",
      "Iter-97290, train loss-0.2130, acc-0.9400, valid loss-0.2144, acc-0.9394, test loss-0.2240, acc-0.9359\n",
      "Iter-97300, train loss-0.1433, acc-0.9600, valid loss-0.2145, acc-0.9390, test loss-0.2240, acc-0.9360\n",
      "Iter-97310, train loss-0.1653, acc-0.9400, valid loss-0.2145, acc-0.9392, test loss-0.2240, acc-0.9360\n",
      "Iter-97320, train loss-0.2476, acc-0.9000, valid loss-0.2145, acc-0.9390, test loss-0.2239, acc-0.9359\n",
      "Iter-97330, train loss-0.1956, acc-0.9400, valid loss-0.2145, acc-0.9392, test loss-0.2239, acc-0.9359\n",
      "Iter-97340, train loss-0.1814, acc-0.9400, valid loss-0.2145, acc-0.9392, test loss-0.2239, acc-0.9359\n",
      "Iter-97350, train loss-0.1612, acc-0.9600, valid loss-0.2145, acc-0.9394, test loss-0.2239, acc-0.9358\n",
      "Iter-97360, train loss-0.1312, acc-0.9600, valid loss-0.2145, acc-0.9392, test loss-0.2239, acc-0.9361\n",
      "Iter-97370, train loss-0.1434, acc-0.9800, valid loss-0.2145, acc-0.9392, test loss-0.2239, acc-0.9359\n",
      "Iter-97380, train loss-0.2653, acc-0.9400, valid loss-0.2145, acc-0.9392, test loss-0.2238, acc-0.9358\n",
      "Iter-97390, train loss-0.3127, acc-0.9400, valid loss-0.2145, acc-0.9394, test loss-0.2238, acc-0.9359\n",
      "Iter-97400, train loss-0.2531, acc-0.9000, valid loss-0.2145, acc-0.9392, test loss-0.2238, acc-0.9362\n",
      "Iter-97410, train loss-0.4493, acc-0.8800, valid loss-0.2145, acc-0.9398, test loss-0.2238, acc-0.9362\n",
      "Iter-97420, train loss-0.3590, acc-0.8600, valid loss-0.2146, acc-0.9398, test loss-0.2238, acc-0.9364\n",
      "Iter-97430, train loss-0.1454, acc-0.9800, valid loss-0.2146, acc-0.9398, test loss-0.2238, acc-0.9365\n",
      "Iter-97440, train loss-0.2613, acc-0.9000, valid loss-0.2146, acc-0.9396, test loss-0.2238, acc-0.9364\n",
      "Iter-97450, train loss-0.2805, acc-0.9200, valid loss-0.2145, acc-0.9398, test loss-0.2238, acc-0.9364\n",
      "Iter-97460, train loss-0.2287, acc-0.9200, valid loss-0.2146, acc-0.9396, test loss-0.2238, acc-0.9363\n",
      "Iter-97470, train loss-0.3094, acc-0.8800, valid loss-0.2145, acc-0.9396, test loss-0.2238, acc-0.9363\n",
      "Iter-97480, train loss-0.2575, acc-0.9400, valid loss-0.2146, acc-0.9398, test loss-0.2237, acc-0.9363\n",
      "Iter-97490, train loss-0.2418, acc-0.8800, valid loss-0.2146, acc-0.9398, test loss-0.2237, acc-0.9365\n",
      "Iter-97500, train loss-0.2254, acc-0.9000, valid loss-0.2146, acc-0.9396, test loss-0.2237, acc-0.9365\n",
      "Iter-97510, train loss-0.1081, acc-0.9800, valid loss-0.2146, acc-0.9400, test loss-0.2237, acc-0.9366\n",
      "Iter-97520, train loss-0.0682, acc-0.9800, valid loss-0.2146, acc-0.9398, test loss-0.2237, acc-0.9365\n",
      "Iter-97530, train loss-0.1326, acc-0.9600, valid loss-0.2147, acc-0.9398, test loss-0.2236, acc-0.9363\n",
      "Iter-97540, train loss-0.3251, acc-0.9000, valid loss-0.2146, acc-0.9398, test loss-0.2237, acc-0.9364\n",
      "Iter-97550, train loss-0.2909, acc-0.8800, valid loss-0.2145, acc-0.9398, test loss-0.2236, acc-0.9363\n",
      "Iter-97560, train loss-0.2210, acc-0.9200, valid loss-0.2144, acc-0.9400, test loss-0.2236, acc-0.9364\n",
      "Iter-97570, train loss-0.1869, acc-0.9800, valid loss-0.2144, acc-0.9398, test loss-0.2236, acc-0.9362\n",
      "Iter-97580, train loss-0.3267, acc-0.9000, valid loss-0.2144, acc-0.9396, test loss-0.2237, acc-0.9364\n",
      "Iter-97590, train loss-0.2796, acc-0.9200, valid loss-0.2143, acc-0.9398, test loss-0.2237, acc-0.9362\n",
      "Iter-97600, train loss-0.2804, acc-0.9200, valid loss-0.2143, acc-0.9396, test loss-0.2237, acc-0.9364\n",
      "Iter-97610, train loss-0.3672, acc-0.9000, valid loss-0.2143, acc-0.9396, test loss-0.2236, acc-0.9360\n",
      "Iter-97620, train loss-0.1543, acc-0.9600, valid loss-0.2143, acc-0.9396, test loss-0.2236, acc-0.9362\n",
      "Iter-97630, train loss-0.1732, acc-0.9200, valid loss-0.2143, acc-0.9396, test loss-0.2236, acc-0.9361\n",
      "Iter-97640, train loss-0.2921, acc-0.9200, valid loss-0.2144, acc-0.9396, test loss-0.2236, acc-0.9363\n",
      "Iter-97650, train loss-0.1312, acc-0.9800, valid loss-0.2144, acc-0.9398, test loss-0.2237, acc-0.9365\n",
      "Iter-97660, train loss-0.1570, acc-0.9600, valid loss-0.2143, acc-0.9398, test loss-0.2237, acc-0.9364\n",
      "Iter-97670, train loss-0.1880, acc-0.9800, valid loss-0.2143, acc-0.9398, test loss-0.2236, acc-0.9365\n",
      "Iter-97680, train loss-0.1111, acc-0.9800, valid loss-0.2143, acc-0.9398, test loss-0.2236, acc-0.9363\n",
      "Iter-97690, train loss-0.3593, acc-0.9200, valid loss-0.2143, acc-0.9396, test loss-0.2237, acc-0.9361\n",
      "Iter-97700, train loss-0.2092, acc-0.9400, valid loss-0.2142, acc-0.9396, test loss-0.2237, acc-0.9361\n",
      "Iter-97710, train loss-0.3677, acc-0.9000, valid loss-0.2142, acc-0.9394, test loss-0.2236, acc-0.9361\n",
      "Iter-97720, train loss-0.1327, acc-0.9400, valid loss-0.2142, acc-0.9396, test loss-0.2236, acc-0.9359\n",
      "Iter-97730, train loss-0.1350, acc-0.9600, valid loss-0.2142, acc-0.9396, test loss-0.2236, acc-0.9362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-97740, train loss-0.1143, acc-0.9800, valid loss-0.2143, acc-0.9394, test loss-0.2236, acc-0.9363\n",
      "Iter-97750, train loss-0.0729, acc-1.0000, valid loss-0.2143, acc-0.9394, test loss-0.2236, acc-0.9363\n",
      "Iter-97760, train loss-0.1434, acc-0.9600, valid loss-0.2144, acc-0.9396, test loss-0.2236, acc-0.9363\n",
      "Iter-97770, train loss-0.3312, acc-0.8600, valid loss-0.2144, acc-0.9398, test loss-0.2236, acc-0.9363\n",
      "Iter-97780, train loss-0.2200, acc-0.9400, valid loss-0.2144, acc-0.9394, test loss-0.2236, acc-0.9364\n",
      "Iter-97790, train loss-0.3107, acc-0.9000, valid loss-0.2143, acc-0.9394, test loss-0.2235, acc-0.9363\n",
      "Iter-97800, train loss-0.2344, acc-0.9000, valid loss-0.2144, acc-0.9396, test loss-0.2235, acc-0.9362\n",
      "Iter-97810, train loss-0.1689, acc-0.9400, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9364\n",
      "Iter-97820, train loss-0.3401, acc-0.9400, valid loss-0.2144, acc-0.9394, test loss-0.2236, acc-0.9363\n",
      "Iter-97830, train loss-0.2891, acc-0.9400, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9364\n",
      "Iter-97840, train loss-0.0602, acc-1.0000, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9366\n",
      "Iter-97850, train loss-0.2526, acc-0.9000, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9364\n",
      "Iter-97860, train loss-0.1754, acc-0.9600, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9365\n",
      "Iter-97870, train loss-0.3185, acc-0.9000, valid loss-0.2144, acc-0.9400, test loss-0.2235, acc-0.9362\n",
      "Iter-97880, train loss-0.2520, acc-0.9000, valid loss-0.2144, acc-0.9396, test loss-0.2235, acc-0.9361\n",
      "Iter-97890, train loss-0.0556, acc-0.9800, valid loss-0.2144, acc-0.9394, test loss-0.2235, acc-0.9362\n",
      "Iter-97900, train loss-0.1185, acc-0.9400, valid loss-0.2143, acc-0.9398, test loss-0.2235, acc-0.9363\n",
      "Iter-97910, train loss-0.3478, acc-0.9400, valid loss-0.2143, acc-0.9400, test loss-0.2235, acc-0.9362\n",
      "Iter-97920, train loss-0.4145, acc-0.9000, valid loss-0.2142, acc-0.9398, test loss-0.2235, acc-0.9359\n",
      "Iter-97930, train loss-0.2273, acc-0.9200, valid loss-0.2142, acc-0.9398, test loss-0.2235, acc-0.9360\n",
      "Iter-97940, train loss-0.1709, acc-0.9600, valid loss-0.2142, acc-0.9398, test loss-0.2235, acc-0.9358\n",
      "Iter-97950, train loss-0.3928, acc-0.8800, valid loss-0.2142, acc-0.9398, test loss-0.2236, acc-0.9357\n",
      "Iter-97960, train loss-0.1231, acc-0.9600, valid loss-0.2141, acc-0.9398, test loss-0.2235, acc-0.9359\n",
      "Iter-97970, train loss-0.2932, acc-0.9000, valid loss-0.2141, acc-0.9400, test loss-0.2235, acc-0.9358\n",
      "Iter-97980, train loss-0.2202, acc-0.9400, valid loss-0.2141, acc-0.9400, test loss-0.2235, acc-0.9357\n",
      "Iter-97990, train loss-0.3396, acc-0.9200, valid loss-0.2140, acc-0.9398, test loss-0.2235, acc-0.9358\n",
      "Iter-98000, train loss-0.1865, acc-0.9400, valid loss-0.2140, acc-0.9402, test loss-0.2235, acc-0.9358\n",
      "Iter-98010, train loss-0.1125, acc-0.9800, valid loss-0.2140, acc-0.9404, test loss-0.2235, acc-0.9358\n",
      "Iter-98020, train loss-0.1026, acc-0.9800, valid loss-0.2140, acc-0.9404, test loss-0.2235, acc-0.9355\n",
      "Iter-98030, train loss-0.1810, acc-0.9200, valid loss-0.2140, acc-0.9404, test loss-0.2235, acc-0.9354\n",
      "Iter-98040, train loss-0.3256, acc-0.9000, valid loss-0.2139, acc-0.9404, test loss-0.2235, acc-0.9356\n",
      "Iter-98050, train loss-0.1272, acc-0.9600, valid loss-0.2138, acc-0.9404, test loss-0.2235, acc-0.9357\n",
      "Iter-98060, train loss-0.3375, acc-0.9000, valid loss-0.2138, acc-0.9404, test loss-0.2235, acc-0.9358\n",
      "Iter-98070, train loss-0.2865, acc-0.9600, valid loss-0.2138, acc-0.9402, test loss-0.2235, acc-0.9360\n",
      "Iter-98080, train loss-0.1910, acc-0.9400, valid loss-0.2138, acc-0.9404, test loss-0.2235, acc-0.9363\n",
      "Iter-98090, train loss-0.3477, acc-0.8800, valid loss-0.2138, acc-0.9404, test loss-0.2235, acc-0.9362\n",
      "Iter-98100, train loss-0.3930, acc-0.8400, valid loss-0.2138, acc-0.9404, test loss-0.2235, acc-0.9361\n",
      "Iter-98110, train loss-0.1313, acc-0.9400, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9359\n",
      "Iter-98120, train loss-0.2459, acc-0.9200, valid loss-0.2138, acc-0.9402, test loss-0.2234, acc-0.9358\n",
      "Iter-98130, train loss-0.2291, acc-0.9200, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9360\n",
      "Iter-98140, train loss-0.3155, acc-0.9200, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9360\n",
      "Iter-98150, train loss-0.1709, acc-0.9400, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9361\n",
      "Iter-98160, train loss-0.3453, acc-0.9200, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9362\n",
      "Iter-98170, train loss-0.3397, acc-0.9000, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9366\n",
      "Iter-98180, train loss-0.2415, acc-0.9000, valid loss-0.2138, acc-0.9404, test loss-0.2234, acc-0.9365\n",
      "Iter-98190, train loss-0.2620, acc-0.9400, valid loss-0.2138, acc-0.9402, test loss-0.2233, acc-0.9367\n",
      "Iter-98200, train loss-0.2326, acc-0.9400, valid loss-0.2138, acc-0.9404, test loss-0.2233, acc-0.9367\n",
      "Iter-98210, train loss-0.2752, acc-0.9400, valid loss-0.2138, acc-0.9402, test loss-0.2233, acc-0.9366\n",
      "Iter-98220, train loss-0.5368, acc-0.8800, valid loss-0.2137, acc-0.9404, test loss-0.2233, acc-0.9366\n",
      "Iter-98230, train loss-0.2870, acc-0.9000, valid loss-0.2137, acc-0.9404, test loss-0.2233, acc-0.9364\n",
      "Iter-98240, train loss-0.1938, acc-0.9400, valid loss-0.2137, acc-0.9402, test loss-0.2233, acc-0.9364\n",
      "Iter-98250, train loss-0.3144, acc-0.9400, valid loss-0.2137, acc-0.9404, test loss-0.2233, acc-0.9366\n",
      "Iter-98260, train loss-0.3155, acc-0.9200, valid loss-0.2138, acc-0.9402, test loss-0.2233, acc-0.9367\n",
      "Iter-98270, train loss-0.2681, acc-0.9200, valid loss-0.2138, acc-0.9402, test loss-0.2233, acc-0.9368\n",
      "Iter-98280, train loss-0.2486, acc-0.9400, valid loss-0.2137, acc-0.9398, test loss-0.2233, acc-0.9367\n",
      "Iter-98290, train loss-0.1317, acc-0.9600, valid loss-0.2137, acc-0.9402, test loss-0.2233, acc-0.9368\n",
      "Iter-98300, train loss-0.0735, acc-1.0000, valid loss-0.2137, acc-0.9404, test loss-0.2233, acc-0.9366\n",
      "Iter-98310, train loss-0.1799, acc-0.9400, valid loss-0.2137, acc-0.9404, test loss-0.2234, acc-0.9367\n",
      "Iter-98320, train loss-0.3907, acc-0.8800, valid loss-0.2137, acc-0.9402, test loss-0.2233, acc-0.9368\n",
      "Iter-98330, train loss-0.4346, acc-0.8400, valid loss-0.2137, acc-0.9400, test loss-0.2233, acc-0.9366\n",
      "Iter-98340, train loss-0.1079, acc-0.9800, valid loss-0.2136, acc-0.9402, test loss-0.2233, acc-0.9364\n",
      "Iter-98350, train loss-0.3263, acc-0.8800, valid loss-0.2137, acc-0.9406, test loss-0.2232, acc-0.9363\n",
      "Iter-98360, train loss-0.2491, acc-0.9000, valid loss-0.2137, acc-0.9404, test loss-0.2233, acc-0.9363\n",
      "Iter-98370, train loss-0.1170, acc-0.9800, valid loss-0.2136, acc-0.9404, test loss-0.2232, acc-0.9363\n",
      "Iter-98380, train loss-0.3474, acc-0.9400, valid loss-0.2136, acc-0.9406, test loss-0.2232, acc-0.9362\n",
      "Iter-98390, train loss-0.2173, acc-0.9600, valid loss-0.2135, acc-0.9406, test loss-0.2232, acc-0.9363\n",
      "Iter-98400, train loss-0.1445, acc-0.9400, valid loss-0.2136, acc-0.9408, test loss-0.2232, acc-0.9364\n",
      "Iter-98410, train loss-0.1623, acc-0.9600, valid loss-0.2136, acc-0.9408, test loss-0.2232, acc-0.9363\n",
      "Iter-98420, train loss-0.2733, acc-0.9200, valid loss-0.2136, acc-0.9408, test loss-0.2232, acc-0.9364\n",
      "Iter-98430, train loss-0.2076, acc-0.9600, valid loss-0.2136, acc-0.9410, test loss-0.2232, acc-0.9365\n",
      "Iter-98440, train loss-0.2847, acc-0.9200, valid loss-0.2136, acc-0.9410, test loss-0.2232, acc-0.9367\n",
      "Iter-98450, train loss-0.2208, acc-0.9000, valid loss-0.2136, acc-0.9406, test loss-0.2232, acc-0.9366\n",
      "Iter-98460, train loss-0.3212, acc-0.9200, valid loss-0.2137, acc-0.9404, test loss-0.2232, acc-0.9367\n",
      "Iter-98470, train loss-0.0755, acc-1.0000, valid loss-0.2137, acc-0.9402, test loss-0.2232, acc-0.9367\n",
      "Iter-98480, train loss-0.3299, acc-0.8600, valid loss-0.2137, acc-0.9406, test loss-0.2232, acc-0.9367\n",
      "Iter-98490, train loss-0.0735, acc-1.0000, valid loss-0.2137, acc-0.9402, test loss-0.2232, acc-0.9366\n",
      "Iter-98500, train loss-0.2500, acc-0.9400, valid loss-0.2137, acc-0.9402, test loss-0.2232, acc-0.9364\n",
      "Iter-98510, train loss-0.2995, acc-0.9200, valid loss-0.2136, acc-0.9402, test loss-0.2232, acc-0.9364\n",
      "Iter-98520, train loss-0.2769, acc-0.9400, valid loss-0.2136, acc-0.9400, test loss-0.2231, acc-0.9365\n",
      "Iter-98530, train loss-0.1572, acc-0.9800, valid loss-0.2137, acc-0.9398, test loss-0.2232, acc-0.9365\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-98540, train loss-0.2808, acc-0.9400, valid loss-0.2137, acc-0.9398, test loss-0.2231, acc-0.9365\n",
      "Iter-98550, train loss-0.2902, acc-0.9200, valid loss-0.2137, acc-0.9398, test loss-0.2231, acc-0.9365\n",
      "Iter-98560, train loss-0.4250, acc-0.8600, valid loss-0.2137, acc-0.9396, test loss-0.2230, acc-0.9369\n",
      "Iter-98570, train loss-0.2788, acc-0.9400, valid loss-0.2137, acc-0.9400, test loss-0.2230, acc-0.9367\n",
      "Iter-98580, train loss-0.1597, acc-0.9800, valid loss-0.2137, acc-0.9402, test loss-0.2230, acc-0.9368\n",
      "Iter-98590, train loss-0.1527, acc-0.9400, valid loss-0.2136, acc-0.9398, test loss-0.2230, acc-0.9367\n",
      "Iter-98600, train loss-0.2526, acc-0.9600, valid loss-0.2137, acc-0.9396, test loss-0.2230, acc-0.9368\n",
      "Iter-98610, train loss-0.3647, acc-0.8600, valid loss-0.2137, acc-0.9396, test loss-0.2229, acc-0.9368\n",
      "Iter-98620, train loss-0.1725, acc-0.9800, valid loss-0.2137, acc-0.9398, test loss-0.2230, acc-0.9368\n",
      "Iter-98630, train loss-0.3012, acc-0.9200, valid loss-0.2137, acc-0.9398, test loss-0.2230, acc-0.9368\n",
      "Iter-98640, train loss-0.1216, acc-0.9400, valid loss-0.2136, acc-0.9400, test loss-0.2229, acc-0.9368\n",
      "Iter-98650, train loss-0.4004, acc-0.9000, valid loss-0.2137, acc-0.9404, test loss-0.2229, acc-0.9367\n",
      "Iter-98660, train loss-0.2255, acc-0.9400, valid loss-0.2136, acc-0.9400, test loss-0.2229, acc-0.9367\n",
      "Iter-98670, train loss-0.2827, acc-0.9000, valid loss-0.2136, acc-0.9402, test loss-0.2229, acc-0.9367\n",
      "Iter-98680, train loss-0.0829, acc-0.9800, valid loss-0.2135, acc-0.9402, test loss-0.2229, acc-0.9367\n",
      "Iter-98690, train loss-0.2535, acc-0.8800, valid loss-0.2135, acc-0.9402, test loss-0.2229, acc-0.9367\n",
      "Iter-98700, train loss-0.1898, acc-0.9200, valid loss-0.2134, acc-0.9402, test loss-0.2229, acc-0.9368\n",
      "Iter-98710, train loss-0.1446, acc-0.9600, valid loss-0.2134, acc-0.9402, test loss-0.2228, acc-0.9367\n",
      "Iter-98720, train loss-0.0963, acc-0.9800, valid loss-0.2134, acc-0.9402, test loss-0.2228, acc-0.9366\n",
      "Iter-98730, train loss-0.1618, acc-0.9400, valid loss-0.2133, acc-0.9402, test loss-0.2228, acc-0.9367\n",
      "Iter-98740, train loss-0.1310, acc-0.9800, valid loss-0.2133, acc-0.9402, test loss-0.2228, acc-0.9368\n",
      "Iter-98750, train loss-0.2206, acc-0.9000, valid loss-0.2134, acc-0.9402, test loss-0.2228, acc-0.9367\n",
      "Iter-98760, train loss-0.2406, acc-0.9400, valid loss-0.2133, acc-0.9400, test loss-0.2228, acc-0.9371\n",
      "Iter-98770, train loss-0.2240, acc-0.9200, valid loss-0.2133, acc-0.9402, test loss-0.2228, acc-0.9369\n",
      "Iter-98780, train loss-0.3073, acc-0.9000, valid loss-0.2133, acc-0.9402, test loss-0.2228, acc-0.9371\n",
      "Iter-98790, train loss-0.1928, acc-0.9400, valid loss-0.2133, acc-0.9402, test loss-0.2228, acc-0.9373\n",
      "Iter-98800, train loss-0.2638, acc-0.9200, valid loss-0.2133, acc-0.9404, test loss-0.2228, acc-0.9373\n",
      "Iter-98810, train loss-0.2183, acc-0.9600, valid loss-0.2133, acc-0.9402, test loss-0.2227, acc-0.9374\n",
      "Iter-98820, train loss-0.1929, acc-0.9600, valid loss-0.2133, acc-0.9402, test loss-0.2227, acc-0.9375\n",
      "Iter-98830, train loss-0.1993, acc-0.9600, valid loss-0.2133, acc-0.9406, test loss-0.2227, acc-0.9375\n",
      "Iter-98840, train loss-0.1968, acc-0.9400, valid loss-0.2133, acc-0.9406, test loss-0.2227, acc-0.9375\n",
      "Iter-98850, train loss-0.2295, acc-0.9400, valid loss-0.2133, acc-0.9404, test loss-0.2227, acc-0.9374\n",
      "Iter-98860, train loss-0.1866, acc-0.9600, valid loss-0.2133, acc-0.9404, test loss-0.2227, acc-0.9375\n",
      "Iter-98870, train loss-0.2685, acc-0.9400, valid loss-0.2133, acc-0.9404, test loss-0.2227, acc-0.9372\n",
      "Iter-98880, train loss-0.1094, acc-0.9600, valid loss-0.2133, acc-0.9406, test loss-0.2227, acc-0.9376\n",
      "Iter-98890, train loss-0.0615, acc-0.9800, valid loss-0.2132, acc-0.9406, test loss-0.2227, acc-0.9375\n",
      "Iter-98900, train loss-0.3692, acc-0.9000, valid loss-0.2132, acc-0.9406, test loss-0.2227, acc-0.9375\n",
      "Iter-98910, train loss-0.1109, acc-0.9800, valid loss-0.2132, acc-0.9406, test loss-0.2227, acc-0.9376\n",
      "Iter-98920, train loss-0.1618, acc-0.9600, valid loss-0.2132, acc-0.9404, test loss-0.2227, acc-0.9371\n",
      "Iter-98930, train loss-0.3057, acc-0.9200, valid loss-0.2132, acc-0.9406, test loss-0.2227, acc-0.9373\n",
      "Iter-98940, train loss-0.2495, acc-0.9200, valid loss-0.2132, acc-0.9404, test loss-0.2227, acc-0.9373\n",
      "Iter-98950, train loss-0.0752, acc-1.0000, valid loss-0.2132, acc-0.9406, test loss-0.2227, acc-0.9373\n",
      "Iter-98960, train loss-0.4209, acc-0.8800, valid loss-0.2131, acc-0.9402, test loss-0.2227, acc-0.9372\n",
      "Iter-98970, train loss-0.1860, acc-0.9400, valid loss-0.2132, acc-0.9400, test loss-0.2227, acc-0.9372\n",
      "Iter-98980, train loss-0.1819, acc-0.9400, valid loss-0.2132, acc-0.9400, test loss-0.2226, acc-0.9371\n",
      "Iter-98990, train loss-0.2302, acc-0.9400, valid loss-0.2132, acc-0.9402, test loss-0.2226, acc-0.9373\n",
      "Iter-99000, train loss-0.0966, acc-0.9600, valid loss-0.2132, acc-0.9400, test loss-0.2225, acc-0.9369\n",
      "Iter-99010, train loss-0.2644, acc-0.8800, valid loss-0.2132, acc-0.9400, test loss-0.2226, acc-0.9371\n",
      "Iter-99020, train loss-0.2520, acc-0.8800, valid loss-0.2132, acc-0.9398, test loss-0.2225, acc-0.9371\n",
      "Iter-99030, train loss-0.2535, acc-0.9400, valid loss-0.2132, acc-0.9400, test loss-0.2225, acc-0.9369\n",
      "Iter-99040, train loss-0.2532, acc-0.9400, valid loss-0.2132, acc-0.9400, test loss-0.2225, acc-0.9370\n",
      "Iter-99050, train loss-0.2911, acc-0.9600, valid loss-0.2132, acc-0.9396, test loss-0.2225, acc-0.9371\n",
      "Iter-99060, train loss-0.5396, acc-0.8800, valid loss-0.2131, acc-0.9394, test loss-0.2224, acc-0.9370\n",
      "Iter-99070, train loss-0.1417, acc-0.9800, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9369\n",
      "Iter-99080, train loss-0.1704, acc-0.9800, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9369\n",
      "Iter-99090, train loss-0.2880, acc-0.9400, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9369\n",
      "Iter-99100, train loss-0.4629, acc-0.9000, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9370\n",
      "Iter-99110, train loss-0.2395, acc-0.9600, valid loss-0.2131, acc-0.9394, test loss-0.2224, acc-0.9372\n",
      "Iter-99120, train loss-0.2090, acc-0.9600, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9369\n",
      "Iter-99130, train loss-0.1178, acc-0.9600, valid loss-0.2131, acc-0.9396, test loss-0.2224, acc-0.9370\n",
      "Iter-99140, train loss-0.2290, acc-0.9600, valid loss-0.2131, acc-0.9394, test loss-0.2223, acc-0.9366\n",
      "Iter-99150, train loss-0.1976, acc-0.9400, valid loss-0.2131, acc-0.9396, test loss-0.2223, acc-0.9368\n",
      "Iter-99160, train loss-0.0788, acc-0.9800, valid loss-0.2131, acc-0.9398, test loss-0.2223, acc-0.9367\n",
      "Iter-99170, train loss-0.0924, acc-0.9600, valid loss-0.2131, acc-0.9398, test loss-0.2223, acc-0.9367\n",
      "Iter-99180, train loss-0.4000, acc-0.9000, valid loss-0.2130, acc-0.9396, test loss-0.2223, acc-0.9369\n",
      "Iter-99190, train loss-0.1880, acc-0.9200, valid loss-0.2130, acc-0.9396, test loss-0.2223, acc-0.9371\n",
      "Iter-99200, train loss-0.3335, acc-0.8800, valid loss-0.2130, acc-0.9396, test loss-0.2222, acc-0.9368\n",
      "Iter-99210, train loss-0.1521, acc-0.9800, valid loss-0.2130, acc-0.9394, test loss-0.2222, acc-0.9369\n",
      "Iter-99220, train loss-0.3050, acc-0.8800, valid loss-0.2131, acc-0.9394, test loss-0.2222, acc-0.9370\n",
      "Iter-99230, train loss-0.1176, acc-0.9600, valid loss-0.2131, acc-0.9396, test loss-0.2222, acc-0.9371\n",
      "Iter-99240, train loss-0.3351, acc-0.9400, valid loss-0.2131, acc-0.9396, test loss-0.2222, acc-0.9370\n",
      "Iter-99250, train loss-0.3065, acc-0.9000, valid loss-0.2131, acc-0.9396, test loss-0.2223, acc-0.9367\n",
      "Iter-99260, train loss-0.2400, acc-0.9600, valid loss-0.2130, acc-0.9398, test loss-0.2223, acc-0.9370\n",
      "Iter-99270, train loss-0.2150, acc-0.9200, valid loss-0.2130, acc-0.9400, test loss-0.2223, acc-0.9371\n",
      "Iter-99280, train loss-0.2779, acc-0.9000, valid loss-0.2130, acc-0.9394, test loss-0.2223, acc-0.9374\n",
      "Iter-99290, train loss-0.2340, acc-0.9000, valid loss-0.2130, acc-0.9396, test loss-0.2222, acc-0.9372\n",
      "Iter-99300, train loss-0.2068, acc-0.9400, valid loss-0.2130, acc-0.9396, test loss-0.2222, acc-0.9369\n",
      "Iter-99310, train loss-0.1888, acc-0.9400, valid loss-0.2130, acc-0.9398, test loss-0.2222, acc-0.9371\n",
      "Iter-99320, train loss-0.3506, acc-0.8800, valid loss-0.2130, acc-0.9396, test loss-0.2222, acc-0.9368\n",
      "Iter-99330, train loss-0.2532, acc-0.9400, valid loss-0.2129, acc-0.9394, test loss-0.2222, acc-0.9371\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-99340, train loss-0.1705, acc-0.9800, valid loss-0.2129, acc-0.9394, test loss-0.2222, acc-0.9370\n",
      "Iter-99350, train loss-0.1963, acc-0.9600, valid loss-0.2128, acc-0.9400, test loss-0.2222, acc-0.9372\n",
      "Iter-99360, train loss-0.2652, acc-0.9000, valid loss-0.2128, acc-0.9398, test loss-0.2222, acc-0.9369\n",
      "Iter-99370, train loss-0.1492, acc-0.9200, valid loss-0.2129, acc-0.9398, test loss-0.2222, acc-0.9367\n",
      "Iter-99380, train loss-0.1800, acc-0.9400, valid loss-0.2128, acc-0.9398, test loss-0.2222, acc-0.9368\n",
      "Iter-99390, train loss-0.3023, acc-0.9000, valid loss-0.2129, acc-0.9396, test loss-0.2221, acc-0.9367\n",
      "Iter-99400, train loss-0.1226, acc-0.9800, valid loss-0.2128, acc-0.9398, test loss-0.2221, acc-0.9368\n",
      "Iter-99410, train loss-0.1494, acc-0.9600, valid loss-0.2128, acc-0.9396, test loss-0.2221, acc-0.9366\n",
      "Iter-99420, train loss-0.1632, acc-0.9600, valid loss-0.2128, acc-0.9396, test loss-0.2221, acc-0.9369\n",
      "Iter-99430, train loss-0.3338, acc-0.9200, valid loss-0.2128, acc-0.9396, test loss-0.2221, acc-0.9368\n",
      "Iter-99440, train loss-0.1774, acc-0.9400, valid loss-0.2127, acc-0.9398, test loss-0.2220, acc-0.9366\n",
      "Iter-99450, train loss-0.1845, acc-0.9000, valid loss-0.2128, acc-0.9398, test loss-0.2220, acc-0.9370\n",
      "Iter-99460, train loss-0.1635, acc-0.9600, valid loss-0.2128, acc-0.9392, test loss-0.2220, acc-0.9370\n",
      "Iter-99470, train loss-0.1152, acc-0.9600, valid loss-0.2128, acc-0.9396, test loss-0.2220, acc-0.9371\n",
      "Iter-99480, train loss-0.2488, acc-0.9000, valid loss-0.2128, acc-0.9394, test loss-0.2220, acc-0.9367\n",
      "Iter-99490, train loss-0.1972, acc-0.9200, valid loss-0.2128, acc-0.9394, test loss-0.2220, acc-0.9367\n",
      "Iter-99500, train loss-0.2121, acc-0.9200, valid loss-0.2127, acc-0.9394, test loss-0.2220, acc-0.9368\n",
      "Iter-99510, train loss-0.1072, acc-1.0000, valid loss-0.2127, acc-0.9394, test loss-0.2220, acc-0.9369\n",
      "Iter-99520, train loss-0.1821, acc-0.9400, valid loss-0.2127, acc-0.9398, test loss-0.2220, acc-0.9367\n",
      "Iter-99530, train loss-0.1221, acc-0.9800, valid loss-0.2126, acc-0.9400, test loss-0.2219, acc-0.9368\n",
      "Iter-99540, train loss-0.1336, acc-0.9600, valid loss-0.2126, acc-0.9402, test loss-0.2220, acc-0.9366\n",
      "Iter-99550, train loss-0.1761, acc-0.9400, valid loss-0.2126, acc-0.9402, test loss-0.2219, acc-0.9367\n",
      "Iter-99560, train loss-0.4204, acc-0.9200, valid loss-0.2127, acc-0.9404, test loss-0.2219, acc-0.9366\n",
      "Iter-99570, train loss-0.1711, acc-0.9400, valid loss-0.2127, acc-0.9400, test loss-0.2219, acc-0.9367\n",
      "Iter-99580, train loss-0.2321, acc-0.9400, valid loss-0.2127, acc-0.9400, test loss-0.2220, acc-0.9367\n",
      "Iter-99590, train loss-0.1138, acc-0.9600, valid loss-0.2127, acc-0.9404, test loss-0.2220, acc-0.9367\n",
      "Iter-99600, train loss-0.2077, acc-0.9000, valid loss-0.2127, acc-0.9400, test loss-0.2220, acc-0.9369\n",
      "Iter-99610, train loss-0.3385, acc-0.8400, valid loss-0.2128, acc-0.9398, test loss-0.2219, acc-0.9369\n",
      "Iter-99620, train loss-0.1244, acc-0.9800, valid loss-0.2128, acc-0.9404, test loss-0.2220, acc-0.9369\n",
      "Iter-99630, train loss-0.2171, acc-0.9600, valid loss-0.2128, acc-0.9404, test loss-0.2219, acc-0.9370\n",
      "Iter-99640, train loss-0.3102, acc-0.9600, valid loss-0.2128, acc-0.9400, test loss-0.2220, acc-0.9369\n",
      "Iter-99650, train loss-0.1539, acc-0.9600, valid loss-0.2128, acc-0.9400, test loss-0.2219, acc-0.9371\n",
      "Iter-99660, train loss-0.1487, acc-0.9600, valid loss-0.2128, acc-0.9404, test loss-0.2219, acc-0.9371\n",
      "Iter-99670, train loss-0.2611, acc-0.8800, valid loss-0.2128, acc-0.9402, test loss-0.2219, acc-0.9371\n",
      "Iter-99680, train loss-0.3304, acc-0.9000, valid loss-0.2128, acc-0.9404, test loss-0.2219, acc-0.9371\n",
      "Iter-99690, train loss-0.1683, acc-0.9600, valid loss-0.2128, acc-0.9402, test loss-0.2218, acc-0.9372\n",
      "Iter-99700, train loss-0.1406, acc-0.9600, valid loss-0.2127, acc-0.9402, test loss-0.2218, acc-0.9372\n",
      "Iter-99710, train loss-0.2784, acc-0.9000, valid loss-0.2127, acc-0.9402, test loss-0.2218, acc-0.9372\n",
      "Iter-99720, train loss-0.0981, acc-0.9800, valid loss-0.2127, acc-0.9404, test loss-0.2219, acc-0.9373\n",
      "Iter-99730, train loss-0.1223, acc-0.9800, valid loss-0.2127, acc-0.9406, test loss-0.2218, acc-0.9371\n",
      "Iter-99740, train loss-0.1214, acc-0.9400, valid loss-0.2126, acc-0.9406, test loss-0.2218, acc-0.9373\n",
      "Iter-99750, train loss-0.1678, acc-0.9400, valid loss-0.2126, acc-0.9406, test loss-0.2218, acc-0.9372\n",
      "Iter-99760, train loss-0.2284, acc-0.9200, valid loss-0.2126, acc-0.9406, test loss-0.2218, acc-0.9372\n",
      "Iter-99770, train loss-0.3498, acc-0.8800, valid loss-0.2125, acc-0.9406, test loss-0.2218, acc-0.9371\n",
      "Iter-99780, train loss-0.1842, acc-0.9600, valid loss-0.2125, acc-0.9406, test loss-0.2218, acc-0.9373\n",
      "Iter-99790, train loss-0.2170, acc-0.9200, valid loss-0.2125, acc-0.9408, test loss-0.2218, acc-0.9372\n",
      "Iter-99800, train loss-0.2253, acc-0.9200, valid loss-0.2125, acc-0.9404, test loss-0.2217, acc-0.9372\n",
      "Iter-99810, train loss-0.1933, acc-0.9400, valid loss-0.2125, acc-0.9406, test loss-0.2218, acc-0.9373\n",
      "Iter-99820, train loss-0.0658, acc-1.0000, valid loss-0.2124, acc-0.9408, test loss-0.2217, acc-0.9374\n",
      "Iter-99830, train loss-0.1564, acc-0.9600, valid loss-0.2124, acc-0.9408, test loss-0.2217, acc-0.9372\n",
      "Iter-99840, train loss-0.1587, acc-0.9400, valid loss-0.2124, acc-0.9408, test loss-0.2218, acc-0.9372\n",
      "Iter-99850, train loss-0.1336, acc-0.9600, valid loss-0.2124, acc-0.9408, test loss-0.2218, acc-0.9371\n",
      "Iter-99860, train loss-0.1899, acc-0.9600, valid loss-0.2124, acc-0.9408, test loss-0.2218, acc-0.9373\n",
      "Iter-99870, train loss-0.1924, acc-0.9800, valid loss-0.2123, acc-0.9408, test loss-0.2218, acc-0.9369\n",
      "Iter-99880, train loss-0.2744, acc-0.9400, valid loss-0.2122, acc-0.9408, test loss-0.2218, acc-0.9370\n",
      "Iter-99890, train loss-0.2208, acc-0.9400, valid loss-0.2122, acc-0.9408, test loss-0.2217, acc-0.9369\n",
      "Iter-99900, train loss-0.2682, acc-0.8800, valid loss-0.2122, acc-0.9408, test loss-0.2218, acc-0.9371\n",
      "Iter-99910, train loss-0.1001, acc-0.9800, valid loss-0.2122, acc-0.9408, test loss-0.2217, acc-0.9370\n",
      "Iter-99920, train loss-0.1901, acc-0.9400, valid loss-0.2122, acc-0.9408, test loss-0.2217, acc-0.9372\n",
      "Iter-99930, train loss-0.2679, acc-0.9000, valid loss-0.2122, acc-0.9404, test loss-0.2216, acc-0.9370\n",
      "Iter-99940, train loss-0.0760, acc-1.0000, valid loss-0.2122, acc-0.9406, test loss-0.2217, acc-0.9370\n",
      "Iter-99950, train loss-0.3026, acc-0.9000, valid loss-0.2122, acc-0.9408, test loss-0.2216, acc-0.9371\n",
      "Iter-99960, train loss-0.1227, acc-0.9800, valid loss-0.2121, acc-0.9408, test loss-0.2216, acc-0.9371\n",
      "Iter-99970, train loss-0.1401, acc-0.9600, valid loss-0.2121, acc-0.9404, test loss-0.2216, acc-0.9371\n",
      "Iter-99980, train loss-0.1118, acc-0.9600, valid loss-0.2121, acc-0.9400, test loss-0.2216, acc-0.9371\n",
      "Iter-99990, train loss-0.1566, acc-0.9400, valid loss-0.2121, acc-0.9402, test loss-0.2216, acc-0.9372\n",
      "Iter-100000, train loss-0.2737, acc-0.9400, valid loss-0.2122, acc-0.9402, test loss-0.2216, acc-0.9372\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/Fsomnk5ni3gAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f677c67dd30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.plot(nn.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/w/3PV9hjqAtXgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f678b711d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['train_acc'], label='Train accuracy')\n",
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.plot(nn.losses['test_acc'], label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
