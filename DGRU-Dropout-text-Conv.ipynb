{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "\n",
    "with open('data/text_data/japan.txt', 'r') as f:\n",
    "    txt = f.read()\n",
    "\n",
    "    X = []\n",
    "    y = []\n",
    "\n",
    "    char_to_idx = {char: i for i, char in enumerate(set(txt))}\n",
    "    idx_to_char = {i: char for i, char in enumerate(set(txt))}\n",
    "\n",
    "    X = np.array([char_to_idx[x] for x in txt])\n",
    "    y = [char_to_idx[x] for x in txt[1:]]\n",
    "    y.append(char_to_idx['.'])\n",
    "    y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model or Network\n",
    "import impl.layer as l\n",
    "\n",
    "class GRU:\n",
    "\n",
    "    def __init__(self, D, H, L, char2idx, idx2char, p_dropout):\n",
    "        self.D = D\n",
    "        self.H = H\n",
    "        self.L = L\n",
    "        self.char2idx = char2idx\n",
    "        self.idx2char = idx2char\n",
    "        self.vocab_size = len(char2idx)\n",
    "        self.losses = {'train':[], 'smooth train':[]}\n",
    "        self.p_dropout = p_dropout\n",
    "        \n",
    "        # Model parameters weights and biases\n",
    "        Z = H + D\n",
    "        m = dict(\n",
    "            Wz=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wr=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wh=np.random.randn(Z, H) / np.sqrt(Z / 2.),\n",
    "            Wy=np.random.randn(H, D) / np.sqrt(H / 2.),\n",
    "            bz=np.zeros((1, H)),\n",
    "            br=np.zeros((1, H)),\n",
    "            bh=np.zeros((1, H)),\n",
    "            by=np.zeros((1, D))\n",
    "        )\n",
    "\n",
    "        self.model = []\n",
    "        for _ in range(self.L):\n",
    "            self.model.append(m)\n",
    "\n",
    "    def initial_state(self):\n",
    "        return np.zeros((1, self.H))\n",
    "\n",
    "    def forward(self, X, h, m, train):\n",
    "        Wz, Wr, Wh, Wy = m['Wz'], m['Wr'], m['Wh'], m['Wy']\n",
    "        bz, br, bh, by = m['bz'], m['br'], m['bh'], m['by']\n",
    "\n",
    "        X_one_hot = X.copy()\n",
    "        h_old = h.copy()\n",
    "\n",
    "        X = np.column_stack((h_old, X_one_hot))\n",
    "\n",
    "        hz, hz_cache = l.fc_forward(X, Wz, bz)\n",
    "        hz, hz_sigm_cache = l.sigmoid_forward(hz)\n",
    "\n",
    "        hr, hr_cache = l.fc_forward(X, Wr, br)\n",
    "        hr, hr_sigm_cache = l.sigmoid_forward(hr)\n",
    "\n",
    "        X_prime = np.column_stack((hr * h_old, X_one_hot))\n",
    "        hh, hh_cache = l.fc_forward(X_prime, Wh, bh)\n",
    "        hh, hh_tanh_cache = l.tanh_forward(hh)\n",
    "\n",
    "        h = (1. - hz) * h_old + hz * hh\n",
    "        y, y_cache = l.fc_forward(h, Wy, by)\n",
    "        if train: \n",
    "            y, do_cache = self.dropout_forward(X=y, p_dropout=self.p_dropout)\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache, do_cache)\n",
    "        else: # not train but test\n",
    "            cache = (X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, \n",
    "                     hh_tanh_cache, y_cache)\n",
    "\n",
    "        return y, h, cache\n",
    "\n",
    "    def backward(self, dy, dh, cache, train):\n",
    "        if train: # include dropout_cache/do_cache\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache, do_cache = cache\n",
    "            dy = self.dropout_backward(dout=dy, cache=do_cache)\n",
    "        else: # not train but test\n",
    "            X, X_prime, h_old, hz, hz_cache, hz_sigm_cache, hr, hr_cache, hr_sigm_cache, hh, hh_cache, hh_tanh_cache, y_cache = cache\n",
    "        \n",
    "        dh_next = dh.copy()\n",
    "        \n",
    "        dh, dWy, dby = l.fc_backward(dy, y_cache)\n",
    "        dh += dh_next\n",
    "\n",
    "        dhh = hz * dh\n",
    "        dh_old1 = (1. - hz) * dh\n",
    "        dhz = hh * dh - h_old * dh\n",
    "\n",
    "        dhh = l.tanh_backward(dhh, hh_tanh_cache)\n",
    "        dX_prime, dWh, dbh = l.fc_backward(dhh, hh_cache)\n",
    "\n",
    "        dh_prime = dX_prime[:, :self.H]\n",
    "        dh_old2 = hr * dh_prime\n",
    "\n",
    "        dhr = h_old * dh_prime\n",
    "        dhr = l.sigmoid_backward(dhr, hr_sigm_cache)\n",
    "        dXr, dWr, dbr = l.fc_backward(dhr, hr_cache)\n",
    "\n",
    "        dhz = l.sigmoid_backward(dhz, hz_sigm_cache)\n",
    "        dXz, dWz, dbz = l.fc_backward(dhz, hz_cache)\n",
    "\n",
    "        dX = dXr + dXz\n",
    "        dh_old3 = dX[:, :self.H]\n",
    "\n",
    "        dh = dh_old1 + dh_old2 + dh_old3\n",
    "        dX = dX[:, self.H:]\n",
    "\n",
    "        grad = dict(Wz=dWz, Wr=dWr, Wh=dWh, Wy=dWy, bz=dbz, br=dbr, bh=dbh, by=dby)\n",
    "        \n",
    "        return dX, dh, grad\n",
    "\n",
    "    def dropout_forward(self, X, p_dropout):\n",
    "        u = np.random.binomial(1, p_dropout, size=X.shape) / p_dropout\n",
    "        #         q = 1-p_dropout\n",
    "        #         u = np.random.binomial(1, q, size=X.shape)\n",
    "        out = X * u\n",
    "        cache = u\n",
    "        return out, cache\n",
    "\n",
    "    def dropout_backward(self, dout, cache):\n",
    "        dX = dout * cache\n",
    "        return dX\n",
    "\n",
    "    def train_forward(self, X_train, h):\n",
    "        ys, caches = [], []\n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "            caches.append([])\n",
    "\n",
    "        layer = 0 # self.L = 1\n",
    "        for X in X_train:\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            X = X_one_hot.reshape(1, -1)\n",
    "            y, h[layer], cache = self.forward(X, h[layer], self.model[layer], train=True)\n",
    "            caches[layer].append(cache)\n",
    "            ys.append(y)\n",
    "            \n",
    "        for layer in range(1, self.L):\n",
    "            X_train = ys.copy()\n",
    "            ys = []\n",
    "            for X in X_train:\n",
    "                y, h[layer], cache = self.forward(X, h[layer], self.model[layer], train=True)\n",
    "                caches[layer].append(cache)\n",
    "                ys.append(y)\n",
    "\n",
    "        return ys, caches\n",
    "\n",
    "    def cross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(prob[range(m), y_train])\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_pred, y_train):\n",
    "        m = y_pred.shape[0]\n",
    "\n",
    "        grad_y = l.softmax(y_pred)\n",
    "        grad_y[range(m), y_train] -= 1.0\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "    \n",
    "    def loss_function(self, y_train, ys):\n",
    "        loss, dys = 0.0, []\n",
    "\n",
    "        for y_pred, y in zip(ys, y_train):\n",
    "            loss += self.cross_entropy(y_pred, y)\n",
    "            dy = self.dcross_entropy(y_pred, y)\n",
    "            dys.append(dy)\n",
    "            \n",
    "        return loss, dys\n",
    "    \n",
    "    def train_backward(self, dys, caches):\n",
    "        dh, grad, grads = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            dh.append(np.zeros((1, self.H)))\n",
    "            grad.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "            grads.append({key: np.zeros_like(val) for key, val in self.model[layer].items()})\n",
    "        \n",
    "        for layer in reversed(range(self.L)):\n",
    "            if layer < (self.L - 1): dys = dXs.copy()\n",
    "            dXs = []\n",
    "            for t in reversed(range(len(dys))):\n",
    "                dX = dys[t]\n",
    "                dX, dh[layer], grad[layer] = self.backward(dX, dh[layer], caches[layer][t], train=True)\n",
    "                for key in grad[0].keys():\n",
    "                    grads[layer][key] += grad[layer][key]\n",
    "                dXs.append(dX)\n",
    "                \n",
    "        return dXs, grads\n",
    "    \n",
    "    def test(self, X_seed, h, size):\n",
    "        chars = [self.idx2char[X_seed]]\n",
    "        idx_list = list(range(self.vocab_size))\n",
    "        X = X_seed\n",
    "        \n",
    "        h_init = h.copy()\n",
    "        h = []\n",
    "        for _ in range(self.L):\n",
    "            h.append(h_init.copy())\n",
    "\n",
    "        for _ in range(size):\n",
    "            X_one_hot = np.zeros(self.D)\n",
    "            X_one_hot[X] = 1.\n",
    "            y = X_one_hot.reshape(1, -1)\n",
    "            for layer in range(self.L):\n",
    "                y, h[layer], _ = self.forward(y, h[layer], self.model[layer], train=False)\n",
    "                \n",
    "            prob = l.softmax(y)\n",
    "            idx = np.random.choice(idx_list, p=prob.ravel())\n",
    "            chars.append(self.idx2char[idx])\n",
    "            X = idx\n",
    "\n",
    "        return ''.join(chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Backprop\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "def get_minibatch(X, y, minibatch_size, shuffle):\n",
    "    minibatches = []\n",
    "\n",
    "    if shuffle:\n",
    "        X, y = skshuffle(X, y)\n",
    "\n",
    "    #     for i in range(0, X.shape[0], minibatch_size):\n",
    "    for i in range(0, X.shape[0] - minibatch_size +1, 1):\n",
    "        X_mini = X[i:i + minibatch_size]\n",
    "        y_mini = y[i:i + minibatch_size]\n",
    "        minibatches.append((X_mini, y_mini))\n",
    "\n",
    "    return minibatches\n",
    "\n",
    "def adam_rnn(nn, X_train, y_train, alpha, mb_size, n_iter, print_after):\n",
    "    M, R = [], []\n",
    "    for layer in range(nn.L):\n",
    "        M.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        R.append({key: np.zeros_like(val) for key, val in nn.model[layer].items()})\n",
    "        \n",
    "    beta1 = .99\n",
    "    beta2 = .999\n",
    "    eps = 1e-8\n",
    "    state = nn.initial_state()\n",
    "    smooth_loss = 1.0\n",
    "    minibatches = get_minibatch(X_train, y_train, mb_size, shuffle=False)\n",
    "\n",
    "    # Epochs\n",
    "    for iter in range(1, n_iter + 1):\n",
    "\n",
    "        # No batches/ full batches/ batch files\n",
    "        # Minibacthes\n",
    "        for idx in range(len(minibatches)):\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            ys, caches = nn.train_forward(X_mini, state)\n",
    "            loss, dys = nn.loss_function(y_train=y_mini, ys=ys)\n",
    "            dX, grads = nn.train_backward(dys, caches)\n",
    "            nn.losses['train'].append(loss)\n",
    "            smooth_loss = (0.999 * smooth_loss) + (0.001 * loss)\n",
    "            nn.losses['smooth train'].append(smooth_loss)\n",
    "        \n",
    "            for layer in range(nn.L):\n",
    "                for key in grads[layer].keys(): #key, value: items\n",
    "                    M[layer][key] = l.exp_running_avg(M[layer][key], grads[layer][key], beta1)\n",
    "                    R[layer][key] = l.exp_running_avg(R[layer][key], grads[layer][key]**2, beta2)\n",
    "\n",
    "                    m_k_hat = M[layer][key] / (1. - (beta1**(iter)))\n",
    "                    r_k_hat = R[layer][key] / (1. - (beta2**(iter)))\n",
    "\n",
    "                    nn.model[layer][key] -= alpha * m_k_hat / (np.sqrt(r_k_hat) + eps)\n",
    "                \n",
    "        # Print loss and test sample\n",
    "        if iter % print_after == 0:\n",
    "            print('Iter-{} loss: {:.4f}'.format(iter, loss))\n",
    "            sample = nn.test(X_mini[0], state, size=100)\n",
    "            print(sample)\n",
    "\n",
    "    return nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1 loss: 48.5748\n",
      "in a cn2. rl -anoytsc dtR nnlsca n1 P toeAtoAa. t Gpia6G t sPJsamlthtaaair2IttJah5taA5t eat  th tJo.c\n",
      "Iter-2 loss: 47.1298\n",
      "i a e acelpph i tpRtii- rainnae tiaIa te22htt  e oaot ehtem  nnethhc tlente  nc h 0y ale iI  htha0 np\n",
      "Iter-3 loss: 44.8546\n",
      "idikcAS estt nn1JrlAt tht,cs fyshc0c ahA soe lvaetd 5nijh le 6su nneheAJ ue 0dIv 2Abt  Cndm caacet u,\n",
      "Iter-4 loss: 44.4574\n",
      "in t h tatnn toiAyTt  ctrs Gna    6)re 2ete.aeRs  aA i op  bth Ihsiltoohei i ria  skssi5ouasdtlto s i\n",
      "Iter-5 loss: 45.3909\n",
      "ia itahdu aoteietApoIoa hsirdaeR  n is  hs. mtotjp htt pTaaat fotbaepubtttih0Il  aiIfxn t oetuhgsnhe2\n",
      "Iter-6 loss: 45.3751\n",
      "is  hxo    imatels  tghhtdh0ahroIysoa tlxhsetethne   2 oonuc hctA .bpt9 thbAn pnsn A6ahue ispxIpf ftu\n",
      "Iter-7 loss: 45.4704\n",
      "i ekae een tcn.aePe  ntos Brnsa  sie ast J bldIbtiyyahhcpmAm.hu geIdp e e onttsce 2 Ai    2oG n ashdn\n",
      "Iter-8 loss: 45.4089\n",
      "iCuysndnAtA  x htua  i khJmshcoi   hh kbsh ucso n.onhtsos s eJt etllx en  tHueu t  eele0ptjofl ant uN\n",
      "Iter-9 loss: 46.7050\n",
      "ii sJipoieaosne    niimttpo atc  sA ae.eswltghn lmoe eihæ—¥t'  ir .cb d aitaay aSA hp ly gtmt6tc2to h- \n",
      "Iter-10 loss: 43.8913\n",
      "i5sb itCsdtt55nitsnfa lsea d nl xlmt 1ttetne0ar ka2ttae a  hnsby  aiivd a eh a cot plalaafrC2hyf  epn\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.GRU at 0x111156518>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "time_step = 10 # width, minibatch size and test sample size as well\n",
    "num_layers = 2 # depth\n",
    "n_iter = 10 # epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "p_dropout = 0.95 # q=1-p, q=keep_prob and p=dropout.\n",
    "print_after = n_iter//10 # print training loss, valid, and test\n",
    "num_hidden_units = 64 # num_hidden_units in hidden layer\n",
    "num_input_units = len(char_to_idx) # vocab_size = len(char_to_idx)\n",
    "\n",
    "# Build the network and learning it or optimizing it using SGD\n",
    "net = GRU(D=num_input_units, H=num_hidden_units, L=num_layers, char2idx=char_to_idx, idx2char=idx_to_char, \n",
    "          p_dropout=p_dropout)\n",
    "\n",
    "# Start learning using BP-SGD-ADAM\n",
    "adam_rnn(nn=net, X_train=X, y_train=y, alpha=alpha, mb_size=time_step, n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1111dcb00>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(net.losses['train'], label='Train loss')\n",
    "plt.plot(net.losses['smooth train'], label='Smooth train loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
