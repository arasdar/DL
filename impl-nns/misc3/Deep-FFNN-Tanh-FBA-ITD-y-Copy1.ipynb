{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # layers\n",
    "        self.C = C # classes\n",
    "        self.losses = {'train':[], 'train_acc':[], \n",
    "                       'valid':[], 'valid_acc':[], \n",
    "                       'test':[], 'test_acc':[]}\n",
    "        \n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.dy_prev = np.zeros((1, C))\n",
    "        self.y_prev = np.zeros((1, C))\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Output layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "#         dX = dout @ W.T # vanilla Backprop\n",
    "        dX = dout @ W_fixed.T # fba backprop\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = l.tanh_forward(X=y)\n",
    "#         y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#         y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#         y *= 2.0 # uni-var/ std\n",
    "        if train:\n",
    "            caches.append((fc_cache, nl_cache))\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = l.tanh_forward(X=y)\n",
    "#             y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#             y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#             y *= 2.0 # uni-var/ std\n",
    "            X = y.copy() # pass to next layer\n",
    "            if train:\n",
    "                fc_caches.append(fc_cache)\n",
    "                nl_caches.append(nl_cache)\n",
    "        if train:\n",
    "            caches.append((fc_caches, nl_caches)) # caches[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        y_prob = l.softmax(X=y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "\n",
    "        return y_prob, caches # for backpropating the error\n",
    "\n",
    "    def cross_entropy(self, y_prob, y_train):\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(y_prob[range(m), y_train] + l.eps) # to avoid the devision by zero\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_prob, y_train): # this is equal for both since the reg_loss (noise) derivative is ZERO.\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         grad_y = l.softmax(y_pred)\n",
    "        grad_y = y_prob\n",
    "        grad_y[range(m), y_train] -= 1.\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y_prob, y_train):\n",
    "        \n",
    "        loss = self.cross_entropy(y_prob, y_train) # softmax is included\n",
    "        dy = self.dcross_entropy(y_prob, y_train) # dsoftmax is included\n",
    "\n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, y):\n",
    "        grads = self.grads.copy() # initialized by Zero in every iteration/epoch\n",
    "#         dy_prev = self.dy_prev.copy() # for temporal differencing\n",
    "#         self.dy_prev = dy.copy() # next iteration/ epoch\n",
    "        y_prev = self.y_prev.copy() # for temporal differencing\n",
    "        self.y_prev = y.copy() # next iteration/ epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        # softmax_backward is included in dcross_entropy.\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "# #         dy =  dy @ self.W_fixed[2].T # done\n",
    "#         dy_prev =  dy_prev @ self.W_fixed[2].T\n",
    "        y =  y @ self.W_fixed[2].T # done\n",
    "        y_prev =  y_prev @ self.W_fixed[2].T\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "#             dy = l.tanh_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "            dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "# #             dy =  dy @ self.W_fixed[2].T # done\n",
    "#             dy_prev =  dy_prev @ self.W_fixed[1][layer].T\n",
    "            y =  y @ self.W_fixed[1][layer].T # done\n",
    "            y_prev =  y_prev @ self.W_fixed[1][layer].T\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "#         dy = l.tanh_backward(cache=nl_cache, dout=dy) # diffable function\n",
    "#         dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#         dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "        dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_prob, _ = self.train_forward(X, train=False)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_prob\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y_prob, caches = self.train_forward(X_mini, train=True)\n",
    "            _, dy = self.loss_function(y_prob, y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, y_prob)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "            \n",
    "            # Training accuracy\n",
    "            y_pred, y_prob = self.test(X_mini)\n",
    "            loss, _ = self.loss_function(y_prob, y_mini) # softmax is included in entropy loss function\n",
    "            self.losses['train'].append(loss)\n",
    "            acc = np.mean(y_pred == y_mini) # confusion matrix\n",
    "            self.losses['train_acc'].append(acc)\n",
    "\n",
    "            # Validate the updated model\n",
    "            y_pred, y_prob = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_prob, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Test the final model\n",
    "            y_pred, y_prob = nn.test(X_test)\n",
    "            test_loss, _ = self.loss_function(y_prob, y_test) # softmax is included in entropy loss function\n",
    "            self.losses['test'].append(test_loss)\n",
    "            test_acc = np.mean(y_pred == y_test)\n",
    "            self.losses['test_acc'].append(test_acc)\n",
    "#             print('Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.\n",
    "#             format(acc.mean(), acc.std(), loss))\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{}, train loss-{:.4f}, acc-{:.4f}, valid loss-{:.4f}, acc-{:.4f}, test loss-{:.4f}, acc-{:.4f}'.format(\n",
    "                   iter, loss, acc, valid_loss, valid_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10, train loss-2.2982, acc-0.1200, valid loss-2.2982, acc-0.1064, test loss-2.3020, acc-0.1102\n",
      "Iter-20, train loss-2.2774, acc-0.1400, valid loss-2.2981, acc-0.1066, test loss-2.3019, acc-0.1100\n",
      "Iter-30, train loss-2.2796, acc-0.1000, valid loss-2.2981, acc-0.1062, test loss-2.3018, acc-0.1100\n",
      "Iter-40, train loss-2.3075, acc-0.0800, valid loss-2.2980, acc-0.1060, test loss-2.3017, acc-0.1103\n",
      "Iter-50, train loss-2.2879, acc-0.1400, valid loss-2.2979, acc-0.1064, test loss-2.3016, acc-0.1101\n",
      "Iter-60, train loss-2.3075, acc-0.1800, valid loss-2.2978, acc-0.1064, test loss-2.3015, acc-0.1103\n",
      "Iter-70, train loss-2.2745, acc-0.1800, valid loss-2.2977, acc-0.1064, test loss-2.3014, acc-0.1108\n",
      "Iter-80, train loss-2.3075, acc-0.1000, valid loss-2.2976, acc-0.1062, test loss-2.3013, acc-0.1109\n",
      "Iter-90, train loss-2.3128, acc-0.1200, valid loss-2.2975, acc-0.1062, test loss-2.3012, acc-0.1108\n",
      "Iter-100, train loss-2.3038, acc-0.1200, valid loss-2.2974, acc-0.1062, test loss-2.3011, acc-0.1111\n",
      "Iter-110, train loss-2.3114, acc-0.0800, valid loss-2.2973, acc-0.1066, test loss-2.3010, acc-0.1110\n",
      "Iter-120, train loss-2.2868, acc-0.1400, valid loss-2.2973, acc-0.1068, test loss-2.3009, acc-0.1113\n",
      "Iter-130, train loss-2.3094, acc-0.1400, valid loss-2.2972, acc-0.1072, test loss-2.3008, acc-0.1117\n",
      "Iter-140, train loss-2.2894, acc-0.1200, valid loss-2.2971, acc-0.1078, test loss-2.3007, acc-0.1119\n",
      "Iter-150, train loss-2.3082, acc-0.1800, valid loss-2.2970, acc-0.1078, test loss-2.3006, acc-0.1120\n",
      "Iter-160, train loss-2.2778, acc-0.1200, valid loss-2.2969, acc-0.1080, test loss-2.3005, acc-0.1123\n",
      "Iter-170, train loss-2.3057, acc-0.1000, valid loss-2.2968, acc-0.1080, test loss-2.3005, acc-0.1123\n",
      "Iter-180, train loss-2.3096, acc-0.1600, valid loss-2.2967, acc-0.1078, test loss-2.3004, acc-0.1123\n",
      "Iter-190, train loss-2.3055, acc-0.0800, valid loss-2.2966, acc-0.1082, test loss-2.3003, acc-0.1124\n",
      "Iter-200, train loss-2.3152, acc-0.1200, valid loss-2.2965, acc-0.1076, test loss-2.3002, acc-0.1124\n",
      "Iter-210, train loss-2.2966, acc-0.1000, valid loss-2.2965, acc-0.1078, test loss-2.3001, acc-0.1125\n",
      "Iter-220, train loss-2.2935, acc-0.1800, valid loss-2.2964, acc-0.1078, test loss-2.3000, acc-0.1126\n",
      "Iter-230, train loss-2.3209, acc-0.1000, valid loss-2.2963, acc-0.1078, test loss-2.2999, acc-0.1127\n",
      "Iter-240, train loss-2.2911, acc-0.1600, valid loss-2.2962, acc-0.1080, test loss-2.2998, acc-0.1127\n",
      "Iter-250, train loss-2.3038, acc-0.0800, valid loss-2.2961, acc-0.1072, test loss-2.2997, acc-0.1127\n",
      "Iter-260, train loss-2.2774, acc-0.2200, valid loss-2.2960, acc-0.1080, test loss-2.2996, acc-0.1130\n",
      "Iter-270, train loss-2.2892, acc-0.1600, valid loss-2.2959, acc-0.1082, test loss-2.2995, acc-0.1134\n",
      "Iter-280, train loss-2.2766, acc-0.1000, valid loss-2.2959, acc-0.1082, test loss-2.2994, acc-0.1134\n",
      "Iter-290, train loss-2.2854, acc-0.1400, valid loss-2.2958, acc-0.1086, test loss-2.2993, acc-0.1136\n",
      "Iter-300, train loss-2.2830, acc-0.1400, valid loss-2.2957, acc-0.1084, test loss-2.2992, acc-0.1137\n",
      "Iter-310, train loss-2.3026, acc-0.1600, valid loss-2.2956, acc-0.1092, test loss-2.2991, acc-0.1139\n",
      "Iter-320, train loss-2.3110, acc-0.0600, valid loss-2.2955, acc-0.1090, test loss-2.2990, acc-0.1132\n",
      "Iter-330, train loss-2.2973, acc-0.1400, valid loss-2.2954, acc-0.1090, test loss-2.2989, acc-0.1135\n",
      "Iter-340, train loss-2.3007, acc-0.1600, valid loss-2.2953, acc-0.1092, test loss-2.2988, acc-0.1135\n",
      "Iter-350, train loss-2.3095, acc-0.0600, valid loss-2.2953, acc-0.1088, test loss-2.2987, acc-0.1136\n",
      "Iter-360, train loss-2.3037, acc-0.1000, valid loss-2.2952, acc-0.1090, test loss-2.2987, acc-0.1137\n",
      "Iter-370, train loss-2.2869, acc-0.1600, valid loss-2.2951, acc-0.1094, test loss-2.2986, acc-0.1137\n",
      "Iter-380, train loss-2.3137, acc-0.0800, valid loss-2.2950, acc-0.1092, test loss-2.2985, acc-0.1138\n",
      "Iter-390, train loss-2.3156, acc-0.0400, valid loss-2.2949, acc-0.1092, test loss-2.2984, acc-0.1140\n",
      "Iter-400, train loss-2.2836, acc-0.1400, valid loss-2.2948, acc-0.1094, test loss-2.2983, acc-0.1141\n",
      "Iter-410, train loss-2.3117, acc-0.1000, valid loss-2.2947, acc-0.1094, test loss-2.2981, acc-0.1143\n",
      "Iter-420, train loss-2.3035, acc-0.1000, valid loss-2.2946, acc-0.1100, test loss-2.2981, acc-0.1145\n",
      "Iter-430, train loss-2.2891, acc-0.1200, valid loss-2.2945, acc-0.1100, test loss-2.2980, acc-0.1144\n",
      "Iter-440, train loss-2.3033, acc-0.1600, valid loss-2.2944, acc-0.1104, test loss-2.2979, acc-0.1145\n",
      "Iter-450, train loss-2.2889, acc-0.2200, valid loss-2.2944, acc-0.1106, test loss-2.2978, acc-0.1145\n",
      "Iter-460, train loss-2.2949, acc-0.1000, valid loss-2.2943, acc-0.1108, test loss-2.2977, acc-0.1149\n",
      "Iter-470, train loss-2.3109, acc-0.0800, valid loss-2.2942, acc-0.1108, test loss-2.2976, acc-0.1149\n",
      "Iter-480, train loss-2.2947, acc-0.1400, valid loss-2.2941, acc-0.1110, test loss-2.2975, acc-0.1150\n",
      "Iter-490, train loss-2.2976, acc-0.1000, valid loss-2.2940, acc-0.1110, test loss-2.2974, acc-0.1152\n",
      "Iter-500, train loss-2.3145, acc-0.0200, valid loss-2.2939, acc-0.1112, test loss-2.2973, acc-0.1153\n",
      "Iter-510, train loss-2.3080, acc-0.1600, valid loss-2.2938, acc-0.1118, test loss-2.2972, acc-0.1154\n",
      "Iter-520, train loss-2.2793, acc-0.1400, valid loss-2.2937, acc-0.1118, test loss-2.2971, acc-0.1156\n",
      "Iter-530, train loss-2.3086, acc-0.1000, valid loss-2.2937, acc-0.1114, test loss-2.2970, acc-0.1157\n",
      "Iter-540, train loss-2.3156, acc-0.1000, valid loss-2.2936, acc-0.1116, test loss-2.2969, acc-0.1163\n",
      "Iter-550, train loss-2.2841, acc-0.1400, valid loss-2.2935, acc-0.1118, test loss-2.2968, acc-0.1169\n",
      "Iter-560, train loss-2.2903, acc-0.1000, valid loss-2.2934, acc-0.1122, test loss-2.2967, acc-0.1168\n",
      "Iter-570, train loss-2.2977, acc-0.1000, valid loss-2.2933, acc-0.1122, test loss-2.2966, acc-0.1168\n",
      "Iter-580, train loss-2.2733, acc-0.1600, valid loss-2.2932, acc-0.1124, test loss-2.2965, acc-0.1168\n",
      "Iter-590, train loss-2.3082, acc-0.0200, valid loss-2.2931, acc-0.1126, test loss-2.2964, acc-0.1169\n",
      "Iter-600, train loss-2.2937, acc-0.1000, valid loss-2.2930, acc-0.1128, test loss-2.2963, acc-0.1167\n",
      "Iter-610, train loss-2.2793, acc-0.1000, valid loss-2.2929, acc-0.1124, test loss-2.2962, acc-0.1171\n",
      "Iter-620, train loss-2.3356, acc-0.0600, valid loss-2.2929, acc-0.1128, test loss-2.2961, acc-0.1170\n",
      "Iter-630, train loss-2.2948, acc-0.1000, valid loss-2.2928, acc-0.1130, test loss-2.2960, acc-0.1171\n",
      "Iter-640, train loss-2.2881, acc-0.2000, valid loss-2.2927, acc-0.1132, test loss-2.2959, acc-0.1176\n",
      "Iter-650, train loss-2.2983, acc-0.1400, valid loss-2.2926, acc-0.1134, test loss-2.2958, acc-0.1180\n",
      "Iter-660, train loss-2.3121, acc-0.1600, valid loss-2.2925, acc-0.1138, test loss-2.2957, acc-0.1180\n",
      "Iter-670, train loss-2.3107, acc-0.0800, valid loss-2.2924, acc-0.1138, test loss-2.2957, acc-0.1179\n",
      "Iter-680, train loss-2.2802, acc-0.1600, valid loss-2.2923, acc-0.1140, test loss-2.2956, acc-0.1179\n",
      "Iter-690, train loss-2.2960, acc-0.1800, valid loss-2.2922, acc-0.1138, test loss-2.2955, acc-0.1184\n",
      "Iter-700, train loss-2.2889, acc-0.1000, valid loss-2.2922, acc-0.1142, test loss-2.2954, acc-0.1185\n",
      "Iter-710, train loss-2.2947, acc-0.1000, valid loss-2.2921, acc-0.1144, test loss-2.2953, acc-0.1188\n",
      "Iter-720, train loss-2.2875, acc-0.1200, valid loss-2.2920, acc-0.1142, test loss-2.2952, acc-0.1195\n",
      "Iter-730, train loss-2.3063, acc-0.0800, valid loss-2.2919, acc-0.1144, test loss-2.2951, acc-0.1194\n",
      "Iter-740, train loss-2.3061, acc-0.1400, valid loss-2.2918, acc-0.1146, test loss-2.2950, acc-0.1195\n",
      "Iter-750, train loss-2.3153, acc-0.0600, valid loss-2.2917, acc-0.1148, test loss-2.2949, acc-0.1198\n",
      "Iter-760, train loss-2.2648, acc-0.2200, valid loss-2.2917, acc-0.1148, test loss-2.2948, acc-0.1194\n",
      "Iter-770, train loss-2.3211, acc-0.0800, valid loss-2.2916, acc-0.1150, test loss-2.2947, acc-0.1194\n",
      "Iter-780, train loss-2.2871, acc-0.1600, valid loss-2.2915, acc-0.1156, test loss-2.2946, acc-0.1194\n",
      "Iter-790, train loss-2.2898, acc-0.2200, valid loss-2.2914, acc-0.1154, test loss-2.2945, acc-0.1195\n",
      "Iter-800, train loss-2.2966, acc-0.1600, valid loss-2.2913, acc-0.1154, test loss-2.2944, acc-0.1198\n",
      "Iter-810, train loss-2.2725, acc-0.1000, valid loss-2.2912, acc-0.1160, test loss-2.2943, acc-0.1201\n",
      "Iter-820, train loss-2.2784, acc-0.2000, valid loss-2.2911, acc-0.1162, test loss-2.2942, acc-0.1201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-830, train loss-2.2956, acc-0.1000, valid loss-2.2910, acc-0.1164, test loss-2.2941, acc-0.1204\n",
      "Iter-840, train loss-2.2942, acc-0.1000, valid loss-2.2910, acc-0.1172, test loss-2.2940, acc-0.1207\n",
      "Iter-850, train loss-2.2835, acc-0.1400, valid loss-2.2909, acc-0.1170, test loss-2.2939, acc-0.1206\n",
      "Iter-860, train loss-2.2704, acc-0.1600, valid loss-2.2908, acc-0.1168, test loss-2.2938, acc-0.1206\n",
      "Iter-870, train loss-2.2868, acc-0.2000, valid loss-2.2907, acc-0.1172, test loss-2.2937, acc-0.1208\n",
      "Iter-880, train loss-2.3125, acc-0.1000, valid loss-2.2906, acc-0.1174, test loss-2.2937, acc-0.1211\n",
      "Iter-890, train loss-2.2918, acc-0.1200, valid loss-2.2905, acc-0.1180, test loss-2.2936, acc-0.1211\n",
      "Iter-900, train loss-2.3059, acc-0.1200, valid loss-2.2904, acc-0.1176, test loss-2.2935, acc-0.1212\n",
      "Iter-910, train loss-2.2753, acc-0.2000, valid loss-2.2904, acc-0.1176, test loss-2.2934, acc-0.1212\n",
      "Iter-920, train loss-2.3018, acc-0.0800, valid loss-2.2903, acc-0.1176, test loss-2.2933, acc-0.1213\n",
      "Iter-930, train loss-2.2954, acc-0.1000, valid loss-2.2902, acc-0.1176, test loss-2.2932, acc-0.1212\n",
      "Iter-940, train loss-2.2964, acc-0.1400, valid loss-2.2901, acc-0.1180, test loss-2.2931, acc-0.1214\n",
      "Iter-950, train loss-2.3020, acc-0.0800, valid loss-2.2900, acc-0.1178, test loss-2.2930, acc-0.1214\n",
      "Iter-960, train loss-2.2922, acc-0.1400, valid loss-2.2899, acc-0.1182, test loss-2.2929, acc-0.1215\n",
      "Iter-970, train loss-2.2985, acc-0.1000, valid loss-2.2898, acc-0.1178, test loss-2.2928, acc-0.1216\n",
      "Iter-980, train loss-2.2910, acc-0.1200, valid loss-2.2897, acc-0.1182, test loss-2.2927, acc-0.1215\n",
      "Iter-990, train loss-2.3197, acc-0.0200, valid loss-2.2897, acc-0.1184, test loss-2.2926, acc-0.1214\n",
      "Iter-1000, train loss-2.2741, acc-0.1200, valid loss-2.2896, acc-0.1184, test loss-2.2925, acc-0.1219\n",
      "Iter-1010, train loss-2.2785, acc-0.2200, valid loss-2.2895, acc-0.1186, test loss-2.2924, acc-0.1219\n",
      "Iter-1020, train loss-2.2802, acc-0.1400, valid loss-2.2894, acc-0.1188, test loss-2.2923, acc-0.1221\n",
      "Iter-1030, train loss-2.3144, acc-0.0400, valid loss-2.2893, acc-0.1188, test loss-2.2922, acc-0.1221\n",
      "Iter-1040, train loss-2.3369, acc-0.0800, valid loss-2.2892, acc-0.1192, test loss-2.2921, acc-0.1224\n",
      "Iter-1050, train loss-2.2749, acc-0.1200, valid loss-2.2891, acc-0.1194, test loss-2.2920, acc-0.1228\n",
      "Iter-1060, train loss-2.3084, acc-0.1200, valid loss-2.2891, acc-0.1196, test loss-2.2919, acc-0.1229\n",
      "Iter-1070, train loss-2.2969, acc-0.1200, valid loss-2.2890, acc-0.1198, test loss-2.2918, acc-0.1231\n",
      "Iter-1080, train loss-2.3126, acc-0.0600, valid loss-2.2889, acc-0.1200, test loss-2.2917, acc-0.1233\n",
      "Iter-1090, train loss-2.3021, acc-0.1200, valid loss-2.2888, acc-0.1198, test loss-2.2917, acc-0.1233\n",
      "Iter-1100, train loss-2.2942, acc-0.0800, valid loss-2.2887, acc-0.1198, test loss-2.2916, acc-0.1237\n",
      "Iter-1110, train loss-2.2866, acc-0.1600, valid loss-2.2886, acc-0.1204, test loss-2.2915, acc-0.1241\n",
      "Iter-1120, train loss-2.2672, acc-0.1600, valid loss-2.2885, acc-0.1206, test loss-2.2914, acc-0.1242\n",
      "Iter-1130, train loss-2.2817, acc-0.1400, valid loss-2.2884, acc-0.1208, test loss-2.2913, acc-0.1243\n",
      "Iter-1140, train loss-2.2857, acc-0.0600, valid loss-2.2884, acc-0.1206, test loss-2.2912, acc-0.1243\n",
      "Iter-1150, train loss-2.2978, acc-0.0800, valid loss-2.2883, acc-0.1212, test loss-2.2911, acc-0.1243\n",
      "Iter-1160, train loss-2.3163, acc-0.1000, valid loss-2.2882, acc-0.1216, test loss-2.2910, acc-0.1247\n",
      "Iter-1170, train loss-2.2920, acc-0.1400, valid loss-2.2881, acc-0.1216, test loss-2.2909, acc-0.1247\n",
      "Iter-1180, train loss-2.2964, acc-0.1000, valid loss-2.2880, acc-0.1220, test loss-2.2908, acc-0.1249\n",
      "Iter-1190, train loss-2.2941, acc-0.1600, valid loss-2.2879, acc-0.1218, test loss-2.2907, acc-0.1250\n",
      "Iter-1200, train loss-2.3251, acc-0.0200, valid loss-2.2878, acc-0.1220, test loss-2.2906, acc-0.1251\n",
      "Iter-1210, train loss-2.2978, acc-0.0800, valid loss-2.2878, acc-0.1222, test loss-2.2905, acc-0.1250\n",
      "Iter-1220, train loss-2.2868, acc-0.1000, valid loss-2.2877, acc-0.1222, test loss-2.2904, acc-0.1252\n",
      "Iter-1230, train loss-2.3161, acc-0.0600, valid loss-2.2876, acc-0.1222, test loss-2.2903, acc-0.1252\n",
      "Iter-1240, train loss-2.2745, acc-0.1600, valid loss-2.2875, acc-0.1224, test loss-2.2902, acc-0.1254\n",
      "Iter-1250, train loss-2.2584, acc-0.1200, valid loss-2.2874, acc-0.1224, test loss-2.2902, acc-0.1255\n",
      "Iter-1260, train loss-2.2940, acc-0.1600, valid loss-2.2873, acc-0.1226, test loss-2.2901, acc-0.1258\n",
      "Iter-1270, train loss-2.2801, acc-0.1600, valid loss-2.2872, acc-0.1228, test loss-2.2900, acc-0.1258\n",
      "Iter-1280, train loss-2.2688, acc-0.1600, valid loss-2.2871, acc-0.1234, test loss-2.2899, acc-0.1258\n",
      "Iter-1290, train loss-2.2660, acc-0.2200, valid loss-2.2871, acc-0.1234, test loss-2.2898, acc-0.1259\n",
      "Iter-1300, train loss-2.2674, acc-0.2000, valid loss-2.2870, acc-0.1234, test loss-2.2897, acc-0.1260\n",
      "Iter-1310, train loss-2.2980, acc-0.0800, valid loss-2.2869, acc-0.1238, test loss-2.2896, acc-0.1266\n",
      "Iter-1320, train loss-2.2819, acc-0.2200, valid loss-2.2868, acc-0.1238, test loss-2.2895, acc-0.1268\n",
      "Iter-1330, train loss-2.2857, acc-0.1400, valid loss-2.2867, acc-0.1240, test loss-2.2894, acc-0.1269\n",
      "Iter-1340, train loss-2.3018, acc-0.1000, valid loss-2.2866, acc-0.1240, test loss-2.2893, acc-0.1271\n",
      "Iter-1350, train loss-2.2902, acc-0.1800, valid loss-2.2866, acc-0.1240, test loss-2.2892, acc-0.1273\n",
      "Iter-1360, train loss-2.2882, acc-0.1800, valid loss-2.2865, acc-0.1240, test loss-2.2891, acc-0.1272\n",
      "Iter-1370, train loss-2.2968, acc-0.1600, valid loss-2.2864, acc-0.1240, test loss-2.2890, acc-0.1276\n",
      "Iter-1380, train loss-2.2830, acc-0.1400, valid loss-2.2863, acc-0.1244, test loss-2.2889, acc-0.1275\n",
      "Iter-1390, train loss-2.2839, acc-0.0800, valid loss-2.2862, acc-0.1244, test loss-2.2888, acc-0.1275\n",
      "Iter-1400, train loss-2.2918, acc-0.0800, valid loss-2.2861, acc-0.1250, test loss-2.2888, acc-0.1279\n",
      "Iter-1410, train loss-2.2838, acc-0.1600, valid loss-2.2861, acc-0.1250, test loss-2.2887, acc-0.1282\n",
      "Iter-1420, train loss-2.2783, acc-0.1600, valid loss-2.2860, acc-0.1256, test loss-2.2886, acc-0.1283\n",
      "Iter-1430, train loss-2.2890, acc-0.0400, valid loss-2.2859, acc-0.1256, test loss-2.2885, acc-0.1283\n",
      "Iter-1440, train loss-2.2816, acc-0.0800, valid loss-2.2858, acc-0.1260, test loss-2.2884, acc-0.1287\n",
      "Iter-1450, train loss-2.2941, acc-0.1800, valid loss-2.2857, acc-0.1264, test loss-2.2883, acc-0.1287\n",
      "Iter-1460, train loss-2.2793, acc-0.1000, valid loss-2.2856, acc-0.1268, test loss-2.2882, acc-0.1290\n",
      "Iter-1470, train loss-2.3085, acc-0.1400, valid loss-2.2855, acc-0.1264, test loss-2.2881, acc-0.1292\n",
      "Iter-1480, train loss-2.2822, acc-0.1200, valid loss-2.2854, acc-0.1264, test loss-2.2880, acc-0.1293\n",
      "Iter-1490, train loss-2.2828, acc-0.1400, valid loss-2.2854, acc-0.1266, test loss-2.2879, acc-0.1296\n",
      "Iter-1500, train loss-2.2893, acc-0.2200, valid loss-2.2853, acc-0.1266, test loss-2.2878, acc-0.1296\n",
      "Iter-1510, train loss-2.2949, acc-0.1000, valid loss-2.2852, acc-0.1264, test loss-2.2877, acc-0.1295\n",
      "Iter-1520, train loss-2.2781, acc-0.1400, valid loss-2.2851, acc-0.1266, test loss-2.2876, acc-0.1299\n",
      "Iter-1530, train loss-2.2927, acc-0.1000, valid loss-2.2850, acc-0.1272, test loss-2.2875, acc-0.1300\n",
      "Iter-1540, train loss-2.2868, acc-0.1200, valid loss-2.2849, acc-0.1274, test loss-2.2874, acc-0.1300\n",
      "Iter-1550, train loss-2.2933, acc-0.1200, valid loss-2.2848, acc-0.1270, test loss-2.2873, acc-0.1301\n",
      "Iter-1560, train loss-2.2956, acc-0.1000, valid loss-2.2848, acc-0.1270, test loss-2.2872, acc-0.1303\n",
      "Iter-1570, train loss-2.2909, acc-0.1600, valid loss-2.2847, acc-0.1270, test loss-2.2871, acc-0.1303\n",
      "Iter-1580, train loss-2.2896, acc-0.1000, valid loss-2.2846, acc-0.1272, test loss-2.2871, acc-0.1303\n",
      "Iter-1590, train loss-2.3066, acc-0.0600, valid loss-2.2845, acc-0.1276, test loss-2.2870, acc-0.1304\n",
      "Iter-1600, train loss-2.2835, acc-0.2000, valid loss-2.2844, acc-0.1278, test loss-2.2869, acc-0.1304\n",
      "Iter-1610, train loss-2.3022, acc-0.0800, valid loss-2.2843, acc-0.1276, test loss-2.2868, acc-0.1305\n",
      "Iter-1620, train loss-2.2903, acc-0.0800, valid loss-2.2843, acc-0.1278, test loss-2.2867, acc-0.1305\n",
      "Iter-1630, train loss-2.2687, acc-0.2000, valid loss-2.2842, acc-0.1278, test loss-2.2866, acc-0.1303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1640, train loss-2.3068, acc-0.1400, valid loss-2.2841, acc-0.1280, test loss-2.2865, acc-0.1303\n",
      "Iter-1650, train loss-2.2668, acc-0.2200, valid loss-2.2840, acc-0.1278, test loss-2.2864, acc-0.1307\n",
      "Iter-1660, train loss-2.2876, acc-0.1400, valid loss-2.2839, acc-0.1280, test loss-2.2863, acc-0.1310\n",
      "Iter-1670, train loss-2.3023, acc-0.1800, valid loss-2.2838, acc-0.1282, test loss-2.2862, acc-0.1310\n",
      "Iter-1680, train loss-2.2896, acc-0.1400, valid loss-2.2837, acc-0.1280, test loss-2.2861, acc-0.1311\n",
      "Iter-1690, train loss-2.2816, acc-0.1200, valid loss-2.2837, acc-0.1288, test loss-2.2860, acc-0.1310\n",
      "Iter-1700, train loss-2.2822, acc-0.1800, valid loss-2.2836, acc-0.1288, test loss-2.2859, acc-0.1310\n",
      "Iter-1710, train loss-2.2700, acc-0.1400, valid loss-2.2835, acc-0.1288, test loss-2.2858, acc-0.1310\n",
      "Iter-1720, train loss-2.2979, acc-0.1000, valid loss-2.2834, acc-0.1288, test loss-2.2857, acc-0.1311\n",
      "Iter-1730, train loss-2.2682, acc-0.1800, valid loss-2.2833, acc-0.1292, test loss-2.2856, acc-0.1313\n",
      "Iter-1740, train loss-2.2944, acc-0.1600, valid loss-2.2832, acc-0.1292, test loss-2.2855, acc-0.1315\n",
      "Iter-1750, train loss-2.2970, acc-0.0600, valid loss-2.2831, acc-0.1292, test loss-2.2855, acc-0.1317\n",
      "Iter-1760, train loss-2.2874, acc-0.1800, valid loss-2.2831, acc-0.1294, test loss-2.2854, acc-0.1319\n",
      "Iter-1770, train loss-2.2829, acc-0.1800, valid loss-2.2830, acc-0.1292, test loss-2.2853, acc-0.1319\n",
      "Iter-1780, train loss-2.2815, acc-0.1800, valid loss-2.2829, acc-0.1290, test loss-2.2852, acc-0.1319\n",
      "Iter-1790, train loss-2.2736, acc-0.1200, valid loss-2.2828, acc-0.1292, test loss-2.2851, acc-0.1318\n",
      "Iter-1800, train loss-2.2875, acc-0.0800, valid loss-2.2827, acc-0.1290, test loss-2.2850, acc-0.1319\n",
      "Iter-1810, train loss-2.2847, acc-0.1000, valid loss-2.2826, acc-0.1296, test loss-2.2849, acc-0.1321\n",
      "Iter-1820, train loss-2.2855, acc-0.1400, valid loss-2.2825, acc-0.1294, test loss-2.2848, acc-0.1324\n",
      "Iter-1830, train loss-2.2691, acc-0.2200, valid loss-2.2824, acc-0.1298, test loss-2.2847, acc-0.1326\n",
      "Iter-1840, train loss-2.2960, acc-0.1000, valid loss-2.2824, acc-0.1296, test loss-2.2846, acc-0.1330\n",
      "Iter-1850, train loss-2.2894, acc-0.0800, valid loss-2.2823, acc-0.1302, test loss-2.2845, acc-0.1331\n",
      "Iter-1860, train loss-2.2792, acc-0.1000, valid loss-2.2822, acc-0.1300, test loss-2.2844, acc-0.1330\n",
      "Iter-1870, train loss-2.2921, acc-0.0600, valid loss-2.2821, acc-0.1298, test loss-2.2843, acc-0.1332\n",
      "Iter-1880, train loss-2.2827, acc-0.1000, valid loss-2.2820, acc-0.1300, test loss-2.2842, acc-0.1331\n",
      "Iter-1890, train loss-2.2746, acc-0.1800, valid loss-2.2819, acc-0.1302, test loss-2.2841, acc-0.1331\n",
      "Iter-1900, train loss-2.2690, acc-0.2000, valid loss-2.2819, acc-0.1308, test loss-2.2840, acc-0.1333\n",
      "Iter-1910, train loss-2.3128, acc-0.0600, valid loss-2.2818, acc-0.1310, test loss-2.2839, acc-0.1338\n",
      "Iter-1920, train loss-2.2790, acc-0.2200, valid loss-2.2817, acc-0.1318, test loss-2.2839, acc-0.1340\n",
      "Iter-1930, train loss-2.2770, acc-0.1600, valid loss-2.2816, acc-0.1314, test loss-2.2838, acc-0.1343\n",
      "Iter-1940, train loss-2.2781, acc-0.1400, valid loss-2.2815, acc-0.1320, test loss-2.2837, acc-0.1342\n",
      "Iter-1950, train loss-2.3237, acc-0.0800, valid loss-2.2814, acc-0.1320, test loss-2.2836, acc-0.1345\n",
      "Iter-1960, train loss-2.2486, acc-0.2400, valid loss-2.2813, acc-0.1324, test loss-2.2835, acc-0.1346\n",
      "Iter-1970, train loss-2.2928, acc-0.0800, valid loss-2.2812, acc-0.1326, test loss-2.2834, acc-0.1350\n",
      "Iter-1980, train loss-2.2534, acc-0.2800, valid loss-2.2812, acc-0.1330, test loss-2.2833, acc-0.1350\n",
      "Iter-1990, train loss-2.2677, acc-0.1600, valid loss-2.2811, acc-0.1332, test loss-2.2832, acc-0.1351\n",
      "Iter-2000, train loss-2.2598, acc-0.1800, valid loss-2.2810, acc-0.1336, test loss-2.2831, acc-0.1355\n",
      "Iter-2010, train loss-2.2937, acc-0.0600, valid loss-2.2809, acc-0.1336, test loss-2.2830, acc-0.1358\n",
      "Iter-2020, train loss-2.2565, acc-0.2400, valid loss-2.2808, acc-0.1340, test loss-2.2829, acc-0.1358\n",
      "Iter-2030, train loss-2.2613, acc-0.0800, valid loss-2.2807, acc-0.1344, test loss-2.2828, acc-0.1361\n",
      "Iter-2040, train loss-2.2860, acc-0.0800, valid loss-2.2806, acc-0.1346, test loss-2.2827, acc-0.1361\n",
      "Iter-2050, train loss-2.2981, acc-0.1200, valid loss-2.2806, acc-0.1352, test loss-2.2826, acc-0.1363\n",
      "Iter-2060, train loss-2.2687, acc-0.1800, valid loss-2.2805, acc-0.1354, test loss-2.2825, acc-0.1362\n",
      "Iter-2070, train loss-2.2891, acc-0.1800, valid loss-2.2804, acc-0.1358, test loss-2.2824, acc-0.1363\n",
      "Iter-2080, train loss-2.2736, acc-0.1600, valid loss-2.2803, acc-0.1356, test loss-2.2823, acc-0.1367\n",
      "Iter-2090, train loss-2.2878, acc-0.1200, valid loss-2.2802, acc-0.1358, test loss-2.2823, acc-0.1368\n",
      "Iter-2100, train loss-2.2930, acc-0.0800, valid loss-2.2802, acc-0.1362, test loss-2.2822, acc-0.1370\n",
      "Iter-2110, train loss-2.3126, acc-0.0800, valid loss-2.2801, acc-0.1364, test loss-2.2821, acc-0.1371\n",
      "Iter-2120, train loss-2.3002, acc-0.1000, valid loss-2.2800, acc-0.1368, test loss-2.2820, acc-0.1371\n",
      "Iter-2130, train loss-2.2843, acc-0.1000, valid loss-2.2799, acc-0.1364, test loss-2.2819, acc-0.1373\n",
      "Iter-2140, train loss-2.2884, acc-0.1000, valid loss-2.2798, acc-0.1366, test loss-2.2818, acc-0.1373\n",
      "Iter-2150, train loss-2.2912, acc-0.1400, valid loss-2.2797, acc-0.1368, test loss-2.2817, acc-0.1376\n",
      "Iter-2160, train loss-2.3155, acc-0.1000, valid loss-2.2796, acc-0.1370, test loss-2.2816, acc-0.1377\n",
      "Iter-2170, train loss-2.2836, acc-0.1600, valid loss-2.2796, acc-0.1374, test loss-2.2815, acc-0.1383\n",
      "Iter-2180, train loss-2.2808, acc-0.1200, valid loss-2.2795, acc-0.1376, test loss-2.2814, acc-0.1382\n",
      "Iter-2190, train loss-2.2777, acc-0.1200, valid loss-2.2794, acc-0.1386, test loss-2.2813, acc-0.1383\n",
      "Iter-2200, train loss-2.2869, acc-0.1000, valid loss-2.2793, acc-0.1382, test loss-2.2812, acc-0.1385\n",
      "Iter-2210, train loss-2.2664, acc-0.1400, valid loss-2.2792, acc-0.1382, test loss-2.2812, acc-0.1381\n",
      "Iter-2220, train loss-2.2789, acc-0.0600, valid loss-2.2791, acc-0.1382, test loss-2.2811, acc-0.1383\n",
      "Iter-2230, train loss-2.2963, acc-0.1400, valid loss-2.2791, acc-0.1384, test loss-2.2810, acc-0.1383\n",
      "Iter-2240, train loss-2.2924, acc-0.0800, valid loss-2.2790, acc-0.1386, test loss-2.2809, acc-0.1385\n",
      "Iter-2250, train loss-2.2975, acc-0.1600, valid loss-2.2789, acc-0.1388, test loss-2.2808, acc-0.1387\n",
      "Iter-2260, train loss-2.2828, acc-0.0800, valid loss-2.2788, acc-0.1390, test loss-2.2807, acc-0.1385\n",
      "Iter-2270, train loss-2.2968, acc-0.1200, valid loss-2.2787, acc-0.1390, test loss-2.2806, acc-0.1388\n",
      "Iter-2280, train loss-2.2909, acc-0.1400, valid loss-2.2786, acc-0.1390, test loss-2.2805, acc-0.1389\n",
      "Iter-2290, train loss-2.2639, acc-0.1800, valid loss-2.2786, acc-0.1392, test loss-2.2804, acc-0.1388\n",
      "Iter-2300, train loss-2.2649, acc-0.2400, valid loss-2.2785, acc-0.1390, test loss-2.2803, acc-0.1391\n",
      "Iter-2310, train loss-2.2850, acc-0.1200, valid loss-2.2784, acc-0.1390, test loss-2.2802, acc-0.1393\n",
      "Iter-2320, train loss-2.2680, acc-0.1600, valid loss-2.2783, acc-0.1392, test loss-2.2801, acc-0.1394\n",
      "Iter-2330, train loss-2.2798, acc-0.1600, valid loss-2.2782, acc-0.1390, test loss-2.2800, acc-0.1394\n",
      "Iter-2340, train loss-2.2646, acc-0.1400, valid loss-2.2781, acc-0.1394, test loss-2.2799, acc-0.1397\n",
      "Iter-2350, train loss-2.2773, acc-0.1000, valid loss-2.2780, acc-0.1392, test loss-2.2799, acc-0.1398\n",
      "Iter-2360, train loss-2.2626, acc-0.1200, valid loss-2.2780, acc-0.1394, test loss-2.2798, acc-0.1399\n",
      "Iter-2370, train loss-2.2773, acc-0.1800, valid loss-2.2779, acc-0.1392, test loss-2.2797, acc-0.1401\n",
      "Iter-2380, train loss-2.2789, acc-0.1400, valid loss-2.2778, acc-0.1398, test loss-2.2796, acc-0.1402\n",
      "Iter-2390, train loss-2.2993, acc-0.1400, valid loss-2.2777, acc-0.1402, test loss-2.2795, acc-0.1406\n",
      "Iter-2400, train loss-2.2667, acc-0.1800, valid loss-2.2776, acc-0.1402, test loss-2.2794, acc-0.1408\n",
      "Iter-2410, train loss-2.2932, acc-0.1800, valid loss-2.2775, acc-0.1406, test loss-2.2793, acc-0.1413\n",
      "Iter-2420, train loss-2.2815, acc-0.1200, valid loss-2.2775, acc-0.1404, test loss-2.2792, acc-0.1412\n",
      "Iter-2430, train loss-2.3049, acc-0.0400, valid loss-2.2774, acc-0.1408, test loss-2.2791, acc-0.1416\n",
      "Iter-2440, train loss-2.2482, acc-0.1800, valid loss-2.2773, acc-0.1408, test loss-2.2790, acc-0.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2450, train loss-2.2910, acc-0.1200, valid loss-2.2772, acc-0.1410, test loss-2.2789, acc-0.1420\n",
      "Iter-2460, train loss-2.2829, acc-0.0800, valid loss-2.2771, acc-0.1412, test loss-2.2788, acc-0.1421\n",
      "Iter-2470, train loss-2.2730, acc-0.1600, valid loss-2.2770, acc-0.1412, test loss-2.2787, acc-0.1418\n",
      "Iter-2480, train loss-2.2745, acc-0.1000, valid loss-2.2769, acc-0.1414, test loss-2.2786, acc-0.1426\n",
      "Iter-2490, train loss-2.2887, acc-0.0800, valid loss-2.2768, acc-0.1416, test loss-2.2785, acc-0.1427\n",
      "Iter-2500, train loss-2.2551, acc-0.1000, valid loss-2.2768, acc-0.1416, test loss-2.2784, acc-0.1428\n",
      "Iter-2510, train loss-2.3081, acc-0.0800, valid loss-2.2767, acc-0.1418, test loss-2.2784, acc-0.1428\n",
      "Iter-2520, train loss-2.2792, acc-0.0400, valid loss-2.2766, acc-0.1418, test loss-2.2783, acc-0.1430\n",
      "Iter-2530, train loss-2.2728, acc-0.1200, valid loss-2.2765, acc-0.1420, test loss-2.2782, acc-0.1431\n",
      "Iter-2540, train loss-2.2653, acc-0.2400, valid loss-2.2764, acc-0.1420, test loss-2.2781, acc-0.1436\n",
      "Iter-2550, train loss-2.3074, acc-0.1400, valid loss-2.2764, acc-0.1420, test loss-2.2780, acc-0.1440\n",
      "Iter-2560, train loss-2.2584, acc-0.2200, valid loss-2.2763, acc-0.1424, test loss-2.2779, acc-0.1440\n",
      "Iter-2570, train loss-2.2939, acc-0.0800, valid loss-2.2762, acc-0.1424, test loss-2.2778, acc-0.1441\n",
      "Iter-2580, train loss-2.2827, acc-0.1600, valid loss-2.2761, acc-0.1428, test loss-2.2777, acc-0.1443\n",
      "Iter-2590, train loss-2.2762, acc-0.0800, valid loss-2.2760, acc-0.1426, test loss-2.2776, acc-0.1447\n",
      "Iter-2600, train loss-2.2881, acc-0.1000, valid loss-2.2759, acc-0.1436, test loss-2.2775, acc-0.1448\n",
      "Iter-2610, train loss-2.2645, acc-0.1600, valid loss-2.2759, acc-0.1436, test loss-2.2775, acc-0.1450\n",
      "Iter-2620, train loss-2.2595, acc-0.1200, valid loss-2.2758, acc-0.1440, test loss-2.2774, acc-0.1454\n",
      "Iter-2630, train loss-2.2810, acc-0.1800, valid loss-2.2757, acc-0.1440, test loss-2.2773, acc-0.1455\n",
      "Iter-2640, train loss-2.2600, acc-0.1000, valid loss-2.2756, acc-0.1444, test loss-2.2772, acc-0.1458\n",
      "Iter-2650, train loss-2.2709, acc-0.1600, valid loss-2.2755, acc-0.1442, test loss-2.2771, acc-0.1460\n",
      "Iter-2660, train loss-2.2795, acc-0.2000, valid loss-2.2754, acc-0.1444, test loss-2.2770, acc-0.1460\n",
      "Iter-2670, train loss-2.2798, acc-0.0800, valid loss-2.2754, acc-0.1446, test loss-2.2769, acc-0.1461\n",
      "Iter-2680, train loss-2.2716, acc-0.2000, valid loss-2.2753, acc-0.1448, test loss-2.2768, acc-0.1464\n",
      "Iter-2690, train loss-2.2790, acc-0.1800, valid loss-2.2752, acc-0.1448, test loss-2.2767, acc-0.1463\n",
      "Iter-2700, train loss-2.2699, acc-0.1800, valid loss-2.2751, acc-0.1448, test loss-2.2766, acc-0.1465\n",
      "Iter-2710, train loss-2.2922, acc-0.1200, valid loss-2.2750, acc-0.1446, test loss-2.2765, acc-0.1463\n",
      "Iter-2720, train loss-2.2736, acc-0.1400, valid loss-2.2749, acc-0.1450, test loss-2.2764, acc-0.1464\n",
      "Iter-2730, train loss-2.2537, acc-0.3400, valid loss-2.2749, acc-0.1450, test loss-2.2763, acc-0.1467\n",
      "Iter-2740, train loss-2.2802, acc-0.1200, valid loss-2.2748, acc-0.1450, test loss-2.2763, acc-0.1465\n",
      "Iter-2750, train loss-2.2884, acc-0.1000, valid loss-2.2747, acc-0.1452, test loss-2.2762, acc-0.1466\n",
      "Iter-2760, train loss-2.2807, acc-0.1800, valid loss-2.2746, acc-0.1462, test loss-2.2761, acc-0.1468\n",
      "Iter-2770, train loss-2.2826, acc-0.1200, valid loss-2.2745, acc-0.1464, test loss-2.2760, acc-0.1473\n",
      "Iter-2780, train loss-2.2868, acc-0.1000, valid loss-2.2744, acc-0.1470, test loss-2.2759, acc-0.1476\n",
      "Iter-2790, train loss-2.2745, acc-0.2000, valid loss-2.2744, acc-0.1476, test loss-2.2758, acc-0.1478\n",
      "Iter-2800, train loss-2.2536, acc-0.1600, valid loss-2.2743, acc-0.1476, test loss-2.2757, acc-0.1479\n",
      "Iter-2810, train loss-2.2824, acc-0.1200, valid loss-2.2742, acc-0.1478, test loss-2.2756, acc-0.1479\n",
      "Iter-2820, train loss-2.2927, acc-0.1600, valid loss-2.2741, acc-0.1476, test loss-2.2755, acc-0.1482\n",
      "Iter-2830, train loss-2.2629, acc-0.1400, valid loss-2.2740, acc-0.1472, test loss-2.2754, acc-0.1484\n",
      "Iter-2840, train loss-2.2621, acc-0.2200, valid loss-2.2739, acc-0.1480, test loss-2.2753, acc-0.1484\n",
      "Iter-2850, train loss-2.2736, acc-0.1600, valid loss-2.2738, acc-0.1476, test loss-2.2752, acc-0.1488\n",
      "Iter-2860, train loss-2.2735, acc-0.1800, valid loss-2.2738, acc-0.1478, test loss-2.2751, acc-0.1487\n",
      "Iter-2870, train loss-2.2874, acc-0.1000, valid loss-2.2737, acc-0.1476, test loss-2.2751, acc-0.1492\n",
      "Iter-2880, train loss-2.2792, acc-0.1200, valid loss-2.2736, acc-0.1478, test loss-2.2750, acc-0.1492\n",
      "Iter-2890, train loss-2.2841, acc-0.1600, valid loss-2.2735, acc-0.1480, test loss-2.2749, acc-0.1494\n",
      "Iter-2900, train loss-2.2866, acc-0.1200, valid loss-2.2734, acc-0.1480, test loss-2.2748, acc-0.1498\n",
      "Iter-2910, train loss-2.2792, acc-0.1200, valid loss-2.2733, acc-0.1482, test loss-2.2747, acc-0.1499\n",
      "Iter-2920, train loss-2.3127, acc-0.1200, valid loss-2.2732, acc-0.1482, test loss-2.2746, acc-0.1500\n",
      "Iter-2930, train loss-2.2499, acc-0.2400, valid loss-2.2732, acc-0.1480, test loss-2.2745, acc-0.1500\n",
      "Iter-2940, train loss-2.2733, acc-0.1400, valid loss-2.2731, acc-0.1480, test loss-2.2744, acc-0.1504\n",
      "Iter-2950, train loss-2.2716, acc-0.1800, valid loss-2.2730, acc-0.1482, test loss-2.2743, acc-0.1505\n",
      "Iter-2960, train loss-2.2728, acc-0.1600, valid loss-2.2729, acc-0.1492, test loss-2.2742, acc-0.1505\n",
      "Iter-2970, train loss-2.2662, acc-0.1400, valid loss-2.2728, acc-0.1494, test loss-2.2741, acc-0.1508\n",
      "Iter-2980, train loss-2.2586, acc-0.1800, valid loss-2.2727, acc-0.1494, test loss-2.2740, acc-0.1510\n",
      "Iter-2990, train loss-2.2686, acc-0.1000, valid loss-2.2726, acc-0.1494, test loss-2.2740, acc-0.1509\n",
      "Iter-3000, train loss-2.2655, acc-0.1200, valid loss-2.2726, acc-0.1498, test loss-2.2739, acc-0.1510\n",
      "Iter-3010, train loss-2.2521, acc-0.2200, valid loss-2.2725, acc-0.1498, test loss-2.2738, acc-0.1513\n",
      "Iter-3020, train loss-2.2752, acc-0.1800, valid loss-2.2724, acc-0.1496, test loss-2.2737, acc-0.1515\n",
      "Iter-3030, train loss-2.2629, acc-0.2000, valid loss-2.2723, acc-0.1496, test loss-2.2736, acc-0.1518\n",
      "Iter-3040, train loss-2.3076, acc-0.1200, valid loss-2.2722, acc-0.1498, test loss-2.2735, acc-0.1520\n",
      "Iter-3050, train loss-2.2796, acc-0.1800, valid loss-2.2722, acc-0.1500, test loss-2.2734, acc-0.1522\n",
      "Iter-3060, train loss-2.2762, acc-0.1600, valid loss-2.2721, acc-0.1500, test loss-2.2733, acc-0.1523\n",
      "Iter-3070, train loss-2.2885, acc-0.1400, valid loss-2.2720, acc-0.1500, test loss-2.2732, acc-0.1525\n",
      "Iter-3080, train loss-2.2690, acc-0.1800, valid loss-2.2719, acc-0.1500, test loss-2.2731, acc-0.1524\n",
      "Iter-3090, train loss-2.2798, acc-0.1800, valid loss-2.2718, acc-0.1502, test loss-2.2731, acc-0.1531\n",
      "Iter-3100, train loss-2.2685, acc-0.1600, valid loss-2.2718, acc-0.1502, test loss-2.2730, acc-0.1530\n",
      "Iter-3110, train loss-2.2648, acc-0.1400, valid loss-2.2717, acc-0.1504, test loss-2.2729, acc-0.1531\n",
      "Iter-3120, train loss-2.2738, acc-0.1400, valid loss-2.2716, acc-0.1508, test loss-2.2728, acc-0.1532\n",
      "Iter-3130, train loss-2.2563, acc-0.2600, valid loss-2.2715, acc-0.1514, test loss-2.2727, acc-0.1533\n",
      "Iter-3140, train loss-2.2776, acc-0.1200, valid loss-2.2714, acc-0.1514, test loss-2.2726, acc-0.1536\n",
      "Iter-3150, train loss-2.2710, acc-0.1600, valid loss-2.2713, acc-0.1518, test loss-2.2725, acc-0.1538\n",
      "Iter-3160, train loss-2.2552, acc-0.1800, valid loss-2.2713, acc-0.1512, test loss-2.2724, acc-0.1539\n",
      "Iter-3170, train loss-2.2890, acc-0.1400, valid loss-2.2712, acc-0.1512, test loss-2.2723, acc-0.1544\n",
      "Iter-3180, train loss-2.2617, acc-0.1400, valid loss-2.2711, acc-0.1514, test loss-2.2722, acc-0.1544\n",
      "Iter-3190, train loss-2.2740, acc-0.2200, valid loss-2.2710, acc-0.1516, test loss-2.2721, acc-0.1544\n",
      "Iter-3200, train loss-2.2675, acc-0.1200, valid loss-2.2709, acc-0.1514, test loss-2.2720, acc-0.1545\n",
      "Iter-3210, train loss-2.2518, acc-0.2400, valid loss-2.2708, acc-0.1516, test loss-2.2720, acc-0.1546\n",
      "Iter-3220, train loss-2.2755, acc-0.1800, valid loss-2.2708, acc-0.1520, test loss-2.2719, acc-0.1546\n",
      "Iter-3230, train loss-2.2606, acc-0.1800, valid loss-2.2707, acc-0.1524, test loss-2.2718, acc-0.1549\n",
      "Iter-3240, train loss-2.2729, acc-0.1800, valid loss-2.2706, acc-0.1530, test loss-2.2717, acc-0.1551\n",
      "Iter-3250, train loss-2.2790, acc-0.1600, valid loss-2.2705, acc-0.1528, test loss-2.2716, acc-0.1549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3260, train loss-2.2734, acc-0.1800, valid loss-2.2704, acc-0.1526, test loss-2.2715, acc-0.1553\n",
      "Iter-3270, train loss-2.2961, acc-0.1600, valid loss-2.2703, acc-0.1534, test loss-2.2714, acc-0.1554\n",
      "Iter-3280, train loss-2.2751, acc-0.1400, valid loss-2.2703, acc-0.1530, test loss-2.2713, acc-0.1556\n",
      "Iter-3290, train loss-2.2842, acc-0.1800, valid loss-2.2702, acc-0.1536, test loss-2.2712, acc-0.1561\n",
      "Iter-3300, train loss-2.2849, acc-0.2000, valid loss-2.2701, acc-0.1538, test loss-2.2712, acc-0.1564\n",
      "Iter-3310, train loss-2.2844, acc-0.2000, valid loss-2.2700, acc-0.1542, test loss-2.2711, acc-0.1565\n",
      "Iter-3320, train loss-2.2678, acc-0.1600, valid loss-2.2699, acc-0.1550, test loss-2.2710, acc-0.1568\n",
      "Iter-3330, train loss-2.2691, acc-0.2200, valid loss-2.2698, acc-0.1550, test loss-2.2709, acc-0.1569\n",
      "Iter-3340, train loss-2.2508, acc-0.1400, valid loss-2.2698, acc-0.1554, test loss-2.2708, acc-0.1570\n",
      "Iter-3350, train loss-2.2827, acc-0.1800, valid loss-2.2697, acc-0.1554, test loss-2.2707, acc-0.1571\n",
      "Iter-3360, train loss-2.2795, acc-0.1400, valid loss-2.2696, acc-0.1556, test loss-2.2706, acc-0.1575\n",
      "Iter-3370, train loss-2.2539, acc-0.1400, valid loss-2.2695, acc-0.1556, test loss-2.2705, acc-0.1576\n",
      "Iter-3380, train loss-2.2990, acc-0.1400, valid loss-2.2694, acc-0.1558, test loss-2.2704, acc-0.1578\n",
      "Iter-3390, train loss-2.2748, acc-0.0800, valid loss-2.2693, acc-0.1556, test loss-2.2703, acc-0.1580\n",
      "Iter-3400, train loss-2.2597, acc-0.2400, valid loss-2.2692, acc-0.1560, test loss-2.2702, acc-0.1579\n",
      "Iter-3410, train loss-2.2614, acc-0.1800, valid loss-2.2692, acc-0.1562, test loss-2.2701, acc-0.1580\n",
      "Iter-3420, train loss-2.2752, acc-0.2200, valid loss-2.2691, acc-0.1564, test loss-2.2700, acc-0.1584\n",
      "Iter-3430, train loss-2.2800, acc-0.1400, valid loss-2.2690, acc-0.1562, test loss-2.2699, acc-0.1585\n",
      "Iter-3440, train loss-2.2721, acc-0.1400, valid loss-2.2689, acc-0.1562, test loss-2.2699, acc-0.1589\n",
      "Iter-3450, train loss-2.2728, acc-0.1400, valid loss-2.2688, acc-0.1564, test loss-2.2698, acc-0.1590\n",
      "Iter-3460, train loss-2.2615, acc-0.1000, valid loss-2.2688, acc-0.1566, test loss-2.2697, acc-0.1593\n",
      "Iter-3470, train loss-2.2554, acc-0.1600, valid loss-2.2687, acc-0.1568, test loss-2.2696, acc-0.1598\n",
      "Iter-3480, train loss-2.2612, acc-0.1400, valid loss-2.2686, acc-0.1572, test loss-2.2695, acc-0.1601\n",
      "Iter-3490, train loss-2.2460, acc-0.2400, valid loss-2.2685, acc-0.1572, test loss-2.2694, acc-0.1606\n",
      "Iter-3500, train loss-2.2744, acc-0.1800, valid loss-2.2684, acc-0.1576, test loss-2.2693, acc-0.1609\n",
      "Iter-3510, train loss-2.2784, acc-0.0600, valid loss-2.2683, acc-0.1580, test loss-2.2692, acc-0.1613\n",
      "Iter-3520, train loss-2.2770, acc-0.2000, valid loss-2.2683, acc-0.1582, test loss-2.2691, acc-0.1611\n",
      "Iter-3530, train loss-2.2580, acc-0.2000, valid loss-2.2682, acc-0.1586, test loss-2.2691, acc-0.1612\n",
      "Iter-3540, train loss-2.2487, acc-0.2000, valid loss-2.2681, acc-0.1590, test loss-2.2690, acc-0.1617\n",
      "Iter-3550, train loss-2.2662, acc-0.1400, valid loss-2.2680, acc-0.1586, test loss-2.2689, acc-0.1621\n",
      "Iter-3560, train loss-2.2820, acc-0.1600, valid loss-2.2679, acc-0.1590, test loss-2.2688, acc-0.1624\n",
      "Iter-3570, train loss-2.2875, acc-0.1200, valid loss-2.2678, acc-0.1590, test loss-2.2687, acc-0.1626\n",
      "Iter-3580, train loss-2.2497, acc-0.2200, valid loss-2.2677, acc-0.1592, test loss-2.2686, acc-0.1624\n",
      "Iter-3590, train loss-2.2658, acc-0.1600, valid loss-2.2677, acc-0.1592, test loss-2.2685, acc-0.1628\n",
      "Iter-3600, train loss-2.2576, acc-0.1800, valid loss-2.2676, acc-0.1592, test loss-2.2684, acc-0.1627\n",
      "Iter-3610, train loss-2.2608, acc-0.2000, valid loss-2.2675, acc-0.1598, test loss-2.2683, acc-0.1628\n",
      "Iter-3620, train loss-2.2604, acc-0.1600, valid loss-2.2674, acc-0.1598, test loss-2.2682, acc-0.1629\n",
      "Iter-3630, train loss-2.2507, acc-0.2600, valid loss-2.2673, acc-0.1602, test loss-2.2681, acc-0.1631\n",
      "Iter-3640, train loss-2.2457, acc-0.1600, valid loss-2.2672, acc-0.1602, test loss-2.2680, acc-0.1632\n",
      "Iter-3650, train loss-2.2501, acc-0.1600, valid loss-2.2672, acc-0.1604, test loss-2.2679, acc-0.1635\n",
      "Iter-3660, train loss-2.2441, acc-0.2800, valid loss-2.2671, acc-0.1604, test loss-2.2679, acc-0.1636\n",
      "Iter-3670, train loss-2.2805, acc-0.1000, valid loss-2.2670, acc-0.1604, test loss-2.2678, acc-0.1640\n",
      "Iter-3680, train loss-2.2681, acc-0.1400, valid loss-2.2669, acc-0.1604, test loss-2.2677, acc-0.1644\n",
      "Iter-3690, train loss-2.2702, acc-0.2200, valid loss-2.2668, acc-0.1604, test loss-2.2676, acc-0.1642\n",
      "Iter-3700, train loss-2.2627, acc-0.1600, valid loss-2.2668, acc-0.1604, test loss-2.2675, acc-0.1641\n",
      "Iter-3710, train loss-2.2604, acc-0.2000, valid loss-2.2667, acc-0.1606, test loss-2.2674, acc-0.1646\n",
      "Iter-3720, train loss-2.2696, acc-0.2000, valid loss-2.2666, acc-0.1608, test loss-2.2673, acc-0.1648\n",
      "Iter-3730, train loss-2.2486, acc-0.1800, valid loss-2.2665, acc-0.1608, test loss-2.2672, acc-0.1649\n",
      "Iter-3740, train loss-2.2959, acc-0.1600, valid loss-2.2664, acc-0.1610, test loss-2.2671, acc-0.1651\n",
      "Iter-3750, train loss-2.2798, acc-0.1600, valid loss-2.2664, acc-0.1610, test loss-2.2671, acc-0.1653\n",
      "Iter-3760, train loss-2.2467, acc-0.2000, valid loss-2.2663, acc-0.1612, test loss-2.2670, acc-0.1657\n",
      "Iter-3770, train loss-2.2774, acc-0.2200, valid loss-2.2662, acc-0.1618, test loss-2.2669, acc-0.1661\n",
      "Iter-3780, train loss-2.2730, acc-0.1800, valid loss-2.2661, acc-0.1614, test loss-2.2668, acc-0.1659\n",
      "Iter-3790, train loss-2.2663, acc-0.1600, valid loss-2.2660, acc-0.1614, test loss-2.2667, acc-0.1660\n",
      "Iter-3800, train loss-2.2721, acc-0.1200, valid loss-2.2659, acc-0.1614, test loss-2.2666, acc-0.1662\n",
      "Iter-3810, train loss-2.2745, acc-0.1600, valid loss-2.2658, acc-0.1612, test loss-2.2665, acc-0.1666\n",
      "Iter-3820, train loss-2.2753, acc-0.2800, valid loss-2.2658, acc-0.1620, test loss-2.2664, acc-0.1669\n",
      "Iter-3830, train loss-2.2820, acc-0.1000, valid loss-2.2657, acc-0.1622, test loss-2.2663, acc-0.1670\n",
      "Iter-3840, train loss-2.2714, acc-0.2000, valid loss-2.2656, acc-0.1624, test loss-2.2662, acc-0.1668\n",
      "Iter-3850, train loss-2.2535, acc-0.2200, valid loss-2.2655, acc-0.1626, test loss-2.2661, acc-0.1671\n",
      "Iter-3860, train loss-2.2465, acc-0.2200, valid loss-2.2654, acc-0.1630, test loss-2.2660, acc-0.1673\n",
      "Iter-3870, train loss-2.2817, acc-0.1000, valid loss-2.2654, acc-0.1634, test loss-2.2660, acc-0.1675\n",
      "Iter-3880, train loss-2.2712, acc-0.1600, valid loss-2.2653, acc-0.1634, test loss-2.2659, acc-0.1676\n",
      "Iter-3890, train loss-2.2762, acc-0.1000, valid loss-2.2652, acc-0.1636, test loss-2.2658, acc-0.1681\n",
      "Iter-3900, train loss-2.2781, acc-0.0600, valid loss-2.2651, acc-0.1634, test loss-2.2657, acc-0.1680\n",
      "Iter-3910, train loss-2.2768, acc-0.1600, valid loss-2.2650, acc-0.1636, test loss-2.2656, acc-0.1684\n",
      "Iter-3920, train loss-2.2642, acc-0.1800, valid loss-2.2650, acc-0.1638, test loss-2.2655, acc-0.1685\n",
      "Iter-3930, train loss-2.2834, acc-0.1400, valid loss-2.2649, acc-0.1638, test loss-2.2654, acc-0.1690\n",
      "Iter-3940, train loss-2.2622, acc-0.1800, valid loss-2.2648, acc-0.1642, test loss-2.2654, acc-0.1690\n",
      "Iter-3950, train loss-2.2896, acc-0.1000, valid loss-2.2647, acc-0.1646, test loss-2.2653, acc-0.1692\n",
      "Iter-3960, train loss-2.2617, acc-0.1800, valid loss-2.2646, acc-0.1650, test loss-2.2652, acc-0.1694\n",
      "Iter-3970, train loss-2.2598, acc-0.1800, valid loss-2.2646, acc-0.1652, test loss-2.2651, acc-0.1695\n",
      "Iter-3980, train loss-2.2685, acc-0.2000, valid loss-2.2645, acc-0.1654, test loss-2.2650, acc-0.1698\n",
      "Iter-3990, train loss-2.2755, acc-0.1000, valid loss-2.2644, acc-0.1654, test loss-2.2649, acc-0.1700\n",
      "Iter-4000, train loss-2.2854, acc-0.1200, valid loss-2.2643, acc-0.1650, test loss-2.2648, acc-0.1702\n",
      "Iter-4010, train loss-2.2739, acc-0.1800, valid loss-2.2642, acc-0.1652, test loss-2.2647, acc-0.1707\n",
      "Iter-4020, train loss-2.2548, acc-0.2000, valid loss-2.2642, acc-0.1658, test loss-2.2646, acc-0.1705\n",
      "Iter-4030, train loss-2.2563, acc-0.1400, valid loss-2.2641, acc-0.1658, test loss-2.2645, acc-0.1706\n",
      "Iter-4040, train loss-2.2584, acc-0.2600, valid loss-2.2640, acc-0.1660, test loss-2.2645, acc-0.1706\n",
      "Iter-4050, train loss-2.2808, acc-0.0400, valid loss-2.2639, acc-0.1664, test loss-2.2644, acc-0.1710\n",
      "Iter-4060, train loss-2.2364, acc-0.2000, valid loss-2.2638, acc-0.1666, test loss-2.2643, acc-0.1714\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4070, train loss-2.2571, acc-0.1600, valid loss-2.2638, acc-0.1666, test loss-2.2642, acc-0.1716\n",
      "Iter-4080, train loss-2.2261, acc-0.2400, valid loss-2.2637, acc-0.1670, test loss-2.2641, acc-0.1720\n",
      "Iter-4090, train loss-2.2761, acc-0.1600, valid loss-2.2636, acc-0.1670, test loss-2.2640, acc-0.1724\n",
      "Iter-4100, train loss-2.2813, acc-0.1200, valid loss-2.2635, acc-0.1672, test loss-2.2639, acc-0.1724\n",
      "Iter-4110, train loss-2.2771, acc-0.1400, valid loss-2.2634, acc-0.1672, test loss-2.2638, acc-0.1725\n",
      "Iter-4120, train loss-2.2687, acc-0.1400, valid loss-2.2634, acc-0.1672, test loss-2.2637, acc-0.1726\n",
      "Iter-4130, train loss-2.2737, acc-0.2400, valid loss-2.2633, acc-0.1674, test loss-2.2637, acc-0.1729\n",
      "Iter-4140, train loss-2.2656, acc-0.0800, valid loss-2.2632, acc-0.1684, test loss-2.2636, acc-0.1733\n",
      "Iter-4150, train loss-2.2729, acc-0.1600, valid loss-2.2631, acc-0.1686, test loss-2.2635, acc-0.1735\n",
      "Iter-4160, train loss-2.2547, acc-0.2000, valid loss-2.2630, acc-0.1686, test loss-2.2634, acc-0.1736\n",
      "Iter-4170, train loss-2.2882, acc-0.0600, valid loss-2.2629, acc-0.1686, test loss-2.2633, acc-0.1736\n",
      "Iter-4180, train loss-2.2648, acc-0.1800, valid loss-2.2629, acc-0.1686, test loss-2.2632, acc-0.1736\n",
      "Iter-4190, train loss-2.2845, acc-0.1200, valid loss-2.2628, acc-0.1688, test loss-2.2631, acc-0.1739\n",
      "Iter-4200, train loss-2.2524, acc-0.2400, valid loss-2.2627, acc-0.1692, test loss-2.2630, acc-0.1740\n",
      "Iter-4210, train loss-2.2838, acc-0.1200, valid loss-2.2626, acc-0.1698, test loss-2.2629, acc-0.1740\n",
      "Iter-4220, train loss-2.2415, acc-0.3000, valid loss-2.2625, acc-0.1696, test loss-2.2628, acc-0.1744\n",
      "Iter-4230, train loss-2.2410, acc-0.1600, valid loss-2.2624, acc-0.1694, test loss-2.2627, acc-0.1744\n",
      "Iter-4240, train loss-2.2625, acc-0.2000, valid loss-2.2623, acc-0.1698, test loss-2.2626, acc-0.1745\n",
      "Iter-4250, train loss-2.2400, acc-0.2600, valid loss-2.2623, acc-0.1700, test loss-2.2626, acc-0.1747\n",
      "Iter-4260, train loss-2.2770, acc-0.1400, valid loss-2.2622, acc-0.1698, test loss-2.2625, acc-0.1750\n",
      "Iter-4270, train loss-2.2696, acc-0.2000, valid loss-2.2621, acc-0.1700, test loss-2.2624, acc-0.1751\n",
      "Iter-4280, train loss-2.2534, acc-0.2200, valid loss-2.2620, acc-0.1702, test loss-2.2623, acc-0.1752\n",
      "Iter-4290, train loss-2.2740, acc-0.1800, valid loss-2.2619, acc-0.1704, test loss-2.2622, acc-0.1756\n",
      "Iter-4300, train loss-2.2902, acc-0.1600, valid loss-2.2619, acc-0.1706, test loss-2.2621, acc-0.1754\n",
      "Iter-4310, train loss-2.2782, acc-0.2000, valid loss-2.2618, acc-0.1708, test loss-2.2620, acc-0.1756\n",
      "Iter-4320, train loss-2.2545, acc-0.1400, valid loss-2.2617, acc-0.1706, test loss-2.2619, acc-0.1756\n",
      "Iter-4330, train loss-2.2803, acc-0.1600, valid loss-2.2616, acc-0.1704, test loss-2.2618, acc-0.1757\n",
      "Iter-4340, train loss-2.2440, acc-0.2000, valid loss-2.2615, acc-0.1706, test loss-2.2618, acc-0.1757\n",
      "Iter-4350, train loss-2.2356, acc-0.2200, valid loss-2.2614, acc-0.1708, test loss-2.2617, acc-0.1764\n",
      "Iter-4360, train loss-2.2600, acc-0.1600, valid loss-2.2614, acc-0.1710, test loss-2.2616, acc-0.1766\n",
      "Iter-4370, train loss-2.2507, acc-0.1200, valid loss-2.2613, acc-0.1710, test loss-2.2615, acc-0.1768\n",
      "Iter-4380, train loss-2.2404, acc-0.2800, valid loss-2.2612, acc-0.1708, test loss-2.2614, acc-0.1771\n",
      "Iter-4390, train loss-2.2650, acc-0.1200, valid loss-2.2611, acc-0.1708, test loss-2.2613, acc-0.1768\n",
      "Iter-4400, train loss-2.2584, acc-0.2600, valid loss-2.2610, acc-0.1716, test loss-2.2612, acc-0.1773\n",
      "Iter-4410, train loss-2.2948, acc-0.1400, valid loss-2.2609, acc-0.1718, test loss-2.2611, acc-0.1773\n",
      "Iter-4420, train loss-2.2571, acc-0.1800, valid loss-2.2609, acc-0.1724, test loss-2.2610, acc-0.1781\n",
      "Iter-4430, train loss-2.2654, acc-0.1400, valid loss-2.2608, acc-0.1728, test loss-2.2609, acc-0.1783\n",
      "Iter-4440, train loss-2.2636, acc-0.1400, valid loss-2.2607, acc-0.1728, test loss-2.2608, acc-0.1784\n",
      "Iter-4450, train loss-2.2649, acc-0.2400, valid loss-2.2606, acc-0.1730, test loss-2.2607, acc-0.1788\n",
      "Iter-4460, train loss-2.2527, acc-0.1800, valid loss-2.2605, acc-0.1732, test loss-2.2607, acc-0.1788\n",
      "Iter-4470, train loss-2.2680, acc-0.2000, valid loss-2.2604, acc-0.1732, test loss-2.2606, acc-0.1792\n",
      "Iter-4480, train loss-2.2659, acc-0.1400, valid loss-2.2604, acc-0.1734, test loss-2.2605, acc-0.1794\n",
      "Iter-4490, train loss-2.2464, acc-0.1800, valid loss-2.2603, acc-0.1734, test loss-2.2604, acc-0.1795\n",
      "Iter-4500, train loss-2.2590, acc-0.1400, valid loss-2.2602, acc-0.1734, test loss-2.2603, acc-0.1795\n",
      "Iter-4510, train loss-2.2710, acc-0.1400, valid loss-2.2601, acc-0.1736, test loss-2.2602, acc-0.1798\n",
      "Iter-4520, train loss-2.2454, acc-0.2200, valid loss-2.2600, acc-0.1742, test loss-2.2601, acc-0.1796\n",
      "Iter-4530, train loss-2.2570, acc-0.1800, valid loss-2.2599, acc-0.1742, test loss-2.2600, acc-0.1795\n",
      "Iter-4540, train loss-2.2363, acc-0.1600, valid loss-2.2599, acc-0.1740, test loss-2.2599, acc-0.1796\n",
      "Iter-4550, train loss-2.2556, acc-0.1400, valid loss-2.2598, acc-0.1742, test loss-2.2598, acc-0.1796\n",
      "Iter-4560, train loss-2.2640, acc-0.2200, valid loss-2.2597, acc-0.1748, test loss-2.2598, acc-0.1796\n",
      "Iter-4570, train loss-2.2630, acc-0.1600, valid loss-2.2596, acc-0.1750, test loss-2.2597, acc-0.1798\n",
      "Iter-4580, train loss-2.2785, acc-0.1800, valid loss-2.2595, acc-0.1752, test loss-2.2596, acc-0.1796\n",
      "Iter-4590, train loss-2.2661, acc-0.1400, valid loss-2.2595, acc-0.1748, test loss-2.2595, acc-0.1802\n",
      "Iter-4600, train loss-2.2524, acc-0.2000, valid loss-2.2594, acc-0.1754, test loss-2.2594, acc-0.1803\n",
      "Iter-4610, train loss-2.2454, acc-0.2200, valid loss-2.2593, acc-0.1754, test loss-2.2593, acc-0.1805\n",
      "Iter-4620, train loss-2.2784, acc-0.0800, valid loss-2.2592, acc-0.1756, test loss-2.2592, acc-0.1805\n",
      "Iter-4630, train loss-2.2705, acc-0.2600, valid loss-2.2592, acc-0.1760, test loss-2.2592, acc-0.1811\n",
      "Iter-4640, train loss-2.2376, acc-0.2400, valid loss-2.2591, acc-0.1762, test loss-2.2591, acc-0.1811\n",
      "Iter-4650, train loss-2.2657, acc-0.0800, valid loss-2.2590, acc-0.1758, test loss-2.2590, acc-0.1812\n",
      "Iter-4660, train loss-2.2611, acc-0.1600, valid loss-2.2589, acc-0.1762, test loss-2.2589, acc-0.1818\n",
      "Iter-4670, train loss-2.2502, acc-0.2400, valid loss-2.2588, acc-0.1760, test loss-2.2588, acc-0.1820\n",
      "Iter-4680, train loss-2.2488, acc-0.1800, valid loss-2.2588, acc-0.1764, test loss-2.2587, acc-0.1824\n",
      "Iter-4690, train loss-2.2599, acc-0.1400, valid loss-2.2587, acc-0.1766, test loss-2.2586, acc-0.1823\n",
      "Iter-4700, train loss-2.2743, acc-0.1200, valid loss-2.2586, acc-0.1770, test loss-2.2585, acc-0.1823\n",
      "Iter-4710, train loss-2.2398, acc-0.2800, valid loss-2.2585, acc-0.1778, test loss-2.2585, acc-0.1825\n",
      "Iter-4720, train loss-2.2655, acc-0.2000, valid loss-2.2584, acc-0.1780, test loss-2.2584, acc-0.1826\n",
      "Iter-4730, train loss-2.2614, acc-0.1400, valid loss-2.2583, acc-0.1774, test loss-2.2583, acc-0.1823\n",
      "Iter-4740, train loss-2.2408, acc-0.1800, valid loss-2.2583, acc-0.1776, test loss-2.2582, acc-0.1826\n",
      "Iter-4750, train loss-2.2530, acc-0.2000, valid loss-2.2582, acc-0.1780, test loss-2.2581, acc-0.1828\n",
      "Iter-4760, train loss-2.2607, acc-0.0800, valid loss-2.2581, acc-0.1782, test loss-2.2580, acc-0.1828\n",
      "Iter-4770, train loss-2.2533, acc-0.2000, valid loss-2.2580, acc-0.1782, test loss-2.2579, acc-0.1829\n",
      "Iter-4780, train loss-2.2382, acc-0.2600, valid loss-2.2580, acc-0.1782, test loss-2.2578, acc-0.1830\n",
      "Iter-4790, train loss-2.2416, acc-0.2200, valid loss-2.2579, acc-0.1786, test loss-2.2577, acc-0.1833\n",
      "Iter-4800, train loss-2.2776, acc-0.0600, valid loss-2.2578, acc-0.1784, test loss-2.2577, acc-0.1835\n",
      "Iter-4810, train loss-2.2631, acc-0.1600, valid loss-2.2577, acc-0.1788, test loss-2.2576, acc-0.1836\n",
      "Iter-4820, train loss-2.2739, acc-0.1400, valid loss-2.2576, acc-0.1792, test loss-2.2575, acc-0.1837\n",
      "Iter-4830, train loss-2.2493, acc-0.1600, valid loss-2.2576, acc-0.1792, test loss-2.2574, acc-0.1835\n",
      "Iter-4840, train loss-2.2458, acc-0.2000, valid loss-2.2575, acc-0.1790, test loss-2.2573, acc-0.1836\n",
      "Iter-4850, train loss-2.2458, acc-0.1800, valid loss-2.2574, acc-0.1796, test loss-2.2572, acc-0.1838\n",
      "Iter-4860, train loss-2.2647, acc-0.1600, valid loss-2.2573, acc-0.1794, test loss-2.2571, acc-0.1838\n",
      "Iter-4870, train loss-2.2619, acc-0.2400, valid loss-2.2573, acc-0.1798, test loss-2.2571, acc-0.1838\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4880, train loss-2.2546, acc-0.1400, valid loss-2.2572, acc-0.1798, test loss-2.2570, acc-0.1840\n",
      "Iter-4890, train loss-2.2743, acc-0.2000, valid loss-2.2571, acc-0.1796, test loss-2.2569, acc-0.1841\n",
      "Iter-4900, train loss-2.2827, acc-0.1400, valid loss-2.2570, acc-0.1798, test loss-2.2568, acc-0.1842\n",
      "Iter-4910, train loss-2.2397, acc-0.2600, valid loss-2.2569, acc-0.1804, test loss-2.2567, acc-0.1845\n",
      "Iter-4920, train loss-2.2469, acc-0.1400, valid loss-2.2569, acc-0.1806, test loss-2.2566, acc-0.1848\n",
      "Iter-4930, train loss-2.2427, acc-0.2400, valid loss-2.2568, acc-0.1806, test loss-2.2565, acc-0.1847\n",
      "Iter-4940, train loss-2.2388, acc-0.2800, valid loss-2.2567, acc-0.1816, test loss-2.2564, acc-0.1846\n",
      "Iter-4950, train loss-2.2661, acc-0.1200, valid loss-2.2566, acc-0.1824, test loss-2.2564, acc-0.1850\n",
      "Iter-4960, train loss-2.3016, acc-0.1200, valid loss-2.2565, acc-0.1826, test loss-2.2563, acc-0.1854\n",
      "Iter-4970, train loss-2.2588, acc-0.2200, valid loss-2.2564, acc-0.1824, test loss-2.2562, acc-0.1854\n",
      "Iter-4980, train loss-2.2785, acc-0.1600, valid loss-2.2564, acc-0.1828, test loss-2.2561, acc-0.1856\n",
      "Iter-4990, train loss-2.2451, acc-0.1600, valid loss-2.2563, acc-0.1826, test loss-2.2560, acc-0.1856\n",
      "Iter-5000, train loss-2.2676, acc-0.1200, valid loss-2.2562, acc-0.1826, test loss-2.2559, acc-0.1857\n",
      "Iter-5010, train loss-2.2774, acc-0.1400, valid loss-2.2561, acc-0.1828, test loss-2.2558, acc-0.1858\n",
      "Iter-5020, train loss-2.2515, acc-0.1600, valid loss-2.2560, acc-0.1832, test loss-2.2557, acc-0.1859\n",
      "Iter-5030, train loss-2.2527, acc-0.1800, valid loss-2.2560, acc-0.1834, test loss-2.2556, acc-0.1862\n",
      "Iter-5040, train loss-2.2564, acc-0.1400, valid loss-2.2559, acc-0.1832, test loss-2.2556, acc-0.1862\n",
      "Iter-5050, train loss-2.2595, acc-0.2000, valid loss-2.2558, acc-0.1834, test loss-2.2555, acc-0.1862\n",
      "Iter-5060, train loss-2.2532, acc-0.2800, valid loss-2.2557, acc-0.1838, test loss-2.2554, acc-0.1865\n",
      "Iter-5070, train loss-2.2455, acc-0.2200, valid loss-2.2556, acc-0.1842, test loss-2.2553, acc-0.1865\n",
      "Iter-5080, train loss-2.2319, acc-0.2400, valid loss-2.2556, acc-0.1842, test loss-2.2552, acc-0.1867\n",
      "Iter-5090, train loss-2.2606, acc-0.1600, valid loss-2.2555, acc-0.1844, test loss-2.2551, acc-0.1869\n",
      "Iter-5100, train loss-2.2701, acc-0.1400, valid loss-2.2554, acc-0.1844, test loss-2.2550, acc-0.1871\n",
      "Iter-5110, train loss-2.2584, acc-0.2600, valid loss-2.2553, acc-0.1848, test loss-2.2549, acc-0.1873\n",
      "Iter-5120, train loss-2.2631, acc-0.1200, valid loss-2.2553, acc-0.1848, test loss-2.2549, acc-0.1874\n",
      "Iter-5130, train loss-2.2402, acc-0.2800, valid loss-2.2552, acc-0.1850, test loss-2.2548, acc-0.1874\n",
      "Iter-5140, train loss-2.2442, acc-0.1000, valid loss-2.2551, acc-0.1854, test loss-2.2547, acc-0.1877\n",
      "Iter-5150, train loss-2.2900, acc-0.1400, valid loss-2.2550, acc-0.1854, test loss-2.2546, acc-0.1878\n",
      "Iter-5160, train loss-2.2498, acc-0.1600, valid loss-2.2549, acc-0.1860, test loss-2.2545, acc-0.1876\n",
      "Iter-5170, train loss-2.2359, acc-0.2200, valid loss-2.2549, acc-0.1864, test loss-2.2544, acc-0.1877\n",
      "Iter-5180, train loss-2.2369, acc-0.2000, valid loss-2.2548, acc-0.1866, test loss-2.2543, acc-0.1874\n",
      "Iter-5190, train loss-2.2396, acc-0.2400, valid loss-2.2547, acc-0.1870, test loss-2.2542, acc-0.1881\n",
      "Iter-5200, train loss-2.2738, acc-0.1200, valid loss-2.2546, acc-0.1874, test loss-2.2542, acc-0.1887\n",
      "Iter-5210, train loss-2.2608, acc-0.1600, valid loss-2.2545, acc-0.1876, test loss-2.2541, acc-0.1887\n",
      "Iter-5220, train loss-2.2472, acc-0.2400, valid loss-2.2545, acc-0.1882, test loss-2.2540, acc-0.1890\n",
      "Iter-5230, train loss-2.2521, acc-0.2800, valid loss-2.2544, acc-0.1884, test loss-2.2539, acc-0.1889\n",
      "Iter-5240, train loss-2.2450, acc-0.2200, valid loss-2.2543, acc-0.1884, test loss-2.2538, acc-0.1894\n",
      "Iter-5250, train loss-2.2650, acc-0.1000, valid loss-2.2542, acc-0.1880, test loss-2.2537, acc-0.1899\n",
      "Iter-5260, train loss-2.2567, acc-0.2800, valid loss-2.2541, acc-0.1888, test loss-2.2536, acc-0.1901\n",
      "Iter-5270, train loss-2.2549, acc-0.2000, valid loss-2.2541, acc-0.1890, test loss-2.2535, acc-0.1906\n",
      "Iter-5280, train loss-2.2436, acc-0.1800, valid loss-2.2540, acc-0.1890, test loss-2.2535, acc-0.1908\n",
      "Iter-5290, train loss-2.2357, acc-0.2600, valid loss-2.2539, acc-0.1892, test loss-2.2534, acc-0.1911\n",
      "Iter-5300, train loss-2.2506, acc-0.1600, valid loss-2.2538, acc-0.1894, test loss-2.2533, acc-0.1913\n",
      "Iter-5310, train loss-2.2434, acc-0.2400, valid loss-2.2538, acc-0.1898, test loss-2.2532, acc-0.1914\n",
      "Iter-5320, train loss-2.2858, acc-0.1800, valid loss-2.2537, acc-0.1900, test loss-2.2531, acc-0.1917\n",
      "Iter-5330, train loss-2.2508, acc-0.2000, valid loss-2.2536, acc-0.1898, test loss-2.2530, acc-0.1917\n",
      "Iter-5340, train loss-2.2530, acc-0.2000, valid loss-2.2535, acc-0.1902, test loss-2.2529, acc-0.1921\n",
      "Iter-5350, train loss-2.2465, acc-0.1800, valid loss-2.2534, acc-0.1904, test loss-2.2528, acc-0.1925\n",
      "Iter-5360, train loss-2.2503, acc-0.2200, valid loss-2.2534, acc-0.1908, test loss-2.2528, acc-0.1928\n",
      "Iter-5370, train loss-2.2547, acc-0.2200, valid loss-2.2533, acc-0.1906, test loss-2.2527, acc-0.1932\n",
      "Iter-5380, train loss-2.3010, acc-0.1200, valid loss-2.2532, acc-0.1906, test loss-2.2526, acc-0.1932\n",
      "Iter-5390, train loss-2.2593, acc-0.1200, valid loss-2.2531, acc-0.1906, test loss-2.2525, acc-0.1934\n",
      "Iter-5400, train loss-2.2548, acc-0.2800, valid loss-2.2530, acc-0.1908, test loss-2.2524, acc-0.1935\n",
      "Iter-5410, train loss-2.2481, acc-0.1600, valid loss-2.2530, acc-0.1908, test loss-2.2523, acc-0.1940\n",
      "Iter-5420, train loss-2.2558, acc-0.1600, valid loss-2.2529, acc-0.1910, test loss-2.2522, acc-0.1938\n",
      "Iter-5430, train loss-2.2839, acc-0.1200, valid loss-2.2528, acc-0.1908, test loss-2.2522, acc-0.1938\n",
      "Iter-5440, train loss-2.2755, acc-0.1800, valid loss-2.2527, acc-0.1910, test loss-2.2521, acc-0.1940\n",
      "Iter-5450, train loss-2.2557, acc-0.2400, valid loss-2.2527, acc-0.1910, test loss-2.2520, acc-0.1943\n",
      "Iter-5460, train loss-2.2630, acc-0.1400, valid loss-2.2526, acc-0.1914, test loss-2.2519, acc-0.1945\n",
      "Iter-5470, train loss-2.2668, acc-0.0600, valid loss-2.2525, acc-0.1916, test loss-2.2518, acc-0.1945\n",
      "Iter-5480, train loss-2.2376, acc-0.2600, valid loss-2.2524, acc-0.1914, test loss-2.2517, acc-0.1948\n",
      "Iter-5490, train loss-2.2325, acc-0.2200, valid loss-2.2523, acc-0.1916, test loss-2.2516, acc-0.1947\n",
      "Iter-5500, train loss-2.2526, acc-0.2800, valid loss-2.2523, acc-0.1918, test loss-2.2515, acc-0.1951\n",
      "Iter-5510, train loss-2.2703, acc-0.1000, valid loss-2.2522, acc-0.1920, test loss-2.2515, acc-0.1952\n",
      "Iter-5520, train loss-2.2593, acc-0.1800, valid loss-2.2521, acc-0.1922, test loss-2.2514, acc-0.1955\n",
      "Iter-5530, train loss-2.2920, acc-0.0800, valid loss-2.2520, acc-0.1922, test loss-2.2513, acc-0.1954\n",
      "Iter-5540, train loss-2.2407, acc-0.2000, valid loss-2.2520, acc-0.1922, test loss-2.2512, acc-0.1954\n",
      "Iter-5550, train loss-2.2444, acc-0.1800, valid loss-2.2519, acc-0.1928, test loss-2.2511, acc-0.1956\n",
      "Iter-5560, train loss-2.2626, acc-0.1800, valid loss-2.2518, acc-0.1922, test loss-2.2510, acc-0.1958\n",
      "Iter-5570, train loss-2.2732, acc-0.1200, valid loss-2.2517, acc-0.1922, test loss-2.2509, acc-0.1960\n",
      "Iter-5580, train loss-2.2660, acc-0.1600, valid loss-2.2516, acc-0.1928, test loss-2.2508, acc-0.1960\n",
      "Iter-5590, train loss-2.2167, acc-0.2600, valid loss-2.2515, acc-0.1930, test loss-2.2508, acc-0.1963\n",
      "Iter-5600, train loss-2.2578, acc-0.1800, valid loss-2.2514, acc-0.1928, test loss-2.2507, acc-0.1963\n",
      "Iter-5610, train loss-2.2600, acc-0.1000, valid loss-2.2514, acc-0.1932, test loss-2.2506, acc-0.1966\n",
      "Iter-5620, train loss-2.2430, acc-0.2200, valid loss-2.2513, acc-0.1932, test loss-2.2505, acc-0.1965\n",
      "Iter-5630, train loss-2.2156, acc-0.3600, valid loss-2.2512, acc-0.1930, test loss-2.2504, acc-0.1968\n",
      "Iter-5640, train loss-2.2668, acc-0.1400, valid loss-2.2511, acc-0.1930, test loss-2.2503, acc-0.1970\n",
      "Iter-5650, train loss-2.2277, acc-0.2400, valid loss-2.2511, acc-0.1942, test loss-2.2502, acc-0.1973\n",
      "Iter-5660, train loss-2.2656, acc-0.1200, valid loss-2.2510, acc-0.1940, test loss-2.2501, acc-0.1975\n",
      "Iter-5670, train loss-2.2512, acc-0.2400, valid loss-2.2509, acc-0.1946, test loss-2.2501, acc-0.1980\n",
      "Iter-5680, train loss-2.2411, acc-0.1600, valid loss-2.2508, acc-0.1952, test loss-2.2500, acc-0.1979\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-5690, train loss-2.2476, acc-0.1600, valid loss-2.2507, acc-0.1950, test loss-2.2499, acc-0.1981\n",
      "Iter-5700, train loss-2.2435, acc-0.1600, valid loss-2.2507, acc-0.1956, test loss-2.2498, acc-0.1980\n",
      "Iter-5710, train loss-2.2610, acc-0.2000, valid loss-2.2506, acc-0.1962, test loss-2.2497, acc-0.1979\n",
      "Iter-5720, train loss-2.2541, acc-0.2200, valid loss-2.2505, acc-0.1964, test loss-2.2496, acc-0.1978\n",
      "Iter-5730, train loss-2.2510, acc-0.2200, valid loss-2.2504, acc-0.1970, test loss-2.2495, acc-0.1978\n",
      "Iter-5740, train loss-2.2580, acc-0.1400, valid loss-2.2504, acc-0.1972, test loss-2.2494, acc-0.1985\n",
      "Iter-5750, train loss-2.2526, acc-0.1800, valid loss-2.2503, acc-0.1974, test loss-2.2493, acc-0.1987\n",
      "Iter-5760, train loss-2.2342, acc-0.2400, valid loss-2.2502, acc-0.1968, test loss-2.2493, acc-0.1987\n",
      "Iter-5770, train loss-2.2818, acc-0.1600, valid loss-2.2501, acc-0.1966, test loss-2.2492, acc-0.1987\n",
      "Iter-5780, train loss-2.2531, acc-0.1400, valid loss-2.2500, acc-0.1976, test loss-2.2491, acc-0.1988\n",
      "Iter-5790, train loss-2.2178, acc-0.2000, valid loss-2.2500, acc-0.1978, test loss-2.2490, acc-0.1993\n",
      "Iter-5800, train loss-2.2305, acc-0.3400, valid loss-2.2499, acc-0.1982, test loss-2.2489, acc-0.1992\n",
      "Iter-5810, train loss-2.2383, acc-0.2400, valid loss-2.2498, acc-0.1986, test loss-2.2488, acc-0.1995\n",
      "Iter-5820, train loss-2.2872, acc-0.1000, valid loss-2.2497, acc-0.1984, test loss-2.2487, acc-0.1995\n",
      "Iter-5830, train loss-2.2587, acc-0.1200, valid loss-2.2496, acc-0.1986, test loss-2.2487, acc-0.1998\n",
      "Iter-5840, train loss-2.2516, acc-0.2000, valid loss-2.2496, acc-0.1992, test loss-2.2486, acc-0.1999\n",
      "Iter-5850, train loss-2.2437, acc-0.1800, valid loss-2.2495, acc-0.1992, test loss-2.2485, acc-0.1999\n",
      "Iter-5860, train loss-2.2617, acc-0.2000, valid loss-2.2494, acc-0.1992, test loss-2.2484, acc-0.1996\n",
      "Iter-5870, train loss-2.2776, acc-0.2000, valid loss-2.2493, acc-0.1994, test loss-2.2483, acc-0.2001\n",
      "Iter-5880, train loss-2.2465, acc-0.2400, valid loss-2.2492, acc-0.2000, test loss-2.2482, acc-0.2002\n",
      "Iter-5890, train loss-2.2509, acc-0.2600, valid loss-2.2492, acc-0.2004, test loss-2.2481, acc-0.2006\n",
      "Iter-5900, train loss-2.2079, acc-0.3200, valid loss-2.2491, acc-0.2004, test loss-2.2480, acc-0.2005\n",
      "Iter-5910, train loss-2.2321, acc-0.2800, valid loss-2.2490, acc-0.2000, test loss-2.2480, acc-0.2007\n",
      "Iter-5920, train loss-2.2764, acc-0.1400, valid loss-2.2489, acc-0.2006, test loss-2.2479, acc-0.2005\n",
      "Iter-5930, train loss-2.2571, acc-0.3200, valid loss-2.2488, acc-0.2010, test loss-2.2478, acc-0.2008\n",
      "Iter-5940, train loss-2.2070, acc-0.3400, valid loss-2.2488, acc-0.2010, test loss-2.2477, acc-0.2010\n",
      "Iter-5950, train loss-2.2608, acc-0.1800, valid loss-2.2487, acc-0.2014, test loss-2.2476, acc-0.2015\n",
      "Iter-5960, train loss-2.2582, acc-0.1800, valid loss-2.2486, acc-0.2014, test loss-2.2475, acc-0.2018\n",
      "Iter-5970, train loss-2.2678, acc-0.1400, valid loss-2.2485, acc-0.2012, test loss-2.2474, acc-0.2022\n",
      "Iter-5980, train loss-2.2479, acc-0.2200, valid loss-2.2485, acc-0.2016, test loss-2.2474, acc-0.2025\n",
      "Iter-5990, train loss-2.2574, acc-0.1400, valid loss-2.2484, acc-0.2014, test loss-2.2473, acc-0.2023\n",
      "Iter-6000, train loss-2.2456, acc-0.1600, valid loss-2.2483, acc-0.2016, test loss-2.2472, acc-0.2026\n",
      "Iter-6010, train loss-2.2768, acc-0.2200, valid loss-2.2482, acc-0.2020, test loss-2.2471, acc-0.2028\n",
      "Iter-6020, train loss-2.2486, acc-0.2200, valid loss-2.2482, acc-0.2028, test loss-2.2470, acc-0.2028\n",
      "Iter-6030, train loss-2.2556, acc-0.2400, valid loss-2.2481, acc-0.2030, test loss-2.2470, acc-0.2029\n",
      "Iter-6040, train loss-2.2686, acc-0.1400, valid loss-2.2480, acc-0.2028, test loss-2.2469, acc-0.2028\n",
      "Iter-6050, train loss-2.2450, acc-0.1600, valid loss-2.2479, acc-0.2032, test loss-2.2468, acc-0.2034\n",
      "Iter-6060, train loss-2.2700, acc-0.1200, valid loss-2.2479, acc-0.2032, test loss-2.2467, acc-0.2036\n",
      "Iter-6070, train loss-2.2606, acc-0.1000, valid loss-2.2478, acc-0.2038, test loss-2.2466, acc-0.2035\n",
      "Iter-6080, train loss-2.2616, acc-0.0600, valid loss-2.2477, acc-0.2032, test loss-2.2465, acc-0.2037\n",
      "Iter-6090, train loss-2.2186, acc-0.2800, valid loss-2.2476, acc-0.2034, test loss-2.2464, acc-0.2042\n",
      "Iter-6100, train loss-2.2415, acc-0.2600, valid loss-2.2475, acc-0.2038, test loss-2.2463, acc-0.2044\n",
      "Iter-6110, train loss-2.2586, acc-0.2200, valid loss-2.2475, acc-0.2042, test loss-2.2463, acc-0.2044\n",
      "Iter-6120, train loss-2.2484, acc-0.2800, valid loss-2.2474, acc-0.2044, test loss-2.2462, acc-0.2046\n",
      "Iter-6130, train loss-2.2576, acc-0.1600, valid loss-2.2473, acc-0.2044, test loss-2.2461, acc-0.2050\n",
      "Iter-6140, train loss-2.2352, acc-0.2000, valid loss-2.2472, acc-0.2046, test loss-2.2460, acc-0.2050\n",
      "Iter-6150, train loss-2.2456, acc-0.2000, valid loss-2.2471, acc-0.2052, test loss-2.2459, acc-0.2053\n",
      "Iter-6160, train loss-2.2511, acc-0.1600, valid loss-2.2471, acc-0.2056, test loss-2.2458, acc-0.2057\n",
      "Iter-6170, train loss-2.2343, acc-0.2200, valid loss-2.2470, acc-0.2060, test loss-2.2457, acc-0.2059\n",
      "Iter-6180, train loss-2.2423, acc-0.2200, valid loss-2.2469, acc-0.2062, test loss-2.2457, acc-0.2058\n",
      "Iter-6190, train loss-2.2606, acc-0.1600, valid loss-2.2468, acc-0.2068, test loss-2.2456, acc-0.2062\n",
      "Iter-6200, train loss-2.2353, acc-0.3000, valid loss-2.2468, acc-0.2066, test loss-2.2455, acc-0.2065\n",
      "Iter-6210, train loss-2.2581, acc-0.1400, valid loss-2.2467, acc-0.2066, test loss-2.2454, acc-0.2068\n",
      "Iter-6220, train loss-2.2384, acc-0.2200, valid loss-2.2466, acc-0.2068, test loss-2.2453, acc-0.2069\n",
      "Iter-6230, train loss-2.2390, acc-0.1200, valid loss-2.2465, acc-0.2070, test loss-2.2452, acc-0.2072\n",
      "Iter-6240, train loss-2.2582, acc-0.1000, valid loss-2.2465, acc-0.2072, test loss-2.2451, acc-0.2073\n",
      "Iter-6250, train loss-2.2450, acc-0.3000, valid loss-2.2464, acc-0.2078, test loss-2.2451, acc-0.2073\n",
      "Iter-6260, train loss-2.2497, acc-0.2000, valid loss-2.2463, acc-0.2080, test loss-2.2450, acc-0.2075\n",
      "Iter-6270, train loss-2.2571, acc-0.1600, valid loss-2.2462, acc-0.2078, test loss-2.2449, acc-0.2078\n",
      "Iter-6280, train loss-2.2617, acc-0.1200, valid loss-2.2461, acc-0.2076, test loss-2.2448, acc-0.2078\n",
      "Iter-6290, train loss-2.2781, acc-0.1000, valid loss-2.2461, acc-0.2080, test loss-2.2447, acc-0.2082\n",
      "Iter-6300, train loss-2.2589, acc-0.1400, valid loss-2.2460, acc-0.2084, test loss-2.2446, acc-0.2079\n",
      "Iter-6310, train loss-2.2512, acc-0.2000, valid loss-2.2459, acc-0.2084, test loss-2.2445, acc-0.2081\n",
      "Iter-6320, train loss-2.2629, acc-0.1400, valid loss-2.2458, acc-0.2092, test loss-2.2444, acc-0.2083\n",
      "Iter-6330, train loss-2.2665, acc-0.2400, valid loss-2.2457, acc-0.2088, test loss-2.2444, acc-0.2086\n",
      "Iter-6340, train loss-2.2340, acc-0.2200, valid loss-2.2457, acc-0.2092, test loss-2.2443, acc-0.2089\n",
      "Iter-6350, train loss-2.2629, acc-0.1600, valid loss-2.2456, acc-0.2094, test loss-2.2442, acc-0.2089\n",
      "Iter-6360, train loss-2.2340, acc-0.1400, valid loss-2.2455, acc-0.2098, test loss-2.2441, acc-0.2091\n",
      "Iter-6370, train loss-2.2563, acc-0.2000, valid loss-2.2454, acc-0.2098, test loss-2.2440, acc-0.2095\n",
      "Iter-6380, train loss-2.2464, acc-0.2800, valid loss-2.2453, acc-0.2100, test loss-2.2439, acc-0.2098\n",
      "Iter-6390, train loss-2.2385, acc-0.3000, valid loss-2.2453, acc-0.2104, test loss-2.2438, acc-0.2100\n",
      "Iter-6400, train loss-2.2064, acc-0.2200, valid loss-2.2452, acc-0.2100, test loss-2.2438, acc-0.2098\n",
      "Iter-6410, train loss-2.2452, acc-0.2800, valid loss-2.2451, acc-0.2104, test loss-2.2437, acc-0.2101\n",
      "Iter-6420, train loss-2.2453, acc-0.1200, valid loss-2.2450, acc-0.2106, test loss-2.2436, acc-0.2104\n",
      "Iter-6430, train loss-2.2465, acc-0.2000, valid loss-2.2450, acc-0.2110, test loss-2.2435, acc-0.2106\n",
      "Iter-6440, train loss-2.2394, acc-0.2400, valid loss-2.2449, acc-0.2114, test loss-2.2434, acc-0.2106\n",
      "Iter-6450, train loss-2.2610, acc-0.1600, valid loss-2.2448, acc-0.2110, test loss-2.2433, acc-0.2106\n",
      "Iter-6460, train loss-2.2239, acc-0.1800, valid loss-2.2447, acc-0.2112, test loss-2.2432, acc-0.2108\n",
      "Iter-6470, train loss-2.2319, acc-0.2200, valid loss-2.2446, acc-0.2120, test loss-2.2431, acc-0.2108\n",
      "Iter-6480, train loss-2.2594, acc-0.1800, valid loss-2.2446, acc-0.2122, test loss-2.2431, acc-0.2109\n",
      "Iter-6490, train loss-2.2258, acc-0.2000, valid loss-2.2445, acc-0.2120, test loss-2.2430, acc-0.2114\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6500, train loss-2.2246, acc-0.2400, valid loss-2.2444, acc-0.2124, test loss-2.2429, acc-0.2115\n",
      "Iter-6510, train loss-2.2309, acc-0.2400, valid loss-2.2443, acc-0.2130, test loss-2.2428, acc-0.2117\n",
      "Iter-6520, train loss-2.2474, acc-0.1800, valid loss-2.2443, acc-0.2132, test loss-2.2427, acc-0.2116\n",
      "Iter-6530, train loss-2.2269, acc-0.2000, valid loss-2.2442, acc-0.2130, test loss-2.2426, acc-0.2118\n",
      "Iter-6540, train loss-2.2231, acc-0.2400, valid loss-2.2441, acc-0.2132, test loss-2.2426, acc-0.2118\n",
      "Iter-6550, train loss-2.2420, acc-0.3000, valid loss-2.2440, acc-0.2132, test loss-2.2425, acc-0.2119\n",
      "Iter-6560, train loss-2.2325, acc-0.2400, valid loss-2.2439, acc-0.2136, test loss-2.2424, acc-0.2121\n",
      "Iter-6570, train loss-2.2349, acc-0.2000, valid loss-2.2439, acc-0.2136, test loss-2.2423, acc-0.2124\n",
      "Iter-6580, train loss-2.2462, acc-0.1800, valid loss-2.2438, acc-0.2138, test loss-2.2422, acc-0.2126\n",
      "Iter-6590, train loss-2.2256, acc-0.2200, valid loss-2.2437, acc-0.2140, test loss-2.2421, acc-0.2130\n",
      "Iter-6600, train loss-2.2321, acc-0.1800, valid loss-2.2436, acc-0.2144, test loss-2.2420, acc-0.2131\n",
      "Iter-6610, train loss-2.2506, acc-0.1600, valid loss-2.2436, acc-0.2148, test loss-2.2420, acc-0.2132\n",
      "Iter-6620, train loss-2.2701, acc-0.1000, valid loss-2.2435, acc-0.2152, test loss-2.2419, acc-0.2136\n",
      "Iter-6630, train loss-2.2334, acc-0.3000, valid loss-2.2434, acc-0.2158, test loss-2.2418, acc-0.2137\n",
      "Iter-6640, train loss-2.2374, acc-0.2600, valid loss-2.2433, acc-0.2154, test loss-2.2417, acc-0.2141\n",
      "Iter-6650, train loss-2.2421, acc-0.2400, valid loss-2.2432, acc-0.2162, test loss-2.2416, acc-0.2141\n",
      "Iter-6660, train loss-2.2483, acc-0.1800, valid loss-2.2432, acc-0.2158, test loss-2.2415, acc-0.2144\n",
      "Iter-6670, train loss-2.2305, acc-0.1800, valid loss-2.2431, acc-0.2164, test loss-2.2414, acc-0.2144\n",
      "Iter-6680, train loss-2.2140, acc-0.3400, valid loss-2.2430, acc-0.2166, test loss-2.2413, acc-0.2150\n",
      "Iter-6690, train loss-2.2274, acc-0.2200, valid loss-2.2429, acc-0.2166, test loss-2.2413, acc-0.2152\n",
      "Iter-6700, train loss-2.2651, acc-0.1600, valid loss-2.2429, acc-0.2170, test loss-2.2412, acc-0.2156\n",
      "Iter-6710, train loss-2.2461, acc-0.3000, valid loss-2.2428, acc-0.2174, test loss-2.2411, acc-0.2156\n",
      "Iter-6720, train loss-2.2473, acc-0.2200, valid loss-2.2427, acc-0.2180, test loss-2.2410, acc-0.2155\n",
      "Iter-6730, train loss-2.2495, acc-0.2200, valid loss-2.2426, acc-0.2176, test loss-2.2409, acc-0.2153\n",
      "Iter-6740, train loss-2.2433, acc-0.1600, valid loss-2.2425, acc-0.2180, test loss-2.2408, acc-0.2157\n",
      "Iter-6750, train loss-2.2369, acc-0.1800, valid loss-2.2425, acc-0.2186, test loss-2.2407, acc-0.2161\n",
      "Iter-6760, train loss-2.2494, acc-0.1400, valid loss-2.2424, acc-0.2188, test loss-2.2407, acc-0.2162\n",
      "Iter-6770, train loss-2.2504, acc-0.2400, valid loss-2.2423, acc-0.2188, test loss-2.2406, acc-0.2166\n",
      "Iter-6780, train loss-2.2505, acc-0.1800, valid loss-2.2422, acc-0.2192, test loss-2.2405, acc-0.2167\n",
      "Iter-6790, train loss-2.2148, acc-0.3400, valid loss-2.2422, acc-0.2192, test loss-2.2404, acc-0.2172\n",
      "Iter-6800, train loss-2.2703, acc-0.0400, valid loss-2.2421, acc-0.2188, test loss-2.2403, acc-0.2173\n",
      "Iter-6810, train loss-2.2389, acc-0.2200, valid loss-2.2420, acc-0.2190, test loss-2.2402, acc-0.2176\n",
      "Iter-6820, train loss-2.2434, acc-0.2000, valid loss-2.2419, acc-0.2196, test loss-2.2402, acc-0.2176\n",
      "Iter-6830, train loss-2.2528, acc-0.2400, valid loss-2.2419, acc-0.2194, test loss-2.2401, acc-0.2177\n",
      "Iter-6840, train loss-2.2229, acc-0.3000, valid loss-2.2418, acc-0.2198, test loss-2.2400, acc-0.2181\n",
      "Iter-6850, train loss-2.2399, acc-0.2000, valid loss-2.2417, acc-0.2198, test loss-2.2399, acc-0.2184\n",
      "Iter-6860, train loss-2.2514, acc-0.0800, valid loss-2.2416, acc-0.2208, test loss-2.2398, acc-0.2184\n",
      "Iter-6870, train loss-2.2331, acc-0.2600, valid loss-2.2415, acc-0.2212, test loss-2.2397, acc-0.2186\n",
      "Iter-6880, train loss-2.2626, acc-0.2400, valid loss-2.2415, acc-0.2206, test loss-2.2396, acc-0.2189\n",
      "Iter-6890, train loss-2.2279, acc-0.1600, valid loss-2.2414, acc-0.2206, test loss-2.2395, acc-0.2190\n",
      "Iter-6900, train loss-2.2296, acc-0.2200, valid loss-2.2413, acc-0.2210, test loss-2.2395, acc-0.2193\n",
      "Iter-6910, train loss-2.2469, acc-0.1400, valid loss-2.2412, acc-0.2214, test loss-2.2394, acc-0.2196\n",
      "Iter-6920, train loss-2.2685, acc-0.1400, valid loss-2.2411, acc-0.2212, test loss-2.2393, acc-0.2195\n",
      "Iter-6930, train loss-2.2339, acc-0.1800, valid loss-2.2411, acc-0.2214, test loss-2.2392, acc-0.2196\n",
      "Iter-6940, train loss-2.2495, acc-0.1200, valid loss-2.2410, acc-0.2214, test loss-2.2391, acc-0.2199\n",
      "Iter-6950, train loss-2.2456, acc-0.2000, valid loss-2.2409, acc-0.2214, test loss-2.2390, acc-0.2200\n",
      "Iter-6960, train loss-2.2567, acc-0.1200, valid loss-2.2408, acc-0.2216, test loss-2.2389, acc-0.2203\n",
      "Iter-6970, train loss-2.2395, acc-0.1800, valid loss-2.2407, acc-0.2224, test loss-2.2389, acc-0.2202\n",
      "Iter-6980, train loss-2.2416, acc-0.2000, valid loss-2.2407, acc-0.2220, test loss-2.2388, acc-0.2205\n",
      "Iter-6990, train loss-2.2366, acc-0.2600, valid loss-2.2406, acc-0.2226, test loss-2.2387, acc-0.2210\n",
      "Iter-7000, train loss-2.2315, acc-0.2000, valid loss-2.2405, acc-0.2226, test loss-2.2386, acc-0.2218\n",
      "Iter-7010, train loss-2.2449, acc-0.1400, valid loss-2.2405, acc-0.2226, test loss-2.2385, acc-0.2220\n",
      "Iter-7020, train loss-2.2663, acc-0.1200, valid loss-2.2404, acc-0.2228, test loss-2.2385, acc-0.2220\n",
      "Iter-7030, train loss-2.2381, acc-0.2000, valid loss-2.2403, acc-0.2228, test loss-2.2384, acc-0.2221\n",
      "Iter-7040, train loss-2.2562, acc-0.2800, valid loss-2.2402, acc-0.2230, test loss-2.2383, acc-0.2226\n",
      "Iter-7050, train loss-2.2496, acc-0.1000, valid loss-2.2402, acc-0.2230, test loss-2.2382, acc-0.2228\n",
      "Iter-7060, train loss-2.2418, acc-0.2800, valid loss-2.2401, acc-0.2234, test loss-2.2381, acc-0.2226\n",
      "Iter-7070, train loss-2.2349, acc-0.1200, valid loss-2.2400, acc-0.2232, test loss-2.2381, acc-0.2230\n",
      "Iter-7080, train loss-2.2537, acc-0.2600, valid loss-2.2399, acc-0.2232, test loss-2.2380, acc-0.2233\n",
      "Iter-7090, train loss-2.2405, acc-0.2000, valid loss-2.2399, acc-0.2232, test loss-2.2379, acc-0.2234\n",
      "Iter-7100, train loss-2.2478, acc-0.1400, valid loss-2.2398, acc-0.2238, test loss-2.2378, acc-0.2234\n",
      "Iter-7110, train loss-2.2140, acc-0.3600, valid loss-2.2397, acc-0.2240, test loss-2.2377, acc-0.2231\n",
      "Iter-7120, train loss-2.2631, acc-0.1200, valid loss-2.2396, acc-0.2240, test loss-2.2376, acc-0.2237\n",
      "Iter-7130, train loss-2.2353, acc-0.2200, valid loss-2.2396, acc-0.2242, test loss-2.2375, acc-0.2238\n",
      "Iter-7140, train loss-2.2573, acc-0.1800, valid loss-2.2395, acc-0.2246, test loss-2.2375, acc-0.2240\n",
      "Iter-7150, train loss-2.2492, acc-0.2200, valid loss-2.2394, acc-0.2244, test loss-2.2374, acc-0.2242\n",
      "Iter-7160, train loss-2.2568, acc-0.1400, valid loss-2.2393, acc-0.2250, test loss-2.2373, acc-0.2243\n",
      "Iter-7170, train loss-2.2356, acc-0.2800, valid loss-2.2392, acc-0.2244, test loss-2.2372, acc-0.2244\n",
      "Iter-7180, train loss-2.2656, acc-0.1400, valid loss-2.2392, acc-0.2246, test loss-2.2371, acc-0.2246\n",
      "Iter-7190, train loss-2.2463, acc-0.1800, valid loss-2.2391, acc-0.2248, test loss-2.2370, acc-0.2242\n",
      "Iter-7200, train loss-2.2430, acc-0.2600, valid loss-2.2390, acc-0.2254, test loss-2.2369, acc-0.2244\n",
      "Iter-7210, train loss-2.2615, acc-0.2600, valid loss-2.2389, acc-0.2254, test loss-2.2368, acc-0.2248\n",
      "Iter-7220, train loss-2.2269, acc-0.3000, valid loss-2.2388, acc-0.2250, test loss-2.2368, acc-0.2249\n",
      "Iter-7230, train loss-2.2527, acc-0.2000, valid loss-2.2388, acc-0.2250, test loss-2.2367, acc-0.2253\n",
      "Iter-7240, train loss-2.2357, acc-0.3200, valid loss-2.2387, acc-0.2252, test loss-2.2366, acc-0.2252\n",
      "Iter-7250, train loss-2.2291, acc-0.3200, valid loss-2.2386, acc-0.2254, test loss-2.2365, acc-0.2253\n",
      "Iter-7260, train loss-2.2415, acc-0.2200, valid loss-2.2385, acc-0.2254, test loss-2.2364, acc-0.2254\n",
      "Iter-7270, train loss-2.2205, acc-0.3000, valid loss-2.2385, acc-0.2256, test loss-2.2363, acc-0.2256\n",
      "Iter-7280, train loss-2.2383, acc-0.2600, valid loss-2.2384, acc-0.2262, test loss-2.2363, acc-0.2256\n",
      "Iter-7290, train loss-2.2460, acc-0.2600, valid loss-2.2383, acc-0.2264, test loss-2.2362, acc-0.2257\n",
      "Iter-7300, train loss-2.2811, acc-0.1000, valid loss-2.2382, acc-0.2264, test loss-2.2361, acc-0.2260\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-7310, train loss-2.2094, acc-0.3200, valid loss-2.2381, acc-0.2266, test loss-2.2360, acc-0.2265\n",
      "Iter-7320, train loss-2.2409, acc-0.2200, valid loss-2.2381, acc-0.2266, test loss-2.2359, acc-0.2268\n",
      "Iter-7330, train loss-2.2358, acc-0.2400, valid loss-2.2380, acc-0.2270, test loss-2.2358, acc-0.2269\n",
      "Iter-7340, train loss-2.2326, acc-0.2800, valid loss-2.2379, acc-0.2272, test loss-2.2358, acc-0.2268\n",
      "Iter-7350, train loss-2.2333, acc-0.2400, valid loss-2.2378, acc-0.2276, test loss-2.2357, acc-0.2269\n",
      "Iter-7360, train loss-2.2298, acc-0.3000, valid loss-2.2378, acc-0.2280, test loss-2.2356, acc-0.2266\n",
      "Iter-7370, train loss-2.2307, acc-0.2000, valid loss-2.2377, acc-0.2282, test loss-2.2355, acc-0.2270\n",
      "Iter-7380, train loss-2.2603, acc-0.1800, valid loss-2.2376, acc-0.2280, test loss-2.2354, acc-0.2276\n",
      "Iter-7390, train loss-2.2447, acc-0.1600, valid loss-2.2375, acc-0.2282, test loss-2.2353, acc-0.2279\n",
      "Iter-7400, train loss-2.2478, acc-0.1600, valid loss-2.2375, acc-0.2276, test loss-2.2353, acc-0.2279\n",
      "Iter-7410, train loss-2.2418, acc-0.2200, valid loss-2.2374, acc-0.2280, test loss-2.2352, acc-0.2279\n",
      "Iter-7420, train loss-2.2433, acc-0.2400, valid loss-2.2373, acc-0.2284, test loss-2.2351, acc-0.2282\n",
      "Iter-7430, train loss-2.2428, acc-0.2800, valid loss-2.2372, acc-0.2290, test loss-2.2350, acc-0.2287\n",
      "Iter-7440, train loss-2.2416, acc-0.2400, valid loss-2.2371, acc-0.2294, test loss-2.2349, acc-0.2292\n",
      "Iter-7450, train loss-2.2598, acc-0.1600, valid loss-2.2371, acc-0.2296, test loss-2.2348, acc-0.2295\n",
      "Iter-7460, train loss-2.2330, acc-0.3000, valid loss-2.2370, acc-0.2294, test loss-2.2348, acc-0.2295\n",
      "Iter-7470, train loss-2.2306, acc-0.1600, valid loss-2.2369, acc-0.2296, test loss-2.2347, acc-0.2296\n",
      "Iter-7480, train loss-2.2470, acc-0.2400, valid loss-2.2368, acc-0.2290, test loss-2.2346, acc-0.2302\n",
      "Iter-7490, train loss-2.2329, acc-0.2600, valid loss-2.2368, acc-0.2294, test loss-2.2345, acc-0.2305\n",
      "Iter-7500, train loss-2.2475, acc-0.2600, valid loss-2.2367, acc-0.2300, test loss-2.2344, acc-0.2308\n",
      "Iter-7510, train loss-2.2397, acc-0.2000, valid loss-2.2366, acc-0.2298, test loss-2.2343, acc-0.2309\n",
      "Iter-7520, train loss-2.2411, acc-0.1400, valid loss-2.2365, acc-0.2300, test loss-2.2343, acc-0.2312\n",
      "Iter-7530, train loss-2.2540, acc-0.1600, valid loss-2.2365, acc-0.2304, test loss-2.2342, acc-0.2313\n",
      "Iter-7540, train loss-2.2340, acc-0.2000, valid loss-2.2364, acc-0.2308, test loss-2.2341, acc-0.2316\n",
      "Iter-7550, train loss-2.2408, acc-0.1600, valid loss-2.2363, acc-0.2300, test loss-2.2340, acc-0.2316\n",
      "Iter-7560, train loss-2.2332, acc-0.1800, valid loss-2.2362, acc-0.2302, test loss-2.2339, acc-0.2319\n",
      "Iter-7570, train loss-2.2171, acc-0.2800, valid loss-2.2362, acc-0.2298, test loss-2.2338, acc-0.2318\n",
      "Iter-7580, train loss-2.2267, acc-0.2600, valid loss-2.2361, acc-0.2302, test loss-2.2338, acc-0.2319\n",
      "Iter-7590, train loss-2.2423, acc-0.2800, valid loss-2.2360, acc-0.2302, test loss-2.2337, acc-0.2321\n",
      "Iter-7600, train loss-2.2403, acc-0.1800, valid loss-2.2359, acc-0.2310, test loss-2.2336, acc-0.2318\n",
      "Iter-7610, train loss-2.2369, acc-0.2000, valid loss-2.2359, acc-0.2310, test loss-2.2335, acc-0.2321\n",
      "Iter-7620, train loss-2.2284, acc-0.2800, valid loss-2.2358, acc-0.2310, test loss-2.2334, acc-0.2325\n",
      "Iter-7630, train loss-2.2305, acc-0.1800, valid loss-2.2357, acc-0.2310, test loss-2.2333, acc-0.2326\n",
      "Iter-7640, train loss-2.2701, acc-0.2000, valid loss-2.2356, acc-0.2308, test loss-2.2332, acc-0.2331\n",
      "Iter-7650, train loss-2.2477, acc-0.2200, valid loss-2.2356, acc-0.2308, test loss-2.2332, acc-0.2331\n",
      "Iter-7660, train loss-2.2256, acc-0.2800, valid loss-2.2355, acc-0.2308, test loss-2.2331, acc-0.2339\n",
      "Iter-7670, train loss-2.2445, acc-0.2400, valid loss-2.2354, acc-0.2310, test loss-2.2330, acc-0.2341\n",
      "Iter-7680, train loss-2.2654, acc-0.1800, valid loss-2.2353, acc-0.2316, test loss-2.2329, acc-0.2343\n",
      "Iter-7690, train loss-2.2218, acc-0.3200, valid loss-2.2352, acc-0.2318, test loss-2.2328, acc-0.2344\n",
      "Iter-7700, train loss-2.2733, acc-0.1200, valid loss-2.2352, acc-0.2318, test loss-2.2328, acc-0.2346\n",
      "Iter-7710, train loss-2.2300, acc-0.2800, valid loss-2.2351, acc-0.2316, test loss-2.2327, acc-0.2348\n",
      "Iter-7720, train loss-2.2226, acc-0.3200, valid loss-2.2350, acc-0.2318, test loss-2.2326, acc-0.2349\n",
      "Iter-7730, train loss-2.2074, acc-0.2600, valid loss-2.2350, acc-0.2318, test loss-2.2325, acc-0.2351\n",
      "Iter-7740, train loss-2.2298, acc-0.2400, valid loss-2.2349, acc-0.2324, test loss-2.2324, acc-0.2352\n",
      "Iter-7750, train loss-2.2367, acc-0.1800, valid loss-2.2348, acc-0.2332, test loss-2.2323, acc-0.2355\n",
      "Iter-7760, train loss-2.2300, acc-0.2600, valid loss-2.2347, acc-0.2328, test loss-2.2323, acc-0.2357\n",
      "Iter-7770, train loss-2.2670, acc-0.1800, valid loss-2.2347, acc-0.2334, test loss-2.2322, acc-0.2364\n",
      "Iter-7780, train loss-2.2346, acc-0.3000, valid loss-2.2346, acc-0.2334, test loss-2.2321, acc-0.2365\n",
      "Iter-7790, train loss-2.2532, acc-0.1400, valid loss-2.2345, acc-0.2336, test loss-2.2320, acc-0.2369\n",
      "Iter-7800, train loss-2.2396, acc-0.2000, valid loss-2.2344, acc-0.2336, test loss-2.2319, acc-0.2366\n",
      "Iter-7810, train loss-2.2263, acc-0.2800, valid loss-2.2344, acc-0.2344, test loss-2.2319, acc-0.2371\n",
      "Iter-7820, train loss-2.2635, acc-0.2200, valid loss-2.2343, acc-0.2348, test loss-2.2318, acc-0.2372\n",
      "Iter-7830, train loss-2.2197, acc-0.2400, valid loss-2.2342, acc-0.2350, test loss-2.2317, acc-0.2374\n",
      "Iter-7840, train loss-2.1946, acc-0.3800, valid loss-2.2341, acc-0.2352, test loss-2.2316, acc-0.2377\n",
      "Iter-7850, train loss-2.2242, acc-0.3400, valid loss-2.2340, acc-0.2348, test loss-2.2315, acc-0.2379\n",
      "Iter-7860, train loss-2.2366, acc-0.2400, valid loss-2.2340, acc-0.2358, test loss-2.2314, acc-0.2381\n",
      "Iter-7870, train loss-2.2227, acc-0.2600, valid loss-2.2339, acc-0.2358, test loss-2.2314, acc-0.2380\n",
      "Iter-7880, train loss-2.2486, acc-0.2000, valid loss-2.2338, acc-0.2356, test loss-2.2313, acc-0.2383\n",
      "Iter-7890, train loss-2.2131, acc-0.2600, valid loss-2.2338, acc-0.2360, test loss-2.2312, acc-0.2384\n",
      "Iter-7900, train loss-2.2291, acc-0.2000, valid loss-2.2337, acc-0.2358, test loss-2.2311, acc-0.2386\n",
      "Iter-7910, train loss-2.2367, acc-0.2400, valid loss-2.2336, acc-0.2358, test loss-2.2310, acc-0.2387\n",
      "Iter-7920, train loss-2.2142, acc-0.2600, valid loss-2.2335, acc-0.2358, test loss-2.2310, acc-0.2394\n",
      "Iter-7930, train loss-2.2668, acc-0.1200, valid loss-2.2334, acc-0.2364, test loss-2.2309, acc-0.2395\n",
      "Iter-7940, train loss-2.2433, acc-0.2000, valid loss-2.2334, acc-0.2366, test loss-2.2308, acc-0.2398\n",
      "Iter-7950, train loss-2.2815, acc-0.2200, valid loss-2.2333, acc-0.2370, test loss-2.2307, acc-0.2400\n",
      "Iter-7960, train loss-2.2493, acc-0.2400, valid loss-2.2332, acc-0.2374, test loss-2.2306, acc-0.2401\n",
      "Iter-7970, train loss-2.2201, acc-0.1800, valid loss-2.2331, acc-0.2374, test loss-2.2305, acc-0.2401\n",
      "Iter-7980, train loss-2.2200, acc-0.3600, valid loss-2.2331, acc-0.2382, test loss-2.2304, acc-0.2401\n",
      "Iter-7990, train loss-2.2273, acc-0.2400, valid loss-2.2330, acc-0.2386, test loss-2.2303, acc-0.2404\n",
      "Iter-8000, train loss-2.2267, acc-0.2400, valid loss-2.2329, acc-0.2390, test loss-2.2303, acc-0.2401\n",
      "Iter-8010, train loss-2.2449, acc-0.2400, valid loss-2.2328, acc-0.2384, test loss-2.2302, acc-0.2403\n",
      "Iter-8020, train loss-2.2554, acc-0.2000, valid loss-2.2328, acc-0.2386, test loss-2.2301, acc-0.2404\n",
      "Iter-8030, train loss-2.2194, acc-0.1800, valid loss-2.2327, acc-0.2390, test loss-2.2300, acc-0.2408\n",
      "Iter-8040, train loss-2.2223, acc-0.3000, valid loss-2.2326, acc-0.2390, test loss-2.2299, acc-0.2410\n",
      "Iter-8050, train loss-2.2372, acc-0.2400, valid loss-2.2325, acc-0.2392, test loss-2.2299, acc-0.2414\n",
      "Iter-8060, train loss-2.2156, acc-0.3200, valid loss-2.2325, acc-0.2396, test loss-2.2298, acc-0.2415\n",
      "Iter-8070, train loss-2.2527, acc-0.2000, valid loss-2.2324, acc-0.2396, test loss-2.2297, acc-0.2416\n",
      "Iter-8080, train loss-2.2421, acc-0.2000, valid loss-2.2323, acc-0.2398, test loss-2.2296, acc-0.2420\n",
      "Iter-8090, train loss-2.2263, acc-0.2200, valid loss-2.2322, acc-0.2402, test loss-2.2295, acc-0.2419\n",
      "Iter-8100, train loss-2.2268, acc-0.2600, valid loss-2.2322, acc-0.2398, test loss-2.2294, acc-0.2423\n",
      "Iter-8110, train loss-2.2214, acc-0.2800, valid loss-2.2321, acc-0.2400, test loss-2.2294, acc-0.2423\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8120, train loss-2.2330, acc-0.2200, valid loss-2.2320, acc-0.2404, test loss-2.2293, acc-0.2425\n",
      "Iter-8130, train loss-2.2258, acc-0.2000, valid loss-2.2319, acc-0.2406, test loss-2.2292, acc-0.2430\n",
      "Iter-8140, train loss-2.2548, acc-0.1200, valid loss-2.2318, acc-0.2408, test loss-2.2291, acc-0.2431\n",
      "Iter-8150, train loss-2.2424, acc-0.3400, valid loss-2.2318, acc-0.2412, test loss-2.2290, acc-0.2434\n",
      "Iter-8160, train loss-2.2141, acc-0.3000, valid loss-2.2317, acc-0.2416, test loss-2.2290, acc-0.2435\n",
      "Iter-8170, train loss-2.2241, acc-0.2800, valid loss-2.2316, acc-0.2414, test loss-2.2289, acc-0.2433\n",
      "Iter-8180, train loss-2.2466, acc-0.2800, valid loss-2.2316, acc-0.2418, test loss-2.2288, acc-0.2439\n",
      "Iter-8190, train loss-2.2304, acc-0.2000, valid loss-2.2315, acc-0.2420, test loss-2.2287, acc-0.2442\n",
      "Iter-8200, train loss-2.2589, acc-0.1800, valid loss-2.2314, acc-0.2422, test loss-2.2286, acc-0.2444\n",
      "Iter-8210, train loss-2.2402, acc-0.2600, valid loss-2.2313, acc-0.2430, test loss-2.2286, acc-0.2446\n",
      "Iter-8220, train loss-2.2483, acc-0.2600, valid loss-2.2313, acc-0.2430, test loss-2.2285, acc-0.2449\n",
      "Iter-8230, train loss-2.2460, acc-0.1800, valid loss-2.2312, acc-0.2432, test loss-2.2284, acc-0.2449\n",
      "Iter-8240, train loss-2.2447, acc-0.1200, valid loss-2.2311, acc-0.2432, test loss-2.2283, acc-0.2454\n",
      "Iter-8250, train loss-2.2524, acc-0.2200, valid loss-2.2310, acc-0.2430, test loss-2.2282, acc-0.2455\n",
      "Iter-8260, train loss-2.2673, acc-0.1800, valid loss-2.2310, acc-0.2438, test loss-2.2282, acc-0.2452\n",
      "Iter-8270, train loss-2.2286, acc-0.2400, valid loss-2.2309, acc-0.2440, test loss-2.2281, acc-0.2454\n",
      "Iter-8280, train loss-2.2507, acc-0.2400, valid loss-2.2308, acc-0.2440, test loss-2.2280, acc-0.2460\n",
      "Iter-8290, train loss-2.2161, acc-0.2800, valid loss-2.2307, acc-0.2438, test loss-2.2279, acc-0.2464\n",
      "Iter-8300, train loss-2.2053, acc-0.3000, valid loss-2.2307, acc-0.2442, test loss-2.2278, acc-0.2468\n",
      "Iter-8310, train loss-2.2635, acc-0.1000, valid loss-2.2306, acc-0.2444, test loss-2.2277, acc-0.2466\n",
      "Iter-8320, train loss-2.2167, acc-0.2600, valid loss-2.2305, acc-0.2446, test loss-2.2277, acc-0.2474\n",
      "Iter-8330, train loss-2.2307, acc-0.2600, valid loss-2.2304, acc-0.2446, test loss-2.2276, acc-0.2475\n",
      "Iter-8340, train loss-2.2213, acc-0.2200, valid loss-2.2304, acc-0.2450, test loss-2.2275, acc-0.2476\n",
      "Iter-8350, train loss-2.2332, acc-0.2200, valid loss-2.2303, acc-0.2450, test loss-2.2274, acc-0.2480\n",
      "Iter-8360, train loss-2.2321, acc-0.2200, valid loss-2.2302, acc-0.2456, test loss-2.2273, acc-0.2483\n",
      "Iter-8370, train loss-2.2434, acc-0.2200, valid loss-2.2301, acc-0.2454, test loss-2.2273, acc-0.2485\n",
      "Iter-8380, train loss-2.2168, acc-0.2400, valid loss-2.2301, acc-0.2456, test loss-2.2272, acc-0.2488\n",
      "Iter-8390, train loss-2.2326, acc-0.3400, valid loss-2.2300, acc-0.2458, test loss-2.2271, acc-0.2489\n",
      "Iter-8400, train loss-2.2114, acc-0.3200, valid loss-2.2299, acc-0.2458, test loss-2.2270, acc-0.2488\n",
      "Iter-8410, train loss-2.2309, acc-0.1600, valid loss-2.2298, acc-0.2458, test loss-2.2269, acc-0.2487\n",
      "Iter-8420, train loss-2.2429, acc-0.2400, valid loss-2.2298, acc-0.2458, test loss-2.2268, acc-0.2490\n",
      "Iter-8430, train loss-2.2132, acc-0.2800, valid loss-2.2297, acc-0.2464, test loss-2.2268, acc-0.2487\n",
      "Iter-8440, train loss-2.2028, acc-0.4000, valid loss-2.2296, acc-0.2474, test loss-2.2267, acc-0.2487\n",
      "Iter-8450, train loss-2.2256, acc-0.3200, valid loss-2.2295, acc-0.2474, test loss-2.2266, acc-0.2489\n",
      "Iter-8460, train loss-2.2092, acc-0.2600, valid loss-2.2294, acc-0.2478, test loss-2.2265, acc-0.2491\n",
      "Iter-8470, train loss-2.2037, acc-0.3400, valid loss-2.2294, acc-0.2478, test loss-2.2264, acc-0.2490\n",
      "Iter-8480, train loss-2.2087, acc-0.3400, valid loss-2.2293, acc-0.2484, test loss-2.2263, acc-0.2489\n",
      "Iter-8490, train loss-2.2331, acc-0.2800, valid loss-2.2292, acc-0.2482, test loss-2.2262, acc-0.2499\n",
      "Iter-8500, train loss-2.2074, acc-0.3800, valid loss-2.2291, acc-0.2490, test loss-2.2262, acc-0.2491\n",
      "Iter-8510, train loss-2.2139, acc-0.3000, valid loss-2.2291, acc-0.2486, test loss-2.2261, acc-0.2495\n",
      "Iter-8520, train loss-2.2132, acc-0.3200, valid loss-2.2290, acc-0.2488, test loss-2.2260, acc-0.2498\n",
      "Iter-8530, train loss-2.2402, acc-0.1600, valid loss-2.2289, acc-0.2490, test loss-2.2259, acc-0.2501\n",
      "Iter-8540, train loss-2.2073, acc-0.2800, valid loss-2.2288, acc-0.2502, test loss-2.2258, acc-0.2502\n",
      "Iter-8550, train loss-2.2137, acc-0.3000, valid loss-2.2287, acc-0.2492, test loss-2.2257, acc-0.2504\n",
      "Iter-8560, train loss-2.2228, acc-0.1800, valid loss-2.2287, acc-0.2494, test loss-2.2257, acc-0.2508\n",
      "Iter-8570, train loss-2.2110, acc-0.2800, valid loss-2.2286, acc-0.2498, test loss-2.2256, acc-0.2510\n",
      "Iter-8580, train loss-2.2573, acc-0.2200, valid loss-2.2285, acc-0.2496, test loss-2.2255, acc-0.2512\n",
      "Iter-8590, train loss-2.2145, acc-0.3200, valid loss-2.2284, acc-0.2498, test loss-2.2254, acc-0.2512\n",
      "Iter-8600, train loss-2.2427, acc-0.1200, valid loss-2.2284, acc-0.2500, test loss-2.2253, acc-0.2517\n",
      "Iter-8610, train loss-2.2417, acc-0.2000, valid loss-2.2283, acc-0.2502, test loss-2.2253, acc-0.2518\n",
      "Iter-8620, train loss-2.2239, acc-0.2600, valid loss-2.2282, acc-0.2508, test loss-2.2252, acc-0.2524\n",
      "Iter-8630, train loss-2.2127, acc-0.3000, valid loss-2.2281, acc-0.2512, test loss-2.2251, acc-0.2523\n",
      "Iter-8640, train loss-2.2100, acc-0.2400, valid loss-2.2281, acc-0.2514, test loss-2.2250, acc-0.2523\n",
      "Iter-8650, train loss-2.2164, acc-0.3400, valid loss-2.2280, acc-0.2516, test loss-2.2249, acc-0.2524\n",
      "Iter-8660, train loss-2.2052, acc-0.3200, valid loss-2.2279, acc-0.2514, test loss-2.2249, acc-0.2524\n",
      "Iter-8670, train loss-2.2174, acc-0.2600, valid loss-2.2278, acc-0.2520, test loss-2.2248, acc-0.2526\n",
      "Iter-8680, train loss-2.1994, acc-0.3400, valid loss-2.2278, acc-0.2522, test loss-2.2247, acc-0.2528\n",
      "Iter-8690, train loss-2.2202, acc-0.2200, valid loss-2.2277, acc-0.2516, test loss-2.2246, acc-0.2530\n",
      "Iter-8700, train loss-2.2263, acc-0.2000, valid loss-2.2276, acc-0.2516, test loss-2.2245, acc-0.2531\n",
      "Iter-8710, train loss-2.2497, acc-0.2200, valid loss-2.2275, acc-0.2522, test loss-2.2244, acc-0.2532\n",
      "Iter-8720, train loss-2.2107, acc-0.2400, valid loss-2.2275, acc-0.2524, test loss-2.2244, acc-0.2533\n",
      "Iter-8730, train loss-2.2222, acc-0.2200, valid loss-2.2274, acc-0.2524, test loss-2.2243, acc-0.2533\n",
      "Iter-8740, train loss-2.2137, acc-0.2800, valid loss-2.2273, acc-0.2524, test loss-2.2242, acc-0.2534\n",
      "Iter-8750, train loss-2.2186, acc-0.2400, valid loss-2.2273, acc-0.2522, test loss-2.2241, acc-0.2540\n",
      "Iter-8760, train loss-2.1960, acc-0.3000, valid loss-2.2272, acc-0.2520, test loss-2.2240, acc-0.2540\n",
      "Iter-8770, train loss-2.2224, acc-0.2800, valid loss-2.2271, acc-0.2526, test loss-2.2240, acc-0.2542\n",
      "Iter-8780, train loss-2.2347, acc-0.2200, valid loss-2.2270, acc-0.2522, test loss-2.2239, acc-0.2544\n",
      "Iter-8790, train loss-2.2311, acc-0.2600, valid loss-2.2270, acc-0.2524, test loss-2.2238, acc-0.2543\n",
      "Iter-8800, train loss-2.2258, acc-0.2800, valid loss-2.2269, acc-0.2526, test loss-2.2237, acc-0.2546\n",
      "Iter-8810, train loss-2.2264, acc-0.2200, valid loss-2.2268, acc-0.2524, test loss-2.2236, acc-0.2546\n",
      "Iter-8820, train loss-2.2285, acc-0.2200, valid loss-2.2267, acc-0.2534, test loss-2.2236, acc-0.2546\n",
      "Iter-8830, train loss-2.2121, acc-0.2800, valid loss-2.2267, acc-0.2534, test loss-2.2235, acc-0.2550\n",
      "Iter-8840, train loss-2.2293, acc-0.1400, valid loss-2.2266, acc-0.2540, test loss-2.2234, acc-0.2550\n",
      "Iter-8850, train loss-2.1945, acc-0.3600, valid loss-2.2265, acc-0.2542, test loss-2.2233, acc-0.2553\n",
      "Iter-8860, train loss-2.2230, acc-0.3200, valid loss-2.2264, acc-0.2542, test loss-2.2232, acc-0.2557\n",
      "Iter-8870, train loss-2.2485, acc-0.1400, valid loss-2.2264, acc-0.2550, test loss-2.2231, acc-0.2558\n",
      "Iter-8880, train loss-2.2357, acc-0.2200, valid loss-2.2263, acc-0.2556, test loss-2.2231, acc-0.2559\n",
      "Iter-8890, train loss-2.2473, acc-0.2600, valid loss-2.2262, acc-0.2562, test loss-2.2230, acc-0.2559\n",
      "Iter-8900, train loss-2.2302, acc-0.2600, valid loss-2.2261, acc-0.2566, test loss-2.2229, acc-0.2562\n",
      "Iter-8910, train loss-2.2063, acc-0.3200, valid loss-2.2261, acc-0.2562, test loss-2.2228, acc-0.2566\n",
      "Iter-8920, train loss-2.2056, acc-0.2600, valid loss-2.2260, acc-0.2560, test loss-2.2227, acc-0.2569\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8930, train loss-2.2502, acc-0.1800, valid loss-2.2259, acc-0.2566, test loss-2.2227, acc-0.2570\n",
      "Iter-8940, train loss-2.2200, acc-0.2200, valid loss-2.2259, acc-0.2560, test loss-2.2226, acc-0.2569\n",
      "Iter-8950, train loss-2.2122, acc-0.2800, valid loss-2.2258, acc-0.2564, test loss-2.2225, acc-0.2573\n",
      "Iter-8960, train loss-2.2209, acc-0.3200, valid loss-2.2257, acc-0.2564, test loss-2.2224, acc-0.2575\n",
      "Iter-8970, train loss-2.2392, acc-0.3200, valid loss-2.2256, acc-0.2560, test loss-2.2223, acc-0.2572\n",
      "Iter-8980, train loss-2.2393, acc-0.1800, valid loss-2.2255, acc-0.2566, test loss-2.2222, acc-0.2576\n",
      "Iter-8990, train loss-2.1918, acc-0.3600, valid loss-2.2255, acc-0.2566, test loss-2.2222, acc-0.2580\n",
      "Iter-9000, train loss-2.2623, acc-0.2000, valid loss-2.2254, acc-0.2562, test loss-2.2221, acc-0.2581\n",
      "Iter-9010, train loss-2.2345, acc-0.2200, valid loss-2.2253, acc-0.2564, test loss-2.2220, acc-0.2583\n",
      "Iter-9020, train loss-2.2236, acc-0.2000, valid loss-2.2252, acc-0.2564, test loss-2.2219, acc-0.2586\n",
      "Iter-9030, train loss-2.2277, acc-0.2600, valid loss-2.2252, acc-0.2564, test loss-2.2218, acc-0.2589\n",
      "Iter-9040, train loss-2.2168, acc-0.2600, valid loss-2.2251, acc-0.2570, test loss-2.2217, acc-0.2591\n",
      "Iter-9050, train loss-2.2526, acc-0.2000, valid loss-2.2250, acc-0.2580, test loss-2.2217, acc-0.2593\n",
      "Iter-9060, train loss-2.2141, acc-0.3000, valid loss-2.2249, acc-0.2582, test loss-2.2216, acc-0.2597\n",
      "Iter-9070, train loss-2.2096, acc-0.3400, valid loss-2.2249, acc-0.2584, test loss-2.2215, acc-0.2597\n",
      "Iter-9080, train loss-2.2382, acc-0.2600, valid loss-2.2248, acc-0.2582, test loss-2.2214, acc-0.2598\n",
      "Iter-9090, train loss-2.2334, acc-0.2200, valid loss-2.2247, acc-0.2588, test loss-2.2213, acc-0.2601\n",
      "Iter-9100, train loss-2.2097, acc-0.2400, valid loss-2.2246, acc-0.2584, test loss-2.2213, acc-0.2599\n",
      "Iter-9110, train loss-2.2292, acc-0.2200, valid loss-2.2246, acc-0.2588, test loss-2.2212, acc-0.2601\n",
      "Iter-9120, train loss-2.2161, acc-0.3000, valid loss-2.2245, acc-0.2586, test loss-2.2211, acc-0.2602\n",
      "Iter-9130, train loss-2.2370, acc-0.1800, valid loss-2.2244, acc-0.2596, test loss-2.2210, acc-0.2609\n",
      "Iter-9140, train loss-2.2275, acc-0.2200, valid loss-2.2244, acc-0.2596, test loss-2.2209, acc-0.2609\n",
      "Iter-9150, train loss-2.2552, acc-0.2200, valid loss-2.2243, acc-0.2594, test loss-2.2209, acc-0.2610\n",
      "Iter-9160, train loss-2.2332, acc-0.2400, valid loss-2.2242, acc-0.2600, test loss-2.2208, acc-0.2608\n",
      "Iter-9170, train loss-2.2105, acc-0.2200, valid loss-2.2241, acc-0.2602, test loss-2.2207, acc-0.2614\n",
      "Iter-9180, train loss-2.2100, acc-0.2400, valid loss-2.2241, acc-0.2604, test loss-2.2206, acc-0.2613\n",
      "Iter-9190, train loss-2.2348, acc-0.3000, valid loss-2.2240, acc-0.2600, test loss-2.2205, acc-0.2616\n",
      "Iter-9200, train loss-2.2131, acc-0.3400, valid loss-2.2239, acc-0.2602, test loss-2.2205, acc-0.2627\n",
      "Iter-9210, train loss-2.2460, acc-0.2600, valid loss-2.2239, acc-0.2600, test loss-2.2204, acc-0.2622\n",
      "Iter-9220, train loss-2.2459, acc-0.1000, valid loss-2.2238, acc-0.2608, test loss-2.2203, acc-0.2621\n",
      "Iter-9230, train loss-2.2152, acc-0.3200, valid loss-2.2237, acc-0.2614, test loss-2.2202, acc-0.2623\n",
      "Iter-9240, train loss-2.2445, acc-0.2600, valid loss-2.2236, acc-0.2612, test loss-2.2201, acc-0.2629\n",
      "Iter-9250, train loss-2.2130, acc-0.2400, valid loss-2.2236, acc-0.2616, test loss-2.2201, acc-0.2628\n",
      "Iter-9260, train loss-2.2389, acc-0.1600, valid loss-2.2235, acc-0.2620, test loss-2.2200, acc-0.2629\n",
      "Iter-9270, train loss-2.2193, acc-0.2000, valid loss-2.2234, acc-0.2618, test loss-2.2199, acc-0.2632\n",
      "Iter-9280, train loss-2.2036, acc-0.3000, valid loss-2.2233, acc-0.2622, test loss-2.2198, acc-0.2636\n",
      "Iter-9290, train loss-2.2532, acc-0.1600, valid loss-2.2233, acc-0.2620, test loss-2.2197, acc-0.2639\n",
      "Iter-9300, train loss-2.2164, acc-0.3000, valid loss-2.2232, acc-0.2626, test loss-2.2196, acc-0.2640\n",
      "Iter-9310, train loss-2.2212, acc-0.2600, valid loss-2.2231, acc-0.2626, test loss-2.2196, acc-0.2641\n",
      "Iter-9320, train loss-2.2165, acc-0.2400, valid loss-2.2230, acc-0.2634, test loss-2.2195, acc-0.2642\n",
      "Iter-9330, train loss-2.2170, acc-0.2400, valid loss-2.2230, acc-0.2642, test loss-2.2194, acc-0.2643\n",
      "Iter-9340, train loss-2.2381, acc-0.2000, valid loss-2.2229, acc-0.2646, test loss-2.2193, acc-0.2646\n",
      "Iter-9350, train loss-2.2177, acc-0.2200, valid loss-2.2228, acc-0.2648, test loss-2.2192, acc-0.2651\n",
      "Iter-9360, train loss-2.2484, acc-0.2200, valid loss-2.2227, acc-0.2646, test loss-2.2192, acc-0.2649\n",
      "Iter-9370, train loss-2.2259, acc-0.3000, valid loss-2.2227, acc-0.2648, test loss-2.2191, acc-0.2653\n",
      "Iter-9380, train loss-2.2261, acc-0.1800, valid loss-2.2226, acc-0.2650, test loss-2.2190, acc-0.2656\n",
      "Iter-9390, train loss-2.2377, acc-0.2800, valid loss-2.2225, acc-0.2656, test loss-2.2189, acc-0.2659\n",
      "Iter-9400, train loss-2.2266, acc-0.3600, valid loss-2.2225, acc-0.2654, test loss-2.2188, acc-0.2657\n",
      "Iter-9410, train loss-2.1969, acc-0.3600, valid loss-2.2224, acc-0.2656, test loss-2.2188, acc-0.2660\n",
      "Iter-9420, train loss-2.2444, acc-0.2200, valid loss-2.2223, acc-0.2652, test loss-2.2187, acc-0.2661\n",
      "Iter-9430, train loss-2.2380, acc-0.2000, valid loss-2.2222, acc-0.2658, test loss-2.2186, acc-0.2665\n",
      "Iter-9440, train loss-2.2281, acc-0.1800, valid loss-2.2222, acc-0.2662, test loss-2.2185, acc-0.2668\n",
      "Iter-9450, train loss-2.2258, acc-0.3400, valid loss-2.2221, acc-0.2662, test loss-2.2185, acc-0.2666\n",
      "Iter-9460, train loss-2.1950, acc-0.3000, valid loss-2.2220, acc-0.2662, test loss-2.2184, acc-0.2669\n",
      "Iter-9470, train loss-2.2177, acc-0.3200, valid loss-2.2220, acc-0.2658, test loss-2.2183, acc-0.2671\n",
      "Iter-9480, train loss-2.2241, acc-0.2200, valid loss-2.2219, acc-0.2662, test loss-2.2182, acc-0.2673\n",
      "Iter-9490, train loss-2.2272, acc-0.1800, valid loss-2.2218, acc-0.2662, test loss-2.2181, acc-0.2673\n",
      "Iter-9500, train loss-2.2216, acc-0.3200, valid loss-2.2217, acc-0.2664, test loss-2.2181, acc-0.2676\n",
      "Iter-9510, train loss-2.2412, acc-0.2800, valid loss-2.2217, acc-0.2668, test loss-2.2180, acc-0.2677\n",
      "Iter-9520, train loss-2.2465, acc-0.2400, valid loss-2.2216, acc-0.2668, test loss-2.2179, acc-0.2681\n",
      "Iter-9530, train loss-2.2139, acc-0.2200, valid loss-2.2215, acc-0.2674, test loss-2.2178, acc-0.2687\n",
      "Iter-9540, train loss-2.2271, acc-0.3400, valid loss-2.2215, acc-0.2670, test loss-2.2177, acc-0.2686\n",
      "Iter-9550, train loss-2.2360, acc-0.3200, valid loss-2.2214, acc-0.2668, test loss-2.2177, acc-0.2688\n",
      "Iter-9560, train loss-2.2154, acc-0.3200, valid loss-2.2213, acc-0.2670, test loss-2.2176, acc-0.2691\n",
      "Iter-9570, train loss-2.2363, acc-0.2200, valid loss-2.2212, acc-0.2672, test loss-2.2175, acc-0.2691\n",
      "Iter-9580, train loss-2.2106, acc-0.3200, valid loss-2.2212, acc-0.2674, test loss-2.2174, acc-0.2696\n",
      "Iter-9590, train loss-2.2588, acc-0.2200, valid loss-2.2211, acc-0.2678, test loss-2.2173, acc-0.2697\n",
      "Iter-9600, train loss-2.2224, acc-0.2400, valid loss-2.2210, acc-0.2678, test loss-2.2172, acc-0.2701\n",
      "Iter-9610, train loss-2.2232, acc-0.3400, valid loss-2.2210, acc-0.2678, test loss-2.2172, acc-0.2703\n",
      "Iter-9620, train loss-2.1973, acc-0.3000, valid loss-2.2209, acc-0.2676, test loss-2.2171, acc-0.2702\n",
      "Iter-9630, train loss-2.2142, acc-0.2600, valid loss-2.2208, acc-0.2680, test loss-2.2170, acc-0.2702\n",
      "Iter-9640, train loss-2.2353, acc-0.1200, valid loss-2.2207, acc-0.2680, test loss-2.2169, acc-0.2704\n",
      "Iter-9650, train loss-2.2062, acc-0.3800, valid loss-2.2207, acc-0.2680, test loss-2.2168, acc-0.2704\n",
      "Iter-9660, train loss-2.2323, acc-0.2600, valid loss-2.2206, acc-0.2684, test loss-2.2168, acc-0.2710\n",
      "Iter-9670, train loss-2.2328, acc-0.2800, valid loss-2.2205, acc-0.2684, test loss-2.2167, acc-0.2712\n",
      "Iter-9680, train loss-2.2331, acc-0.2400, valid loss-2.2204, acc-0.2684, test loss-2.2166, acc-0.2710\n",
      "Iter-9690, train loss-2.2453, acc-0.2000, valid loss-2.2204, acc-0.2684, test loss-2.2165, acc-0.2713\n",
      "Iter-9700, train loss-2.2364, acc-0.2200, valid loss-2.2203, acc-0.2684, test loss-2.2164, acc-0.2715\n",
      "Iter-9710, train loss-2.2357, acc-0.2800, valid loss-2.2202, acc-0.2684, test loss-2.2164, acc-0.2715\n",
      "Iter-9720, train loss-2.1980, acc-0.3400, valid loss-2.2202, acc-0.2686, test loss-2.2163, acc-0.2719\n",
      "Iter-9730, train loss-2.2529, acc-0.1800, valid loss-2.2201, acc-0.2684, test loss-2.2162, acc-0.2718\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-9740, train loss-2.1969, acc-0.2400, valid loss-2.2200, acc-0.2684, test loss-2.2161, acc-0.2721\n",
      "Iter-9750, train loss-2.2167, acc-0.3400, valid loss-2.2199, acc-0.2688, test loss-2.2160, acc-0.2720\n",
      "Iter-9760, train loss-2.2126, acc-0.2400, valid loss-2.2199, acc-0.2690, test loss-2.2159, acc-0.2724\n",
      "Iter-9770, train loss-2.2531, acc-0.1400, valid loss-2.2198, acc-0.2690, test loss-2.2159, acc-0.2728\n",
      "Iter-9780, train loss-2.2152, acc-0.3000, valid loss-2.2197, acc-0.2696, test loss-2.2158, acc-0.2729\n",
      "Iter-9790, train loss-2.2447, acc-0.2200, valid loss-2.2196, acc-0.2694, test loss-2.2157, acc-0.2733\n",
      "Iter-9800, train loss-2.2461, acc-0.2200, valid loss-2.2196, acc-0.2700, test loss-2.2156, acc-0.2732\n",
      "Iter-9810, train loss-2.2422, acc-0.1400, valid loss-2.2195, acc-0.2694, test loss-2.2156, acc-0.2734\n",
      "Iter-9820, train loss-2.2232, acc-0.2400, valid loss-2.2194, acc-0.2700, test loss-2.2155, acc-0.2741\n",
      "Iter-9830, train loss-2.2194, acc-0.2600, valid loss-2.2194, acc-0.2706, test loss-2.2154, acc-0.2740\n",
      "Iter-9840, train loss-2.1730, acc-0.4200, valid loss-2.2193, acc-0.2704, test loss-2.2153, acc-0.2736\n",
      "Iter-9850, train loss-2.2191, acc-0.2200, valid loss-2.2192, acc-0.2704, test loss-2.2152, acc-0.2741\n",
      "Iter-9860, train loss-2.2236, acc-0.2600, valid loss-2.2191, acc-0.2704, test loss-2.2152, acc-0.2739\n",
      "Iter-9870, train loss-2.2276, acc-0.3000, valid loss-2.2191, acc-0.2710, test loss-2.2151, acc-0.2740\n",
      "Iter-9880, train loss-2.1963, acc-0.3600, valid loss-2.2190, acc-0.2714, test loss-2.2150, acc-0.2742\n",
      "Iter-9890, train loss-2.1923, acc-0.3000, valid loss-2.2189, acc-0.2708, test loss-2.2149, acc-0.2743\n",
      "Iter-9900, train loss-2.1905, acc-0.3800, valid loss-2.2188, acc-0.2712, test loss-2.2148, acc-0.2744\n",
      "Iter-9910, train loss-2.2346, acc-0.3400, valid loss-2.2188, acc-0.2716, test loss-2.2147, acc-0.2747\n",
      "Iter-9920, train loss-2.2392, acc-0.2000, valid loss-2.2187, acc-0.2712, test loss-2.2147, acc-0.2752\n",
      "Iter-9930, train loss-2.2577, acc-0.1600, valid loss-2.2186, acc-0.2708, test loss-2.2146, acc-0.2751\n",
      "Iter-9940, train loss-2.2321, acc-0.3200, valid loss-2.2185, acc-0.2710, test loss-2.2145, acc-0.2754\n",
      "Iter-9950, train loss-2.2369, acc-0.2600, valid loss-2.2185, acc-0.2716, test loss-2.2144, acc-0.2751\n",
      "Iter-9960, train loss-2.2186, acc-0.2800, valid loss-2.2184, acc-0.2710, test loss-2.2143, acc-0.2756\n",
      "Iter-9970, train loss-2.2333, acc-0.2600, valid loss-2.2183, acc-0.2718, test loss-2.2143, acc-0.2758\n",
      "Iter-9980, train loss-2.2104, acc-0.3000, valid loss-2.2182, acc-0.2722, test loss-2.2142, acc-0.2757\n",
      "Iter-9990, train loss-2.2030, acc-0.2400, valid loss-2.2182, acc-0.2730, test loss-2.2141, acc-0.2761\n",
      "Iter-10000, train loss-2.1949, acc-0.3400, valid loss-2.2181, acc-0.2732, test loss-2.2140, acc-0.2761\n",
      "Iter-10010, train loss-2.2244, acc-0.2400, valid loss-2.2180, acc-0.2738, test loss-2.2139, acc-0.2762\n",
      "Iter-10020, train loss-2.2070, acc-0.2400, valid loss-2.2180, acc-0.2744, test loss-2.2139, acc-0.2761\n",
      "Iter-10030, train loss-2.2403, acc-0.1800, valid loss-2.2179, acc-0.2746, test loss-2.2138, acc-0.2762\n",
      "Iter-10040, train loss-2.2230, acc-0.1600, valid loss-2.2178, acc-0.2750, test loss-2.2137, acc-0.2765\n",
      "Iter-10050, train loss-2.2382, acc-0.2600, valid loss-2.2177, acc-0.2750, test loss-2.2136, acc-0.2766\n",
      "Iter-10060, train loss-2.2133, acc-0.2000, valid loss-2.2177, acc-0.2754, test loss-2.2136, acc-0.2770\n",
      "Iter-10070, train loss-2.2292, acc-0.3200, valid loss-2.2176, acc-0.2758, test loss-2.2135, acc-0.2772\n",
      "Iter-10080, train loss-2.2381, acc-0.2400, valid loss-2.2175, acc-0.2756, test loss-2.2134, acc-0.2774\n",
      "Iter-10090, train loss-2.2426, acc-0.2400, valid loss-2.2175, acc-0.2760, test loss-2.2133, acc-0.2780\n",
      "Iter-10100, train loss-2.2321, acc-0.3000, valid loss-2.2174, acc-0.2758, test loss-2.2132, acc-0.2782\n",
      "Iter-10110, train loss-2.2301, acc-0.2000, valid loss-2.2173, acc-0.2760, test loss-2.2132, acc-0.2783\n",
      "Iter-10120, train loss-2.1877, acc-0.3200, valid loss-2.2172, acc-0.2756, test loss-2.2131, acc-0.2784\n",
      "Iter-10130, train loss-2.1951, acc-0.3600, valid loss-2.2172, acc-0.2758, test loss-2.2130, acc-0.2782\n",
      "Iter-10140, train loss-2.2127, acc-0.2200, valid loss-2.2171, acc-0.2762, test loss-2.2129, acc-0.2786\n",
      "Iter-10150, train loss-2.2291, acc-0.2800, valid loss-2.2170, acc-0.2766, test loss-2.2129, acc-0.2788\n",
      "Iter-10160, train loss-2.2476, acc-0.2200, valid loss-2.2170, acc-0.2768, test loss-2.2128, acc-0.2790\n",
      "Iter-10170, train loss-2.1970, acc-0.2800, valid loss-2.2169, acc-0.2768, test loss-2.2127, acc-0.2790\n",
      "Iter-10180, train loss-2.2085, acc-0.3600, valid loss-2.2168, acc-0.2772, test loss-2.2126, acc-0.2796\n",
      "Iter-10190, train loss-2.2197, acc-0.3000, valid loss-2.2167, acc-0.2774, test loss-2.2125, acc-0.2795\n",
      "Iter-10200, train loss-2.2037, acc-0.3400, valid loss-2.2167, acc-0.2772, test loss-2.2124, acc-0.2797\n",
      "Iter-10210, train loss-2.2188, acc-0.2600, valid loss-2.2166, acc-0.2772, test loss-2.2124, acc-0.2799\n",
      "Iter-10220, train loss-2.2212, acc-0.2800, valid loss-2.2165, acc-0.2770, test loss-2.2123, acc-0.2801\n",
      "Iter-10230, train loss-2.2306, acc-0.1600, valid loss-2.2165, acc-0.2772, test loss-2.2122, acc-0.2803\n",
      "Iter-10240, train loss-2.2354, acc-0.2400, valid loss-2.2164, acc-0.2774, test loss-2.2121, acc-0.2803\n",
      "Iter-10250, train loss-2.2341, acc-0.2200, valid loss-2.2163, acc-0.2774, test loss-2.2121, acc-0.2810\n",
      "Iter-10260, train loss-2.2153, acc-0.2800, valid loss-2.2162, acc-0.2774, test loss-2.2120, acc-0.2811\n",
      "Iter-10270, train loss-2.2068, acc-0.3000, valid loss-2.2162, acc-0.2774, test loss-2.2119, acc-0.2812\n",
      "Iter-10280, train loss-2.2022, acc-0.3000, valid loss-2.2161, acc-0.2776, test loss-2.2118, acc-0.2814\n",
      "Iter-10290, train loss-2.1964, acc-0.3400, valid loss-2.2160, acc-0.2780, test loss-2.2118, acc-0.2816\n",
      "Iter-10300, train loss-2.2141, acc-0.3000, valid loss-2.2160, acc-0.2780, test loss-2.2117, acc-0.2819\n",
      "Iter-10310, train loss-2.2323, acc-0.2200, valid loss-2.2159, acc-0.2782, test loss-2.2116, acc-0.2824\n",
      "Iter-10320, train loss-2.2241, acc-0.3000, valid loss-2.2158, acc-0.2780, test loss-2.2115, acc-0.2820\n",
      "Iter-10330, train loss-2.1852, acc-0.3200, valid loss-2.2157, acc-0.2782, test loss-2.2114, acc-0.2821\n",
      "Iter-10340, train loss-2.2089, acc-0.2800, valid loss-2.2157, acc-0.2780, test loss-2.2114, acc-0.2821\n",
      "Iter-10350, train loss-2.2158, acc-0.3000, valid loss-2.2156, acc-0.2786, test loss-2.2113, acc-0.2826\n",
      "Iter-10360, train loss-2.2283, acc-0.3000, valid loss-2.2155, acc-0.2782, test loss-2.2112, acc-0.2829\n",
      "Iter-10370, train loss-2.2013, acc-0.3400, valid loss-2.2155, acc-0.2780, test loss-2.2111, acc-0.2830\n",
      "Iter-10380, train loss-2.2551, acc-0.2600, valid loss-2.2154, acc-0.2782, test loss-2.2110, acc-0.2833\n",
      "Iter-10390, train loss-2.2003, acc-0.3600, valid loss-2.2153, acc-0.2786, test loss-2.2110, acc-0.2837\n",
      "Iter-10400, train loss-2.2051, acc-0.3000, valid loss-2.2152, acc-0.2792, test loss-2.2109, acc-0.2835\n",
      "Iter-10410, train loss-2.2130, acc-0.2800, valid loss-2.2152, acc-0.2794, test loss-2.2108, acc-0.2839\n",
      "Iter-10420, train loss-2.2007, acc-0.3200, valid loss-2.2151, acc-0.2792, test loss-2.2107, acc-0.2839\n",
      "Iter-10430, train loss-2.2284, acc-0.2800, valid loss-2.2150, acc-0.2796, test loss-2.2106, acc-0.2844\n",
      "Iter-10440, train loss-2.2133, acc-0.2200, valid loss-2.2150, acc-0.2798, test loss-2.2106, acc-0.2846\n",
      "Iter-10450, train loss-2.2044, acc-0.1800, valid loss-2.2149, acc-0.2800, test loss-2.2105, acc-0.2849\n",
      "Iter-10460, train loss-2.2021, acc-0.3200, valid loss-2.2148, acc-0.2798, test loss-2.2104, acc-0.2847\n",
      "Iter-10470, train loss-2.2111, acc-0.3400, valid loss-2.2148, acc-0.2800, test loss-2.2103, acc-0.2854\n",
      "Iter-10480, train loss-2.2135, acc-0.2000, valid loss-2.2147, acc-0.2804, test loss-2.2102, acc-0.2857\n",
      "Iter-10490, train loss-2.2220, acc-0.1600, valid loss-2.2146, acc-0.2802, test loss-2.2102, acc-0.2858\n",
      "Iter-10500, train loss-2.2238, acc-0.2400, valid loss-2.2145, acc-0.2802, test loss-2.2101, acc-0.2856\n",
      "Iter-10510, train loss-2.2403, acc-0.2000, valid loss-2.2145, acc-0.2800, test loss-2.2100, acc-0.2857\n",
      "Iter-10520, train loss-2.2343, acc-0.1600, valid loss-2.2144, acc-0.2804, test loss-2.2099, acc-0.2860\n",
      "Iter-10530, train loss-2.2287, acc-0.2400, valid loss-2.2143, acc-0.2802, test loss-2.2099, acc-0.2859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10540, train loss-2.2264, acc-0.3000, valid loss-2.2142, acc-0.2800, test loss-2.2098, acc-0.2861\n",
      "Iter-10550, train loss-2.2115, acc-0.2200, valid loss-2.2142, acc-0.2798, test loss-2.2097, acc-0.2862\n",
      "Iter-10560, train loss-2.1784, acc-0.3800, valid loss-2.2141, acc-0.2806, test loss-2.2096, acc-0.2866\n",
      "Iter-10570, train loss-2.2042, acc-0.3000, valid loss-2.2140, acc-0.2804, test loss-2.2096, acc-0.2866\n",
      "Iter-10580, train loss-2.2099, acc-0.3200, valid loss-2.2140, acc-0.2808, test loss-2.2095, acc-0.2867\n",
      "Iter-10590, train loss-2.2053, acc-0.3600, valid loss-2.2139, acc-0.2810, test loss-2.2094, acc-0.2875\n",
      "Iter-10600, train loss-2.2167, acc-0.2600, valid loss-2.2138, acc-0.2810, test loss-2.2093, acc-0.2874\n",
      "Iter-10610, train loss-2.2220, acc-0.2000, valid loss-2.2137, acc-0.2812, test loss-2.2092, acc-0.2875\n",
      "Iter-10620, train loss-2.2222, acc-0.3400, valid loss-2.2137, acc-0.2814, test loss-2.2092, acc-0.2883\n",
      "Iter-10630, train loss-2.1943, acc-0.2400, valid loss-2.2136, acc-0.2814, test loss-2.2091, acc-0.2880\n",
      "Iter-10640, train loss-2.2082, acc-0.3600, valid loss-2.2135, acc-0.2818, test loss-2.2090, acc-0.2880\n",
      "Iter-10650, train loss-2.2024, acc-0.3000, valid loss-2.2134, acc-0.2824, test loss-2.2089, acc-0.2882\n",
      "Iter-10660, train loss-2.2127, acc-0.1800, valid loss-2.2134, acc-0.2828, test loss-2.2088, acc-0.2885\n",
      "Iter-10670, train loss-2.2249, acc-0.2000, valid loss-2.2133, acc-0.2828, test loss-2.2088, acc-0.2884\n",
      "Iter-10680, train loss-2.2056, acc-0.2800, valid loss-2.2132, acc-0.2832, test loss-2.2087, acc-0.2886\n",
      "Iter-10690, train loss-2.2167, acc-0.3200, valid loss-2.2131, acc-0.2832, test loss-2.2086, acc-0.2886\n",
      "Iter-10700, train loss-2.2239, acc-0.2800, valid loss-2.2131, acc-0.2832, test loss-2.2085, acc-0.2888\n",
      "Iter-10710, train loss-2.2242, acc-0.2200, valid loss-2.2130, acc-0.2834, test loss-2.2084, acc-0.2886\n",
      "Iter-10720, train loss-2.2201, acc-0.2800, valid loss-2.2129, acc-0.2832, test loss-2.2084, acc-0.2891\n",
      "Iter-10730, train loss-2.2165, acc-0.3200, valid loss-2.2129, acc-0.2832, test loss-2.2083, acc-0.2893\n",
      "Iter-10740, train loss-2.2183, acc-0.2800, valid loss-2.2128, acc-0.2836, test loss-2.2082, acc-0.2894\n",
      "Iter-10750, train loss-2.1932, acc-0.3000, valid loss-2.2127, acc-0.2836, test loss-2.2081, acc-0.2895\n",
      "Iter-10760, train loss-2.2075, acc-0.4400, valid loss-2.2127, acc-0.2838, test loss-2.2080, acc-0.2894\n",
      "Iter-10770, train loss-2.2177, acc-0.3200, valid loss-2.2126, acc-0.2832, test loss-2.2080, acc-0.2895\n",
      "Iter-10780, train loss-2.2422, acc-0.1800, valid loss-2.2125, acc-0.2844, test loss-2.2079, acc-0.2895\n",
      "Iter-10790, train loss-2.2267, acc-0.2600, valid loss-2.2124, acc-0.2846, test loss-2.2078, acc-0.2899\n",
      "Iter-10800, train loss-2.2321, acc-0.2400, valid loss-2.2124, acc-0.2848, test loss-2.2077, acc-0.2897\n",
      "Iter-10810, train loss-2.2115, acc-0.2000, valid loss-2.2123, acc-0.2850, test loss-2.2077, acc-0.2903\n",
      "Iter-10820, train loss-2.2166, acc-0.3000, valid loss-2.2122, acc-0.2848, test loss-2.2076, acc-0.2903\n",
      "Iter-10830, train loss-2.1865, acc-0.3600, valid loss-2.2122, acc-0.2846, test loss-2.2075, acc-0.2905\n",
      "Iter-10840, train loss-2.2166, acc-0.2200, valid loss-2.2121, acc-0.2850, test loss-2.2074, acc-0.2909\n",
      "Iter-10850, train loss-2.2244, acc-0.3000, valid loss-2.2120, acc-0.2850, test loss-2.2073, acc-0.2906\n",
      "Iter-10860, train loss-2.2223, acc-0.1600, valid loss-2.2119, acc-0.2848, test loss-2.2073, acc-0.2911\n",
      "Iter-10870, train loss-2.2126, acc-0.3200, valid loss-2.2119, acc-0.2850, test loss-2.2072, acc-0.2913\n",
      "Iter-10880, train loss-2.1879, acc-0.3000, valid loss-2.2118, acc-0.2850, test loss-2.2071, acc-0.2915\n",
      "Iter-10890, train loss-2.1843, acc-0.4200, valid loss-2.2117, acc-0.2852, test loss-2.2070, acc-0.2918\n",
      "Iter-10900, train loss-2.1936, acc-0.3000, valid loss-2.2117, acc-0.2858, test loss-2.2069, acc-0.2919\n",
      "Iter-10910, train loss-2.2053, acc-0.2600, valid loss-2.2116, acc-0.2856, test loss-2.2069, acc-0.2919\n",
      "Iter-10920, train loss-2.1910, acc-0.3000, valid loss-2.2115, acc-0.2858, test loss-2.2068, acc-0.2925\n",
      "Iter-10930, train loss-2.1520, acc-0.4000, valid loss-2.2114, acc-0.2864, test loss-2.2067, acc-0.2928\n",
      "Iter-10940, train loss-2.2263, acc-0.3200, valid loss-2.2114, acc-0.2868, test loss-2.2066, acc-0.2928\n",
      "Iter-10950, train loss-2.2000, acc-0.2200, valid loss-2.2113, acc-0.2866, test loss-2.2065, acc-0.2930\n",
      "Iter-10960, train loss-2.1952, acc-0.3200, valid loss-2.2112, acc-0.2862, test loss-2.2065, acc-0.2932\n",
      "Iter-10970, train loss-2.2066, acc-0.2400, valid loss-2.2111, acc-0.2870, test loss-2.2064, acc-0.2928\n",
      "Iter-10980, train loss-2.2182, acc-0.3600, valid loss-2.2111, acc-0.2870, test loss-2.2063, acc-0.2928\n",
      "Iter-10990, train loss-2.2281, acc-0.3200, valid loss-2.2110, acc-0.2876, test loss-2.2062, acc-0.2931\n",
      "Iter-11000, train loss-2.2208, acc-0.2600, valid loss-2.2109, acc-0.2884, test loss-2.2061, acc-0.2930\n",
      "Iter-11010, train loss-2.2234, acc-0.2200, valid loss-2.2108, acc-0.2886, test loss-2.2061, acc-0.2932\n",
      "Iter-11020, train loss-2.2128, acc-0.2600, valid loss-2.2108, acc-0.2888, test loss-2.2060, acc-0.2933\n",
      "Iter-11030, train loss-2.2072, acc-0.2600, valid loss-2.2107, acc-0.2886, test loss-2.2059, acc-0.2934\n",
      "Iter-11040, train loss-2.2193, acc-0.2400, valid loss-2.2106, acc-0.2884, test loss-2.2058, acc-0.2938\n",
      "Iter-11050, train loss-2.2221, acc-0.2600, valid loss-2.2106, acc-0.2884, test loss-2.2057, acc-0.2944\n",
      "Iter-11060, train loss-2.2157, acc-0.3200, valid loss-2.2105, acc-0.2890, test loss-2.2057, acc-0.2944\n",
      "Iter-11070, train loss-2.1861, acc-0.3600, valid loss-2.2104, acc-0.2888, test loss-2.2056, acc-0.2946\n",
      "Iter-11080, train loss-2.2279, acc-0.3600, valid loss-2.2103, acc-0.2890, test loss-2.2055, acc-0.2949\n",
      "Iter-11090, train loss-2.2065, acc-0.2800, valid loss-2.2103, acc-0.2888, test loss-2.2054, acc-0.2943\n",
      "Iter-11100, train loss-2.2015, acc-0.2800, valid loss-2.2102, acc-0.2888, test loss-2.2054, acc-0.2946\n",
      "Iter-11110, train loss-2.2026, acc-0.2400, valid loss-2.2101, acc-0.2888, test loss-2.2053, acc-0.2947\n",
      "Iter-11120, train loss-2.2028, acc-0.3200, valid loss-2.2101, acc-0.2888, test loss-2.2052, acc-0.2950\n",
      "Iter-11130, train loss-2.1990, acc-0.2800, valid loss-2.2100, acc-0.2894, test loss-2.2051, acc-0.2947\n",
      "Iter-11140, train loss-2.2228, acc-0.2400, valid loss-2.2099, acc-0.2896, test loss-2.2050, acc-0.2948\n",
      "Iter-11150, train loss-2.2179, acc-0.3200, valid loss-2.2098, acc-0.2898, test loss-2.2049, acc-0.2948\n",
      "Iter-11160, train loss-2.1915, acc-0.3000, valid loss-2.2098, acc-0.2898, test loss-2.2049, acc-0.2948\n",
      "Iter-11170, train loss-2.1941, acc-0.3800, valid loss-2.2097, acc-0.2902, test loss-2.2048, acc-0.2952\n",
      "Iter-11180, train loss-2.1880, acc-0.4000, valid loss-2.2096, acc-0.2900, test loss-2.2047, acc-0.2955\n",
      "Iter-11190, train loss-2.2056, acc-0.2600, valid loss-2.2095, acc-0.2906, test loss-2.2046, acc-0.2957\n",
      "Iter-11200, train loss-2.2206, acc-0.3000, valid loss-2.2094, acc-0.2910, test loss-2.2045, acc-0.2959\n",
      "Iter-11210, train loss-2.1906, acc-0.3200, valid loss-2.2094, acc-0.2912, test loss-2.2045, acc-0.2961\n",
      "Iter-11220, train loss-2.2224, acc-0.3000, valid loss-2.2093, acc-0.2920, test loss-2.2044, acc-0.2965\n",
      "Iter-11230, train loss-2.2072, acc-0.3400, valid loss-2.2092, acc-0.2922, test loss-2.2043, acc-0.2965\n",
      "Iter-11240, train loss-2.2212, acc-0.2600, valid loss-2.2092, acc-0.2918, test loss-2.2042, acc-0.2965\n",
      "Iter-11250, train loss-2.2059, acc-0.2600, valid loss-2.2091, acc-0.2918, test loss-2.2041, acc-0.2963\n",
      "Iter-11260, train loss-2.2035, acc-0.3000, valid loss-2.2090, acc-0.2918, test loss-2.2041, acc-0.2964\n",
      "Iter-11270, train loss-2.1953, acc-0.3800, valid loss-2.2089, acc-0.2924, test loss-2.2040, acc-0.2970\n",
      "Iter-11280, train loss-2.1937, acc-0.3800, valid loss-2.2089, acc-0.2928, test loss-2.2039, acc-0.2967\n",
      "Iter-11290, train loss-2.1974, acc-0.3600, valid loss-2.2088, acc-0.2926, test loss-2.2038, acc-0.2969\n",
      "Iter-11300, train loss-2.1884, acc-0.3800, valid loss-2.2087, acc-0.2928, test loss-2.2038, acc-0.2968\n",
      "Iter-11310, train loss-2.2245, acc-0.3000, valid loss-2.2087, acc-0.2928, test loss-2.2037, acc-0.2974\n",
      "Iter-11320, train loss-2.1767, acc-0.3400, valid loss-2.2086, acc-0.2930, test loss-2.2036, acc-0.2975\n",
      "Iter-11330, train loss-2.2191, acc-0.2200, valid loss-2.2085, acc-0.2932, test loss-2.2035, acc-0.2973\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-11340, train loss-2.2050, acc-0.2200, valid loss-2.2085, acc-0.2922, test loss-2.2034, acc-0.2973\n",
      "Iter-11350, train loss-2.2065, acc-0.3400, valid loss-2.2084, acc-0.2926, test loss-2.2034, acc-0.2976\n",
      "Iter-11360, train loss-2.2166, acc-0.3200, valid loss-2.2083, acc-0.2928, test loss-2.2033, acc-0.2978\n",
      "Iter-11370, train loss-2.2000, acc-0.2800, valid loss-2.2083, acc-0.2934, test loss-2.2032, acc-0.2979\n",
      "Iter-11380, train loss-2.2171, acc-0.2800, valid loss-2.2082, acc-0.2932, test loss-2.2031, acc-0.2985\n",
      "Iter-11390, train loss-2.2046, acc-0.3000, valid loss-2.2081, acc-0.2932, test loss-2.2031, acc-0.2986\n",
      "Iter-11400, train loss-2.2414, acc-0.2600, valid loss-2.2081, acc-0.2936, test loss-2.2030, acc-0.2989\n",
      "Iter-11410, train loss-2.2051, acc-0.2200, valid loss-2.2080, acc-0.2940, test loss-2.2029, acc-0.2994\n",
      "Iter-11420, train loss-2.2299, acc-0.2800, valid loss-2.2079, acc-0.2936, test loss-2.2028, acc-0.2993\n",
      "Iter-11430, train loss-2.2201, acc-0.2600, valid loss-2.2078, acc-0.2940, test loss-2.2028, acc-0.2992\n",
      "Iter-11440, train loss-2.2035, acc-0.2000, valid loss-2.2078, acc-0.2944, test loss-2.2027, acc-0.2991\n",
      "Iter-11450, train loss-2.1952, acc-0.2600, valid loss-2.2077, acc-0.2944, test loss-2.2026, acc-0.2998\n",
      "Iter-11460, train loss-2.2080, acc-0.3000, valid loss-2.2076, acc-0.2946, test loss-2.2025, acc-0.3000\n",
      "Iter-11470, train loss-2.1965, acc-0.4200, valid loss-2.2075, acc-0.2950, test loss-2.2024, acc-0.2999\n",
      "Iter-11480, train loss-2.1931, acc-0.2600, valid loss-2.2075, acc-0.2956, test loss-2.2024, acc-0.3002\n",
      "Iter-11490, train loss-2.2305, acc-0.2600, valid loss-2.2074, acc-0.2960, test loss-2.2023, acc-0.3002\n",
      "Iter-11500, train loss-2.2151, acc-0.2400, valid loss-2.2073, acc-0.2962, test loss-2.2022, acc-0.3004\n",
      "Iter-11510, train loss-2.2050, acc-0.2600, valid loss-2.2073, acc-0.2962, test loss-2.2021, acc-0.3004\n",
      "Iter-11520, train loss-2.2289, acc-0.2000, valid loss-2.2072, acc-0.2962, test loss-2.2021, acc-0.3008\n",
      "Iter-11530, train loss-2.1689, acc-0.4200, valid loss-2.2071, acc-0.2966, test loss-2.2020, acc-0.3014\n",
      "Iter-11540, train loss-2.2057, acc-0.3200, valid loss-2.2071, acc-0.2962, test loss-2.2019, acc-0.3015\n",
      "Iter-11550, train loss-2.2359, acc-0.2800, valid loss-2.2070, acc-0.2966, test loss-2.2018, acc-0.3014\n",
      "Iter-11560, train loss-2.1878, acc-0.3000, valid loss-2.2069, acc-0.2966, test loss-2.2017, acc-0.3012\n",
      "Iter-11570, train loss-2.2028, acc-0.2400, valid loss-2.2069, acc-0.2972, test loss-2.2017, acc-0.3013\n",
      "Iter-11580, train loss-2.2238, acc-0.2000, valid loss-2.2068, acc-0.2968, test loss-2.2016, acc-0.3015\n",
      "Iter-11590, train loss-2.1912, acc-0.2800, valid loss-2.2067, acc-0.2974, test loss-2.2015, acc-0.3014\n",
      "Iter-11600, train loss-2.2398, acc-0.1800, valid loss-2.2067, acc-0.2984, test loss-2.2014, acc-0.3012\n",
      "Iter-11610, train loss-2.1858, acc-0.3400, valid loss-2.2066, acc-0.2978, test loss-2.2014, acc-0.3018\n",
      "Iter-11620, train loss-2.2004, acc-0.3000, valid loss-2.2065, acc-0.2984, test loss-2.2013, acc-0.3021\n",
      "Iter-11630, train loss-2.1934, acc-0.3400, valid loss-2.2065, acc-0.2990, test loss-2.2012, acc-0.3019\n",
      "Iter-11640, train loss-2.2235, acc-0.2800, valid loss-2.2064, acc-0.2992, test loss-2.2011, acc-0.3020\n",
      "Iter-11650, train loss-2.1810, acc-0.4400, valid loss-2.2063, acc-0.2998, test loss-2.2011, acc-0.3024\n",
      "Iter-11660, train loss-2.2220, acc-0.2800, valid loss-2.2062, acc-0.2996, test loss-2.2010, acc-0.3025\n",
      "Iter-11670, train loss-2.2286, acc-0.3000, valid loss-2.2062, acc-0.2996, test loss-2.2009, acc-0.3029\n",
      "Iter-11680, train loss-2.2030, acc-0.3000, valid loss-2.2061, acc-0.2994, test loss-2.2008, acc-0.3029\n",
      "Iter-11690, train loss-2.2031, acc-0.3800, valid loss-2.2060, acc-0.3000, test loss-2.2007, acc-0.3027\n",
      "Iter-11700, train loss-2.2195, acc-0.2400, valid loss-2.2060, acc-0.2998, test loss-2.2007, acc-0.3029\n",
      "Iter-11710, train loss-2.1997, acc-0.3200, valid loss-2.2059, acc-0.3002, test loss-2.2006, acc-0.3033\n",
      "Iter-11720, train loss-2.2486, acc-0.2200, valid loss-2.2058, acc-0.3002, test loss-2.2005, acc-0.3035\n",
      "Iter-11730, train loss-2.2086, acc-0.2200, valid loss-2.2058, acc-0.3000, test loss-2.2004, acc-0.3035\n",
      "Iter-11740, train loss-2.2073, acc-0.3600, valid loss-2.2057, acc-0.3004, test loss-2.2004, acc-0.3040\n",
      "Iter-11750, train loss-2.2117, acc-0.3200, valid loss-2.2056, acc-0.3002, test loss-2.2003, acc-0.3040\n",
      "Iter-11760, train loss-2.1936, acc-0.2800, valid loss-2.2055, acc-0.3006, test loss-2.2002, acc-0.3041\n",
      "Iter-11770, train loss-2.2340, acc-0.2800, valid loss-2.2055, acc-0.3004, test loss-2.2001, acc-0.3044\n",
      "Iter-11780, train loss-2.1816, acc-0.4200, valid loss-2.2054, acc-0.3006, test loss-2.2000, acc-0.3044\n",
      "Iter-11790, train loss-2.1664, acc-0.3600, valid loss-2.2053, acc-0.3002, test loss-2.2000, acc-0.3047\n",
      "Iter-11800, train loss-2.2120, acc-0.2000, valid loss-2.2053, acc-0.3002, test loss-2.1999, acc-0.3051\n",
      "Iter-11810, train loss-2.1814, acc-0.4400, valid loss-2.2052, acc-0.3004, test loss-2.1998, acc-0.3050\n",
      "Iter-11820, train loss-2.1938, acc-0.2800, valid loss-2.2051, acc-0.3006, test loss-2.1997, acc-0.3049\n",
      "Iter-11830, train loss-2.1936, acc-0.2800, valid loss-2.2050, acc-0.3006, test loss-2.1997, acc-0.3052\n",
      "Iter-11840, train loss-2.1969, acc-0.3200, valid loss-2.2050, acc-0.3016, test loss-2.1996, acc-0.3054\n",
      "Iter-11850, train loss-2.2086, acc-0.2400, valid loss-2.2049, acc-0.3016, test loss-2.1995, acc-0.3053\n",
      "Iter-11860, train loss-2.1973, acc-0.3400, valid loss-2.2048, acc-0.3014, test loss-2.1994, acc-0.3058\n",
      "Iter-11870, train loss-2.2129, acc-0.3600, valid loss-2.2048, acc-0.3020, test loss-2.1994, acc-0.3061\n",
      "Iter-11880, train loss-2.2196, acc-0.2600, valid loss-2.2047, acc-0.3022, test loss-2.1993, acc-0.3065\n",
      "Iter-11890, train loss-2.2087, acc-0.2800, valid loss-2.2046, acc-0.3022, test loss-2.1992, acc-0.3065\n",
      "Iter-11900, train loss-2.1937, acc-0.3400, valid loss-2.2045, acc-0.3020, test loss-2.1991, acc-0.3067\n",
      "Iter-11910, train loss-2.2274, acc-0.2200, valid loss-2.2045, acc-0.3024, test loss-2.1990, acc-0.3065\n",
      "Iter-11920, train loss-2.2073, acc-0.2200, valid loss-2.2044, acc-0.3024, test loss-2.1990, acc-0.3067\n",
      "Iter-11930, train loss-2.2016, acc-0.2800, valid loss-2.2043, acc-0.3024, test loss-2.1989, acc-0.3072\n",
      "Iter-11940, train loss-2.2107, acc-0.2600, valid loss-2.2043, acc-0.3022, test loss-2.1988, acc-0.3074\n",
      "Iter-11950, train loss-2.2017, acc-0.3400, valid loss-2.2042, acc-0.3026, test loss-2.1987, acc-0.3070\n",
      "Iter-11960, train loss-2.1963, acc-0.2800, valid loss-2.2041, acc-0.3028, test loss-2.1987, acc-0.3076\n",
      "Iter-11970, train loss-2.2074, acc-0.3400, valid loss-2.2041, acc-0.3026, test loss-2.1986, acc-0.3078\n",
      "Iter-11980, train loss-2.2414, acc-0.1400, valid loss-2.2040, acc-0.3028, test loss-2.1985, acc-0.3085\n",
      "Iter-11990, train loss-2.2711, acc-0.0800, valid loss-2.2039, acc-0.3028, test loss-2.1984, acc-0.3089\n",
      "Iter-12000, train loss-2.2178, acc-0.3200, valid loss-2.2039, acc-0.3032, test loss-2.1984, acc-0.3092\n",
      "Iter-12010, train loss-2.1792, acc-0.2600, valid loss-2.2038, acc-0.3036, test loss-2.1983, acc-0.3093\n",
      "Iter-12020, train loss-2.1884, acc-0.3600, valid loss-2.2037, acc-0.3036, test loss-2.1982, acc-0.3096\n",
      "Iter-12030, train loss-2.1921, acc-0.3000, valid loss-2.2037, acc-0.3038, test loss-2.1981, acc-0.3098\n",
      "Iter-12040, train loss-2.1981, acc-0.2600, valid loss-2.2036, acc-0.3042, test loss-2.1981, acc-0.3102\n",
      "Iter-12050, train loss-2.2185, acc-0.3000, valid loss-2.2035, acc-0.3042, test loss-2.1980, acc-0.3100\n",
      "Iter-12060, train loss-2.1954, acc-0.3400, valid loss-2.2034, acc-0.3044, test loss-2.1979, acc-0.3099\n",
      "Iter-12070, train loss-2.1934, acc-0.2400, valid loss-2.2034, acc-0.3046, test loss-2.1978, acc-0.3105\n",
      "Iter-12080, train loss-2.1952, acc-0.3600, valid loss-2.2033, acc-0.3046, test loss-2.1978, acc-0.3106\n",
      "Iter-12090, train loss-2.1939, acc-0.2600, valid loss-2.2032, acc-0.3042, test loss-2.1977, acc-0.3103\n",
      "Iter-12100, train loss-2.1894, acc-0.3000, valid loss-2.2032, acc-0.3044, test loss-2.1976, acc-0.3105\n",
      "Iter-12110, train loss-2.2112, acc-0.3000, valid loss-2.2031, acc-0.3046, test loss-2.1975, acc-0.3110\n",
      "Iter-12120, train loss-2.1992, acc-0.3000, valid loss-2.2030, acc-0.3044, test loss-2.1974, acc-0.3107\n",
      "Iter-12130, train loss-2.1781, acc-0.2400, valid loss-2.2029, acc-0.3046, test loss-2.1974, acc-0.3108\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12140, train loss-2.2138, acc-0.3200, valid loss-2.2029, acc-0.3046, test loss-2.1973, acc-0.3107\n",
      "Iter-12150, train loss-2.1892, acc-0.3800, valid loss-2.2028, acc-0.3052, test loss-2.1972, acc-0.3105\n",
      "Iter-12160, train loss-2.2247, acc-0.3200, valid loss-2.2027, acc-0.3046, test loss-2.1971, acc-0.3112\n",
      "Iter-12170, train loss-2.1658, acc-0.3000, valid loss-2.2027, acc-0.3044, test loss-2.1971, acc-0.3106\n",
      "Iter-12180, train loss-2.2114, acc-0.2400, valid loss-2.2026, acc-0.3046, test loss-2.1970, acc-0.3113\n",
      "Iter-12190, train loss-2.2094, acc-0.2400, valid loss-2.2025, acc-0.3048, test loss-2.1969, acc-0.3113\n",
      "Iter-12200, train loss-2.2147, acc-0.3200, valid loss-2.2025, acc-0.3048, test loss-2.1968, acc-0.3116\n",
      "Iter-12210, train loss-2.1892, acc-0.3000, valid loss-2.2024, acc-0.3054, test loss-2.1967, acc-0.3114\n",
      "Iter-12220, train loss-2.1904, acc-0.3400, valid loss-2.2023, acc-0.3058, test loss-2.1967, acc-0.3120\n",
      "Iter-12230, train loss-2.1946, acc-0.3800, valid loss-2.2022, acc-0.3060, test loss-2.1966, acc-0.3119\n",
      "Iter-12240, train loss-2.1904, acc-0.3400, valid loss-2.2022, acc-0.3062, test loss-2.1965, acc-0.3120\n",
      "Iter-12250, train loss-2.1903, acc-0.3000, valid loss-2.2021, acc-0.3060, test loss-2.1964, acc-0.3122\n",
      "Iter-12260, train loss-2.1976, acc-0.3000, valid loss-2.2020, acc-0.3058, test loss-2.1964, acc-0.3123\n",
      "Iter-12270, train loss-2.2267, acc-0.2000, valid loss-2.2020, acc-0.3060, test loss-2.1963, acc-0.3127\n",
      "Iter-12280, train loss-2.1927, acc-0.3000, valid loss-2.2019, acc-0.3060, test loss-2.1962, acc-0.3127\n",
      "Iter-12290, train loss-2.2188, acc-0.2000, valid loss-2.2018, acc-0.3058, test loss-2.1961, acc-0.3128\n",
      "Iter-12300, train loss-2.1994, acc-0.3000, valid loss-2.2018, acc-0.3058, test loss-2.1961, acc-0.3129\n",
      "Iter-12310, train loss-2.1860, acc-0.3000, valid loss-2.2017, acc-0.3064, test loss-2.1960, acc-0.3130\n",
      "Iter-12320, train loss-2.1900, acc-0.3000, valid loss-2.2016, acc-0.3060, test loss-2.1959, acc-0.3132\n",
      "Iter-12330, train loss-2.2040, acc-0.2800, valid loss-2.2016, acc-0.3064, test loss-2.1958, acc-0.3136\n",
      "Iter-12340, train loss-2.1895, acc-0.3800, valid loss-2.2015, acc-0.3060, test loss-2.1958, acc-0.3136\n",
      "Iter-12350, train loss-2.2018, acc-0.3200, valid loss-2.2014, acc-0.3060, test loss-2.1957, acc-0.3139\n",
      "Iter-12360, train loss-2.1775, acc-0.3200, valid loss-2.2014, acc-0.3064, test loss-2.1956, acc-0.3137\n",
      "Iter-12370, train loss-2.2105, acc-0.3200, valid loss-2.2013, acc-0.3062, test loss-2.1955, acc-0.3135\n",
      "Iter-12380, train loss-2.2174, acc-0.2000, valid loss-2.2012, acc-0.3072, test loss-2.1955, acc-0.3138\n",
      "Iter-12390, train loss-2.2103, acc-0.2800, valid loss-2.2012, acc-0.3072, test loss-2.1954, acc-0.3139\n",
      "Iter-12400, train loss-2.2188, acc-0.3400, valid loss-2.2011, acc-0.3080, test loss-2.1953, acc-0.3140\n",
      "Iter-12410, train loss-2.2170, acc-0.2800, valid loss-2.2010, acc-0.3080, test loss-2.1952, acc-0.3137\n",
      "Iter-12420, train loss-2.1848, acc-0.3800, valid loss-2.2009, acc-0.3078, test loss-2.1952, acc-0.3141\n",
      "Iter-12430, train loss-2.1967, acc-0.2800, valid loss-2.2009, acc-0.3080, test loss-2.1951, acc-0.3140\n",
      "Iter-12440, train loss-2.2117, acc-0.3800, valid loss-2.2008, acc-0.3082, test loss-2.1950, acc-0.3142\n",
      "Iter-12450, train loss-2.1836, acc-0.2400, valid loss-2.2007, acc-0.3082, test loss-2.1949, acc-0.3141\n",
      "Iter-12460, train loss-2.2175, acc-0.3600, valid loss-2.2007, acc-0.3084, test loss-2.1949, acc-0.3144\n",
      "Iter-12470, train loss-2.1851, acc-0.3600, valid loss-2.2006, acc-0.3086, test loss-2.1948, acc-0.3141\n",
      "Iter-12480, train loss-2.1681, acc-0.3000, valid loss-2.2005, acc-0.3086, test loss-2.1947, acc-0.3142\n",
      "Iter-12490, train loss-2.2034, acc-0.2200, valid loss-2.2005, acc-0.3090, test loss-2.1946, acc-0.3145\n",
      "Iter-12500, train loss-2.1994, acc-0.4000, valid loss-2.2004, acc-0.3086, test loss-2.1945, acc-0.3145\n",
      "Iter-12510, train loss-2.2251, acc-0.2400, valid loss-2.2003, acc-0.3094, test loss-2.1945, acc-0.3150\n",
      "Iter-12520, train loss-2.2106, acc-0.2800, valid loss-2.2003, acc-0.3098, test loss-2.1944, acc-0.3150\n",
      "Iter-12530, train loss-2.1955, acc-0.2600, valid loss-2.2002, acc-0.3098, test loss-2.1943, acc-0.3149\n",
      "Iter-12540, train loss-2.1927, acc-0.3800, valid loss-2.2001, acc-0.3096, test loss-2.1942, acc-0.3150\n",
      "Iter-12550, train loss-2.2160, acc-0.2400, valid loss-2.2000, acc-0.3096, test loss-2.1942, acc-0.3148\n",
      "Iter-12560, train loss-2.2087, acc-0.3200, valid loss-2.2000, acc-0.3094, test loss-2.1941, acc-0.3148\n",
      "Iter-12570, train loss-2.2135, acc-0.1600, valid loss-2.1999, acc-0.3092, test loss-2.1940, acc-0.3153\n",
      "Iter-12580, train loss-2.1854, acc-0.3200, valid loss-2.1998, acc-0.3094, test loss-2.1939, acc-0.3153\n",
      "Iter-12590, train loss-2.1859, acc-0.3600, valid loss-2.1998, acc-0.3102, test loss-2.1939, acc-0.3152\n",
      "Iter-12600, train loss-2.2058, acc-0.3400, valid loss-2.1997, acc-0.3110, test loss-2.1938, acc-0.3153\n",
      "Iter-12610, train loss-2.1999, acc-0.2800, valid loss-2.1996, acc-0.3104, test loss-2.1937, acc-0.3153\n",
      "Iter-12620, train loss-2.2199, acc-0.2400, valid loss-2.1996, acc-0.3106, test loss-2.1936, acc-0.3156\n",
      "Iter-12630, train loss-2.2023, acc-0.3000, valid loss-2.1995, acc-0.3110, test loss-2.1935, acc-0.3155\n",
      "Iter-12640, train loss-2.1953, acc-0.3800, valid loss-2.1994, acc-0.3114, test loss-2.1935, acc-0.3164\n",
      "Iter-12650, train loss-2.1816, acc-0.3200, valid loss-2.1993, acc-0.3112, test loss-2.1934, acc-0.3164\n",
      "Iter-12660, train loss-2.2145, acc-0.3200, valid loss-2.1993, acc-0.3116, test loss-2.1933, acc-0.3164\n",
      "Iter-12670, train loss-2.1955, acc-0.2200, valid loss-2.1992, acc-0.3112, test loss-2.1932, acc-0.3163\n",
      "Iter-12680, train loss-2.1850, acc-0.3000, valid loss-2.1991, acc-0.3120, test loss-2.1932, acc-0.3166\n",
      "Iter-12690, train loss-2.1675, acc-0.4000, valid loss-2.1990, acc-0.3126, test loss-2.1931, acc-0.3167\n",
      "Iter-12700, train loss-2.2017, acc-0.4200, valid loss-2.1990, acc-0.3120, test loss-2.1930, acc-0.3166\n",
      "Iter-12710, train loss-2.1819, acc-0.3600, valid loss-2.1989, acc-0.3124, test loss-2.1929, acc-0.3164\n",
      "Iter-12720, train loss-2.1942, acc-0.2800, valid loss-2.1988, acc-0.3130, test loss-2.1929, acc-0.3166\n",
      "Iter-12730, train loss-2.1728, acc-0.3200, valid loss-2.1988, acc-0.3128, test loss-2.1928, acc-0.3163\n",
      "Iter-12740, train loss-2.2108, acc-0.2800, valid loss-2.1987, acc-0.3128, test loss-2.1927, acc-0.3162\n",
      "Iter-12750, train loss-2.2071, acc-0.2400, valid loss-2.1986, acc-0.3132, test loss-2.1926, acc-0.3165\n",
      "Iter-12760, train loss-2.1813, acc-0.2600, valid loss-2.1986, acc-0.3134, test loss-2.1925, acc-0.3166\n",
      "Iter-12770, train loss-2.2273, acc-0.2200, valid loss-2.1985, acc-0.3136, test loss-2.1925, acc-0.3167\n",
      "Iter-12780, train loss-2.1751, acc-0.3600, valid loss-2.1984, acc-0.3136, test loss-2.1924, acc-0.3171\n",
      "Iter-12790, train loss-2.1921, acc-0.2600, valid loss-2.1984, acc-0.3134, test loss-2.1923, acc-0.3167\n",
      "Iter-12800, train loss-2.1898, acc-0.4000, valid loss-2.1983, acc-0.3134, test loss-2.1922, acc-0.3170\n",
      "Iter-12810, train loss-2.1990, acc-0.2000, valid loss-2.1982, acc-0.3146, test loss-2.1921, acc-0.3169\n",
      "Iter-12820, train loss-2.1938, acc-0.3400, valid loss-2.1981, acc-0.3154, test loss-2.1921, acc-0.3175\n",
      "Iter-12830, train loss-2.1950, acc-0.3200, valid loss-2.1981, acc-0.3154, test loss-2.1920, acc-0.3175\n",
      "Iter-12840, train loss-2.2168, acc-0.2800, valid loss-2.1980, acc-0.3150, test loss-2.1919, acc-0.3174\n",
      "Iter-12850, train loss-2.2114, acc-0.3000, valid loss-2.1979, acc-0.3156, test loss-2.1918, acc-0.3177\n",
      "Iter-12860, train loss-2.1894, acc-0.3800, valid loss-2.1979, acc-0.3154, test loss-2.1918, acc-0.3180\n",
      "Iter-12870, train loss-2.1732, acc-0.3400, valid loss-2.1978, acc-0.3156, test loss-2.1917, acc-0.3180\n",
      "Iter-12880, train loss-2.1835, acc-0.4200, valid loss-2.1977, acc-0.3156, test loss-2.1916, acc-0.3183\n",
      "Iter-12890, train loss-2.2489, acc-0.2800, valid loss-2.1976, acc-0.3154, test loss-2.1915, acc-0.3184\n",
      "Iter-12900, train loss-2.2062, acc-0.2000, valid loss-2.1976, acc-0.3154, test loss-2.1914, acc-0.3183\n",
      "Iter-12910, train loss-2.1540, acc-0.4200, valid loss-2.1975, acc-0.3164, test loss-2.1914, acc-0.3187\n",
      "Iter-12920, train loss-2.1966, acc-0.2600, valid loss-2.1974, acc-0.3156, test loss-2.1913, acc-0.3183\n",
      "Iter-12930, train loss-2.2063, acc-0.3800, valid loss-2.1974, acc-0.3156, test loss-2.1912, acc-0.3184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12940, train loss-2.2022, acc-0.3200, valid loss-2.1973, acc-0.3160, test loss-2.1911, acc-0.3188\n",
      "Iter-12950, train loss-2.2027, acc-0.3600, valid loss-2.1972, acc-0.3168, test loss-2.1911, acc-0.3184\n",
      "Iter-12960, train loss-2.2082, acc-0.2800, valid loss-2.1971, acc-0.3170, test loss-2.1910, acc-0.3185\n",
      "Iter-12970, train loss-2.2326, acc-0.2800, valid loss-2.1971, acc-0.3168, test loss-2.1909, acc-0.3188\n",
      "Iter-12980, train loss-2.1850, acc-0.3400, valid loss-2.1970, acc-0.3170, test loss-2.1908, acc-0.3191\n",
      "Iter-12990, train loss-2.1642, acc-0.2800, valid loss-2.1969, acc-0.3182, test loss-2.1908, acc-0.3189\n",
      "Iter-13000, train loss-2.2154, acc-0.2800, valid loss-2.1969, acc-0.3180, test loss-2.1907, acc-0.3191\n",
      "Iter-13010, train loss-2.2360, acc-0.2200, valid loss-2.1968, acc-0.3180, test loss-2.1906, acc-0.3193\n",
      "Iter-13020, train loss-2.2080, acc-0.3600, valid loss-2.1967, acc-0.3188, test loss-2.1905, acc-0.3194\n",
      "Iter-13030, train loss-2.1833, acc-0.4000, valid loss-2.1966, acc-0.3182, test loss-2.1905, acc-0.3193\n",
      "Iter-13040, train loss-2.2126, acc-0.3200, valid loss-2.1966, acc-0.3184, test loss-2.1904, acc-0.3191\n",
      "Iter-13050, train loss-2.1830, acc-0.4000, valid loss-2.1965, acc-0.3186, test loss-2.1903, acc-0.3193\n",
      "Iter-13060, train loss-2.1917, acc-0.3600, valid loss-2.1965, acc-0.3186, test loss-2.1902, acc-0.3193\n",
      "Iter-13070, train loss-2.1966, acc-0.4000, valid loss-2.1964, acc-0.3186, test loss-2.1902, acc-0.3196\n",
      "Iter-13080, train loss-2.1760, acc-0.3400, valid loss-2.1963, acc-0.3194, test loss-2.1901, acc-0.3197\n",
      "Iter-13090, train loss-2.1978, acc-0.2400, valid loss-2.1962, acc-0.3192, test loss-2.1900, acc-0.3201\n",
      "Iter-13100, train loss-2.1961, acc-0.4000, valid loss-2.1962, acc-0.3198, test loss-2.1899, acc-0.3201\n",
      "Iter-13110, train loss-2.1937, acc-0.2800, valid loss-2.1961, acc-0.3200, test loss-2.1899, acc-0.3201\n",
      "Iter-13120, train loss-2.1923, acc-0.3600, valid loss-2.1960, acc-0.3200, test loss-2.1898, acc-0.3202\n",
      "Iter-13130, train loss-2.2039, acc-0.3200, valid loss-2.1960, acc-0.3196, test loss-2.1897, acc-0.3203\n",
      "Iter-13140, train loss-2.1535, acc-0.3600, valid loss-2.1959, acc-0.3200, test loss-2.1896, acc-0.3208\n",
      "Iter-13150, train loss-2.2065, acc-0.2800, valid loss-2.1958, acc-0.3206, test loss-2.1896, acc-0.3206\n",
      "Iter-13160, train loss-2.1868, acc-0.3200, valid loss-2.1958, acc-0.3204, test loss-2.1895, acc-0.3211\n",
      "Iter-13170, train loss-2.1970, acc-0.3600, valid loss-2.1957, acc-0.3210, test loss-2.1894, acc-0.3212\n",
      "Iter-13180, train loss-2.1554, acc-0.5000, valid loss-2.1956, acc-0.3208, test loss-2.1893, acc-0.3214\n",
      "Iter-13190, train loss-2.1957, acc-0.3600, valid loss-2.1955, acc-0.3208, test loss-2.1892, acc-0.3216\n",
      "Iter-13200, train loss-2.2113, acc-0.2800, valid loss-2.1955, acc-0.3208, test loss-2.1892, acc-0.3218\n",
      "Iter-13210, train loss-2.2017, acc-0.3200, valid loss-2.1954, acc-0.3210, test loss-2.1891, acc-0.3220\n",
      "Iter-13220, train loss-2.1942, acc-0.3200, valid loss-2.1953, acc-0.3216, test loss-2.1890, acc-0.3218\n",
      "Iter-13230, train loss-2.1498, acc-0.3600, valid loss-2.1953, acc-0.3216, test loss-2.1889, acc-0.3218\n",
      "Iter-13240, train loss-2.1725, acc-0.4200, valid loss-2.1952, acc-0.3218, test loss-2.1889, acc-0.3226\n",
      "Iter-13250, train loss-2.2046, acc-0.2000, valid loss-2.1951, acc-0.3216, test loss-2.1888, acc-0.3226\n",
      "Iter-13260, train loss-2.1851, acc-0.3000, valid loss-2.1951, acc-0.3220, test loss-2.1887, acc-0.3226\n",
      "Iter-13270, train loss-2.1815, acc-0.3000, valid loss-2.1950, acc-0.3224, test loss-2.1886, acc-0.3224\n",
      "Iter-13280, train loss-2.2195, acc-0.3800, valid loss-2.1949, acc-0.3220, test loss-2.1886, acc-0.3226\n",
      "Iter-13290, train loss-2.2105, acc-0.2600, valid loss-2.1949, acc-0.3220, test loss-2.1885, acc-0.3226\n",
      "Iter-13300, train loss-2.1754, acc-0.3600, valid loss-2.1948, acc-0.3216, test loss-2.1884, acc-0.3228\n",
      "Iter-13310, train loss-2.1756, acc-0.3800, valid loss-2.1947, acc-0.3218, test loss-2.1883, acc-0.3230\n",
      "Iter-13320, train loss-2.1959, acc-0.3800, valid loss-2.1946, acc-0.3230, test loss-2.1882, acc-0.3232\n",
      "Iter-13330, train loss-2.1838, acc-0.3400, valid loss-2.1946, acc-0.3224, test loss-2.1882, acc-0.3231\n",
      "Iter-13340, train loss-2.1901, acc-0.3200, valid loss-2.1945, acc-0.3228, test loss-2.1881, acc-0.3231\n",
      "Iter-13350, train loss-2.1845, acc-0.3400, valid loss-2.1944, acc-0.3230, test loss-2.1880, acc-0.3235\n",
      "Iter-13360, train loss-2.2093, acc-0.2600, valid loss-2.1944, acc-0.3234, test loss-2.1879, acc-0.3238\n",
      "Iter-13370, train loss-2.1825, acc-0.3200, valid loss-2.1943, acc-0.3230, test loss-2.1879, acc-0.3242\n",
      "Iter-13380, train loss-2.1778, acc-0.3600, valid loss-2.1942, acc-0.3234, test loss-2.1878, acc-0.3240\n",
      "Iter-13390, train loss-2.1810, acc-0.3000, valid loss-2.1942, acc-0.3234, test loss-2.1877, acc-0.3243\n",
      "Iter-13400, train loss-2.1708, acc-0.3800, valid loss-2.1941, acc-0.3234, test loss-2.1876, acc-0.3240\n",
      "Iter-13410, train loss-2.1789, acc-0.3600, valid loss-2.1940, acc-0.3232, test loss-2.1876, acc-0.3244\n",
      "Iter-13420, train loss-2.1828, acc-0.2800, valid loss-2.1939, acc-0.3236, test loss-2.1875, acc-0.3242\n",
      "Iter-13430, train loss-2.1696, acc-0.3600, valid loss-2.1939, acc-0.3234, test loss-2.1874, acc-0.3247\n",
      "Iter-13440, train loss-2.1828, acc-0.3400, valid loss-2.1938, acc-0.3236, test loss-2.1873, acc-0.3251\n",
      "Iter-13450, train loss-2.2151, acc-0.2400, valid loss-2.1937, acc-0.3240, test loss-2.1873, acc-0.3255\n",
      "Iter-13460, train loss-2.2010, acc-0.3600, valid loss-2.1937, acc-0.3238, test loss-2.1872, acc-0.3255\n",
      "Iter-13470, train loss-2.1890, acc-0.3000, valid loss-2.1936, acc-0.3240, test loss-2.1871, acc-0.3258\n",
      "Iter-13480, train loss-2.1709, acc-0.3600, valid loss-2.1935, acc-0.3244, test loss-2.1870, acc-0.3255\n",
      "Iter-13490, train loss-2.1603, acc-0.3200, valid loss-2.1935, acc-0.3238, test loss-2.1870, acc-0.3261\n",
      "Iter-13500, train loss-2.1464, acc-0.4600, valid loss-2.1934, acc-0.3242, test loss-2.1869, acc-0.3264\n",
      "Iter-13510, train loss-2.1928, acc-0.3800, valid loss-2.1933, acc-0.3242, test loss-2.1868, acc-0.3266\n",
      "Iter-13520, train loss-2.1601, acc-0.3200, valid loss-2.1933, acc-0.3244, test loss-2.1867, acc-0.3265\n",
      "Iter-13530, train loss-2.1876, acc-0.3000, valid loss-2.1932, acc-0.3252, test loss-2.1867, acc-0.3265\n",
      "Iter-13540, train loss-2.2115, acc-0.3000, valid loss-2.1931, acc-0.3252, test loss-2.1866, acc-0.3268\n",
      "Iter-13550, train loss-2.1634, acc-0.3200, valid loss-2.1931, acc-0.3256, test loss-2.1865, acc-0.3268\n",
      "Iter-13560, train loss-2.1764, acc-0.3800, valid loss-2.1930, acc-0.3256, test loss-2.1864, acc-0.3272\n",
      "Iter-13570, train loss-2.2019, acc-0.2400, valid loss-2.1929, acc-0.3258, test loss-2.1863, acc-0.3273\n",
      "Iter-13580, train loss-2.2110, acc-0.2400, valid loss-2.1928, acc-0.3260, test loss-2.1863, acc-0.3276\n",
      "Iter-13590, train loss-2.1917, acc-0.3400, valid loss-2.1928, acc-0.3258, test loss-2.1862, acc-0.3277\n",
      "Iter-13600, train loss-2.2096, acc-0.2600, valid loss-2.1927, acc-0.3258, test loss-2.1861, acc-0.3277\n",
      "Iter-13610, train loss-2.1860, acc-0.3000, valid loss-2.1926, acc-0.3258, test loss-2.1860, acc-0.3278\n",
      "Iter-13620, train loss-2.2222, acc-0.2600, valid loss-2.1926, acc-0.3260, test loss-2.1860, acc-0.3282\n",
      "Iter-13630, train loss-2.2140, acc-0.2600, valid loss-2.1925, acc-0.3264, test loss-2.1859, acc-0.3283\n",
      "Iter-13640, train loss-2.1866, acc-0.4200, valid loss-2.1924, acc-0.3262, test loss-2.1858, acc-0.3283\n",
      "Iter-13650, train loss-2.1970, acc-0.3400, valid loss-2.1924, acc-0.3260, test loss-2.1857, acc-0.3287\n",
      "Iter-13660, train loss-2.1819, acc-0.3800, valid loss-2.1923, acc-0.3256, test loss-2.1856, acc-0.3284\n",
      "Iter-13670, train loss-2.2425, acc-0.1600, valid loss-2.1922, acc-0.3264, test loss-2.1856, acc-0.3288\n",
      "Iter-13680, train loss-2.2163, acc-0.3000, valid loss-2.1922, acc-0.3266, test loss-2.1855, acc-0.3290\n",
      "Iter-13690, train loss-2.2033, acc-0.2400, valid loss-2.1921, acc-0.3266, test loss-2.1854, acc-0.3292\n",
      "Iter-13700, train loss-2.1847, acc-0.3200, valid loss-2.1920, acc-0.3266, test loss-2.1854, acc-0.3294\n",
      "Iter-13710, train loss-2.2015, acc-0.2800, valid loss-2.1920, acc-0.3274, test loss-2.1853, acc-0.3294\n",
      "Iter-13720, train loss-2.1843, acc-0.4200, valid loss-2.1919, acc-0.3278, test loss-2.1852, acc-0.3296\n",
      "Iter-13730, train loss-2.1700, acc-0.4000, valid loss-2.1918, acc-0.3280, test loss-2.1851, acc-0.3295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13740, train loss-2.1751, acc-0.3800, valid loss-2.1918, acc-0.3282, test loss-2.1851, acc-0.3298\n",
      "Iter-13750, train loss-2.1783, acc-0.3600, valid loss-2.1917, acc-0.3282, test loss-2.1850, acc-0.3300\n",
      "Iter-13760, train loss-2.1641, acc-0.2800, valid loss-2.1916, acc-0.3280, test loss-2.1849, acc-0.3305\n",
      "Iter-13770, train loss-2.1882, acc-0.2800, valid loss-2.1915, acc-0.3282, test loss-2.1848, acc-0.3304\n",
      "Iter-13780, train loss-2.1990, acc-0.3600, valid loss-2.1915, acc-0.3280, test loss-2.1848, acc-0.3305\n",
      "Iter-13790, train loss-2.1887, acc-0.3000, valid loss-2.1914, acc-0.3278, test loss-2.1847, acc-0.3305\n",
      "Iter-13800, train loss-2.1987, acc-0.3200, valid loss-2.1913, acc-0.3288, test loss-2.1846, acc-0.3308\n",
      "Iter-13810, train loss-2.1663, acc-0.3600, valid loss-2.1913, acc-0.3290, test loss-2.1845, acc-0.3309\n",
      "Iter-13820, train loss-2.1709, acc-0.3200, valid loss-2.1912, acc-0.3286, test loss-2.1844, acc-0.3310\n",
      "Iter-13830, train loss-2.1841, acc-0.3000, valid loss-2.1911, acc-0.3294, test loss-2.1844, acc-0.3313\n",
      "Iter-13840, train loss-2.2089, acc-0.2400, valid loss-2.1910, acc-0.3302, test loss-2.1843, acc-0.3312\n",
      "Iter-13850, train loss-2.2049, acc-0.3000, valid loss-2.1910, acc-0.3302, test loss-2.1842, acc-0.3313\n",
      "Iter-13860, train loss-2.1760, acc-0.2200, valid loss-2.1909, acc-0.3306, test loss-2.1841, acc-0.3315\n",
      "Iter-13870, train loss-2.2097, acc-0.3600, valid loss-2.1909, acc-0.3310, test loss-2.1841, acc-0.3317\n",
      "Iter-13880, train loss-2.1592, acc-0.3400, valid loss-2.1908, acc-0.3306, test loss-2.1840, acc-0.3321\n",
      "Iter-13890, train loss-2.1981, acc-0.1800, valid loss-2.1907, acc-0.3306, test loss-2.1839, acc-0.3322\n",
      "Iter-13900, train loss-2.1857, acc-0.3200, valid loss-2.1906, acc-0.3308, test loss-2.1839, acc-0.3325\n",
      "Iter-13910, train loss-2.1745, acc-0.4000, valid loss-2.1906, acc-0.3302, test loss-2.1838, acc-0.3329\n",
      "Iter-13920, train loss-2.1660, acc-0.2400, valid loss-2.1905, acc-0.3306, test loss-2.1837, acc-0.3327\n",
      "Iter-13930, train loss-2.1786, acc-0.2800, valid loss-2.1904, acc-0.3312, test loss-2.1836, acc-0.3331\n",
      "Iter-13940, train loss-2.1563, acc-0.4400, valid loss-2.1904, acc-0.3316, test loss-2.1835, acc-0.3334\n",
      "Iter-13950, train loss-2.1499, acc-0.4000, valid loss-2.1903, acc-0.3318, test loss-2.1835, acc-0.3334\n",
      "Iter-13960, train loss-2.1774, acc-0.3800, valid loss-2.1902, acc-0.3314, test loss-2.1834, acc-0.3331\n",
      "Iter-13970, train loss-2.2298, acc-0.1600, valid loss-2.1901, acc-0.3318, test loss-2.1833, acc-0.3329\n",
      "Iter-13980, train loss-2.1912, acc-0.3000, valid loss-2.1901, acc-0.3314, test loss-2.1832, acc-0.3334\n",
      "Iter-13990, train loss-2.1861, acc-0.3800, valid loss-2.1900, acc-0.3316, test loss-2.1832, acc-0.3335\n",
      "Iter-14000, train loss-2.1433, acc-0.4000, valid loss-2.1899, acc-0.3318, test loss-2.1831, acc-0.3337\n",
      "Iter-14010, train loss-2.2039, acc-0.3200, valid loss-2.1899, acc-0.3322, test loss-2.1830, acc-0.3339\n",
      "Iter-14020, train loss-2.2163, acc-0.1800, valid loss-2.1898, acc-0.3324, test loss-2.1829, acc-0.3339\n",
      "Iter-14030, train loss-2.1858, acc-0.2600, valid loss-2.1897, acc-0.3324, test loss-2.1829, acc-0.3340\n",
      "Iter-14040, train loss-2.1995, acc-0.2400, valid loss-2.1897, acc-0.3326, test loss-2.1828, acc-0.3342\n",
      "Iter-14050, train loss-2.1511, acc-0.3800, valid loss-2.1896, acc-0.3326, test loss-2.1827, acc-0.3343\n",
      "Iter-14060, train loss-2.1979, acc-0.3200, valid loss-2.1895, acc-0.3324, test loss-2.1826, acc-0.3342\n",
      "Iter-14070, train loss-2.1944, acc-0.3600, valid loss-2.1895, acc-0.3326, test loss-2.1826, acc-0.3343\n",
      "Iter-14080, train loss-2.2113, acc-0.2000, valid loss-2.1894, acc-0.3324, test loss-2.1825, acc-0.3342\n",
      "Iter-14090, train loss-2.1671, acc-0.3400, valid loss-2.1893, acc-0.3328, test loss-2.1824, acc-0.3347\n",
      "Iter-14100, train loss-2.1738, acc-0.4000, valid loss-2.1893, acc-0.3330, test loss-2.1823, acc-0.3349\n",
      "Iter-14110, train loss-2.1823, acc-0.4800, valid loss-2.1892, acc-0.3330, test loss-2.1823, acc-0.3348\n",
      "Iter-14120, train loss-2.1947, acc-0.3200, valid loss-2.1891, acc-0.3330, test loss-2.1822, acc-0.3353\n",
      "Iter-14130, train loss-2.1978, acc-0.4000, valid loss-2.1891, acc-0.3332, test loss-2.1821, acc-0.3355\n",
      "Iter-14140, train loss-2.1961, acc-0.3400, valid loss-2.1890, acc-0.3334, test loss-2.1821, acc-0.3359\n",
      "Iter-14150, train loss-2.2104, acc-0.2200, valid loss-2.1889, acc-0.3344, test loss-2.1820, acc-0.3364\n",
      "Iter-14160, train loss-2.1611, acc-0.4600, valid loss-2.1889, acc-0.3344, test loss-2.1819, acc-0.3367\n",
      "Iter-14170, train loss-2.1811, acc-0.3600, valid loss-2.1888, acc-0.3350, test loss-2.1818, acc-0.3366\n",
      "Iter-14180, train loss-2.1971, acc-0.3800, valid loss-2.1887, acc-0.3350, test loss-2.1818, acc-0.3368\n",
      "Iter-14190, train loss-2.1601, acc-0.3200, valid loss-2.1887, acc-0.3348, test loss-2.1817, acc-0.3367\n",
      "Iter-14200, train loss-2.1676, acc-0.3200, valid loss-2.1886, acc-0.3348, test loss-2.1816, acc-0.3364\n",
      "Iter-14210, train loss-2.1930, acc-0.3000, valid loss-2.1885, acc-0.3350, test loss-2.1815, acc-0.3367\n",
      "Iter-14220, train loss-2.2107, acc-0.2800, valid loss-2.1884, acc-0.3348, test loss-2.1815, acc-0.3369\n",
      "Iter-14230, train loss-2.1565, acc-0.3400, valid loss-2.1884, acc-0.3352, test loss-2.1814, acc-0.3372\n",
      "Iter-14240, train loss-2.1651, acc-0.3600, valid loss-2.1883, acc-0.3346, test loss-2.1813, acc-0.3374\n",
      "Iter-14250, train loss-2.2005, acc-0.3400, valid loss-2.1882, acc-0.3348, test loss-2.1812, acc-0.3376\n",
      "Iter-14260, train loss-2.1936, acc-0.3000, valid loss-2.1882, acc-0.3348, test loss-2.1812, acc-0.3378\n",
      "Iter-14270, train loss-2.2062, acc-0.2800, valid loss-2.1881, acc-0.3348, test loss-2.1811, acc-0.3379\n",
      "Iter-14280, train loss-2.1813, acc-0.3000, valid loss-2.1880, acc-0.3350, test loss-2.1810, acc-0.3380\n",
      "Iter-14290, train loss-2.2035, acc-0.3400, valid loss-2.1880, acc-0.3352, test loss-2.1809, acc-0.3382\n",
      "Iter-14300, train loss-2.1632, acc-0.3600, valid loss-2.1879, acc-0.3348, test loss-2.1809, acc-0.3385\n",
      "Iter-14310, train loss-2.1998, acc-0.3200, valid loss-2.1879, acc-0.3350, test loss-2.1808, acc-0.3386\n",
      "Iter-14320, train loss-2.1479, acc-0.3600, valid loss-2.1878, acc-0.3356, test loss-2.1807, acc-0.3383\n",
      "Iter-14330, train loss-2.1602, acc-0.4200, valid loss-2.1877, acc-0.3358, test loss-2.1806, acc-0.3386\n",
      "Iter-14340, train loss-2.1839, acc-0.4000, valid loss-2.1876, acc-0.3358, test loss-2.1806, acc-0.3382\n",
      "Iter-14350, train loss-2.1894, acc-0.3400, valid loss-2.1876, acc-0.3362, test loss-2.1805, acc-0.3386\n",
      "Iter-14360, train loss-2.2025, acc-0.3600, valid loss-2.1875, acc-0.3358, test loss-2.1804, acc-0.3396\n",
      "Iter-14370, train loss-2.1866, acc-0.3600, valid loss-2.1874, acc-0.3360, test loss-2.1803, acc-0.3398\n",
      "Iter-14380, train loss-2.1566, acc-0.4400, valid loss-2.1874, acc-0.3364, test loss-2.1803, acc-0.3398\n",
      "Iter-14390, train loss-2.1899, acc-0.4000, valid loss-2.1873, acc-0.3366, test loss-2.1802, acc-0.3399\n",
      "Iter-14400, train loss-2.1932, acc-0.3200, valid loss-2.1872, acc-0.3368, test loss-2.1801, acc-0.3395\n",
      "Iter-14410, train loss-2.1788, acc-0.3200, valid loss-2.1872, acc-0.3370, test loss-2.1800, acc-0.3398\n",
      "Iter-14420, train loss-2.1745, acc-0.3400, valid loss-2.1871, acc-0.3370, test loss-2.1800, acc-0.3397\n",
      "Iter-14430, train loss-2.2074, acc-0.2200, valid loss-2.1870, acc-0.3370, test loss-2.1799, acc-0.3399\n",
      "Iter-14440, train loss-2.1868, acc-0.3000, valid loss-2.1870, acc-0.3374, test loss-2.1798, acc-0.3399\n",
      "Iter-14450, train loss-2.1855, acc-0.3200, valid loss-2.1869, acc-0.3370, test loss-2.1798, acc-0.3399\n",
      "Iter-14460, train loss-2.1799, acc-0.3400, valid loss-2.1868, acc-0.3370, test loss-2.1797, acc-0.3401\n",
      "Iter-14470, train loss-2.1790, acc-0.2800, valid loss-2.1868, acc-0.3378, test loss-2.1796, acc-0.3401\n",
      "Iter-14480, train loss-2.1705, acc-0.3600, valid loss-2.1867, acc-0.3380, test loss-2.1795, acc-0.3401\n",
      "Iter-14490, train loss-2.2081, acc-0.1800, valid loss-2.1866, acc-0.3378, test loss-2.1794, acc-0.3404\n",
      "Iter-14500, train loss-2.2066, acc-0.2600, valid loss-2.1866, acc-0.3382, test loss-2.1794, acc-0.3407\n",
      "Iter-14510, train loss-2.1955, acc-0.3000, valid loss-2.1865, acc-0.3384, test loss-2.1793, acc-0.3405\n",
      "Iter-14520, train loss-2.1880, acc-0.2800, valid loss-2.1864, acc-0.3382, test loss-2.1792, acc-0.3407\n",
      "Iter-14530, train loss-2.1604, acc-0.4600, valid loss-2.1864, acc-0.3384, test loss-2.1791, acc-0.3410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-14540, train loss-2.1633, acc-0.4400, valid loss-2.1863, acc-0.3386, test loss-2.1791, acc-0.3410\n",
      "Iter-14550, train loss-2.2027, acc-0.3200, valid loss-2.1862, acc-0.3386, test loss-2.1790, acc-0.3408\n",
      "Iter-14560, train loss-2.1713, acc-0.3400, valid loss-2.1862, acc-0.3384, test loss-2.1789, acc-0.3411\n",
      "Iter-14570, train loss-2.1810, acc-0.4200, valid loss-2.1861, acc-0.3382, test loss-2.1788, acc-0.3414\n",
      "Iter-14580, train loss-2.1746, acc-0.3800, valid loss-2.1860, acc-0.3388, test loss-2.1788, acc-0.3417\n",
      "Iter-14590, train loss-2.1750, acc-0.3200, valid loss-2.1860, acc-0.3388, test loss-2.1787, acc-0.3420\n",
      "Iter-14600, train loss-2.1952, acc-0.2400, valid loss-2.1859, acc-0.3386, test loss-2.1786, acc-0.3421\n",
      "Iter-14610, train loss-2.1924, acc-0.2600, valid loss-2.1858, acc-0.3388, test loss-2.1786, acc-0.3418\n",
      "Iter-14620, train loss-2.1993, acc-0.2600, valid loss-2.1858, acc-0.3390, test loss-2.1785, acc-0.3420\n",
      "Iter-14630, train loss-2.2235, acc-0.3000, valid loss-2.1857, acc-0.3392, test loss-2.1784, acc-0.3421\n",
      "Iter-14640, train loss-2.1677, acc-0.4200, valid loss-2.1856, acc-0.3394, test loss-2.1783, acc-0.3422\n",
      "Iter-14650, train loss-2.1998, acc-0.3000, valid loss-2.1856, acc-0.3394, test loss-2.1783, acc-0.3426\n",
      "Iter-14660, train loss-2.1530, acc-0.4200, valid loss-2.1855, acc-0.3398, test loss-2.1782, acc-0.3424\n",
      "Iter-14670, train loss-2.2246, acc-0.2400, valid loss-2.1854, acc-0.3400, test loss-2.1781, acc-0.3431\n",
      "Iter-14680, train loss-2.1742, acc-0.2800, valid loss-2.1853, acc-0.3402, test loss-2.1780, acc-0.3433\n",
      "Iter-14690, train loss-2.1939, acc-0.3200, valid loss-2.1853, acc-0.3402, test loss-2.1780, acc-0.3431\n",
      "Iter-14700, train loss-2.1870, acc-0.4000, valid loss-2.1852, acc-0.3408, test loss-2.1779, acc-0.3430\n",
      "Iter-14710, train loss-2.2107, acc-0.2600, valid loss-2.1851, acc-0.3406, test loss-2.1778, acc-0.3434\n",
      "Iter-14720, train loss-2.1476, acc-0.2800, valid loss-2.1851, acc-0.3410, test loss-2.1777, acc-0.3437\n",
      "Iter-14730, train loss-2.2110, acc-0.3600, valid loss-2.1850, acc-0.3408, test loss-2.1777, acc-0.3435\n",
      "Iter-14740, train loss-2.1854, acc-0.3000, valid loss-2.1849, acc-0.3410, test loss-2.1776, acc-0.3437\n",
      "Iter-14750, train loss-2.2071, acc-0.3000, valid loss-2.1849, acc-0.3414, test loss-2.1775, acc-0.3438\n",
      "Iter-14760, train loss-2.1987, acc-0.2800, valid loss-2.1848, acc-0.3412, test loss-2.1774, acc-0.3438\n",
      "Iter-14770, train loss-2.2037, acc-0.2800, valid loss-2.1847, acc-0.3410, test loss-2.1774, acc-0.3439\n",
      "Iter-14780, train loss-2.2022, acc-0.3400, valid loss-2.1847, acc-0.3410, test loss-2.1773, acc-0.3439\n",
      "Iter-14790, train loss-2.1873, acc-0.2800, valid loss-2.1846, acc-0.3412, test loss-2.1772, acc-0.3438\n",
      "Iter-14800, train loss-2.1945, acc-0.4400, valid loss-2.1846, acc-0.3416, test loss-2.1772, acc-0.3438\n",
      "Iter-14810, train loss-2.1705, acc-0.4200, valid loss-2.1845, acc-0.3414, test loss-2.1771, acc-0.3438\n",
      "Iter-14820, train loss-2.2078, acc-0.2400, valid loss-2.1844, acc-0.3418, test loss-2.1770, acc-0.3435\n",
      "Iter-14830, train loss-2.1849, acc-0.3200, valid loss-2.1844, acc-0.3418, test loss-2.1769, acc-0.3437\n",
      "Iter-14840, train loss-2.1771, acc-0.3000, valid loss-2.1843, acc-0.3414, test loss-2.1769, acc-0.3440\n",
      "Iter-14850, train loss-2.1346, acc-0.4400, valid loss-2.1842, acc-0.3416, test loss-2.1768, acc-0.3440\n",
      "Iter-14860, train loss-2.1949, acc-0.2600, valid loss-2.1842, acc-0.3414, test loss-2.1767, acc-0.3444\n",
      "Iter-14870, train loss-2.1490, acc-0.4000, valid loss-2.1841, acc-0.3420, test loss-2.1766, acc-0.3443\n",
      "Iter-14880, train loss-2.1369, acc-0.5000, valid loss-2.1840, acc-0.3422, test loss-2.1766, acc-0.3442\n",
      "Iter-14890, train loss-2.1916, acc-0.3200, valid loss-2.1840, acc-0.3422, test loss-2.1765, acc-0.3447\n",
      "Iter-14900, train loss-2.1653, acc-0.3800, valid loss-2.1839, acc-0.3420, test loss-2.1764, acc-0.3444\n",
      "Iter-14910, train loss-2.1752, acc-0.3600, valid loss-2.1838, acc-0.3424, test loss-2.1763, acc-0.3447\n",
      "Iter-14920, train loss-2.1790, acc-0.3200, valid loss-2.1837, acc-0.3426, test loss-2.1762, acc-0.3449\n",
      "Iter-14930, train loss-2.2019, acc-0.3600, valid loss-2.1837, acc-0.3432, test loss-2.1762, acc-0.3447\n",
      "Iter-14940, train loss-2.1724, acc-0.3400, valid loss-2.1836, acc-0.3432, test loss-2.1761, acc-0.3448\n",
      "Iter-14950, train loss-2.2076, acc-0.3200, valid loss-2.1835, acc-0.3428, test loss-2.1760, acc-0.3449\n",
      "Iter-14960, train loss-2.1668, acc-0.3800, valid loss-2.1835, acc-0.3428, test loss-2.1759, acc-0.3451\n",
      "Iter-14970, train loss-2.2110, acc-0.2600, valid loss-2.1834, acc-0.3434, test loss-2.1759, acc-0.3451\n",
      "Iter-14980, train loss-2.2507, acc-0.2800, valid loss-2.1833, acc-0.3436, test loss-2.1758, acc-0.3449\n",
      "Iter-14990, train loss-2.1806, acc-0.3800, valid loss-2.1833, acc-0.3438, test loss-2.1757, acc-0.3452\n",
      "Iter-15000, train loss-2.2055, acc-0.3000, valid loss-2.1832, acc-0.3436, test loss-2.1757, acc-0.3456\n",
      "Iter-15010, train loss-2.1519, acc-0.3200, valid loss-2.1832, acc-0.3436, test loss-2.1756, acc-0.3460\n",
      "Iter-15020, train loss-2.1900, acc-0.3000, valid loss-2.1831, acc-0.3440, test loss-2.1755, acc-0.3462\n",
      "Iter-15030, train loss-2.1931, acc-0.2800, valid loss-2.1830, acc-0.3438, test loss-2.1754, acc-0.3464\n",
      "Iter-15040, train loss-2.1685, acc-0.3800, valid loss-2.1830, acc-0.3440, test loss-2.1754, acc-0.3469\n",
      "Iter-15050, train loss-2.1660, acc-0.3200, valid loss-2.1829, acc-0.3434, test loss-2.1753, acc-0.3467\n",
      "Iter-15060, train loss-2.1656, acc-0.3800, valid loss-2.1828, acc-0.3436, test loss-2.1752, acc-0.3467\n",
      "Iter-15070, train loss-2.2020, acc-0.3600, valid loss-2.1828, acc-0.3434, test loss-2.1751, acc-0.3469\n",
      "Iter-15080, train loss-2.1931, acc-0.3800, valid loss-2.1827, acc-0.3432, test loss-2.1751, acc-0.3469\n",
      "Iter-15090, train loss-2.1717, acc-0.3000, valid loss-2.1826, acc-0.3436, test loss-2.1750, acc-0.3470\n",
      "Iter-15100, train loss-2.1667, acc-0.2600, valid loss-2.1826, acc-0.3438, test loss-2.1749, acc-0.3474\n",
      "Iter-15110, train loss-2.1708, acc-0.3600, valid loss-2.1825, acc-0.3440, test loss-2.1748, acc-0.3477\n",
      "Iter-15120, train loss-2.2031, acc-0.2600, valid loss-2.1824, acc-0.3440, test loss-2.1748, acc-0.3479\n",
      "Iter-15130, train loss-2.1949, acc-0.3000, valid loss-2.1824, acc-0.3436, test loss-2.1747, acc-0.3479\n",
      "Iter-15140, train loss-2.1391, acc-0.3800, valid loss-2.1823, acc-0.3432, test loss-2.1746, acc-0.3484\n",
      "Iter-15150, train loss-2.2147, acc-0.2400, valid loss-2.1822, acc-0.3434, test loss-2.1746, acc-0.3484\n",
      "Iter-15160, train loss-2.1603, acc-0.3400, valid loss-2.1822, acc-0.3436, test loss-2.1745, acc-0.3487\n",
      "Iter-15170, train loss-2.2039, acc-0.2800, valid loss-2.1821, acc-0.3438, test loss-2.1744, acc-0.3485\n",
      "Iter-15180, train loss-2.1861, acc-0.3800, valid loss-2.1820, acc-0.3438, test loss-2.1743, acc-0.3486\n",
      "Iter-15190, train loss-2.1716, acc-0.2600, valid loss-2.1820, acc-0.3440, test loss-2.1743, acc-0.3485\n",
      "Iter-15200, train loss-2.1833, acc-0.3800, valid loss-2.1819, acc-0.3444, test loss-2.1742, acc-0.3488\n",
      "Iter-15210, train loss-2.1383, acc-0.5600, valid loss-2.1818, acc-0.3444, test loss-2.1741, acc-0.3488\n",
      "Iter-15220, train loss-2.1810, acc-0.4000, valid loss-2.1818, acc-0.3442, test loss-2.1740, acc-0.3486\n",
      "Iter-15230, train loss-2.1371, acc-0.4200, valid loss-2.1817, acc-0.3446, test loss-2.1740, acc-0.3488\n",
      "Iter-15240, train loss-2.1680, acc-0.3400, valid loss-2.1816, acc-0.3452, test loss-2.1739, acc-0.3490\n",
      "Iter-15250, train loss-2.2072, acc-0.2400, valid loss-2.1815, acc-0.3454, test loss-2.1738, acc-0.3494\n",
      "Iter-15260, train loss-2.1936, acc-0.3600, valid loss-2.1815, acc-0.3452, test loss-2.1737, acc-0.3494\n",
      "Iter-15270, train loss-2.1680, acc-0.3600, valid loss-2.1814, acc-0.3454, test loss-2.1737, acc-0.3492\n",
      "Iter-15280, train loss-2.1734, acc-0.4200, valid loss-2.1813, acc-0.3454, test loss-2.1736, acc-0.3490\n",
      "Iter-15290, train loss-2.1674, acc-0.3600, valid loss-2.1813, acc-0.3454, test loss-2.1735, acc-0.3495\n",
      "Iter-15300, train loss-2.1850, acc-0.3200, valid loss-2.1812, acc-0.3454, test loss-2.1734, acc-0.3495\n",
      "Iter-15310, train loss-2.1617, acc-0.3800, valid loss-2.1811, acc-0.3458, test loss-2.1734, acc-0.3494\n",
      "Iter-15320, train loss-2.1965, acc-0.3200, valid loss-2.1811, acc-0.3458, test loss-2.1733, acc-0.3496\n",
      "Iter-15330, train loss-2.1898, acc-0.3200, valid loss-2.1810, acc-0.3464, test loss-2.1732, acc-0.3499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-15340, train loss-2.1977, acc-0.2200, valid loss-2.1809, acc-0.3464, test loss-2.1731, acc-0.3501\n",
      "Iter-15350, train loss-2.1682, acc-0.3600, valid loss-2.1809, acc-0.3464, test loss-2.1731, acc-0.3506\n",
      "Iter-15360, train loss-2.1599, acc-0.3600, valid loss-2.1808, acc-0.3464, test loss-2.1730, acc-0.3506\n",
      "Iter-15370, train loss-2.1954, acc-0.3800, valid loss-2.1807, acc-0.3464, test loss-2.1729, acc-0.3505\n",
      "Iter-15380, train loss-2.1582, acc-0.3400, valid loss-2.1807, acc-0.3466, test loss-2.1729, acc-0.3510\n",
      "Iter-15390, train loss-2.1581, acc-0.4200, valid loss-2.1806, acc-0.3466, test loss-2.1728, acc-0.3512\n",
      "Iter-15400, train loss-2.1636, acc-0.3000, valid loss-2.1805, acc-0.3466, test loss-2.1727, acc-0.3512\n",
      "Iter-15410, train loss-2.1923, acc-0.3000, valid loss-2.1805, acc-0.3474, test loss-2.1726, acc-0.3509\n",
      "Iter-15420, train loss-2.1608, acc-0.4200, valid loss-2.1804, acc-0.3480, test loss-2.1726, acc-0.3514\n",
      "Iter-15430, train loss-2.1630, acc-0.3000, valid loss-2.1803, acc-0.3474, test loss-2.1725, acc-0.3518\n",
      "Iter-15440, train loss-2.1801, acc-0.3600, valid loss-2.1803, acc-0.3472, test loss-2.1724, acc-0.3518\n",
      "Iter-15450, train loss-2.1739, acc-0.4000, valid loss-2.1802, acc-0.3468, test loss-2.1723, acc-0.3520\n",
      "Iter-15460, train loss-2.1615, acc-0.4000, valid loss-2.1801, acc-0.3466, test loss-2.1723, acc-0.3517\n",
      "Iter-15470, train loss-2.1788, acc-0.3600, valid loss-2.1801, acc-0.3468, test loss-2.1722, acc-0.3519\n",
      "Iter-15480, train loss-2.1732, acc-0.3200, valid loss-2.1800, acc-0.3474, test loss-2.1721, acc-0.3520\n",
      "Iter-15490, train loss-2.1890, acc-0.3400, valid loss-2.1799, acc-0.3472, test loss-2.1721, acc-0.3522\n",
      "Iter-15500, train loss-2.1809, acc-0.3000, valid loss-2.1799, acc-0.3476, test loss-2.1720, acc-0.3523\n",
      "Iter-15510, train loss-2.2146, acc-0.2600, valid loss-2.1798, acc-0.3482, test loss-2.1719, acc-0.3524\n",
      "Iter-15520, train loss-2.1780, acc-0.2600, valid loss-2.1797, acc-0.3484, test loss-2.1718, acc-0.3527\n",
      "Iter-15530, train loss-2.1589, acc-0.3000, valid loss-2.1797, acc-0.3486, test loss-2.1718, acc-0.3525\n",
      "Iter-15540, train loss-2.1983, acc-0.3800, valid loss-2.1796, acc-0.3486, test loss-2.1717, acc-0.3528\n",
      "Iter-15550, train loss-2.2217, acc-0.3600, valid loss-2.1795, acc-0.3484, test loss-2.1716, acc-0.3528\n",
      "Iter-15560, train loss-2.1732, acc-0.2800, valid loss-2.1795, acc-0.3482, test loss-2.1716, acc-0.3534\n",
      "Iter-15570, train loss-2.2021, acc-0.2800, valid loss-2.1794, acc-0.3484, test loss-2.1715, acc-0.3536\n",
      "Iter-15580, train loss-2.1788, acc-0.3400, valid loss-2.1793, acc-0.3484, test loss-2.1714, acc-0.3540\n",
      "Iter-15590, train loss-2.1319, acc-0.4400, valid loss-2.1793, acc-0.3488, test loss-2.1713, acc-0.3539\n",
      "Iter-15600, train loss-2.1770, acc-0.3600, valid loss-2.1792, acc-0.3486, test loss-2.1713, acc-0.3539\n",
      "Iter-15610, train loss-2.1947, acc-0.3000, valid loss-2.1791, acc-0.3486, test loss-2.1712, acc-0.3540\n",
      "Iter-15620, train loss-2.1899, acc-0.3000, valid loss-2.1791, acc-0.3492, test loss-2.1711, acc-0.3544\n",
      "Iter-15630, train loss-2.1389, acc-0.3400, valid loss-2.1790, acc-0.3494, test loss-2.1710, acc-0.3544\n",
      "Iter-15640, train loss-2.1625, acc-0.3400, valid loss-2.1789, acc-0.3492, test loss-2.1710, acc-0.3545\n",
      "Iter-15650, train loss-2.1624, acc-0.3200, valid loss-2.1789, acc-0.3492, test loss-2.1709, acc-0.3545\n",
      "Iter-15660, train loss-2.1873, acc-0.3600, valid loss-2.1788, acc-0.3492, test loss-2.1708, acc-0.3548\n",
      "Iter-15670, train loss-2.1950, acc-0.3200, valid loss-2.1787, acc-0.3500, test loss-2.1708, acc-0.3553\n",
      "Iter-15680, train loss-2.1757, acc-0.3800, valid loss-2.1787, acc-0.3500, test loss-2.1707, acc-0.3555\n",
      "Iter-15690, train loss-2.1551, acc-0.3800, valid loss-2.1786, acc-0.3502, test loss-2.1706, acc-0.3556\n",
      "Iter-15700, train loss-2.1820, acc-0.2800, valid loss-2.1785, acc-0.3502, test loss-2.1705, acc-0.3559\n",
      "Iter-15710, train loss-2.1489, acc-0.4200, valid loss-2.1785, acc-0.3506, test loss-2.1705, acc-0.3560\n",
      "Iter-15720, train loss-2.1616, acc-0.3600, valid loss-2.1784, acc-0.3504, test loss-2.1704, acc-0.3564\n",
      "Iter-15730, train loss-2.1963, acc-0.3400, valid loss-2.1783, acc-0.3504, test loss-2.1703, acc-0.3563\n",
      "Iter-15740, train loss-2.1873, acc-0.2600, valid loss-2.1783, acc-0.3504, test loss-2.1702, acc-0.3567\n",
      "Iter-15750, train loss-2.1512, acc-0.4200, valid loss-2.1782, acc-0.3512, test loss-2.1702, acc-0.3566\n",
      "Iter-15760, train loss-2.2061, acc-0.1800, valid loss-2.1781, acc-0.3514, test loss-2.1701, acc-0.3566\n",
      "Iter-15770, train loss-2.1637, acc-0.4800, valid loss-2.1781, acc-0.3514, test loss-2.1700, acc-0.3563\n",
      "Iter-15780, train loss-2.1507, acc-0.3200, valid loss-2.1780, acc-0.3516, test loss-2.1700, acc-0.3564\n",
      "Iter-15790, train loss-2.2093, acc-0.3200, valid loss-2.1779, acc-0.3512, test loss-2.1699, acc-0.3563\n",
      "Iter-15800, train loss-2.1752, acc-0.4000, valid loss-2.1779, acc-0.3514, test loss-2.1698, acc-0.3564\n",
      "Iter-15810, train loss-2.1276, acc-0.3800, valid loss-2.1778, acc-0.3518, test loss-2.1697, acc-0.3567\n",
      "Iter-15820, train loss-2.1666, acc-0.3200, valid loss-2.1777, acc-0.3518, test loss-2.1697, acc-0.3570\n",
      "Iter-15830, train loss-2.1800, acc-0.3000, valid loss-2.1777, acc-0.3516, test loss-2.1696, acc-0.3571\n",
      "Iter-15840, train loss-2.1906, acc-0.3800, valid loss-2.1776, acc-0.3520, test loss-2.1695, acc-0.3574\n",
      "Iter-15850, train loss-2.1441, acc-0.3800, valid loss-2.1775, acc-0.3522, test loss-2.1694, acc-0.3575\n",
      "Iter-15860, train loss-2.2031, acc-0.2600, valid loss-2.1775, acc-0.3518, test loss-2.1694, acc-0.3575\n",
      "Iter-15870, train loss-2.1690, acc-0.5000, valid loss-2.1774, acc-0.3518, test loss-2.1693, acc-0.3576\n",
      "Iter-15880, train loss-2.1627, acc-0.4000, valid loss-2.1773, acc-0.3516, test loss-2.1692, acc-0.3573\n",
      "Iter-15890, train loss-2.1574, acc-0.3800, valid loss-2.1773, acc-0.3514, test loss-2.1692, acc-0.3575\n",
      "Iter-15900, train loss-2.1829, acc-0.3400, valid loss-2.1772, acc-0.3520, test loss-2.1691, acc-0.3580\n",
      "Iter-15910, train loss-2.1882, acc-0.2600, valid loss-2.1772, acc-0.3514, test loss-2.1690, acc-0.3578\n",
      "Iter-15920, train loss-2.1769, acc-0.2800, valid loss-2.1771, acc-0.3520, test loss-2.1689, acc-0.3581\n",
      "Iter-15930, train loss-2.1815, acc-0.2800, valid loss-2.1770, acc-0.3518, test loss-2.1689, acc-0.3581\n",
      "Iter-15940, train loss-2.1953, acc-0.2600, valid loss-2.1770, acc-0.3520, test loss-2.1688, acc-0.3582\n",
      "Iter-15950, train loss-2.1508, acc-0.4800, valid loss-2.1769, acc-0.3526, test loss-2.1687, acc-0.3580\n",
      "Iter-15960, train loss-2.1429, acc-0.4200, valid loss-2.1768, acc-0.3534, test loss-2.1687, acc-0.3582\n",
      "Iter-15970, train loss-2.1663, acc-0.4200, valid loss-2.1767, acc-0.3538, test loss-2.1686, acc-0.3582\n",
      "Iter-15980, train loss-2.2118, acc-0.3200, valid loss-2.1767, acc-0.3540, test loss-2.1685, acc-0.3580\n",
      "Iter-15990, train loss-2.1748, acc-0.3400, valid loss-2.1766, acc-0.3540, test loss-2.1684, acc-0.3583\n",
      "Iter-16000, train loss-2.1576, acc-0.3400, valid loss-2.1766, acc-0.3540, test loss-2.1684, acc-0.3583\n",
      "Iter-16010, train loss-2.1837, acc-0.3000, valid loss-2.1765, acc-0.3544, test loss-2.1683, acc-0.3584\n",
      "Iter-16020, train loss-2.1529, acc-0.4200, valid loss-2.1764, acc-0.3536, test loss-2.1682, acc-0.3586\n",
      "Iter-16030, train loss-2.1842, acc-0.3200, valid loss-2.1763, acc-0.3536, test loss-2.1681, acc-0.3587\n",
      "Iter-16040, train loss-2.1821, acc-0.3400, valid loss-2.1763, acc-0.3534, test loss-2.1681, acc-0.3588\n",
      "Iter-16050, train loss-2.1588, acc-0.3400, valid loss-2.1762, acc-0.3534, test loss-2.1680, acc-0.3589\n",
      "Iter-16060, train loss-2.1922, acc-0.2600, valid loss-2.1761, acc-0.3534, test loss-2.1679, acc-0.3595\n",
      "Iter-16070, train loss-2.1486, acc-0.3800, valid loss-2.1761, acc-0.3532, test loss-2.1678, acc-0.3594\n",
      "Iter-16080, train loss-2.1950, acc-0.3200, valid loss-2.1760, acc-0.3530, test loss-2.1678, acc-0.3597\n",
      "Iter-16090, train loss-2.1683, acc-0.4000, valid loss-2.1759, acc-0.3528, test loss-2.1677, acc-0.3599\n",
      "Iter-16100, train loss-2.1729, acc-0.3400, valid loss-2.1759, acc-0.3532, test loss-2.1676, acc-0.3599\n",
      "Iter-16110, train loss-2.2054, acc-0.2000, valid loss-2.1758, acc-0.3532, test loss-2.1675, acc-0.3601\n",
      "Iter-16120, train loss-2.1328, acc-0.3800, valid loss-2.1757, acc-0.3530, test loss-2.1675, acc-0.3601\n",
      "Iter-16130, train loss-2.1797, acc-0.3600, valid loss-2.1757, acc-0.3526, test loss-2.1674, acc-0.3599\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16140, train loss-2.1834, acc-0.3200, valid loss-2.1756, acc-0.3528, test loss-2.1673, acc-0.3608\n",
      "Iter-16150, train loss-2.1666, acc-0.4600, valid loss-2.1755, acc-0.3524, test loss-2.1672, acc-0.3609\n",
      "Iter-16160, train loss-2.1900, acc-0.2600, valid loss-2.1755, acc-0.3528, test loss-2.1672, acc-0.3610\n",
      "Iter-16170, train loss-2.1902, acc-0.3400, valid loss-2.1754, acc-0.3532, test loss-2.1671, acc-0.3608\n",
      "Iter-16180, train loss-2.1635, acc-0.3200, valid loss-2.1753, acc-0.3530, test loss-2.1670, acc-0.3613\n",
      "Iter-16190, train loss-2.1924, acc-0.2800, valid loss-2.1753, acc-0.3532, test loss-2.1669, acc-0.3612\n",
      "Iter-16200, train loss-2.1525, acc-0.2800, valid loss-2.1752, acc-0.3532, test loss-2.1669, acc-0.3615\n",
      "Iter-16210, train loss-2.1584, acc-0.4000, valid loss-2.1751, acc-0.3532, test loss-2.1668, acc-0.3615\n",
      "Iter-16220, train loss-2.1543, acc-0.4000, valid loss-2.1751, acc-0.3536, test loss-2.1667, acc-0.3615\n",
      "Iter-16230, train loss-2.1994, acc-0.2600, valid loss-2.1750, acc-0.3534, test loss-2.1667, acc-0.3612\n",
      "Iter-16240, train loss-2.1673, acc-0.3000, valid loss-2.1749, acc-0.3538, test loss-2.1666, acc-0.3615\n",
      "Iter-16250, train loss-2.1621, acc-0.3800, valid loss-2.1749, acc-0.3534, test loss-2.1665, acc-0.3615\n",
      "Iter-16260, train loss-2.1810, acc-0.3600, valid loss-2.1748, acc-0.3532, test loss-2.1664, acc-0.3616\n",
      "Iter-16270, train loss-2.1595, acc-0.4400, valid loss-2.1747, acc-0.3530, test loss-2.1664, acc-0.3619\n",
      "Iter-16280, train loss-2.1880, acc-0.3000, valid loss-2.1747, acc-0.3530, test loss-2.1663, acc-0.3616\n",
      "Iter-16290, train loss-2.2034, acc-0.3200, valid loss-2.1746, acc-0.3532, test loss-2.1662, acc-0.3617\n",
      "Iter-16300, train loss-2.1653, acc-0.4000, valid loss-2.1745, acc-0.3532, test loss-2.1662, acc-0.3615\n",
      "Iter-16310, train loss-2.1294, acc-0.4400, valid loss-2.1745, acc-0.3532, test loss-2.1661, acc-0.3613\n",
      "Iter-16320, train loss-2.1904, acc-0.3200, valid loss-2.1744, acc-0.3534, test loss-2.1660, acc-0.3613\n",
      "Iter-16330, train loss-2.1170, acc-0.5600, valid loss-2.1743, acc-0.3530, test loss-2.1659, acc-0.3615\n",
      "Iter-16340, train loss-2.1618, acc-0.4400, valid loss-2.1743, acc-0.3534, test loss-2.1659, acc-0.3616\n",
      "Iter-16350, train loss-2.1158, acc-0.4400, valid loss-2.1742, acc-0.3534, test loss-2.1658, acc-0.3616\n",
      "Iter-16360, train loss-2.1527, acc-0.4400, valid loss-2.1741, acc-0.3536, test loss-2.1657, acc-0.3618\n",
      "Iter-16370, train loss-2.1652, acc-0.3400, valid loss-2.1741, acc-0.3534, test loss-2.1656, acc-0.3621\n",
      "Iter-16380, train loss-2.1406, acc-0.5200, valid loss-2.1740, acc-0.3534, test loss-2.1656, acc-0.3621\n",
      "Iter-16390, train loss-2.1640, acc-0.4200, valid loss-2.1739, acc-0.3536, test loss-2.1655, acc-0.3618\n",
      "Iter-16400, train loss-2.1519, acc-0.3400, valid loss-2.1739, acc-0.3536, test loss-2.1654, acc-0.3618\n",
      "Iter-16410, train loss-2.1675, acc-0.3200, valid loss-2.1738, acc-0.3538, test loss-2.1654, acc-0.3620\n",
      "Iter-16420, train loss-2.1672, acc-0.5000, valid loss-2.1738, acc-0.3536, test loss-2.1653, acc-0.3624\n",
      "Iter-16430, train loss-2.1577, acc-0.4000, valid loss-2.1737, acc-0.3536, test loss-2.1652, acc-0.3625\n",
      "Iter-16440, train loss-2.1281, acc-0.4200, valid loss-2.1736, acc-0.3544, test loss-2.1651, acc-0.3626\n",
      "Iter-16450, train loss-2.1613, acc-0.2600, valid loss-2.1736, acc-0.3544, test loss-2.1651, acc-0.3627\n",
      "Iter-16460, train loss-2.1504, acc-0.3400, valid loss-2.1735, acc-0.3544, test loss-2.1650, acc-0.3629\n",
      "Iter-16470, train loss-2.1338, acc-0.5200, valid loss-2.1734, acc-0.3544, test loss-2.1649, acc-0.3632\n",
      "Iter-16480, train loss-2.1530, acc-0.3600, valid loss-2.1734, acc-0.3548, test loss-2.1648, acc-0.3630\n",
      "Iter-16490, train loss-2.1881, acc-0.3200, valid loss-2.1733, acc-0.3542, test loss-2.1648, acc-0.3631\n",
      "Iter-16500, train loss-2.1621, acc-0.4600, valid loss-2.1732, acc-0.3550, test loss-2.1647, acc-0.3630\n",
      "Iter-16510, train loss-2.1720, acc-0.4000, valid loss-2.1732, acc-0.3548, test loss-2.1646, acc-0.3633\n",
      "Iter-16520, train loss-2.1733, acc-0.3800, valid loss-2.1731, acc-0.3554, test loss-2.1646, acc-0.3631\n",
      "Iter-16530, train loss-2.1833, acc-0.3000, valid loss-2.1730, acc-0.3546, test loss-2.1645, acc-0.3640\n",
      "Iter-16540, train loss-2.1845, acc-0.3400, valid loss-2.1730, acc-0.3548, test loss-2.1644, acc-0.3640\n",
      "Iter-16550, train loss-2.2095, acc-0.2400, valid loss-2.1729, acc-0.3550, test loss-2.1643, acc-0.3638\n",
      "Iter-16560, train loss-2.1897, acc-0.2400, valid loss-2.1728, acc-0.3552, test loss-2.1643, acc-0.3638\n",
      "Iter-16570, train loss-2.1842, acc-0.3000, valid loss-2.1728, acc-0.3552, test loss-2.1642, acc-0.3640\n",
      "Iter-16580, train loss-2.1717, acc-0.2800, valid loss-2.1727, acc-0.3556, test loss-2.1641, acc-0.3640\n",
      "Iter-16590, train loss-2.1928, acc-0.4200, valid loss-2.1726, acc-0.3556, test loss-2.1641, acc-0.3640\n",
      "Iter-16600, train loss-2.1668, acc-0.3000, valid loss-2.1726, acc-0.3552, test loss-2.1640, acc-0.3645\n",
      "Iter-16610, train loss-2.1679, acc-0.3800, valid loss-2.1725, acc-0.3554, test loss-2.1639, acc-0.3649\n",
      "Iter-16620, train loss-2.1253, acc-0.5400, valid loss-2.1724, acc-0.3552, test loss-2.1639, acc-0.3649\n",
      "Iter-16630, train loss-2.1710, acc-0.4000, valid loss-2.1724, acc-0.3554, test loss-2.1638, acc-0.3649\n",
      "Iter-16640, train loss-2.1438, acc-0.3400, valid loss-2.1723, acc-0.3554, test loss-2.1637, acc-0.3648\n",
      "Iter-16650, train loss-2.1322, acc-0.4200, valid loss-2.1722, acc-0.3550, test loss-2.1636, acc-0.3650\n",
      "Iter-16660, train loss-2.1477, acc-0.4400, valid loss-2.1722, acc-0.3556, test loss-2.1636, acc-0.3652\n",
      "Iter-16670, train loss-2.1515, acc-0.2600, valid loss-2.1721, acc-0.3556, test loss-2.1635, acc-0.3652\n",
      "Iter-16680, train loss-2.1704, acc-0.3600, valid loss-2.1721, acc-0.3554, test loss-2.1634, acc-0.3653\n",
      "Iter-16690, train loss-2.1563, acc-0.4000, valid loss-2.1720, acc-0.3562, test loss-2.1633, acc-0.3657\n",
      "Iter-16700, train loss-2.1892, acc-0.3400, valid loss-2.1719, acc-0.3556, test loss-2.1633, acc-0.3657\n",
      "Iter-16710, train loss-2.2068, acc-0.3200, valid loss-2.1719, acc-0.3550, test loss-2.1632, acc-0.3658\n",
      "Iter-16720, train loss-2.1798, acc-0.3800, valid loss-2.1718, acc-0.3560, test loss-2.1631, acc-0.3662\n",
      "Iter-16730, train loss-2.1652, acc-0.3800, valid loss-2.1717, acc-0.3558, test loss-2.1631, acc-0.3665\n",
      "Iter-16740, train loss-2.1510, acc-0.3400, valid loss-2.1716, acc-0.3564, test loss-2.1630, acc-0.3664\n",
      "Iter-16750, train loss-2.1567, acc-0.3600, valid loss-2.1716, acc-0.3560, test loss-2.1629, acc-0.3664\n",
      "Iter-16760, train loss-2.1541, acc-0.4400, valid loss-2.1715, acc-0.3560, test loss-2.1628, acc-0.3664\n",
      "Iter-16770, train loss-2.1501, acc-0.3600, valid loss-2.1715, acc-0.3564, test loss-2.1628, acc-0.3670\n",
      "Iter-16780, train loss-2.1835, acc-0.2800, valid loss-2.1714, acc-0.3564, test loss-2.1627, acc-0.3670\n",
      "Iter-16790, train loss-2.1410, acc-0.4000, valid loss-2.1713, acc-0.3564, test loss-2.1626, acc-0.3666\n",
      "Iter-16800, train loss-2.1614, acc-0.3200, valid loss-2.1713, acc-0.3568, test loss-2.1626, acc-0.3667\n",
      "Iter-16810, train loss-2.1612, acc-0.3800, valid loss-2.1712, acc-0.3566, test loss-2.1625, acc-0.3669\n",
      "Iter-16820, train loss-2.1808, acc-0.2400, valid loss-2.1711, acc-0.3570, test loss-2.1624, acc-0.3671\n",
      "Iter-16830, train loss-2.1535, acc-0.4200, valid loss-2.1711, acc-0.3572, test loss-2.1623, acc-0.3672\n",
      "Iter-16840, train loss-2.1737, acc-0.3200, valid loss-2.1710, acc-0.3572, test loss-2.1623, acc-0.3673\n",
      "Iter-16850, train loss-2.1774, acc-0.3600, valid loss-2.1709, acc-0.3574, test loss-2.1622, acc-0.3673\n",
      "Iter-16860, train loss-2.1748, acc-0.3000, valid loss-2.1709, acc-0.3574, test loss-2.1621, acc-0.3672\n",
      "Iter-16870, train loss-2.1564, acc-0.3400, valid loss-2.1708, acc-0.3574, test loss-2.1621, acc-0.3672\n",
      "Iter-16880, train loss-2.1560, acc-0.4800, valid loss-2.1707, acc-0.3572, test loss-2.1620, acc-0.3673\n",
      "Iter-16890, train loss-2.1783, acc-0.3600, valid loss-2.1707, acc-0.3578, test loss-2.1619, acc-0.3674\n",
      "Iter-16900, train loss-2.1950, acc-0.2400, valid loss-2.1706, acc-0.3578, test loss-2.1618, acc-0.3675\n",
      "Iter-16910, train loss-2.1441, acc-0.3600, valid loss-2.1705, acc-0.3576, test loss-2.1618, acc-0.3675\n",
      "Iter-16920, train loss-2.1523, acc-0.5000, valid loss-2.1705, acc-0.3582, test loss-2.1617, acc-0.3680\n",
      "Iter-16930, train loss-2.1917, acc-0.3400, valid loss-2.1704, acc-0.3580, test loss-2.1616, acc-0.3680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16940, train loss-2.1585, acc-0.3800, valid loss-2.1704, acc-0.3580, test loss-2.1616, acc-0.3683\n",
      "Iter-16950, train loss-2.1422, acc-0.3800, valid loss-2.1703, acc-0.3584, test loss-2.1615, acc-0.3682\n",
      "Iter-16960, train loss-2.1163, acc-0.3600, valid loss-2.1702, acc-0.3584, test loss-2.1614, acc-0.3682\n",
      "Iter-16970, train loss-2.1157, acc-0.5600, valid loss-2.1702, acc-0.3586, test loss-2.1614, acc-0.3685\n",
      "Iter-16980, train loss-2.1926, acc-0.2800, valid loss-2.1701, acc-0.3584, test loss-2.1613, acc-0.3684\n",
      "Iter-16990, train loss-2.1737, acc-0.3000, valid loss-2.1701, acc-0.3584, test loss-2.1612, acc-0.3682\n",
      "Iter-17000, train loss-2.1594, acc-0.3600, valid loss-2.1700, acc-0.3584, test loss-2.1611, acc-0.3684\n",
      "Iter-17010, train loss-2.1155, acc-0.4400, valid loss-2.1699, acc-0.3588, test loss-2.1611, acc-0.3686\n",
      "Iter-17020, train loss-2.2170, acc-0.2600, valid loss-2.1699, acc-0.3588, test loss-2.1610, acc-0.3692\n",
      "Iter-17030, train loss-2.1513, acc-0.4200, valid loss-2.1698, acc-0.3590, test loss-2.1609, acc-0.3694\n",
      "Iter-17040, train loss-2.1256, acc-0.3600, valid loss-2.1697, acc-0.3594, test loss-2.1609, acc-0.3700\n",
      "Iter-17050, train loss-2.1775, acc-0.4200, valid loss-2.1696, acc-0.3596, test loss-2.1608, acc-0.3696\n",
      "Iter-17060, train loss-2.1494, acc-0.3400, valid loss-2.1696, acc-0.3598, test loss-2.1607, acc-0.3696\n",
      "Iter-17070, train loss-2.1696, acc-0.2800, valid loss-2.1695, acc-0.3598, test loss-2.1606, acc-0.3700\n",
      "Iter-17080, train loss-2.1753, acc-0.3600, valid loss-2.1695, acc-0.3598, test loss-2.1606, acc-0.3699\n",
      "Iter-17090, train loss-2.1989, acc-0.3200, valid loss-2.1694, acc-0.3600, test loss-2.1605, acc-0.3700\n",
      "Iter-17100, train loss-2.2009, acc-0.3600, valid loss-2.1693, acc-0.3600, test loss-2.1604, acc-0.3699\n",
      "Iter-17110, train loss-2.1490, acc-0.4600, valid loss-2.1693, acc-0.3602, test loss-2.1604, acc-0.3702\n",
      "Iter-17120, train loss-2.1743, acc-0.3600, valid loss-2.1692, acc-0.3602, test loss-2.1603, acc-0.3701\n",
      "Iter-17130, train loss-2.1382, acc-0.3600, valid loss-2.1691, acc-0.3606, test loss-2.1602, acc-0.3704\n",
      "Iter-17140, train loss-2.1475, acc-0.4600, valid loss-2.1691, acc-0.3606, test loss-2.1601, acc-0.3703\n",
      "Iter-17150, train loss-2.1635, acc-0.3400, valid loss-2.1690, acc-0.3606, test loss-2.1601, acc-0.3705\n",
      "Iter-17160, train loss-2.2100, acc-0.2800, valid loss-2.1689, acc-0.3604, test loss-2.1600, acc-0.3708\n",
      "Iter-17170, train loss-2.2032, acc-0.2200, valid loss-2.1689, acc-0.3608, test loss-2.1599, acc-0.3707\n",
      "Iter-17180, train loss-2.1454, acc-0.3800, valid loss-2.1688, acc-0.3608, test loss-2.1599, acc-0.3705\n",
      "Iter-17190, train loss-2.1329, acc-0.4000, valid loss-2.1687, acc-0.3612, test loss-2.1598, acc-0.3705\n",
      "Iter-17200, train loss-2.1391, acc-0.5400, valid loss-2.1687, acc-0.3608, test loss-2.1597, acc-0.3704\n",
      "Iter-17210, train loss-2.1538, acc-0.4200, valid loss-2.1686, acc-0.3616, test loss-2.1596, acc-0.3706\n",
      "Iter-17220, train loss-2.2075, acc-0.3200, valid loss-2.1685, acc-0.3616, test loss-2.1596, acc-0.3707\n",
      "Iter-17230, train loss-2.2121, acc-0.3200, valid loss-2.1685, acc-0.3616, test loss-2.1595, acc-0.3709\n",
      "Iter-17240, train loss-2.1762, acc-0.2200, valid loss-2.1684, acc-0.3616, test loss-2.1594, acc-0.3711\n",
      "Iter-17250, train loss-2.1512, acc-0.4800, valid loss-2.1684, acc-0.3616, test loss-2.1594, acc-0.3712\n",
      "Iter-17260, train loss-2.1276, acc-0.4200, valid loss-2.1683, acc-0.3618, test loss-2.1593, acc-0.3714\n",
      "Iter-17270, train loss-2.1917, acc-0.2000, valid loss-2.1682, acc-0.3620, test loss-2.1592, acc-0.3713\n",
      "Iter-17280, train loss-2.1776, acc-0.3800, valid loss-2.1682, acc-0.3620, test loss-2.1592, acc-0.3715\n",
      "Iter-17290, train loss-2.1687, acc-0.3400, valid loss-2.1681, acc-0.3622, test loss-2.1591, acc-0.3717\n",
      "Iter-17300, train loss-2.1559, acc-0.4400, valid loss-2.1680, acc-0.3624, test loss-2.1590, acc-0.3718\n",
      "Iter-17310, train loss-2.2069, acc-0.3000, valid loss-2.1680, acc-0.3620, test loss-2.1589, acc-0.3718\n",
      "Iter-17320, train loss-2.1742, acc-0.2800, valid loss-2.1679, acc-0.3624, test loss-2.1589, acc-0.3718\n",
      "Iter-17330, train loss-2.1659, acc-0.3600, valid loss-2.1678, acc-0.3624, test loss-2.1588, acc-0.3719\n",
      "Iter-17340, train loss-2.1874, acc-0.2600, valid loss-2.1678, acc-0.3628, test loss-2.1587, acc-0.3718\n",
      "Iter-17350, train loss-2.1639, acc-0.3800, valid loss-2.1677, acc-0.3620, test loss-2.1587, acc-0.3719\n",
      "Iter-17360, train loss-2.1747, acc-0.4000, valid loss-2.1677, acc-0.3628, test loss-2.1586, acc-0.3721\n",
      "Iter-17370, train loss-2.1692, acc-0.3400, valid loss-2.1676, acc-0.3630, test loss-2.1585, acc-0.3725\n",
      "Iter-17380, train loss-2.1726, acc-0.4200, valid loss-2.1675, acc-0.3634, test loss-2.1584, acc-0.3721\n",
      "Iter-17390, train loss-2.1879, acc-0.3800, valid loss-2.1675, acc-0.3634, test loss-2.1584, acc-0.3724\n",
      "Iter-17400, train loss-2.1507, acc-0.4000, valid loss-2.1674, acc-0.3638, test loss-2.1583, acc-0.3725\n",
      "Iter-17410, train loss-2.1689, acc-0.2400, valid loss-2.1673, acc-0.3634, test loss-2.1582, acc-0.3725\n",
      "Iter-17420, train loss-2.1842, acc-0.3200, valid loss-2.1673, acc-0.3638, test loss-2.1582, acc-0.3722\n",
      "Iter-17430, train loss-2.1471, acc-0.3800, valid loss-2.1672, acc-0.3638, test loss-2.1581, acc-0.3724\n",
      "Iter-17440, train loss-2.1468, acc-0.4000, valid loss-2.1672, acc-0.3642, test loss-2.1580, acc-0.3729\n",
      "Iter-17450, train loss-2.1966, acc-0.3400, valid loss-2.1671, acc-0.3642, test loss-2.1580, acc-0.3727\n",
      "Iter-17460, train loss-2.1566, acc-0.3000, valid loss-2.1670, acc-0.3646, test loss-2.1579, acc-0.3730\n",
      "Iter-17470, train loss-2.1284, acc-0.5000, valid loss-2.1670, acc-0.3646, test loss-2.1578, acc-0.3731\n",
      "Iter-17480, train loss-2.1562, acc-0.3400, valid loss-2.1669, acc-0.3646, test loss-2.1578, acc-0.3736\n",
      "Iter-17490, train loss-2.1466, acc-0.4200, valid loss-2.1668, acc-0.3646, test loss-2.1577, acc-0.3736\n",
      "Iter-17500, train loss-2.1555, acc-0.3600, valid loss-2.1668, acc-0.3644, test loss-2.1576, acc-0.3736\n",
      "Iter-17510, train loss-2.1721, acc-0.4000, valid loss-2.1667, acc-0.3650, test loss-2.1575, acc-0.3737\n",
      "Iter-17520, train loss-2.1388, acc-0.3800, valid loss-2.1667, acc-0.3650, test loss-2.1575, acc-0.3739\n",
      "Iter-17530, train loss-2.1441, acc-0.5200, valid loss-2.1666, acc-0.3650, test loss-2.1574, acc-0.3736\n",
      "Iter-17540, train loss-2.1374, acc-0.2800, valid loss-2.1665, acc-0.3650, test loss-2.1573, acc-0.3735\n",
      "Iter-17550, train loss-2.1974, acc-0.3400, valid loss-2.1665, acc-0.3654, test loss-2.1573, acc-0.3738\n",
      "Iter-17560, train loss-2.1391, acc-0.4400, valid loss-2.1664, acc-0.3654, test loss-2.1572, acc-0.3741\n",
      "Iter-17570, train loss-2.1355, acc-0.3800, valid loss-2.1663, acc-0.3652, test loss-2.1571, acc-0.3737\n",
      "Iter-17580, train loss-2.1378, acc-0.4400, valid loss-2.1663, acc-0.3656, test loss-2.1570, acc-0.3739\n",
      "Iter-17590, train loss-2.1523, acc-0.3200, valid loss-2.1662, acc-0.3654, test loss-2.1570, acc-0.3739\n",
      "Iter-17600, train loss-2.1741, acc-0.3000, valid loss-2.1661, acc-0.3652, test loss-2.1569, acc-0.3746\n",
      "Iter-17610, train loss-2.1388, acc-0.3400, valid loss-2.1661, acc-0.3656, test loss-2.1568, acc-0.3749\n",
      "Iter-17620, train loss-2.1640, acc-0.3600, valid loss-2.1660, acc-0.3654, test loss-2.1568, acc-0.3750\n",
      "Iter-17630, train loss-2.2294, acc-0.3200, valid loss-2.1660, acc-0.3660, test loss-2.1567, acc-0.3750\n",
      "Iter-17640, train loss-2.1698, acc-0.4000, valid loss-2.1659, acc-0.3658, test loss-2.1566, acc-0.3753\n",
      "Iter-17650, train loss-2.1677, acc-0.3800, valid loss-2.1658, acc-0.3656, test loss-2.1566, acc-0.3752\n",
      "Iter-17660, train loss-2.1347, acc-0.4400, valid loss-2.1658, acc-0.3662, test loss-2.1565, acc-0.3750\n",
      "Iter-17670, train loss-2.1607, acc-0.3600, valid loss-2.1657, acc-0.3664, test loss-2.1564, acc-0.3751\n",
      "Iter-17680, train loss-2.1571, acc-0.3200, valid loss-2.1656, acc-0.3674, test loss-2.1563, acc-0.3751\n",
      "Iter-17690, train loss-2.1412, acc-0.5400, valid loss-2.1656, acc-0.3672, test loss-2.1563, acc-0.3751\n",
      "Iter-17700, train loss-2.1701, acc-0.4000, valid loss-2.1655, acc-0.3670, test loss-2.1562, acc-0.3751\n",
      "Iter-17710, train loss-2.1507, acc-0.4000, valid loss-2.1655, acc-0.3670, test loss-2.1561, acc-0.3751\n",
      "Iter-17720, train loss-2.1493, acc-0.3200, valid loss-2.1654, acc-0.3674, test loss-2.1561, acc-0.3752\n",
      "Iter-17730, train loss-2.1737, acc-0.3800, valid loss-2.1653, acc-0.3676, test loss-2.1560, acc-0.3755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-17740, train loss-2.1781, acc-0.3200, valid loss-2.1653, acc-0.3674, test loss-2.1559, acc-0.3754\n",
      "Iter-17750, train loss-2.1549, acc-0.4200, valid loss-2.1652, acc-0.3678, test loss-2.1558, acc-0.3756\n",
      "Iter-17760, train loss-2.1774, acc-0.2800, valid loss-2.1651, acc-0.3674, test loss-2.1558, acc-0.3758\n",
      "Iter-17770, train loss-2.1328, acc-0.4400, valid loss-2.1651, acc-0.3672, test loss-2.1557, acc-0.3757\n",
      "Iter-17780, train loss-2.1516, acc-0.4600, valid loss-2.1650, acc-0.3672, test loss-2.1556, acc-0.3757\n",
      "Iter-17790, train loss-2.1605, acc-0.2800, valid loss-2.1649, acc-0.3672, test loss-2.1556, acc-0.3758\n",
      "Iter-17800, train loss-2.1729, acc-0.3200, valid loss-2.1649, acc-0.3672, test loss-2.1555, acc-0.3760\n",
      "Iter-17810, train loss-2.1219, acc-0.3400, valid loss-2.1648, acc-0.3668, test loss-2.1554, acc-0.3760\n",
      "Iter-17820, train loss-2.1196, acc-0.4400, valid loss-2.1647, acc-0.3664, test loss-2.1554, acc-0.3759\n",
      "Iter-17830, train loss-2.1844, acc-0.3200, valid loss-2.1647, acc-0.3666, test loss-2.1553, acc-0.3758\n",
      "Iter-17840, train loss-2.1545, acc-0.2600, valid loss-2.1646, acc-0.3668, test loss-2.1552, acc-0.3761\n",
      "Iter-17850, train loss-2.1459, acc-0.3800, valid loss-2.1646, acc-0.3672, test loss-2.1552, acc-0.3759\n",
      "Iter-17860, train loss-2.1441, acc-0.3600, valid loss-2.1645, acc-0.3668, test loss-2.1551, acc-0.3761\n",
      "Iter-17870, train loss-2.1317, acc-0.4600, valid loss-2.1644, acc-0.3674, test loss-2.1550, acc-0.3762\n",
      "Iter-17880, train loss-2.1251, acc-0.3800, valid loss-2.1644, acc-0.3676, test loss-2.1549, acc-0.3762\n",
      "Iter-17890, train loss-2.1482, acc-0.4400, valid loss-2.1643, acc-0.3672, test loss-2.1549, acc-0.3762\n",
      "Iter-17900, train loss-2.1944, acc-0.2600, valid loss-2.1642, acc-0.3678, test loss-2.1548, acc-0.3764\n",
      "Iter-17910, train loss-2.1753, acc-0.3000, valid loss-2.1642, acc-0.3680, test loss-2.1547, acc-0.3762\n",
      "Iter-17920, train loss-2.1273, acc-0.3600, valid loss-2.1641, acc-0.3684, test loss-2.1547, acc-0.3764\n",
      "Iter-17930, train loss-2.1958, acc-0.2000, valid loss-2.1640, acc-0.3682, test loss-2.1546, acc-0.3767\n",
      "Iter-17940, train loss-2.1772, acc-0.3400, valid loss-2.1640, acc-0.3682, test loss-2.1545, acc-0.3765\n",
      "Iter-17950, train loss-2.1700, acc-0.3600, valid loss-2.1639, acc-0.3686, test loss-2.1544, acc-0.3764\n",
      "Iter-17960, train loss-2.1289, acc-0.3400, valid loss-2.1638, acc-0.3684, test loss-2.1544, acc-0.3767\n",
      "Iter-17970, train loss-2.1242, acc-0.4000, valid loss-2.1638, acc-0.3686, test loss-2.1543, acc-0.3766\n",
      "Iter-17980, train loss-2.1780, acc-0.3200, valid loss-2.1637, acc-0.3688, test loss-2.1542, acc-0.3765\n",
      "Iter-17990, train loss-2.1875, acc-0.3000, valid loss-2.1637, acc-0.3686, test loss-2.1542, acc-0.3769\n",
      "Iter-18000, train loss-2.1632, acc-0.4400, valid loss-2.1636, acc-0.3686, test loss-2.1541, acc-0.3769\n",
      "Iter-18010, train loss-2.1393, acc-0.4800, valid loss-2.1635, acc-0.3690, test loss-2.1540, acc-0.3770\n",
      "Iter-18020, train loss-2.1481, acc-0.3400, valid loss-2.1635, acc-0.3690, test loss-2.1539, acc-0.3772\n",
      "Iter-18030, train loss-2.1882, acc-0.2600, valid loss-2.1634, acc-0.3696, test loss-2.1539, acc-0.3772\n",
      "Iter-18040, train loss-2.1534, acc-0.4400, valid loss-2.1633, acc-0.3692, test loss-2.1538, acc-0.3777\n",
      "Iter-18050, train loss-2.1964, acc-0.4000, valid loss-2.1633, acc-0.3690, test loss-2.1537, acc-0.3777\n",
      "Iter-18060, train loss-2.1430, acc-0.3600, valid loss-2.1632, acc-0.3690, test loss-2.1537, acc-0.3775\n",
      "Iter-18070, train loss-2.1787, acc-0.3000, valid loss-2.1631, acc-0.3694, test loss-2.1536, acc-0.3772\n",
      "Iter-18080, train loss-2.1793, acc-0.4200, valid loss-2.1631, acc-0.3694, test loss-2.1535, acc-0.3778\n",
      "Iter-18090, train loss-2.1825, acc-0.2800, valid loss-2.1630, acc-0.3694, test loss-2.1534, acc-0.3777\n",
      "Iter-18100, train loss-2.1425, acc-0.3600, valid loss-2.1629, acc-0.3694, test loss-2.1534, acc-0.3778\n",
      "Iter-18110, train loss-2.1536, acc-0.4000, valid loss-2.1629, acc-0.3694, test loss-2.1533, acc-0.3777\n",
      "Iter-18120, train loss-2.1341, acc-0.4000, valid loss-2.1628, acc-0.3698, test loss-2.1532, acc-0.3778\n",
      "Iter-18130, train loss-2.1664, acc-0.4000, valid loss-2.1627, acc-0.3706, test loss-2.1532, acc-0.3778\n",
      "Iter-18140, train loss-2.2054, acc-0.3000, valid loss-2.1627, acc-0.3708, test loss-2.1531, acc-0.3776\n",
      "Iter-18150, train loss-2.1748, acc-0.2600, valid loss-2.1626, acc-0.3708, test loss-2.1530, acc-0.3779\n",
      "Iter-18160, train loss-2.1655, acc-0.3600, valid loss-2.1625, acc-0.3708, test loss-2.1529, acc-0.3782\n",
      "Iter-18170, train loss-2.1622, acc-0.3200, valid loss-2.1625, acc-0.3708, test loss-2.1529, acc-0.3780\n",
      "Iter-18180, train loss-2.1705, acc-0.4200, valid loss-2.1624, acc-0.3708, test loss-2.1528, acc-0.3784\n",
      "Iter-18190, train loss-2.1440, acc-0.3800, valid loss-2.1624, acc-0.3710, test loss-2.1527, acc-0.3783\n",
      "Iter-18200, train loss-2.1392, acc-0.3000, valid loss-2.1623, acc-0.3712, test loss-2.1527, acc-0.3784\n",
      "Iter-18210, train loss-2.1388, acc-0.5000, valid loss-2.1622, acc-0.3712, test loss-2.1526, acc-0.3786\n",
      "Iter-18220, train loss-2.1621, acc-0.3800, valid loss-2.1622, acc-0.3712, test loss-2.1525, acc-0.3789\n",
      "Iter-18230, train loss-2.1424, acc-0.3600, valid loss-2.1621, acc-0.3712, test loss-2.1524, acc-0.3788\n",
      "Iter-18240, train loss-2.1729, acc-0.3000, valid loss-2.1620, acc-0.3716, test loss-2.1524, acc-0.3787\n",
      "Iter-18250, train loss-2.1830, acc-0.3200, valid loss-2.1620, acc-0.3714, test loss-2.1523, acc-0.3790\n",
      "Iter-18260, train loss-2.1362, acc-0.4000, valid loss-2.1619, acc-0.3714, test loss-2.1522, acc-0.3794\n",
      "Iter-18270, train loss-2.1887, acc-0.2200, valid loss-2.1619, acc-0.3714, test loss-2.1522, acc-0.3792\n",
      "Iter-18280, train loss-2.1360, acc-0.4000, valid loss-2.1618, acc-0.3716, test loss-2.1521, acc-0.3796\n",
      "Iter-18290, train loss-2.1671, acc-0.3800, valid loss-2.1617, acc-0.3718, test loss-2.1520, acc-0.3795\n",
      "Iter-18300, train loss-2.1942, acc-0.2400, valid loss-2.1617, acc-0.3720, test loss-2.1520, acc-0.3794\n",
      "Iter-18310, train loss-2.1769, acc-0.2400, valid loss-2.1616, acc-0.3724, test loss-2.1519, acc-0.3795\n",
      "Iter-18320, train loss-2.1333, acc-0.4600, valid loss-2.1615, acc-0.3722, test loss-2.1518, acc-0.3796\n",
      "Iter-18330, train loss-2.1530, acc-0.3000, valid loss-2.1615, acc-0.3718, test loss-2.1518, acc-0.3794\n",
      "Iter-18340, train loss-2.1640, acc-0.3600, valid loss-2.1614, acc-0.3720, test loss-2.1517, acc-0.3793\n",
      "Iter-18350, train loss-2.1248, acc-0.4800, valid loss-2.1613, acc-0.3720, test loss-2.1516, acc-0.3793\n",
      "Iter-18360, train loss-2.1282, acc-0.5000, valid loss-2.1613, acc-0.3720, test loss-2.1515, acc-0.3792\n",
      "Iter-18370, train loss-2.1070, acc-0.4400, valid loss-2.1612, acc-0.3728, test loss-2.1515, acc-0.3795\n",
      "Iter-18380, train loss-2.1674, acc-0.4200, valid loss-2.1612, acc-0.3728, test loss-2.1514, acc-0.3798\n",
      "Iter-18390, train loss-2.1293, acc-0.4800, valid loss-2.1611, acc-0.3732, test loss-2.1513, acc-0.3800\n",
      "Iter-18400, train loss-2.1678, acc-0.3600, valid loss-2.1610, acc-0.3726, test loss-2.1513, acc-0.3803\n",
      "Iter-18410, train loss-2.1670, acc-0.3400, valid loss-2.1610, acc-0.3730, test loss-2.1512, acc-0.3803\n",
      "Iter-18420, train loss-2.1558, acc-0.4000, valid loss-2.1609, acc-0.3732, test loss-2.1511, acc-0.3803\n",
      "Iter-18430, train loss-2.1401, acc-0.5200, valid loss-2.1608, acc-0.3732, test loss-2.1511, acc-0.3807\n",
      "Iter-18440, train loss-2.1934, acc-0.3600, valid loss-2.1608, acc-0.3732, test loss-2.1510, acc-0.3809\n",
      "Iter-18450, train loss-2.1166, acc-0.3400, valid loss-2.1607, acc-0.3736, test loss-2.1509, acc-0.3809\n",
      "Iter-18460, train loss-2.1550, acc-0.2800, valid loss-2.1606, acc-0.3732, test loss-2.1509, acc-0.3816\n",
      "Iter-18470, train loss-2.1838, acc-0.3200, valid loss-2.1606, acc-0.3732, test loss-2.1508, acc-0.3815\n",
      "Iter-18480, train loss-2.1498, acc-0.3400, valid loss-2.1605, acc-0.3734, test loss-2.1507, acc-0.3816\n",
      "Iter-18490, train loss-2.1861, acc-0.3400, valid loss-2.1604, acc-0.3732, test loss-2.1506, acc-0.3816\n",
      "Iter-18500, train loss-2.1672, acc-0.4000, valid loss-2.1604, acc-0.3736, test loss-2.1506, acc-0.3817\n",
      "Iter-18510, train loss-2.1566, acc-0.4200, valid loss-2.1603, acc-0.3734, test loss-2.1505, acc-0.3819\n",
      "Iter-18520, train loss-2.1480, acc-0.3200, valid loss-2.1603, acc-0.3736, test loss-2.1504, acc-0.3818\n",
      "Iter-18530, train loss-2.1722, acc-0.3400, valid loss-2.1602, acc-0.3740, test loss-2.1504, acc-0.3823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-18540, train loss-2.1549, acc-0.4000, valid loss-2.1601, acc-0.3738, test loss-2.1503, acc-0.3824\n",
      "Iter-18550, train loss-2.1542, acc-0.4000, valid loss-2.1601, acc-0.3740, test loss-2.1502, acc-0.3822\n",
      "Iter-18560, train loss-2.1431, acc-0.3600, valid loss-2.1600, acc-0.3742, test loss-2.1501, acc-0.3828\n",
      "Iter-18570, train loss-2.1027, acc-0.4400, valid loss-2.1600, acc-0.3742, test loss-2.1501, acc-0.3826\n",
      "Iter-18580, train loss-2.1578, acc-0.4200, valid loss-2.1599, acc-0.3742, test loss-2.1500, acc-0.3827\n",
      "Iter-18590, train loss-2.1085, acc-0.4400, valid loss-2.1598, acc-0.3742, test loss-2.1499, acc-0.3826\n",
      "Iter-18600, train loss-2.1516, acc-0.3600, valid loss-2.1598, acc-0.3746, test loss-2.1499, acc-0.3827\n",
      "Iter-18610, train loss-2.1926, acc-0.3600, valid loss-2.1597, acc-0.3746, test loss-2.1498, acc-0.3827\n",
      "Iter-18620, train loss-2.1657, acc-0.3200, valid loss-2.1597, acc-0.3746, test loss-2.1497, acc-0.3828\n",
      "Iter-18630, train loss-2.1332, acc-0.4000, valid loss-2.1596, acc-0.3746, test loss-2.1497, acc-0.3830\n",
      "Iter-18640, train loss-2.1334, acc-0.4200, valid loss-2.1595, acc-0.3748, test loss-2.1496, acc-0.3832\n",
      "Iter-18650, train loss-2.1491, acc-0.3800, valid loss-2.1595, acc-0.3750, test loss-2.1495, acc-0.3836\n",
      "Iter-18660, train loss-2.1755, acc-0.3600, valid loss-2.1594, acc-0.3750, test loss-2.1495, acc-0.3835\n",
      "Iter-18670, train loss-2.1445, acc-0.3200, valid loss-2.1593, acc-0.3748, test loss-2.1494, acc-0.3836\n",
      "Iter-18680, train loss-2.1615, acc-0.3400, valid loss-2.1593, acc-0.3750, test loss-2.1493, acc-0.3835\n",
      "Iter-18690, train loss-2.1648, acc-0.3400, valid loss-2.1592, acc-0.3750, test loss-2.1493, acc-0.3837\n",
      "Iter-18700, train loss-2.1843, acc-0.2800, valid loss-2.1592, acc-0.3752, test loss-2.1492, acc-0.3837\n",
      "Iter-18710, train loss-2.1515, acc-0.3400, valid loss-2.1591, acc-0.3750, test loss-2.1491, acc-0.3837\n",
      "Iter-18720, train loss-2.1646, acc-0.4600, valid loss-2.1590, acc-0.3752, test loss-2.1491, acc-0.3836\n",
      "Iter-18730, train loss-2.1410, acc-0.4200, valid loss-2.1590, acc-0.3758, test loss-2.1490, acc-0.3834\n",
      "Iter-18740, train loss-2.1562, acc-0.4800, valid loss-2.1589, acc-0.3758, test loss-2.1489, acc-0.3833\n",
      "Iter-18750, train loss-2.1231, acc-0.4400, valid loss-2.1589, acc-0.3758, test loss-2.1488, acc-0.3835\n",
      "Iter-18760, train loss-2.1852, acc-0.2800, valid loss-2.1588, acc-0.3758, test loss-2.1488, acc-0.3835\n",
      "Iter-18770, train loss-2.1683, acc-0.3200, valid loss-2.1587, acc-0.3756, test loss-2.1487, acc-0.3834\n",
      "Iter-18780, train loss-2.1529, acc-0.4000, valid loss-2.1587, acc-0.3758, test loss-2.1486, acc-0.3836\n",
      "Iter-18790, train loss-2.1388, acc-0.4200, valid loss-2.1586, acc-0.3756, test loss-2.1486, acc-0.3841\n",
      "Iter-18800, train loss-2.1325, acc-0.4200, valid loss-2.1585, acc-0.3758, test loss-2.1485, acc-0.3837\n",
      "Iter-18810, train loss-2.2176, acc-0.2800, valid loss-2.1585, acc-0.3758, test loss-2.1484, acc-0.3840\n",
      "Iter-18820, train loss-2.1527, acc-0.4200, valid loss-2.1584, acc-0.3760, test loss-2.1484, acc-0.3839\n",
      "Iter-18830, train loss-2.1587, acc-0.4200, valid loss-2.1584, acc-0.3760, test loss-2.1483, acc-0.3842\n",
      "Iter-18840, train loss-2.1509, acc-0.3600, valid loss-2.1583, acc-0.3760, test loss-2.1482, acc-0.3841\n",
      "Iter-18850, train loss-2.1928, acc-0.4000, valid loss-2.1582, acc-0.3756, test loss-2.1482, acc-0.3842\n",
      "Iter-18860, train loss-2.1729, acc-0.2800, valid loss-2.1582, acc-0.3760, test loss-2.1481, acc-0.3841\n",
      "Iter-18870, train loss-2.1813, acc-0.3200, valid loss-2.1581, acc-0.3760, test loss-2.1480, acc-0.3843\n",
      "Iter-18880, train loss-2.1450, acc-0.3600, valid loss-2.1581, acc-0.3764, test loss-2.1480, acc-0.3845\n",
      "Iter-18890, train loss-2.1598, acc-0.3600, valid loss-2.1580, acc-0.3758, test loss-2.1479, acc-0.3851\n",
      "Iter-18900, train loss-2.1458, acc-0.3200, valid loss-2.1579, acc-0.3760, test loss-2.1478, acc-0.3852\n",
      "Iter-18910, train loss-2.1681, acc-0.2800, valid loss-2.1579, acc-0.3760, test loss-2.1478, acc-0.3853\n",
      "Iter-18920, train loss-2.1353, acc-0.4800, valid loss-2.1578, acc-0.3760, test loss-2.1477, acc-0.3854\n",
      "Iter-18930, train loss-2.1537, acc-0.3400, valid loss-2.1577, acc-0.3760, test loss-2.1476, acc-0.3857\n",
      "Iter-18940, train loss-2.1623, acc-0.4000, valid loss-2.1577, acc-0.3766, test loss-2.1476, acc-0.3856\n",
      "Iter-18950, train loss-2.1821, acc-0.3400, valid loss-2.1576, acc-0.3770, test loss-2.1475, acc-0.3855\n",
      "Iter-18960, train loss-2.1010, acc-0.5000, valid loss-2.1576, acc-0.3772, test loss-2.1474, acc-0.3858\n",
      "Iter-18970, train loss-2.1539, acc-0.4600, valid loss-2.1575, acc-0.3772, test loss-2.1473, acc-0.3860\n",
      "Iter-18980, train loss-2.1274, acc-0.4200, valid loss-2.1574, acc-0.3768, test loss-2.1473, acc-0.3858\n",
      "Iter-18990, train loss-2.1723, acc-0.4400, valid loss-2.1574, acc-0.3772, test loss-2.1472, acc-0.3859\n",
      "Iter-19000, train loss-2.1732, acc-0.3200, valid loss-2.1573, acc-0.3772, test loss-2.1471, acc-0.3864\n",
      "Iter-19010, train loss-2.1572, acc-0.3600, valid loss-2.1572, acc-0.3774, test loss-2.1471, acc-0.3863\n",
      "Iter-19020, train loss-2.1803, acc-0.3200, valid loss-2.1572, acc-0.3774, test loss-2.1470, acc-0.3866\n",
      "Iter-19030, train loss-2.1911, acc-0.2800, valid loss-2.1571, acc-0.3770, test loss-2.1469, acc-0.3870\n",
      "Iter-19040, train loss-2.1302, acc-0.4200, valid loss-2.1571, acc-0.3772, test loss-2.1469, acc-0.3875\n",
      "Iter-19050, train loss-2.1707, acc-0.3200, valid loss-2.1570, acc-0.3772, test loss-2.1468, acc-0.3876\n",
      "Iter-19060, train loss-2.1500, acc-0.3400, valid loss-2.1569, acc-0.3772, test loss-2.1467, acc-0.3876\n",
      "Iter-19070, train loss-2.1425, acc-0.4600, valid loss-2.1569, acc-0.3772, test loss-2.1467, acc-0.3875\n",
      "Iter-19080, train loss-2.1335, acc-0.3400, valid loss-2.1568, acc-0.3774, test loss-2.1466, acc-0.3876\n",
      "Iter-19090, train loss-2.1877, acc-0.3000, valid loss-2.1567, acc-0.3780, test loss-2.1465, acc-0.3879\n",
      "Iter-19100, train loss-2.1607, acc-0.3200, valid loss-2.1567, acc-0.3784, test loss-2.1464, acc-0.3877\n",
      "Iter-19110, train loss-2.1674, acc-0.3600, valid loss-2.1566, acc-0.3782, test loss-2.1464, acc-0.3879\n",
      "Iter-19120, train loss-2.1464, acc-0.4200, valid loss-2.1566, acc-0.3782, test loss-2.1463, acc-0.3878\n",
      "Iter-19130, train loss-2.1604, acc-0.3800, valid loss-2.1565, acc-0.3782, test loss-2.1462, acc-0.3881\n",
      "Iter-19140, train loss-2.1709, acc-0.3400, valid loss-2.1564, acc-0.3782, test loss-2.1462, acc-0.3884\n",
      "Iter-19150, train loss-2.1634, acc-0.3000, valid loss-2.1564, acc-0.3782, test loss-2.1461, acc-0.3884\n",
      "Iter-19160, train loss-2.1688, acc-0.2600, valid loss-2.1563, acc-0.3786, test loss-2.1460, acc-0.3882\n",
      "Iter-19170, train loss-2.1607, acc-0.3400, valid loss-2.1563, acc-0.3782, test loss-2.1460, acc-0.3884\n",
      "Iter-19180, train loss-2.1433, acc-0.4400, valid loss-2.1562, acc-0.3780, test loss-2.1459, acc-0.3878\n",
      "Iter-19190, train loss-2.1668, acc-0.3800, valid loss-2.1561, acc-0.3778, test loss-2.1458, acc-0.3877\n",
      "Iter-19200, train loss-2.1428, acc-0.4600, valid loss-2.1561, acc-0.3780, test loss-2.1458, acc-0.3877\n",
      "Iter-19210, train loss-2.1252, acc-0.4200, valid loss-2.1560, acc-0.3780, test loss-2.1457, acc-0.3876\n",
      "Iter-19220, train loss-2.1594, acc-0.2400, valid loss-2.1559, acc-0.3782, test loss-2.1456, acc-0.3876\n",
      "Iter-19230, train loss-2.1903, acc-0.2600, valid loss-2.1559, acc-0.3788, test loss-2.1456, acc-0.3879\n",
      "Iter-19240, train loss-2.1604, acc-0.3400, valid loss-2.1558, acc-0.3788, test loss-2.1455, acc-0.3882\n",
      "Iter-19250, train loss-2.1609, acc-0.3800, valid loss-2.1558, acc-0.3790, test loss-2.1454, acc-0.3883\n",
      "Iter-19260, train loss-2.1139, acc-0.5800, valid loss-2.1557, acc-0.3786, test loss-2.1454, acc-0.3884\n",
      "Iter-19270, train loss-2.1169, acc-0.3800, valid loss-2.1556, acc-0.3790, test loss-2.1453, acc-0.3883\n",
      "Iter-19280, train loss-2.0954, acc-0.4600, valid loss-2.1556, acc-0.3790, test loss-2.1452, acc-0.3881\n",
      "Iter-19290, train loss-2.1738, acc-0.4000, valid loss-2.1555, acc-0.3796, test loss-2.1452, acc-0.3883\n",
      "Iter-19300, train loss-2.2010, acc-0.3600, valid loss-2.1554, acc-0.3794, test loss-2.1451, acc-0.3884\n",
      "Iter-19310, train loss-2.1619, acc-0.3800, valid loss-2.1554, acc-0.3796, test loss-2.1450, acc-0.3889\n",
      "Iter-19320, train loss-2.1682, acc-0.3400, valid loss-2.1553, acc-0.3798, test loss-2.1449, acc-0.3888\n",
      "Iter-19330, train loss-2.1998, acc-0.2400, valid loss-2.1553, acc-0.3796, test loss-2.1449, acc-0.3890\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-19340, train loss-2.2073, acc-0.2400, valid loss-2.1552, acc-0.3796, test loss-2.1448, acc-0.3891\n",
      "Iter-19350, train loss-2.1102, acc-0.4600, valid loss-2.1551, acc-0.3794, test loss-2.1447, acc-0.3894\n",
      "Iter-19360, train loss-2.1572, acc-0.3800, valid loss-2.1551, acc-0.3798, test loss-2.1447, acc-0.3892\n",
      "Iter-19370, train loss-2.1164, acc-0.5200, valid loss-2.1550, acc-0.3798, test loss-2.1446, acc-0.3894\n",
      "Iter-19380, train loss-2.1337, acc-0.3200, valid loss-2.1549, acc-0.3798, test loss-2.1445, acc-0.3898\n",
      "Iter-19390, train loss-2.1629, acc-0.4000, valid loss-2.1549, acc-0.3800, test loss-2.1445, acc-0.3903\n",
      "Iter-19400, train loss-2.1508, acc-0.4600, valid loss-2.1548, acc-0.3800, test loss-2.1444, acc-0.3903\n",
      "Iter-19410, train loss-2.1503, acc-0.3600, valid loss-2.1547, acc-0.3802, test loss-2.1443, acc-0.3903\n",
      "Iter-19420, train loss-2.1178, acc-0.5000, valid loss-2.1547, acc-0.3802, test loss-2.1443, acc-0.3904\n",
      "Iter-19430, train loss-2.1908, acc-0.3400, valid loss-2.1546, acc-0.3804, test loss-2.1442, acc-0.3900\n",
      "Iter-19440, train loss-2.1707, acc-0.3000, valid loss-2.1546, acc-0.3808, test loss-2.1441, acc-0.3900\n",
      "Iter-19450, train loss-2.0835, acc-0.5800, valid loss-2.1545, acc-0.3812, test loss-2.1441, acc-0.3901\n",
      "Iter-19460, train loss-2.1359, acc-0.4200, valid loss-2.1544, acc-0.3806, test loss-2.1440, acc-0.3903\n",
      "Iter-19470, train loss-2.1236, acc-0.4000, valid loss-2.1544, acc-0.3812, test loss-2.1439, acc-0.3904\n",
      "Iter-19480, train loss-2.1154, acc-0.3400, valid loss-2.1543, acc-0.3810, test loss-2.1438, acc-0.3904\n",
      "Iter-19490, train loss-2.1617, acc-0.3600, valid loss-2.1542, acc-0.3812, test loss-2.1438, acc-0.3904\n",
      "Iter-19500, train loss-2.1419, acc-0.4200, valid loss-2.1542, acc-0.3816, test loss-2.1437, acc-0.3903\n",
      "Iter-19510, train loss-2.1495, acc-0.3800, valid loss-2.1541, acc-0.3812, test loss-2.1436, acc-0.3904\n",
      "Iter-19520, train loss-2.2094, acc-0.3400, valid loss-2.1541, acc-0.3814, test loss-2.1436, acc-0.3908\n",
      "Iter-19530, train loss-2.1267, acc-0.4000, valid loss-2.1540, acc-0.3812, test loss-2.1435, acc-0.3907\n",
      "Iter-19540, train loss-2.1357, acc-0.4400, valid loss-2.1539, acc-0.3812, test loss-2.1434, acc-0.3908\n",
      "Iter-19550, train loss-2.1407, acc-0.3200, valid loss-2.1539, acc-0.3816, test loss-2.1434, acc-0.3909\n",
      "Iter-19560, train loss-2.1303, acc-0.3600, valid loss-2.1538, acc-0.3822, test loss-2.1433, acc-0.3911\n",
      "Iter-19570, train loss-2.1410, acc-0.4000, valid loss-2.1537, acc-0.3820, test loss-2.1432, acc-0.3910\n",
      "Iter-19580, train loss-2.1720, acc-0.4200, valid loss-2.1537, acc-0.3822, test loss-2.1432, acc-0.3913\n",
      "Iter-19590, train loss-2.1215, acc-0.4400, valid loss-2.1536, acc-0.3822, test loss-2.1431, acc-0.3911\n",
      "Iter-19600, train loss-2.1684, acc-0.3200, valid loss-2.1536, acc-0.3818, test loss-2.1430, acc-0.3913\n",
      "Iter-19610, train loss-2.1561, acc-0.4200, valid loss-2.1535, acc-0.3824, test loss-2.1430, acc-0.3916\n",
      "Iter-19620, train loss-2.1498, acc-0.3800, valid loss-2.1534, acc-0.3828, test loss-2.1429, acc-0.3916\n",
      "Iter-19630, train loss-2.1253, acc-0.5200, valid loss-2.1534, acc-0.3828, test loss-2.1428, acc-0.3916\n",
      "Iter-19640, train loss-2.1383, acc-0.3600, valid loss-2.1533, acc-0.3828, test loss-2.1428, acc-0.3917\n",
      "Iter-19650, train loss-2.1256, acc-0.4200, valid loss-2.1533, acc-0.3834, test loss-2.1427, acc-0.3916\n",
      "Iter-19660, train loss-2.1337, acc-0.5400, valid loss-2.1532, acc-0.3840, test loss-2.1426, acc-0.3918\n",
      "Iter-19670, train loss-2.1182, acc-0.4600, valid loss-2.1531, acc-0.3834, test loss-2.1425, acc-0.3919\n",
      "Iter-19680, train loss-2.1351, acc-0.5400, valid loss-2.1531, acc-0.3838, test loss-2.1425, acc-0.3918\n",
      "Iter-19690, train loss-2.1018, acc-0.4400, valid loss-2.1530, acc-0.3836, test loss-2.1424, acc-0.3921\n",
      "Iter-19700, train loss-2.1438, acc-0.4600, valid loss-2.1529, acc-0.3838, test loss-2.1423, acc-0.3925\n",
      "Iter-19710, train loss-2.1482, acc-0.3400, valid loss-2.1529, acc-0.3838, test loss-2.1423, acc-0.3925\n",
      "Iter-19720, train loss-2.1429, acc-0.4200, valid loss-2.1528, acc-0.3842, test loss-2.1422, acc-0.3924\n",
      "Iter-19730, train loss-2.1452, acc-0.4200, valid loss-2.1528, acc-0.3842, test loss-2.1421, acc-0.3923\n",
      "Iter-19740, train loss-2.1710, acc-0.2800, valid loss-2.1527, acc-0.3844, test loss-2.1421, acc-0.3926\n",
      "Iter-19750, train loss-2.1467, acc-0.3400, valid loss-2.1526, acc-0.3844, test loss-2.1420, acc-0.3928\n",
      "Iter-19760, train loss-2.1985, acc-0.3000, valid loss-2.1526, acc-0.3842, test loss-2.1419, acc-0.3928\n",
      "Iter-19770, train loss-2.1678, acc-0.4400, valid loss-2.1525, acc-0.3844, test loss-2.1419, acc-0.3930\n",
      "Iter-19780, train loss-2.1338, acc-0.4000, valid loss-2.1524, acc-0.3846, test loss-2.1418, acc-0.3929\n",
      "Iter-19790, train loss-2.1453, acc-0.4400, valid loss-2.1524, acc-0.3848, test loss-2.1417, acc-0.3929\n",
      "Iter-19800, train loss-2.1452, acc-0.4600, valid loss-2.1523, acc-0.3848, test loss-2.1417, acc-0.3929\n",
      "Iter-19810, train loss-2.1646, acc-0.4200, valid loss-2.1523, acc-0.3844, test loss-2.1416, acc-0.3930\n",
      "Iter-19820, train loss-2.1282, acc-0.4000, valid loss-2.1522, acc-0.3848, test loss-2.1415, acc-0.3929\n",
      "Iter-19830, train loss-2.1600, acc-0.4400, valid loss-2.1521, acc-0.3856, test loss-2.1415, acc-0.3931\n",
      "Iter-19840, train loss-2.0887, acc-0.5600, valid loss-2.1521, acc-0.3856, test loss-2.1414, acc-0.3935\n",
      "Iter-19850, train loss-2.1184, acc-0.3600, valid loss-2.1520, acc-0.3854, test loss-2.1413, acc-0.3936\n",
      "Iter-19860, train loss-2.1508, acc-0.3200, valid loss-2.1520, acc-0.3852, test loss-2.1412, acc-0.3940\n",
      "Iter-19870, train loss-2.1341, acc-0.3600, valid loss-2.1519, acc-0.3856, test loss-2.1412, acc-0.3940\n",
      "Iter-19880, train loss-2.1338, acc-0.4200, valid loss-2.1518, acc-0.3856, test loss-2.1411, acc-0.3937\n",
      "Iter-19890, train loss-2.1547, acc-0.3600, valid loss-2.1518, acc-0.3858, test loss-2.1410, acc-0.3943\n",
      "Iter-19900, train loss-2.1436, acc-0.2800, valid loss-2.1517, acc-0.3860, test loss-2.1410, acc-0.3947\n",
      "Iter-19910, train loss-2.1617, acc-0.3200, valid loss-2.1517, acc-0.3864, test loss-2.1409, acc-0.3944\n",
      "Iter-19920, train loss-2.1685, acc-0.3400, valid loss-2.1516, acc-0.3864, test loss-2.1409, acc-0.3946\n",
      "Iter-19930, train loss-2.1412, acc-0.3400, valid loss-2.1515, acc-0.3862, test loss-2.1408, acc-0.3944\n",
      "Iter-19940, train loss-2.1832, acc-0.2400, valid loss-2.1515, acc-0.3866, test loss-2.1407, acc-0.3946\n",
      "Iter-19950, train loss-2.1479, acc-0.2400, valid loss-2.1514, acc-0.3864, test loss-2.1407, acc-0.3946\n",
      "Iter-19960, train loss-2.1318, acc-0.3600, valid loss-2.1514, acc-0.3866, test loss-2.1406, acc-0.3951\n",
      "Iter-19970, train loss-2.1269, acc-0.4200, valid loss-2.1513, acc-0.3860, test loss-2.1405, acc-0.3947\n",
      "Iter-19980, train loss-2.1277, acc-0.4200, valid loss-2.1512, acc-0.3864, test loss-2.1404, acc-0.3946\n",
      "Iter-19990, train loss-2.1178, acc-0.4000, valid loss-2.1512, acc-0.3868, test loss-2.1404, acc-0.3950\n",
      "Iter-20000, train loss-2.1320, acc-0.3600, valid loss-2.1511, acc-0.3870, test loss-2.1403, acc-0.3955\n",
      "Iter-20010, train loss-2.1612, acc-0.4000, valid loss-2.1510, acc-0.3874, test loss-2.1403, acc-0.3956\n",
      "Iter-20020, train loss-2.1531, acc-0.2800, valid loss-2.1510, acc-0.3864, test loss-2.1402, acc-0.3961\n",
      "Iter-20030, train loss-2.1475, acc-0.3800, valid loss-2.1509, acc-0.3864, test loss-2.1401, acc-0.3960\n",
      "Iter-20040, train loss-2.1196, acc-0.4800, valid loss-2.1509, acc-0.3870, test loss-2.1400, acc-0.3958\n",
      "Iter-20050, train loss-2.1784, acc-0.3000, valid loss-2.1508, acc-0.3872, test loss-2.1400, acc-0.3962\n",
      "Iter-20060, train loss-2.1781, acc-0.2400, valid loss-2.1507, acc-0.3870, test loss-2.1399, acc-0.3961\n",
      "Iter-20070, train loss-2.1151, acc-0.4600, valid loss-2.1507, acc-0.3872, test loss-2.1398, acc-0.3964\n",
      "Iter-20080, train loss-2.1828, acc-0.3400, valid loss-2.1506, acc-0.3874, test loss-2.1398, acc-0.3961\n",
      "Iter-20090, train loss-2.1617, acc-0.3600, valid loss-2.1505, acc-0.3872, test loss-2.1397, acc-0.3961\n",
      "Iter-20100, train loss-2.1402, acc-0.3400, valid loss-2.1505, acc-0.3872, test loss-2.1396, acc-0.3963\n",
      "Iter-20110, train loss-2.1767, acc-0.3000, valid loss-2.1504, acc-0.3872, test loss-2.1396, acc-0.3963\n",
      "Iter-20120, train loss-2.1384, acc-0.4400, valid loss-2.1503, acc-0.3874, test loss-2.1395, acc-0.3967\n",
      "Iter-20130, train loss-2.1622, acc-0.2800, valid loss-2.1503, acc-0.3876, test loss-2.1394, acc-0.3966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20140, train loss-2.1399, acc-0.3200, valid loss-2.1502, acc-0.3876, test loss-2.1393, acc-0.3966\n",
      "Iter-20150, train loss-2.1583, acc-0.2800, valid loss-2.1502, acc-0.3878, test loss-2.1393, acc-0.3966\n",
      "Iter-20160, train loss-2.1589, acc-0.2800, valid loss-2.1501, acc-0.3876, test loss-2.1392, acc-0.3966\n",
      "Iter-20170, train loss-2.1657, acc-0.3000, valid loss-2.1500, acc-0.3878, test loss-2.1391, acc-0.3966\n",
      "Iter-20180, train loss-2.1316, acc-0.4200, valid loss-2.1500, acc-0.3880, test loss-2.1391, acc-0.3968\n",
      "Iter-20190, train loss-2.1666, acc-0.4400, valid loss-2.1499, acc-0.3880, test loss-2.1390, acc-0.3974\n",
      "Iter-20200, train loss-2.1391, acc-0.4200, valid loss-2.1498, acc-0.3874, test loss-2.1389, acc-0.3972\n",
      "Iter-20210, train loss-2.1563, acc-0.3800, valid loss-2.1498, acc-0.3880, test loss-2.1389, acc-0.3972\n",
      "Iter-20220, train loss-2.1626, acc-0.4400, valid loss-2.1497, acc-0.3880, test loss-2.1388, acc-0.3973\n",
      "Iter-20230, train loss-2.1091, acc-0.4200, valid loss-2.1497, acc-0.3882, test loss-2.1387, acc-0.3976\n",
      "Iter-20240, train loss-2.1422, acc-0.4000, valid loss-2.1496, acc-0.3880, test loss-2.1387, acc-0.3973\n",
      "Iter-20250, train loss-2.1028, acc-0.5000, valid loss-2.1495, acc-0.3882, test loss-2.1386, acc-0.3975\n",
      "Iter-20260, train loss-2.1567, acc-0.4200, valid loss-2.1495, acc-0.3884, test loss-2.1385, acc-0.3976\n",
      "Iter-20270, train loss-2.1813, acc-0.3400, valid loss-2.1494, acc-0.3880, test loss-2.1384, acc-0.3977\n",
      "Iter-20280, train loss-2.1096, acc-0.4200, valid loss-2.1493, acc-0.3886, test loss-2.1384, acc-0.3975\n",
      "Iter-20290, train loss-2.1039, acc-0.5600, valid loss-2.1493, acc-0.3884, test loss-2.1383, acc-0.3976\n",
      "Iter-20300, train loss-2.1302, acc-0.3600, valid loss-2.1492, acc-0.3886, test loss-2.1383, acc-0.3979\n",
      "Iter-20310, train loss-2.1660, acc-0.4600, valid loss-2.1492, acc-0.3882, test loss-2.1382, acc-0.3982\n",
      "Iter-20320, train loss-2.1462, acc-0.4400, valid loss-2.1491, acc-0.3884, test loss-2.1381, acc-0.3983\n",
      "Iter-20330, train loss-2.1604, acc-0.4000, valid loss-2.1490, acc-0.3880, test loss-2.1381, acc-0.3986\n",
      "Iter-20340, train loss-2.0920, acc-0.4400, valid loss-2.1490, acc-0.3888, test loss-2.1380, acc-0.3988\n",
      "Iter-20350, train loss-2.1343, acc-0.4000, valid loss-2.1489, acc-0.3880, test loss-2.1379, acc-0.3988\n",
      "Iter-20360, train loss-2.1447, acc-0.4400, valid loss-2.1489, acc-0.3878, test loss-2.1379, acc-0.3982\n",
      "Iter-20370, train loss-2.1198, acc-0.4200, valid loss-2.1488, acc-0.3882, test loss-2.1378, acc-0.3986\n",
      "Iter-20380, train loss-2.1840, acc-0.3600, valid loss-2.1487, acc-0.3882, test loss-2.1377, acc-0.3982\n",
      "Iter-20390, train loss-2.1426, acc-0.3800, valid loss-2.1487, acc-0.3890, test loss-2.1377, acc-0.3986\n",
      "Iter-20400, train loss-2.1305, acc-0.3400, valid loss-2.1486, acc-0.3886, test loss-2.1376, acc-0.3982\n",
      "Iter-20410, train loss-2.1024, acc-0.5000, valid loss-2.1486, acc-0.3888, test loss-2.1375, acc-0.3983\n",
      "Iter-20420, train loss-2.1457, acc-0.4000, valid loss-2.1485, acc-0.3888, test loss-2.1374, acc-0.3990\n",
      "Iter-20430, train loss-2.1087, acc-0.4600, valid loss-2.1484, acc-0.3888, test loss-2.1374, acc-0.3987\n",
      "Iter-20440, train loss-2.1144, acc-0.4200, valid loss-2.1484, acc-0.3890, test loss-2.1373, acc-0.3985\n",
      "Iter-20450, train loss-2.1913, acc-0.3200, valid loss-2.1483, acc-0.3888, test loss-2.1372, acc-0.3985\n",
      "Iter-20460, train loss-2.1646, acc-0.4000, valid loss-2.1482, acc-0.3894, test loss-2.1372, acc-0.3984\n",
      "Iter-20470, train loss-2.1300, acc-0.4000, valid loss-2.1482, acc-0.3898, test loss-2.1371, acc-0.3985\n",
      "Iter-20480, train loss-2.1958, acc-0.3600, valid loss-2.1481, acc-0.3894, test loss-2.1370, acc-0.3985\n",
      "Iter-20490, train loss-2.1488, acc-0.3600, valid loss-2.1481, acc-0.3900, test loss-2.1370, acc-0.3984\n",
      "Iter-20500, train loss-2.1164, acc-0.2800, valid loss-2.1480, acc-0.3898, test loss-2.1369, acc-0.3989\n",
      "Iter-20510, train loss-2.1731, acc-0.4000, valid loss-2.1479, acc-0.3898, test loss-2.1368, acc-0.3988\n",
      "Iter-20520, train loss-2.1142, acc-0.5400, valid loss-2.1479, acc-0.3898, test loss-2.1368, acc-0.3988\n",
      "Iter-20530, train loss-2.1647, acc-0.4000, valid loss-2.1478, acc-0.3900, test loss-2.1367, acc-0.3990\n",
      "Iter-20540, train loss-2.1627, acc-0.4200, valid loss-2.1478, acc-0.3898, test loss-2.1366, acc-0.3990\n",
      "Iter-20550, train loss-2.1644, acc-0.3800, valid loss-2.1477, acc-0.3904, test loss-2.1366, acc-0.3992\n",
      "Iter-20560, train loss-2.1351, acc-0.4600, valid loss-2.1476, acc-0.3900, test loss-2.1365, acc-0.3993\n",
      "Iter-20570, train loss-2.1476, acc-0.3200, valid loss-2.1476, acc-0.3900, test loss-2.1364, acc-0.3992\n",
      "Iter-20580, train loss-2.1136, acc-0.5000, valid loss-2.1475, acc-0.3904, test loss-2.1364, acc-0.3994\n",
      "Iter-20590, train loss-2.1114, acc-0.5600, valid loss-2.1475, acc-0.3906, test loss-2.1363, acc-0.3997\n",
      "Iter-20600, train loss-2.1209, acc-0.4200, valid loss-2.1474, acc-0.3904, test loss-2.1362, acc-0.3996\n",
      "Iter-20610, train loss-2.1554, acc-0.3600, valid loss-2.1473, acc-0.3906, test loss-2.1362, acc-0.4000\n",
      "Iter-20620, train loss-2.1652, acc-0.3800, valid loss-2.1473, acc-0.3906, test loss-2.1361, acc-0.3997\n",
      "Iter-20630, train loss-2.1538, acc-0.4200, valid loss-2.1472, acc-0.3910, test loss-2.1360, acc-0.4000\n",
      "Iter-20640, train loss-2.0991, acc-0.4400, valid loss-2.1472, acc-0.3910, test loss-2.1360, acc-0.4000\n",
      "Iter-20650, train loss-2.0851, acc-0.5200, valid loss-2.1471, acc-0.3910, test loss-2.1359, acc-0.4000\n",
      "Iter-20660, train loss-2.1114, acc-0.4400, valid loss-2.1470, acc-0.3908, test loss-2.1358, acc-0.4008\n",
      "Iter-20670, train loss-2.0844, acc-0.5000, valid loss-2.1470, acc-0.3906, test loss-2.1358, acc-0.4006\n",
      "Iter-20680, train loss-2.1626, acc-0.3800, valid loss-2.1469, acc-0.3910, test loss-2.1357, acc-0.4006\n",
      "Iter-20690, train loss-2.1367, acc-0.3800, valid loss-2.1469, acc-0.3908, test loss-2.1356, acc-0.4006\n",
      "Iter-20700, train loss-2.1512, acc-0.4000, valid loss-2.1468, acc-0.3908, test loss-2.1356, acc-0.4011\n",
      "Iter-20710, train loss-2.1385, acc-0.4000, valid loss-2.1467, acc-0.3910, test loss-2.1355, acc-0.4012\n",
      "Iter-20720, train loss-2.1337, acc-0.4000, valid loss-2.1467, acc-0.3908, test loss-2.1354, acc-0.4016\n",
      "Iter-20730, train loss-2.1312, acc-0.4800, valid loss-2.1466, acc-0.3910, test loss-2.1354, acc-0.4013\n",
      "Iter-20740, train loss-2.1306, acc-0.3200, valid loss-2.1465, acc-0.3908, test loss-2.1353, acc-0.4013\n",
      "Iter-20750, train loss-2.1086, acc-0.4800, valid loss-2.1465, acc-0.3906, test loss-2.1352, acc-0.4012\n",
      "Iter-20760, train loss-2.1230, acc-0.4600, valid loss-2.1464, acc-0.3908, test loss-2.1351, acc-0.4013\n",
      "Iter-20770, train loss-2.1538, acc-0.4600, valid loss-2.1463, acc-0.3910, test loss-2.1351, acc-0.4014\n",
      "Iter-20780, train loss-2.1477, acc-0.4200, valid loss-2.1463, acc-0.3910, test loss-2.1350, acc-0.4014\n",
      "Iter-20790, train loss-2.1808, acc-0.3400, valid loss-2.1462, acc-0.3908, test loss-2.1350, acc-0.4017\n",
      "Iter-20800, train loss-2.1403, acc-0.4400, valid loss-2.1462, acc-0.3908, test loss-2.1349, acc-0.4017\n",
      "Iter-20810, train loss-2.1628, acc-0.3600, valid loss-2.1461, acc-0.3912, test loss-2.1348, acc-0.4017\n",
      "Iter-20820, train loss-2.1331, acc-0.4400, valid loss-2.1460, acc-0.3912, test loss-2.1348, acc-0.4017\n",
      "Iter-20830, train loss-2.1260, acc-0.4800, valid loss-2.1460, acc-0.3912, test loss-2.1347, acc-0.4019\n",
      "Iter-20840, train loss-2.1280, acc-0.4200, valid loss-2.1459, acc-0.3916, test loss-2.1346, acc-0.4022\n",
      "Iter-20850, train loss-2.1766, acc-0.2800, valid loss-2.1459, acc-0.3912, test loss-2.1345, acc-0.4025\n",
      "Iter-20860, train loss-2.1648, acc-0.4000, valid loss-2.1458, acc-0.3916, test loss-2.1345, acc-0.4023\n",
      "Iter-20870, train loss-2.1446, acc-0.2600, valid loss-2.1457, acc-0.3918, test loss-2.1344, acc-0.4026\n",
      "Iter-20880, train loss-2.1469, acc-0.3400, valid loss-2.1457, acc-0.3916, test loss-2.1343, acc-0.4024\n",
      "Iter-20890, train loss-2.1336, acc-0.4400, valid loss-2.1456, acc-0.3916, test loss-2.1343, acc-0.4025\n",
      "Iter-20900, train loss-2.1709, acc-0.3200, valid loss-2.1456, acc-0.3918, test loss-2.1342, acc-0.4025\n",
      "Iter-20910, train loss-2.1620, acc-0.3200, valid loss-2.1455, acc-0.3918, test loss-2.1342, acc-0.4026\n",
      "Iter-20920, train loss-2.1233, acc-0.4000, valid loss-2.1454, acc-0.3918, test loss-2.1341, acc-0.4027\n",
      "Iter-20930, train loss-2.0993, acc-0.4800, valid loss-2.1454, acc-0.3920, test loss-2.1340, acc-0.4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20940, train loss-2.1608, acc-0.3400, valid loss-2.1453, acc-0.3924, test loss-2.1340, acc-0.4025\n",
      "Iter-20950, train loss-2.1342, acc-0.4800, valid loss-2.1453, acc-0.3930, test loss-2.1339, acc-0.4026\n",
      "Iter-20960, train loss-2.1575, acc-0.3800, valid loss-2.1452, acc-0.3930, test loss-2.1338, acc-0.4026\n",
      "Iter-20970, train loss-2.1769, acc-0.2800, valid loss-2.1451, acc-0.3930, test loss-2.1338, acc-0.4026\n",
      "Iter-20980, train loss-2.1562, acc-0.3200, valid loss-2.1451, acc-0.3928, test loss-2.1337, acc-0.4029\n",
      "Iter-20990, train loss-2.1393, acc-0.4400, valid loss-2.1450, acc-0.3928, test loss-2.1336, acc-0.4030\n",
      "Iter-21000, train loss-2.1523, acc-0.4800, valid loss-2.1450, acc-0.3928, test loss-2.1336, acc-0.4030\n",
      "Iter-21010, train loss-2.1459, acc-0.4800, valid loss-2.1449, acc-0.3938, test loss-2.1335, acc-0.4030\n",
      "Iter-21020, train loss-2.1560, acc-0.3600, valid loss-2.1448, acc-0.3936, test loss-2.1334, acc-0.4035\n",
      "Iter-21030, train loss-2.1212, acc-0.4800, valid loss-2.1448, acc-0.3934, test loss-2.1334, acc-0.4031\n",
      "Iter-21040, train loss-2.1201, acc-0.4200, valid loss-2.1447, acc-0.3936, test loss-2.1333, acc-0.4034\n",
      "Iter-21050, train loss-2.1722, acc-0.1800, valid loss-2.1446, acc-0.3938, test loss-2.1332, acc-0.4035\n",
      "Iter-21060, train loss-2.1580, acc-0.4200, valid loss-2.1446, acc-0.3936, test loss-2.1332, acc-0.4032\n",
      "Iter-21070, train loss-2.1469, acc-0.3400, valid loss-2.1445, acc-0.3934, test loss-2.1331, acc-0.4036\n",
      "Iter-21080, train loss-2.1522, acc-0.3200, valid loss-2.1444, acc-0.3936, test loss-2.1330, acc-0.4031\n",
      "Iter-21090, train loss-2.1298, acc-0.4200, valid loss-2.1444, acc-0.3938, test loss-2.1329, acc-0.4034\n",
      "Iter-21100, train loss-2.1646, acc-0.3800, valid loss-2.1443, acc-0.3936, test loss-2.1329, acc-0.4030\n",
      "Iter-21110, train loss-2.1353, acc-0.3400, valid loss-2.1443, acc-0.3934, test loss-2.1328, acc-0.4031\n",
      "Iter-21120, train loss-2.1135, acc-0.4800, valid loss-2.1442, acc-0.3934, test loss-2.1327, acc-0.4027\n",
      "Iter-21130, train loss-2.1532, acc-0.4200, valid loss-2.1441, acc-0.3934, test loss-2.1327, acc-0.4032\n",
      "Iter-21140, train loss-2.1019, acc-0.5400, valid loss-2.1441, acc-0.3936, test loss-2.1326, acc-0.4034\n",
      "Iter-21150, train loss-2.1067, acc-0.4600, valid loss-2.1440, acc-0.3938, test loss-2.1325, acc-0.4034\n",
      "Iter-21160, train loss-2.1318, acc-0.3600, valid loss-2.1439, acc-0.3932, test loss-2.1325, acc-0.4032\n",
      "Iter-21170, train loss-2.1387, acc-0.4200, valid loss-2.1439, acc-0.3938, test loss-2.1324, acc-0.4033\n",
      "Iter-21180, train loss-2.1491, acc-0.4600, valid loss-2.1438, acc-0.3938, test loss-2.1323, acc-0.4040\n",
      "Iter-21190, train loss-2.1612, acc-0.3400, valid loss-2.1437, acc-0.3940, test loss-2.1323, acc-0.4041\n",
      "Iter-21200, train loss-2.1308, acc-0.4000, valid loss-2.1437, acc-0.3944, test loss-2.1322, acc-0.4042\n",
      "Iter-21210, train loss-2.1284, acc-0.3600, valid loss-2.1436, acc-0.3944, test loss-2.1321, acc-0.4042\n",
      "Iter-21220, train loss-2.1181, acc-0.5200, valid loss-2.1436, acc-0.3948, test loss-2.1321, acc-0.4042\n",
      "Iter-21230, train loss-2.1276, acc-0.4000, valid loss-2.1435, acc-0.3948, test loss-2.1320, acc-0.4043\n",
      "Iter-21240, train loss-2.1369, acc-0.3800, valid loss-2.1434, acc-0.3948, test loss-2.1319, acc-0.4045\n",
      "Iter-21250, train loss-2.1241, acc-0.4200, valid loss-2.1434, acc-0.3948, test loss-2.1319, acc-0.4045\n",
      "Iter-21260, train loss-2.2071, acc-0.4000, valid loss-2.1433, acc-0.3948, test loss-2.1318, acc-0.4048\n",
      "Iter-21270, train loss-2.1141, acc-0.4000, valid loss-2.1433, acc-0.3948, test loss-2.1317, acc-0.4050\n",
      "Iter-21280, train loss-2.2059, acc-0.3000, valid loss-2.1432, acc-0.3950, test loss-2.1317, acc-0.4050\n",
      "Iter-21290, train loss-2.1224, acc-0.3000, valid loss-2.1431, acc-0.3952, test loss-2.1316, acc-0.4052\n",
      "Iter-21300, train loss-2.1231, acc-0.3600, valid loss-2.1431, acc-0.3952, test loss-2.1315, acc-0.4055\n",
      "Iter-21310, train loss-2.1466, acc-0.3600, valid loss-2.1430, acc-0.3952, test loss-2.1315, acc-0.4057\n",
      "Iter-21320, train loss-2.1467, acc-0.4000, valid loss-2.1430, acc-0.3952, test loss-2.1314, acc-0.4056\n",
      "Iter-21330, train loss-2.1402, acc-0.3800, valid loss-2.1429, acc-0.3950, test loss-2.1313, acc-0.4059\n",
      "Iter-21340, train loss-2.1567, acc-0.4000, valid loss-2.1428, acc-0.3950, test loss-2.1313, acc-0.4060\n",
      "Iter-21350, train loss-2.1546, acc-0.3400, valid loss-2.1428, acc-0.3948, test loss-2.1312, acc-0.4061\n",
      "Iter-21360, train loss-2.1078, acc-0.4800, valid loss-2.1427, acc-0.3950, test loss-2.1311, acc-0.4061\n",
      "Iter-21370, train loss-2.1565, acc-0.3800, valid loss-2.1427, acc-0.3948, test loss-2.1311, acc-0.4059\n",
      "Iter-21380, train loss-2.1475, acc-0.3600, valid loss-2.1426, acc-0.3950, test loss-2.1310, acc-0.4062\n",
      "Iter-21390, train loss-2.1296, acc-0.3400, valid loss-2.1425, acc-0.3948, test loss-2.1309, acc-0.4062\n",
      "Iter-21400, train loss-2.1444, acc-0.3600, valid loss-2.1425, acc-0.3948, test loss-2.1309, acc-0.4063\n",
      "Iter-21410, train loss-2.1066, acc-0.3800, valid loss-2.1424, acc-0.3950, test loss-2.1308, acc-0.4065\n",
      "Iter-21420, train loss-2.1211, acc-0.4400, valid loss-2.1424, acc-0.3954, test loss-2.1307, acc-0.4065\n",
      "Iter-21430, train loss-2.1465, acc-0.2400, valid loss-2.1423, acc-0.3958, test loss-2.1307, acc-0.4066\n",
      "Iter-21440, train loss-2.1536, acc-0.2800, valid loss-2.1422, acc-0.3960, test loss-2.1306, acc-0.4065\n",
      "Iter-21450, train loss-2.2080, acc-0.2400, valid loss-2.1422, acc-0.3960, test loss-2.1305, acc-0.4068\n",
      "Iter-21460, train loss-2.1404, acc-0.3600, valid loss-2.1421, acc-0.3958, test loss-2.1305, acc-0.4070\n",
      "Iter-21470, train loss-2.1575, acc-0.3000, valid loss-2.1421, acc-0.3960, test loss-2.1304, acc-0.4071\n",
      "Iter-21480, train loss-2.1517, acc-0.4200, valid loss-2.1420, acc-0.3962, test loss-2.1303, acc-0.4071\n",
      "Iter-21490, train loss-2.1764, acc-0.3800, valid loss-2.1419, acc-0.3960, test loss-2.1303, acc-0.4072\n",
      "Iter-21500, train loss-2.1243, acc-0.4600, valid loss-2.1419, acc-0.3958, test loss-2.1302, acc-0.4071\n",
      "Iter-21510, train loss-2.1508, acc-0.5000, valid loss-2.1418, acc-0.3960, test loss-2.1301, acc-0.4071\n",
      "Iter-21520, train loss-2.1588, acc-0.3000, valid loss-2.1417, acc-0.3964, test loss-2.1301, acc-0.4070\n",
      "Iter-21530, train loss-2.1165, acc-0.4200, valid loss-2.1417, acc-0.3962, test loss-2.1300, acc-0.4069\n",
      "Iter-21540, train loss-2.1412, acc-0.4600, valid loss-2.1416, acc-0.3960, test loss-2.1299, acc-0.4070\n",
      "Iter-21550, train loss-2.1336, acc-0.4000, valid loss-2.1416, acc-0.3960, test loss-2.1299, acc-0.4068\n",
      "Iter-21560, train loss-2.1950, acc-0.2800, valid loss-2.1415, acc-0.3966, test loss-2.1298, acc-0.4072\n",
      "Iter-21570, train loss-2.1138, acc-0.4200, valid loss-2.1414, acc-0.3960, test loss-2.1297, acc-0.4069\n",
      "Iter-21580, train loss-2.1136, acc-0.4200, valid loss-2.1414, acc-0.3960, test loss-2.1297, acc-0.4070\n",
      "Iter-21590, train loss-2.1180, acc-0.4400, valid loss-2.1413, acc-0.3960, test loss-2.1296, acc-0.4073\n",
      "Iter-21600, train loss-2.1447, acc-0.4200, valid loss-2.1413, acc-0.3966, test loss-2.1295, acc-0.4069\n",
      "Iter-21610, train loss-2.1314, acc-0.5400, valid loss-2.1412, acc-0.3970, test loss-2.1295, acc-0.4071\n",
      "Iter-21620, train loss-2.0777, acc-0.4600, valid loss-2.1411, acc-0.3970, test loss-2.1294, acc-0.4070\n",
      "Iter-21630, train loss-2.0993, acc-0.5000, valid loss-2.1411, acc-0.3970, test loss-2.1293, acc-0.4072\n",
      "Iter-21640, train loss-2.1141, acc-0.4400, valid loss-2.1410, acc-0.3970, test loss-2.1293, acc-0.4071\n",
      "Iter-21650, train loss-2.0881, acc-0.4600, valid loss-2.1409, acc-0.3972, test loss-2.1292, acc-0.4073\n",
      "Iter-21660, train loss-2.1277, acc-0.4000, valid loss-2.1409, acc-0.3964, test loss-2.1291, acc-0.4073\n",
      "Iter-21670, train loss-2.1127, acc-0.4000, valid loss-2.1408, acc-0.3968, test loss-2.1291, acc-0.4075\n",
      "Iter-21680, train loss-2.0918, acc-0.4800, valid loss-2.1408, acc-0.3966, test loss-2.1290, acc-0.4075\n",
      "Iter-21690, train loss-2.1817, acc-0.4400, valid loss-2.1407, acc-0.3972, test loss-2.1289, acc-0.4072\n",
      "Iter-21700, train loss-2.1295, acc-0.4200, valid loss-2.1406, acc-0.3970, test loss-2.1289, acc-0.4074\n",
      "Iter-21710, train loss-2.1518, acc-0.3400, valid loss-2.1406, acc-0.3972, test loss-2.1288, acc-0.4072\n",
      "Iter-21720, train loss-2.1943, acc-0.3200, valid loss-2.1405, acc-0.3972, test loss-2.1287, acc-0.4074\n",
      "Iter-21730, train loss-2.1410, acc-0.4400, valid loss-2.1405, acc-0.3978, test loss-2.1287, acc-0.4072\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-21740, train loss-2.1455, acc-0.3600, valid loss-2.1404, acc-0.3976, test loss-2.1286, acc-0.4071\n",
      "Iter-21750, train loss-2.1499, acc-0.3600, valid loss-2.1403, acc-0.3978, test loss-2.1285, acc-0.4071\n",
      "Iter-21760, train loss-2.1105, acc-0.5000, valid loss-2.1403, acc-0.3974, test loss-2.1285, acc-0.4074\n",
      "Iter-21770, train loss-2.1559, acc-0.3600, valid loss-2.1402, acc-0.3976, test loss-2.1284, acc-0.4075\n",
      "Iter-21780, train loss-2.1509, acc-0.2800, valid loss-2.1402, acc-0.3976, test loss-2.1283, acc-0.4075\n",
      "Iter-21790, train loss-2.1610, acc-0.3400, valid loss-2.1401, acc-0.3976, test loss-2.1282, acc-0.4079\n",
      "Iter-21800, train loss-2.1147, acc-0.3600, valid loss-2.1400, acc-0.3976, test loss-2.1282, acc-0.4077\n",
      "Iter-21810, train loss-2.1186, acc-0.3800, valid loss-2.1400, acc-0.3980, test loss-2.1281, acc-0.4077\n",
      "Iter-21820, train loss-2.1264, acc-0.4800, valid loss-2.1399, acc-0.3980, test loss-2.1280, acc-0.4078\n",
      "Iter-21830, train loss-2.1675, acc-0.3200, valid loss-2.1399, acc-0.3986, test loss-2.1280, acc-0.4079\n",
      "Iter-21840, train loss-2.0927, acc-0.4800, valid loss-2.1398, acc-0.3986, test loss-2.1279, acc-0.4079\n",
      "Iter-21850, train loss-2.0667, acc-0.5600, valid loss-2.1397, acc-0.3988, test loss-2.1279, acc-0.4080\n",
      "Iter-21860, train loss-2.1028, acc-0.4600, valid loss-2.1397, acc-0.3988, test loss-2.1278, acc-0.4078\n",
      "Iter-21870, train loss-2.1528, acc-0.3200, valid loss-2.1396, acc-0.3986, test loss-2.1277, acc-0.4078\n",
      "Iter-21880, train loss-2.1142, acc-0.4200, valid loss-2.1396, acc-0.3988, test loss-2.1277, acc-0.4083\n",
      "Iter-21890, train loss-2.1371, acc-0.3600, valid loss-2.1395, acc-0.3984, test loss-2.1276, acc-0.4080\n",
      "Iter-21900, train loss-2.1287, acc-0.4600, valid loss-2.1394, acc-0.3982, test loss-2.1275, acc-0.4078\n",
      "Iter-21910, train loss-2.1328, acc-0.4000, valid loss-2.1394, acc-0.3984, test loss-2.1275, acc-0.4080\n",
      "Iter-21920, train loss-2.0894, acc-0.4800, valid loss-2.1393, acc-0.3984, test loss-2.1274, acc-0.4082\n",
      "Iter-21930, train loss-2.1205, acc-0.4000, valid loss-2.1393, acc-0.3984, test loss-2.1273, acc-0.4081\n",
      "Iter-21940, train loss-2.1190, acc-0.3600, valid loss-2.1392, acc-0.3982, test loss-2.1272, acc-0.4084\n",
      "Iter-21950, train loss-2.1257, acc-0.4400, valid loss-2.1392, acc-0.3984, test loss-2.1272, acc-0.4084\n",
      "Iter-21960, train loss-2.1235, acc-0.4000, valid loss-2.1391, acc-0.3982, test loss-2.1271, acc-0.4085\n",
      "Iter-21970, train loss-2.1298, acc-0.4600, valid loss-2.1390, acc-0.3980, test loss-2.1270, acc-0.4085\n",
      "Iter-21980, train loss-2.0981, acc-0.4600, valid loss-2.1390, acc-0.3978, test loss-2.1270, acc-0.4086\n",
      "Iter-21990, train loss-2.1200, acc-0.4600, valid loss-2.1389, acc-0.3978, test loss-2.1269, acc-0.4084\n",
      "Iter-22000, train loss-2.1224, acc-0.5200, valid loss-2.1389, acc-0.3978, test loss-2.1268, acc-0.4087\n",
      "Iter-22010, train loss-2.1227, acc-0.4800, valid loss-2.1388, acc-0.3980, test loss-2.1268, acc-0.4087\n",
      "Iter-22020, train loss-2.1235, acc-0.4000, valid loss-2.1387, acc-0.3988, test loss-2.1267, acc-0.4086\n",
      "Iter-22030, train loss-2.1175, acc-0.4200, valid loss-2.1387, acc-0.3984, test loss-2.1267, acc-0.4088\n",
      "Iter-22040, train loss-2.1152, acc-0.4600, valid loss-2.1386, acc-0.3982, test loss-2.1266, acc-0.4090\n",
      "Iter-22050, train loss-2.1165, acc-0.4400, valid loss-2.1386, acc-0.3984, test loss-2.1265, acc-0.4093\n",
      "Iter-22060, train loss-2.1275, acc-0.4400, valid loss-2.1385, acc-0.3986, test loss-2.1265, acc-0.4094\n",
      "Iter-22070, train loss-2.1275, acc-0.4200, valid loss-2.1384, acc-0.3982, test loss-2.1264, acc-0.4096\n",
      "Iter-22080, train loss-2.1257, acc-0.5000, valid loss-2.1384, acc-0.3986, test loss-2.1263, acc-0.4092\n",
      "Iter-22090, train loss-2.1171, acc-0.3400, valid loss-2.1383, acc-0.3986, test loss-2.1263, acc-0.4093\n",
      "Iter-22100, train loss-2.1314, acc-0.5000, valid loss-2.1383, acc-0.3988, test loss-2.1262, acc-0.4094\n",
      "Iter-22110, train loss-2.1340, acc-0.3400, valid loss-2.1382, acc-0.3990, test loss-2.1261, acc-0.4094\n",
      "Iter-22120, train loss-2.1501, acc-0.4400, valid loss-2.1382, acc-0.3990, test loss-2.1261, acc-0.4097\n",
      "Iter-22130, train loss-2.1528, acc-0.3800, valid loss-2.1381, acc-0.3992, test loss-2.1260, acc-0.4098\n",
      "Iter-22140, train loss-2.1242, acc-0.4200, valid loss-2.1380, acc-0.3992, test loss-2.1259, acc-0.4098\n",
      "Iter-22150, train loss-2.1004, acc-0.4200, valid loss-2.1380, acc-0.3992, test loss-2.1259, acc-0.4098\n",
      "Iter-22160, train loss-2.1062, acc-0.4200, valid loss-2.1379, acc-0.3994, test loss-2.1258, acc-0.4101\n",
      "Iter-22170, train loss-2.1093, acc-0.5600, valid loss-2.1378, acc-0.3996, test loss-2.1257, acc-0.4100\n",
      "Iter-22180, train loss-2.1092, acc-0.4200, valid loss-2.1378, acc-0.3992, test loss-2.1257, acc-0.4099\n",
      "Iter-22190, train loss-2.1060, acc-0.4000, valid loss-2.1377, acc-0.3992, test loss-2.1256, acc-0.4103\n",
      "Iter-22200, train loss-2.1061, acc-0.5000, valid loss-2.1377, acc-0.3992, test loss-2.1255, acc-0.4100\n",
      "Iter-22210, train loss-2.1161, acc-0.4600, valid loss-2.1376, acc-0.3990, test loss-2.1255, acc-0.4103\n",
      "Iter-22220, train loss-2.1310, acc-0.4600, valid loss-2.1375, acc-0.3992, test loss-2.1254, acc-0.4103\n",
      "Iter-22230, train loss-2.1024, acc-0.4600, valid loss-2.1375, acc-0.3998, test loss-2.1253, acc-0.4100\n",
      "Iter-22240, train loss-2.1046, acc-0.4800, valid loss-2.1374, acc-0.4000, test loss-2.1253, acc-0.4102\n",
      "Iter-22250, train loss-2.1148, acc-0.4400, valid loss-2.1374, acc-0.3998, test loss-2.1252, acc-0.4103\n",
      "Iter-22260, train loss-2.1241, acc-0.4000, valid loss-2.1373, acc-0.4000, test loss-2.1251, acc-0.4107\n",
      "Iter-22270, train loss-2.0787, acc-0.4800, valid loss-2.1372, acc-0.4000, test loss-2.1251, acc-0.4107\n",
      "Iter-22280, train loss-2.0961, acc-0.4600, valid loss-2.1372, acc-0.4002, test loss-2.1250, acc-0.4103\n",
      "Iter-22290, train loss-2.1414, acc-0.3000, valid loss-2.1371, acc-0.3998, test loss-2.1249, acc-0.4106\n",
      "Iter-22300, train loss-2.1307, acc-0.3600, valid loss-2.1371, acc-0.3996, test loss-2.1249, acc-0.4108\n",
      "Iter-22310, train loss-2.1407, acc-0.4400, valid loss-2.1370, acc-0.4002, test loss-2.1248, acc-0.4109\n",
      "Iter-22320, train loss-2.1415, acc-0.3800, valid loss-2.1369, acc-0.4006, test loss-2.1247, acc-0.4109\n",
      "Iter-22330, train loss-2.1661, acc-0.4000, valid loss-2.1369, acc-0.4008, test loss-2.1247, acc-0.4110\n",
      "Iter-22340, train loss-2.0851, acc-0.5400, valid loss-2.1368, acc-0.4002, test loss-2.1246, acc-0.4111\n",
      "Iter-22350, train loss-2.1180, acc-0.4200, valid loss-2.1368, acc-0.4002, test loss-2.1245, acc-0.4115\n",
      "Iter-22360, train loss-2.1333, acc-0.3200, valid loss-2.1367, acc-0.4004, test loss-2.1245, acc-0.4114\n",
      "Iter-22370, train loss-2.1365, acc-0.4000, valid loss-2.1367, acc-0.4008, test loss-2.1244, acc-0.4114\n",
      "Iter-22380, train loss-2.1264, acc-0.4000, valid loss-2.1366, acc-0.4008, test loss-2.1244, acc-0.4119\n",
      "Iter-22390, train loss-2.0993, acc-0.5200, valid loss-2.1365, acc-0.4004, test loss-2.1243, acc-0.4117\n",
      "Iter-22400, train loss-2.1115, acc-0.4400, valid loss-2.1365, acc-0.4010, test loss-2.1242, acc-0.4113\n",
      "Iter-22410, train loss-2.1098, acc-0.4600, valid loss-2.1364, acc-0.4012, test loss-2.1242, acc-0.4114\n",
      "Iter-22420, train loss-2.1477, acc-0.3400, valid loss-2.1364, acc-0.4014, test loss-2.1241, acc-0.4113\n",
      "Iter-22430, train loss-2.1152, acc-0.3000, valid loss-2.1363, acc-0.4012, test loss-2.1240, acc-0.4120\n",
      "Iter-22440, train loss-2.1631, acc-0.3800, valid loss-2.1362, acc-0.4016, test loss-2.1240, acc-0.4119\n",
      "Iter-22450, train loss-2.1216, acc-0.3200, valid loss-2.1362, acc-0.4008, test loss-2.1239, acc-0.4120\n",
      "Iter-22460, train loss-2.1523, acc-0.4200, valid loss-2.1361, acc-0.4014, test loss-2.1238, acc-0.4121\n",
      "Iter-22470, train loss-2.1468, acc-0.3400, valid loss-2.1361, acc-0.4016, test loss-2.1237, acc-0.4120\n",
      "Iter-22480, train loss-2.1615, acc-0.3400, valid loss-2.1360, acc-0.4014, test loss-2.1237, acc-0.4119\n",
      "Iter-22490, train loss-2.1578, acc-0.4600, valid loss-2.1360, acc-0.4016, test loss-2.1236, acc-0.4123\n",
      "Iter-22500, train loss-2.1174, acc-0.4200, valid loss-2.1359, acc-0.4018, test loss-2.1236, acc-0.4125\n",
      "Iter-22510, train loss-2.1458, acc-0.3800, valid loss-2.1358, acc-0.4016, test loss-2.1235, acc-0.4128\n",
      "Iter-22520, train loss-2.1677, acc-0.3600, valid loss-2.1358, acc-0.4024, test loss-2.1234, acc-0.4129\n",
      "Iter-22530, train loss-2.0937, acc-0.5000, valid loss-2.1357, acc-0.4022, test loss-2.1234, acc-0.4131\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-22540, train loss-2.1628, acc-0.3200, valid loss-2.1357, acc-0.4022, test loss-2.1233, acc-0.4130\n",
      "Iter-22550, train loss-2.1089, acc-0.4800, valid loss-2.1356, acc-0.4016, test loss-2.1232, acc-0.4131\n",
      "Iter-22560, train loss-2.1367, acc-0.3400, valid loss-2.1355, acc-0.4024, test loss-2.1232, acc-0.4128\n",
      "Iter-22570, train loss-2.1028, acc-0.5400, valid loss-2.1355, acc-0.4026, test loss-2.1231, acc-0.4132\n",
      "Iter-22580, train loss-2.1032, acc-0.4200, valid loss-2.1354, acc-0.4030, test loss-2.1230, acc-0.4129\n",
      "Iter-22590, train loss-2.1003, acc-0.4000, valid loss-2.1354, acc-0.4036, test loss-2.1230, acc-0.4128\n",
      "Iter-22600, train loss-2.1425, acc-0.3800, valid loss-2.1353, acc-0.4034, test loss-2.1229, acc-0.4130\n",
      "Iter-22610, train loss-2.1331, acc-0.2800, valid loss-2.1353, acc-0.4036, test loss-2.1228, acc-0.4131\n",
      "Iter-22620, train loss-2.1448, acc-0.3600, valid loss-2.1352, acc-0.4038, test loss-2.1228, acc-0.4132\n",
      "Iter-22630, train loss-2.1625, acc-0.3600, valid loss-2.1351, acc-0.4038, test loss-2.1227, acc-0.4132\n",
      "Iter-22640, train loss-2.0821, acc-0.5600, valid loss-2.1351, acc-0.4038, test loss-2.1226, acc-0.4136\n",
      "Iter-22650, train loss-2.2034, acc-0.3200, valid loss-2.1350, acc-0.4040, test loss-2.1226, acc-0.4134\n",
      "Iter-22660, train loss-2.1110, acc-0.4000, valid loss-2.1350, acc-0.4040, test loss-2.1225, acc-0.4132\n",
      "Iter-22670, train loss-2.1475, acc-0.4600, valid loss-2.1349, acc-0.4040, test loss-2.1224, acc-0.4137\n",
      "Iter-22680, train loss-2.1342, acc-0.3600, valid loss-2.1348, acc-0.4044, test loss-2.1224, acc-0.4135\n",
      "Iter-22690, train loss-2.1493, acc-0.3800, valid loss-2.1348, acc-0.4042, test loss-2.1223, acc-0.4133\n",
      "Iter-22700, train loss-2.1231, acc-0.3600, valid loss-2.1347, acc-0.4044, test loss-2.1223, acc-0.4139\n",
      "Iter-22710, train loss-2.1538, acc-0.3400, valid loss-2.1347, acc-0.4044, test loss-2.1222, acc-0.4137\n",
      "Iter-22720, train loss-2.1261, acc-0.4000, valid loss-2.1346, acc-0.4044, test loss-2.1221, acc-0.4139\n",
      "Iter-22730, train loss-2.1351, acc-0.3200, valid loss-2.1345, acc-0.4044, test loss-2.1221, acc-0.4137\n",
      "Iter-22740, train loss-2.0932, acc-0.3800, valid loss-2.1345, acc-0.4044, test loss-2.1220, acc-0.4139\n",
      "Iter-22750, train loss-2.0999, acc-0.4000, valid loss-2.1344, acc-0.4044, test loss-2.1219, acc-0.4141\n",
      "Iter-22760, train loss-2.1088, acc-0.4000, valid loss-2.1344, acc-0.4050, test loss-2.1219, acc-0.4140\n",
      "Iter-22770, train loss-2.1468, acc-0.4400, valid loss-2.1343, acc-0.4048, test loss-2.1218, acc-0.4142\n",
      "Iter-22780, train loss-2.1332, acc-0.4200, valid loss-2.1342, acc-0.4048, test loss-2.1217, acc-0.4142\n",
      "Iter-22790, train loss-2.1327, acc-0.3600, valid loss-2.1342, acc-0.4056, test loss-2.1217, acc-0.4141\n",
      "Iter-22800, train loss-2.1277, acc-0.3800, valid loss-2.1341, acc-0.4054, test loss-2.1216, acc-0.4143\n",
      "Iter-22810, train loss-2.0709, acc-0.5000, valid loss-2.1341, acc-0.4054, test loss-2.1215, acc-0.4143\n",
      "Iter-22820, train loss-2.0991, acc-0.4600, valid loss-2.1340, acc-0.4052, test loss-2.1215, acc-0.4141\n",
      "Iter-22830, train loss-2.1151, acc-0.4400, valid loss-2.1339, acc-0.4052, test loss-2.1214, acc-0.4139\n",
      "Iter-22840, train loss-2.1236, acc-0.4400, valid loss-2.1339, acc-0.4052, test loss-2.1213, acc-0.4143\n",
      "Iter-22850, train loss-2.0824, acc-0.5200, valid loss-2.1338, acc-0.4052, test loss-2.1213, acc-0.4146\n",
      "Iter-22860, train loss-2.0811, acc-0.3800, valid loss-2.1338, acc-0.4056, test loss-2.1212, acc-0.4144\n",
      "Iter-22870, train loss-2.0984, acc-0.5600, valid loss-2.1337, acc-0.4056, test loss-2.1211, acc-0.4145\n",
      "Iter-22880, train loss-2.1221, acc-0.3600, valid loss-2.1336, acc-0.4056, test loss-2.1211, acc-0.4147\n",
      "Iter-22890, train loss-2.1447, acc-0.3400, valid loss-2.1336, acc-0.4050, test loss-2.1210, acc-0.4146\n",
      "Iter-22900, train loss-2.1195, acc-0.3400, valid loss-2.1335, acc-0.4054, test loss-2.1209, acc-0.4146\n",
      "Iter-22910, train loss-2.1137, acc-0.5000, valid loss-2.1335, acc-0.4056, test loss-2.1209, acc-0.4149\n",
      "Iter-22920, train loss-2.1170, acc-0.4800, valid loss-2.1334, acc-0.4058, test loss-2.1208, acc-0.4151\n",
      "Iter-22930, train loss-2.1377, acc-0.3000, valid loss-2.1334, acc-0.4056, test loss-2.1207, acc-0.4149\n",
      "Iter-22940, train loss-2.1454, acc-0.3000, valid loss-2.1333, acc-0.4062, test loss-2.1207, acc-0.4148\n",
      "Iter-22950, train loss-2.1142, acc-0.4400, valid loss-2.1332, acc-0.4060, test loss-2.1206, acc-0.4147\n",
      "Iter-22960, train loss-2.0939, acc-0.4800, valid loss-2.1332, acc-0.4062, test loss-2.1205, acc-0.4147\n",
      "Iter-22970, train loss-2.1218, acc-0.3800, valid loss-2.1331, acc-0.4058, test loss-2.1205, acc-0.4150\n",
      "Iter-22980, train loss-2.1004, acc-0.5000, valid loss-2.1331, acc-0.4056, test loss-2.1204, acc-0.4149\n",
      "Iter-22990, train loss-2.1290, acc-0.4200, valid loss-2.1330, acc-0.4058, test loss-2.1203, acc-0.4150\n",
      "Iter-23000, train loss-2.1007, acc-0.4400, valid loss-2.1329, acc-0.4062, test loss-2.1203, acc-0.4153\n",
      "Iter-23010, train loss-2.1634, acc-0.4000, valid loss-2.1329, acc-0.4058, test loss-2.1202, acc-0.4151\n",
      "Iter-23020, train loss-2.0964, acc-0.4000, valid loss-2.1328, acc-0.4058, test loss-2.1202, acc-0.4154\n",
      "Iter-23030, train loss-2.1332, acc-0.4600, valid loss-2.1328, acc-0.4062, test loss-2.1201, acc-0.4153\n",
      "Iter-23040, train loss-2.1047, acc-0.4400, valid loss-2.1327, acc-0.4060, test loss-2.1200, acc-0.4157\n",
      "Iter-23050, train loss-2.0986, acc-0.4600, valid loss-2.1326, acc-0.4056, test loss-2.1200, acc-0.4157\n",
      "Iter-23060, train loss-2.1313, acc-0.3600, valid loss-2.1326, acc-0.4058, test loss-2.1199, acc-0.4154\n",
      "Iter-23070, train loss-2.1292, acc-0.3400, valid loss-2.1325, acc-0.4058, test loss-2.1198, acc-0.4154\n",
      "Iter-23080, train loss-2.1052, acc-0.4400, valid loss-2.1325, acc-0.4060, test loss-2.1198, acc-0.4162\n",
      "Iter-23090, train loss-2.1395, acc-0.4400, valid loss-2.1324, acc-0.4062, test loss-2.1197, acc-0.4156\n",
      "Iter-23100, train loss-2.1388, acc-0.4800, valid loss-2.1323, acc-0.4062, test loss-2.1196, acc-0.4157\n",
      "Iter-23110, train loss-2.0339, acc-0.6000, valid loss-2.1323, acc-0.4060, test loss-2.1196, acc-0.4161\n",
      "Iter-23120, train loss-2.1618, acc-0.4600, valid loss-2.1322, acc-0.4060, test loss-2.1195, acc-0.4163\n",
      "Iter-23130, train loss-2.1571, acc-0.2600, valid loss-2.1322, acc-0.4062, test loss-2.1194, acc-0.4162\n",
      "Iter-23140, train loss-2.0779, acc-0.4600, valid loss-2.1321, acc-0.4062, test loss-2.1194, acc-0.4162\n",
      "Iter-23150, train loss-2.1077, acc-0.4600, valid loss-2.1321, acc-0.4064, test loss-2.1193, acc-0.4162\n",
      "Iter-23160, train loss-2.1607, acc-0.3600, valid loss-2.1320, acc-0.4066, test loss-2.1192, acc-0.4163\n",
      "Iter-23170, train loss-2.1042, acc-0.5000, valid loss-2.1319, acc-0.4070, test loss-2.1192, acc-0.4163\n",
      "Iter-23180, train loss-2.1954, acc-0.4200, valid loss-2.1319, acc-0.4068, test loss-2.1191, acc-0.4164\n",
      "Iter-23190, train loss-2.0944, acc-0.4000, valid loss-2.1318, acc-0.4072, test loss-2.1191, acc-0.4166\n",
      "Iter-23200, train loss-2.1131, acc-0.3800, valid loss-2.1318, acc-0.4072, test loss-2.1190, acc-0.4170\n",
      "Iter-23210, train loss-2.1361, acc-0.4800, valid loss-2.1317, acc-0.4072, test loss-2.1189, acc-0.4166\n",
      "Iter-23220, train loss-2.1098, acc-0.4400, valid loss-2.1316, acc-0.4072, test loss-2.1189, acc-0.4166\n",
      "Iter-23230, train loss-2.0932, acc-0.3800, valid loss-2.1316, acc-0.4074, test loss-2.1188, acc-0.4169\n",
      "Iter-23240, train loss-2.1430, acc-0.3200, valid loss-2.1315, acc-0.4072, test loss-2.1187, acc-0.4170\n",
      "Iter-23250, train loss-2.1144, acc-0.4200, valid loss-2.1315, acc-0.4072, test loss-2.1187, acc-0.4170\n",
      "Iter-23260, train loss-2.1085, acc-0.5000, valid loss-2.1314, acc-0.4072, test loss-2.1186, acc-0.4167\n",
      "Iter-23270, train loss-2.1531, acc-0.4600, valid loss-2.1313, acc-0.4072, test loss-2.1185, acc-0.4169\n",
      "Iter-23280, train loss-2.1357, acc-0.3800, valid loss-2.1313, acc-0.4078, test loss-2.1185, acc-0.4166\n",
      "Iter-23290, train loss-2.1790, acc-0.3200, valid loss-2.1312, acc-0.4078, test loss-2.1184, acc-0.4169\n",
      "Iter-23300, train loss-2.1796, acc-0.3600, valid loss-2.1312, acc-0.4076, test loss-2.1183, acc-0.4170\n",
      "Iter-23310, train loss-2.1196, acc-0.4200, valid loss-2.1311, acc-0.4078, test loss-2.1183, acc-0.4170\n",
      "Iter-23320, train loss-2.1316, acc-0.4200, valid loss-2.1311, acc-0.4076, test loss-2.1182, acc-0.4167\n",
      "Iter-23330, train loss-2.0907, acc-0.4600, valid loss-2.1310, acc-0.4080, test loss-2.1181, acc-0.4169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-23340, train loss-2.0834, acc-0.5600, valid loss-2.1309, acc-0.4078, test loss-2.1181, acc-0.4170\n",
      "Iter-23350, train loss-2.1504, acc-0.3800, valid loss-2.1309, acc-0.4082, test loss-2.1180, acc-0.4171\n",
      "Iter-23360, train loss-2.1292, acc-0.4200, valid loss-2.1308, acc-0.4082, test loss-2.1180, acc-0.4169\n",
      "Iter-23370, train loss-2.1349, acc-0.4000, valid loss-2.1308, acc-0.4082, test loss-2.1179, acc-0.4168\n",
      "Iter-23380, train loss-2.1448, acc-0.4200, valid loss-2.1307, acc-0.4080, test loss-2.1178, acc-0.4169\n",
      "Iter-23390, train loss-2.0705, acc-0.5000, valid loss-2.1307, acc-0.4080, test loss-2.1178, acc-0.4170\n",
      "Iter-23400, train loss-2.1308, acc-0.4600, valid loss-2.1306, acc-0.4080, test loss-2.1177, acc-0.4168\n",
      "Iter-23410, train loss-2.1338, acc-0.3600, valid loss-2.1305, acc-0.4078, test loss-2.1176, acc-0.4174\n",
      "Iter-23420, train loss-2.1430, acc-0.4200, valid loss-2.1305, acc-0.4078, test loss-2.1176, acc-0.4172\n",
      "Iter-23430, train loss-2.1203, acc-0.3000, valid loss-2.1304, acc-0.4078, test loss-2.1175, acc-0.4173\n",
      "Iter-23440, train loss-2.1248, acc-0.4000, valid loss-2.1304, acc-0.4078, test loss-2.1174, acc-0.4174\n",
      "Iter-23450, train loss-2.1391, acc-0.4200, valid loss-2.1303, acc-0.4078, test loss-2.1174, acc-0.4174\n",
      "Iter-23460, train loss-2.1215, acc-0.3800, valid loss-2.1302, acc-0.4080, test loss-2.1173, acc-0.4176\n",
      "Iter-23470, train loss-2.1014, acc-0.5000, valid loss-2.1302, acc-0.4080, test loss-2.1173, acc-0.4174\n",
      "Iter-23480, train loss-2.1352, acc-0.4000, valid loss-2.1301, acc-0.4082, test loss-2.1172, acc-0.4176\n",
      "Iter-23490, train loss-2.0972, acc-0.4200, valid loss-2.1301, acc-0.4086, test loss-2.1171, acc-0.4176\n",
      "Iter-23500, train loss-2.1445, acc-0.4400, valid loss-2.1300, acc-0.4086, test loss-2.1171, acc-0.4178\n",
      "Iter-23510, train loss-2.1163, acc-0.4000, valid loss-2.1300, acc-0.4084, test loss-2.1170, acc-0.4175\n",
      "Iter-23520, train loss-2.1432, acc-0.4800, valid loss-2.1299, acc-0.4090, test loss-2.1169, acc-0.4176\n",
      "Iter-23530, train loss-2.1459, acc-0.4200, valid loss-2.1298, acc-0.4088, test loss-2.1169, acc-0.4175\n",
      "Iter-23540, train loss-2.1386, acc-0.4000, valid loss-2.1298, acc-0.4088, test loss-2.1168, acc-0.4177\n",
      "Iter-23550, train loss-2.1402, acc-0.3600, valid loss-2.1297, acc-0.4086, test loss-2.1167, acc-0.4176\n",
      "Iter-23560, train loss-2.1216, acc-0.3400, valid loss-2.1297, acc-0.4090, test loss-2.1167, acc-0.4180\n",
      "Iter-23570, train loss-2.0928, acc-0.4600, valid loss-2.1296, acc-0.4088, test loss-2.1166, acc-0.4179\n",
      "Iter-23580, train loss-2.0931, acc-0.5000, valid loss-2.1296, acc-0.4086, test loss-2.1165, acc-0.4179\n",
      "Iter-23590, train loss-2.1072, acc-0.4000, valid loss-2.1295, acc-0.4088, test loss-2.1165, acc-0.4178\n",
      "Iter-23600, train loss-2.0994, acc-0.5000, valid loss-2.1294, acc-0.4090, test loss-2.1164, acc-0.4178\n",
      "Iter-23610, train loss-2.1424, acc-0.4800, valid loss-2.1294, acc-0.4092, test loss-2.1164, acc-0.4181\n",
      "Iter-23620, train loss-2.1278, acc-0.4800, valid loss-2.1293, acc-0.4090, test loss-2.1163, acc-0.4182\n",
      "Iter-23630, train loss-2.1400, acc-0.4600, valid loss-2.1293, acc-0.4092, test loss-2.1162, acc-0.4184\n",
      "Iter-23640, train loss-2.1884, acc-0.3600, valid loss-2.1292, acc-0.4094, test loss-2.1162, acc-0.4190\n",
      "Iter-23650, train loss-2.1090, acc-0.3600, valid loss-2.1292, acc-0.4090, test loss-2.1161, acc-0.4186\n",
      "Iter-23660, train loss-2.0811, acc-0.4800, valid loss-2.1291, acc-0.4092, test loss-2.1160, acc-0.4186\n",
      "Iter-23670, train loss-2.1442, acc-0.3000, valid loss-2.1290, acc-0.4094, test loss-2.1160, acc-0.4186\n",
      "Iter-23680, train loss-2.1253, acc-0.4000, valid loss-2.1290, acc-0.4094, test loss-2.1159, acc-0.4188\n",
      "Iter-23690, train loss-2.1237, acc-0.3800, valid loss-2.1289, acc-0.4094, test loss-2.1158, acc-0.4188\n",
      "Iter-23700, train loss-2.1004, acc-0.4600, valid loss-2.1289, acc-0.4094, test loss-2.1158, acc-0.4188\n",
      "Iter-23710, train loss-2.1096, acc-0.4000, valid loss-2.1288, acc-0.4100, test loss-2.1157, acc-0.4190\n",
      "Iter-23720, train loss-2.0793, acc-0.5600, valid loss-2.1288, acc-0.4098, test loss-2.1157, acc-0.4191\n",
      "Iter-23730, train loss-2.1272, acc-0.3600, valid loss-2.1287, acc-0.4098, test loss-2.1156, acc-0.4191\n",
      "Iter-23740, train loss-2.1062, acc-0.3600, valid loss-2.1286, acc-0.4098, test loss-2.1155, acc-0.4191\n",
      "Iter-23750, train loss-2.1239, acc-0.4600, valid loss-2.1286, acc-0.4096, test loss-2.1155, acc-0.4194\n",
      "Iter-23760, train loss-2.1123, acc-0.4600, valid loss-2.1285, acc-0.4096, test loss-2.1154, acc-0.4196\n",
      "Iter-23770, train loss-2.1253, acc-0.4800, valid loss-2.1285, acc-0.4094, test loss-2.1153, acc-0.4191\n",
      "Iter-23780, train loss-2.1161, acc-0.4200, valid loss-2.1284, acc-0.4096, test loss-2.1153, acc-0.4194\n",
      "Iter-23790, train loss-2.1208, acc-0.4800, valid loss-2.1284, acc-0.4102, test loss-2.1152, acc-0.4194\n",
      "Iter-23800, train loss-2.1444, acc-0.3000, valid loss-2.1283, acc-0.4098, test loss-2.1151, acc-0.4196\n",
      "Iter-23810, train loss-2.1112, acc-0.4600, valid loss-2.1282, acc-0.4100, test loss-2.1151, acc-0.4194\n",
      "Iter-23820, train loss-2.1363, acc-0.3400, valid loss-2.1282, acc-0.4102, test loss-2.1150, acc-0.4191\n",
      "Iter-23830, train loss-2.1022, acc-0.4400, valid loss-2.1281, acc-0.4102, test loss-2.1150, acc-0.4190\n",
      "Iter-23840, train loss-2.0683, acc-0.5200, valid loss-2.1281, acc-0.4102, test loss-2.1149, acc-0.4193\n",
      "Iter-23850, train loss-2.1331, acc-0.4000, valid loss-2.1280, acc-0.4102, test loss-2.1148, acc-0.4194\n",
      "Iter-23860, train loss-2.1162, acc-0.4200, valid loss-2.1279, acc-0.4100, test loss-2.1148, acc-0.4194\n",
      "Iter-23870, train loss-2.1183, acc-0.5000, valid loss-2.1279, acc-0.4102, test loss-2.1147, acc-0.4196\n",
      "Iter-23880, train loss-2.1295, acc-0.4000, valid loss-2.1278, acc-0.4102, test loss-2.1146, acc-0.4196\n",
      "Iter-23890, train loss-2.1209, acc-0.3600, valid loss-2.1278, acc-0.4104, test loss-2.1146, acc-0.4195\n",
      "Iter-23900, train loss-2.0924, acc-0.4400, valid loss-2.1277, acc-0.4104, test loss-2.1145, acc-0.4198\n",
      "Iter-23910, train loss-2.0959, acc-0.3400, valid loss-2.1277, acc-0.4106, test loss-2.1144, acc-0.4198\n",
      "Iter-23920, train loss-2.1230, acc-0.3600, valid loss-2.1276, acc-0.4106, test loss-2.1144, acc-0.4200\n",
      "Iter-23930, train loss-2.1271, acc-0.4400, valid loss-2.1275, acc-0.4104, test loss-2.1143, acc-0.4204\n",
      "Iter-23940, train loss-2.1730, acc-0.3400, valid loss-2.1275, acc-0.4104, test loss-2.1142, acc-0.4202\n",
      "Iter-23950, train loss-2.1098, acc-0.4000, valid loss-2.1274, acc-0.4104, test loss-2.1142, acc-0.4202\n",
      "Iter-23960, train loss-2.1342, acc-0.3200, valid loss-2.1274, acc-0.4104, test loss-2.1141, acc-0.4204\n",
      "Iter-23970, train loss-2.1269, acc-0.4200, valid loss-2.1273, acc-0.4108, test loss-2.1140, acc-0.4204\n",
      "Iter-23980, train loss-2.1208, acc-0.4200, valid loss-2.1272, acc-0.4104, test loss-2.1140, acc-0.4206\n",
      "Iter-23990, train loss-2.1639, acc-0.3200, valid loss-2.1272, acc-0.4106, test loss-2.1139, acc-0.4206\n",
      "Iter-24000, train loss-2.1647, acc-0.3200, valid loss-2.1271, acc-0.4108, test loss-2.1139, acc-0.4207\n",
      "Iter-24010, train loss-2.1292, acc-0.3600, valid loss-2.1271, acc-0.4100, test loss-2.1138, acc-0.4207\n",
      "Iter-24020, train loss-2.1478, acc-0.3600, valid loss-2.1270, acc-0.4106, test loss-2.1137, acc-0.4209\n",
      "Iter-24030, train loss-2.1848, acc-0.2400, valid loss-2.1270, acc-0.4104, test loss-2.1137, acc-0.4210\n",
      "Iter-24040, train loss-2.1404, acc-0.4600, valid loss-2.1269, acc-0.4102, test loss-2.1136, acc-0.4209\n",
      "Iter-24050, train loss-2.1245, acc-0.3600, valid loss-2.1268, acc-0.4108, test loss-2.1135, acc-0.4209\n",
      "Iter-24060, train loss-2.1037, acc-0.4800, valid loss-2.1268, acc-0.4108, test loss-2.1135, acc-0.4208\n",
      "Iter-24070, train loss-2.1483, acc-0.3600, valid loss-2.1267, acc-0.4106, test loss-2.1134, acc-0.4209\n",
      "Iter-24080, train loss-2.1411, acc-0.4600, valid loss-2.1267, acc-0.4108, test loss-2.1133, acc-0.4208\n",
      "Iter-24090, train loss-2.1535, acc-0.3800, valid loss-2.1266, acc-0.4106, test loss-2.1133, acc-0.4210\n",
      "Iter-24100, train loss-2.1028, acc-0.4200, valid loss-2.1266, acc-0.4108, test loss-2.1132, acc-0.4212\n",
      "Iter-24110, train loss-2.1284, acc-0.4400, valid loss-2.1265, acc-0.4106, test loss-2.1132, acc-0.4215\n",
      "Iter-24120, train loss-2.1463, acc-0.3000, valid loss-2.1264, acc-0.4108, test loss-2.1131, acc-0.4212\n",
      "Iter-24130, train loss-2.0923, acc-0.4800, valid loss-2.1264, acc-0.4106, test loss-2.1130, acc-0.4214\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24140, train loss-2.1332, acc-0.4400, valid loss-2.1263, acc-0.4106, test loss-2.1130, acc-0.4214\n",
      "Iter-24150, train loss-2.0765, acc-0.5000, valid loss-2.1263, acc-0.4106, test loss-2.1129, acc-0.4214\n",
      "Iter-24160, train loss-2.1306, acc-0.4000, valid loss-2.1262, acc-0.4106, test loss-2.1128, acc-0.4214\n",
      "Iter-24170, train loss-2.1065, acc-0.4400, valid loss-2.1262, acc-0.4108, test loss-2.1128, acc-0.4214\n",
      "Iter-24180, train loss-2.1046, acc-0.4400, valid loss-2.1261, acc-0.4106, test loss-2.1127, acc-0.4214\n",
      "Iter-24190, train loss-2.1281, acc-0.4400, valid loss-2.1260, acc-0.4106, test loss-2.1126, acc-0.4214\n",
      "Iter-24200, train loss-2.0775, acc-0.4800, valid loss-2.1260, acc-0.4108, test loss-2.1126, acc-0.4215\n",
      "Iter-24210, train loss-2.1398, acc-0.3800, valid loss-2.1259, acc-0.4106, test loss-2.1125, acc-0.4215\n",
      "Iter-24220, train loss-2.1446, acc-0.5000, valid loss-2.1259, acc-0.4108, test loss-2.1125, acc-0.4215\n",
      "Iter-24230, train loss-2.0963, acc-0.4800, valid loss-2.1258, acc-0.4108, test loss-2.1124, acc-0.4215\n",
      "Iter-24240, train loss-2.1457, acc-0.2400, valid loss-2.1257, acc-0.4110, test loss-2.1123, acc-0.4213\n",
      "Iter-24250, train loss-2.1283, acc-0.4600, valid loss-2.1257, acc-0.4108, test loss-2.1123, acc-0.4214\n",
      "Iter-24260, train loss-2.1553, acc-0.3400, valid loss-2.1256, acc-0.4104, test loss-2.1122, acc-0.4215\n",
      "Iter-24270, train loss-2.0806, acc-0.5000, valid loss-2.1256, acc-0.4110, test loss-2.1121, acc-0.4215\n",
      "Iter-24280, train loss-2.0974, acc-0.4200, valid loss-2.1255, acc-0.4106, test loss-2.1121, acc-0.4215\n",
      "Iter-24290, train loss-2.1454, acc-0.3400, valid loss-2.1255, acc-0.4104, test loss-2.1120, acc-0.4214\n",
      "Iter-24300, train loss-2.1158, acc-0.3800, valid loss-2.1254, acc-0.4106, test loss-2.1119, acc-0.4218\n",
      "Iter-24310, train loss-2.1212, acc-0.4600, valid loss-2.1253, acc-0.4106, test loss-2.1119, acc-0.4216\n",
      "Iter-24320, train loss-2.0898, acc-0.5400, valid loss-2.1253, acc-0.4108, test loss-2.1118, acc-0.4214\n",
      "Iter-24330, train loss-2.0702, acc-0.5200, valid loss-2.1252, acc-0.4106, test loss-2.1118, acc-0.4214\n",
      "Iter-24340, train loss-2.1405, acc-0.2800, valid loss-2.1252, acc-0.4106, test loss-2.1117, acc-0.4216\n",
      "Iter-24350, train loss-2.1017, acc-0.4800, valid loss-2.1251, acc-0.4108, test loss-2.1116, acc-0.4213\n",
      "Iter-24360, train loss-2.1210, acc-0.3800, valid loss-2.1250, acc-0.4106, test loss-2.1116, acc-0.4214\n",
      "Iter-24370, train loss-2.1420, acc-0.3600, valid loss-2.1250, acc-0.4108, test loss-2.1115, acc-0.4215\n",
      "Iter-24380, train loss-2.1209, acc-0.3800, valid loss-2.1249, acc-0.4108, test loss-2.1114, acc-0.4213\n",
      "Iter-24390, train loss-2.1581, acc-0.3000, valid loss-2.1249, acc-0.4106, test loss-2.1114, acc-0.4213\n",
      "Iter-24400, train loss-2.1353, acc-0.5000, valid loss-2.1248, acc-0.4112, test loss-2.1113, acc-0.4215\n",
      "Iter-24410, train loss-2.0929, acc-0.5000, valid loss-2.1248, acc-0.4106, test loss-2.1112, acc-0.4214\n",
      "Iter-24420, train loss-2.1332, acc-0.3400, valid loss-2.1247, acc-0.4108, test loss-2.1112, acc-0.4216\n",
      "Iter-24430, train loss-2.1271, acc-0.4000, valid loss-2.1246, acc-0.4106, test loss-2.1111, acc-0.4218\n",
      "Iter-24440, train loss-2.0964, acc-0.4400, valid loss-2.1246, acc-0.4108, test loss-2.1110, acc-0.4217\n",
      "Iter-24450, train loss-2.1265, acc-0.4000, valid loss-2.1245, acc-0.4110, test loss-2.1110, acc-0.4218\n",
      "Iter-24460, train loss-2.0943, acc-0.3800, valid loss-2.1245, acc-0.4116, test loss-2.1109, acc-0.4219\n",
      "Iter-24470, train loss-2.1141, acc-0.4000, valid loss-2.1244, acc-0.4116, test loss-2.1109, acc-0.4221\n",
      "Iter-24480, train loss-2.0986, acc-0.4600, valid loss-2.1243, acc-0.4116, test loss-2.1108, acc-0.4220\n",
      "Iter-24490, train loss-2.0918, acc-0.5000, valid loss-2.1243, acc-0.4116, test loss-2.1107, acc-0.4220\n",
      "Iter-24500, train loss-2.1116, acc-0.5200, valid loss-2.1242, acc-0.4114, test loss-2.1106, acc-0.4220\n",
      "Iter-24510, train loss-2.0535, acc-0.5400, valid loss-2.1242, acc-0.4114, test loss-2.1106, acc-0.4220\n",
      "Iter-24520, train loss-2.0876, acc-0.3800, valid loss-2.1241, acc-0.4114, test loss-2.1105, acc-0.4219\n",
      "Iter-24530, train loss-2.0971, acc-0.4400, valid loss-2.1240, acc-0.4116, test loss-2.1105, acc-0.4218\n",
      "Iter-24540, train loss-2.1550, acc-0.2600, valid loss-2.1240, acc-0.4114, test loss-2.1104, acc-0.4219\n",
      "Iter-24550, train loss-2.1204, acc-0.3600, valid loss-2.1239, acc-0.4116, test loss-2.1103, acc-0.4222\n",
      "Iter-24560, train loss-2.1010, acc-0.4200, valid loss-2.1239, acc-0.4116, test loss-2.1103, acc-0.4221\n",
      "Iter-24570, train loss-2.1299, acc-0.3800, valid loss-2.1238, acc-0.4114, test loss-2.1102, acc-0.4223\n",
      "Iter-24580, train loss-2.0798, acc-0.4800, valid loss-2.1238, acc-0.4116, test loss-2.1101, acc-0.4225\n",
      "Iter-24590, train loss-2.0991, acc-0.4200, valid loss-2.1237, acc-0.4118, test loss-2.1101, acc-0.4226\n",
      "Iter-24600, train loss-2.1396, acc-0.3800, valid loss-2.1236, acc-0.4120, test loss-2.1100, acc-0.4225\n",
      "Iter-24610, train loss-2.1739, acc-0.3600, valid loss-2.1236, acc-0.4118, test loss-2.1100, acc-0.4226\n",
      "Iter-24620, train loss-2.1345, acc-0.3400, valid loss-2.1235, acc-0.4116, test loss-2.1099, acc-0.4223\n",
      "Iter-24630, train loss-2.1079, acc-0.4400, valid loss-2.1235, acc-0.4116, test loss-2.1098, acc-0.4222\n",
      "Iter-24640, train loss-2.0803, acc-0.5600, valid loss-2.1234, acc-0.4120, test loss-2.1098, acc-0.4222\n",
      "Iter-24650, train loss-2.1235, acc-0.3200, valid loss-2.1234, acc-0.4124, test loss-2.1097, acc-0.4224\n",
      "Iter-24660, train loss-2.1240, acc-0.3200, valid loss-2.1233, acc-0.4126, test loss-2.1096, acc-0.4225\n",
      "Iter-24670, train loss-2.0932, acc-0.5600, valid loss-2.1232, acc-0.4126, test loss-2.1096, acc-0.4227\n",
      "Iter-24680, train loss-2.1157, acc-0.3600, valid loss-2.1232, acc-0.4126, test loss-2.1095, acc-0.4227\n",
      "Iter-24690, train loss-2.1189, acc-0.3800, valid loss-2.1231, acc-0.4126, test loss-2.1094, acc-0.4226\n",
      "Iter-24700, train loss-2.0342, acc-0.5200, valid loss-2.1231, acc-0.4128, test loss-2.1094, acc-0.4226\n",
      "Iter-24710, train loss-2.0866, acc-0.5400, valid loss-2.1230, acc-0.4130, test loss-2.1093, acc-0.4227\n",
      "Iter-24720, train loss-2.1074, acc-0.4600, valid loss-2.1229, acc-0.4128, test loss-2.1093, acc-0.4226\n",
      "Iter-24730, train loss-2.0789, acc-0.4600, valid loss-2.1229, acc-0.4124, test loss-2.1092, acc-0.4226\n",
      "Iter-24740, train loss-2.0963, acc-0.4600, valid loss-2.1228, acc-0.4126, test loss-2.1091, acc-0.4228\n",
      "Iter-24750, train loss-2.1101, acc-0.3600, valid loss-2.1228, acc-0.4124, test loss-2.1091, acc-0.4226\n",
      "Iter-24760, train loss-2.1305, acc-0.4200, valid loss-2.1227, acc-0.4122, test loss-2.1090, acc-0.4227\n",
      "Iter-24770, train loss-2.1278, acc-0.4600, valid loss-2.1226, acc-0.4128, test loss-2.1089, acc-0.4226\n",
      "Iter-24780, train loss-2.0980, acc-0.4400, valid loss-2.1226, acc-0.4128, test loss-2.1089, acc-0.4227\n",
      "Iter-24790, train loss-2.1646, acc-0.3400, valid loss-2.1225, acc-0.4132, test loss-2.1088, acc-0.4228\n",
      "Iter-24800, train loss-2.1096, acc-0.4000, valid loss-2.1225, acc-0.4134, test loss-2.1087, acc-0.4227\n",
      "Iter-24810, train loss-2.1373, acc-0.3400, valid loss-2.1224, acc-0.4134, test loss-2.1087, acc-0.4226\n",
      "Iter-24820, train loss-2.1207, acc-0.4400, valid loss-2.1224, acc-0.4134, test loss-2.1086, acc-0.4227\n",
      "Iter-24830, train loss-2.0876, acc-0.3400, valid loss-2.1223, acc-0.4132, test loss-2.1085, acc-0.4226\n",
      "Iter-24840, train loss-2.1052, acc-0.3800, valid loss-2.1222, acc-0.4132, test loss-2.1085, acc-0.4227\n",
      "Iter-24850, train loss-2.1092, acc-0.4000, valid loss-2.1222, acc-0.4136, test loss-2.1084, acc-0.4232\n",
      "Iter-24860, train loss-2.1136, acc-0.4000, valid loss-2.1221, acc-0.4136, test loss-2.1084, acc-0.4236\n",
      "Iter-24870, train loss-2.0920, acc-0.5400, valid loss-2.1221, acc-0.4134, test loss-2.1083, acc-0.4235\n",
      "Iter-24880, train loss-2.0853, acc-0.5400, valid loss-2.1220, acc-0.4134, test loss-2.1082, acc-0.4236\n",
      "Iter-24890, train loss-2.1507, acc-0.3200, valid loss-2.1219, acc-0.4138, test loss-2.1082, acc-0.4236\n",
      "Iter-24900, train loss-2.1145, acc-0.3600, valid loss-2.1219, acc-0.4134, test loss-2.1081, acc-0.4234\n",
      "Iter-24910, train loss-2.1332, acc-0.3400, valid loss-2.1218, acc-0.4134, test loss-2.1080, acc-0.4238\n",
      "Iter-24920, train loss-2.1034, acc-0.4200, valid loss-2.1218, acc-0.4134, test loss-2.1080, acc-0.4238\n",
      "Iter-24930, train loss-2.1022, acc-0.4600, valid loss-2.1217, acc-0.4134, test loss-2.1079, acc-0.4242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24940, train loss-2.1458, acc-0.3400, valid loss-2.1217, acc-0.4138, test loss-2.1079, acc-0.4243\n",
      "Iter-24950, train loss-2.1302, acc-0.3800, valid loss-2.1216, acc-0.4138, test loss-2.1078, acc-0.4243\n",
      "Iter-24960, train loss-2.1575, acc-0.3800, valid loss-2.1216, acc-0.4142, test loss-2.1077, acc-0.4245\n",
      "Iter-24970, train loss-2.1185, acc-0.4400, valid loss-2.1215, acc-0.4140, test loss-2.1077, acc-0.4245\n",
      "Iter-24980, train loss-2.0965, acc-0.4200, valid loss-2.1215, acc-0.4138, test loss-2.1076, acc-0.4244\n",
      "Iter-24990, train loss-2.1192, acc-0.4200, valid loss-2.1214, acc-0.4146, test loss-2.1075, acc-0.4243\n",
      "Iter-25000, train loss-2.1618, acc-0.4000, valid loss-2.1213, acc-0.4144, test loss-2.1075, acc-0.4241\n",
      "Iter-25010, train loss-2.0869, acc-0.3800, valid loss-2.1213, acc-0.4146, test loss-2.1074, acc-0.4243\n",
      "Iter-25020, train loss-2.1640, acc-0.3600, valid loss-2.1212, acc-0.4144, test loss-2.1074, acc-0.4245\n",
      "Iter-25030, train loss-2.1409, acc-0.3600, valid loss-2.1212, acc-0.4146, test loss-2.1073, acc-0.4246\n",
      "Iter-25040, train loss-2.0416, acc-0.5000, valid loss-2.1211, acc-0.4144, test loss-2.1072, acc-0.4247\n",
      "Iter-25050, train loss-2.1071, acc-0.4000, valid loss-2.1211, acc-0.4146, test loss-2.1072, acc-0.4248\n",
      "Iter-25060, train loss-2.1160, acc-0.4000, valid loss-2.1210, acc-0.4150, test loss-2.1071, acc-0.4248\n",
      "Iter-25070, train loss-2.1073, acc-0.4600, valid loss-2.1209, acc-0.4148, test loss-2.1070, acc-0.4247\n",
      "Iter-25080, train loss-2.0719, acc-0.5000, valid loss-2.1209, acc-0.4152, test loss-2.1070, acc-0.4251\n",
      "Iter-25090, train loss-2.1291, acc-0.3600, valid loss-2.1208, acc-0.4148, test loss-2.1069, acc-0.4250\n",
      "Iter-25100, train loss-2.0924, acc-0.4000, valid loss-2.1208, acc-0.4148, test loss-2.1069, acc-0.4251\n",
      "Iter-25110, train loss-2.1022, acc-0.3800, valid loss-2.1207, acc-0.4148, test loss-2.1068, acc-0.4251\n",
      "Iter-25120, train loss-2.1194, acc-0.4400, valid loss-2.1206, acc-0.4146, test loss-2.1067, acc-0.4249\n",
      "Iter-25130, train loss-2.0924, acc-0.4400, valid loss-2.1206, acc-0.4142, test loss-2.1067, acc-0.4250\n",
      "Iter-25140, train loss-2.1512, acc-0.3600, valid loss-2.1205, acc-0.4148, test loss-2.1066, acc-0.4250\n",
      "Iter-25150, train loss-2.1276, acc-0.4000, valid loss-2.1205, acc-0.4144, test loss-2.1065, acc-0.4251\n",
      "Iter-25160, train loss-2.0976, acc-0.4000, valid loss-2.1204, acc-0.4148, test loss-2.1065, acc-0.4253\n",
      "Iter-25170, train loss-2.1128, acc-0.5000, valid loss-2.1204, acc-0.4148, test loss-2.1064, acc-0.4254\n",
      "Iter-25180, train loss-2.1042, acc-0.5000, valid loss-2.1203, acc-0.4146, test loss-2.1064, acc-0.4253\n",
      "Iter-25190, train loss-2.1188, acc-0.4600, valid loss-2.1203, acc-0.4148, test loss-2.1063, acc-0.4255\n",
      "Iter-25200, train loss-2.1127, acc-0.3800, valid loss-2.1202, acc-0.4146, test loss-2.1062, acc-0.4254\n",
      "Iter-25210, train loss-2.1122, acc-0.4600, valid loss-2.1201, acc-0.4148, test loss-2.1062, acc-0.4256\n",
      "Iter-25220, train loss-2.1096, acc-0.3800, valid loss-2.1201, acc-0.4152, test loss-2.1061, acc-0.4253\n",
      "Iter-25230, train loss-2.1509, acc-0.4200, valid loss-2.1200, acc-0.4154, test loss-2.1061, acc-0.4255\n",
      "Iter-25240, train loss-2.1214, acc-0.4200, valid loss-2.1200, acc-0.4158, test loss-2.1060, acc-0.4256\n",
      "Iter-25250, train loss-2.0682, acc-0.4800, valid loss-2.1199, acc-0.4158, test loss-2.1059, acc-0.4260\n",
      "Iter-25260, train loss-2.1722, acc-0.3000, valid loss-2.1198, acc-0.4160, test loss-2.1059, acc-0.4261\n",
      "Iter-25270, train loss-2.1081, acc-0.5000, valid loss-2.1198, acc-0.4160, test loss-2.1058, acc-0.4258\n",
      "Iter-25280, train loss-2.1305, acc-0.4200, valid loss-2.1197, acc-0.4162, test loss-2.1057, acc-0.4256\n",
      "Iter-25290, train loss-2.1548, acc-0.4400, valid loss-2.1197, acc-0.4162, test loss-2.1057, acc-0.4259\n",
      "Iter-25300, train loss-2.0911, acc-0.4400, valid loss-2.1196, acc-0.4160, test loss-2.1056, acc-0.4260\n",
      "Iter-25310, train loss-2.0869, acc-0.4600, valid loss-2.1196, acc-0.4164, test loss-2.1055, acc-0.4258\n",
      "Iter-25320, train loss-2.1378, acc-0.3600, valid loss-2.1195, acc-0.4162, test loss-2.1055, acc-0.4259\n",
      "Iter-25330, train loss-2.1196, acc-0.3800, valid loss-2.1194, acc-0.4162, test loss-2.1054, acc-0.4261\n",
      "Iter-25340, train loss-2.0892, acc-0.3800, valid loss-2.1194, acc-0.4166, test loss-2.1054, acc-0.4262\n",
      "Iter-25350, train loss-2.1300, acc-0.3400, valid loss-2.1193, acc-0.4164, test loss-2.1053, acc-0.4262\n",
      "Iter-25360, train loss-2.1171, acc-0.4400, valid loss-2.1193, acc-0.4164, test loss-2.1052, acc-0.4264\n",
      "Iter-25370, train loss-2.1100, acc-0.4400, valid loss-2.1192, acc-0.4164, test loss-2.1052, acc-0.4262\n",
      "Iter-25380, train loss-2.0828, acc-0.5000, valid loss-2.1192, acc-0.4164, test loss-2.1051, acc-0.4267\n",
      "Iter-25390, train loss-2.1229, acc-0.4000, valid loss-2.1191, acc-0.4168, test loss-2.1051, acc-0.4268\n",
      "Iter-25400, train loss-2.1274, acc-0.3600, valid loss-2.1190, acc-0.4166, test loss-2.1050, acc-0.4267\n",
      "Iter-25410, train loss-2.0547, acc-0.4800, valid loss-2.1190, acc-0.4174, test loss-2.1049, acc-0.4269\n",
      "Iter-25420, train loss-2.1272, acc-0.2800, valid loss-2.1189, acc-0.4172, test loss-2.1049, acc-0.4268\n",
      "Iter-25430, train loss-2.1381, acc-0.3600, valid loss-2.1189, acc-0.4174, test loss-2.1048, acc-0.4269\n",
      "Iter-25440, train loss-2.1118, acc-0.3200, valid loss-2.1188, acc-0.4176, test loss-2.1047, acc-0.4269\n",
      "Iter-25450, train loss-2.1097, acc-0.3800, valid loss-2.1188, acc-0.4178, test loss-2.1047, acc-0.4269\n",
      "Iter-25460, train loss-2.0899, acc-0.4600, valid loss-2.1187, acc-0.4178, test loss-2.1046, acc-0.4271\n",
      "Iter-25470, train loss-2.1416, acc-0.3400, valid loss-2.1187, acc-0.4178, test loss-2.1046, acc-0.4272\n",
      "Iter-25480, train loss-2.0783, acc-0.4800, valid loss-2.1186, acc-0.4176, test loss-2.1045, acc-0.4272\n",
      "Iter-25490, train loss-2.1248, acc-0.3400, valid loss-2.1186, acc-0.4174, test loss-2.1044, acc-0.4273\n",
      "Iter-25500, train loss-2.1056, acc-0.3800, valid loss-2.1185, acc-0.4178, test loss-2.1044, acc-0.4273\n",
      "Iter-25510, train loss-2.0910, acc-0.4600, valid loss-2.1184, acc-0.4178, test loss-2.1043, acc-0.4276\n",
      "Iter-25520, train loss-2.1478, acc-0.3600, valid loss-2.1184, acc-0.4178, test loss-2.1043, acc-0.4273\n",
      "Iter-25530, train loss-2.0695, acc-0.5000, valid loss-2.1183, acc-0.4182, test loss-2.1042, acc-0.4273\n",
      "Iter-25540, train loss-2.1470, acc-0.4800, valid loss-2.1183, acc-0.4180, test loss-2.1041, acc-0.4275\n",
      "Iter-25550, train loss-2.1059, acc-0.5000, valid loss-2.1182, acc-0.4180, test loss-2.1041, acc-0.4277\n",
      "Iter-25560, train loss-2.0500, acc-0.4800, valid loss-2.1182, acc-0.4182, test loss-2.1040, acc-0.4280\n",
      "Iter-25570, train loss-2.0951, acc-0.4200, valid loss-2.1181, acc-0.4180, test loss-2.1039, acc-0.4279\n",
      "Iter-25580, train loss-2.1586, acc-0.3400, valid loss-2.1180, acc-0.4180, test loss-2.1039, acc-0.4281\n",
      "Iter-25590, train loss-2.1434, acc-0.3400, valid loss-2.1180, acc-0.4178, test loss-2.1038, acc-0.4278\n",
      "Iter-25600, train loss-2.1095, acc-0.3000, valid loss-2.1179, acc-0.4176, test loss-2.1038, acc-0.4281\n",
      "Iter-25610, train loss-2.0967, acc-0.4200, valid loss-2.1179, acc-0.4170, test loss-2.1037, acc-0.4282\n",
      "Iter-25620, train loss-2.1053, acc-0.3200, valid loss-2.1178, acc-0.4170, test loss-2.1036, acc-0.4282\n",
      "Iter-25630, train loss-2.0643, acc-0.4400, valid loss-2.1178, acc-0.4176, test loss-2.1036, acc-0.4287\n",
      "Iter-25640, train loss-2.0773, acc-0.4600, valid loss-2.1177, acc-0.4176, test loss-2.1035, acc-0.4285\n",
      "Iter-25650, train loss-2.1325, acc-0.4400, valid loss-2.1177, acc-0.4178, test loss-2.1034, acc-0.4283\n",
      "Iter-25660, train loss-2.0866, acc-0.5000, valid loss-2.1176, acc-0.4180, test loss-2.1034, acc-0.4284\n",
      "Iter-25670, train loss-2.0768, acc-0.4400, valid loss-2.1175, acc-0.4182, test loss-2.1033, acc-0.4287\n",
      "Iter-25680, train loss-2.0972, acc-0.4000, valid loss-2.1175, acc-0.4184, test loss-2.1033, acc-0.4284\n",
      "Iter-25690, train loss-2.1180, acc-0.3800, valid loss-2.1174, acc-0.4180, test loss-2.1032, acc-0.4287\n",
      "Iter-25700, train loss-2.0673, acc-0.4800, valid loss-2.1174, acc-0.4178, test loss-2.1031, acc-0.4288\n",
      "Iter-25710, train loss-2.1244, acc-0.4000, valid loss-2.1173, acc-0.4184, test loss-2.1031, acc-0.4288\n",
      "Iter-25720, train loss-2.1204, acc-0.4400, valid loss-2.1173, acc-0.4184, test loss-2.1030, acc-0.4288\n",
      "Iter-25730, train loss-2.0924, acc-0.3800, valid loss-2.1172, acc-0.4186, test loss-2.1029, acc-0.4289\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-25740, train loss-2.1504, acc-0.4600, valid loss-2.1172, acc-0.4188, test loss-2.1029, acc-0.4292\n",
      "Iter-25750, train loss-2.1180, acc-0.4000, valid loss-2.1171, acc-0.4180, test loss-2.1028, acc-0.4294\n",
      "Iter-25760, train loss-2.1139, acc-0.4800, valid loss-2.1171, acc-0.4186, test loss-2.1028, acc-0.4292\n",
      "Iter-25770, train loss-2.1327, acc-0.3800, valid loss-2.1170, acc-0.4190, test loss-2.1027, acc-0.4294\n",
      "Iter-25780, train loss-2.0839, acc-0.5200, valid loss-2.1169, acc-0.4190, test loss-2.1026, acc-0.4296\n",
      "Iter-25790, train loss-2.1079, acc-0.4000, valid loss-2.1169, acc-0.4190, test loss-2.1026, acc-0.4298\n",
      "Iter-25800, train loss-2.1148, acc-0.3400, valid loss-2.1168, acc-0.4188, test loss-2.1025, acc-0.4295\n",
      "Iter-25810, train loss-2.1276, acc-0.3800, valid loss-2.1168, acc-0.4190, test loss-2.1024, acc-0.4298\n",
      "Iter-25820, train loss-2.1072, acc-0.4200, valid loss-2.1167, acc-0.4188, test loss-2.1024, acc-0.4299\n",
      "Iter-25830, train loss-2.1133, acc-0.4200, valid loss-2.1166, acc-0.4190, test loss-2.1023, acc-0.4297\n",
      "Iter-25840, train loss-2.1449, acc-0.3000, valid loss-2.1166, acc-0.4190, test loss-2.1023, acc-0.4300\n",
      "Iter-25850, train loss-2.1139, acc-0.4000, valid loss-2.1165, acc-0.4190, test loss-2.1022, acc-0.4303\n",
      "Iter-25860, train loss-2.1250, acc-0.3800, valid loss-2.1165, acc-0.4190, test loss-2.1021, acc-0.4302\n",
      "Iter-25870, train loss-2.0958, acc-0.4200, valid loss-2.1164, acc-0.4188, test loss-2.1021, acc-0.4301\n",
      "Iter-25880, train loss-2.1125, acc-0.4200, valid loss-2.1164, acc-0.4190, test loss-2.1020, acc-0.4300\n",
      "Iter-25890, train loss-2.1083, acc-0.4800, valid loss-2.1163, acc-0.4192, test loss-2.1020, acc-0.4309\n",
      "Iter-25900, train loss-2.1197, acc-0.4400, valid loss-2.1163, acc-0.4190, test loss-2.1019, acc-0.4309\n",
      "Iter-25910, train loss-2.1390, acc-0.3200, valid loss-2.1162, acc-0.4192, test loss-2.1018, acc-0.4312\n",
      "Iter-25920, train loss-2.1458, acc-0.4000, valid loss-2.1161, acc-0.4194, test loss-2.1018, acc-0.4313\n",
      "Iter-25930, train loss-2.0648, acc-0.5400, valid loss-2.1161, acc-0.4192, test loss-2.1017, acc-0.4311\n",
      "Iter-25940, train loss-2.1085, acc-0.4000, valid loss-2.1160, acc-0.4198, test loss-2.1016, acc-0.4313\n",
      "Iter-25950, train loss-2.0690, acc-0.5000, valid loss-2.1160, acc-0.4198, test loss-2.1016, acc-0.4311\n",
      "Iter-25960, train loss-2.1376, acc-0.4000, valid loss-2.1159, acc-0.4198, test loss-2.1015, acc-0.4313\n",
      "Iter-25970, train loss-2.1117, acc-0.5000, valid loss-2.1159, acc-0.4200, test loss-2.1015, acc-0.4315\n",
      "Iter-25980, train loss-2.1195, acc-0.4600, valid loss-2.1158, acc-0.4202, test loss-2.1014, acc-0.4314\n",
      "Iter-25990, train loss-2.1215, acc-0.3800, valid loss-2.1158, acc-0.4200, test loss-2.1013, acc-0.4315\n",
      "Iter-26000, train loss-2.0703, acc-0.4600, valid loss-2.1157, acc-0.4200, test loss-2.1013, acc-0.4315\n",
      "Iter-26010, train loss-2.1161, acc-0.4200, valid loss-2.1156, acc-0.4202, test loss-2.1012, acc-0.4315\n",
      "Iter-26020, train loss-2.0893, acc-0.4600, valid loss-2.1156, acc-0.4202, test loss-2.1012, acc-0.4314\n",
      "Iter-26030, train loss-2.1220, acc-0.4400, valid loss-2.1155, acc-0.4206, test loss-2.1011, acc-0.4315\n",
      "Iter-26040, train loss-2.1003, acc-0.3800, valid loss-2.1155, acc-0.4206, test loss-2.1010, acc-0.4313\n",
      "Iter-26050, train loss-2.1251, acc-0.4600, valid loss-2.1154, acc-0.4208, test loss-2.1010, acc-0.4318\n",
      "Iter-26060, train loss-2.1230, acc-0.3400, valid loss-2.1154, acc-0.4208, test loss-2.1009, acc-0.4319\n",
      "Iter-26070, train loss-2.0762, acc-0.3600, valid loss-2.1153, acc-0.4208, test loss-2.1009, acc-0.4319\n",
      "Iter-26080, train loss-2.1092, acc-0.4200, valid loss-2.1153, acc-0.4208, test loss-2.1008, acc-0.4319\n",
      "Iter-26090, train loss-2.1130, acc-0.4600, valid loss-2.1152, acc-0.4206, test loss-2.1007, acc-0.4319\n",
      "Iter-26100, train loss-2.1542, acc-0.3800, valid loss-2.1151, acc-0.4208, test loss-2.1007, acc-0.4319\n",
      "Iter-26110, train loss-2.0899, acc-0.4800, valid loss-2.1151, acc-0.4204, test loss-2.1006, acc-0.4320\n",
      "Iter-26120, train loss-2.0981, acc-0.4400, valid loss-2.1150, acc-0.4204, test loss-2.1005, acc-0.4321\n",
      "Iter-26130, train loss-2.1131, acc-0.3000, valid loss-2.1150, acc-0.4198, test loss-2.1005, acc-0.4318\n",
      "Iter-26140, train loss-2.1189, acc-0.4000, valid loss-2.1149, acc-0.4202, test loss-2.1004, acc-0.4319\n",
      "Iter-26150, train loss-2.1192, acc-0.3800, valid loss-2.1149, acc-0.4202, test loss-2.1004, acc-0.4318\n",
      "Iter-26160, train loss-2.1126, acc-0.4600, valid loss-2.1148, acc-0.4206, test loss-2.1003, acc-0.4320\n",
      "Iter-26170, train loss-2.0963, acc-0.4600, valid loss-2.1148, acc-0.4204, test loss-2.1002, acc-0.4320\n",
      "Iter-26180, train loss-2.1002, acc-0.4200, valid loss-2.1147, acc-0.4204, test loss-2.1002, acc-0.4321\n",
      "Iter-26190, train loss-2.1042, acc-0.4400, valid loss-2.1146, acc-0.4202, test loss-2.1001, acc-0.4320\n",
      "Iter-26200, train loss-2.1003, acc-0.3800, valid loss-2.1146, acc-0.4204, test loss-2.1001, acc-0.4322\n",
      "Iter-26210, train loss-2.0739, acc-0.5400, valid loss-2.1145, acc-0.4208, test loss-2.1000, acc-0.4321\n",
      "Iter-26220, train loss-2.0791, acc-0.4400, valid loss-2.1145, acc-0.4206, test loss-2.0999, acc-0.4321\n",
      "Iter-26230, train loss-2.1249, acc-0.2400, valid loss-2.1144, acc-0.4210, test loss-2.0999, acc-0.4321\n",
      "Iter-26240, train loss-2.0966, acc-0.4000, valid loss-2.1144, acc-0.4206, test loss-2.0998, acc-0.4322\n",
      "Iter-26250, train loss-2.0948, acc-0.4600, valid loss-2.1143, acc-0.4204, test loss-2.0997, acc-0.4322\n",
      "Iter-26260, train loss-2.1167, acc-0.4000, valid loss-2.1142, acc-0.4204, test loss-2.0997, acc-0.4324\n",
      "Iter-26270, train loss-2.0953, acc-0.4400, valid loss-2.1142, acc-0.4202, test loss-2.0996, acc-0.4325\n",
      "Iter-26280, train loss-2.1369, acc-0.3200, valid loss-2.1141, acc-0.4206, test loss-2.0996, acc-0.4325\n",
      "Iter-26290, train loss-2.1254, acc-0.3400, valid loss-2.1141, acc-0.4204, test loss-2.0995, acc-0.4326\n",
      "Iter-26300, train loss-2.0786, acc-0.5600, valid loss-2.1140, acc-0.4204, test loss-2.0994, acc-0.4323\n",
      "Iter-26310, train loss-2.1351, acc-0.3800, valid loss-2.1140, acc-0.4206, test loss-2.0994, acc-0.4323\n",
      "Iter-26320, train loss-2.1712, acc-0.3000, valid loss-2.1139, acc-0.4208, test loss-2.0993, acc-0.4328\n",
      "Iter-26330, train loss-2.1267, acc-0.3200, valid loss-2.1138, acc-0.4208, test loss-2.0992, acc-0.4327\n",
      "Iter-26340, train loss-2.0862, acc-0.4800, valid loss-2.1138, acc-0.4208, test loss-2.0992, acc-0.4328\n",
      "Iter-26350, train loss-2.0784, acc-0.5000, valid loss-2.1137, acc-0.4210, test loss-2.0991, acc-0.4327\n",
      "Iter-26360, train loss-2.0813, acc-0.5000, valid loss-2.1137, acc-0.4212, test loss-2.0990, acc-0.4329\n",
      "Iter-26370, train loss-2.1016, acc-0.3000, valid loss-2.1136, acc-0.4214, test loss-2.0990, acc-0.4334\n",
      "Iter-26380, train loss-2.1156, acc-0.4000, valid loss-2.1136, acc-0.4212, test loss-2.0989, acc-0.4335\n",
      "Iter-26390, train loss-2.0851, acc-0.4200, valid loss-2.1135, acc-0.4214, test loss-2.0989, acc-0.4332\n",
      "Iter-26400, train loss-2.1092, acc-0.4000, valid loss-2.1134, acc-0.4216, test loss-2.0988, acc-0.4330\n",
      "Iter-26410, train loss-2.1199, acc-0.4000, valid loss-2.1134, acc-0.4216, test loss-2.0987, acc-0.4332\n",
      "Iter-26420, train loss-2.1009, acc-0.4800, valid loss-2.1133, acc-0.4216, test loss-2.0987, acc-0.4331\n",
      "Iter-26430, train loss-2.1314, acc-0.3200, valid loss-2.1133, acc-0.4220, test loss-2.0986, acc-0.4333\n",
      "Iter-26440, train loss-2.1118, acc-0.3800, valid loss-2.1132, acc-0.4218, test loss-2.0985, acc-0.4333\n",
      "Iter-26450, train loss-2.1165, acc-0.3800, valid loss-2.1132, acc-0.4218, test loss-2.0985, acc-0.4334\n",
      "Iter-26460, train loss-2.1367, acc-0.3600, valid loss-2.1131, acc-0.4216, test loss-2.0984, acc-0.4335\n",
      "Iter-26470, train loss-2.0725, acc-0.4200, valid loss-2.1130, acc-0.4214, test loss-2.0984, acc-0.4333\n",
      "Iter-26480, train loss-2.0843, acc-0.4400, valid loss-2.1130, acc-0.4210, test loss-2.0983, acc-0.4338\n",
      "Iter-26490, train loss-2.1069, acc-0.4000, valid loss-2.1129, acc-0.4214, test loss-2.0982, acc-0.4339\n",
      "Iter-26500, train loss-2.1154, acc-0.5000, valid loss-2.1129, acc-0.4212, test loss-2.0982, acc-0.4338\n",
      "Iter-26510, train loss-2.0911, acc-0.5400, valid loss-2.1128, acc-0.4210, test loss-2.0981, acc-0.4340\n",
      "Iter-26520, train loss-2.1925, acc-0.2200, valid loss-2.1128, acc-0.4210, test loss-2.0981, acc-0.4340\n",
      "Iter-26530, train loss-2.0731, acc-0.5000, valid loss-2.1127, acc-0.4214, test loss-2.0980, acc-0.4339\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-26540, train loss-2.1050, acc-0.4200, valid loss-2.1127, acc-0.4216, test loss-2.0979, acc-0.4341\n",
      "Iter-26550, train loss-2.0726, acc-0.4200, valid loss-2.1126, acc-0.4218, test loss-2.0979, acc-0.4338\n",
      "Iter-26560, train loss-2.1107, acc-0.4000, valid loss-2.1125, acc-0.4218, test loss-2.0978, acc-0.4338\n",
      "Iter-26570, train loss-2.1389, acc-0.3000, valid loss-2.1125, acc-0.4218, test loss-2.0977, acc-0.4341\n",
      "Iter-26580, train loss-2.0586, acc-0.5400, valid loss-2.1124, acc-0.4218, test loss-2.0977, acc-0.4342\n",
      "Iter-26590, train loss-2.1186, acc-0.3800, valid loss-2.1124, acc-0.4218, test loss-2.0976, acc-0.4342\n",
      "Iter-26600, train loss-2.0533, acc-0.5400, valid loss-2.1123, acc-0.4216, test loss-2.0976, acc-0.4341\n",
      "Iter-26610, train loss-2.1154, acc-0.3800, valid loss-2.1123, acc-0.4218, test loss-2.0975, acc-0.4342\n",
      "Iter-26620, train loss-2.1135, acc-0.3400, valid loss-2.1122, acc-0.4212, test loss-2.0974, acc-0.4342\n",
      "Iter-26630, train loss-2.0854, acc-0.4200, valid loss-2.1121, acc-0.4216, test loss-2.0974, acc-0.4340\n",
      "Iter-26640, train loss-2.0820, acc-0.4000, valid loss-2.1121, acc-0.4220, test loss-2.0973, acc-0.4338\n",
      "Iter-26650, train loss-2.1039, acc-0.4800, valid loss-2.1120, acc-0.4218, test loss-2.0972, acc-0.4338\n",
      "Iter-26660, train loss-2.1130, acc-0.4600, valid loss-2.1120, acc-0.4216, test loss-2.0972, acc-0.4338\n",
      "Iter-26670, train loss-2.0872, acc-0.4000, valid loss-2.1119, acc-0.4216, test loss-2.0971, acc-0.4339\n",
      "Iter-26680, train loss-2.1136, acc-0.4200, valid loss-2.1119, acc-0.4214, test loss-2.0971, acc-0.4341\n",
      "Iter-26690, train loss-2.1170, acc-0.3800, valid loss-2.1118, acc-0.4218, test loss-2.0970, acc-0.4341\n",
      "Iter-26700, train loss-2.1134, acc-0.4200, valid loss-2.1117, acc-0.4214, test loss-2.0969, acc-0.4339\n",
      "Iter-26710, train loss-2.0712, acc-0.5200, valid loss-2.1117, acc-0.4212, test loss-2.0969, acc-0.4340\n",
      "Iter-26720, train loss-2.1266, acc-0.3600, valid loss-2.1116, acc-0.4216, test loss-2.0968, acc-0.4342\n",
      "Iter-26730, train loss-2.1296, acc-0.3400, valid loss-2.1116, acc-0.4216, test loss-2.0968, acc-0.4342\n",
      "Iter-26740, train loss-2.0846, acc-0.4000, valid loss-2.1115, acc-0.4214, test loss-2.0967, acc-0.4344\n",
      "Iter-26750, train loss-2.1386, acc-0.3800, valid loss-2.1115, acc-0.4214, test loss-2.0966, acc-0.4342\n",
      "Iter-26760, train loss-2.0985, acc-0.4800, valid loss-2.1114, acc-0.4216, test loss-2.0966, acc-0.4343\n",
      "Iter-26770, train loss-2.1058, acc-0.3800, valid loss-2.1114, acc-0.4218, test loss-2.0965, acc-0.4351\n",
      "Iter-26780, train loss-2.0847, acc-0.4400, valid loss-2.1113, acc-0.4220, test loss-2.0965, acc-0.4347\n",
      "Iter-26790, train loss-2.1157, acc-0.3400, valid loss-2.1113, acc-0.4220, test loss-2.0964, acc-0.4346\n",
      "Iter-26800, train loss-2.1328, acc-0.3600, valid loss-2.1112, acc-0.4220, test loss-2.0963, acc-0.4347\n",
      "Iter-26810, train loss-2.0685, acc-0.4000, valid loss-2.1112, acc-0.4222, test loss-2.0963, acc-0.4348\n",
      "Iter-26820, train loss-2.1142, acc-0.3800, valid loss-2.1111, acc-0.4226, test loss-2.0962, acc-0.4347\n",
      "Iter-26830, train loss-2.0756, acc-0.4800, valid loss-2.1110, acc-0.4228, test loss-2.0962, acc-0.4345\n",
      "Iter-26840, train loss-2.0404, acc-0.4800, valid loss-2.1110, acc-0.4234, test loss-2.0961, acc-0.4346\n",
      "Iter-26850, train loss-2.0914, acc-0.4400, valid loss-2.1109, acc-0.4230, test loss-2.0960, acc-0.4349\n",
      "Iter-26860, train loss-2.1630, acc-0.3800, valid loss-2.1109, acc-0.4224, test loss-2.0960, acc-0.4351\n",
      "Iter-26870, train loss-2.1143, acc-0.3000, valid loss-2.1108, acc-0.4224, test loss-2.0959, acc-0.4351\n",
      "Iter-26880, train loss-2.1139, acc-0.4200, valid loss-2.1108, acc-0.4222, test loss-2.0958, acc-0.4352\n",
      "Iter-26890, train loss-2.0817, acc-0.3600, valid loss-2.1107, acc-0.4226, test loss-2.0958, acc-0.4352\n",
      "Iter-26900, train loss-2.1171, acc-0.3800, valid loss-2.1106, acc-0.4226, test loss-2.0957, acc-0.4354\n",
      "Iter-26910, train loss-2.1155, acc-0.3800, valid loss-2.1106, acc-0.4228, test loss-2.0957, acc-0.4354\n",
      "Iter-26920, train loss-2.0855, acc-0.4600, valid loss-2.1105, acc-0.4226, test loss-2.0956, acc-0.4357\n",
      "Iter-26930, train loss-2.0914, acc-0.4000, valid loss-2.1105, acc-0.4224, test loss-2.0955, acc-0.4356\n",
      "Iter-26940, train loss-2.1657, acc-0.3000, valid loss-2.1104, acc-0.4228, test loss-2.0955, acc-0.4355\n",
      "Iter-26950, train loss-2.0945, acc-0.3800, valid loss-2.1104, acc-0.4236, test loss-2.0954, acc-0.4356\n",
      "Iter-26960, train loss-2.1653, acc-0.3400, valid loss-2.1103, acc-0.4234, test loss-2.0954, acc-0.4355\n",
      "Iter-26970, train loss-2.1050, acc-0.3800, valid loss-2.1103, acc-0.4232, test loss-2.0953, acc-0.4353\n",
      "Iter-26980, train loss-2.0709, acc-0.5000, valid loss-2.1102, acc-0.4232, test loss-2.0952, acc-0.4354\n",
      "Iter-26990, train loss-2.0893, acc-0.4200, valid loss-2.1102, acc-0.4234, test loss-2.0952, acc-0.4356\n",
      "Iter-27000, train loss-2.0897, acc-0.4200, valid loss-2.1101, acc-0.4228, test loss-2.0951, acc-0.4358\n",
      "Iter-27010, train loss-2.1360, acc-0.3800, valid loss-2.1101, acc-0.4230, test loss-2.0951, acc-0.4355\n",
      "Iter-27020, train loss-2.0752, acc-0.4000, valid loss-2.1100, acc-0.4234, test loss-2.0950, acc-0.4357\n",
      "Iter-27030, train loss-2.1570, acc-0.3800, valid loss-2.1099, acc-0.4236, test loss-2.0949, acc-0.4355\n",
      "Iter-27040, train loss-2.1264, acc-0.4000, valid loss-2.1099, acc-0.4238, test loss-2.0949, acc-0.4358\n",
      "Iter-27050, train loss-2.1106, acc-0.3800, valid loss-2.1098, acc-0.4238, test loss-2.0948, acc-0.4359\n",
      "Iter-27060, train loss-2.1341, acc-0.3600, valid loss-2.1098, acc-0.4240, test loss-2.0947, acc-0.4360\n",
      "Iter-27070, train loss-2.0885, acc-0.4800, valid loss-2.1097, acc-0.4242, test loss-2.0947, acc-0.4361\n",
      "Iter-27080, train loss-2.0736, acc-0.5200, valid loss-2.1096, acc-0.4240, test loss-2.0946, acc-0.4358\n",
      "Iter-27090, train loss-2.1432, acc-0.4000, valid loss-2.1096, acc-0.4238, test loss-2.0946, acc-0.4357\n",
      "Iter-27100, train loss-2.0679, acc-0.5600, valid loss-2.1095, acc-0.4240, test loss-2.0945, acc-0.4358\n",
      "Iter-27110, train loss-2.0951, acc-0.4000, valid loss-2.1095, acc-0.4238, test loss-2.0944, acc-0.4359\n",
      "Iter-27120, train loss-2.1180, acc-0.4400, valid loss-2.1094, acc-0.4240, test loss-2.0944, acc-0.4360\n",
      "Iter-27130, train loss-2.1356, acc-0.2400, valid loss-2.1094, acc-0.4242, test loss-2.0943, acc-0.4361\n",
      "Iter-27140, train loss-2.1077, acc-0.4400, valid loss-2.1093, acc-0.4240, test loss-2.0943, acc-0.4363\n",
      "Iter-27150, train loss-2.1251, acc-0.4400, valid loss-2.1093, acc-0.4240, test loss-2.0942, acc-0.4362\n",
      "Iter-27160, train loss-2.1275, acc-0.4200, valid loss-2.1092, acc-0.4244, test loss-2.0941, acc-0.4361\n",
      "Iter-27170, train loss-2.0828, acc-0.4400, valid loss-2.1092, acc-0.4246, test loss-2.0941, acc-0.4364\n",
      "Iter-27180, train loss-2.0649, acc-0.4400, valid loss-2.1091, acc-0.4250, test loss-2.0940, acc-0.4367\n",
      "Iter-27190, train loss-2.0858, acc-0.5000, valid loss-2.1090, acc-0.4254, test loss-2.0940, acc-0.4371\n",
      "Iter-27200, train loss-2.0980, acc-0.3800, valid loss-2.1090, acc-0.4252, test loss-2.0939, acc-0.4368\n",
      "Iter-27210, train loss-2.0938, acc-0.4000, valid loss-2.1089, acc-0.4254, test loss-2.0938, acc-0.4369\n",
      "Iter-27220, train loss-2.0273, acc-0.5800, valid loss-2.1089, acc-0.4252, test loss-2.0938, acc-0.4367\n",
      "Iter-27230, train loss-2.1369, acc-0.3400, valid loss-2.1088, acc-0.4250, test loss-2.0937, acc-0.4367\n",
      "Iter-27240, train loss-2.1084, acc-0.4400, valid loss-2.1088, acc-0.4252, test loss-2.0937, acc-0.4371\n",
      "Iter-27250, train loss-2.0750, acc-0.5400, valid loss-2.1087, acc-0.4250, test loss-2.0936, acc-0.4371\n",
      "Iter-27260, train loss-2.0794, acc-0.4800, valid loss-2.1087, acc-0.4252, test loss-2.0935, acc-0.4372\n",
      "Iter-27270, train loss-2.0635, acc-0.4600, valid loss-2.1086, acc-0.4256, test loss-2.0935, acc-0.4373\n",
      "Iter-27280, train loss-2.0722, acc-0.5000, valid loss-2.1086, acc-0.4254, test loss-2.0934, acc-0.4373\n",
      "Iter-27290, train loss-2.1060, acc-0.4600, valid loss-2.1085, acc-0.4256, test loss-2.0933, acc-0.4374\n",
      "Iter-27300, train loss-2.1204, acc-0.4000, valid loss-2.1084, acc-0.4252, test loss-2.0933, acc-0.4375\n",
      "Iter-27310, train loss-2.1099, acc-0.3600, valid loss-2.1084, acc-0.4256, test loss-2.0932, acc-0.4375\n",
      "Iter-27320, train loss-2.0895, acc-0.4600, valid loss-2.1083, acc-0.4254, test loss-2.0932, acc-0.4375\n",
      "Iter-27330, train loss-2.0795, acc-0.5400, valid loss-2.1083, acc-0.4258, test loss-2.0931, acc-0.4374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-27340, train loss-2.1079, acc-0.4200, valid loss-2.1082, acc-0.4260, test loss-2.0930, acc-0.4373\n",
      "Iter-27350, train loss-2.1169, acc-0.4200, valid loss-2.1082, acc-0.4260, test loss-2.0930, acc-0.4376\n",
      "Iter-27360, train loss-2.0969, acc-0.3600, valid loss-2.1081, acc-0.4264, test loss-2.0929, acc-0.4377\n",
      "Iter-27370, train loss-2.1263, acc-0.3400, valid loss-2.1081, acc-0.4262, test loss-2.0929, acc-0.4379\n",
      "Iter-27380, train loss-2.0933, acc-0.4400, valid loss-2.1080, acc-0.4264, test loss-2.0928, acc-0.4378\n",
      "Iter-27390, train loss-2.0910, acc-0.4400, valid loss-2.1080, acc-0.4260, test loss-2.0927, acc-0.4379\n",
      "Iter-27400, train loss-2.0526, acc-0.4600, valid loss-2.1079, acc-0.4262, test loss-2.0927, acc-0.4379\n",
      "Iter-27410, train loss-2.1585, acc-0.3200, valid loss-2.1078, acc-0.4262, test loss-2.0926, acc-0.4379\n",
      "Iter-27420, train loss-2.0892, acc-0.4200, valid loss-2.1078, acc-0.4264, test loss-2.0925, acc-0.4380\n",
      "Iter-27430, train loss-2.1416, acc-0.4000, valid loss-2.1077, acc-0.4264, test loss-2.0925, acc-0.4382\n",
      "Iter-27440, train loss-2.1277, acc-0.3600, valid loss-2.1077, acc-0.4266, test loss-2.0924, acc-0.4380\n",
      "Iter-27450, train loss-2.0478, acc-0.5600, valid loss-2.1076, acc-0.4262, test loss-2.0924, acc-0.4384\n",
      "Iter-27460, train loss-2.1023, acc-0.4600, valid loss-2.1076, acc-0.4268, test loss-2.0923, acc-0.4383\n",
      "Iter-27470, train loss-2.0372, acc-0.6200, valid loss-2.1075, acc-0.4268, test loss-2.0923, acc-0.4383\n",
      "Iter-27480, train loss-2.0580, acc-0.4600, valid loss-2.1075, acc-0.4264, test loss-2.0922, acc-0.4380\n",
      "Iter-27490, train loss-2.0967, acc-0.4200, valid loss-2.1074, acc-0.4266, test loss-2.0921, acc-0.4382\n",
      "Iter-27500, train loss-2.1048, acc-0.5600, valid loss-2.1074, acc-0.4268, test loss-2.0921, acc-0.4382\n",
      "Iter-27510, train loss-2.1713, acc-0.3200, valid loss-2.1073, acc-0.4270, test loss-2.0920, acc-0.4384\n",
      "Iter-27520, train loss-2.0652, acc-0.5400, valid loss-2.1072, acc-0.4270, test loss-2.0919, acc-0.4382\n",
      "Iter-27530, train loss-2.0861, acc-0.4200, valid loss-2.1072, acc-0.4272, test loss-2.0919, acc-0.4382\n",
      "Iter-27540, train loss-2.1121, acc-0.4800, valid loss-2.1071, acc-0.4276, test loss-2.0918, acc-0.4382\n",
      "Iter-27550, train loss-2.0473, acc-0.5000, valid loss-2.1071, acc-0.4274, test loss-2.0918, acc-0.4381\n",
      "Iter-27560, train loss-2.1434, acc-0.3600, valid loss-2.1070, acc-0.4278, test loss-2.0917, acc-0.4381\n",
      "Iter-27570, train loss-2.0708, acc-0.5400, valid loss-2.1070, acc-0.4278, test loss-2.0916, acc-0.4383\n",
      "Iter-27580, train loss-2.0735, acc-0.4800, valid loss-2.1069, acc-0.4274, test loss-2.0916, acc-0.4383\n",
      "Iter-27590, train loss-2.0927, acc-0.4800, valid loss-2.1069, acc-0.4274, test loss-2.0915, acc-0.4382\n",
      "Iter-27600, train loss-2.1145, acc-0.4000, valid loss-2.1068, acc-0.4274, test loss-2.0915, acc-0.4382\n",
      "Iter-27610, train loss-2.0587, acc-0.4400, valid loss-2.1068, acc-0.4274, test loss-2.0914, acc-0.4382\n",
      "Iter-27620, train loss-2.1159, acc-0.4200, valid loss-2.1067, acc-0.4276, test loss-2.0913, acc-0.4383\n",
      "Iter-27630, train loss-2.0323, acc-0.5200, valid loss-2.1067, acc-0.4274, test loss-2.0913, acc-0.4381\n",
      "Iter-27640, train loss-2.0954, acc-0.4600, valid loss-2.1066, acc-0.4278, test loss-2.0912, acc-0.4381\n",
      "Iter-27650, train loss-2.0858, acc-0.4000, valid loss-2.1065, acc-0.4278, test loss-2.0912, acc-0.4381\n",
      "Iter-27660, train loss-2.1058, acc-0.3600, valid loss-2.1065, acc-0.4280, test loss-2.0911, acc-0.4384\n",
      "Iter-27670, train loss-2.0976, acc-0.4800, valid loss-2.1064, acc-0.4276, test loss-2.0910, acc-0.4385\n",
      "Iter-27680, train loss-2.1327, acc-0.3200, valid loss-2.1064, acc-0.4278, test loss-2.0910, acc-0.4383\n",
      "Iter-27690, train loss-2.1257, acc-0.3400, valid loss-2.1063, acc-0.4280, test loss-2.0909, acc-0.4385\n",
      "Iter-27700, train loss-2.0766, acc-0.4000, valid loss-2.1063, acc-0.4280, test loss-2.0909, acc-0.4382\n",
      "Iter-27710, train loss-2.1044, acc-0.4200, valid loss-2.1062, acc-0.4282, test loss-2.0908, acc-0.4384\n",
      "Iter-27720, train loss-2.1217, acc-0.3600, valid loss-2.1062, acc-0.4276, test loss-2.0907, acc-0.4384\n",
      "Iter-27730, train loss-2.0765, acc-0.4200, valid loss-2.1061, acc-0.4280, test loss-2.0907, acc-0.4382\n",
      "Iter-27740, train loss-2.1183, acc-0.4400, valid loss-2.1060, acc-0.4278, test loss-2.0906, acc-0.4382\n",
      "Iter-27750, train loss-2.0940, acc-0.5000, valid loss-2.1060, acc-0.4278, test loss-2.0905, acc-0.4384\n",
      "Iter-27760, train loss-2.1387, acc-0.3400, valid loss-2.1059, acc-0.4278, test loss-2.0905, acc-0.4383\n",
      "Iter-27770, train loss-2.0714, acc-0.5600, valid loss-2.1059, acc-0.4280, test loss-2.0904, acc-0.4383\n",
      "Iter-27780, train loss-2.1208, acc-0.3800, valid loss-2.1058, acc-0.4280, test loss-2.0904, acc-0.4385\n",
      "Iter-27790, train loss-2.0476, acc-0.5800, valid loss-2.1058, acc-0.4276, test loss-2.0903, acc-0.4386\n",
      "Iter-27800, train loss-2.0966, acc-0.4400, valid loss-2.1057, acc-0.4276, test loss-2.0902, acc-0.4386\n",
      "Iter-27810, train loss-2.1159, acc-0.3400, valid loss-2.1057, acc-0.4276, test loss-2.0902, acc-0.4386\n",
      "Iter-27820, train loss-2.0951, acc-0.4200, valid loss-2.1056, acc-0.4280, test loss-2.0901, acc-0.4387\n",
      "Iter-27830, train loss-2.0729, acc-0.4800, valid loss-2.1055, acc-0.4278, test loss-2.0901, acc-0.4387\n",
      "Iter-27840, train loss-2.1077, acc-0.3200, valid loss-2.1055, acc-0.4280, test loss-2.0900, acc-0.4386\n",
      "Iter-27850, train loss-2.0936, acc-0.4400, valid loss-2.1054, acc-0.4280, test loss-2.0899, acc-0.4385\n",
      "Iter-27860, train loss-2.1432, acc-0.4400, valid loss-2.1054, acc-0.4284, test loss-2.0899, acc-0.4388\n",
      "Iter-27870, train loss-2.0991, acc-0.3800, valid loss-2.1053, acc-0.4284, test loss-2.0898, acc-0.4386\n",
      "Iter-27880, train loss-2.0351, acc-0.5200, valid loss-2.1053, acc-0.4286, test loss-2.0898, acc-0.4387\n",
      "Iter-27890, train loss-2.1273, acc-0.3600, valid loss-2.1052, acc-0.4288, test loss-2.0897, acc-0.4389\n",
      "Iter-27900, train loss-2.0952, acc-0.2600, valid loss-2.1052, acc-0.4286, test loss-2.0896, acc-0.4389\n",
      "Iter-27910, train loss-1.9933, acc-0.6000, valid loss-2.1051, acc-0.4288, test loss-2.0896, acc-0.4390\n",
      "Iter-27920, train loss-2.1312, acc-0.3400, valid loss-2.1051, acc-0.4288, test loss-2.0895, acc-0.4391\n",
      "Iter-27930, train loss-2.1021, acc-0.4000, valid loss-2.1050, acc-0.4282, test loss-2.0895, acc-0.4390\n",
      "Iter-27940, train loss-2.0275, acc-0.5000, valid loss-2.1049, acc-0.4286, test loss-2.0894, acc-0.4389\n",
      "Iter-27950, train loss-2.1199, acc-0.4200, valid loss-2.1049, acc-0.4288, test loss-2.0893, acc-0.4388\n",
      "Iter-27960, train loss-2.0985, acc-0.5000, valid loss-2.1048, acc-0.4286, test loss-2.0893, acc-0.4389\n",
      "Iter-27970, train loss-2.0647, acc-0.5200, valid loss-2.1048, acc-0.4286, test loss-2.0892, acc-0.4389\n",
      "Iter-27980, train loss-2.0766, acc-0.5400, valid loss-2.1047, acc-0.4288, test loss-2.0892, acc-0.4389\n",
      "Iter-27990, train loss-2.0955, acc-0.3400, valid loss-2.1047, acc-0.4288, test loss-2.0891, acc-0.4391\n",
      "Iter-28000, train loss-2.0779, acc-0.3800, valid loss-2.1046, acc-0.4288, test loss-2.0890, acc-0.4390\n",
      "Iter-28010, train loss-2.0228, acc-0.5600, valid loss-2.1046, acc-0.4286, test loss-2.0890, acc-0.4391\n",
      "Iter-28020, train loss-2.0528, acc-0.4600, valid loss-2.1045, acc-0.4286, test loss-2.0889, acc-0.4391\n",
      "Iter-28030, train loss-2.0971, acc-0.4400, valid loss-2.1045, acc-0.4288, test loss-2.0889, acc-0.4392\n",
      "Iter-28040, train loss-2.0637, acc-0.4400, valid loss-2.1044, acc-0.4288, test loss-2.0888, acc-0.4394\n",
      "Iter-28050, train loss-2.1047, acc-0.4200, valid loss-2.1043, acc-0.4288, test loss-2.0887, acc-0.4393\n",
      "Iter-28060, train loss-2.1172, acc-0.4600, valid loss-2.1043, acc-0.4290, test loss-2.0887, acc-0.4393\n",
      "Iter-28070, train loss-2.0696, acc-0.5000, valid loss-2.1042, acc-0.4288, test loss-2.0886, acc-0.4394\n",
      "Iter-28080, train loss-2.0727, acc-0.5600, valid loss-2.1042, acc-0.4288, test loss-2.0885, acc-0.4395\n",
      "Iter-28090, train loss-2.1044, acc-0.4000, valid loss-2.1041, acc-0.4288, test loss-2.0885, acc-0.4395\n",
      "Iter-28100, train loss-2.0530, acc-0.5400, valid loss-2.1041, acc-0.4288, test loss-2.0884, acc-0.4394\n",
      "Iter-28110, train loss-2.0827, acc-0.5000, valid loss-2.1040, acc-0.4286, test loss-2.0884, acc-0.4395\n",
      "Iter-28120, train loss-2.0929, acc-0.3400, valid loss-2.1040, acc-0.4286, test loss-2.0883, acc-0.4395\n",
      "Iter-28130, train loss-2.0945, acc-0.4800, valid loss-2.1039, acc-0.4286, test loss-2.0882, acc-0.4396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28140, train loss-2.0934, acc-0.4800, valid loss-2.1039, acc-0.4292, test loss-2.0882, acc-0.4397\n",
      "Iter-28150, train loss-2.1170, acc-0.4200, valid loss-2.1038, acc-0.4286, test loss-2.0881, acc-0.4395\n",
      "Iter-28160, train loss-2.0994, acc-0.4200, valid loss-2.1037, acc-0.4290, test loss-2.0881, acc-0.4398\n",
      "Iter-28170, train loss-2.1033, acc-0.4400, valid loss-2.1037, acc-0.4286, test loss-2.0880, acc-0.4400\n",
      "Iter-28180, train loss-2.0752, acc-0.4800, valid loss-2.1036, acc-0.4286, test loss-2.0880, acc-0.4399\n",
      "Iter-28190, train loss-2.0876, acc-0.4000, valid loss-2.1036, acc-0.4288, test loss-2.0879, acc-0.4399\n",
      "Iter-28200, train loss-2.0905, acc-0.5400, valid loss-2.1035, acc-0.4288, test loss-2.0878, acc-0.4399\n",
      "Iter-28210, train loss-2.0214, acc-0.5400, valid loss-2.1035, acc-0.4288, test loss-2.0878, acc-0.4399\n",
      "Iter-28220, train loss-2.0882, acc-0.4600, valid loss-2.1034, acc-0.4292, test loss-2.0877, acc-0.4397\n",
      "Iter-28230, train loss-2.1140, acc-0.3200, valid loss-2.1034, acc-0.4294, test loss-2.0877, acc-0.4399\n",
      "Iter-28240, train loss-2.0706, acc-0.4400, valid loss-2.1033, acc-0.4288, test loss-2.0876, acc-0.4400\n",
      "Iter-28250, train loss-2.1064, acc-0.4600, valid loss-2.1033, acc-0.4290, test loss-2.0875, acc-0.4401\n",
      "Iter-28260, train loss-2.0797, acc-0.3800, valid loss-2.1032, acc-0.4290, test loss-2.0875, acc-0.4402\n",
      "Iter-28270, train loss-2.1146, acc-0.3400, valid loss-2.1031, acc-0.4290, test loss-2.0874, acc-0.4400\n",
      "Iter-28280, train loss-2.0953, acc-0.4400, valid loss-2.1031, acc-0.4292, test loss-2.0874, acc-0.4406\n",
      "Iter-28290, train loss-2.0768, acc-0.4600, valid loss-2.1030, acc-0.4294, test loss-2.0873, acc-0.4406\n",
      "Iter-28300, train loss-2.1183, acc-0.4400, valid loss-2.1030, acc-0.4294, test loss-2.0872, acc-0.4404\n",
      "Iter-28310, train loss-2.0723, acc-0.4600, valid loss-2.1029, acc-0.4298, test loss-2.0872, acc-0.4408\n",
      "Iter-28320, train loss-2.1047, acc-0.3400, valid loss-2.1029, acc-0.4294, test loss-2.0871, acc-0.4407\n",
      "Iter-28330, train loss-2.0958, acc-0.5000, valid loss-2.1028, acc-0.4294, test loss-2.0871, acc-0.4407\n",
      "Iter-28340, train loss-2.0871, acc-0.4000, valid loss-2.1028, acc-0.4296, test loss-2.0870, acc-0.4408\n",
      "Iter-28350, train loss-2.1323, acc-0.3600, valid loss-2.1027, acc-0.4296, test loss-2.0869, acc-0.4409\n",
      "Iter-28360, train loss-2.0659, acc-0.4800, valid loss-2.1027, acc-0.4296, test loss-2.0869, acc-0.4409\n",
      "Iter-28370, train loss-2.1020, acc-0.3800, valid loss-2.1026, acc-0.4296, test loss-2.0868, acc-0.4409\n",
      "Iter-28380, train loss-2.1136, acc-0.3800, valid loss-2.1026, acc-0.4296, test loss-2.0868, acc-0.4409\n",
      "Iter-28390, train loss-2.0233, acc-0.4400, valid loss-2.1025, acc-0.4298, test loss-2.0867, acc-0.4410\n",
      "Iter-28400, train loss-2.0743, acc-0.5600, valid loss-2.1024, acc-0.4298, test loss-2.0866, acc-0.4410\n",
      "Iter-28410, train loss-2.0935, acc-0.4000, valid loss-2.1024, acc-0.4298, test loss-2.0866, acc-0.4408\n",
      "Iter-28420, train loss-2.0488, acc-0.4800, valid loss-2.1023, acc-0.4300, test loss-2.0865, acc-0.4409\n",
      "Iter-28430, train loss-2.0845, acc-0.4400, valid loss-2.1023, acc-0.4298, test loss-2.0865, acc-0.4408\n",
      "Iter-28440, train loss-2.0995, acc-0.3600, valid loss-2.1022, acc-0.4298, test loss-2.0864, acc-0.4407\n",
      "Iter-28450, train loss-2.0762, acc-0.3800, valid loss-2.1022, acc-0.4304, test loss-2.0863, acc-0.4408\n",
      "Iter-28460, train loss-2.1094, acc-0.4800, valid loss-2.1021, acc-0.4298, test loss-2.0863, acc-0.4408\n",
      "Iter-28470, train loss-2.0489, acc-0.4800, valid loss-2.1021, acc-0.4300, test loss-2.0862, acc-0.4409\n",
      "Iter-28480, train loss-2.1416, acc-0.3800, valid loss-2.1020, acc-0.4300, test loss-2.0862, acc-0.4407\n",
      "Iter-28490, train loss-2.1022, acc-0.4000, valid loss-2.1019, acc-0.4302, test loss-2.0861, acc-0.4408\n",
      "Iter-28500, train loss-2.1261, acc-0.3600, valid loss-2.1019, acc-0.4308, test loss-2.0860, acc-0.4408\n",
      "Iter-28510, train loss-2.1062, acc-0.4200, valid loss-2.1018, acc-0.4308, test loss-2.0860, acc-0.4409\n",
      "Iter-28520, train loss-2.0848, acc-0.5400, valid loss-2.1018, acc-0.4308, test loss-2.0859, acc-0.4408\n",
      "Iter-28530, train loss-2.0811, acc-0.3800, valid loss-2.1017, acc-0.4308, test loss-2.0859, acc-0.4408\n",
      "Iter-28540, train loss-2.0660, acc-0.4200, valid loss-2.1017, acc-0.4302, test loss-2.0858, acc-0.4408\n",
      "Iter-28550, train loss-2.0804, acc-0.4200, valid loss-2.1016, acc-0.4304, test loss-2.0857, acc-0.4407\n",
      "Iter-28560, train loss-2.0957, acc-0.4800, valid loss-2.1016, acc-0.4304, test loss-2.0857, acc-0.4413\n",
      "Iter-28570, train loss-2.0925, acc-0.3800, valid loss-2.1015, acc-0.4308, test loss-2.0856, acc-0.4412\n",
      "Iter-28580, train loss-2.1458, acc-0.3200, valid loss-2.1015, acc-0.4308, test loss-2.0856, acc-0.4410\n",
      "Iter-28590, train loss-2.1171, acc-0.4400, valid loss-2.1014, acc-0.4312, test loss-2.0855, acc-0.4414\n",
      "Iter-28600, train loss-2.0436, acc-0.4400, valid loss-2.1014, acc-0.4312, test loss-2.0854, acc-0.4409\n",
      "Iter-28610, train loss-2.0672, acc-0.4600, valid loss-2.1013, acc-0.4310, test loss-2.0854, acc-0.4410\n",
      "Iter-28620, train loss-2.0523, acc-0.5000, valid loss-2.1012, acc-0.4310, test loss-2.0853, acc-0.4409\n",
      "Iter-28630, train loss-2.1290, acc-0.3400, valid loss-2.1012, acc-0.4312, test loss-2.0853, acc-0.4414\n",
      "Iter-28640, train loss-2.0877, acc-0.3800, valid loss-2.1011, acc-0.4314, test loss-2.0852, acc-0.4413\n",
      "Iter-28650, train loss-2.1101, acc-0.4200, valid loss-2.1011, acc-0.4314, test loss-2.0851, acc-0.4414\n",
      "Iter-28660, train loss-2.0957, acc-0.3800, valid loss-2.1010, acc-0.4312, test loss-2.0851, acc-0.4412\n",
      "Iter-28670, train loss-2.1395, acc-0.4600, valid loss-2.1010, acc-0.4312, test loss-2.0850, acc-0.4412\n",
      "Iter-28680, train loss-2.0795, acc-0.4000, valid loss-2.1009, acc-0.4314, test loss-2.0850, acc-0.4413\n",
      "Iter-28690, train loss-2.1264, acc-0.3600, valid loss-2.1009, acc-0.4310, test loss-2.0849, acc-0.4415\n",
      "Iter-28700, train loss-2.1084, acc-0.4000, valid loss-2.1008, acc-0.4312, test loss-2.0848, acc-0.4412\n",
      "Iter-28710, train loss-2.0722, acc-0.4800, valid loss-2.1008, acc-0.4314, test loss-2.0848, acc-0.4413\n",
      "Iter-28720, train loss-2.0710, acc-0.4600, valid loss-2.1007, acc-0.4316, test loss-2.0847, acc-0.4416\n",
      "Iter-28730, train loss-2.0373, acc-0.5400, valid loss-2.1007, acc-0.4320, test loss-2.0847, acc-0.4416\n",
      "Iter-28740, train loss-2.0586, acc-0.5600, valid loss-2.1006, acc-0.4320, test loss-2.0846, acc-0.4416\n",
      "Iter-28750, train loss-2.1270, acc-0.3600, valid loss-2.1005, acc-0.4316, test loss-2.0845, acc-0.4412\n",
      "Iter-28760, train loss-2.1378, acc-0.3400, valid loss-2.1005, acc-0.4318, test loss-2.0845, acc-0.4414\n",
      "Iter-28770, train loss-2.0966, acc-0.4400, valid loss-2.1004, acc-0.4320, test loss-2.0844, acc-0.4415\n",
      "Iter-28780, train loss-2.0392, acc-0.4800, valid loss-2.1004, acc-0.4318, test loss-2.0844, acc-0.4417\n",
      "Iter-28790, train loss-2.1426, acc-0.3200, valid loss-2.1003, acc-0.4318, test loss-2.0843, acc-0.4417\n",
      "Iter-28800, train loss-2.1509, acc-0.3200, valid loss-2.1003, acc-0.4320, test loss-2.0843, acc-0.4415\n",
      "Iter-28810, train loss-2.0843, acc-0.4200, valid loss-2.1002, acc-0.4322, test loss-2.0842, acc-0.4418\n",
      "Iter-28820, train loss-2.0497, acc-0.5200, valid loss-2.1002, acc-0.4322, test loss-2.0841, acc-0.4419\n",
      "Iter-28830, train loss-2.0612, acc-0.4400, valid loss-2.1001, acc-0.4320, test loss-2.0841, acc-0.4420\n",
      "Iter-28840, train loss-2.0575, acc-0.5000, valid loss-2.1001, acc-0.4320, test loss-2.0840, acc-0.4421\n",
      "Iter-28850, train loss-2.0873, acc-0.4800, valid loss-2.1000, acc-0.4318, test loss-2.0840, acc-0.4416\n",
      "Iter-28860, train loss-2.0566, acc-0.4600, valid loss-2.1000, acc-0.4322, test loss-2.0839, acc-0.4417\n",
      "Iter-28870, train loss-2.1030, acc-0.3400, valid loss-2.0999, acc-0.4322, test loss-2.0838, acc-0.4418\n",
      "Iter-28880, train loss-2.0916, acc-0.4400, valid loss-2.0999, acc-0.4322, test loss-2.0838, acc-0.4417\n",
      "Iter-28890, train loss-2.0911, acc-0.4400, valid loss-2.0998, acc-0.4316, test loss-2.0837, acc-0.4417\n",
      "Iter-28900, train loss-2.0675, acc-0.3600, valid loss-2.0997, acc-0.4320, test loss-2.0836, acc-0.4417\n",
      "Iter-28910, train loss-2.1026, acc-0.3800, valid loss-2.0997, acc-0.4322, test loss-2.0836, acc-0.4420\n",
      "Iter-28920, train loss-2.0742, acc-0.4800, valid loss-2.0996, acc-0.4322, test loss-2.0835, acc-0.4420\n",
      "Iter-28930, train loss-2.0728, acc-0.4400, valid loss-2.0996, acc-0.4324, test loss-2.0835, acc-0.4420\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28940, train loss-2.1035, acc-0.4400, valid loss-2.0995, acc-0.4326, test loss-2.0834, acc-0.4422\n",
      "Iter-28950, train loss-2.0910, acc-0.4400, valid loss-2.0995, acc-0.4326, test loss-2.0834, acc-0.4421\n",
      "Iter-28960, train loss-2.0690, acc-0.4800, valid loss-2.0994, acc-0.4326, test loss-2.0833, acc-0.4422\n",
      "Iter-28970, train loss-2.0785, acc-0.5600, valid loss-2.0994, acc-0.4328, test loss-2.0832, acc-0.4422\n",
      "Iter-28980, train loss-2.1061, acc-0.3800, valid loss-2.0993, acc-0.4328, test loss-2.0832, acc-0.4423\n",
      "Iter-28990, train loss-2.0817, acc-0.5200, valid loss-2.0993, acc-0.4328, test loss-2.0831, acc-0.4422\n",
      "Iter-29000, train loss-2.0979, acc-0.4200, valid loss-2.0992, acc-0.4328, test loss-2.0831, acc-0.4424\n",
      "Iter-29010, train loss-2.1092, acc-0.3600, valid loss-2.0991, acc-0.4328, test loss-2.0830, acc-0.4423\n",
      "Iter-29020, train loss-2.0964, acc-0.4800, valid loss-2.0991, acc-0.4330, test loss-2.0829, acc-0.4427\n",
      "Iter-29030, train loss-2.0287, acc-0.5200, valid loss-2.0990, acc-0.4330, test loss-2.0829, acc-0.4427\n",
      "Iter-29040, train loss-2.1233, acc-0.4200, valid loss-2.0990, acc-0.4330, test loss-2.0828, acc-0.4427\n",
      "Iter-29050, train loss-2.0719, acc-0.4400, valid loss-2.0989, acc-0.4330, test loss-2.0827, acc-0.4426\n",
      "Iter-29060, train loss-2.0841, acc-0.4600, valid loss-2.0989, acc-0.4330, test loss-2.0827, acc-0.4426\n",
      "Iter-29070, train loss-2.0525, acc-0.6000, valid loss-2.0988, acc-0.4330, test loss-2.0826, acc-0.4426\n",
      "Iter-29080, train loss-2.0624, acc-0.5200, valid loss-2.0988, acc-0.4330, test loss-2.0826, acc-0.4423\n",
      "Iter-29090, train loss-2.0911, acc-0.3600, valid loss-2.0987, acc-0.4330, test loss-2.0825, acc-0.4421\n",
      "Iter-29100, train loss-2.0886, acc-0.4600, valid loss-2.0987, acc-0.4330, test loss-2.0825, acc-0.4422\n",
      "Iter-29110, train loss-2.0987, acc-0.4400, valid loss-2.0986, acc-0.4326, test loss-2.0824, acc-0.4423\n",
      "Iter-29120, train loss-2.0773, acc-0.4200, valid loss-2.0985, acc-0.4332, test loss-2.0823, acc-0.4423\n",
      "Iter-29130, train loss-2.1057, acc-0.5200, valid loss-2.0985, acc-0.4334, test loss-2.0823, acc-0.4423\n",
      "Iter-29140, train loss-2.0914, acc-0.4400, valid loss-2.0984, acc-0.4330, test loss-2.0822, acc-0.4424\n",
      "Iter-29150, train loss-2.1104, acc-0.4000, valid loss-2.0984, acc-0.4332, test loss-2.0822, acc-0.4425\n",
      "Iter-29160, train loss-2.1144, acc-0.3800, valid loss-2.0983, acc-0.4332, test loss-2.0821, acc-0.4428\n",
      "Iter-29170, train loss-2.0883, acc-0.5000, valid loss-2.0983, acc-0.4330, test loss-2.0820, acc-0.4427\n",
      "Iter-29180, train loss-2.0512, acc-0.4800, valid loss-2.0982, acc-0.4330, test loss-2.0820, acc-0.4427\n",
      "Iter-29190, train loss-2.1113, acc-0.4000, valid loss-2.0982, acc-0.4326, test loss-2.0819, acc-0.4425\n",
      "Iter-29200, train loss-2.0871, acc-0.4400, valid loss-2.0981, acc-0.4326, test loss-2.0819, acc-0.4427\n",
      "Iter-29210, train loss-2.1028, acc-0.4600, valid loss-2.0981, acc-0.4324, test loss-2.0818, acc-0.4427\n",
      "Iter-29220, train loss-2.0543, acc-0.4400, valid loss-2.0980, acc-0.4326, test loss-2.0817, acc-0.4424\n",
      "Iter-29230, train loss-2.1301, acc-0.3200, valid loss-2.0979, acc-0.4326, test loss-2.0817, acc-0.4424\n",
      "Iter-29240, train loss-2.1221, acc-0.2800, valid loss-2.0979, acc-0.4330, test loss-2.0816, acc-0.4424\n",
      "Iter-29250, train loss-2.0330, acc-0.5200, valid loss-2.0978, acc-0.4328, test loss-2.0816, acc-0.4423\n",
      "Iter-29260, train loss-2.0999, acc-0.4400, valid loss-2.0978, acc-0.4328, test loss-2.0815, acc-0.4423\n",
      "Iter-29270, train loss-2.0910, acc-0.5400, valid loss-2.0977, acc-0.4328, test loss-2.0814, acc-0.4424\n",
      "Iter-29280, train loss-2.0432, acc-0.5200, valid loss-2.0977, acc-0.4330, test loss-2.0814, acc-0.4424\n",
      "Iter-29290, train loss-2.1309, acc-0.3600, valid loss-2.0976, acc-0.4330, test loss-2.0813, acc-0.4423\n",
      "Iter-29300, train loss-2.0638, acc-0.3800, valid loss-2.0976, acc-0.4332, test loss-2.0812, acc-0.4425\n",
      "Iter-29310, train loss-2.0831, acc-0.4200, valid loss-2.0975, acc-0.4332, test loss-2.0812, acc-0.4426\n",
      "Iter-29320, train loss-2.0943, acc-0.4000, valid loss-2.0975, acc-0.4332, test loss-2.0811, acc-0.4425\n",
      "Iter-29330, train loss-2.0596, acc-0.4200, valid loss-2.0974, acc-0.4334, test loss-2.0811, acc-0.4425\n",
      "Iter-29340, train loss-2.0504, acc-0.5400, valid loss-2.0974, acc-0.4338, test loss-2.0810, acc-0.4426\n",
      "Iter-29350, train loss-2.0930, acc-0.5000, valid loss-2.0973, acc-0.4336, test loss-2.0810, acc-0.4426\n",
      "Iter-29360, train loss-2.1760, acc-0.3600, valid loss-2.0973, acc-0.4338, test loss-2.0809, acc-0.4425\n",
      "Iter-29370, train loss-2.1229, acc-0.4200, valid loss-2.0972, acc-0.4332, test loss-2.0808, acc-0.4423\n",
      "Iter-29380, train loss-2.0282, acc-0.5000, valid loss-2.0971, acc-0.4334, test loss-2.0808, acc-0.4422\n",
      "Iter-29390, train loss-2.0369, acc-0.5000, valid loss-2.0971, acc-0.4338, test loss-2.0807, acc-0.4425\n",
      "Iter-29400, train loss-2.0688, acc-0.4200, valid loss-2.0970, acc-0.4340, test loss-2.0807, acc-0.4425\n",
      "Iter-29410, train loss-2.1005, acc-0.2800, valid loss-2.0970, acc-0.4340, test loss-2.0806, acc-0.4426\n",
      "Iter-29420, train loss-2.0593, acc-0.4600, valid loss-2.0969, acc-0.4336, test loss-2.0805, acc-0.4424\n",
      "Iter-29430, train loss-2.0836, acc-0.4400, valid loss-2.0969, acc-0.4336, test loss-2.0805, acc-0.4426\n",
      "Iter-29440, train loss-2.0953, acc-0.5400, valid loss-2.0968, acc-0.4336, test loss-2.0804, acc-0.4425\n",
      "Iter-29450, train loss-2.1521, acc-0.4400, valid loss-2.0968, acc-0.4336, test loss-2.0804, acc-0.4427\n",
      "Iter-29460, train loss-2.1664, acc-0.3000, valid loss-2.0967, acc-0.4336, test loss-2.0803, acc-0.4429\n",
      "Iter-29470, train loss-2.0873, acc-0.5200, valid loss-2.0967, acc-0.4334, test loss-2.0802, acc-0.4428\n",
      "Iter-29480, train loss-2.0933, acc-0.4800, valid loss-2.0966, acc-0.4338, test loss-2.0802, acc-0.4428\n",
      "Iter-29490, train loss-2.0912, acc-0.4200, valid loss-2.0966, acc-0.4336, test loss-2.0801, acc-0.4428\n",
      "Iter-29500, train loss-2.0799, acc-0.4200, valid loss-2.0965, acc-0.4340, test loss-2.0801, acc-0.4429\n",
      "Iter-29510, train loss-2.0775, acc-0.5000, valid loss-2.0965, acc-0.4338, test loss-2.0800, acc-0.4428\n",
      "Iter-29520, train loss-2.1022, acc-0.4200, valid loss-2.0964, acc-0.4338, test loss-2.0799, acc-0.4429\n",
      "Iter-29530, train loss-2.0882, acc-0.4600, valid loss-2.0964, acc-0.4338, test loss-2.0799, acc-0.4429\n",
      "Iter-29540, train loss-2.1105, acc-0.4600, valid loss-2.0963, acc-0.4340, test loss-2.0798, acc-0.4429\n",
      "Iter-29550, train loss-2.1150, acc-0.3600, valid loss-2.0963, acc-0.4344, test loss-2.0798, acc-0.4429\n",
      "Iter-29560, train loss-2.0244, acc-0.5800, valid loss-2.0962, acc-0.4342, test loss-2.0797, acc-0.4430\n",
      "Iter-29570, train loss-2.0943, acc-0.4200, valid loss-2.0961, acc-0.4342, test loss-2.0797, acc-0.4428\n",
      "Iter-29580, train loss-2.0987, acc-0.4400, valid loss-2.0961, acc-0.4342, test loss-2.0796, acc-0.4426\n",
      "Iter-29590, train loss-2.1203, acc-0.2800, valid loss-2.0960, acc-0.4340, test loss-2.0795, acc-0.4425\n",
      "Iter-29600, train loss-2.0763, acc-0.4400, valid loss-2.0960, acc-0.4340, test loss-2.0795, acc-0.4425\n",
      "Iter-29610, train loss-2.0914, acc-0.3800, valid loss-2.0959, acc-0.4342, test loss-2.0794, acc-0.4423\n",
      "Iter-29620, train loss-2.0918, acc-0.3400, valid loss-2.0959, acc-0.4346, test loss-2.0794, acc-0.4427\n",
      "Iter-29630, train loss-2.1091, acc-0.4600, valid loss-2.0958, acc-0.4342, test loss-2.0793, acc-0.4427\n",
      "Iter-29640, train loss-2.1117, acc-0.4000, valid loss-2.0958, acc-0.4344, test loss-2.0792, acc-0.4427\n",
      "Iter-29650, train loss-2.0781, acc-0.4400, valid loss-2.0957, acc-0.4344, test loss-2.0792, acc-0.4433\n",
      "Iter-29660, train loss-2.1268, acc-0.5000, valid loss-2.0957, acc-0.4342, test loss-2.0791, acc-0.4431\n",
      "Iter-29670, train loss-2.1079, acc-0.4400, valid loss-2.0956, acc-0.4336, test loss-2.0791, acc-0.4432\n",
      "Iter-29680, train loss-2.0601, acc-0.4600, valid loss-2.0956, acc-0.4336, test loss-2.0790, acc-0.4432\n",
      "Iter-29690, train loss-2.1054, acc-0.4200, valid loss-2.0955, acc-0.4340, test loss-2.0790, acc-0.4433\n",
      "Iter-29700, train loss-2.0739, acc-0.4800, valid loss-2.0955, acc-0.4340, test loss-2.0789, acc-0.4434\n",
      "Iter-29710, train loss-2.0858, acc-0.4400, valid loss-2.0954, acc-0.4342, test loss-2.0789, acc-0.4434\n",
      "Iter-29720, train loss-2.0500, acc-0.4600, valid loss-2.0954, acc-0.4338, test loss-2.0788, acc-0.4432\n",
      "Iter-29730, train loss-2.0800, acc-0.4400, valid loss-2.0953, acc-0.4346, test loss-2.0787, acc-0.4434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-29740, train loss-2.0775, acc-0.4400, valid loss-2.0953, acc-0.4340, test loss-2.0787, acc-0.4435\n",
      "Iter-29750, train loss-2.0972, acc-0.5000, valid loss-2.0952, acc-0.4344, test loss-2.0786, acc-0.4434\n",
      "Iter-29760, train loss-2.0990, acc-0.4400, valid loss-2.0951, acc-0.4344, test loss-2.0786, acc-0.4434\n",
      "Iter-29770, train loss-2.1076, acc-0.4800, valid loss-2.0951, acc-0.4348, test loss-2.0785, acc-0.4437\n",
      "Iter-29780, train loss-2.0704, acc-0.5000, valid loss-2.0950, acc-0.4346, test loss-2.0784, acc-0.4435\n",
      "Iter-29790, train loss-2.0472, acc-0.4200, valid loss-2.0950, acc-0.4342, test loss-2.0784, acc-0.4434\n",
      "Iter-29800, train loss-2.0579, acc-0.4000, valid loss-2.0949, acc-0.4342, test loss-2.0783, acc-0.4435\n",
      "Iter-29810, train loss-2.1135, acc-0.4000, valid loss-2.0949, acc-0.4342, test loss-2.0783, acc-0.4433\n",
      "Iter-29820, train loss-2.1747, acc-0.2600, valid loss-2.0948, acc-0.4344, test loss-2.0782, acc-0.4434\n",
      "Iter-29830, train loss-2.0784, acc-0.4600, valid loss-2.0948, acc-0.4344, test loss-2.0781, acc-0.4431\n",
      "Iter-29840, train loss-2.0731, acc-0.4400, valid loss-2.0947, acc-0.4344, test loss-2.0781, acc-0.4431\n",
      "Iter-29850, train loss-2.0643, acc-0.4600, valid loss-2.0946, acc-0.4346, test loss-2.0780, acc-0.4432\n",
      "Iter-29860, train loss-2.0314, acc-0.5600, valid loss-2.0946, acc-0.4348, test loss-2.0780, acc-0.4433\n",
      "Iter-29870, train loss-2.1296, acc-0.4000, valid loss-2.0945, acc-0.4348, test loss-2.0779, acc-0.4432\n",
      "Iter-29880, train loss-2.0734, acc-0.4400, valid loss-2.0945, acc-0.4350, test loss-2.0778, acc-0.4433\n",
      "Iter-29890, train loss-2.1393, acc-0.3600, valid loss-2.0944, acc-0.4352, test loss-2.0778, acc-0.4434\n",
      "Iter-29900, train loss-2.0744, acc-0.4800, valid loss-2.0944, acc-0.4346, test loss-2.0777, acc-0.4433\n",
      "Iter-29910, train loss-2.1124, acc-0.4000, valid loss-2.0943, acc-0.4350, test loss-2.0777, acc-0.4435\n",
      "Iter-29920, train loss-2.0703, acc-0.4600, valid loss-2.0943, acc-0.4348, test loss-2.0776, acc-0.4435\n",
      "Iter-29930, train loss-2.0472, acc-0.4600, valid loss-2.0942, acc-0.4352, test loss-2.0776, acc-0.4435\n",
      "Iter-29940, train loss-2.0725, acc-0.4800, valid loss-2.0942, acc-0.4352, test loss-2.0775, acc-0.4434\n",
      "Iter-29950, train loss-2.1150, acc-0.4200, valid loss-2.0941, acc-0.4352, test loss-2.0774, acc-0.4434\n",
      "Iter-29960, train loss-2.0902, acc-0.4400, valid loss-2.0941, acc-0.4354, test loss-2.0774, acc-0.4432\n",
      "Iter-29970, train loss-2.0973, acc-0.4200, valid loss-2.0940, acc-0.4350, test loss-2.0773, acc-0.4436\n",
      "Iter-29980, train loss-2.1078, acc-0.4200, valid loss-2.0940, acc-0.4352, test loss-2.0773, acc-0.4435\n",
      "Iter-29990, train loss-2.0759, acc-0.5000, valid loss-2.0939, acc-0.4356, test loss-2.0772, acc-0.4437\n",
      "Iter-30000, train loss-2.0815, acc-0.4600, valid loss-2.0939, acc-0.4356, test loss-2.0771, acc-0.4437\n",
      "Iter-30010, train loss-2.0750, acc-0.4200, valid loss-2.0938, acc-0.4358, test loss-2.0771, acc-0.4440\n",
      "Iter-30020, train loss-2.1114, acc-0.3200, valid loss-2.0938, acc-0.4358, test loss-2.0770, acc-0.4437\n",
      "Iter-30030, train loss-2.1512, acc-0.3600, valid loss-2.0937, acc-0.4358, test loss-2.0770, acc-0.4439\n",
      "Iter-30040, train loss-2.0407, acc-0.5000, valid loss-2.0936, acc-0.4358, test loss-2.0769, acc-0.4441\n",
      "Iter-30050, train loss-2.1406, acc-0.3800, valid loss-2.0936, acc-0.4360, test loss-2.0768, acc-0.4441\n",
      "Iter-30060, train loss-2.0703, acc-0.4800, valid loss-2.0935, acc-0.4358, test loss-2.0768, acc-0.4444\n",
      "Iter-30070, train loss-2.0526, acc-0.5200, valid loss-2.0935, acc-0.4356, test loss-2.0767, acc-0.4443\n",
      "Iter-30080, train loss-2.0617, acc-0.5400, valid loss-2.0934, acc-0.4354, test loss-2.0767, acc-0.4442\n",
      "Iter-30090, train loss-2.0791, acc-0.5200, valid loss-2.0934, acc-0.4354, test loss-2.0766, acc-0.4441\n",
      "Iter-30100, train loss-2.0456, acc-0.4200, valid loss-2.0933, acc-0.4354, test loss-2.0765, acc-0.4442\n",
      "Iter-30110, train loss-2.0403, acc-0.5000, valid loss-2.0933, acc-0.4354, test loss-2.0765, acc-0.4440\n",
      "Iter-30120, train loss-2.1470, acc-0.3200, valid loss-2.0932, acc-0.4356, test loss-2.0764, acc-0.4442\n",
      "Iter-30130, train loss-2.0713, acc-0.4600, valid loss-2.0932, acc-0.4352, test loss-2.0764, acc-0.4442\n",
      "Iter-30140, train loss-2.1023, acc-0.3800, valid loss-2.0931, acc-0.4354, test loss-2.0763, acc-0.4443\n",
      "Iter-30150, train loss-2.0609, acc-0.3800, valid loss-2.0930, acc-0.4354, test loss-2.0762, acc-0.4443\n",
      "Iter-30160, train loss-2.0293, acc-0.4400, valid loss-2.0930, acc-0.4352, test loss-2.0762, acc-0.4445\n",
      "Iter-30170, train loss-2.1013, acc-0.4400, valid loss-2.0929, acc-0.4354, test loss-2.0761, acc-0.4446\n",
      "Iter-30180, train loss-2.0644, acc-0.4600, valid loss-2.0929, acc-0.4350, test loss-2.0761, acc-0.4445\n",
      "Iter-30190, train loss-2.0477, acc-0.5000, valid loss-2.0928, acc-0.4348, test loss-2.0760, acc-0.4446\n",
      "Iter-30200, train loss-2.1231, acc-0.3800, valid loss-2.0928, acc-0.4352, test loss-2.0760, acc-0.4445\n",
      "Iter-30210, train loss-2.1406, acc-0.4000, valid loss-2.0927, acc-0.4348, test loss-2.0759, acc-0.4445\n",
      "Iter-30220, train loss-2.1159, acc-0.3200, valid loss-2.0927, acc-0.4350, test loss-2.0758, acc-0.4443\n",
      "Iter-30230, train loss-2.0639, acc-0.5000, valid loss-2.0926, acc-0.4352, test loss-2.0758, acc-0.4444\n",
      "Iter-30240, train loss-2.0392, acc-0.5200, valid loss-2.0926, acc-0.4352, test loss-2.0757, acc-0.4443\n",
      "Iter-30250, train loss-2.0951, acc-0.4800, valid loss-2.0925, acc-0.4348, test loss-2.0756, acc-0.4447\n",
      "Iter-30260, train loss-2.0485, acc-0.5800, valid loss-2.0924, acc-0.4348, test loss-2.0756, acc-0.4446\n",
      "Iter-30270, train loss-2.0746, acc-0.4200, valid loss-2.0924, acc-0.4350, test loss-2.0755, acc-0.4446\n",
      "Iter-30280, train loss-2.0723, acc-0.4200, valid loss-2.0923, acc-0.4350, test loss-2.0755, acc-0.4448\n",
      "Iter-30290, train loss-2.1625, acc-0.2600, valid loss-2.0923, acc-0.4354, test loss-2.0754, acc-0.4448\n",
      "Iter-30300, train loss-2.1023, acc-0.4600, valid loss-2.0922, acc-0.4352, test loss-2.0754, acc-0.4448\n",
      "Iter-30310, train loss-2.0757, acc-0.4000, valid loss-2.0922, acc-0.4356, test loss-2.0753, acc-0.4446\n",
      "Iter-30320, train loss-2.1052, acc-0.4200, valid loss-2.0921, acc-0.4354, test loss-2.0752, acc-0.4449\n",
      "Iter-30330, train loss-2.0564, acc-0.5000, valid loss-2.0921, acc-0.4350, test loss-2.0752, acc-0.4448\n",
      "Iter-30340, train loss-2.0574, acc-0.4600, valid loss-2.0920, acc-0.4358, test loss-2.0751, acc-0.4448\n",
      "Iter-30350, train loss-2.0749, acc-0.5000, valid loss-2.0920, acc-0.4356, test loss-2.0751, acc-0.4449\n",
      "Iter-30360, train loss-2.0902, acc-0.3600, valid loss-2.0919, acc-0.4356, test loss-2.0750, acc-0.4449\n",
      "Iter-30370, train loss-2.0804, acc-0.4600, valid loss-2.0919, acc-0.4356, test loss-2.0749, acc-0.4450\n",
      "Iter-30380, train loss-2.0198, acc-0.4800, valid loss-2.0918, acc-0.4354, test loss-2.0749, acc-0.4450\n",
      "Iter-30390, train loss-2.0606, acc-0.5000, valid loss-2.0918, acc-0.4356, test loss-2.0748, acc-0.4451\n",
      "Iter-30400, train loss-2.1087, acc-0.3800, valid loss-2.0917, acc-0.4356, test loss-2.0748, acc-0.4452\n",
      "Iter-30410, train loss-2.0469, acc-0.4400, valid loss-2.0917, acc-0.4356, test loss-2.0747, acc-0.4450\n",
      "Iter-30420, train loss-2.0645, acc-0.5000, valid loss-2.0916, acc-0.4356, test loss-2.0747, acc-0.4454\n",
      "Iter-30430, train loss-2.1190, acc-0.3000, valid loss-2.0915, acc-0.4358, test loss-2.0746, acc-0.4453\n",
      "Iter-30440, train loss-2.1120, acc-0.4800, valid loss-2.0915, acc-0.4358, test loss-2.0745, acc-0.4452\n",
      "Iter-30450, train loss-2.0538, acc-0.5000, valid loss-2.0914, acc-0.4356, test loss-2.0745, acc-0.4453\n",
      "Iter-30460, train loss-2.1332, acc-0.4000, valid loss-2.0914, acc-0.4354, test loss-2.0744, acc-0.4454\n",
      "Iter-30470, train loss-2.1246, acc-0.3000, valid loss-2.0913, acc-0.4352, test loss-2.0744, acc-0.4452\n",
      "Iter-30480, train loss-2.0524, acc-0.4600, valid loss-2.0913, acc-0.4358, test loss-2.0743, acc-0.4451\n",
      "Iter-30490, train loss-2.1451, acc-0.2800, valid loss-2.0912, acc-0.4360, test loss-2.0743, acc-0.4452\n",
      "Iter-30500, train loss-2.0933, acc-0.4600, valid loss-2.0912, acc-0.4362, test loss-2.0742, acc-0.4452\n",
      "Iter-30510, train loss-2.0984, acc-0.4400, valid loss-2.0911, acc-0.4366, test loss-2.0741, acc-0.4454\n",
      "Iter-30520, train loss-2.0971, acc-0.4800, valid loss-2.0911, acc-0.4366, test loss-2.0741, acc-0.4453\n",
      "Iter-30530, train loss-2.0533, acc-0.4800, valid loss-2.0910, acc-0.4366, test loss-2.0740, acc-0.4453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-30540, train loss-2.0731, acc-0.3800, valid loss-2.0910, acc-0.4368, test loss-2.0740, acc-0.4455\n",
      "Iter-30550, train loss-2.1733, acc-0.3600, valid loss-2.0909, acc-0.4370, test loss-2.0739, acc-0.4454\n",
      "Iter-30560, train loss-2.0720, acc-0.4200, valid loss-2.0909, acc-0.4368, test loss-2.0739, acc-0.4455\n",
      "Iter-30570, train loss-2.0653, acc-0.4200, valid loss-2.0908, acc-0.4366, test loss-2.0738, acc-0.4453\n",
      "Iter-30580, train loss-2.0688, acc-0.4400, valid loss-2.0907, acc-0.4366, test loss-2.0737, acc-0.4453\n",
      "Iter-30590, train loss-2.0776, acc-0.5200, valid loss-2.0907, acc-0.4372, test loss-2.0737, acc-0.4452\n",
      "Iter-30600, train loss-2.0975, acc-0.4400, valid loss-2.0906, acc-0.4368, test loss-2.0736, acc-0.4453\n",
      "Iter-30610, train loss-2.0583, acc-0.4800, valid loss-2.0906, acc-0.4366, test loss-2.0736, acc-0.4452\n",
      "Iter-30620, train loss-2.0309, acc-0.5200, valid loss-2.0905, acc-0.4364, test loss-2.0735, acc-0.4452\n",
      "Iter-30630, train loss-2.0885, acc-0.4800, valid loss-2.0905, acc-0.4360, test loss-2.0735, acc-0.4451\n",
      "Iter-30640, train loss-2.1289, acc-0.3800, valid loss-2.0904, acc-0.4368, test loss-2.0734, acc-0.4452\n",
      "Iter-30650, train loss-2.0697, acc-0.4000, valid loss-2.0904, acc-0.4370, test loss-2.0733, acc-0.4451\n",
      "Iter-30660, train loss-2.0761, acc-0.3400, valid loss-2.0903, acc-0.4364, test loss-2.0733, acc-0.4450\n",
      "Iter-30670, train loss-2.1151, acc-0.3800, valid loss-2.0903, acc-0.4364, test loss-2.0732, acc-0.4450\n",
      "Iter-30680, train loss-2.0975, acc-0.5200, valid loss-2.0902, acc-0.4364, test loss-2.0732, acc-0.4449\n",
      "Iter-30690, train loss-2.1276, acc-0.3800, valid loss-2.0902, acc-0.4362, test loss-2.0731, acc-0.4451\n",
      "Iter-30700, train loss-2.0279, acc-0.5800, valid loss-2.0901, acc-0.4370, test loss-2.0731, acc-0.4453\n",
      "Iter-30710, train loss-2.1263, acc-0.4000, valid loss-2.0901, acc-0.4368, test loss-2.0730, acc-0.4453\n",
      "Iter-30720, train loss-2.0474, acc-0.5400, valid loss-2.0900, acc-0.4372, test loss-2.0729, acc-0.4456\n",
      "Iter-30730, train loss-2.0381, acc-0.4200, valid loss-2.0900, acc-0.4372, test loss-2.0729, acc-0.4457\n",
      "Iter-30740, train loss-2.0545, acc-0.5200, valid loss-2.0899, acc-0.4374, test loss-2.0728, acc-0.4457\n",
      "Iter-30750, train loss-2.0518, acc-0.5000, valid loss-2.0899, acc-0.4372, test loss-2.0728, acc-0.4457\n",
      "Iter-30760, train loss-2.0817, acc-0.4400, valid loss-2.0898, acc-0.4372, test loss-2.0727, acc-0.4460\n",
      "Iter-30770, train loss-2.0308, acc-0.5400, valid loss-2.0898, acc-0.4372, test loss-2.0726, acc-0.4458\n",
      "Iter-30780, train loss-2.0949, acc-0.4400, valid loss-2.0897, acc-0.4370, test loss-2.0726, acc-0.4460\n",
      "Iter-30790, train loss-2.1060, acc-0.4600, valid loss-2.0896, acc-0.4366, test loss-2.0725, acc-0.4460\n",
      "Iter-30800, train loss-2.1103, acc-0.4200, valid loss-2.0896, acc-0.4370, test loss-2.0725, acc-0.4461\n",
      "Iter-30810, train loss-2.0788, acc-0.4200, valid loss-2.0895, acc-0.4372, test loss-2.0724, acc-0.4460\n",
      "Iter-30820, train loss-2.0326, acc-0.5000, valid loss-2.0895, acc-0.4372, test loss-2.0724, acc-0.4457\n",
      "Iter-30830, train loss-2.0976, acc-0.3800, valid loss-2.0894, acc-0.4374, test loss-2.0723, acc-0.4460\n",
      "Iter-30840, train loss-2.0442, acc-0.4600, valid loss-2.0894, acc-0.4372, test loss-2.0722, acc-0.4460\n",
      "Iter-30850, train loss-2.1554, acc-0.4200, valid loss-2.0893, acc-0.4370, test loss-2.0722, acc-0.4459\n",
      "Iter-30860, train loss-2.0317, acc-0.5000, valid loss-2.0893, acc-0.4370, test loss-2.0721, acc-0.4460\n",
      "Iter-30870, train loss-2.0736, acc-0.4600, valid loss-2.0892, acc-0.4370, test loss-2.0721, acc-0.4463\n",
      "Iter-30880, train loss-2.0731, acc-0.4600, valid loss-2.0892, acc-0.4374, test loss-2.0720, acc-0.4464\n",
      "Iter-30890, train loss-2.0663, acc-0.5200, valid loss-2.0891, acc-0.4372, test loss-2.0719, acc-0.4462\n",
      "Iter-30900, train loss-2.0568, acc-0.5000, valid loss-2.0891, acc-0.4372, test loss-2.0719, acc-0.4462\n",
      "Iter-30910, train loss-2.0794, acc-0.4800, valid loss-2.0890, acc-0.4372, test loss-2.0718, acc-0.4459\n",
      "Iter-30920, train loss-2.0893, acc-0.4600, valid loss-2.0889, acc-0.4372, test loss-2.0718, acc-0.4459\n",
      "Iter-30930, train loss-2.1020, acc-0.4400, valid loss-2.0889, acc-0.4364, test loss-2.0717, acc-0.4460\n",
      "Iter-30940, train loss-2.1226, acc-0.2600, valid loss-2.0888, acc-0.4366, test loss-2.0717, acc-0.4460\n",
      "Iter-30950, train loss-2.0203, acc-0.4800, valid loss-2.0888, acc-0.4370, test loss-2.0716, acc-0.4457\n",
      "Iter-30960, train loss-2.0385, acc-0.5200, valid loss-2.0887, acc-0.4370, test loss-2.0715, acc-0.4458\n",
      "Iter-30970, train loss-2.0704, acc-0.4800, valid loss-2.0887, acc-0.4372, test loss-2.0715, acc-0.4461\n",
      "Iter-30980, train loss-2.0879, acc-0.4200, valid loss-2.0886, acc-0.4372, test loss-2.0714, acc-0.4463\n",
      "Iter-30990, train loss-2.0843, acc-0.4200, valid loss-2.0886, acc-0.4366, test loss-2.0714, acc-0.4463\n",
      "Iter-31000, train loss-2.0842, acc-0.4800, valid loss-2.0885, acc-0.4366, test loss-2.0713, acc-0.4463\n",
      "Iter-31010, train loss-2.0945, acc-0.4000, valid loss-2.0885, acc-0.4374, test loss-2.0713, acc-0.4462\n",
      "Iter-31020, train loss-2.0720, acc-0.4400, valid loss-2.0884, acc-0.4374, test loss-2.0712, acc-0.4461\n",
      "Iter-31030, train loss-2.0798, acc-0.5200, valid loss-2.0884, acc-0.4374, test loss-2.0711, acc-0.4459\n",
      "Iter-31040, train loss-2.1648, acc-0.2800, valid loss-2.0883, acc-0.4374, test loss-2.0711, acc-0.4460\n",
      "Iter-31050, train loss-2.0669, acc-0.4600, valid loss-2.0883, acc-0.4372, test loss-2.0710, acc-0.4456\n",
      "Iter-31060, train loss-2.0894, acc-0.4000, valid loss-2.0882, acc-0.4370, test loss-2.0710, acc-0.4460\n",
      "Iter-31070, train loss-2.1094, acc-0.4600, valid loss-2.0882, acc-0.4372, test loss-2.0709, acc-0.4461\n",
      "Iter-31080, train loss-2.0645, acc-0.5200, valid loss-2.0881, acc-0.4374, test loss-2.0709, acc-0.4460\n",
      "Iter-31090, train loss-2.0866, acc-0.3400, valid loss-2.0881, acc-0.4376, test loss-2.0708, acc-0.4462\n",
      "Iter-31100, train loss-2.1403, acc-0.3800, valid loss-2.0880, acc-0.4376, test loss-2.0707, acc-0.4460\n",
      "Iter-31110, train loss-2.1019, acc-0.3400, valid loss-2.0880, acc-0.4376, test loss-2.0707, acc-0.4461\n",
      "Iter-31120, train loss-2.0747, acc-0.5000, valid loss-2.0879, acc-0.4374, test loss-2.0706, acc-0.4462\n",
      "Iter-31130, train loss-2.1010, acc-0.4400, valid loss-2.0879, acc-0.4372, test loss-2.0706, acc-0.4462\n",
      "Iter-31140, train loss-2.0615, acc-0.4600, valid loss-2.0878, acc-0.4374, test loss-2.0705, acc-0.4463\n",
      "Iter-31150, train loss-2.1001, acc-0.4200, valid loss-2.0878, acc-0.4372, test loss-2.0704, acc-0.4460\n",
      "Iter-31160, train loss-2.0610, acc-0.5200, valid loss-2.0877, acc-0.4372, test loss-2.0704, acc-0.4460\n",
      "Iter-31170, train loss-2.0604, acc-0.4400, valid loss-2.0876, acc-0.4372, test loss-2.0703, acc-0.4460\n",
      "Iter-31180, train loss-2.0255, acc-0.4800, valid loss-2.0876, acc-0.4374, test loss-2.0703, acc-0.4457\n",
      "Iter-31190, train loss-2.0936, acc-0.4800, valid loss-2.0875, acc-0.4372, test loss-2.0702, acc-0.4457\n",
      "Iter-31200, train loss-2.1373, acc-0.3400, valid loss-2.0875, acc-0.4374, test loss-2.0702, acc-0.4462\n",
      "Iter-31210, train loss-2.0917, acc-0.4000, valid loss-2.0874, acc-0.4374, test loss-2.0701, acc-0.4464\n",
      "Iter-31220, train loss-2.1051, acc-0.3200, valid loss-2.0874, acc-0.4372, test loss-2.0700, acc-0.4462\n",
      "Iter-31230, train loss-2.0700, acc-0.4400, valid loss-2.0873, acc-0.4364, test loss-2.0700, acc-0.4468\n",
      "Iter-31240, train loss-2.0959, acc-0.4800, valid loss-2.0873, acc-0.4364, test loss-2.0699, acc-0.4465\n",
      "Iter-31250, train loss-2.0967, acc-0.4400, valid loss-2.0872, acc-0.4366, test loss-2.0699, acc-0.4467\n",
      "Iter-31260, train loss-2.1178, acc-0.4400, valid loss-2.0872, acc-0.4366, test loss-2.0698, acc-0.4465\n",
      "Iter-31270, train loss-2.0938, acc-0.3600, valid loss-2.0871, acc-0.4366, test loss-2.0698, acc-0.4465\n",
      "Iter-31280, train loss-2.1297, acc-0.3600, valid loss-2.0871, acc-0.4362, test loss-2.0697, acc-0.4468\n",
      "Iter-31290, train loss-2.0518, acc-0.5200, valid loss-2.0870, acc-0.4366, test loss-2.0696, acc-0.4467\n",
      "Iter-31300, train loss-2.0764, acc-0.4000, valid loss-2.0870, acc-0.4366, test loss-2.0696, acc-0.4469\n",
      "Iter-31310, train loss-2.0570, acc-0.4800, valid loss-2.0869, acc-0.4366, test loss-2.0695, acc-0.4471\n",
      "Iter-31320, train loss-2.1149, acc-0.4000, valid loss-2.0869, acc-0.4370, test loss-2.0695, acc-0.4471\n",
      "Iter-31330, train loss-2.0425, acc-0.4400, valid loss-2.0868, acc-0.4370, test loss-2.0694, acc-0.4470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-31340, train loss-2.1186, acc-0.3200, valid loss-2.0868, acc-0.4366, test loss-2.0693, acc-0.4472\n",
      "Iter-31350, train loss-2.0833, acc-0.4800, valid loss-2.0867, acc-0.4366, test loss-2.0693, acc-0.4473\n",
      "Iter-31360, train loss-2.0820, acc-0.4800, valid loss-2.0867, acc-0.4366, test loss-2.0692, acc-0.4476\n",
      "Iter-31370, train loss-2.1147, acc-0.4000, valid loss-2.0866, acc-0.4370, test loss-2.0692, acc-0.4478\n",
      "Iter-31380, train loss-2.0660, acc-0.4400, valid loss-2.0865, acc-0.4366, test loss-2.0691, acc-0.4477\n",
      "Iter-31390, train loss-2.0669, acc-0.5000, valid loss-2.0865, acc-0.4368, test loss-2.0691, acc-0.4477\n",
      "Iter-31400, train loss-2.0931, acc-0.4600, valid loss-2.0864, acc-0.4372, test loss-2.0690, acc-0.4477\n",
      "Iter-31410, train loss-2.0402, acc-0.4600, valid loss-2.0864, acc-0.4372, test loss-2.0689, acc-0.4476\n",
      "Iter-31420, train loss-2.0697, acc-0.4800, valid loss-2.0863, acc-0.4370, test loss-2.0689, acc-0.4475\n",
      "Iter-31430, train loss-2.1034, acc-0.4400, valid loss-2.0863, acc-0.4368, test loss-2.0688, acc-0.4477\n",
      "Iter-31440, train loss-2.0809, acc-0.4200, valid loss-2.0862, acc-0.4366, test loss-2.0688, acc-0.4474\n",
      "Iter-31450, train loss-2.0508, acc-0.4400, valid loss-2.0862, acc-0.4368, test loss-2.0687, acc-0.4480\n",
      "Iter-31460, train loss-2.0531, acc-0.5400, valid loss-2.0861, acc-0.4370, test loss-2.0687, acc-0.4480\n",
      "Iter-31470, train loss-2.1056, acc-0.3600, valid loss-2.0861, acc-0.4370, test loss-2.0686, acc-0.4480\n",
      "Iter-31480, train loss-2.0708, acc-0.3600, valid loss-2.0860, acc-0.4366, test loss-2.0686, acc-0.4481\n",
      "Iter-31490, train loss-2.0420, acc-0.4200, valid loss-2.0860, acc-0.4366, test loss-2.0685, acc-0.4481\n",
      "Iter-31500, train loss-2.0255, acc-0.5200, valid loss-2.0859, acc-0.4368, test loss-2.0684, acc-0.4480\n",
      "Iter-31510, train loss-2.0616, acc-0.5200, valid loss-2.0859, acc-0.4364, test loss-2.0684, acc-0.4482\n",
      "Iter-31520, train loss-2.0317, acc-0.5000, valid loss-2.0858, acc-0.4364, test loss-2.0683, acc-0.4480\n",
      "Iter-31530, train loss-2.0563, acc-0.4400, valid loss-2.0858, acc-0.4366, test loss-2.0683, acc-0.4479\n",
      "Iter-31540, train loss-2.1105, acc-0.3800, valid loss-2.0857, acc-0.4364, test loss-2.0682, acc-0.4481\n",
      "Iter-31550, train loss-2.1567, acc-0.3800, valid loss-2.0857, acc-0.4366, test loss-2.0681, acc-0.4481\n",
      "Iter-31560, train loss-2.1524, acc-0.3800, valid loss-2.0856, acc-0.4366, test loss-2.0681, acc-0.4482\n",
      "Iter-31570, train loss-2.1203, acc-0.4000, valid loss-2.0856, acc-0.4368, test loss-2.0680, acc-0.4481\n",
      "Iter-31580, train loss-2.0559, acc-0.4400, valid loss-2.0855, acc-0.4372, test loss-2.0680, acc-0.4484\n",
      "Iter-31590, train loss-2.0889, acc-0.3600, valid loss-2.0855, acc-0.4366, test loss-2.0679, acc-0.4484\n",
      "Iter-31600, train loss-2.0342, acc-0.6200, valid loss-2.0854, acc-0.4370, test loss-2.0679, acc-0.4484\n",
      "Iter-31610, train loss-2.1554, acc-0.3200, valid loss-2.0854, acc-0.4372, test loss-2.0678, acc-0.4483\n",
      "Iter-31620, train loss-2.1197, acc-0.4400, valid loss-2.0853, acc-0.4366, test loss-2.0677, acc-0.4481\n",
      "Iter-31630, train loss-2.0527, acc-0.4400, valid loss-2.0853, acc-0.4366, test loss-2.0677, acc-0.4482\n",
      "Iter-31640, train loss-2.1438, acc-0.3400, valid loss-2.0852, acc-0.4370, test loss-2.0676, acc-0.4482\n",
      "Iter-31650, train loss-2.0395, acc-0.5400, valid loss-2.0852, acc-0.4368, test loss-2.0676, acc-0.4482\n",
      "Iter-31660, train loss-2.0567, acc-0.3600, valid loss-2.0851, acc-0.4374, test loss-2.0675, acc-0.4483\n",
      "Iter-31670, train loss-2.1587, acc-0.2800, valid loss-2.0851, acc-0.4372, test loss-2.0675, acc-0.4486\n",
      "Iter-31680, train loss-2.1370, acc-0.4000, valid loss-2.0850, acc-0.4376, test loss-2.0674, acc-0.4490\n",
      "Iter-31690, train loss-2.0731, acc-0.4000, valid loss-2.0850, acc-0.4376, test loss-2.0674, acc-0.4487\n",
      "Iter-31700, train loss-2.0482, acc-0.4400, valid loss-2.0849, acc-0.4374, test loss-2.0673, acc-0.4488\n",
      "Iter-31710, train loss-2.0526, acc-0.5000, valid loss-2.0848, acc-0.4376, test loss-2.0672, acc-0.4489\n",
      "Iter-31720, train loss-2.0278, acc-0.5600, valid loss-2.0848, acc-0.4374, test loss-2.0672, acc-0.4490\n",
      "Iter-31730, train loss-2.0320, acc-0.5600, valid loss-2.0847, acc-0.4374, test loss-2.0671, acc-0.4491\n",
      "Iter-31740, train loss-2.0986, acc-0.3200, valid loss-2.0847, acc-0.4378, test loss-2.0671, acc-0.4488\n",
      "Iter-31750, train loss-2.0226, acc-0.4800, valid loss-2.0846, acc-0.4380, test loss-2.0670, acc-0.4486\n",
      "Iter-31760, train loss-2.0975, acc-0.3000, valid loss-2.0846, acc-0.4380, test loss-2.0669, acc-0.4489\n",
      "Iter-31770, train loss-2.0920, acc-0.4200, valid loss-2.0845, acc-0.4382, test loss-2.0669, acc-0.4487\n",
      "Iter-31780, train loss-2.0579, acc-0.4800, valid loss-2.0845, acc-0.4382, test loss-2.0668, acc-0.4487\n",
      "Iter-31790, train loss-2.0713, acc-0.4200, valid loss-2.0844, acc-0.4378, test loss-2.0668, acc-0.4488\n",
      "Iter-31800, train loss-2.1773, acc-0.2600, valid loss-2.0844, acc-0.4382, test loss-2.0667, acc-0.4488\n",
      "Iter-31810, train loss-2.0426, acc-0.4800, valid loss-2.0843, acc-0.4384, test loss-2.0667, acc-0.4489\n",
      "Iter-31820, train loss-2.0644, acc-0.4800, valid loss-2.0843, acc-0.4378, test loss-2.0666, acc-0.4489\n",
      "Iter-31830, train loss-2.0348, acc-0.5400, valid loss-2.0842, acc-0.4378, test loss-2.0666, acc-0.4492\n",
      "Iter-31840, train loss-2.0783, acc-0.4400, valid loss-2.0842, acc-0.4378, test loss-2.0665, acc-0.4490\n",
      "Iter-31850, train loss-2.0222, acc-0.5400, valid loss-2.0841, acc-0.4382, test loss-2.0664, acc-0.4485\n",
      "Iter-31860, train loss-2.0567, acc-0.4600, valid loss-2.0841, acc-0.4384, test loss-2.0664, acc-0.4488\n",
      "Iter-31870, train loss-2.1180, acc-0.2800, valid loss-2.0840, acc-0.4384, test loss-2.0663, acc-0.4488\n",
      "Iter-31880, train loss-2.0741, acc-0.5000, valid loss-2.0840, acc-0.4388, test loss-2.0663, acc-0.4487\n",
      "Iter-31890, train loss-2.0922, acc-0.3800, valid loss-2.0839, acc-0.4388, test loss-2.0662, acc-0.4490\n",
      "Iter-31900, train loss-2.0623, acc-0.5200, valid loss-2.0839, acc-0.4388, test loss-2.0662, acc-0.4488\n",
      "Iter-31910, train loss-2.0973, acc-0.3800, valid loss-2.0838, acc-0.4388, test loss-2.0661, acc-0.4488\n",
      "Iter-31920, train loss-2.0500, acc-0.4400, valid loss-2.0838, acc-0.4384, test loss-2.0660, acc-0.4487\n",
      "Iter-31930, train loss-2.0835, acc-0.5000, valid loss-2.0837, acc-0.4384, test loss-2.0660, acc-0.4492\n",
      "Iter-31940, train loss-2.0959, acc-0.4200, valid loss-2.0837, acc-0.4384, test loss-2.0659, acc-0.4489\n",
      "Iter-31950, train loss-2.0769, acc-0.5200, valid loss-2.0836, acc-0.4386, test loss-2.0659, acc-0.4494\n",
      "Iter-31960, train loss-2.0595, acc-0.4400, valid loss-2.0835, acc-0.4384, test loss-2.0658, acc-0.4494\n",
      "Iter-31970, train loss-2.0236, acc-0.5600, valid loss-2.0835, acc-0.4386, test loss-2.0657, acc-0.4494\n",
      "Iter-31980, train loss-2.0512, acc-0.5400, valid loss-2.0834, acc-0.4386, test loss-2.0657, acc-0.4496\n",
      "Iter-31990, train loss-2.0891, acc-0.4000, valid loss-2.0834, acc-0.4386, test loss-2.0656, acc-0.4495\n",
      "Iter-32000, train loss-2.0784, acc-0.4800, valid loss-2.0833, acc-0.4384, test loss-2.0656, acc-0.4493\n",
      "Iter-32010, train loss-2.0746, acc-0.4200, valid loss-2.0833, acc-0.4386, test loss-2.0655, acc-0.4494\n",
      "Iter-32020, train loss-2.0871, acc-0.4800, valid loss-2.0832, acc-0.4386, test loss-2.0655, acc-0.4492\n",
      "Iter-32030, train loss-2.1115, acc-0.4400, valid loss-2.0832, acc-0.4384, test loss-2.0654, acc-0.4493\n",
      "Iter-32040, train loss-2.1246, acc-0.4400, valid loss-2.0831, acc-0.4386, test loss-2.0653, acc-0.4497\n",
      "Iter-32050, train loss-2.0731, acc-0.4000, valid loss-2.0831, acc-0.4384, test loss-2.0653, acc-0.4497\n",
      "Iter-32060, train loss-2.0554, acc-0.5200, valid loss-2.0830, acc-0.4386, test loss-2.0652, acc-0.4496\n",
      "Iter-32070, train loss-2.0977, acc-0.3400, valid loss-2.0830, acc-0.4382, test loss-2.0652, acc-0.4496\n",
      "Iter-32080, train loss-2.0128, acc-0.5200, valid loss-2.0829, acc-0.4390, test loss-2.0651, acc-0.4497\n",
      "Iter-32090, train loss-2.0530, acc-0.4200, valid loss-2.0829, acc-0.4386, test loss-2.0651, acc-0.4497\n",
      "Iter-32100, train loss-2.0221, acc-0.5000, valid loss-2.0828, acc-0.4392, test loss-2.0650, acc-0.4498\n",
      "Iter-32110, train loss-2.0754, acc-0.4400, valid loss-2.0828, acc-0.4390, test loss-2.0650, acc-0.4496\n",
      "Iter-32120, train loss-2.0489, acc-0.5200, valid loss-2.0827, acc-0.4388, test loss-2.0649, acc-0.4497\n",
      "Iter-32130, train loss-2.0940, acc-0.4400, valid loss-2.0827, acc-0.4386, test loss-2.0648, acc-0.4498\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32140, train loss-2.1451, acc-0.4200, valid loss-2.0826, acc-0.4386, test loss-2.0648, acc-0.4495\n",
      "Iter-32150, train loss-2.1055, acc-0.5000, valid loss-2.0826, acc-0.4386, test loss-2.0647, acc-0.4496\n",
      "Iter-32160, train loss-2.1325, acc-0.3600, valid loss-2.0825, acc-0.4388, test loss-2.0647, acc-0.4499\n",
      "Iter-32170, train loss-2.1291, acc-0.3400, valid loss-2.0825, acc-0.4388, test loss-2.0646, acc-0.4502\n",
      "Iter-32180, train loss-2.0227, acc-0.4600, valid loss-2.0824, acc-0.4388, test loss-2.0646, acc-0.4503\n",
      "Iter-32190, train loss-2.0500, acc-0.4800, valid loss-2.0824, acc-0.4388, test loss-2.0645, acc-0.4501\n",
      "Iter-32200, train loss-2.1188, acc-0.4600, valid loss-2.0823, acc-0.4388, test loss-2.0644, acc-0.4499\n",
      "Iter-32210, train loss-2.0742, acc-0.4200, valid loss-2.0823, acc-0.4388, test loss-2.0644, acc-0.4498\n",
      "Iter-32220, train loss-2.0859, acc-0.4400, valid loss-2.0822, acc-0.4388, test loss-2.0643, acc-0.4502\n",
      "Iter-32230, train loss-2.0840, acc-0.3800, valid loss-2.0822, acc-0.4386, test loss-2.0643, acc-0.4503\n",
      "Iter-32240, train loss-2.1087, acc-0.3800, valid loss-2.0821, acc-0.4386, test loss-2.0642, acc-0.4504\n",
      "Iter-32250, train loss-2.0725, acc-0.4600, valid loss-2.0821, acc-0.4384, test loss-2.0642, acc-0.4505\n",
      "Iter-32260, train loss-2.0814, acc-0.4400, valid loss-2.0820, acc-0.4392, test loss-2.0641, acc-0.4505\n",
      "Iter-32270, train loss-2.1070, acc-0.3800, valid loss-2.0820, acc-0.4390, test loss-2.0641, acc-0.4506\n",
      "Iter-32280, train loss-2.0571, acc-0.4600, valid loss-2.0819, acc-0.4390, test loss-2.0640, acc-0.4503\n",
      "Iter-32290, train loss-2.0628, acc-0.3800, valid loss-2.0819, acc-0.4392, test loss-2.0640, acc-0.4506\n",
      "Iter-32300, train loss-2.0509, acc-0.4800, valid loss-2.0818, acc-0.4392, test loss-2.0639, acc-0.4506\n",
      "Iter-32310, train loss-2.0767, acc-0.4000, valid loss-2.0818, acc-0.4392, test loss-2.0638, acc-0.4507\n",
      "Iter-32320, train loss-1.9927, acc-0.6000, valid loss-2.0817, acc-0.4392, test loss-2.0638, acc-0.4505\n",
      "Iter-32330, train loss-2.0512, acc-0.4800, valid loss-2.0817, acc-0.4390, test loss-2.0637, acc-0.4507\n",
      "Iter-32340, train loss-2.0321, acc-0.4000, valid loss-2.0816, acc-0.4390, test loss-2.0637, acc-0.4505\n",
      "Iter-32350, train loss-2.0907, acc-0.4800, valid loss-2.0816, acc-0.4392, test loss-2.0636, acc-0.4505\n",
      "Iter-32360, train loss-2.0897, acc-0.4600, valid loss-2.0815, acc-0.4394, test loss-2.0635, acc-0.4506\n",
      "Iter-32370, train loss-2.0517, acc-0.4600, valid loss-2.0814, acc-0.4392, test loss-2.0635, acc-0.4506\n",
      "Iter-32380, train loss-2.0581, acc-0.4400, valid loss-2.0814, acc-0.4394, test loss-2.0634, acc-0.4507\n",
      "Iter-32390, train loss-2.1262, acc-0.3400, valid loss-2.0813, acc-0.4390, test loss-2.0634, acc-0.4509\n",
      "Iter-32400, train loss-2.0876, acc-0.4000, valid loss-2.0813, acc-0.4392, test loss-2.0633, acc-0.4510\n",
      "Iter-32410, train loss-2.0659, acc-0.4000, valid loss-2.0812, acc-0.4386, test loss-2.0633, acc-0.4508\n",
      "Iter-32420, train loss-2.0884, acc-0.4800, valid loss-2.0812, acc-0.4388, test loss-2.0632, acc-0.4507\n",
      "Iter-32430, train loss-2.0701, acc-0.3800, valid loss-2.0811, acc-0.4390, test loss-2.0632, acc-0.4512\n",
      "Iter-32440, train loss-2.0502, acc-0.5200, valid loss-2.0811, acc-0.4390, test loss-2.0631, acc-0.4512\n",
      "Iter-32450, train loss-2.1455, acc-0.3000, valid loss-2.0810, acc-0.4390, test loss-2.0630, acc-0.4512\n",
      "Iter-32460, train loss-2.0352, acc-0.4600, valid loss-2.0810, acc-0.4394, test loss-2.0630, acc-0.4513\n",
      "Iter-32470, train loss-2.0181, acc-0.6200, valid loss-2.0809, acc-0.4396, test loss-2.0629, acc-0.4512\n",
      "Iter-32480, train loss-2.0684, acc-0.3600, valid loss-2.0809, acc-0.4392, test loss-2.0629, acc-0.4514\n",
      "Iter-32490, train loss-2.0630, acc-0.4600, valid loss-2.0808, acc-0.4390, test loss-2.0628, acc-0.4514\n",
      "Iter-32500, train loss-2.1591, acc-0.4000, valid loss-2.0808, acc-0.4396, test loss-2.0628, acc-0.4514\n",
      "Iter-32510, train loss-2.0822, acc-0.4800, valid loss-2.0807, acc-0.4398, test loss-2.0627, acc-0.4515\n",
      "Iter-32520, train loss-2.0696, acc-0.4600, valid loss-2.0807, acc-0.4392, test loss-2.0626, acc-0.4517\n",
      "Iter-32530, train loss-2.0746, acc-0.4200, valid loss-2.0806, acc-0.4400, test loss-2.0626, acc-0.4517\n",
      "Iter-32540, train loss-2.0721, acc-0.3800, valid loss-2.0806, acc-0.4400, test loss-2.0625, acc-0.4519\n",
      "Iter-32550, train loss-2.0554, acc-0.4600, valid loss-2.0805, acc-0.4400, test loss-2.0625, acc-0.4518\n",
      "Iter-32560, train loss-2.0852, acc-0.4200, valid loss-2.0805, acc-0.4400, test loss-2.0624, acc-0.4518\n",
      "Iter-32570, train loss-2.0944, acc-0.4200, valid loss-2.0804, acc-0.4400, test loss-2.0624, acc-0.4517\n",
      "Iter-32580, train loss-2.1245, acc-0.3200, valid loss-2.0804, acc-0.4398, test loss-2.0623, acc-0.4517\n",
      "Iter-32590, train loss-2.0670, acc-0.4000, valid loss-2.0803, acc-0.4402, test loss-2.0622, acc-0.4518\n",
      "Iter-32600, train loss-2.0395, acc-0.5000, valid loss-2.0803, acc-0.4402, test loss-2.0622, acc-0.4516\n",
      "Iter-32610, train loss-2.1240, acc-0.3200, valid loss-2.0802, acc-0.4400, test loss-2.0621, acc-0.4517\n",
      "Iter-32620, train loss-2.0598, acc-0.3600, valid loss-2.0802, acc-0.4402, test loss-2.0621, acc-0.4517\n",
      "Iter-32630, train loss-2.1217, acc-0.3200, valid loss-2.0801, acc-0.4402, test loss-2.0620, acc-0.4518\n",
      "Iter-32640, train loss-2.0968, acc-0.4400, valid loss-2.0801, acc-0.4402, test loss-2.0620, acc-0.4519\n",
      "Iter-32650, train loss-2.0908, acc-0.4600, valid loss-2.0800, acc-0.4404, test loss-2.0619, acc-0.4520\n",
      "Iter-32660, train loss-2.0563, acc-0.3600, valid loss-2.0800, acc-0.4404, test loss-2.0618, acc-0.4519\n",
      "Iter-32670, train loss-2.0449, acc-0.4800, valid loss-2.0799, acc-0.4406, test loss-2.0618, acc-0.4519\n",
      "Iter-32680, train loss-2.0232, acc-0.5000, valid loss-2.0799, acc-0.4406, test loss-2.0617, acc-0.4520\n",
      "Iter-32690, train loss-2.1308, acc-0.3600, valid loss-2.0798, acc-0.4406, test loss-2.0617, acc-0.4522\n",
      "Iter-32700, train loss-2.0741, acc-0.4400, valid loss-2.0798, acc-0.4404, test loss-2.0616, acc-0.4523\n",
      "Iter-32710, train loss-2.1097, acc-0.4000, valid loss-2.0797, acc-0.4408, test loss-2.0616, acc-0.4522\n",
      "Iter-32720, train loss-2.0569, acc-0.4000, valid loss-2.0797, acc-0.4406, test loss-2.0615, acc-0.4520\n",
      "Iter-32730, train loss-2.0352, acc-0.4200, valid loss-2.0796, acc-0.4408, test loss-2.0615, acc-0.4522\n",
      "Iter-32740, train loss-2.1033, acc-0.3800, valid loss-2.0796, acc-0.4410, test loss-2.0614, acc-0.4522\n",
      "Iter-32750, train loss-2.0828, acc-0.3600, valid loss-2.0795, acc-0.4410, test loss-2.0613, acc-0.4521\n",
      "Iter-32760, train loss-2.0617, acc-0.4200, valid loss-2.0795, acc-0.4410, test loss-2.0613, acc-0.4521\n",
      "Iter-32770, train loss-2.0384, acc-0.5000, valid loss-2.0794, acc-0.4410, test loss-2.0612, acc-0.4521\n",
      "Iter-32780, train loss-2.1159, acc-0.4400, valid loss-2.0794, acc-0.4414, test loss-2.0612, acc-0.4522\n",
      "Iter-32790, train loss-2.0806, acc-0.4200, valid loss-2.0793, acc-0.4416, test loss-2.0611, acc-0.4524\n",
      "Iter-32800, train loss-2.1210, acc-0.4000, valid loss-2.0793, acc-0.4414, test loss-2.0611, acc-0.4519\n",
      "Iter-32810, train loss-2.0732, acc-0.4200, valid loss-2.0792, acc-0.4412, test loss-2.0610, acc-0.4523\n",
      "Iter-32820, train loss-2.0694, acc-0.4600, valid loss-2.0792, acc-0.4414, test loss-2.0610, acc-0.4521\n",
      "Iter-32830, train loss-2.0724, acc-0.5600, valid loss-2.0791, acc-0.4414, test loss-2.0609, acc-0.4521\n",
      "Iter-32840, train loss-2.0884, acc-0.3600, valid loss-2.0791, acc-0.4414, test loss-2.0608, acc-0.4523\n",
      "Iter-32850, train loss-2.0869, acc-0.3400, valid loss-2.0790, acc-0.4414, test loss-2.0608, acc-0.4523\n",
      "Iter-32860, train loss-2.0450, acc-0.4600, valid loss-2.0790, acc-0.4414, test loss-2.0607, acc-0.4524\n",
      "Iter-32870, train loss-2.1257, acc-0.4200, valid loss-2.0789, acc-0.4416, test loss-2.0607, acc-0.4524\n",
      "Iter-32880, train loss-2.1176, acc-0.3400, valid loss-2.0789, acc-0.4418, test loss-2.0606, acc-0.4524\n",
      "Iter-32890, train loss-2.0254, acc-0.5400, valid loss-2.0788, acc-0.4416, test loss-2.0606, acc-0.4525\n",
      "Iter-32900, train loss-2.1245, acc-0.3800, valid loss-2.0788, acc-0.4420, test loss-2.0605, acc-0.4527\n",
      "Iter-32910, train loss-2.0662, acc-0.5200, valid loss-2.0787, acc-0.4420, test loss-2.0604, acc-0.4528\n",
      "Iter-32920, train loss-2.0498, acc-0.5600, valid loss-2.0787, acc-0.4418, test loss-2.0604, acc-0.4526\n",
      "Iter-32930, train loss-2.0612, acc-0.4600, valid loss-2.0786, acc-0.4418, test loss-2.0603, acc-0.4525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32940, train loss-2.1472, acc-0.3600, valid loss-2.0786, acc-0.4420, test loss-2.0603, acc-0.4527\n",
      "Iter-32950, train loss-2.0823, acc-0.4200, valid loss-2.0785, acc-0.4422, test loss-2.0602, acc-0.4526\n",
      "Iter-32960, train loss-2.1040, acc-0.3200, valid loss-2.0785, acc-0.4418, test loss-2.0602, acc-0.4529\n",
      "Iter-32970, train loss-2.0622, acc-0.5000, valid loss-2.0784, acc-0.4420, test loss-2.0601, acc-0.4530\n",
      "Iter-32980, train loss-2.0401, acc-0.4000, valid loss-2.0783, acc-0.4422, test loss-2.0600, acc-0.4530\n",
      "Iter-32990, train loss-2.0058, acc-0.4800, valid loss-2.0783, acc-0.4422, test loss-2.0600, acc-0.4531\n",
      "Iter-33000, train loss-2.0447, acc-0.5400, valid loss-2.0782, acc-0.4424, test loss-2.0599, acc-0.4532\n",
      "Iter-33010, train loss-2.0431, acc-0.5200, valid loss-2.0782, acc-0.4426, test loss-2.0599, acc-0.4531\n",
      "Iter-33020, train loss-2.1053, acc-0.4600, valid loss-2.0781, acc-0.4426, test loss-2.0598, acc-0.4530\n",
      "Iter-33030, train loss-2.0651, acc-0.5000, valid loss-2.0781, acc-0.4428, test loss-2.0598, acc-0.4532\n",
      "Iter-33040, train loss-2.0702, acc-0.3800, valid loss-2.0780, acc-0.4434, test loss-2.0597, acc-0.4535\n",
      "Iter-33050, train loss-2.0719, acc-0.4800, valid loss-2.0780, acc-0.4436, test loss-2.0597, acc-0.4535\n",
      "Iter-33060, train loss-2.0584, acc-0.3200, valid loss-2.0779, acc-0.4434, test loss-2.0596, acc-0.4536\n",
      "Iter-33070, train loss-2.0779, acc-0.4800, valid loss-2.0779, acc-0.4436, test loss-2.0595, acc-0.4537\n",
      "Iter-33080, train loss-2.1105, acc-0.4000, valid loss-2.0778, acc-0.4436, test loss-2.0595, acc-0.4537\n",
      "Iter-33090, train loss-2.0445, acc-0.5000, valid loss-2.0778, acc-0.4434, test loss-2.0594, acc-0.4539\n",
      "Iter-33100, train loss-2.0381, acc-0.5000, valid loss-2.0777, acc-0.4430, test loss-2.0594, acc-0.4538\n",
      "Iter-33110, train loss-2.0281, acc-0.5200, valid loss-2.0777, acc-0.4432, test loss-2.0593, acc-0.4538\n",
      "Iter-33120, train loss-2.0916, acc-0.3400, valid loss-2.0776, acc-0.4430, test loss-2.0593, acc-0.4540\n",
      "Iter-33130, train loss-2.0991, acc-0.5000, valid loss-2.0776, acc-0.4434, test loss-2.0592, acc-0.4539\n",
      "Iter-33140, train loss-2.0822, acc-0.4400, valid loss-2.0775, acc-0.4434, test loss-2.0591, acc-0.4543\n",
      "Iter-33150, train loss-2.0720, acc-0.4800, valid loss-2.0775, acc-0.4432, test loss-2.0591, acc-0.4543\n",
      "Iter-33160, train loss-2.1108, acc-0.4600, valid loss-2.0774, acc-0.4436, test loss-2.0590, acc-0.4542\n",
      "Iter-33170, train loss-2.0110, acc-0.5400, valid loss-2.0774, acc-0.4438, test loss-2.0590, acc-0.4543\n",
      "Iter-33180, train loss-2.0904, acc-0.4000, valid loss-2.0773, acc-0.4436, test loss-2.0589, acc-0.4545\n",
      "Iter-33190, train loss-2.1770, acc-0.2400, valid loss-2.0773, acc-0.4438, test loss-2.0589, acc-0.4544\n",
      "Iter-33200, train loss-2.0655, acc-0.3200, valid loss-2.0772, acc-0.4436, test loss-2.0588, acc-0.4543\n",
      "Iter-33210, train loss-2.0774, acc-0.3800, valid loss-2.0772, acc-0.4436, test loss-2.0588, acc-0.4544\n",
      "Iter-33220, train loss-2.0193, acc-0.5800, valid loss-2.0771, acc-0.4434, test loss-2.0587, acc-0.4545\n",
      "Iter-33230, train loss-2.0790, acc-0.4400, valid loss-2.0771, acc-0.4434, test loss-2.0586, acc-0.4546\n",
      "Iter-33240, train loss-2.0532, acc-0.4600, valid loss-2.0770, acc-0.4432, test loss-2.0586, acc-0.4547\n",
      "Iter-33250, train loss-2.0842, acc-0.3800, valid loss-2.0770, acc-0.4432, test loss-2.0585, acc-0.4548\n",
      "Iter-33260, train loss-2.0647, acc-0.5000, valid loss-2.0769, acc-0.4432, test loss-2.0585, acc-0.4548\n",
      "Iter-33270, train loss-2.0577, acc-0.5000, valid loss-2.0769, acc-0.4432, test loss-2.0584, acc-0.4548\n",
      "Iter-33280, train loss-2.0415, acc-0.4400, valid loss-2.0768, acc-0.4432, test loss-2.0584, acc-0.4549\n",
      "Iter-33290, train loss-2.0912, acc-0.5000, valid loss-2.0768, acc-0.4434, test loss-2.0583, acc-0.4551\n",
      "Iter-33300, train loss-2.0664, acc-0.4800, valid loss-2.0767, acc-0.4434, test loss-2.0582, acc-0.4553\n",
      "Iter-33310, train loss-2.0525, acc-0.4000, valid loss-2.0767, acc-0.4434, test loss-2.0582, acc-0.4553\n",
      "Iter-33320, train loss-1.9715, acc-0.6200, valid loss-2.0766, acc-0.4434, test loss-2.0581, acc-0.4553\n",
      "Iter-33330, train loss-2.0109, acc-0.4200, valid loss-2.0766, acc-0.4436, test loss-2.0581, acc-0.4554\n",
      "Iter-33340, train loss-2.1424, acc-0.3600, valid loss-2.0765, acc-0.4436, test loss-2.0580, acc-0.4554\n",
      "Iter-33350, train loss-2.0544, acc-0.4800, valid loss-2.0765, acc-0.4436, test loss-2.0580, acc-0.4554\n",
      "Iter-33360, train loss-2.1055, acc-0.3400, valid loss-2.0764, acc-0.4436, test loss-2.0579, acc-0.4553\n",
      "Iter-33370, train loss-2.0682, acc-0.4200, valid loss-2.0763, acc-0.4438, test loss-2.0579, acc-0.4554\n",
      "Iter-33380, train loss-2.0459, acc-0.4800, valid loss-2.0763, acc-0.4438, test loss-2.0578, acc-0.4556\n",
      "Iter-33390, train loss-2.1135, acc-0.3600, valid loss-2.0762, acc-0.4434, test loss-2.0577, acc-0.4555\n",
      "Iter-33400, train loss-2.0656, acc-0.4200, valid loss-2.0762, acc-0.4434, test loss-2.0577, acc-0.4556\n",
      "Iter-33410, train loss-2.1402, acc-0.3200, valid loss-2.0762, acc-0.4438, test loss-2.0576, acc-0.4559\n",
      "Iter-33420, train loss-2.1105, acc-0.3800, valid loss-2.0761, acc-0.4444, test loss-2.0576, acc-0.4559\n",
      "Iter-33430, train loss-2.1119, acc-0.2600, valid loss-2.0761, acc-0.4448, test loss-2.0575, acc-0.4557\n",
      "Iter-33440, train loss-2.0983, acc-0.4000, valid loss-2.0760, acc-0.4446, test loss-2.0575, acc-0.4557\n",
      "Iter-33450, train loss-2.0832, acc-0.4600, valid loss-2.0760, acc-0.4446, test loss-2.0574, acc-0.4558\n",
      "Iter-33460, train loss-2.0727, acc-0.4600, valid loss-2.0759, acc-0.4446, test loss-2.0573, acc-0.4556\n",
      "Iter-33470, train loss-2.0944, acc-0.4400, valid loss-2.0759, acc-0.4444, test loss-2.0573, acc-0.4557\n",
      "Iter-33480, train loss-2.0668, acc-0.3400, valid loss-2.0758, acc-0.4448, test loss-2.0572, acc-0.4558\n",
      "Iter-33490, train loss-2.0820, acc-0.4600, valid loss-2.0758, acc-0.4450, test loss-2.0572, acc-0.4557\n",
      "Iter-33500, train loss-2.0552, acc-0.5000, valid loss-2.0757, acc-0.4446, test loss-2.0571, acc-0.4557\n",
      "Iter-33510, train loss-2.0403, acc-0.4000, valid loss-2.0757, acc-0.4448, test loss-2.0571, acc-0.4558\n",
      "Iter-33520, train loss-2.0531, acc-0.5000, valid loss-2.0756, acc-0.4448, test loss-2.0570, acc-0.4558\n",
      "Iter-33530, train loss-2.0111, acc-0.5800, valid loss-2.0755, acc-0.4448, test loss-2.0570, acc-0.4556\n",
      "Iter-33540, train loss-2.0879, acc-0.4400, valid loss-2.0755, acc-0.4446, test loss-2.0569, acc-0.4556\n",
      "Iter-33550, train loss-2.0459, acc-0.5400, valid loss-2.0755, acc-0.4446, test loss-2.0569, acc-0.4555\n",
      "Iter-33560, train loss-2.0817, acc-0.4200, valid loss-2.0754, acc-0.4442, test loss-2.0568, acc-0.4557\n",
      "Iter-33570, train loss-2.0830, acc-0.4600, valid loss-2.0753, acc-0.4444, test loss-2.0567, acc-0.4556\n",
      "Iter-33580, train loss-2.0790, acc-0.4000, valid loss-2.0753, acc-0.4444, test loss-2.0567, acc-0.4557\n",
      "Iter-33590, train loss-2.1081, acc-0.4600, valid loss-2.0752, acc-0.4444, test loss-2.0566, acc-0.4559\n",
      "Iter-33600, train loss-2.0391, acc-0.5000, valid loss-2.0752, acc-0.4444, test loss-2.0566, acc-0.4561\n",
      "Iter-33610, train loss-2.0935, acc-0.4800, valid loss-2.0751, acc-0.4442, test loss-2.0565, acc-0.4560\n",
      "Iter-33620, train loss-2.0599, acc-0.4800, valid loss-2.0751, acc-0.4442, test loss-2.0565, acc-0.4560\n",
      "Iter-33630, train loss-2.0196, acc-0.6800, valid loss-2.0750, acc-0.4444, test loss-2.0564, acc-0.4559\n",
      "Iter-33640, train loss-2.0975, acc-0.3200, valid loss-2.0750, acc-0.4438, test loss-2.0563, acc-0.4561\n",
      "Iter-33650, train loss-2.0519, acc-0.5400, valid loss-2.0749, acc-0.4444, test loss-2.0563, acc-0.4560\n",
      "Iter-33660, train loss-2.1141, acc-0.3800, valid loss-2.0749, acc-0.4448, test loss-2.0562, acc-0.4562\n",
      "Iter-33670, train loss-2.0569, acc-0.5600, valid loss-2.0748, acc-0.4446, test loss-2.0562, acc-0.4558\n",
      "Iter-33680, train loss-2.0477, acc-0.5000, valid loss-2.0748, acc-0.4446, test loss-2.0561, acc-0.4561\n",
      "Iter-33690, train loss-2.1160, acc-0.3400, valid loss-2.0747, acc-0.4448, test loss-2.0561, acc-0.4563\n",
      "Iter-33700, train loss-2.0800, acc-0.4600, valid loss-2.0747, acc-0.4450, test loss-2.0560, acc-0.4562\n",
      "Iter-33710, train loss-2.0650, acc-0.4200, valid loss-2.0746, acc-0.4448, test loss-2.0559, acc-0.4559\n",
      "Iter-33720, train loss-2.1284, acc-0.3800, valid loss-2.0746, acc-0.4450, test loss-2.0559, acc-0.4560\n",
      "Iter-33730, train loss-2.0953, acc-0.3400, valid loss-2.0745, acc-0.4456, test loss-2.0558, acc-0.4563\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-33740, train loss-2.1122, acc-0.3600, valid loss-2.0745, acc-0.4456, test loss-2.0558, acc-0.4560\n",
      "Iter-33750, train loss-2.0670, acc-0.4000, valid loss-2.0744, acc-0.4454, test loss-2.0557, acc-0.4562\n",
      "Iter-33760, train loss-2.0817, acc-0.4200, valid loss-2.0744, acc-0.4452, test loss-2.0557, acc-0.4562\n",
      "Iter-33770, train loss-2.0930, acc-0.4200, valid loss-2.0744, acc-0.4456, test loss-2.0556, acc-0.4561\n",
      "Iter-33780, train loss-2.0404, acc-0.3200, valid loss-2.0743, acc-0.4456, test loss-2.0556, acc-0.4562\n",
      "Iter-33790, train loss-2.0696, acc-0.3800, valid loss-2.0743, acc-0.4454, test loss-2.0555, acc-0.4564\n",
      "Iter-33800, train loss-2.0647, acc-0.4000, valid loss-2.0742, acc-0.4454, test loss-2.0555, acc-0.4564\n",
      "Iter-33810, train loss-2.0601, acc-0.4000, valid loss-2.0741, acc-0.4456, test loss-2.0554, acc-0.4565\n",
      "Iter-33820, train loss-2.0189, acc-0.4600, valid loss-2.0741, acc-0.4452, test loss-2.0554, acc-0.4565\n",
      "Iter-33830, train loss-2.0805, acc-0.4200, valid loss-2.0741, acc-0.4452, test loss-2.0553, acc-0.4565\n",
      "Iter-33840, train loss-2.0955, acc-0.4600, valid loss-2.0740, acc-0.4452, test loss-2.0552, acc-0.4566\n",
      "Iter-33850, train loss-2.0274, acc-0.4600, valid loss-2.0740, acc-0.4452, test loss-2.0552, acc-0.4570\n",
      "Iter-33860, train loss-2.0483, acc-0.4600, valid loss-2.0739, acc-0.4454, test loss-2.0551, acc-0.4570\n",
      "Iter-33870, train loss-2.0336, acc-0.4200, valid loss-2.0739, acc-0.4454, test loss-2.0551, acc-0.4568\n",
      "Iter-33880, train loss-2.0054, acc-0.6200, valid loss-2.0738, acc-0.4452, test loss-2.0550, acc-0.4571\n",
      "Iter-33890, train loss-2.0885, acc-0.2800, valid loss-2.0738, acc-0.4452, test loss-2.0550, acc-0.4568\n",
      "Iter-33900, train loss-2.0472, acc-0.6200, valid loss-2.0737, acc-0.4456, test loss-2.0549, acc-0.4568\n",
      "Iter-33910, train loss-2.0140, acc-0.4800, valid loss-2.0737, acc-0.4454, test loss-2.0548, acc-0.4571\n",
      "Iter-33920, train loss-2.0661, acc-0.4800, valid loss-2.0736, acc-0.4452, test loss-2.0548, acc-0.4571\n",
      "Iter-33930, train loss-2.1294, acc-0.3800, valid loss-2.0736, acc-0.4456, test loss-2.0547, acc-0.4571\n",
      "Iter-33940, train loss-2.1229, acc-0.4400, valid loss-2.0735, acc-0.4454, test loss-2.0547, acc-0.4572\n",
      "Iter-33950, train loss-2.1077, acc-0.3400, valid loss-2.0734, acc-0.4454, test loss-2.0546, acc-0.4571\n",
      "Iter-33960, train loss-2.0272, acc-0.5200, valid loss-2.0734, acc-0.4450, test loss-2.0546, acc-0.4573\n",
      "Iter-33970, train loss-2.0649, acc-0.3800, valid loss-2.0733, acc-0.4454, test loss-2.0545, acc-0.4575\n",
      "Iter-33980, train loss-2.0573, acc-0.5200, valid loss-2.0733, acc-0.4454, test loss-2.0545, acc-0.4577\n",
      "Iter-33990, train loss-2.0252, acc-0.5600, valid loss-2.0732, acc-0.4452, test loss-2.0544, acc-0.4577\n",
      "Iter-34000, train loss-2.0776, acc-0.4800, valid loss-2.0732, acc-0.4454, test loss-2.0543, acc-0.4581\n",
      "Iter-34010, train loss-2.0865, acc-0.3000, valid loss-2.0731, acc-0.4452, test loss-2.0543, acc-0.4579\n",
      "Iter-34020, train loss-2.0543, acc-0.4000, valid loss-2.0731, acc-0.4456, test loss-2.0542, acc-0.4579\n",
      "Iter-34030, train loss-2.1101, acc-0.3400, valid loss-2.0731, acc-0.4458, test loss-2.0542, acc-0.4579\n",
      "Iter-34040, train loss-2.0573, acc-0.4600, valid loss-2.0730, acc-0.4460, test loss-2.0541, acc-0.4579\n",
      "Iter-34050, train loss-2.0446, acc-0.5000, valid loss-2.0730, acc-0.4460, test loss-2.0541, acc-0.4579\n",
      "Iter-34060, train loss-2.1047, acc-0.4000, valid loss-2.0729, acc-0.4460, test loss-2.0540, acc-0.4577\n",
      "Iter-34070, train loss-2.0966, acc-0.3600, valid loss-2.0729, acc-0.4460, test loss-2.0540, acc-0.4576\n",
      "Iter-34080, train loss-2.0676, acc-0.3600, valid loss-2.0728, acc-0.4460, test loss-2.0539, acc-0.4577\n",
      "Iter-34090, train loss-2.0093, acc-0.5000, valid loss-2.0728, acc-0.4460, test loss-2.0539, acc-0.4576\n",
      "Iter-34100, train loss-2.0449, acc-0.5000, valid loss-2.0727, acc-0.4460, test loss-2.0538, acc-0.4576\n",
      "Iter-34110, train loss-2.0322, acc-0.4800, valid loss-2.0727, acc-0.4460, test loss-2.0537, acc-0.4575\n",
      "Iter-34120, train loss-2.0161, acc-0.5400, valid loss-2.0726, acc-0.4464, test loss-2.0537, acc-0.4574\n",
      "Iter-34130, train loss-2.0687, acc-0.4400, valid loss-2.0726, acc-0.4466, test loss-2.0536, acc-0.4572\n",
      "Iter-34140, train loss-2.0481, acc-0.4000, valid loss-2.0725, acc-0.4464, test loss-2.0536, acc-0.4574\n",
      "Iter-34150, train loss-2.1168, acc-0.3600, valid loss-2.0725, acc-0.4464, test loss-2.0535, acc-0.4572\n",
      "Iter-34160, train loss-2.1794, acc-0.3400, valid loss-2.0724, acc-0.4468, test loss-2.0535, acc-0.4574\n",
      "Iter-34170, train loss-2.0456, acc-0.4600, valid loss-2.0724, acc-0.4464, test loss-2.0534, acc-0.4571\n",
      "Iter-34180, train loss-2.0438, acc-0.4800, valid loss-2.0723, acc-0.4468, test loss-2.0534, acc-0.4571\n",
      "Iter-34190, train loss-2.0315, acc-0.4400, valid loss-2.0723, acc-0.4468, test loss-2.0533, acc-0.4570\n",
      "Iter-34200, train loss-2.0564, acc-0.5200, valid loss-2.0722, acc-0.4466, test loss-2.0532, acc-0.4573\n",
      "Iter-34210, train loss-2.0599, acc-0.5200, valid loss-2.0722, acc-0.4468, test loss-2.0532, acc-0.4572\n",
      "Iter-34220, train loss-2.0706, acc-0.4000, valid loss-2.0721, acc-0.4468, test loss-2.0531, acc-0.4572\n",
      "Iter-34230, train loss-2.0387, acc-0.3600, valid loss-2.0721, acc-0.4468, test loss-2.0531, acc-0.4576\n",
      "Iter-34240, train loss-2.1084, acc-0.3600, valid loss-2.0720, acc-0.4470, test loss-2.0530, acc-0.4579\n",
      "Iter-34250, train loss-2.0548, acc-0.4800, valid loss-2.0720, acc-0.4470, test loss-2.0530, acc-0.4578\n",
      "Iter-34260, train loss-2.0403, acc-0.5200, valid loss-2.0719, acc-0.4470, test loss-2.0529, acc-0.4578\n",
      "Iter-34270, train loss-2.0889, acc-0.3000, valid loss-2.0719, acc-0.4468, test loss-2.0529, acc-0.4576\n",
      "Iter-34280, train loss-2.0454, acc-0.4800, valid loss-2.0718, acc-0.4470, test loss-2.0528, acc-0.4577\n",
      "Iter-34290, train loss-2.0537, acc-0.4800, valid loss-2.0718, acc-0.4472, test loss-2.0527, acc-0.4579\n",
      "Iter-34300, train loss-2.0896, acc-0.4400, valid loss-2.0717, acc-0.4474, test loss-2.0527, acc-0.4581\n",
      "Iter-34310, train loss-2.1000, acc-0.4000, valid loss-2.0717, acc-0.4474, test loss-2.0526, acc-0.4582\n",
      "Iter-34320, train loss-2.0059, acc-0.5400, valid loss-2.0716, acc-0.4474, test loss-2.0526, acc-0.4582\n",
      "Iter-34330, train loss-2.0886, acc-0.4000, valid loss-2.0716, acc-0.4474, test loss-2.0525, acc-0.4583\n",
      "Iter-34340, train loss-2.0233, acc-0.5000, valid loss-2.0715, acc-0.4472, test loss-2.0525, acc-0.4584\n",
      "Iter-34350, train loss-2.0164, acc-0.5600, valid loss-2.0714, acc-0.4474, test loss-2.0524, acc-0.4583\n",
      "Iter-34360, train loss-2.0691, acc-0.4400, valid loss-2.0714, acc-0.4476, test loss-2.0524, acc-0.4583\n",
      "Iter-34370, train loss-2.0961, acc-0.4200, valid loss-2.0713, acc-0.4474, test loss-2.0523, acc-0.4584\n",
      "Iter-34380, train loss-2.0383, acc-0.4400, valid loss-2.0713, acc-0.4474, test loss-2.0522, acc-0.4584\n",
      "Iter-34390, train loss-2.0764, acc-0.4800, valid loss-2.0712, acc-0.4478, test loss-2.0522, acc-0.4586\n",
      "Iter-34400, train loss-2.0781, acc-0.4400, valid loss-2.0712, acc-0.4478, test loss-2.0521, acc-0.4587\n",
      "Iter-34410, train loss-2.0456, acc-0.4400, valid loss-2.0711, acc-0.4476, test loss-2.0521, acc-0.4586\n",
      "Iter-34420, train loss-2.0994, acc-0.3200, valid loss-2.0711, acc-0.4474, test loss-2.0520, acc-0.4586\n",
      "Iter-34430, train loss-2.0598, acc-0.5200, valid loss-2.0711, acc-0.4474, test loss-2.0520, acc-0.4585\n",
      "Iter-34440, train loss-2.1023, acc-0.5200, valid loss-2.0710, acc-0.4474, test loss-2.0519, acc-0.4583\n",
      "Iter-34450, train loss-2.0882, acc-0.4600, valid loss-2.0710, acc-0.4476, test loss-2.0519, acc-0.4583\n",
      "Iter-34460, train loss-2.0876, acc-0.4200, valid loss-2.0709, acc-0.4474, test loss-2.0518, acc-0.4583\n",
      "Iter-34470, train loss-2.0357, acc-0.4600, valid loss-2.0709, acc-0.4474, test loss-2.0518, acc-0.4583\n",
      "Iter-34480, train loss-2.1058, acc-0.4400, valid loss-2.0708, acc-0.4480, test loss-2.0517, acc-0.4583\n",
      "Iter-34490, train loss-2.0671, acc-0.4200, valid loss-2.0708, acc-0.4480, test loss-2.0516, acc-0.4586\n",
      "Iter-34500, train loss-2.0791, acc-0.5400, valid loss-2.0707, acc-0.4476, test loss-2.0516, acc-0.4586\n",
      "Iter-34510, train loss-2.0675, acc-0.3400, valid loss-2.0707, acc-0.4476, test loss-2.0515, acc-0.4587\n",
      "Iter-34520, train loss-2.0370, acc-0.4800, valid loss-2.0706, acc-0.4474, test loss-2.0515, acc-0.4587\n",
      "Iter-34530, train loss-2.0132, acc-0.5200, valid loss-2.0706, acc-0.4476, test loss-2.0514, acc-0.4588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-34540, train loss-2.0302, acc-0.5600, valid loss-2.0705, acc-0.4476, test loss-2.0514, acc-0.4589\n",
      "Iter-34550, train loss-2.0226, acc-0.5000, valid loss-2.0705, acc-0.4474, test loss-2.0513, acc-0.4589\n",
      "Iter-34560, train loss-2.0381, acc-0.4600, valid loss-2.0704, acc-0.4474, test loss-2.0513, acc-0.4588\n",
      "Iter-34570, train loss-2.0612, acc-0.5000, valid loss-2.0704, acc-0.4474, test loss-2.0512, acc-0.4589\n",
      "Iter-34580, train loss-2.0377, acc-0.5200, valid loss-2.0703, acc-0.4474, test loss-2.0511, acc-0.4591\n",
      "Iter-34590, train loss-2.0208, acc-0.4800, valid loss-2.0703, acc-0.4484, test loss-2.0511, acc-0.4592\n",
      "Iter-34600, train loss-2.0741, acc-0.4200, valid loss-2.0702, acc-0.4474, test loss-2.0510, acc-0.4592\n",
      "Iter-34610, train loss-2.0747, acc-0.4000, valid loss-2.0702, acc-0.4484, test loss-2.0510, acc-0.4591\n",
      "Iter-34620, train loss-2.0664, acc-0.4400, valid loss-2.0701, acc-0.4478, test loss-2.0509, acc-0.4591\n",
      "Iter-34630, train loss-2.0357, acc-0.4600, valid loss-2.0701, acc-0.4476, test loss-2.0509, acc-0.4590\n",
      "Iter-34640, train loss-2.0769, acc-0.5400, valid loss-2.0700, acc-0.4478, test loss-2.0508, acc-0.4592\n",
      "Iter-34650, train loss-2.0540, acc-0.4400, valid loss-2.0700, acc-0.4488, test loss-2.0508, acc-0.4594\n",
      "Iter-34660, train loss-2.0121, acc-0.5600, valid loss-2.0699, acc-0.4488, test loss-2.0507, acc-0.4596\n",
      "Iter-34670, train loss-2.0840, acc-0.3600, valid loss-2.0699, acc-0.4484, test loss-2.0506, acc-0.4596\n",
      "Iter-34680, train loss-2.0485, acc-0.5400, valid loss-2.0698, acc-0.4486, test loss-2.0506, acc-0.4596\n",
      "Iter-34690, train loss-2.0639, acc-0.4600, valid loss-2.0698, acc-0.4486, test loss-2.0505, acc-0.4597\n",
      "Iter-34700, train loss-2.0652, acc-0.4200, valid loss-2.0697, acc-0.4486, test loss-2.0505, acc-0.4596\n",
      "Iter-34710, train loss-2.0513, acc-0.4800, valid loss-2.0697, acc-0.4488, test loss-2.0504, acc-0.4598\n",
      "Iter-34720, train loss-2.0657, acc-0.3600, valid loss-2.0696, acc-0.4486, test loss-2.0504, acc-0.4602\n",
      "Iter-34730, train loss-2.0086, acc-0.5200, valid loss-2.0696, acc-0.4486, test loss-2.0503, acc-0.4601\n",
      "Iter-34740, train loss-2.0860, acc-0.5000, valid loss-2.0695, acc-0.4486, test loss-2.0503, acc-0.4598\n",
      "Iter-34750, train loss-2.0563, acc-0.4400, valid loss-2.0695, acc-0.4490, test loss-2.0502, acc-0.4601\n",
      "Iter-34760, train loss-2.0351, acc-0.4400, valid loss-2.0694, acc-0.4490, test loss-2.0502, acc-0.4598\n",
      "Iter-34770, train loss-2.1652, acc-0.3600, valid loss-2.0694, acc-0.4490, test loss-2.0501, acc-0.4599\n",
      "Iter-34780, train loss-2.0453, acc-0.5200, valid loss-2.0693, acc-0.4486, test loss-2.0500, acc-0.4599\n",
      "Iter-34790, train loss-2.0545, acc-0.4600, valid loss-2.0693, acc-0.4486, test loss-2.0500, acc-0.4602\n",
      "Iter-34800, train loss-2.0189, acc-0.5400, valid loss-2.0692, acc-0.4488, test loss-2.0499, acc-0.4601\n",
      "Iter-34810, train loss-2.0404, acc-0.3400, valid loss-2.0692, acc-0.4488, test loss-2.0499, acc-0.4602\n",
      "Iter-34820, train loss-2.0012, acc-0.4800, valid loss-2.0691, acc-0.4490, test loss-2.0498, acc-0.4601\n",
      "Iter-34830, train loss-2.0459, acc-0.4800, valid loss-2.0691, acc-0.4490, test loss-2.0498, acc-0.4603\n",
      "Iter-34840, train loss-2.0362, acc-0.4000, valid loss-2.0690, acc-0.4490, test loss-2.0497, acc-0.4601\n",
      "Iter-34850, train loss-2.0710, acc-0.3400, valid loss-2.0690, acc-0.4488, test loss-2.0497, acc-0.4603\n",
      "Iter-34860, train loss-2.0946, acc-0.3800, valid loss-2.0689, acc-0.4492, test loss-2.0496, acc-0.4606\n",
      "Iter-34870, train loss-2.0567, acc-0.4800, valid loss-2.0689, acc-0.4488, test loss-2.0496, acc-0.4602\n",
      "Iter-34880, train loss-2.0542, acc-0.4000, valid loss-2.0688, acc-0.4488, test loss-2.0495, acc-0.4599\n",
      "Iter-34890, train loss-2.0454, acc-0.4400, valid loss-2.0688, acc-0.4486, test loss-2.0495, acc-0.4599\n",
      "Iter-34900, train loss-2.0346, acc-0.5000, valid loss-2.0687, acc-0.4488, test loss-2.0494, acc-0.4600\n",
      "Iter-34910, train loss-2.0840, acc-0.4200, valid loss-2.0687, acc-0.4488, test loss-2.0493, acc-0.4603\n",
      "Iter-34920, train loss-2.0446, acc-0.4400, valid loss-2.0686, acc-0.4488, test loss-2.0493, acc-0.4600\n",
      "Iter-34930, train loss-2.0522, acc-0.4400, valid loss-2.0686, acc-0.4480, test loss-2.0492, acc-0.4601\n",
      "Iter-34940, train loss-2.0559, acc-0.5400, valid loss-2.0685, acc-0.4480, test loss-2.0492, acc-0.4601\n",
      "Iter-34950, train loss-2.0292, acc-0.4800, valid loss-2.0685, acc-0.4480, test loss-2.0491, acc-0.4599\n",
      "Iter-34960, train loss-2.0124, acc-0.4400, valid loss-2.0684, acc-0.4484, test loss-2.0491, acc-0.4602\n",
      "Iter-34970, train loss-2.0522, acc-0.4800, valid loss-2.0684, acc-0.4484, test loss-2.0490, acc-0.4600\n",
      "Iter-34980, train loss-2.0717, acc-0.3600, valid loss-2.0683, acc-0.4482, test loss-2.0490, acc-0.4597\n",
      "Iter-34990, train loss-2.1007, acc-0.4800, valid loss-2.0683, acc-0.4484, test loss-2.0489, acc-0.4597\n",
      "Iter-35000, train loss-2.0786, acc-0.3400, valid loss-2.0682, acc-0.4482, test loss-2.0489, acc-0.4598\n",
      "Iter-35010, train loss-2.0929, acc-0.4000, valid loss-2.0682, acc-0.4482, test loss-2.0488, acc-0.4599\n",
      "Iter-35020, train loss-2.1048, acc-0.3800, valid loss-2.0681, acc-0.4484, test loss-2.0487, acc-0.4601\n",
      "Iter-35030, train loss-2.1484, acc-0.2800, valid loss-2.0681, acc-0.4484, test loss-2.0487, acc-0.4600\n",
      "Iter-35040, train loss-2.0619, acc-0.5600, valid loss-2.0680, acc-0.4488, test loss-2.0486, acc-0.4601\n",
      "Iter-35050, train loss-2.0387, acc-0.4600, valid loss-2.0680, acc-0.4486, test loss-2.0486, acc-0.4600\n",
      "Iter-35060, train loss-2.0500, acc-0.4600, valid loss-2.0680, acc-0.4488, test loss-2.0485, acc-0.4604\n",
      "Iter-35070, train loss-2.0528, acc-0.3800, valid loss-2.0679, acc-0.4486, test loss-2.0485, acc-0.4606\n",
      "Iter-35080, train loss-2.0678, acc-0.4800, valid loss-2.0679, acc-0.4484, test loss-2.0484, acc-0.4603\n",
      "Iter-35090, train loss-2.0587, acc-0.4800, valid loss-2.0678, acc-0.4490, test loss-2.0484, acc-0.4604\n",
      "Iter-35100, train loss-2.0291, acc-0.5000, valid loss-2.0678, acc-0.4488, test loss-2.0483, acc-0.4606\n",
      "Iter-35110, train loss-2.0092, acc-0.4800, valid loss-2.0677, acc-0.4490, test loss-2.0483, acc-0.4603\n",
      "Iter-35120, train loss-2.0635, acc-0.4200, valid loss-2.0677, acc-0.4488, test loss-2.0482, acc-0.4605\n",
      "Iter-35130, train loss-2.0301, acc-0.4600, valid loss-2.0676, acc-0.4488, test loss-2.0481, acc-0.4604\n",
      "Iter-35140, train loss-2.0380, acc-0.5000, valid loss-2.0675, acc-0.4488, test loss-2.0481, acc-0.4606\n",
      "Iter-35150, train loss-2.0512, acc-0.5200, valid loss-2.0675, acc-0.4486, test loss-2.0480, acc-0.4605\n",
      "Iter-35160, train loss-2.0529, acc-0.5000, valid loss-2.0674, acc-0.4488, test loss-2.0480, acc-0.4604\n",
      "Iter-35170, train loss-2.0442, acc-0.5000, valid loss-2.0674, acc-0.4490, test loss-2.0479, acc-0.4606\n",
      "Iter-35180, train loss-1.9912, acc-0.4800, valid loss-2.0673, acc-0.4494, test loss-2.0479, acc-0.4608\n",
      "Iter-35190, train loss-2.0391, acc-0.5600, valid loss-2.0673, acc-0.4494, test loss-2.0478, acc-0.4604\n",
      "Iter-35200, train loss-1.9943, acc-0.5200, valid loss-2.0672, acc-0.4492, test loss-2.0478, acc-0.4602\n",
      "Iter-35210, train loss-2.0013, acc-0.5800, valid loss-2.0672, acc-0.4494, test loss-2.0477, acc-0.4603\n",
      "Iter-35220, train loss-2.0634, acc-0.4600, valid loss-2.0671, acc-0.4492, test loss-2.0476, acc-0.4605\n",
      "Iter-35230, train loss-2.0211, acc-0.5000, valid loss-2.0671, acc-0.4490, test loss-2.0476, acc-0.4603\n",
      "Iter-35240, train loss-2.0625, acc-0.4000, valid loss-2.0670, acc-0.4492, test loss-2.0475, acc-0.4606\n",
      "Iter-35250, train loss-2.0884, acc-0.4200, valid loss-2.0670, acc-0.4494, test loss-2.0475, acc-0.4603\n",
      "Iter-35260, train loss-2.0805, acc-0.5200, valid loss-2.0669, acc-0.4494, test loss-2.0474, acc-0.4604\n",
      "Iter-35270, train loss-2.0850, acc-0.3800, valid loss-2.0669, acc-0.4494, test loss-2.0474, acc-0.4606\n",
      "Iter-35280, train loss-2.0236, acc-0.5400, valid loss-2.0668, acc-0.4494, test loss-2.0473, acc-0.4604\n",
      "Iter-35290, train loss-2.1031, acc-0.3800, valid loss-2.0668, acc-0.4492, test loss-2.0473, acc-0.4606\n",
      "Iter-35300, train loss-2.0534, acc-0.3600, valid loss-2.0667, acc-0.4494, test loss-2.0472, acc-0.4608\n",
      "Iter-35310, train loss-2.0768, acc-0.3800, valid loss-2.0667, acc-0.4492, test loss-2.0471, acc-0.4606\n",
      "Iter-35320, train loss-2.0803, acc-0.4400, valid loss-2.0666, acc-0.4490, test loss-2.0471, acc-0.4605\n",
      "Iter-35330, train loss-2.0075, acc-0.5000, valid loss-2.0666, acc-0.4494, test loss-2.0470, acc-0.4607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-35340, train loss-2.0888, acc-0.2800, valid loss-2.0665, acc-0.4492, test loss-2.0470, acc-0.4603\n",
      "Iter-35350, train loss-2.1081, acc-0.3800, valid loss-2.0665, acc-0.4488, test loss-2.0469, acc-0.4603\n",
      "Iter-35360, train loss-2.0638, acc-0.4200, valid loss-2.0664, acc-0.4492, test loss-2.0469, acc-0.4606\n",
      "Iter-35370, train loss-2.0326, acc-0.4400, valid loss-2.0664, acc-0.4490, test loss-2.0468, acc-0.4604\n",
      "Iter-35380, train loss-2.0243, acc-0.4800, valid loss-2.0663, acc-0.4490, test loss-2.0468, acc-0.4605\n",
      "Iter-35390, train loss-2.0534, acc-0.5200, valid loss-2.0663, acc-0.4490, test loss-2.0467, acc-0.4606\n",
      "Iter-35400, train loss-2.0319, acc-0.5200, valid loss-2.0662, acc-0.4490, test loss-2.0467, acc-0.4605\n",
      "Iter-35410, train loss-2.0400, acc-0.4600, valid loss-2.0662, acc-0.4488, test loss-2.0466, acc-0.4604\n",
      "Iter-35420, train loss-2.0931, acc-0.4200, valid loss-2.0661, acc-0.4488, test loss-2.0465, acc-0.4607\n",
      "Iter-35430, train loss-2.0729, acc-0.4000, valid loss-2.0661, acc-0.4492, test loss-2.0465, acc-0.4607\n",
      "Iter-35440, train loss-2.0226, acc-0.5600, valid loss-2.0660, acc-0.4492, test loss-2.0464, acc-0.4609\n",
      "Iter-35450, train loss-2.0429, acc-0.4200, valid loss-2.0660, acc-0.4498, test loss-2.0464, acc-0.4611\n",
      "Iter-35460, train loss-2.0243, acc-0.5400, valid loss-2.0660, acc-0.4494, test loss-2.0463, acc-0.4611\n",
      "Iter-35470, train loss-2.0476, acc-0.4600, valid loss-2.0659, acc-0.4490, test loss-2.0463, acc-0.4609\n",
      "Iter-35480, train loss-2.0865, acc-0.3800, valid loss-2.0659, acc-0.4490, test loss-2.0462, acc-0.4609\n",
      "Iter-35490, train loss-2.0519, acc-0.4200, valid loss-2.0658, acc-0.4490, test loss-2.0462, acc-0.4608\n",
      "Iter-35500, train loss-2.1045, acc-0.3600, valid loss-2.0658, acc-0.4492, test loss-2.0461, acc-0.4612\n",
      "Iter-35510, train loss-2.0472, acc-0.4600, valid loss-2.0657, acc-0.4492, test loss-2.0461, acc-0.4612\n",
      "Iter-35520, train loss-2.0754, acc-0.4800, valid loss-2.0657, acc-0.4492, test loss-2.0460, acc-0.4611\n",
      "Iter-35530, train loss-2.0777, acc-0.4600, valid loss-2.0656, acc-0.4492, test loss-2.0459, acc-0.4609\n",
      "Iter-35540, train loss-2.1185, acc-0.3600, valid loss-2.0656, acc-0.4496, test loss-2.0459, acc-0.4610\n",
      "Iter-35550, train loss-2.1162, acc-0.4400, valid loss-2.0655, acc-0.4496, test loss-2.0458, acc-0.4610\n",
      "Iter-35560, train loss-2.0366, acc-0.3800, valid loss-2.0655, acc-0.4492, test loss-2.0458, acc-0.4609\n",
      "Iter-35570, train loss-2.0883, acc-0.5000, valid loss-2.0654, acc-0.4494, test loss-2.0457, acc-0.4608\n",
      "Iter-35580, train loss-2.0865, acc-0.3800, valid loss-2.0654, acc-0.4496, test loss-2.0457, acc-0.4611\n",
      "Iter-35590, train loss-2.0802, acc-0.4000, valid loss-2.0653, acc-0.4494, test loss-2.0456, acc-0.4615\n",
      "Iter-35600, train loss-2.1043, acc-0.4200, valid loss-2.0653, acc-0.4498, test loss-2.0456, acc-0.4615\n",
      "Iter-35610, train loss-1.9956, acc-0.5800, valid loss-2.0652, acc-0.4496, test loss-2.0455, acc-0.4614\n",
      "Iter-35620, train loss-2.0816, acc-0.5400, valid loss-2.0652, acc-0.4498, test loss-2.0455, acc-0.4618\n",
      "Iter-35630, train loss-2.0414, acc-0.5000, valid loss-2.0651, acc-0.4496, test loss-2.0454, acc-0.4619\n",
      "Iter-35640, train loss-2.1450, acc-0.3000, valid loss-2.0651, acc-0.4500, test loss-2.0453, acc-0.4618\n",
      "Iter-35650, train loss-2.0848, acc-0.4800, valid loss-2.0650, acc-0.4502, test loss-2.0453, acc-0.4620\n",
      "Iter-35660, train loss-2.0695, acc-0.4600, valid loss-2.0650, acc-0.4504, test loss-2.0452, acc-0.4621\n",
      "Iter-35670, train loss-2.0365, acc-0.5000, valid loss-2.0649, acc-0.4504, test loss-2.0452, acc-0.4620\n",
      "Iter-35680, train loss-2.0571, acc-0.4800, valid loss-2.0649, acc-0.4504, test loss-2.0451, acc-0.4623\n",
      "Iter-35690, train loss-2.0495, acc-0.4600, valid loss-2.0648, acc-0.4504, test loss-2.0451, acc-0.4623\n",
      "Iter-35700, train loss-2.0280, acc-0.4000, valid loss-2.0648, acc-0.4502, test loss-2.0450, acc-0.4621\n",
      "Iter-35710, train loss-2.0323, acc-0.5000, valid loss-2.0647, acc-0.4506, test loss-2.0450, acc-0.4623\n",
      "Iter-35720, train loss-2.0580, acc-0.4400, valid loss-2.0647, acc-0.4500, test loss-2.0449, acc-0.4623\n",
      "Iter-35730, train loss-2.0590, acc-0.4800, valid loss-2.0646, acc-0.4498, test loss-2.0449, acc-0.4624\n",
      "Iter-35740, train loss-2.1475, acc-0.3200, valid loss-2.0646, acc-0.4500, test loss-2.0448, acc-0.4623\n",
      "Iter-35750, train loss-2.0732, acc-0.3000, valid loss-2.0645, acc-0.4502, test loss-2.0448, acc-0.4623\n",
      "Iter-35760, train loss-2.0218, acc-0.5400, valid loss-2.0645, acc-0.4500, test loss-2.0447, acc-0.4623\n",
      "Iter-35770, train loss-2.0667, acc-0.4200, valid loss-2.0644, acc-0.4500, test loss-2.0446, acc-0.4623\n",
      "Iter-35780, train loss-2.0827, acc-0.4000, valid loss-2.0644, acc-0.4502, test loss-2.0446, acc-0.4621\n",
      "Iter-35790, train loss-1.9675, acc-0.5400, valid loss-2.0643, acc-0.4504, test loss-2.0445, acc-0.4622\n",
      "Iter-35800, train loss-2.1119, acc-0.3600, valid loss-2.0643, acc-0.4506, test loss-2.0445, acc-0.4624\n",
      "Iter-35810, train loss-2.0857, acc-0.4600, valid loss-2.0642, acc-0.4502, test loss-2.0444, acc-0.4624\n",
      "Iter-35820, train loss-2.0881, acc-0.4000, valid loss-2.0642, acc-0.4502, test loss-2.0444, acc-0.4624\n",
      "Iter-35830, train loss-2.0198, acc-0.5600, valid loss-2.0641, acc-0.4502, test loss-2.0443, acc-0.4624\n",
      "Iter-35840, train loss-2.0502, acc-0.4200, valid loss-2.0641, acc-0.4500, test loss-2.0443, acc-0.4623\n",
      "Iter-35850, train loss-2.0187, acc-0.4800, valid loss-2.0640, acc-0.4502, test loss-2.0442, acc-0.4624\n",
      "Iter-35860, train loss-2.0426, acc-0.4600, valid loss-2.0640, acc-0.4506, test loss-2.0442, acc-0.4626\n",
      "Iter-35870, train loss-2.0336, acc-0.4200, valid loss-2.0639, acc-0.4506, test loss-2.0441, acc-0.4622\n",
      "Iter-35880, train loss-2.0384, acc-0.4600, valid loss-2.0639, acc-0.4506, test loss-2.0440, acc-0.4626\n",
      "Iter-35890, train loss-2.0766, acc-0.5200, valid loss-2.0638, acc-0.4508, test loss-2.0440, acc-0.4625\n",
      "Iter-35900, train loss-2.1010, acc-0.4600, valid loss-2.0638, acc-0.4508, test loss-2.0439, acc-0.4625\n",
      "Iter-35910, train loss-2.1080, acc-0.3200, valid loss-2.0638, acc-0.4508, test loss-2.0439, acc-0.4626\n",
      "Iter-35920, train loss-2.0506, acc-0.5200, valid loss-2.0637, acc-0.4514, test loss-2.0438, acc-0.4627\n",
      "Iter-35930, train loss-2.1123, acc-0.3000, valid loss-2.0637, acc-0.4516, test loss-2.0438, acc-0.4627\n",
      "Iter-35940, train loss-2.0824, acc-0.4000, valid loss-2.0636, acc-0.4516, test loss-2.0437, acc-0.4629\n",
      "Iter-35950, train loss-2.0243, acc-0.6200, valid loss-2.0636, acc-0.4518, test loss-2.0437, acc-0.4627\n",
      "Iter-35960, train loss-2.0475, acc-0.4800, valid loss-2.0635, acc-0.4514, test loss-2.0436, acc-0.4628\n",
      "Iter-35970, train loss-2.0533, acc-0.5400, valid loss-2.0635, acc-0.4510, test loss-2.0436, acc-0.4627\n",
      "Iter-35980, train loss-2.0713, acc-0.4600, valid loss-2.0634, acc-0.4510, test loss-2.0435, acc-0.4628\n",
      "Iter-35990, train loss-2.0802, acc-0.4200, valid loss-2.0634, acc-0.4512, test loss-2.0435, acc-0.4628\n",
      "Iter-36000, train loss-2.0932, acc-0.3800, valid loss-2.0633, acc-0.4514, test loss-2.0434, acc-0.4627\n",
      "Iter-36010, train loss-2.0374, acc-0.4800, valid loss-2.0633, acc-0.4514, test loss-2.0434, acc-0.4628\n",
      "Iter-36020, train loss-2.1157, acc-0.3600, valid loss-2.0632, acc-0.4514, test loss-2.0433, acc-0.4627\n",
      "Iter-36030, train loss-2.0152, acc-0.5000, valid loss-2.0632, acc-0.4516, test loss-2.0432, acc-0.4628\n",
      "Iter-36040, train loss-2.0882, acc-0.4400, valid loss-2.0631, acc-0.4512, test loss-2.0432, acc-0.4630\n",
      "Iter-36050, train loss-2.0606, acc-0.4000, valid loss-2.0631, acc-0.4512, test loss-2.0431, acc-0.4631\n",
      "Iter-36060, train loss-2.0813, acc-0.3600, valid loss-2.0630, acc-0.4512, test loss-2.0431, acc-0.4632\n",
      "Iter-36070, train loss-2.0557, acc-0.5200, valid loss-2.0630, acc-0.4510, test loss-2.0430, acc-0.4632\n",
      "Iter-36080, train loss-2.0854, acc-0.4400, valid loss-2.0629, acc-0.4510, test loss-2.0430, acc-0.4630\n",
      "Iter-36090, train loss-2.0683, acc-0.4000, valid loss-2.0629, acc-0.4508, test loss-2.0429, acc-0.4630\n",
      "Iter-36100, train loss-2.1027, acc-0.3800, valid loss-2.0628, acc-0.4510, test loss-2.0429, acc-0.4632\n",
      "Iter-36110, train loss-2.0342, acc-0.4400, valid loss-2.0628, acc-0.4510, test loss-2.0428, acc-0.4633\n",
      "Iter-36120, train loss-2.0663, acc-0.4200, valid loss-2.0627, acc-0.4510, test loss-2.0428, acc-0.4632\n",
      "Iter-36130, train loss-2.0765, acc-0.4000, valid loss-2.0627, acc-0.4512, test loss-2.0427, acc-0.4631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36140, train loss-2.0379, acc-0.4600, valid loss-2.0626, acc-0.4514, test loss-2.0427, acc-0.4634\n",
      "Iter-36150, train loss-2.0428, acc-0.4600, valid loss-2.0626, acc-0.4514, test loss-2.0426, acc-0.4634\n",
      "Iter-36160, train loss-2.0331, acc-0.5000, valid loss-2.0625, acc-0.4514, test loss-2.0426, acc-0.4634\n",
      "Iter-36170, train loss-2.0156, acc-0.4000, valid loss-2.0625, acc-0.4508, test loss-2.0425, acc-0.4635\n",
      "Iter-36180, train loss-2.0435, acc-0.4800, valid loss-2.0624, acc-0.4510, test loss-2.0424, acc-0.4638\n",
      "Iter-36190, train loss-2.0339, acc-0.5000, valid loss-2.0624, acc-0.4510, test loss-2.0424, acc-0.4638\n",
      "Iter-36200, train loss-2.0722, acc-0.4200, valid loss-2.0623, acc-0.4514, test loss-2.0423, acc-0.4640\n",
      "Iter-36210, train loss-2.0981, acc-0.3200, valid loss-2.0623, acc-0.4516, test loss-2.0423, acc-0.4638\n",
      "Iter-36220, train loss-2.0408, acc-0.4400, valid loss-2.0622, acc-0.4514, test loss-2.0422, acc-0.4638\n",
      "Iter-36230, train loss-1.9945, acc-0.5800, valid loss-2.0622, acc-0.4516, test loss-2.0422, acc-0.4636\n",
      "Iter-36240, train loss-2.0687, acc-0.4400, valid loss-2.0621, acc-0.4514, test loss-2.0421, acc-0.4640\n",
      "Iter-36250, train loss-2.0462, acc-0.4200, valid loss-2.0621, acc-0.4514, test loss-2.0421, acc-0.4641\n",
      "Iter-36260, train loss-2.0384, acc-0.4400, valid loss-2.0620, acc-0.4514, test loss-2.0420, acc-0.4640\n",
      "Iter-36270, train loss-2.0369, acc-0.5400, valid loss-2.0620, acc-0.4516, test loss-2.0419, acc-0.4641\n",
      "Iter-36280, train loss-2.0436, acc-0.4400, valid loss-2.0619, acc-0.4514, test loss-2.0419, acc-0.4643\n",
      "Iter-36290, train loss-2.0628, acc-0.3800, valid loss-2.0619, acc-0.4520, test loss-2.0418, acc-0.4643\n",
      "Iter-36300, train loss-2.0819, acc-0.4400, valid loss-2.0618, acc-0.4514, test loss-2.0418, acc-0.4641\n",
      "Iter-36310, train loss-2.0558, acc-0.5000, valid loss-2.0618, acc-0.4516, test loss-2.0417, acc-0.4638\n",
      "Iter-36320, train loss-2.0230, acc-0.5800, valid loss-2.0617, acc-0.4516, test loss-2.0417, acc-0.4638\n",
      "Iter-36330, train loss-2.0587, acc-0.4400, valid loss-2.0617, acc-0.4514, test loss-2.0416, acc-0.4637\n",
      "Iter-36340, train loss-2.0365, acc-0.4000, valid loss-2.0616, acc-0.4514, test loss-2.0416, acc-0.4636\n",
      "Iter-36350, train loss-2.0169, acc-0.5000, valid loss-2.0616, acc-0.4516, test loss-2.0415, acc-0.4637\n",
      "Iter-36360, train loss-2.0377, acc-0.4400, valid loss-2.0615, acc-0.4506, test loss-2.0415, acc-0.4638\n",
      "Iter-36370, train loss-2.0274, acc-0.4600, valid loss-2.0615, acc-0.4508, test loss-2.0414, acc-0.4639\n",
      "Iter-36380, train loss-2.0395, acc-0.4400, valid loss-2.0614, acc-0.4508, test loss-2.0414, acc-0.4640\n",
      "Iter-36390, train loss-2.0491, acc-0.4800, valid loss-2.0614, acc-0.4508, test loss-2.0413, acc-0.4641\n",
      "Iter-36400, train loss-2.0198, acc-0.4400, valid loss-2.0614, acc-0.4508, test loss-2.0413, acc-0.4640\n",
      "Iter-36410, train loss-2.0811, acc-0.4000, valid loss-2.0613, acc-0.4508, test loss-2.0412, acc-0.4641\n",
      "Iter-36420, train loss-2.0351, acc-0.4800, valid loss-2.0613, acc-0.4506, test loss-2.0412, acc-0.4641\n",
      "Iter-36430, train loss-1.9833, acc-0.5800, valid loss-2.0612, acc-0.4508, test loss-2.0411, acc-0.4640\n",
      "Iter-36440, train loss-1.9674, acc-0.5600, valid loss-2.0612, acc-0.4508, test loss-2.0411, acc-0.4640\n",
      "Iter-36450, train loss-2.0421, acc-0.5000, valid loss-2.0611, acc-0.4512, test loss-2.0410, acc-0.4643\n",
      "Iter-36460, train loss-2.0572, acc-0.3400, valid loss-2.0611, acc-0.4512, test loss-2.0409, acc-0.4646\n",
      "Iter-36470, train loss-2.0207, acc-0.4400, valid loss-2.0610, acc-0.4508, test loss-2.0409, acc-0.4643\n",
      "Iter-36480, train loss-2.1038, acc-0.3800, valid loss-2.0610, acc-0.4508, test loss-2.0408, acc-0.4642\n",
      "Iter-36490, train loss-2.0213, acc-0.5600, valid loss-2.0609, acc-0.4510, test loss-2.0408, acc-0.4642\n",
      "Iter-36500, train loss-2.0642, acc-0.3800, valid loss-2.0609, acc-0.4512, test loss-2.0407, acc-0.4646\n",
      "Iter-36510, train loss-2.0523, acc-0.5000, valid loss-2.0608, acc-0.4508, test loss-2.0407, acc-0.4642\n",
      "Iter-36520, train loss-2.1199, acc-0.4400, valid loss-2.0608, acc-0.4510, test loss-2.0406, acc-0.4647\n",
      "Iter-36530, train loss-2.0388, acc-0.4000, valid loss-2.0607, acc-0.4512, test loss-2.0406, acc-0.4649\n",
      "Iter-36540, train loss-2.0126, acc-0.6000, valid loss-2.0607, acc-0.4512, test loss-2.0405, acc-0.4648\n",
      "Iter-36550, train loss-2.0604, acc-0.3800, valid loss-2.0606, acc-0.4510, test loss-2.0405, acc-0.4648\n",
      "Iter-36560, train loss-2.1295, acc-0.3200, valid loss-2.0606, acc-0.4510, test loss-2.0404, acc-0.4648\n",
      "Iter-36570, train loss-2.0724, acc-0.4400, valid loss-2.0606, acc-0.4512, test loss-2.0404, acc-0.4649\n",
      "Iter-36580, train loss-2.0313, acc-0.4800, valid loss-2.0605, acc-0.4516, test loss-2.0403, acc-0.4647\n",
      "Iter-36590, train loss-2.0263, acc-0.5200, valid loss-2.0605, acc-0.4516, test loss-2.0402, acc-0.4651\n",
      "Iter-36600, train loss-2.0597, acc-0.4000, valid loss-2.0604, acc-0.4516, test loss-2.0402, acc-0.4648\n",
      "Iter-36610, train loss-2.0958, acc-0.4200, valid loss-2.0604, acc-0.4516, test loss-2.0401, acc-0.4651\n",
      "Iter-36620, train loss-1.9985, acc-0.5400, valid loss-2.0603, acc-0.4514, test loss-2.0401, acc-0.4656\n",
      "Iter-36630, train loss-2.0837, acc-0.3800, valid loss-2.0603, acc-0.4514, test loss-2.0400, acc-0.4655\n",
      "Iter-36640, train loss-1.9908, acc-0.4600, valid loss-2.0602, acc-0.4514, test loss-2.0400, acc-0.4656\n",
      "Iter-36650, train loss-2.0815, acc-0.4600, valid loss-2.0602, acc-0.4514, test loss-2.0399, acc-0.4656\n",
      "Iter-36660, train loss-2.0342, acc-0.3800, valid loss-2.0601, acc-0.4518, test loss-2.0399, acc-0.4658\n",
      "Iter-36670, train loss-2.0776, acc-0.4200, valid loss-2.0601, acc-0.4514, test loss-2.0398, acc-0.4658\n",
      "Iter-36680, train loss-2.0282, acc-0.5400, valid loss-2.0600, acc-0.4518, test loss-2.0398, acc-0.4658\n",
      "Iter-36690, train loss-1.9929, acc-0.6000, valid loss-2.0600, acc-0.4518, test loss-2.0397, acc-0.4659\n",
      "Iter-36700, train loss-2.0595, acc-0.4200, valid loss-2.0599, acc-0.4518, test loss-2.0397, acc-0.4656\n",
      "Iter-36710, train loss-2.0157, acc-0.4800, valid loss-2.0599, acc-0.4520, test loss-2.0396, acc-0.4658\n",
      "Iter-36720, train loss-2.0164, acc-0.4400, valid loss-2.0598, acc-0.4520, test loss-2.0396, acc-0.4655\n",
      "Iter-36730, train loss-2.0273, acc-0.5400, valid loss-2.0598, acc-0.4520, test loss-2.0395, acc-0.4658\n",
      "Iter-36740, train loss-2.0657, acc-0.3800, valid loss-2.0597, acc-0.4518, test loss-2.0394, acc-0.4657\n",
      "Iter-36750, train loss-2.0493, acc-0.4600, valid loss-2.0597, acc-0.4518, test loss-2.0394, acc-0.4656\n",
      "Iter-36760, train loss-2.0367, acc-0.5000, valid loss-2.0596, acc-0.4522, test loss-2.0393, acc-0.4659\n",
      "Iter-36770, train loss-2.0800, acc-0.4200, valid loss-2.0596, acc-0.4520, test loss-2.0393, acc-0.4657\n",
      "Iter-36780, train loss-2.0588, acc-0.4000, valid loss-2.0595, acc-0.4522, test loss-2.0392, acc-0.4658\n",
      "Iter-36790, train loss-2.0491, acc-0.4600, valid loss-2.0595, acc-0.4520, test loss-2.0392, acc-0.4657\n",
      "Iter-36800, train loss-2.0156, acc-0.5400, valid loss-2.0594, acc-0.4520, test loss-2.0391, acc-0.4657\n",
      "Iter-36810, train loss-2.0646, acc-0.4600, valid loss-2.0594, acc-0.4524, test loss-2.0391, acc-0.4658\n",
      "Iter-36820, train loss-2.0685, acc-0.4000, valid loss-2.0593, acc-0.4524, test loss-2.0390, acc-0.4661\n",
      "Iter-36830, train loss-2.0859, acc-0.4800, valid loss-2.0593, acc-0.4528, test loss-2.0389, acc-0.4662\n",
      "Iter-36840, train loss-2.0553, acc-0.5200, valid loss-2.0592, acc-0.4528, test loss-2.0389, acc-0.4662\n",
      "Iter-36850, train loss-1.9974, acc-0.5600, valid loss-2.0592, acc-0.4528, test loss-2.0388, acc-0.4662\n",
      "Iter-36860, train loss-2.0487, acc-0.5000, valid loss-2.0591, acc-0.4524, test loss-2.0388, acc-0.4661\n",
      "Iter-36870, train loss-2.1079, acc-0.3600, valid loss-2.0591, acc-0.4522, test loss-2.0387, acc-0.4663\n",
      "Iter-36880, train loss-2.0413, acc-0.4600, valid loss-2.0590, acc-0.4526, test loss-2.0387, acc-0.4663\n",
      "Iter-36890, train loss-2.1048, acc-0.4000, valid loss-2.0590, acc-0.4530, test loss-2.0386, acc-0.4662\n",
      "Iter-36900, train loss-2.0169, acc-0.5400, valid loss-2.0589, acc-0.4528, test loss-2.0386, acc-0.4664\n",
      "Iter-36910, train loss-2.0210, acc-0.5600, valid loss-2.0589, acc-0.4526, test loss-2.0385, acc-0.4664\n",
      "Iter-36920, train loss-2.0310, acc-0.5600, valid loss-2.0589, acc-0.4524, test loss-2.0385, acc-0.4663\n",
      "Iter-36930, train loss-2.0576, acc-0.5000, valid loss-2.0588, acc-0.4526, test loss-2.0384, acc-0.4664\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36940, train loss-1.9920, acc-0.5600, valid loss-2.0587, acc-0.4532, test loss-2.0384, acc-0.4663\n",
      "Iter-36950, train loss-2.0666, acc-0.3800, valid loss-2.0587, acc-0.4528, test loss-2.0383, acc-0.4663\n",
      "Iter-36960, train loss-2.1252, acc-0.3800, valid loss-2.0587, acc-0.4530, test loss-2.0383, acc-0.4665\n",
      "Iter-36970, train loss-1.9939, acc-0.5400, valid loss-2.0586, acc-0.4530, test loss-2.0382, acc-0.4668\n",
      "Iter-36980, train loss-2.0513, acc-0.4800, valid loss-2.0585, acc-0.4530, test loss-2.0381, acc-0.4667\n",
      "Iter-36990, train loss-2.0902, acc-0.3400, valid loss-2.0585, acc-0.4528, test loss-2.0381, acc-0.4668\n",
      "Iter-37000, train loss-2.0624, acc-0.5000, valid loss-2.0584, acc-0.4530, test loss-2.0380, acc-0.4668\n",
      "Iter-37010, train loss-2.0681, acc-0.4200, valid loss-2.0584, acc-0.4530, test loss-2.0380, acc-0.4668\n",
      "Iter-37020, train loss-2.1349, acc-0.3800, valid loss-2.0584, acc-0.4540, test loss-2.0379, acc-0.4671\n",
      "Iter-37030, train loss-2.0469, acc-0.4800, valid loss-2.0583, acc-0.4538, test loss-2.0379, acc-0.4669\n",
      "Iter-37040, train loss-2.0448, acc-0.4600, valid loss-2.0583, acc-0.4538, test loss-2.0378, acc-0.4672\n",
      "Iter-37050, train loss-2.0205, acc-0.4600, valid loss-2.0582, acc-0.4538, test loss-2.0378, acc-0.4673\n",
      "Iter-37060, train loss-2.0470, acc-0.4000, valid loss-2.0582, acc-0.4538, test loss-2.0377, acc-0.4668\n",
      "Iter-37070, train loss-2.0649, acc-0.3400, valid loss-2.0581, acc-0.4538, test loss-2.0377, acc-0.4667\n",
      "Iter-37080, train loss-1.9796, acc-0.6000, valid loss-2.0581, acc-0.4538, test loss-2.0376, acc-0.4672\n",
      "Iter-37090, train loss-2.0614, acc-0.4200, valid loss-2.0580, acc-0.4538, test loss-2.0376, acc-0.4672\n",
      "Iter-37100, train loss-2.0155, acc-0.5400, valid loss-2.0580, acc-0.4538, test loss-2.0375, acc-0.4672\n",
      "Iter-37110, train loss-2.0668, acc-0.4600, valid loss-2.0579, acc-0.4538, test loss-2.0375, acc-0.4673\n",
      "Iter-37120, train loss-2.0503, acc-0.5000, valid loss-2.0579, acc-0.4540, test loss-2.0374, acc-0.4672\n",
      "Iter-37130, train loss-2.0677, acc-0.4800, valid loss-2.0578, acc-0.4540, test loss-2.0374, acc-0.4672\n",
      "Iter-37140, train loss-2.0653, acc-0.3000, valid loss-2.0578, acc-0.4540, test loss-2.0373, acc-0.4672\n",
      "Iter-37150, train loss-2.0522, acc-0.4400, valid loss-2.0577, acc-0.4540, test loss-2.0372, acc-0.4670\n",
      "Iter-37160, train loss-2.1253, acc-0.3400, valid loss-2.0577, acc-0.4542, test loss-2.0372, acc-0.4672\n",
      "Iter-37170, train loss-1.9934, acc-0.5200, valid loss-2.0576, acc-0.4542, test loss-2.0371, acc-0.4673\n",
      "Iter-37180, train loss-2.0625, acc-0.4000, valid loss-2.0576, acc-0.4544, test loss-2.0371, acc-0.4673\n",
      "Iter-37190, train loss-2.0355, acc-0.4800, valid loss-2.0575, acc-0.4544, test loss-2.0370, acc-0.4672\n",
      "Iter-37200, train loss-2.1164, acc-0.2800, valid loss-2.0575, acc-0.4546, test loss-2.0370, acc-0.4672\n",
      "Iter-37210, train loss-2.0579, acc-0.5600, valid loss-2.0575, acc-0.4544, test loss-2.0369, acc-0.4673\n",
      "Iter-37220, train loss-2.1061, acc-0.3600, valid loss-2.0574, acc-0.4540, test loss-2.0369, acc-0.4674\n",
      "Iter-37230, train loss-2.0291, acc-0.4400, valid loss-2.0574, acc-0.4538, test loss-2.0368, acc-0.4675\n",
      "Iter-37240, train loss-2.0587, acc-0.5000, valid loss-2.0573, acc-0.4536, test loss-2.0368, acc-0.4676\n",
      "Iter-37250, train loss-2.0370, acc-0.4400, valid loss-2.0573, acc-0.4536, test loss-2.0367, acc-0.4676\n",
      "Iter-37260, train loss-2.0327, acc-0.4400, valid loss-2.0572, acc-0.4538, test loss-2.0367, acc-0.4674\n",
      "Iter-37270, train loss-2.0364, acc-0.5000, valid loss-2.0572, acc-0.4536, test loss-2.0366, acc-0.4675\n",
      "Iter-37280, train loss-2.0584, acc-0.4000, valid loss-2.0571, acc-0.4536, test loss-2.0366, acc-0.4675\n",
      "Iter-37290, train loss-2.0007, acc-0.4600, valid loss-2.0571, acc-0.4536, test loss-2.0365, acc-0.4676\n",
      "Iter-37300, train loss-2.0686, acc-0.4400, valid loss-2.0570, acc-0.4536, test loss-2.0364, acc-0.4676\n",
      "Iter-37310, train loss-2.0459, acc-0.4200, valid loss-2.0570, acc-0.4538, test loss-2.0364, acc-0.4676\n",
      "Iter-37320, train loss-2.0627, acc-0.5000, valid loss-2.0569, acc-0.4540, test loss-2.0363, acc-0.4678\n",
      "Iter-37330, train loss-2.0212, acc-0.4600, valid loss-2.0569, acc-0.4540, test loss-2.0363, acc-0.4677\n",
      "Iter-37340, train loss-1.9977, acc-0.5200, valid loss-2.0568, acc-0.4540, test loss-2.0362, acc-0.4676\n",
      "Iter-37350, train loss-2.0040, acc-0.5200, valid loss-2.0568, acc-0.4540, test loss-2.0362, acc-0.4679\n",
      "Iter-37360, train loss-2.0428, acc-0.4800, valid loss-2.0567, acc-0.4540, test loss-2.0361, acc-0.4678\n",
      "Iter-37370, train loss-2.0377, acc-0.5000, valid loss-2.0567, acc-0.4538, test loss-2.0361, acc-0.4678\n",
      "Iter-37380, train loss-2.0328, acc-0.5200, valid loss-2.0566, acc-0.4540, test loss-2.0360, acc-0.4677\n",
      "Iter-37390, train loss-2.0694, acc-0.4800, valid loss-2.0566, acc-0.4538, test loss-2.0360, acc-0.4677\n",
      "Iter-37400, train loss-2.0698, acc-0.4600, valid loss-2.0565, acc-0.4540, test loss-2.0359, acc-0.4676\n",
      "Iter-37410, train loss-2.0436, acc-0.4600, valid loss-2.0565, acc-0.4540, test loss-2.0359, acc-0.4676\n",
      "Iter-37420, train loss-2.0947, acc-0.3600, valid loss-2.0564, acc-0.4538, test loss-2.0358, acc-0.4678\n",
      "Iter-37430, train loss-2.0781, acc-0.4600, valid loss-2.0564, acc-0.4540, test loss-2.0358, acc-0.4676\n",
      "Iter-37440, train loss-1.9848, acc-0.5200, valid loss-2.0563, acc-0.4540, test loss-2.0357, acc-0.4676\n",
      "Iter-37450, train loss-2.0039, acc-0.4200, valid loss-2.0563, acc-0.4538, test loss-2.0357, acc-0.4672\n",
      "Iter-37460, train loss-2.0699, acc-0.5000, valid loss-2.0562, acc-0.4536, test loss-2.0356, acc-0.4672\n",
      "Iter-37470, train loss-2.0828, acc-0.3600, valid loss-2.0562, acc-0.4536, test loss-2.0355, acc-0.4674\n",
      "Iter-37480, train loss-2.0834, acc-0.3400, valid loss-2.0561, acc-0.4534, test loss-2.0355, acc-0.4676\n",
      "Iter-37490, train loss-2.0665, acc-0.4000, valid loss-2.0561, acc-0.4536, test loss-2.0354, acc-0.4675\n",
      "Iter-37500, train loss-2.0349, acc-0.4600, valid loss-2.0561, acc-0.4536, test loss-2.0354, acc-0.4677\n",
      "Iter-37510, train loss-2.0731, acc-0.4800, valid loss-2.0560, acc-0.4536, test loss-2.0353, acc-0.4677\n",
      "Iter-37520, train loss-2.1026, acc-0.4000, valid loss-2.0560, acc-0.4538, test loss-2.0353, acc-0.4679\n",
      "Iter-37530, train loss-2.0538, acc-0.5400, valid loss-2.0559, acc-0.4536, test loss-2.0352, acc-0.4678\n",
      "Iter-37540, train loss-2.0339, acc-0.5400, valid loss-2.0559, acc-0.4536, test loss-2.0352, acc-0.4678\n",
      "Iter-37550, train loss-2.0272, acc-0.5000, valid loss-2.0558, acc-0.4538, test loss-2.0351, acc-0.4678\n",
      "Iter-37560, train loss-2.0304, acc-0.5200, valid loss-2.0558, acc-0.4538, test loss-2.0351, acc-0.4679\n",
      "Iter-37570, train loss-2.0351, acc-0.5200, valid loss-2.0557, acc-0.4534, test loss-2.0350, acc-0.4678\n",
      "Iter-37580, train loss-2.0154, acc-0.5200, valid loss-2.0557, acc-0.4534, test loss-2.0350, acc-0.4680\n",
      "Iter-37590, train loss-2.0414, acc-0.4400, valid loss-2.0556, acc-0.4534, test loss-2.0349, acc-0.4678\n",
      "Iter-37600, train loss-2.0653, acc-0.4200, valid loss-2.0556, acc-0.4534, test loss-2.0349, acc-0.4680\n",
      "Iter-37610, train loss-2.0216, acc-0.5600, valid loss-2.0555, acc-0.4534, test loss-2.0348, acc-0.4680\n",
      "Iter-37620, train loss-2.0578, acc-0.5000, valid loss-2.0555, acc-0.4538, test loss-2.0348, acc-0.4680\n",
      "Iter-37630, train loss-2.0225, acc-0.4400, valid loss-2.0554, acc-0.4538, test loss-2.0347, acc-0.4676\n",
      "Iter-37640, train loss-2.0661, acc-0.5200, valid loss-2.0554, acc-0.4538, test loss-2.0347, acc-0.4681\n",
      "Iter-37650, train loss-2.0294, acc-0.4400, valid loss-2.0553, acc-0.4538, test loss-2.0346, acc-0.4681\n",
      "Iter-37660, train loss-2.0381, acc-0.4600, valid loss-2.0553, acc-0.4538, test loss-2.0346, acc-0.4682\n",
      "Iter-37670, train loss-2.0330, acc-0.5000, valid loss-2.0552, acc-0.4540, test loss-2.0345, acc-0.4682\n",
      "Iter-37680, train loss-2.0635, acc-0.4800, valid loss-2.0552, acc-0.4540, test loss-2.0344, acc-0.4682\n",
      "Iter-37690, train loss-2.0618, acc-0.4200, valid loss-2.0551, acc-0.4540, test loss-2.0344, acc-0.4682\n",
      "Iter-37700, train loss-2.0815, acc-0.4200, valid loss-2.0551, acc-0.4540, test loss-2.0343, acc-0.4681\n",
      "Iter-37710, train loss-2.0110, acc-0.5600, valid loss-2.0550, acc-0.4540, test loss-2.0343, acc-0.4683\n",
      "Iter-37720, train loss-2.1262, acc-0.4400, valid loss-2.0550, acc-0.4540, test loss-2.0342, acc-0.4684\n",
      "Iter-37730, train loss-2.1092, acc-0.4400, valid loss-2.0549, acc-0.4540, test loss-2.0342, acc-0.4683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-37740, train loss-2.0670, acc-0.4400, valid loss-2.0549, acc-0.4540, test loss-2.0341, acc-0.4685\n",
      "Iter-37750, train loss-2.0123, acc-0.5400, valid loss-2.0548, acc-0.4540, test loss-2.0341, acc-0.4682\n",
      "Iter-37760, train loss-2.0175, acc-0.4600, valid loss-2.0548, acc-0.4542, test loss-2.0340, acc-0.4680\n",
      "Iter-37770, train loss-2.0552, acc-0.4800, valid loss-2.0547, acc-0.4542, test loss-2.0340, acc-0.4680\n",
      "Iter-37780, train loss-1.9805, acc-0.5200, valid loss-2.0547, acc-0.4542, test loss-2.0339, acc-0.4684\n",
      "Iter-37790, train loss-2.0781, acc-0.3800, valid loss-2.0547, acc-0.4542, test loss-2.0339, acc-0.4683\n",
      "Iter-37800, train loss-2.0758, acc-0.4600, valid loss-2.0546, acc-0.4540, test loss-2.0338, acc-0.4685\n",
      "Iter-37810, train loss-2.0274, acc-0.4800, valid loss-2.0546, acc-0.4544, test loss-2.0338, acc-0.4686\n",
      "Iter-37820, train loss-2.0229, acc-0.5800, valid loss-2.0545, acc-0.4542, test loss-2.0337, acc-0.4683\n",
      "Iter-37830, train loss-2.0351, acc-0.5400, valid loss-2.0545, acc-0.4542, test loss-2.0337, acc-0.4685\n",
      "Iter-37840, train loss-2.0867, acc-0.4000, valid loss-2.0544, acc-0.4544, test loss-2.0336, acc-0.4686\n",
      "Iter-37850, train loss-2.1012, acc-0.4000, valid loss-2.0544, acc-0.4544, test loss-2.0336, acc-0.4684\n",
      "Iter-37860, train loss-1.9995, acc-0.5000, valid loss-2.0543, acc-0.4542, test loss-2.0335, acc-0.4683\n",
      "Iter-37870, train loss-2.0488, acc-0.5000, valid loss-2.0543, acc-0.4544, test loss-2.0334, acc-0.4683\n",
      "Iter-37880, train loss-2.0604, acc-0.3800, valid loss-2.0542, acc-0.4544, test loss-2.0334, acc-0.4685\n",
      "Iter-37890, train loss-2.0297, acc-0.5200, valid loss-2.0542, acc-0.4542, test loss-2.0333, acc-0.4683\n",
      "Iter-37900, train loss-2.0499, acc-0.4600, valid loss-2.0541, acc-0.4540, test loss-2.0333, acc-0.4685\n",
      "Iter-37910, train loss-2.1167, acc-0.4000, valid loss-2.0541, acc-0.4540, test loss-2.0332, acc-0.4685\n",
      "Iter-37920, train loss-2.0187, acc-0.4800, valid loss-2.0540, acc-0.4540, test loss-2.0332, acc-0.4685\n",
      "Iter-37930, train loss-2.0131, acc-0.5800, valid loss-2.0540, acc-0.4540, test loss-2.0331, acc-0.4686\n",
      "Iter-37940, train loss-2.0240, acc-0.5600, valid loss-2.0539, acc-0.4546, test loss-2.0331, acc-0.4682\n",
      "Iter-37950, train loss-2.0753, acc-0.4000, valid loss-2.0539, acc-0.4546, test loss-2.0330, acc-0.4682\n",
      "Iter-37960, train loss-2.0674, acc-0.4200, valid loss-2.0539, acc-0.4546, test loss-2.0330, acc-0.4684\n",
      "Iter-37970, train loss-2.0327, acc-0.4000, valid loss-2.0538, acc-0.4544, test loss-2.0329, acc-0.4688\n",
      "Iter-37980, train loss-2.0592, acc-0.4200, valid loss-2.0538, acc-0.4544, test loss-2.0329, acc-0.4685\n",
      "Iter-37990, train loss-2.0166, acc-0.4400, valid loss-2.0537, acc-0.4546, test loss-2.0328, acc-0.4683\n",
      "Iter-38000, train loss-2.0613, acc-0.4400, valid loss-2.0537, acc-0.4542, test loss-2.0328, acc-0.4684\n",
      "Iter-38010, train loss-2.0327, acc-0.5000, valid loss-2.0536, acc-0.4544, test loss-2.0327, acc-0.4686\n",
      "Iter-38020, train loss-2.0948, acc-0.3000, valid loss-2.0536, acc-0.4546, test loss-2.0327, acc-0.4685\n",
      "Iter-38030, train loss-1.9887, acc-0.5400, valid loss-2.0535, acc-0.4544, test loss-2.0326, acc-0.4685\n",
      "Iter-38040, train loss-2.0702, acc-0.4200, valid loss-2.0535, acc-0.4546, test loss-2.0326, acc-0.4688\n",
      "Iter-38050, train loss-2.1260, acc-0.4200, valid loss-2.0534, acc-0.4548, test loss-2.0325, acc-0.4689\n",
      "Iter-38060, train loss-2.0518, acc-0.4200, valid loss-2.0534, acc-0.4550, test loss-2.0325, acc-0.4689\n",
      "Iter-38070, train loss-2.0150, acc-0.4800, valid loss-2.0533, acc-0.4546, test loss-2.0324, acc-0.4688\n",
      "Iter-38080, train loss-2.0652, acc-0.4200, valid loss-2.0533, acc-0.4550, test loss-2.0324, acc-0.4688\n",
      "Iter-38090, train loss-1.9697, acc-0.5400, valid loss-2.0532, acc-0.4550, test loss-2.0323, acc-0.4685\n",
      "Iter-38100, train loss-2.0444, acc-0.5000, valid loss-2.0532, acc-0.4550, test loss-2.0323, acc-0.4685\n",
      "Iter-38110, train loss-2.0383, acc-0.5200, valid loss-2.0531, acc-0.4554, test loss-2.0322, acc-0.4687\n",
      "Iter-38120, train loss-2.0047, acc-0.5400, valid loss-2.0531, acc-0.4554, test loss-2.0321, acc-0.4687\n",
      "Iter-38130, train loss-2.1198, acc-0.3400, valid loss-2.0530, acc-0.4556, test loss-2.0321, acc-0.4689\n",
      "Iter-38140, train loss-2.0866, acc-0.5200, valid loss-2.0530, acc-0.4550, test loss-2.0321, acc-0.4688\n",
      "Iter-38150, train loss-2.0689, acc-0.4400, valid loss-2.0530, acc-0.4550, test loss-2.0320, acc-0.4689\n",
      "Iter-38160, train loss-2.1062, acc-0.3600, valid loss-2.0529, acc-0.4552, test loss-2.0319, acc-0.4688\n",
      "Iter-38170, train loss-2.0160, acc-0.4400, valid loss-2.0529, acc-0.4554, test loss-2.0319, acc-0.4686\n",
      "Iter-38180, train loss-2.0274, acc-0.4800, valid loss-2.0528, acc-0.4552, test loss-2.0318, acc-0.4688\n",
      "Iter-38190, train loss-2.0253, acc-0.4600, valid loss-2.0528, acc-0.4554, test loss-2.0318, acc-0.4687\n",
      "Iter-38200, train loss-2.0557, acc-0.3200, valid loss-2.0527, acc-0.4556, test loss-2.0317, acc-0.4688\n",
      "Iter-38210, train loss-2.0852, acc-0.4600, valid loss-2.0527, acc-0.4556, test loss-2.0317, acc-0.4688\n",
      "Iter-38220, train loss-2.0142, acc-0.5200, valid loss-2.0526, acc-0.4556, test loss-2.0316, acc-0.4686\n",
      "Iter-38230, train loss-2.0245, acc-0.4800, valid loss-2.0526, acc-0.4556, test loss-2.0316, acc-0.4687\n",
      "Iter-38240, train loss-2.0232, acc-0.4400, valid loss-2.0525, acc-0.4556, test loss-2.0315, acc-0.4691\n",
      "Iter-38250, train loss-2.0665, acc-0.4200, valid loss-2.0525, acc-0.4556, test loss-2.0315, acc-0.4686\n",
      "Iter-38260, train loss-2.0210, acc-0.4200, valid loss-2.0524, acc-0.4556, test loss-2.0314, acc-0.4687\n",
      "Iter-38270, train loss-2.1157, acc-0.2600, valid loss-2.0524, acc-0.4556, test loss-2.0314, acc-0.4688\n",
      "Iter-38280, train loss-2.0730, acc-0.4800, valid loss-2.0523, acc-0.4556, test loss-2.0313, acc-0.4689\n",
      "Iter-38290, train loss-2.0674, acc-0.4200, valid loss-2.0523, acc-0.4556, test loss-2.0313, acc-0.4687\n",
      "Iter-38300, train loss-2.0763, acc-0.3200, valid loss-2.0522, acc-0.4552, test loss-2.0312, acc-0.4686\n",
      "Iter-38310, train loss-1.9560, acc-0.5400, valid loss-2.0522, acc-0.4552, test loss-2.0312, acc-0.4688\n",
      "Iter-38320, train loss-2.0375, acc-0.4800, valid loss-2.0521, acc-0.4552, test loss-2.0311, acc-0.4687\n",
      "Iter-38330, train loss-2.0575, acc-0.4600, valid loss-2.0521, acc-0.4554, test loss-2.0311, acc-0.4682\n",
      "Iter-38340, train loss-2.0094, acc-0.5000, valid loss-2.0520, acc-0.4554, test loss-2.0310, acc-0.4685\n",
      "Iter-38350, train loss-2.0208, acc-0.4800, valid loss-2.0520, acc-0.4556, test loss-2.0310, acc-0.4686\n",
      "Iter-38360, train loss-2.0232, acc-0.5200, valid loss-2.0520, acc-0.4556, test loss-2.0309, acc-0.4686\n",
      "Iter-38370, train loss-1.9975, acc-0.5200, valid loss-2.0519, acc-0.4556, test loss-2.0309, acc-0.4688\n",
      "Iter-38380, train loss-2.0348, acc-0.4600, valid loss-2.0519, acc-0.4554, test loss-2.0308, acc-0.4687\n",
      "Iter-38390, train loss-2.0966, acc-0.3200, valid loss-2.0518, acc-0.4554, test loss-2.0308, acc-0.4690\n",
      "Iter-38400, train loss-2.0746, acc-0.3800, valid loss-2.0518, acc-0.4554, test loss-2.0307, acc-0.4687\n",
      "Iter-38410, train loss-2.0401, acc-0.4600, valid loss-2.0517, acc-0.4554, test loss-2.0307, acc-0.4687\n",
      "Iter-38420, train loss-2.0199, acc-0.4600, valid loss-2.0517, acc-0.4554, test loss-2.0306, acc-0.4690\n",
      "Iter-38430, train loss-1.9909, acc-0.4400, valid loss-2.0516, acc-0.4554, test loss-2.0305, acc-0.4691\n",
      "Iter-38440, train loss-2.1395, acc-0.3400, valid loss-2.0516, acc-0.4552, test loss-2.0305, acc-0.4693\n",
      "Iter-38450, train loss-2.0225, acc-0.4000, valid loss-2.0515, acc-0.4554, test loss-2.0304, acc-0.4689\n",
      "Iter-38460, train loss-2.0398, acc-0.3600, valid loss-2.0515, acc-0.4558, test loss-2.0304, acc-0.4691\n",
      "Iter-38470, train loss-2.0397, acc-0.4400, valid loss-2.0514, acc-0.4558, test loss-2.0303, acc-0.4688\n",
      "Iter-38480, train loss-2.0741, acc-0.3800, valid loss-2.0514, acc-0.4558, test loss-2.0303, acc-0.4692\n",
      "Iter-38490, train loss-2.0427, acc-0.4600, valid loss-2.0514, acc-0.4558, test loss-2.0302, acc-0.4690\n",
      "Iter-38500, train loss-2.0495, acc-0.5000, valid loss-2.0513, acc-0.4558, test loss-2.0302, acc-0.4690\n",
      "Iter-38510, train loss-2.0199, acc-0.4400, valid loss-2.0513, acc-0.4558, test loss-2.0301, acc-0.4693\n",
      "Iter-38520, train loss-2.0679, acc-0.5000, valid loss-2.0512, acc-0.4556, test loss-2.0301, acc-0.4690\n",
      "Iter-38530, train loss-2.0893, acc-0.4000, valid loss-2.0512, acc-0.4556, test loss-2.0300, acc-0.4690\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-38540, train loss-2.0442, acc-0.5000, valid loss-2.0511, acc-0.4558, test loss-2.0300, acc-0.4691\n",
      "Iter-38550, train loss-1.9635, acc-0.4400, valid loss-2.0511, acc-0.4558, test loss-2.0299, acc-0.4688\n",
      "Iter-38560, train loss-2.0771, acc-0.3600, valid loss-2.0510, acc-0.4558, test loss-2.0299, acc-0.4691\n",
      "Iter-38570, train loss-2.0248, acc-0.4600, valid loss-2.0510, acc-0.4554, test loss-2.0298, acc-0.4689\n",
      "Iter-38580, train loss-2.0351, acc-0.3800, valid loss-2.0509, acc-0.4554, test loss-2.0298, acc-0.4689\n",
      "Iter-38590, train loss-1.9483, acc-0.6200, valid loss-2.0509, acc-0.4556, test loss-2.0297, acc-0.4687\n",
      "Iter-38600, train loss-2.0921, acc-0.3600, valid loss-2.0508, acc-0.4556, test loss-2.0297, acc-0.4687\n",
      "Iter-38610, train loss-2.0519, acc-0.4400, valid loss-2.0508, acc-0.4554, test loss-2.0296, acc-0.4688\n",
      "Iter-38620, train loss-2.0096, acc-0.6200, valid loss-2.0507, acc-0.4556, test loss-2.0296, acc-0.4687\n",
      "Iter-38630, train loss-2.0082, acc-0.5800, valid loss-2.0507, acc-0.4554, test loss-2.0295, acc-0.4689\n",
      "Iter-38640, train loss-1.9658, acc-0.5400, valid loss-2.0507, acc-0.4556, test loss-2.0295, acc-0.4688\n",
      "Iter-38650, train loss-2.0611, acc-0.4800, valid loss-2.0506, acc-0.4556, test loss-2.0294, acc-0.4690\n",
      "Iter-38660, train loss-2.0483, acc-0.4600, valid loss-2.0506, acc-0.4556, test loss-2.0294, acc-0.4691\n",
      "Iter-38670, train loss-2.0284, acc-0.5000, valid loss-2.0505, acc-0.4556, test loss-2.0293, acc-0.4690\n",
      "Iter-38680, train loss-2.0354, acc-0.4200, valid loss-2.0505, acc-0.4556, test loss-2.0293, acc-0.4691\n",
      "Iter-38690, train loss-2.0487, acc-0.4600, valid loss-2.0504, acc-0.4558, test loss-2.0292, acc-0.4692\n",
      "Iter-38700, train loss-2.0926, acc-0.4000, valid loss-2.0504, acc-0.4558, test loss-2.0292, acc-0.4695\n",
      "Iter-38710, train loss-2.0432, acc-0.5000, valid loss-2.0503, acc-0.4558, test loss-2.0291, acc-0.4696\n",
      "Iter-38720, train loss-2.0290, acc-0.4200, valid loss-2.0503, acc-0.4558, test loss-2.0290, acc-0.4695\n",
      "Iter-38730, train loss-2.0833, acc-0.4000, valid loss-2.0502, acc-0.4558, test loss-2.0290, acc-0.4696\n",
      "Iter-38740, train loss-2.0781, acc-0.4200, valid loss-2.0502, acc-0.4562, test loss-2.0289, acc-0.4699\n",
      "Iter-38750, train loss-2.0082, acc-0.4200, valid loss-2.0501, acc-0.4562, test loss-2.0289, acc-0.4699\n",
      "Iter-38760, train loss-2.0196, acc-0.4800, valid loss-2.0501, acc-0.4562, test loss-2.0288, acc-0.4699\n",
      "Iter-38770, train loss-2.0578, acc-0.5000, valid loss-2.0500, acc-0.4562, test loss-2.0288, acc-0.4699\n",
      "Iter-38780, train loss-2.0382, acc-0.4400, valid loss-2.0500, acc-0.4562, test loss-2.0287, acc-0.4697\n",
      "Iter-38790, train loss-2.0614, acc-0.3600, valid loss-2.0499, acc-0.4562, test loss-2.0287, acc-0.4698\n",
      "Iter-38800, train loss-2.1385, acc-0.3000, valid loss-2.0499, acc-0.4562, test loss-2.0286, acc-0.4701\n",
      "Iter-38810, train loss-2.0490, acc-0.5600, valid loss-2.0498, acc-0.4562, test loss-2.0286, acc-0.4699\n",
      "Iter-38820, train loss-1.9859, acc-0.5600, valid loss-2.0498, acc-0.4560, test loss-2.0285, acc-0.4700\n",
      "Iter-38830, train loss-2.0086, acc-0.4400, valid loss-2.0497, acc-0.4560, test loss-2.0285, acc-0.4701\n",
      "Iter-38840, train loss-2.1263, acc-0.4200, valid loss-2.0497, acc-0.4562, test loss-2.0284, acc-0.4701\n",
      "Iter-38850, train loss-2.0133, acc-0.4800, valid loss-2.0496, acc-0.4560, test loss-2.0284, acc-0.4702\n",
      "Iter-38860, train loss-2.0481, acc-0.4200, valid loss-2.0496, acc-0.4562, test loss-2.0283, acc-0.4698\n",
      "Iter-38870, train loss-2.0820, acc-0.4600, valid loss-2.0495, acc-0.4562, test loss-2.0283, acc-0.4702\n",
      "Iter-38880, train loss-2.0753, acc-0.5000, valid loss-2.0495, acc-0.4564, test loss-2.0282, acc-0.4700\n",
      "Iter-38890, train loss-2.0637, acc-0.4200, valid loss-2.0495, acc-0.4564, test loss-2.0282, acc-0.4702\n",
      "Iter-38900, train loss-2.0032, acc-0.4400, valid loss-2.0494, acc-0.4562, test loss-2.0281, acc-0.4702\n",
      "Iter-38910, train loss-2.0019, acc-0.4200, valid loss-2.0494, acc-0.4562, test loss-2.0280, acc-0.4703\n",
      "Iter-38920, train loss-2.0651, acc-0.5400, valid loss-2.0493, acc-0.4564, test loss-2.0280, acc-0.4702\n",
      "Iter-38930, train loss-2.1111, acc-0.3200, valid loss-2.0493, acc-0.4564, test loss-2.0279, acc-0.4704\n",
      "Iter-38940, train loss-2.0709, acc-0.4400, valid loss-2.0492, acc-0.4566, test loss-2.0279, acc-0.4705\n",
      "Iter-38950, train loss-2.0265, acc-0.4800, valid loss-2.0492, acc-0.4566, test loss-2.0278, acc-0.4704\n",
      "Iter-38960, train loss-2.0506, acc-0.5200, valid loss-2.0491, acc-0.4566, test loss-2.0278, acc-0.4704\n",
      "Iter-38970, train loss-2.0937, acc-0.2400, valid loss-2.0491, acc-0.4566, test loss-2.0277, acc-0.4705\n",
      "Iter-38980, train loss-2.0824, acc-0.4200, valid loss-2.0490, acc-0.4566, test loss-2.0277, acc-0.4704\n",
      "Iter-38990, train loss-2.0257, acc-0.5400, valid loss-2.0490, acc-0.4564, test loss-2.0276, acc-0.4706\n",
      "Iter-39000, train loss-2.0388, acc-0.4400, valid loss-2.0489, acc-0.4566, test loss-2.0276, acc-0.4704\n",
      "Iter-39010, train loss-2.0597, acc-0.4000, valid loss-2.0489, acc-0.4566, test loss-2.0275, acc-0.4704\n",
      "Iter-39020, train loss-2.0699, acc-0.3800, valid loss-2.0488, acc-0.4568, test loss-2.0275, acc-0.4704\n",
      "Iter-39030, train loss-1.9951, acc-0.5400, valid loss-2.0488, acc-0.4570, test loss-2.0274, acc-0.4704\n",
      "Iter-39040, train loss-2.0280, acc-0.4600, valid loss-2.0487, acc-0.4570, test loss-2.0274, acc-0.4703\n",
      "Iter-39050, train loss-1.9827, acc-0.5000, valid loss-2.0487, acc-0.4570, test loss-2.0273, acc-0.4703\n",
      "Iter-39060, train loss-2.0596, acc-0.3800, valid loss-2.0487, acc-0.4566, test loss-2.0273, acc-0.4704\n",
      "Iter-39070, train loss-2.0124, acc-0.4600, valid loss-2.0486, acc-0.4566, test loss-2.0272, acc-0.4704\n",
      "Iter-39080, train loss-2.0452, acc-0.5800, valid loss-2.0486, acc-0.4566, test loss-2.0272, acc-0.4704\n",
      "Iter-39090, train loss-2.0642, acc-0.4000, valid loss-2.0485, acc-0.4566, test loss-2.0271, acc-0.4706\n",
      "Iter-39100, train loss-1.9937, acc-0.4800, valid loss-2.0485, acc-0.4566, test loss-2.0271, acc-0.4706\n",
      "Iter-39110, train loss-2.0729, acc-0.4400, valid loss-2.0484, acc-0.4570, test loss-2.0270, acc-0.4707\n",
      "Iter-39120, train loss-2.0805, acc-0.4200, valid loss-2.0484, acc-0.4570, test loss-2.0270, acc-0.4707\n",
      "Iter-39130, train loss-2.0573, acc-0.4600, valid loss-2.0483, acc-0.4570, test loss-2.0269, acc-0.4706\n",
      "Iter-39140, train loss-2.1022, acc-0.3400, valid loss-2.0483, acc-0.4570, test loss-2.0269, acc-0.4707\n",
      "Iter-39150, train loss-2.0566, acc-0.4600, valid loss-2.0482, acc-0.4570, test loss-2.0268, acc-0.4708\n",
      "Iter-39160, train loss-1.9966, acc-0.5200, valid loss-2.0482, acc-0.4570, test loss-2.0268, acc-0.4706\n",
      "Iter-39170, train loss-2.0300, acc-0.4400, valid loss-2.0481, acc-0.4570, test loss-2.0267, acc-0.4704\n",
      "Iter-39180, train loss-2.0125, acc-0.5400, valid loss-2.0481, acc-0.4570, test loss-2.0267, acc-0.4705\n",
      "Iter-39190, train loss-2.0524, acc-0.3800, valid loss-2.0480, acc-0.4570, test loss-2.0266, acc-0.4704\n",
      "Iter-39200, train loss-2.0082, acc-0.6000, valid loss-2.0480, acc-0.4568, test loss-2.0265, acc-0.4706\n",
      "Iter-39210, train loss-2.0412, acc-0.5400, valid loss-2.0479, acc-0.4568, test loss-2.0265, acc-0.4706\n",
      "Iter-39220, train loss-2.0525, acc-0.4200, valid loss-2.0479, acc-0.4568, test loss-2.0264, acc-0.4706\n",
      "Iter-39230, train loss-1.9830, acc-0.5000, valid loss-2.0479, acc-0.4570, test loss-2.0264, acc-0.4707\n",
      "Iter-39240, train loss-2.0698, acc-0.3600, valid loss-2.0478, acc-0.4568, test loss-2.0263, acc-0.4705\n",
      "Iter-39250, train loss-2.0433, acc-0.5000, valid loss-2.0478, acc-0.4568, test loss-2.0263, acc-0.4705\n",
      "Iter-39260, train loss-2.0658, acc-0.3800, valid loss-2.0477, acc-0.4568, test loss-2.0262, acc-0.4708\n",
      "Iter-39270, train loss-2.0004, acc-0.4800, valid loss-2.0477, acc-0.4566, test loss-2.0262, acc-0.4708\n",
      "Iter-39280, train loss-2.0535, acc-0.5200, valid loss-2.0476, acc-0.4566, test loss-2.0261, acc-0.4707\n",
      "Iter-39290, train loss-1.9936, acc-0.4200, valid loss-2.0476, acc-0.4572, test loss-2.0261, acc-0.4709\n",
      "Iter-39300, train loss-2.0189, acc-0.5000, valid loss-2.0475, acc-0.4570, test loss-2.0260, acc-0.4709\n",
      "Iter-39310, train loss-2.0431, acc-0.5200, valid loss-2.0475, acc-0.4566, test loss-2.0260, acc-0.4707\n",
      "Iter-39320, train loss-1.9831, acc-0.6200, valid loss-2.0474, acc-0.4566, test loss-2.0259, acc-0.4709\n",
      "Iter-39330, train loss-1.9822, acc-0.5400, valid loss-2.0474, acc-0.4566, test loss-2.0259, acc-0.4708\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-39340, train loss-2.0755, acc-0.4800, valid loss-2.0473, acc-0.4566, test loss-2.0258, acc-0.4706\n",
      "Iter-39350, train loss-2.0745, acc-0.4600, valid loss-2.0473, acc-0.4566, test loss-2.0258, acc-0.4708\n",
      "Iter-39360, train loss-2.0612, acc-0.4000, valid loss-2.0473, acc-0.4566, test loss-2.0257, acc-0.4708\n",
      "Iter-39370, train loss-2.0645, acc-0.4600, valid loss-2.0472, acc-0.4568, test loss-2.0257, acc-0.4705\n",
      "Iter-39380, train loss-1.9838, acc-0.5200, valid loss-2.0471, acc-0.4570, test loss-2.0256, acc-0.4704\n",
      "Iter-39390, train loss-1.9558, acc-0.6400, valid loss-2.0471, acc-0.4568, test loss-2.0256, acc-0.4705\n",
      "Iter-39400, train loss-2.0005, acc-0.4800, valid loss-2.0471, acc-0.4568, test loss-2.0255, acc-0.4705\n",
      "Iter-39410, train loss-2.0818, acc-0.3600, valid loss-2.0470, acc-0.4566, test loss-2.0255, acc-0.4703\n",
      "Iter-39420, train loss-2.0641, acc-0.4600, valid loss-2.0470, acc-0.4566, test loss-2.0254, acc-0.4704\n",
      "Iter-39430, train loss-2.0086, acc-0.5800, valid loss-2.0469, acc-0.4566, test loss-2.0254, acc-0.4705\n",
      "Iter-39440, train loss-1.9701, acc-0.6200, valid loss-2.0469, acc-0.4568, test loss-2.0253, acc-0.4705\n",
      "Iter-39450, train loss-2.0296, acc-0.4000, valid loss-2.0468, acc-0.4568, test loss-2.0253, acc-0.4704\n",
      "Iter-39460, train loss-2.0157, acc-0.4400, valid loss-2.0468, acc-0.4566, test loss-2.0252, acc-0.4705\n",
      "Iter-39470, train loss-2.0608, acc-0.3800, valid loss-2.0467, acc-0.4568, test loss-2.0251, acc-0.4704\n",
      "Iter-39480, train loss-2.0462, acc-0.4200, valid loss-2.0467, acc-0.4566, test loss-2.0251, acc-0.4705\n",
      "Iter-39490, train loss-2.1082, acc-0.3600, valid loss-2.0466, acc-0.4566, test loss-2.0250, acc-0.4705\n",
      "Iter-39500, train loss-2.0210, acc-0.4200, valid loss-2.0466, acc-0.4568, test loss-2.0250, acc-0.4708\n",
      "Iter-39510, train loss-1.9961, acc-0.4600, valid loss-2.0465, acc-0.4570, test loss-2.0249, acc-0.4709\n",
      "Iter-39520, train loss-2.0472, acc-0.4200, valid loss-2.0465, acc-0.4574, test loss-2.0249, acc-0.4710\n",
      "Iter-39530, train loss-1.9940, acc-0.5000, valid loss-2.0465, acc-0.4574, test loss-2.0248, acc-0.4710\n",
      "Iter-39540, train loss-2.0075, acc-0.5400, valid loss-2.0464, acc-0.4568, test loss-2.0248, acc-0.4709\n",
      "Iter-39550, train loss-2.0400, acc-0.3200, valid loss-2.0464, acc-0.4576, test loss-2.0247, acc-0.4710\n",
      "Iter-39560, train loss-2.0351, acc-0.5000, valid loss-2.0463, acc-0.4576, test loss-2.0247, acc-0.4710\n",
      "Iter-39570, train loss-2.0427, acc-0.4000, valid loss-2.0463, acc-0.4574, test loss-2.0246, acc-0.4712\n",
      "Iter-39580, train loss-2.0647, acc-0.4200, valid loss-2.0462, acc-0.4574, test loss-2.0246, acc-0.4712\n",
      "Iter-39590, train loss-2.0183, acc-0.4600, valid loss-2.0462, acc-0.4574, test loss-2.0245, acc-0.4711\n",
      "Iter-39600, train loss-2.0513, acc-0.4400, valid loss-2.0461, acc-0.4574, test loss-2.0245, acc-0.4710\n",
      "Iter-39610, train loss-2.0092, acc-0.4800, valid loss-2.0461, acc-0.4574, test loss-2.0244, acc-0.4709\n",
      "Iter-39620, train loss-2.0340, acc-0.4400, valid loss-2.0461, acc-0.4574, test loss-2.0244, acc-0.4711\n",
      "Iter-39630, train loss-2.0204, acc-0.5000, valid loss-2.0460, acc-0.4574, test loss-2.0243, acc-0.4710\n",
      "Iter-39640, train loss-2.0435, acc-0.4000, valid loss-2.0460, acc-0.4574, test loss-2.0243, acc-0.4710\n",
      "Iter-39650, train loss-2.0453, acc-0.5600, valid loss-2.0459, acc-0.4576, test loss-2.0242, acc-0.4709\n",
      "Iter-39660, train loss-1.9950, acc-0.4600, valid loss-2.0459, acc-0.4574, test loss-2.0242, acc-0.4709\n",
      "Iter-39670, train loss-1.9866, acc-0.5400, valid loss-2.0458, acc-0.4574, test loss-2.0241, acc-0.4709\n",
      "Iter-39680, train loss-2.0578, acc-0.3800, valid loss-2.0458, acc-0.4574, test loss-2.0241, acc-0.4708\n",
      "Iter-39690, train loss-1.9878, acc-0.5200, valid loss-2.0457, acc-0.4576, test loss-2.0240, acc-0.4708\n",
      "Iter-39700, train loss-2.0456, acc-0.4600, valid loss-2.0457, acc-0.4578, test loss-2.0240, acc-0.4710\n",
      "Iter-39710, train loss-2.0025, acc-0.5400, valid loss-2.0456, acc-0.4574, test loss-2.0239, acc-0.4709\n",
      "Iter-39720, train loss-2.0297, acc-0.5800, valid loss-2.0456, acc-0.4572, test loss-2.0239, acc-0.4708\n",
      "Iter-39730, train loss-2.0390, acc-0.4800, valid loss-2.0455, acc-0.4572, test loss-2.0238, acc-0.4708\n",
      "Iter-39740, train loss-2.0051, acc-0.5000, valid loss-2.0455, acc-0.4572, test loss-2.0238, acc-0.4709\n",
      "Iter-39750, train loss-2.0683, acc-0.3200, valid loss-2.0454, acc-0.4574, test loss-2.0237, acc-0.4709\n",
      "Iter-39760, train loss-2.0637, acc-0.3800, valid loss-2.0454, acc-0.4574, test loss-2.0237, acc-0.4709\n",
      "Iter-39770, train loss-2.0976, acc-0.3400, valid loss-2.0454, acc-0.4576, test loss-2.0236, acc-0.4709\n",
      "Iter-39780, train loss-2.1032, acc-0.3600, valid loss-2.0453, acc-0.4578, test loss-2.0236, acc-0.4711\n",
      "Iter-39790, train loss-2.0672, acc-0.4000, valid loss-2.0453, acc-0.4580, test loss-2.0235, acc-0.4711\n",
      "Iter-39800, train loss-2.0084, acc-0.5600, valid loss-2.0452, acc-0.4580, test loss-2.0235, acc-0.4712\n",
      "Iter-39810, train loss-2.0867, acc-0.3600, valid loss-2.0452, acc-0.4580, test loss-2.0234, acc-0.4713\n",
      "Iter-39820, train loss-2.0304, acc-0.5400, valid loss-2.0451, acc-0.4582, test loss-2.0234, acc-0.4713\n",
      "Iter-39830, train loss-1.9913, acc-0.4600, valid loss-2.0451, acc-0.4580, test loss-2.0233, acc-0.4713\n",
      "Iter-39840, train loss-2.0530, acc-0.4800, valid loss-2.0450, acc-0.4584, test loss-2.0233, acc-0.4714\n",
      "Iter-39850, train loss-2.0434, acc-0.4800, valid loss-2.0450, acc-0.4582, test loss-2.0232, acc-0.4715\n",
      "Iter-39860, train loss-1.9780, acc-0.5400, valid loss-2.0449, acc-0.4580, test loss-2.0232, acc-0.4714\n",
      "Iter-39870, train loss-2.0020, acc-0.5000, valid loss-2.0449, acc-0.4578, test loss-2.0231, acc-0.4714\n",
      "Iter-39880, train loss-2.1068, acc-0.3600, valid loss-2.0449, acc-0.4580, test loss-2.0231, acc-0.4713\n",
      "Iter-39890, train loss-2.0511, acc-0.4600, valid loss-2.0448, acc-0.4580, test loss-2.0230, acc-0.4713\n",
      "Iter-39900, train loss-2.0548, acc-0.3600, valid loss-2.0448, acc-0.4578, test loss-2.0230, acc-0.4714\n",
      "Iter-39910, train loss-2.0085, acc-0.4400, valid loss-2.0447, acc-0.4576, test loss-2.0229, acc-0.4715\n",
      "Iter-39920, train loss-2.0549, acc-0.4800, valid loss-2.0447, acc-0.4576, test loss-2.0229, acc-0.4715\n",
      "Iter-39930, train loss-2.0081, acc-0.4600, valid loss-2.0446, acc-0.4580, test loss-2.0228, acc-0.4715\n",
      "Iter-39940, train loss-2.0365, acc-0.4400, valid loss-2.0446, acc-0.4582, test loss-2.0228, acc-0.4716\n",
      "Iter-39950, train loss-2.0191, acc-0.5200, valid loss-2.0445, acc-0.4582, test loss-2.0227, acc-0.4715\n",
      "Iter-39960, train loss-2.0774, acc-0.3600, valid loss-2.0445, acc-0.4582, test loss-2.0227, acc-0.4715\n",
      "Iter-39970, train loss-2.0008, acc-0.4800, valid loss-2.0444, acc-0.4582, test loss-2.0226, acc-0.4715\n",
      "Iter-39980, train loss-2.0697, acc-0.3400, valid loss-2.0444, acc-0.4580, test loss-2.0226, acc-0.4714\n",
      "Iter-39990, train loss-1.9990, acc-0.5200, valid loss-2.0443, acc-0.4582, test loss-2.0225, acc-0.4715\n",
      "Iter-40000, train loss-2.0880, acc-0.3200, valid loss-2.0443, acc-0.4582, test loss-2.0225, acc-0.4716\n",
      "Iter-40010, train loss-2.0485, acc-0.4600, valid loss-2.0442, acc-0.4584, test loss-2.0224, acc-0.4716\n",
      "Iter-40020, train loss-2.1013, acc-0.3000, valid loss-2.0442, acc-0.4584, test loss-2.0223, acc-0.4715\n",
      "Iter-40030, train loss-2.0093, acc-0.4800, valid loss-2.0441, acc-0.4584, test loss-2.0223, acc-0.4716\n",
      "Iter-40040, train loss-2.1181, acc-0.4200, valid loss-2.0441, acc-0.4584, test loss-2.0222, acc-0.4716\n",
      "Iter-40050, train loss-2.0613, acc-0.3600, valid loss-2.0441, acc-0.4582, test loss-2.0222, acc-0.4717\n",
      "Iter-40060, train loss-2.0047, acc-0.4400, valid loss-2.0440, acc-0.4582, test loss-2.0221, acc-0.4718\n",
      "Iter-40070, train loss-2.0821, acc-0.3800, valid loss-2.0440, acc-0.4582, test loss-2.0221, acc-0.4719\n",
      "Iter-40080, train loss-2.0895, acc-0.3400, valid loss-2.0439, acc-0.4582, test loss-2.0220, acc-0.4720\n",
      "Iter-40090, train loss-2.0353, acc-0.5200, valid loss-2.0439, acc-0.4582, test loss-2.0220, acc-0.4721\n",
      "Iter-40100, train loss-1.9881, acc-0.4800, valid loss-2.0438, acc-0.4584, test loss-2.0219, acc-0.4718\n",
      "Iter-40110, train loss-2.0565, acc-0.4200, valid loss-2.0438, acc-0.4584, test loss-2.0219, acc-0.4720\n",
      "Iter-40120, train loss-2.0116, acc-0.4600, valid loss-2.0437, acc-0.4584, test loss-2.0218, acc-0.4721\n",
      "Iter-40130, train loss-2.0145, acc-0.5200, valid loss-2.0437, acc-0.4586, test loss-2.0218, acc-0.4720\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40140, train loss-2.0106, acc-0.5400, valid loss-2.0436, acc-0.4584, test loss-2.0217, acc-0.4722\n",
      "Iter-40150, train loss-1.9762, acc-0.4600, valid loss-2.0436, acc-0.4586, test loss-2.0217, acc-0.4724\n",
      "Iter-40160, train loss-2.0297, acc-0.3800, valid loss-2.0435, acc-0.4588, test loss-2.0216, acc-0.4723\n",
      "Iter-40170, train loss-2.0085, acc-0.5200, valid loss-2.0435, acc-0.4588, test loss-2.0216, acc-0.4723\n",
      "Iter-40180, train loss-2.0110, acc-0.4000, valid loss-2.0434, acc-0.4586, test loss-2.0215, acc-0.4723\n",
      "Iter-40190, train loss-2.0260, acc-0.5800, valid loss-2.0434, acc-0.4584, test loss-2.0215, acc-0.4723\n",
      "Iter-40200, train loss-2.0347, acc-0.4400, valid loss-2.0434, acc-0.4586, test loss-2.0214, acc-0.4722\n",
      "Iter-40210, train loss-2.0923, acc-0.4600, valid loss-2.0433, acc-0.4588, test loss-2.0214, acc-0.4724\n",
      "Iter-40220, train loss-2.0355, acc-0.4200, valid loss-2.0433, acc-0.4586, test loss-2.0213, acc-0.4726\n",
      "Iter-40230, train loss-1.9852, acc-0.5000, valid loss-2.0432, acc-0.4588, test loss-2.0213, acc-0.4726\n",
      "Iter-40240, train loss-2.0308, acc-0.3600, valid loss-2.0432, acc-0.4588, test loss-2.0212, acc-0.4727\n",
      "Iter-40250, train loss-1.9827, acc-0.5600, valid loss-2.0431, acc-0.4590, test loss-2.0212, acc-0.4727\n",
      "Iter-40260, train loss-2.0109, acc-0.4800, valid loss-2.0431, acc-0.4590, test loss-2.0211, acc-0.4727\n",
      "Iter-40270, train loss-2.0337, acc-0.4400, valid loss-2.0430, acc-0.4592, test loss-2.0211, acc-0.4727\n",
      "Iter-40280, train loss-2.0278, acc-0.3800, valid loss-2.0430, acc-0.4596, test loss-2.0210, acc-0.4727\n",
      "Iter-40290, train loss-1.9923, acc-0.4200, valid loss-2.0429, acc-0.4594, test loss-2.0210, acc-0.4728\n",
      "Iter-40300, train loss-2.0118, acc-0.5400, valid loss-2.0429, acc-0.4594, test loss-2.0209, acc-0.4726\n",
      "Iter-40310, train loss-1.9937, acc-0.4800, valid loss-2.0428, acc-0.4590, test loss-2.0209, acc-0.4725\n",
      "Iter-40320, train loss-2.0194, acc-0.4200, valid loss-2.0428, acc-0.4592, test loss-2.0208, acc-0.4729\n",
      "Iter-40330, train loss-2.0115, acc-0.5000, valid loss-2.0428, acc-0.4592, test loss-2.0208, acc-0.4728\n",
      "Iter-40340, train loss-2.0211, acc-0.4000, valid loss-2.0427, acc-0.4592, test loss-2.0207, acc-0.4728\n",
      "Iter-40350, train loss-2.0471, acc-0.3600, valid loss-2.0427, acc-0.4594, test loss-2.0207, acc-0.4730\n",
      "Iter-40360, train loss-2.0457, acc-0.4800, valid loss-2.0426, acc-0.4594, test loss-2.0206, acc-0.4731\n",
      "Iter-40370, train loss-2.0546, acc-0.4000, valid loss-2.0426, acc-0.4594, test loss-2.0206, acc-0.4729\n",
      "Iter-40380, train loss-2.0192, acc-0.5000, valid loss-2.0425, acc-0.4592, test loss-2.0205, acc-0.4730\n",
      "Iter-40390, train loss-2.0758, acc-0.4000, valid loss-2.0425, acc-0.4594, test loss-2.0205, acc-0.4732\n",
      "Iter-40400, train loss-2.1382, acc-0.2600, valid loss-2.0424, acc-0.4592, test loss-2.0204, acc-0.4733\n",
      "Iter-40410, train loss-2.0513, acc-0.4600, valid loss-2.0424, acc-0.4590, test loss-2.0204, acc-0.4733\n",
      "Iter-40420, train loss-2.0524, acc-0.5000, valid loss-2.0423, acc-0.4590, test loss-2.0203, acc-0.4733\n",
      "Iter-40430, train loss-2.0544, acc-0.4200, valid loss-2.0423, acc-0.4592, test loss-2.0203, acc-0.4731\n",
      "Iter-40440, train loss-2.0426, acc-0.3800, valid loss-2.0423, acc-0.4590, test loss-2.0202, acc-0.4735\n",
      "Iter-40450, train loss-2.0211, acc-0.4600, valid loss-2.0422, acc-0.4592, test loss-2.0202, acc-0.4733\n",
      "Iter-40460, train loss-2.0385, acc-0.4000, valid loss-2.0422, acc-0.4592, test loss-2.0201, acc-0.4732\n",
      "Iter-40470, train loss-2.0181, acc-0.4800, valid loss-2.0421, acc-0.4592, test loss-2.0201, acc-0.4732\n",
      "Iter-40480, train loss-2.0423, acc-0.5200, valid loss-2.0421, acc-0.4596, test loss-2.0200, acc-0.4731\n",
      "Iter-40490, train loss-2.0049, acc-0.5600, valid loss-2.0420, acc-0.4596, test loss-2.0200, acc-0.4733\n",
      "Iter-40500, train loss-2.0009, acc-0.4200, valid loss-2.0420, acc-0.4598, test loss-2.0199, acc-0.4731\n",
      "Iter-40510, train loss-2.0161, acc-0.5200, valid loss-2.0419, acc-0.4596, test loss-2.0199, acc-0.4734\n",
      "Iter-40520, train loss-2.0686, acc-0.3600, valid loss-2.0419, acc-0.4596, test loss-2.0198, acc-0.4733\n",
      "Iter-40530, train loss-2.0663, acc-0.4400, valid loss-2.0419, acc-0.4596, test loss-2.0198, acc-0.4734\n",
      "Iter-40540, train loss-2.0555, acc-0.5000, valid loss-2.0418, acc-0.4596, test loss-2.0197, acc-0.4735\n",
      "Iter-40550, train loss-2.1073, acc-0.3800, valid loss-2.0418, acc-0.4596, test loss-2.0197, acc-0.4733\n",
      "Iter-40560, train loss-1.9938, acc-0.4600, valid loss-2.0417, acc-0.4596, test loss-2.0196, acc-0.4734\n",
      "Iter-40570, train loss-2.0421, acc-0.5000, valid loss-2.0417, acc-0.4596, test loss-2.0196, acc-0.4732\n",
      "Iter-40580, train loss-2.1078, acc-0.2600, valid loss-2.0416, acc-0.4596, test loss-2.0195, acc-0.4735\n",
      "Iter-40590, train loss-2.0338, acc-0.4600, valid loss-2.0416, acc-0.4594, test loss-2.0195, acc-0.4736\n",
      "Iter-40600, train loss-2.0114, acc-0.4800, valid loss-2.0415, acc-0.4594, test loss-2.0194, acc-0.4735\n",
      "Iter-40610, train loss-2.0801, acc-0.4200, valid loss-2.0415, acc-0.4594, test loss-2.0193, acc-0.4738\n",
      "Iter-40620, train loss-2.0181, acc-0.5200, valid loss-2.0414, acc-0.4592, test loss-2.0193, acc-0.4737\n",
      "Iter-40630, train loss-2.0422, acc-0.4200, valid loss-2.0414, acc-0.4592, test loss-2.0192, acc-0.4738\n",
      "Iter-40640, train loss-2.0976, acc-0.4000, valid loss-2.0413, acc-0.4594, test loss-2.0192, acc-0.4739\n",
      "Iter-40650, train loss-1.9994, acc-0.5000, valid loss-2.0413, acc-0.4594, test loss-2.0191, acc-0.4738\n",
      "Iter-40660, train loss-2.0028, acc-0.5800, valid loss-2.0413, acc-0.4594, test loss-2.0191, acc-0.4736\n",
      "Iter-40670, train loss-2.0769, acc-0.4000, valid loss-2.0412, acc-0.4594, test loss-2.0190, acc-0.4739\n",
      "Iter-40680, train loss-1.9998, acc-0.4800, valid loss-2.0412, acc-0.4594, test loss-2.0190, acc-0.4738\n",
      "Iter-40690, train loss-2.0479, acc-0.3200, valid loss-2.0411, acc-0.4594, test loss-2.0189, acc-0.4738\n",
      "Iter-40700, train loss-2.0611, acc-0.4600, valid loss-2.0411, acc-0.4594, test loss-2.0189, acc-0.4739\n",
      "Iter-40710, train loss-2.0359, acc-0.4800, valid loss-2.0410, acc-0.4598, test loss-2.0188, acc-0.4740\n",
      "Iter-40720, train loss-2.0152, acc-0.5200, valid loss-2.0410, acc-0.4600, test loss-2.0188, acc-0.4742\n",
      "Iter-40730, train loss-1.9884, acc-0.4000, valid loss-2.0409, acc-0.4606, test loss-2.0187, acc-0.4741\n",
      "Iter-40740, train loss-2.0683, acc-0.4200, valid loss-2.0409, acc-0.4606, test loss-2.0187, acc-0.4738\n",
      "Iter-40750, train loss-2.0222, acc-0.4800, valid loss-2.0408, acc-0.4608, test loss-2.0186, acc-0.4738\n",
      "Iter-40760, train loss-1.9935, acc-0.4400, valid loss-2.0408, acc-0.4610, test loss-2.0186, acc-0.4740\n",
      "Iter-40770, train loss-2.0012, acc-0.3800, valid loss-2.0407, acc-0.4608, test loss-2.0185, acc-0.4740\n",
      "Iter-40780, train loss-2.0902, acc-0.4800, valid loss-2.0407, acc-0.4608, test loss-2.0185, acc-0.4739\n",
      "Iter-40790, train loss-2.0558, acc-0.4000, valid loss-2.0407, acc-0.4608, test loss-2.0184, acc-0.4745\n",
      "Iter-40800, train loss-2.1185, acc-0.3600, valid loss-2.0406, acc-0.4608, test loss-2.0184, acc-0.4744\n",
      "Iter-40810, train loss-2.0434, acc-0.4600, valid loss-2.0406, acc-0.4602, test loss-2.0183, acc-0.4743\n",
      "Iter-40820, train loss-1.9767, acc-0.5600, valid loss-2.0405, acc-0.4606, test loss-2.0183, acc-0.4745\n",
      "Iter-40830, train loss-1.9632, acc-0.6200, valid loss-2.0405, acc-0.4602, test loss-2.0182, acc-0.4744\n",
      "Iter-40840, train loss-1.9887, acc-0.5200, valid loss-2.0404, acc-0.4602, test loss-2.0182, acc-0.4744\n",
      "Iter-40850, train loss-2.0396, acc-0.4600, valid loss-2.0404, acc-0.4610, test loss-2.0181, acc-0.4742\n",
      "Iter-40860, train loss-1.9834, acc-0.3800, valid loss-2.0403, acc-0.4612, test loss-2.0181, acc-0.4745\n",
      "Iter-40870, train loss-2.0455, acc-0.4800, valid loss-2.0403, acc-0.4610, test loss-2.0180, acc-0.4742\n",
      "Iter-40880, train loss-2.0285, acc-0.5000, valid loss-2.0402, acc-0.4608, test loss-2.0180, acc-0.4742\n",
      "Iter-40890, train loss-2.0294, acc-0.4600, valid loss-2.0402, acc-0.4610, test loss-2.0179, acc-0.4743\n",
      "Iter-40900, train loss-2.0335, acc-0.4200, valid loss-2.0402, acc-0.4612, test loss-2.0179, acc-0.4745\n",
      "Iter-40910, train loss-2.0168, acc-0.5000, valid loss-2.0401, acc-0.4614, test loss-2.0178, acc-0.4747\n",
      "Iter-40920, train loss-2.1172, acc-0.4000, valid loss-2.0401, acc-0.4616, test loss-2.0178, acc-0.4745\n",
      "Iter-40930, train loss-2.0665, acc-0.3200, valid loss-2.0400, acc-0.4612, test loss-2.0177, acc-0.4745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40940, train loss-2.0520, acc-0.4400, valid loss-2.0400, acc-0.4614, test loss-2.0177, acc-0.4745\n",
      "Iter-40950, train loss-1.9834, acc-0.5400, valid loss-2.0399, acc-0.4614, test loss-2.0176, acc-0.4747\n",
      "Iter-40960, train loss-2.0684, acc-0.4600, valid loss-2.0399, acc-0.4614, test loss-2.0176, acc-0.4745\n",
      "Iter-40970, train loss-2.0131, acc-0.5200, valid loss-2.0398, acc-0.4616, test loss-2.0175, acc-0.4745\n",
      "Iter-40980, train loss-1.9511, acc-0.5200, valid loss-2.0398, acc-0.4614, test loss-2.0175, acc-0.4748\n",
      "Iter-40990, train loss-2.0877, acc-0.3200, valid loss-2.0397, acc-0.4612, test loss-2.0174, acc-0.4750\n",
      "Iter-41000, train loss-2.0645, acc-0.5200, valid loss-2.0397, acc-0.4614, test loss-2.0174, acc-0.4750\n",
      "Iter-41010, train loss-2.0421, acc-0.5000, valid loss-2.0396, acc-0.4612, test loss-2.0173, acc-0.4749\n",
      "Iter-41020, train loss-2.0707, acc-0.3200, valid loss-2.0396, acc-0.4618, test loss-2.0173, acc-0.4751\n",
      "Iter-41030, train loss-2.0348, acc-0.3800, valid loss-2.0396, acc-0.4618, test loss-2.0172, acc-0.4751\n",
      "Iter-41040, train loss-2.0440, acc-0.4200, valid loss-2.0395, acc-0.4616, test loss-2.0172, acc-0.4750\n",
      "Iter-41050, train loss-1.9790, acc-0.5000, valid loss-2.0395, acc-0.4620, test loss-2.0171, acc-0.4751\n",
      "Iter-41060, train loss-2.0200, acc-0.4600, valid loss-2.0394, acc-0.4620, test loss-2.0171, acc-0.4752\n",
      "Iter-41070, train loss-1.9509, acc-0.6000, valid loss-2.0394, acc-0.4618, test loss-2.0170, acc-0.4752\n",
      "Iter-41080, train loss-1.9568, acc-0.4600, valid loss-2.0393, acc-0.4618, test loss-2.0170, acc-0.4755\n",
      "Iter-41090, train loss-2.0274, acc-0.4800, valid loss-2.0393, acc-0.4620, test loss-2.0169, acc-0.4755\n",
      "Iter-41100, train loss-2.0310, acc-0.3400, valid loss-2.0392, acc-0.4620, test loss-2.0169, acc-0.4754\n",
      "Iter-41110, train loss-2.0176, acc-0.3800, valid loss-2.0392, acc-0.4620, test loss-2.0168, acc-0.4755\n",
      "Iter-41120, train loss-2.0759, acc-0.4600, valid loss-2.0392, acc-0.4626, test loss-2.0168, acc-0.4756\n",
      "Iter-41130, train loss-1.9736, acc-0.6400, valid loss-2.0391, acc-0.4626, test loss-2.0167, acc-0.4756\n",
      "Iter-41140, train loss-1.9890, acc-0.4200, valid loss-2.0391, acc-0.4622, test loss-2.0167, acc-0.4758\n",
      "Iter-41150, train loss-1.9665, acc-0.5800, valid loss-2.0390, acc-0.4622, test loss-2.0166, acc-0.4753\n",
      "Iter-41160, train loss-1.9868, acc-0.5600, valid loss-2.0390, acc-0.4622, test loss-2.0166, acc-0.4753\n",
      "Iter-41170, train loss-2.0825, acc-0.4600, valid loss-2.0389, acc-0.4620, test loss-2.0165, acc-0.4753\n",
      "Iter-41180, train loss-2.0313, acc-0.4200, valid loss-2.0389, acc-0.4620, test loss-2.0165, acc-0.4755\n",
      "Iter-41190, train loss-2.0756, acc-0.3200, valid loss-2.0388, acc-0.4620, test loss-2.0164, acc-0.4755\n",
      "Iter-41200, train loss-2.0312, acc-0.4600, valid loss-2.0388, acc-0.4624, test loss-2.0164, acc-0.4756\n",
      "Iter-41210, train loss-2.0246, acc-0.4600, valid loss-2.0388, acc-0.4622, test loss-2.0163, acc-0.4755\n",
      "Iter-41220, train loss-1.9898, acc-0.5600, valid loss-2.0387, acc-0.4622, test loss-2.0163, acc-0.4758\n",
      "Iter-41230, train loss-2.0641, acc-0.4000, valid loss-2.0387, acc-0.4624, test loss-2.0162, acc-0.4756\n",
      "Iter-41240, train loss-2.0616, acc-0.4400, valid loss-2.0386, acc-0.4624, test loss-2.0162, acc-0.4755\n",
      "Iter-41250, train loss-2.0340, acc-0.3600, valid loss-2.0386, acc-0.4626, test loss-2.0161, acc-0.4756\n",
      "Iter-41260, train loss-2.0823, acc-0.3200, valid loss-2.0385, acc-0.4624, test loss-2.0161, acc-0.4757\n",
      "Iter-41270, train loss-2.0322, acc-0.4000, valid loss-2.0385, acc-0.4622, test loss-2.0160, acc-0.4758\n",
      "Iter-41280, train loss-2.0499, acc-0.5800, valid loss-2.0384, acc-0.4618, test loss-2.0160, acc-0.4756\n",
      "Iter-41290, train loss-1.9915, acc-0.4400, valid loss-2.0384, acc-0.4618, test loss-2.0159, acc-0.4755\n",
      "Iter-41300, train loss-2.0587, acc-0.4400, valid loss-2.0383, acc-0.4620, test loss-2.0159, acc-0.4755\n",
      "Iter-41310, train loss-2.0418, acc-0.4400, valid loss-2.0383, acc-0.4618, test loss-2.0158, acc-0.4754\n",
      "Iter-41320, train loss-2.0268, acc-0.4200, valid loss-2.0383, acc-0.4620, test loss-2.0158, acc-0.4752\n",
      "Iter-41330, train loss-2.0149, acc-0.4800, valid loss-2.0382, acc-0.4620, test loss-2.0157, acc-0.4754\n",
      "Iter-41340, train loss-2.0438, acc-0.4400, valid loss-2.0382, acc-0.4626, test loss-2.0157, acc-0.4756\n",
      "Iter-41350, train loss-2.0592, acc-0.3600, valid loss-2.0381, acc-0.4628, test loss-2.0156, acc-0.4757\n",
      "Iter-41360, train loss-2.0295, acc-0.5000, valid loss-2.0381, acc-0.4624, test loss-2.0156, acc-0.4757\n",
      "Iter-41370, train loss-2.0752, acc-0.4600, valid loss-2.0380, acc-0.4622, test loss-2.0155, acc-0.4756\n",
      "Iter-41380, train loss-2.0897, acc-0.4400, valid loss-2.0380, acc-0.4620, test loss-2.0155, acc-0.4755\n",
      "Iter-41390, train loss-2.0113, acc-0.5200, valid loss-2.0379, acc-0.4618, test loss-2.0154, acc-0.4755\n",
      "Iter-41400, train loss-1.9703, acc-0.5800, valid loss-2.0379, acc-0.4620, test loss-2.0154, acc-0.4755\n",
      "Iter-41410, train loss-2.0142, acc-0.5400, valid loss-2.0378, acc-0.4624, test loss-2.0153, acc-0.4755\n",
      "Iter-41420, train loss-1.9400, acc-0.5600, valid loss-2.0378, acc-0.4624, test loss-2.0153, acc-0.4756\n",
      "Iter-41430, train loss-2.0773, acc-0.3800, valid loss-2.0377, acc-0.4630, test loss-2.0152, acc-0.4757\n",
      "Iter-41440, train loss-2.0094, acc-0.5200, valid loss-2.0377, acc-0.4634, test loss-2.0152, acc-0.4757\n",
      "Iter-41450, train loss-2.0239, acc-0.5000, valid loss-2.0376, acc-0.4632, test loss-2.0151, acc-0.4757\n",
      "Iter-41460, train loss-2.0006, acc-0.4000, valid loss-2.0376, acc-0.4632, test loss-2.0151, acc-0.4755\n",
      "Iter-41470, train loss-2.0109, acc-0.4400, valid loss-2.0376, acc-0.4632, test loss-2.0150, acc-0.4757\n",
      "Iter-41480, train loss-2.0604, acc-0.4600, valid loss-2.0375, acc-0.4632, test loss-2.0150, acc-0.4753\n",
      "Iter-41490, train loss-1.9865, acc-0.4800, valid loss-2.0375, acc-0.4630, test loss-2.0149, acc-0.4754\n",
      "Iter-41500, train loss-2.1175, acc-0.3000, valid loss-2.0374, acc-0.4622, test loss-2.0149, acc-0.4754\n",
      "Iter-41510, train loss-2.0332, acc-0.4600, valid loss-2.0374, acc-0.4622, test loss-2.0148, acc-0.4753\n",
      "Iter-41520, train loss-1.9921, acc-0.5200, valid loss-2.0373, acc-0.4620, test loss-2.0148, acc-0.4753\n",
      "Iter-41530, train loss-2.0118, acc-0.4600, valid loss-2.0373, acc-0.4622, test loss-2.0147, acc-0.4751\n",
      "Iter-41540, train loss-2.0440, acc-0.4600, valid loss-2.0372, acc-0.4624, test loss-2.0147, acc-0.4751\n",
      "Iter-41550, train loss-1.9933, acc-0.5800, valid loss-2.0372, acc-0.4622, test loss-2.0146, acc-0.4752\n",
      "Iter-41560, train loss-1.9813, acc-0.4800, valid loss-2.0371, acc-0.4622, test loss-2.0146, acc-0.4751\n",
      "Iter-41570, train loss-1.9963, acc-0.4800, valid loss-2.0371, acc-0.4618, test loss-2.0145, acc-0.4749\n",
      "Iter-41580, train loss-2.0379, acc-0.4800, valid loss-2.0371, acc-0.4620, test loss-2.0145, acc-0.4752\n",
      "Iter-41590, train loss-2.0311, acc-0.4800, valid loss-2.0370, acc-0.4622, test loss-2.0144, acc-0.4751\n",
      "Iter-41600, train loss-1.9903, acc-0.5400, valid loss-2.0370, acc-0.4622, test loss-2.0144, acc-0.4750\n",
      "Iter-41610, train loss-2.0233, acc-0.4600, valid loss-2.0369, acc-0.4620, test loss-2.0143, acc-0.4752\n",
      "Iter-41620, train loss-2.0442, acc-0.4600, valid loss-2.0369, acc-0.4620, test loss-2.0143, acc-0.4751\n",
      "Iter-41630, train loss-2.0656, acc-0.2400, valid loss-2.0368, acc-0.4618, test loss-2.0142, acc-0.4753\n",
      "Iter-41640, train loss-2.0394, acc-0.4600, valid loss-2.0368, acc-0.4618, test loss-2.0142, acc-0.4751\n",
      "Iter-41650, train loss-2.0045, acc-0.4800, valid loss-2.0367, acc-0.4618, test loss-2.0142, acc-0.4752\n",
      "Iter-41660, train loss-1.9905, acc-0.5000, valid loss-2.0367, acc-0.4618, test loss-2.0141, acc-0.4751\n",
      "Iter-41670, train loss-2.0176, acc-0.5400, valid loss-2.0366, acc-0.4620, test loss-2.0141, acc-0.4753\n",
      "Iter-41680, train loss-1.9946, acc-0.5000, valid loss-2.0366, acc-0.4624, test loss-2.0140, acc-0.4752\n",
      "Iter-41690, train loss-2.0041, acc-0.4800, valid loss-2.0366, acc-0.4622, test loss-2.0140, acc-0.4752\n",
      "Iter-41700, train loss-1.9778, acc-0.4800, valid loss-2.0365, acc-0.4620, test loss-2.0139, acc-0.4752\n",
      "Iter-41710, train loss-2.0382, acc-0.5000, valid loss-2.0365, acc-0.4620, test loss-2.0139, acc-0.4752\n",
      "Iter-41720, train loss-2.0736, acc-0.3400, valid loss-2.0364, acc-0.4622, test loss-2.0138, acc-0.4752\n",
      "Iter-41730, train loss-2.0293, acc-0.5400, valid loss-2.0364, acc-0.4622, test loss-2.0138, acc-0.4752\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-41740, train loss-2.0551, acc-0.4400, valid loss-2.0363, acc-0.4622, test loss-2.0137, acc-0.4755\n",
      "Iter-41750, train loss-2.0122, acc-0.5400, valid loss-2.0363, acc-0.4622, test loss-2.0137, acc-0.4752\n",
      "Iter-41760, train loss-1.9991, acc-0.5400, valid loss-2.0362, acc-0.4620, test loss-2.0136, acc-0.4753\n",
      "Iter-41770, train loss-2.0217, acc-0.4000, valid loss-2.0362, acc-0.4622, test loss-2.0136, acc-0.4756\n",
      "Iter-41780, train loss-1.9793, acc-0.4400, valid loss-2.0362, acc-0.4618, test loss-2.0135, acc-0.4757\n",
      "Iter-41790, train loss-1.9464, acc-0.5000, valid loss-2.0361, acc-0.4620, test loss-2.0135, acc-0.4758\n",
      "Iter-41800, train loss-2.0501, acc-0.4600, valid loss-2.0361, acc-0.4622, test loss-2.0134, acc-0.4758\n",
      "Iter-41810, train loss-2.0176, acc-0.3600, valid loss-2.0360, acc-0.4624, test loss-2.0134, acc-0.4758\n",
      "Iter-41820, train loss-2.0045, acc-0.4800, valid loss-2.0360, acc-0.4624, test loss-2.0133, acc-0.4759\n",
      "Iter-41830, train loss-2.0166, acc-0.4400, valid loss-2.0359, acc-0.4622, test loss-2.0133, acc-0.4758\n",
      "Iter-41840, train loss-2.0049, acc-0.5200, valid loss-2.0359, acc-0.4624, test loss-2.0132, acc-0.4758\n",
      "Iter-41850, train loss-2.0404, acc-0.4800, valid loss-2.0358, acc-0.4622, test loss-2.0132, acc-0.4758\n",
      "Iter-41860, train loss-2.0135, acc-0.5200, valid loss-2.0358, acc-0.4622, test loss-2.0131, acc-0.4759\n",
      "Iter-41870, train loss-2.0210, acc-0.5600, valid loss-2.0357, acc-0.4622, test loss-2.0131, acc-0.4755\n",
      "Iter-41880, train loss-2.0021, acc-0.5000, valid loss-2.0357, acc-0.4620, test loss-2.0130, acc-0.4755\n",
      "Iter-41890, train loss-2.0200, acc-0.4800, valid loss-2.0356, acc-0.4620, test loss-2.0130, acc-0.4755\n",
      "Iter-41900, train loss-1.9843, acc-0.5200, valid loss-2.0356, acc-0.4620, test loss-2.0129, acc-0.4756\n",
      "Iter-41910, train loss-1.9853, acc-0.5000, valid loss-2.0356, acc-0.4622, test loss-2.0129, acc-0.4755\n",
      "Iter-41920, train loss-2.0340, acc-0.3800, valid loss-2.0355, acc-0.4618, test loss-2.0128, acc-0.4758\n",
      "Iter-41930, train loss-1.9526, acc-0.6200, valid loss-2.0355, acc-0.4624, test loss-2.0128, acc-0.4754\n",
      "Iter-41940, train loss-2.0604, acc-0.3400, valid loss-2.0354, acc-0.4628, test loss-2.0127, acc-0.4756\n",
      "Iter-41950, train loss-1.9933, acc-0.4400, valid loss-2.0354, acc-0.4628, test loss-2.0127, acc-0.4756\n",
      "Iter-41960, train loss-2.0438, acc-0.4400, valid loss-2.0353, acc-0.4626, test loss-2.0126, acc-0.4756\n",
      "Iter-41970, train loss-2.0918, acc-0.4600, valid loss-2.0353, acc-0.4626, test loss-2.0126, acc-0.4758\n",
      "Iter-41980, train loss-2.0550, acc-0.5000, valid loss-2.0352, acc-0.4630, test loss-2.0125, acc-0.4757\n",
      "Iter-41990, train loss-2.1142, acc-0.2600, valid loss-2.0352, acc-0.4626, test loss-2.0125, acc-0.4759\n",
      "Iter-42000, train loss-2.0002, acc-0.4800, valid loss-2.0351, acc-0.4622, test loss-2.0124, acc-0.4757\n",
      "Iter-42010, train loss-2.0512, acc-0.4600, valid loss-2.0351, acc-0.4622, test loss-2.0124, acc-0.4756\n",
      "Iter-42020, train loss-2.0737, acc-0.3800, valid loss-2.0351, acc-0.4618, test loss-2.0123, acc-0.4757\n",
      "Iter-42030, train loss-2.0279, acc-0.4800, valid loss-2.0350, acc-0.4618, test loss-2.0123, acc-0.4758\n",
      "Iter-42040, train loss-2.0477, acc-0.4400, valid loss-2.0350, acc-0.4618, test loss-2.0122, acc-0.4759\n",
      "Iter-42050, train loss-1.9842, acc-0.4800, valid loss-2.0349, acc-0.4616, test loss-2.0122, acc-0.4757\n",
      "Iter-42060, train loss-2.0874, acc-0.4200, valid loss-2.0349, acc-0.4616, test loss-2.0121, acc-0.4758\n",
      "Iter-42070, train loss-1.9612, acc-0.4600, valid loss-2.0348, acc-0.4618, test loss-2.0121, acc-0.4758\n",
      "Iter-42080, train loss-2.0337, acc-0.4200, valid loss-2.0348, acc-0.4620, test loss-2.0120, acc-0.4759\n",
      "Iter-42090, train loss-2.0232, acc-0.3800, valid loss-2.0347, acc-0.4616, test loss-2.0120, acc-0.4760\n",
      "Iter-42100, train loss-1.9856, acc-0.5000, valid loss-2.0347, acc-0.4620, test loss-2.0119, acc-0.4761\n",
      "Iter-42110, train loss-1.9477, acc-0.5000, valid loss-2.0347, acc-0.4618, test loss-2.0119, acc-0.4760\n",
      "Iter-42120, train loss-1.9783, acc-0.4600, valid loss-2.0346, acc-0.4618, test loss-2.0118, acc-0.4760\n",
      "Iter-42130, train loss-1.9813, acc-0.5000, valid loss-2.0346, acc-0.4622, test loss-2.0118, acc-0.4761\n",
      "Iter-42140, train loss-2.0251, acc-0.4400, valid loss-2.0345, acc-0.4622, test loss-2.0117, acc-0.4761\n",
      "Iter-42150, train loss-2.0782, acc-0.4400, valid loss-2.0345, acc-0.4620, test loss-2.0117, acc-0.4761\n",
      "Iter-42160, train loss-2.0683, acc-0.3400, valid loss-2.0344, acc-0.4618, test loss-2.0116, acc-0.4760\n",
      "Iter-42170, train loss-2.0138, acc-0.4000, valid loss-2.0344, acc-0.4620, test loss-2.0116, acc-0.4759\n",
      "Iter-42180, train loss-1.9848, acc-0.5000, valid loss-2.0344, acc-0.4632, test loss-2.0115, acc-0.4761\n",
      "Iter-42190, train loss-2.0115, acc-0.4800, valid loss-2.0343, acc-0.4634, test loss-2.0115, acc-0.4760\n",
      "Iter-42200, train loss-2.0169, acc-0.5800, valid loss-2.0343, acc-0.4632, test loss-2.0114, acc-0.4761\n",
      "Iter-42210, train loss-2.0207, acc-0.4800, valid loss-2.0342, acc-0.4636, test loss-2.0114, acc-0.4761\n",
      "Iter-42220, train loss-2.0715, acc-0.4000, valid loss-2.0342, acc-0.4636, test loss-2.0113, acc-0.4762\n",
      "Iter-42230, train loss-2.0999, acc-0.3600, valid loss-2.0341, acc-0.4636, test loss-2.0113, acc-0.4762\n",
      "Iter-42240, train loss-2.0124, acc-0.5200, valid loss-2.0341, acc-0.4636, test loss-2.0112, acc-0.4761\n",
      "Iter-42250, train loss-2.0996, acc-0.3400, valid loss-2.0341, acc-0.4634, test loss-2.0112, acc-0.4761\n",
      "Iter-42260, train loss-2.0488, acc-0.4000, valid loss-2.0340, acc-0.4636, test loss-2.0111, acc-0.4763\n",
      "Iter-42270, train loss-1.9541, acc-0.6400, valid loss-2.0340, acc-0.4636, test loss-2.0111, acc-0.4764\n",
      "Iter-42280, train loss-2.0587, acc-0.4200, valid loss-2.0339, acc-0.4634, test loss-2.0110, acc-0.4762\n",
      "Iter-42290, train loss-2.1248, acc-0.2600, valid loss-2.0339, acc-0.4634, test loss-2.0110, acc-0.4761\n",
      "Iter-42300, train loss-2.0872, acc-0.2800, valid loss-2.0338, acc-0.4634, test loss-2.0109, acc-0.4761\n",
      "Iter-42310, train loss-2.0022, acc-0.4000, valid loss-2.0338, acc-0.4634, test loss-2.0109, acc-0.4761\n",
      "Iter-42320, train loss-2.0230, acc-0.4200, valid loss-2.0337, acc-0.4634, test loss-2.0108, acc-0.4762\n",
      "Iter-42330, train loss-2.0192, acc-0.4800, valid loss-2.0337, acc-0.4632, test loss-2.0108, acc-0.4763\n",
      "Iter-42340, train loss-2.0277, acc-0.5200, valid loss-2.0337, acc-0.4634, test loss-2.0107, acc-0.4763\n",
      "Iter-42350, train loss-1.9502, acc-0.6000, valid loss-2.0336, acc-0.4634, test loss-2.0107, acc-0.4762\n",
      "Iter-42360, train loss-1.9727, acc-0.5000, valid loss-2.0336, acc-0.4630, test loss-2.0106, acc-0.4762\n",
      "Iter-42370, train loss-2.0924, acc-0.4200, valid loss-2.0335, acc-0.4630, test loss-2.0106, acc-0.4762\n",
      "Iter-42380, train loss-2.0006, acc-0.5200, valid loss-2.0335, acc-0.4632, test loss-2.0105, acc-0.4764\n",
      "Iter-42390, train loss-1.9958, acc-0.4800, valid loss-2.0334, acc-0.4632, test loss-2.0105, acc-0.4766\n",
      "Iter-42400, train loss-1.9706, acc-0.4600, valid loss-2.0334, acc-0.4630, test loss-2.0104, acc-0.4767\n",
      "Iter-42410, train loss-2.0083, acc-0.5200, valid loss-2.0333, acc-0.4632, test loss-2.0104, acc-0.4764\n",
      "Iter-42420, train loss-1.9963, acc-0.6200, valid loss-2.0333, acc-0.4630, test loss-2.0103, acc-0.4766\n",
      "Iter-42430, train loss-2.0726, acc-0.4200, valid loss-2.0332, acc-0.4630, test loss-2.0103, acc-0.4768\n",
      "Iter-42440, train loss-1.9940, acc-0.5400, valid loss-2.0332, acc-0.4632, test loss-2.0102, acc-0.4769\n",
      "Iter-42450, train loss-2.0504, acc-0.4600, valid loss-2.0331, acc-0.4636, test loss-2.0102, acc-0.4770\n",
      "Iter-42460, train loss-2.0214, acc-0.4400, valid loss-2.0331, acc-0.4638, test loss-2.0101, acc-0.4771\n",
      "Iter-42470, train loss-1.9920, acc-0.4800, valid loss-2.0331, acc-0.4640, test loss-2.0101, acc-0.4770\n",
      "Iter-42480, train loss-2.0177, acc-0.4200, valid loss-2.0330, acc-0.4638, test loss-2.0100, acc-0.4772\n",
      "Iter-42490, train loss-2.0600, acc-0.3200, valid loss-2.0330, acc-0.4636, test loss-2.0100, acc-0.4774\n",
      "Iter-42500, train loss-2.0684, acc-0.4800, valid loss-2.0329, acc-0.4642, test loss-2.0099, acc-0.4773\n",
      "Iter-42510, train loss-2.0103, acc-0.5400, valid loss-2.0329, acc-0.4638, test loss-2.0099, acc-0.4773\n",
      "Iter-42520, train loss-2.0544, acc-0.3800, valid loss-2.0328, acc-0.4640, test loss-2.0099, acc-0.4771\n",
      "Iter-42530, train loss-1.9354, acc-0.6000, valid loss-2.0328, acc-0.4640, test loss-2.0098, acc-0.4771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-42540, train loss-2.0282, acc-0.5000, valid loss-2.0327, acc-0.4640, test loss-2.0098, acc-0.4772\n",
      "Iter-42550, train loss-1.9391, acc-0.5400, valid loss-2.0327, acc-0.4640, test loss-2.0097, acc-0.4772\n",
      "Iter-42560, train loss-2.0280, acc-0.4800, valid loss-2.0327, acc-0.4638, test loss-2.0097, acc-0.4773\n",
      "Iter-42570, train loss-1.9817, acc-0.4600, valid loss-2.0326, acc-0.4642, test loss-2.0096, acc-0.4772\n",
      "Iter-42580, train loss-2.0061, acc-0.5000, valid loss-2.0326, acc-0.4642, test loss-2.0096, acc-0.4771\n",
      "Iter-42590, train loss-1.9718, acc-0.5200, valid loss-2.0325, acc-0.4642, test loss-2.0095, acc-0.4774\n",
      "Iter-42600, train loss-2.0469, acc-0.4600, valid loss-2.0325, acc-0.4638, test loss-2.0095, acc-0.4773\n",
      "Iter-42610, train loss-1.9890, acc-0.4600, valid loss-2.0324, acc-0.4640, test loss-2.0094, acc-0.4772\n",
      "Iter-42620, train loss-1.9876, acc-0.4600, valid loss-2.0324, acc-0.4640, test loss-2.0094, acc-0.4771\n",
      "Iter-42630, train loss-2.0906, acc-0.3600, valid loss-2.0323, acc-0.4638, test loss-2.0093, acc-0.4770\n",
      "Iter-42640, train loss-2.0124, acc-0.4600, valid loss-2.0323, acc-0.4636, test loss-2.0093, acc-0.4771\n",
      "Iter-42650, train loss-2.0240, acc-0.5200, valid loss-2.0322, acc-0.4636, test loss-2.0092, acc-0.4771\n",
      "Iter-42660, train loss-2.0429, acc-0.4800, valid loss-2.0322, acc-0.4632, test loss-2.0092, acc-0.4772\n",
      "Iter-42670, train loss-2.0507, acc-0.4400, valid loss-2.0322, acc-0.4632, test loss-2.0091, acc-0.4771\n",
      "Iter-42680, train loss-2.0143, acc-0.4200, valid loss-2.0321, acc-0.4636, test loss-2.0091, acc-0.4771\n",
      "Iter-42690, train loss-2.0301, acc-0.5200, valid loss-2.0321, acc-0.4636, test loss-2.0090, acc-0.4771\n",
      "Iter-42700, train loss-2.0167, acc-0.4000, valid loss-2.0320, acc-0.4636, test loss-2.0090, acc-0.4770\n",
      "Iter-42710, train loss-2.0204, acc-0.5200, valid loss-2.0320, acc-0.4638, test loss-2.0089, acc-0.4770\n",
      "Iter-42720, train loss-2.0293, acc-0.5800, valid loss-2.0319, acc-0.4636, test loss-2.0089, acc-0.4771\n",
      "Iter-42730, train loss-2.0405, acc-0.4400, valid loss-2.0319, acc-0.4638, test loss-2.0088, acc-0.4771\n",
      "Iter-42740, train loss-1.9955, acc-0.5400, valid loss-2.0318, acc-0.4636, test loss-2.0088, acc-0.4771\n",
      "Iter-42750, train loss-1.9726, acc-0.6000, valid loss-2.0318, acc-0.4638, test loss-2.0087, acc-0.4771\n",
      "Iter-42760, train loss-2.0024, acc-0.4600, valid loss-2.0317, acc-0.4636, test loss-2.0087, acc-0.4774\n",
      "Iter-42770, train loss-2.0479, acc-0.4200, valid loss-2.0317, acc-0.4638, test loss-2.0086, acc-0.4771\n",
      "Iter-42780, train loss-2.0333, acc-0.4600, valid loss-2.0317, acc-0.4638, test loss-2.0086, acc-0.4772\n",
      "Iter-42790, train loss-2.1076, acc-0.3400, valid loss-2.0316, acc-0.4638, test loss-2.0085, acc-0.4771\n",
      "Iter-42800, train loss-2.0005, acc-0.5200, valid loss-2.0316, acc-0.4638, test loss-2.0085, acc-0.4772\n",
      "Iter-42810, train loss-2.0414, acc-0.4600, valid loss-2.0315, acc-0.4638, test loss-2.0084, acc-0.4771\n",
      "Iter-42820, train loss-2.0087, acc-0.5000, valid loss-2.0315, acc-0.4644, test loss-2.0084, acc-0.4771\n",
      "Iter-42830, train loss-1.9871, acc-0.5400, valid loss-2.0314, acc-0.4638, test loss-2.0083, acc-0.4771\n",
      "Iter-42840, train loss-2.0287, acc-0.4200, valid loss-2.0314, acc-0.4640, test loss-2.0083, acc-0.4771\n",
      "Iter-42850, train loss-1.9899, acc-0.4200, valid loss-2.0313, acc-0.4640, test loss-2.0082, acc-0.4771\n",
      "Iter-42860, train loss-2.0067, acc-0.4600, valid loss-2.0313, acc-0.4642, test loss-2.0082, acc-0.4771\n",
      "Iter-42870, train loss-2.0551, acc-0.4600, valid loss-2.0312, acc-0.4642, test loss-2.0081, acc-0.4770\n",
      "Iter-42880, train loss-1.9778, acc-0.4600, valid loss-2.0312, acc-0.4634, test loss-2.0081, acc-0.4770\n",
      "Iter-42890, train loss-1.9940, acc-0.3800, valid loss-2.0311, acc-0.4640, test loss-2.0080, acc-0.4771\n",
      "Iter-42900, train loss-2.0205, acc-0.4200, valid loss-2.0311, acc-0.4640, test loss-2.0080, acc-0.4770\n",
      "Iter-42910, train loss-2.0069, acc-0.4800, valid loss-2.0311, acc-0.4640, test loss-2.0079, acc-0.4771\n",
      "Iter-42920, train loss-1.9950, acc-0.4400, valid loss-2.0310, acc-0.4640, test loss-2.0079, acc-0.4770\n",
      "Iter-42930, train loss-2.0034, acc-0.4400, valid loss-2.0310, acc-0.4638, test loss-2.0078, acc-0.4771\n",
      "Iter-42940, train loss-2.0101, acc-0.4600, valid loss-2.0309, acc-0.4638, test loss-2.0078, acc-0.4771\n",
      "Iter-42950, train loss-2.0727, acc-0.5000, valid loss-2.0309, acc-0.4640, test loss-2.0077, acc-0.4771\n",
      "Iter-42960, train loss-1.9809, acc-0.4800, valid loss-2.0308, acc-0.4640, test loss-2.0077, acc-0.4771\n",
      "Iter-42970, train loss-2.0354, acc-0.3200, valid loss-2.0308, acc-0.4636, test loss-2.0076, acc-0.4769\n",
      "Iter-42980, train loss-2.0038, acc-0.5000, valid loss-2.0307, acc-0.4630, test loss-2.0076, acc-0.4769\n",
      "Iter-42990, train loss-1.9457, acc-0.5400, valid loss-2.0307, acc-0.4634, test loss-2.0075, acc-0.4771\n",
      "Iter-43000, train loss-2.0138, acc-0.3800, valid loss-2.0306, acc-0.4634, test loss-2.0075, acc-0.4769\n",
      "Iter-43010, train loss-1.9873, acc-0.4800, valid loss-2.0306, acc-0.4634, test loss-2.0074, acc-0.4770\n",
      "Iter-43020, train loss-2.0204, acc-0.4600, valid loss-2.0306, acc-0.4634, test loss-2.0074, acc-0.4770\n",
      "Iter-43030, train loss-1.9696, acc-0.5800, valid loss-2.0305, acc-0.4634, test loss-2.0073, acc-0.4772\n",
      "Iter-43040, train loss-2.1018, acc-0.3000, valid loss-2.0305, acc-0.4634, test loss-2.0073, acc-0.4773\n",
      "Iter-43050, train loss-2.0238, acc-0.5200, valid loss-2.0304, acc-0.4634, test loss-2.0072, acc-0.4771\n",
      "Iter-43060, train loss-1.9505, acc-0.4800, valid loss-2.0304, acc-0.4638, test loss-2.0072, acc-0.4771\n",
      "Iter-43070, train loss-1.9889, acc-0.4800, valid loss-2.0303, acc-0.4638, test loss-2.0071, acc-0.4772\n",
      "Iter-43080, train loss-2.0201, acc-0.4600, valid loss-2.0303, acc-0.4636, test loss-2.0071, acc-0.4773\n",
      "Iter-43090, train loss-2.0612, acc-0.5000, valid loss-2.0302, acc-0.4640, test loss-2.0070, acc-0.4770\n",
      "Iter-43100, train loss-2.0524, acc-0.3600, valid loss-2.0302, acc-0.4640, test loss-2.0070, acc-0.4770\n",
      "Iter-43110, train loss-2.0328, acc-0.4200, valid loss-2.0301, acc-0.4640, test loss-2.0069, acc-0.4769\n",
      "Iter-43120, train loss-1.9721, acc-0.6000, valid loss-2.0301, acc-0.4636, test loss-2.0069, acc-0.4769\n",
      "Iter-43130, train loss-1.9647, acc-0.5000, valid loss-2.0300, acc-0.4638, test loss-2.0068, acc-0.4772\n",
      "Iter-43140, train loss-2.0138, acc-0.4800, valid loss-2.0300, acc-0.4638, test loss-2.0068, acc-0.4771\n",
      "Iter-43150, train loss-1.9930, acc-0.5600, valid loss-2.0299, acc-0.4636, test loss-2.0067, acc-0.4772\n",
      "Iter-43160, train loss-2.0616, acc-0.3600, valid loss-2.0299, acc-0.4636, test loss-2.0067, acc-0.4770\n",
      "Iter-43170, train loss-1.9618, acc-0.4800, valid loss-2.0299, acc-0.4640, test loss-2.0066, acc-0.4770\n",
      "Iter-43180, train loss-2.0516, acc-0.4400, valid loss-2.0298, acc-0.4636, test loss-2.0066, acc-0.4769\n",
      "Iter-43190, train loss-2.0617, acc-0.3800, valid loss-2.0298, acc-0.4636, test loss-2.0065, acc-0.4771\n",
      "Iter-43200, train loss-2.0131, acc-0.4400, valid loss-2.0297, acc-0.4636, test loss-2.0065, acc-0.4771\n",
      "Iter-43210, train loss-2.0326, acc-0.4800, valid loss-2.0297, acc-0.4638, test loss-2.0064, acc-0.4769\n",
      "Iter-43220, train loss-2.0651, acc-0.3600, valid loss-2.0296, acc-0.4640, test loss-2.0064, acc-0.4770\n",
      "Iter-43230, train loss-2.0060, acc-0.4400, valid loss-2.0296, acc-0.4638, test loss-2.0063, acc-0.4772\n",
      "Iter-43240, train loss-1.9909, acc-0.5200, valid loss-2.0295, acc-0.4640, test loss-2.0063, acc-0.4774\n",
      "Iter-43250, train loss-2.0642, acc-0.5200, valid loss-2.0295, acc-0.4644, test loss-2.0062, acc-0.4774\n",
      "Iter-43260, train loss-2.0455, acc-0.4400, valid loss-2.0295, acc-0.4646, test loss-2.0062, acc-0.4772\n",
      "Iter-43270, train loss-2.0486, acc-0.4800, valid loss-2.0294, acc-0.4644, test loss-2.0061, acc-0.4772\n",
      "Iter-43280, train loss-2.0515, acc-0.3800, valid loss-2.0294, acc-0.4644, test loss-2.0061, acc-0.4773\n",
      "Iter-43290, train loss-1.9967, acc-0.5800, valid loss-2.0293, acc-0.4646, test loss-2.0060, acc-0.4775\n",
      "Iter-43300, train loss-2.0488, acc-0.4000, valid loss-2.0293, acc-0.4646, test loss-2.0060, acc-0.4774\n",
      "Iter-43310, train loss-2.0458, acc-0.3800, valid loss-2.0292, acc-0.4644, test loss-2.0059, acc-0.4772\n",
      "Iter-43320, train loss-1.9367, acc-0.6200, valid loss-2.0292, acc-0.4646, test loss-2.0059, acc-0.4774\n",
      "Iter-43330, train loss-2.0198, acc-0.4600, valid loss-2.0292, acc-0.4650, test loss-2.0058, acc-0.4775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-43340, train loss-2.0127, acc-0.4800, valid loss-2.0291, acc-0.4650, test loss-2.0058, acc-0.4776\n",
      "Iter-43350, train loss-2.0163, acc-0.5200, valid loss-2.0291, acc-0.4650, test loss-2.0057, acc-0.4774\n",
      "Iter-43360, train loss-2.0063, acc-0.5800, valid loss-2.0290, acc-0.4654, test loss-2.0057, acc-0.4775\n",
      "Iter-43370, train loss-2.0075, acc-0.4800, valid loss-2.0290, acc-0.4656, test loss-2.0056, acc-0.4773\n",
      "Iter-43380, train loss-2.0154, acc-0.4200, valid loss-2.0289, acc-0.4654, test loss-2.0056, acc-0.4772\n",
      "Iter-43390, train loss-1.9934, acc-0.5000, valid loss-2.0289, acc-0.4656, test loss-2.0055, acc-0.4773\n",
      "Iter-43400, train loss-2.0075, acc-0.3800, valid loss-2.0289, acc-0.4654, test loss-2.0055, acc-0.4772\n",
      "Iter-43410, train loss-2.0323, acc-0.3400, valid loss-2.0288, acc-0.4656, test loss-2.0054, acc-0.4775\n",
      "Iter-43420, train loss-2.0456, acc-0.4600, valid loss-2.0288, acc-0.4656, test loss-2.0054, acc-0.4775\n",
      "Iter-43430, train loss-2.0778, acc-0.4000, valid loss-2.0287, acc-0.4652, test loss-2.0053, acc-0.4776\n",
      "Iter-43440, train loss-1.9996, acc-0.6400, valid loss-2.0287, acc-0.4654, test loss-2.0053, acc-0.4775\n",
      "Iter-43450, train loss-2.0214, acc-0.4200, valid loss-2.0286, acc-0.4652, test loss-2.0052, acc-0.4776\n",
      "Iter-43460, train loss-1.9334, acc-0.5000, valid loss-2.0286, acc-0.4654, test loss-2.0052, acc-0.4775\n",
      "Iter-43470, train loss-2.0087, acc-0.5200, valid loss-2.0285, acc-0.4654, test loss-2.0051, acc-0.4776\n",
      "Iter-43480, train loss-2.0371, acc-0.4000, valid loss-2.0285, acc-0.4656, test loss-2.0051, acc-0.4777\n",
      "Iter-43490, train loss-2.0498, acc-0.3600, valid loss-2.0285, acc-0.4654, test loss-2.0050, acc-0.4776\n",
      "Iter-43500, train loss-1.9531, acc-0.5400, valid loss-2.0284, acc-0.4656, test loss-2.0050, acc-0.4776\n",
      "Iter-43510, train loss-1.9674, acc-0.5000, valid loss-2.0284, acc-0.4656, test loss-2.0049, acc-0.4778\n",
      "Iter-43520, train loss-2.0317, acc-0.4600, valid loss-2.0283, acc-0.4656, test loss-2.0049, acc-0.4777\n",
      "Iter-43530, train loss-2.0532, acc-0.4400, valid loss-2.0283, acc-0.4654, test loss-2.0048, acc-0.4780\n",
      "Iter-43540, train loss-2.0296, acc-0.4000, valid loss-2.0282, acc-0.4652, test loss-2.0048, acc-0.4780\n",
      "Iter-43550, train loss-2.0583, acc-0.5000, valid loss-2.0282, acc-0.4652, test loss-2.0047, acc-0.4778\n",
      "Iter-43560, train loss-1.9915, acc-0.5200, valid loss-2.0281, acc-0.4654, test loss-2.0047, acc-0.4778\n",
      "Iter-43570, train loss-2.0152, acc-0.5200, valid loss-2.0281, acc-0.4652, test loss-2.0046, acc-0.4780\n",
      "Iter-43580, train loss-2.0026, acc-0.5600, valid loss-2.0281, acc-0.4652, test loss-2.0046, acc-0.4779\n",
      "Iter-43590, train loss-2.0005, acc-0.5600, valid loss-2.0280, acc-0.4652, test loss-2.0045, acc-0.4779\n",
      "Iter-43600, train loss-2.0237, acc-0.5400, valid loss-2.0280, acc-0.4652, test loss-2.0045, acc-0.4779\n",
      "Iter-43610, train loss-2.0774, acc-0.2000, valid loss-2.0279, acc-0.4654, test loss-2.0045, acc-0.4780\n",
      "Iter-43620, train loss-2.0617, acc-0.4000, valid loss-2.0279, acc-0.4652, test loss-2.0044, acc-0.4781\n",
      "Iter-43630, train loss-2.0673, acc-0.4400, valid loss-2.0278, acc-0.4652, test loss-2.0044, acc-0.4783\n",
      "Iter-43640, train loss-1.8870, acc-0.7000, valid loss-2.0278, acc-0.4652, test loss-2.0043, acc-0.4780\n",
      "Iter-43650, train loss-1.9917, acc-0.4800, valid loss-2.0277, acc-0.4652, test loss-2.0043, acc-0.4782\n",
      "Iter-43660, train loss-2.0293, acc-0.4400, valid loss-2.0277, acc-0.4652, test loss-2.0042, acc-0.4782\n",
      "Iter-43670, train loss-2.0003, acc-0.4400, valid loss-2.0276, acc-0.4654, test loss-2.0042, acc-0.4782\n",
      "Iter-43680, train loss-1.9977, acc-0.4400, valid loss-2.0276, acc-0.4652, test loss-2.0041, acc-0.4782\n",
      "Iter-43690, train loss-2.0036, acc-0.4400, valid loss-2.0276, acc-0.4654, test loss-2.0041, acc-0.4781\n",
      "Iter-43700, train loss-2.0142, acc-0.4800, valid loss-2.0275, acc-0.4656, test loss-2.0040, acc-0.4783\n",
      "Iter-43710, train loss-1.9625, acc-0.5000, valid loss-2.0275, acc-0.4656, test loss-2.0040, acc-0.4782\n",
      "Iter-43720, train loss-2.0419, acc-0.4600, valid loss-2.0274, acc-0.4656, test loss-2.0039, acc-0.4782\n",
      "Iter-43730, train loss-2.0139, acc-0.4400, valid loss-2.0274, acc-0.4656, test loss-2.0039, acc-0.4784\n",
      "Iter-43740, train loss-2.0447, acc-0.3800, valid loss-2.0273, acc-0.4658, test loss-2.0038, acc-0.4782\n",
      "Iter-43750, train loss-1.9093, acc-0.6600, valid loss-2.0273, acc-0.4658, test loss-2.0038, acc-0.4782\n",
      "Iter-43760, train loss-2.0284, acc-0.4200, valid loss-2.0272, acc-0.4660, test loss-2.0037, acc-0.4783\n",
      "Iter-43770, train loss-2.0046, acc-0.5000, valid loss-2.0272, acc-0.4654, test loss-2.0037, acc-0.4783\n",
      "Iter-43780, train loss-2.0417, acc-0.4800, valid loss-2.0272, acc-0.4658, test loss-2.0036, acc-0.4784\n",
      "Iter-43790, train loss-2.0524, acc-0.4600, valid loss-2.0271, acc-0.4658, test loss-2.0036, acc-0.4783\n",
      "Iter-43800, train loss-1.9958, acc-0.5000, valid loss-2.0271, acc-0.4658, test loss-2.0035, acc-0.4783\n",
      "Iter-43810, train loss-2.0527, acc-0.4200, valid loss-2.0270, acc-0.4658, test loss-2.0035, acc-0.4782\n",
      "Iter-43820, train loss-2.0238, acc-0.4800, valid loss-2.0270, acc-0.4660, test loss-2.0034, acc-0.4785\n",
      "Iter-43830, train loss-2.0664, acc-0.5000, valid loss-2.0269, acc-0.4658, test loss-2.0034, acc-0.4784\n",
      "Iter-43840, train loss-1.9725, acc-0.5000, valid loss-2.0269, acc-0.4656, test loss-2.0033, acc-0.4784\n",
      "Iter-43850, train loss-2.0693, acc-0.3600, valid loss-2.0268, acc-0.4658, test loss-2.0033, acc-0.4784\n",
      "Iter-43860, train loss-2.0216, acc-0.4600, valid loss-2.0268, acc-0.4658, test loss-2.0032, acc-0.4783\n",
      "Iter-43870, train loss-2.0519, acc-0.4000, valid loss-2.0268, acc-0.4656, test loss-2.0032, acc-0.4782\n",
      "Iter-43880, train loss-1.9907, acc-0.5000, valid loss-2.0267, acc-0.4652, test loss-2.0031, acc-0.4781\n",
      "Iter-43890, train loss-1.9958, acc-0.5400, valid loss-2.0267, acc-0.4654, test loss-2.0031, acc-0.4782\n",
      "Iter-43900, train loss-1.9894, acc-0.4600, valid loss-2.0266, acc-0.4662, test loss-2.0030, acc-0.4783\n",
      "Iter-43910, train loss-2.0416, acc-0.4200, valid loss-2.0266, acc-0.4660, test loss-2.0030, acc-0.4783\n",
      "Iter-43920, train loss-2.0557, acc-0.3600, valid loss-2.0265, acc-0.4660, test loss-2.0029, acc-0.4783\n",
      "Iter-43930, train loss-2.0000, acc-0.4800, valid loss-2.0265, acc-0.4660, test loss-2.0029, acc-0.4784\n",
      "Iter-43940, train loss-1.9644, acc-0.6200, valid loss-2.0265, acc-0.4660, test loss-2.0029, acc-0.4784\n",
      "Iter-43950, train loss-2.1001, acc-0.4400, valid loss-2.0264, acc-0.4658, test loss-2.0028, acc-0.4783\n",
      "Iter-43960, train loss-2.0139, acc-0.4000, valid loss-2.0264, acc-0.4658, test loss-2.0028, acc-0.4784\n",
      "Iter-43970, train loss-2.0259, acc-0.4400, valid loss-2.0263, acc-0.4660, test loss-2.0027, acc-0.4784\n",
      "Iter-43980, train loss-1.9853, acc-0.4800, valid loss-2.0263, acc-0.4654, test loss-2.0027, acc-0.4785\n",
      "Iter-43990, train loss-1.9675, acc-0.4600, valid loss-2.0262, acc-0.4654, test loss-2.0026, acc-0.4786\n",
      "Iter-44000, train loss-1.9663, acc-0.4800, valid loss-2.0262, acc-0.4656, test loss-2.0026, acc-0.4784\n",
      "Iter-44010, train loss-2.0075, acc-0.4400, valid loss-2.0262, acc-0.4656, test loss-2.0025, acc-0.4787\n",
      "Iter-44020, train loss-1.9922, acc-0.4400, valid loss-2.0261, acc-0.4656, test loss-2.0025, acc-0.4785\n",
      "Iter-44030, train loss-2.0105, acc-0.4200, valid loss-2.0261, acc-0.4656, test loss-2.0024, acc-0.4786\n",
      "Iter-44040, train loss-2.0348, acc-0.5000, valid loss-2.0260, acc-0.4654, test loss-2.0024, acc-0.4787\n",
      "Iter-44050, train loss-2.0204, acc-0.4600, valid loss-2.0260, acc-0.4654, test loss-2.0023, acc-0.4786\n",
      "Iter-44060, train loss-1.9697, acc-0.4800, valid loss-2.0259, acc-0.4656, test loss-2.0023, acc-0.4788\n",
      "Iter-44070, train loss-2.0779, acc-0.3200, valid loss-2.0259, acc-0.4654, test loss-2.0022, acc-0.4788\n",
      "Iter-44080, train loss-2.0257, acc-0.4000, valid loss-2.0258, acc-0.4656, test loss-2.0022, acc-0.4787\n",
      "Iter-44090, train loss-1.9734, acc-0.5400, valid loss-2.0258, acc-0.4654, test loss-2.0021, acc-0.4787\n",
      "Iter-44100, train loss-1.9936, acc-0.6200, valid loss-2.0258, acc-0.4654, test loss-2.0021, acc-0.4783\n",
      "Iter-44110, train loss-1.9919, acc-0.5000, valid loss-2.0257, acc-0.4654, test loss-2.0020, acc-0.4784\n",
      "Iter-44120, train loss-2.0582, acc-0.5000, valid loss-2.0257, acc-0.4654, test loss-2.0020, acc-0.4782\n",
      "Iter-44130, train loss-1.9870, acc-0.4800, valid loss-2.0256, acc-0.4654, test loss-2.0019, acc-0.4786\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44140, train loss-1.9717, acc-0.4600, valid loss-2.0256, acc-0.4654, test loss-2.0019, acc-0.4786\n",
      "Iter-44150, train loss-2.0410, acc-0.4400, valid loss-2.0255, acc-0.4654, test loss-2.0018, acc-0.4785\n",
      "Iter-44160, train loss-2.0054, acc-0.4600, valid loss-2.0255, acc-0.4654, test loss-2.0018, acc-0.4785\n",
      "Iter-44170, train loss-1.9787, acc-0.5400, valid loss-2.0254, acc-0.4654, test loss-2.0017, acc-0.4785\n",
      "Iter-44180, train loss-1.9888, acc-0.5200, valid loss-2.0254, acc-0.4654, test loss-2.0017, acc-0.4785\n",
      "Iter-44190, train loss-2.0097, acc-0.4600, valid loss-2.0253, acc-0.4654, test loss-2.0016, acc-0.4785\n",
      "Iter-44200, train loss-2.0716, acc-0.3600, valid loss-2.0253, acc-0.4652, test loss-2.0016, acc-0.4786\n",
      "Iter-44210, train loss-1.9881, acc-0.5000, valid loss-2.0253, acc-0.4652, test loss-2.0015, acc-0.4786\n",
      "Iter-44220, train loss-1.9829, acc-0.5400, valid loss-2.0252, acc-0.4650, test loss-2.0015, acc-0.4786\n",
      "Iter-44230, train loss-1.9588, acc-0.5600, valid loss-2.0252, acc-0.4652, test loss-2.0014, acc-0.4786\n",
      "Iter-44240, train loss-2.0190, acc-0.5200, valid loss-2.0251, acc-0.4652, test loss-2.0014, acc-0.4787\n",
      "Iter-44250, train loss-2.0203, acc-0.4000, valid loss-2.0251, acc-0.4652, test loss-2.0014, acc-0.4787\n",
      "Iter-44260, train loss-1.9319, acc-0.6800, valid loss-2.0250, acc-0.4652, test loss-2.0013, acc-0.4787\n",
      "Iter-44270, train loss-2.0045, acc-0.4800, valid loss-2.0250, acc-0.4652, test loss-2.0013, acc-0.4788\n",
      "Iter-44280, train loss-1.9678, acc-0.5200, valid loss-2.0249, acc-0.4652, test loss-2.0012, acc-0.4787\n",
      "Iter-44290, train loss-1.9767, acc-0.5600, valid loss-2.0249, acc-0.4652, test loss-2.0012, acc-0.4787\n",
      "Iter-44300, train loss-2.0865, acc-0.3800, valid loss-2.0249, acc-0.4652, test loss-2.0011, acc-0.4788\n",
      "Iter-44310, train loss-2.0484, acc-0.3400, valid loss-2.0248, acc-0.4652, test loss-2.0011, acc-0.4790\n",
      "Iter-44320, train loss-2.0321, acc-0.4200, valid loss-2.0248, acc-0.4652, test loss-2.0010, acc-0.4789\n",
      "Iter-44330, train loss-1.9370, acc-0.6000, valid loss-2.0247, acc-0.4654, test loss-2.0010, acc-0.4790\n",
      "Iter-44340, train loss-2.0049, acc-0.5200, valid loss-2.0247, acc-0.4654, test loss-2.0009, acc-0.4789\n",
      "Iter-44350, train loss-2.0143, acc-0.3200, valid loss-2.0246, acc-0.4652, test loss-2.0009, acc-0.4789\n",
      "Iter-44360, train loss-1.9839, acc-0.5000, valid loss-2.0246, acc-0.4652, test loss-2.0008, acc-0.4790\n",
      "Iter-44370, train loss-1.9139, acc-0.5200, valid loss-2.0245, acc-0.4654, test loss-2.0008, acc-0.4790\n",
      "Iter-44380, train loss-2.0592, acc-0.4000, valid loss-2.0245, acc-0.4658, test loss-2.0007, acc-0.4790\n",
      "Iter-44390, train loss-2.0259, acc-0.5200, valid loss-2.0245, acc-0.4656, test loss-2.0007, acc-0.4790\n",
      "Iter-44400, train loss-1.9563, acc-0.5200, valid loss-2.0244, acc-0.4658, test loss-2.0006, acc-0.4790\n",
      "Iter-44410, train loss-2.0523, acc-0.3400, valid loss-2.0244, acc-0.4658, test loss-2.0006, acc-0.4790\n",
      "Iter-44420, train loss-1.9341, acc-0.5000, valid loss-2.0243, acc-0.4656, test loss-2.0005, acc-0.4790\n",
      "Iter-44430, train loss-1.9891, acc-0.5200, valid loss-2.0243, acc-0.4656, test loss-2.0005, acc-0.4792\n",
      "Iter-44440, train loss-2.0372, acc-0.4400, valid loss-2.0242, acc-0.4656, test loss-2.0004, acc-0.4791\n",
      "Iter-44450, train loss-1.9515, acc-0.5400, valid loss-2.0242, acc-0.4656, test loss-2.0004, acc-0.4793\n",
      "Iter-44460, train loss-1.9551, acc-0.6200, valid loss-2.0242, acc-0.4658, test loss-2.0003, acc-0.4791\n",
      "Iter-44470, train loss-2.0405, acc-0.4200, valid loss-2.0241, acc-0.4656, test loss-2.0003, acc-0.4792\n",
      "Iter-44480, train loss-2.0556, acc-0.3800, valid loss-2.0241, acc-0.4660, test loss-2.0002, acc-0.4793\n",
      "Iter-44490, train loss-2.0206, acc-0.4200, valid loss-2.0240, acc-0.4656, test loss-2.0002, acc-0.4790\n",
      "Iter-44500, train loss-1.9848, acc-0.5000, valid loss-2.0240, acc-0.4656, test loss-2.0001, acc-0.4790\n",
      "Iter-44510, train loss-1.9989, acc-0.4800, valid loss-2.0239, acc-0.4658, test loss-2.0001, acc-0.4791\n",
      "Iter-44520, train loss-1.9596, acc-0.5200, valid loss-2.0239, acc-0.4658, test loss-2.0000, acc-0.4790\n",
      "Iter-44530, train loss-1.9760, acc-0.4800, valid loss-2.0238, acc-0.4658, test loss-2.0000, acc-0.4791\n",
      "Iter-44540, train loss-1.9802, acc-0.4600, valid loss-2.0238, acc-0.4662, test loss-2.0000, acc-0.4789\n",
      "Iter-44550, train loss-2.0170, acc-0.4800, valid loss-2.0238, acc-0.4666, test loss-1.9999, acc-0.4790\n",
      "Iter-44560, train loss-2.1527, acc-0.3400, valid loss-2.0237, acc-0.4662, test loss-1.9999, acc-0.4792\n",
      "Iter-44570, train loss-2.0383, acc-0.4800, valid loss-2.0237, acc-0.4666, test loss-1.9998, acc-0.4791\n",
      "Iter-44580, train loss-1.9804, acc-0.4000, valid loss-2.0236, acc-0.4664, test loss-1.9998, acc-0.4792\n",
      "Iter-44590, train loss-1.9233, acc-0.5800, valid loss-2.0236, acc-0.4662, test loss-1.9997, acc-0.4791\n",
      "Iter-44600, train loss-2.0141, acc-0.4200, valid loss-2.0235, acc-0.4664, test loss-1.9997, acc-0.4791\n",
      "Iter-44610, train loss-2.0474, acc-0.4000, valid loss-2.0235, acc-0.4664, test loss-1.9996, acc-0.4791\n",
      "Iter-44620, train loss-2.0340, acc-0.4400, valid loss-2.0234, acc-0.4664, test loss-1.9996, acc-0.4790\n",
      "Iter-44630, train loss-2.0282, acc-0.4200, valid loss-2.0234, acc-0.4670, test loss-1.9995, acc-0.4791\n",
      "Iter-44640, train loss-2.0135, acc-0.4000, valid loss-2.0234, acc-0.4666, test loss-1.9995, acc-0.4790\n",
      "Iter-44650, train loss-2.0007, acc-0.4400, valid loss-2.0233, acc-0.4662, test loss-1.9994, acc-0.4787\n",
      "Iter-44660, train loss-2.0040, acc-0.5800, valid loss-2.0233, acc-0.4662, test loss-1.9994, acc-0.4788\n",
      "Iter-44670, train loss-1.9879, acc-0.4800, valid loss-2.0232, acc-0.4662, test loss-1.9993, acc-0.4789\n",
      "Iter-44680, train loss-2.0889, acc-0.4200, valid loss-2.0232, acc-0.4664, test loss-1.9993, acc-0.4790\n",
      "Iter-44690, train loss-2.0541, acc-0.4400, valid loss-2.0231, acc-0.4662, test loss-1.9992, acc-0.4791\n",
      "Iter-44700, train loss-1.9768, acc-0.5800, valid loss-2.0231, acc-0.4658, test loss-1.9992, acc-0.4791\n",
      "Iter-44710, train loss-2.0042, acc-0.4400, valid loss-2.0230, acc-0.4656, test loss-1.9991, acc-0.4792\n",
      "Iter-44720, train loss-2.0190, acc-0.4800, valid loss-2.0230, acc-0.4656, test loss-1.9991, acc-0.4793\n",
      "Iter-44730, train loss-1.9986, acc-0.3800, valid loss-2.0230, acc-0.4658, test loss-1.9990, acc-0.4792\n",
      "Iter-44740, train loss-1.9311, acc-0.6000, valid loss-2.0229, acc-0.4656, test loss-1.9990, acc-0.4792\n",
      "Iter-44750, train loss-2.0529, acc-0.4200, valid loss-2.0229, acc-0.4656, test loss-1.9990, acc-0.4790\n",
      "Iter-44760, train loss-1.9866, acc-0.4200, valid loss-2.0228, acc-0.4654, test loss-1.9989, acc-0.4792\n",
      "Iter-44770, train loss-2.1099, acc-0.3800, valid loss-2.0228, acc-0.4654, test loss-1.9989, acc-0.4788\n",
      "Iter-44780, train loss-2.0034, acc-0.5200, valid loss-2.0227, acc-0.4654, test loss-1.9988, acc-0.4787\n",
      "Iter-44790, train loss-2.0224, acc-0.4400, valid loss-2.0227, acc-0.4654, test loss-1.9988, acc-0.4790\n",
      "Iter-44800, train loss-1.9810, acc-0.5200, valid loss-2.0226, acc-0.4654, test loss-1.9987, acc-0.4792\n",
      "Iter-44810, train loss-2.0153, acc-0.3800, valid loss-2.0226, acc-0.4654, test loss-1.9987, acc-0.4795\n",
      "Iter-44820, train loss-2.0325, acc-0.3200, valid loss-2.0226, acc-0.4654, test loss-1.9986, acc-0.4795\n",
      "Iter-44830, train loss-2.1420, acc-0.3600, valid loss-2.0225, acc-0.4654, test loss-1.9986, acc-0.4795\n",
      "Iter-44840, train loss-1.9628, acc-0.4200, valid loss-2.0225, acc-0.4654, test loss-1.9985, acc-0.4794\n",
      "Iter-44850, train loss-2.0121, acc-0.4000, valid loss-2.0224, acc-0.4656, test loss-1.9985, acc-0.4795\n",
      "Iter-44860, train loss-1.9838, acc-0.5400, valid loss-2.0224, acc-0.4656, test loss-1.9984, acc-0.4797\n",
      "Iter-44870, train loss-2.0070, acc-0.5400, valid loss-2.0223, acc-0.4656, test loss-1.9984, acc-0.4792\n",
      "Iter-44880, train loss-1.9936, acc-0.4800, valid loss-2.0223, acc-0.4656, test loss-1.9983, acc-0.4792\n",
      "Iter-44890, train loss-1.9863, acc-0.4600, valid loss-2.0222, acc-0.4656, test loss-1.9983, acc-0.4790\n",
      "Iter-44900, train loss-2.0594, acc-0.4200, valid loss-2.0222, acc-0.4656, test loss-1.9982, acc-0.4788\n",
      "Iter-44910, train loss-1.9998, acc-0.4200, valid loss-2.0221, acc-0.4658, test loss-1.9982, acc-0.4788\n",
      "Iter-44920, train loss-1.9903, acc-0.4800, valid loss-2.0221, acc-0.4656, test loss-1.9981, acc-0.4789\n",
      "Iter-44930, train loss-1.9922, acc-0.5200, valid loss-2.0221, acc-0.4658, test loss-1.9981, acc-0.4789\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44940, train loss-2.0096, acc-0.4000, valid loss-2.0220, acc-0.4654, test loss-1.9980, acc-0.4793\n",
      "Iter-44950, train loss-2.0332, acc-0.4600, valid loss-2.0220, acc-0.4658, test loss-1.9980, acc-0.4791\n",
      "Iter-44960, train loss-2.0536, acc-0.4200, valid loss-2.0219, acc-0.4660, test loss-1.9979, acc-0.4789\n",
      "Iter-44970, train loss-1.9758, acc-0.5800, valid loss-2.0219, acc-0.4656, test loss-1.9979, acc-0.4791\n",
      "Iter-44980, train loss-2.1043, acc-0.3000, valid loss-2.0218, acc-0.4658, test loss-1.9978, acc-0.4790\n",
      "Iter-44990, train loss-2.0325, acc-0.4800, valid loss-2.0218, acc-0.4656, test loss-1.9978, acc-0.4791\n",
      "Iter-45000, train loss-2.0331, acc-0.4400, valid loss-2.0217, acc-0.4658, test loss-1.9977, acc-0.4791\n",
      "Iter-45010, train loss-1.9766, acc-0.5000, valid loss-2.0217, acc-0.4658, test loss-1.9977, acc-0.4792\n",
      "Iter-45020, train loss-2.0052, acc-0.5000, valid loss-2.0217, acc-0.4660, test loss-1.9976, acc-0.4788\n",
      "Iter-45030, train loss-2.0223, acc-0.4000, valid loss-2.0216, acc-0.4658, test loss-1.9976, acc-0.4789\n",
      "Iter-45040, train loss-1.9898, acc-0.5000, valid loss-2.0216, acc-0.4660, test loss-1.9975, acc-0.4787\n",
      "Iter-45050, train loss-2.0133, acc-0.5800, valid loss-2.0215, acc-0.4662, test loss-1.9975, acc-0.4788\n",
      "Iter-45060, train loss-2.0621, acc-0.5000, valid loss-2.0215, acc-0.4658, test loss-1.9974, acc-0.4789\n",
      "Iter-45070, train loss-2.0068, acc-0.4200, valid loss-2.0214, acc-0.4658, test loss-1.9974, acc-0.4787\n",
      "Iter-45080, train loss-1.9870, acc-0.4800, valid loss-2.0214, acc-0.4660, test loss-1.9973, acc-0.4787\n",
      "Iter-45090, train loss-1.9542, acc-0.5400, valid loss-2.0213, acc-0.4660, test loss-1.9973, acc-0.4786\n",
      "Iter-45100, train loss-1.9799, acc-0.5400, valid loss-2.0213, acc-0.4658, test loss-1.9972, acc-0.4784\n",
      "Iter-45110, train loss-1.9921, acc-0.5000, valid loss-2.0212, acc-0.4658, test loss-1.9972, acc-0.4784\n",
      "Iter-45120, train loss-1.9876, acc-0.4400, valid loss-2.0212, acc-0.4660, test loss-1.9971, acc-0.4783\n",
      "Iter-45130, train loss-1.9931, acc-0.5600, valid loss-2.0211, acc-0.4660, test loss-1.9971, acc-0.4786\n",
      "Iter-45140, train loss-2.0467, acc-0.4800, valid loss-2.0211, acc-0.4662, test loss-1.9970, acc-0.4783\n",
      "Iter-45150, train loss-2.0226, acc-0.4600, valid loss-2.0211, acc-0.4660, test loss-1.9970, acc-0.4784\n",
      "Iter-45160, train loss-1.9952, acc-0.5000, valid loss-2.0210, acc-0.4662, test loss-1.9970, acc-0.4784\n",
      "Iter-45170, train loss-2.0376, acc-0.4600, valid loss-2.0210, acc-0.4662, test loss-1.9969, acc-0.4786\n",
      "Iter-45180, train loss-2.0105, acc-0.5800, valid loss-2.0209, acc-0.4660, test loss-1.9969, acc-0.4787\n",
      "Iter-45190, train loss-2.0318, acc-0.5400, valid loss-2.0209, acc-0.4662, test loss-1.9968, acc-0.4786\n",
      "Iter-45200, train loss-1.9961, acc-0.5000, valid loss-2.0209, acc-0.4664, test loss-1.9968, acc-0.4786\n",
      "Iter-45210, train loss-1.9296, acc-0.6000, valid loss-2.0208, acc-0.4662, test loss-1.9967, acc-0.4787\n",
      "Iter-45220, train loss-2.0157, acc-0.5400, valid loss-2.0208, acc-0.4660, test loss-1.9967, acc-0.4788\n",
      "Iter-45230, train loss-1.9975, acc-0.4400, valid loss-2.0207, acc-0.4662, test loss-1.9966, acc-0.4787\n",
      "Iter-45240, train loss-2.0474, acc-0.4400, valid loss-2.0207, acc-0.4664, test loss-1.9966, acc-0.4789\n",
      "Iter-45250, train loss-1.9815, acc-0.4800, valid loss-2.0206, acc-0.4664, test loss-1.9965, acc-0.4791\n",
      "Iter-45260, train loss-2.0766, acc-0.4200, valid loss-2.0206, acc-0.4664, test loss-1.9965, acc-0.4787\n",
      "Iter-45270, train loss-2.0189, acc-0.4400, valid loss-2.0206, acc-0.4664, test loss-1.9964, acc-0.4788\n",
      "Iter-45280, train loss-2.0012, acc-0.4800, valid loss-2.0205, acc-0.4662, test loss-1.9964, acc-0.4790\n",
      "Iter-45290, train loss-2.0693, acc-0.3000, valid loss-2.0205, acc-0.4660, test loss-1.9963, acc-0.4793\n",
      "Iter-45300, train loss-1.9897, acc-0.6000, valid loss-2.0204, acc-0.4660, test loss-1.9963, acc-0.4792\n",
      "Iter-45310, train loss-2.0416, acc-0.5200, valid loss-2.0204, acc-0.4660, test loss-1.9963, acc-0.4791\n",
      "Iter-45320, train loss-1.9583, acc-0.4200, valid loss-2.0203, acc-0.4662, test loss-1.9962, acc-0.4791\n",
      "Iter-45330, train loss-1.9934, acc-0.4600, valid loss-2.0203, acc-0.4660, test loss-1.9962, acc-0.4793\n",
      "Iter-45340, train loss-1.9372, acc-0.6000, valid loss-2.0203, acc-0.4662, test loss-1.9961, acc-0.4792\n",
      "Iter-45350, train loss-1.9830, acc-0.5200, valid loss-2.0202, acc-0.4662, test loss-1.9961, acc-0.4790\n",
      "Iter-45360, train loss-1.9875, acc-0.5400, valid loss-2.0202, acc-0.4666, test loss-1.9960, acc-0.4793\n",
      "Iter-45370, train loss-1.9384, acc-0.5200, valid loss-2.0201, acc-0.4662, test loss-1.9960, acc-0.4794\n",
      "Iter-45380, train loss-1.9588, acc-0.5000, valid loss-2.0201, acc-0.4664, test loss-1.9959, acc-0.4796\n",
      "Iter-45390, train loss-2.0405, acc-0.4200, valid loss-2.0201, acc-0.4664, test loss-1.9959, acc-0.4796\n",
      "Iter-45400, train loss-2.0109, acc-0.5200, valid loss-2.0200, acc-0.4666, test loss-1.9958, acc-0.4794\n",
      "Iter-45410, train loss-2.0375, acc-0.3800, valid loss-2.0200, acc-0.4666, test loss-1.9958, acc-0.4794\n",
      "Iter-45420, train loss-2.0367, acc-0.3600, valid loss-2.0199, acc-0.4664, test loss-1.9957, acc-0.4791\n",
      "Iter-45430, train loss-1.9471, acc-0.5200, valid loss-2.0199, acc-0.4664, test loss-1.9957, acc-0.4794\n",
      "Iter-45440, train loss-2.0339, acc-0.4600, valid loss-2.0198, acc-0.4664, test loss-1.9956, acc-0.4794\n",
      "Iter-45450, train loss-1.9911, acc-0.5600, valid loss-2.0198, acc-0.4664, test loss-1.9956, acc-0.4795\n",
      "Iter-45460, train loss-1.9864, acc-0.5200, valid loss-2.0197, acc-0.4662, test loss-1.9955, acc-0.4793\n",
      "Iter-45470, train loss-2.0383, acc-0.4800, valid loss-2.0197, acc-0.4662, test loss-1.9955, acc-0.4794\n",
      "Iter-45480, train loss-2.0077, acc-0.4600, valid loss-2.0196, acc-0.4662, test loss-1.9954, acc-0.4791\n",
      "Iter-45490, train loss-1.9464, acc-0.4800, valid loss-2.0196, acc-0.4662, test loss-1.9954, acc-0.4794\n",
      "Iter-45500, train loss-2.0191, acc-0.4600, valid loss-2.0196, acc-0.4664, test loss-1.9953, acc-0.4795\n",
      "Iter-45510, train loss-2.0103, acc-0.5400, valid loss-2.0195, acc-0.4666, test loss-1.9953, acc-0.4795\n",
      "Iter-45520, train loss-2.0181, acc-0.4000, valid loss-2.0195, acc-0.4660, test loss-1.9952, acc-0.4794\n",
      "Iter-45530, train loss-1.9584, acc-0.5000, valid loss-2.0194, acc-0.4664, test loss-1.9952, acc-0.4795\n",
      "Iter-45540, train loss-2.0011, acc-0.4400, valid loss-2.0194, acc-0.4664, test loss-1.9951, acc-0.4795\n",
      "Iter-45550, train loss-1.9308, acc-0.5200, valid loss-2.0193, acc-0.4662, test loss-1.9951, acc-0.4793\n",
      "Iter-45560, train loss-1.9338, acc-0.5000, valid loss-2.0193, acc-0.4666, test loss-1.9950, acc-0.4794\n",
      "Iter-45570, train loss-2.0008, acc-0.4600, valid loss-2.0193, acc-0.4666, test loss-1.9950, acc-0.4794\n",
      "Iter-45580, train loss-1.9773, acc-0.4400, valid loss-2.0192, acc-0.4662, test loss-1.9950, acc-0.4794\n",
      "Iter-45590, train loss-2.0322, acc-0.3600, valid loss-2.0192, acc-0.4662, test loss-1.9949, acc-0.4795\n",
      "Iter-45600, train loss-1.9617, acc-0.5600, valid loss-2.0191, acc-0.4664, test loss-1.9949, acc-0.4795\n",
      "Iter-45610, train loss-1.9450, acc-0.5600, valid loss-2.0191, acc-0.4662, test loss-1.9948, acc-0.4797\n",
      "Iter-45620, train loss-1.9796, acc-0.5200, valid loss-2.0190, acc-0.4666, test loss-1.9948, acc-0.4796\n",
      "Iter-45630, train loss-2.0461, acc-0.4000, valid loss-2.0190, acc-0.4666, test loss-1.9947, acc-0.4796\n",
      "Iter-45640, train loss-2.0206, acc-0.3800, valid loss-2.0189, acc-0.4666, test loss-1.9947, acc-0.4797\n",
      "Iter-45650, train loss-1.9820, acc-0.4200, valid loss-2.0189, acc-0.4664, test loss-1.9946, acc-0.4797\n",
      "Iter-45660, train loss-2.0186, acc-0.4200, valid loss-2.0189, acc-0.4660, test loss-1.9946, acc-0.4800\n",
      "Iter-45670, train loss-1.9789, acc-0.6000, valid loss-2.0188, acc-0.4664, test loss-1.9945, acc-0.4801\n",
      "Iter-45680, train loss-2.0372, acc-0.5200, valid loss-2.0188, acc-0.4664, test loss-1.9945, acc-0.4803\n",
      "Iter-45690, train loss-2.0024, acc-0.5800, valid loss-2.0187, acc-0.4664, test loss-1.9944, acc-0.4802\n",
      "Iter-45700, train loss-2.0383, acc-0.4400, valid loss-2.0187, acc-0.4664, test loss-1.9944, acc-0.4803\n",
      "Iter-45710, train loss-1.9813, acc-0.4400, valid loss-2.0187, acc-0.4664, test loss-1.9943, acc-0.4804\n",
      "Iter-45720, train loss-2.0835, acc-0.3200, valid loss-2.0186, acc-0.4666, test loss-1.9943, acc-0.4806\n",
      "Iter-45730, train loss-1.9929, acc-0.5200, valid loss-2.0186, acc-0.4666, test loss-1.9942, acc-0.4809\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-45740, train loss-1.9112, acc-0.5600, valid loss-2.0185, acc-0.4668, test loss-1.9942, acc-0.4810\n",
      "Iter-45750, train loss-2.0033, acc-0.4000, valid loss-2.0185, acc-0.4668, test loss-1.9941, acc-0.4809\n",
      "Iter-45760, train loss-2.0627, acc-0.3800, valid loss-2.0184, acc-0.4670, test loss-1.9941, acc-0.4810\n",
      "Iter-45770, train loss-1.9244, acc-0.6000, valid loss-2.0184, acc-0.4672, test loss-1.9940, acc-0.4810\n",
      "Iter-45780, train loss-1.9790, acc-0.6000, valid loss-2.0184, acc-0.4672, test loss-1.9940, acc-0.4811\n",
      "Iter-45790, train loss-1.9754, acc-0.4800, valid loss-2.0183, acc-0.4674, test loss-1.9940, acc-0.4811\n",
      "Iter-45800, train loss-2.0134, acc-0.4600, valid loss-2.0183, acc-0.4678, test loss-1.9939, acc-0.4809\n",
      "Iter-45810, train loss-2.0193, acc-0.4000, valid loss-2.0182, acc-0.4678, test loss-1.9939, acc-0.4811\n",
      "Iter-45820, train loss-2.0435, acc-0.4200, valid loss-2.0182, acc-0.4678, test loss-1.9938, acc-0.4809\n",
      "Iter-45830, train loss-2.0760, acc-0.3000, valid loss-2.0181, acc-0.4676, test loss-1.9938, acc-0.4811\n",
      "Iter-45840, train loss-1.9626, acc-0.5800, valid loss-2.0181, acc-0.4676, test loss-1.9937, acc-0.4811\n",
      "Iter-45850, train loss-2.0273, acc-0.5200, valid loss-2.0181, acc-0.4676, test loss-1.9937, acc-0.4811\n",
      "Iter-45860, train loss-2.0952, acc-0.3400, valid loss-2.0180, acc-0.4676, test loss-1.9936, acc-0.4813\n",
      "Iter-45870, train loss-1.9919, acc-0.4200, valid loss-2.0180, acc-0.4678, test loss-1.9936, acc-0.4813\n",
      "Iter-45880, train loss-1.9631, acc-0.4600, valid loss-2.0179, acc-0.4680, test loss-1.9935, acc-0.4817\n",
      "Iter-45890, train loss-2.0227, acc-0.4000, valid loss-2.0179, acc-0.4682, test loss-1.9935, acc-0.4818\n",
      "Iter-45900, train loss-1.9282, acc-0.5000, valid loss-2.0179, acc-0.4682, test loss-1.9934, acc-0.4819\n",
      "Iter-45910, train loss-1.9466, acc-0.4600, valid loss-2.0178, acc-0.4682, test loss-1.9934, acc-0.4818\n",
      "Iter-45920, train loss-1.9848, acc-0.4800, valid loss-2.0178, acc-0.4682, test loss-1.9934, acc-0.4820\n",
      "Iter-45930, train loss-1.9945, acc-0.5200, valid loss-2.0177, acc-0.4682, test loss-1.9933, acc-0.4821\n",
      "Iter-45940, train loss-1.9998, acc-0.4800, valid loss-2.0177, acc-0.4684, test loss-1.9933, acc-0.4823\n",
      "Iter-45950, train loss-2.0387, acc-0.4600, valid loss-2.0176, acc-0.4684, test loss-1.9932, acc-0.4823\n",
      "Iter-45960, train loss-2.0256, acc-0.4200, valid loss-2.0176, acc-0.4688, test loss-1.9932, acc-0.4822\n",
      "Iter-45970, train loss-1.9684, acc-0.5200, valid loss-2.0176, acc-0.4688, test loss-1.9931, acc-0.4825\n",
      "Iter-45980, train loss-2.0642, acc-0.4600, valid loss-2.0175, acc-0.4688, test loss-1.9931, acc-0.4827\n",
      "Iter-45990, train loss-2.0522, acc-0.3800, valid loss-2.0175, acc-0.4686, test loss-1.9930, acc-0.4824\n",
      "Iter-46000, train loss-1.9890, acc-0.4200, valid loss-2.0174, acc-0.4686, test loss-1.9930, acc-0.4825\n",
      "Iter-46010, train loss-2.0273, acc-0.5000, valid loss-2.0174, acc-0.4686, test loss-1.9929, acc-0.4824\n",
      "Iter-46020, train loss-2.0225, acc-0.4600, valid loss-2.0173, acc-0.4686, test loss-1.9929, acc-0.4823\n",
      "Iter-46030, train loss-2.0096, acc-0.5000, valid loss-2.0173, acc-0.4684, test loss-1.9928, acc-0.4823\n",
      "Iter-46040, train loss-1.9741, acc-0.4200, valid loss-2.0173, acc-0.4690, test loss-1.9928, acc-0.4823\n",
      "Iter-46050, train loss-1.9560, acc-0.5000, valid loss-2.0172, acc-0.4690, test loss-1.9927, acc-0.4827\n",
      "Iter-46060, train loss-2.0685, acc-0.3600, valid loss-2.0172, acc-0.4688, test loss-1.9927, acc-0.4825\n",
      "Iter-46070, train loss-2.0649, acc-0.4000, valid loss-2.0171, acc-0.4688, test loss-1.9926, acc-0.4825\n",
      "Iter-46080, train loss-2.0700, acc-0.4800, valid loss-2.0171, acc-0.4686, test loss-1.9926, acc-0.4823\n",
      "Iter-46090, train loss-2.0022, acc-0.4000, valid loss-2.0171, acc-0.4686, test loss-1.9925, acc-0.4826\n",
      "Iter-46100, train loss-2.0848, acc-0.3800, valid loss-2.0170, acc-0.4686, test loss-1.9925, acc-0.4829\n",
      "Iter-46110, train loss-1.9985, acc-0.3600, valid loss-2.0170, acc-0.4686, test loss-1.9924, acc-0.4833\n",
      "Iter-46120, train loss-2.0173, acc-0.3600, valid loss-2.0169, acc-0.4690, test loss-1.9924, acc-0.4829\n",
      "Iter-46130, train loss-2.0283, acc-0.4200, valid loss-2.0169, acc-0.4688, test loss-1.9924, acc-0.4831\n",
      "Iter-46140, train loss-2.0239, acc-0.4600, valid loss-2.0168, acc-0.4684, test loss-1.9923, acc-0.4829\n",
      "Iter-46150, train loss-1.9504, acc-0.5800, valid loss-2.0168, acc-0.4688, test loss-1.9923, acc-0.4829\n",
      "Iter-46160, train loss-1.9899, acc-0.5600, valid loss-2.0168, acc-0.4688, test loss-1.9922, acc-0.4828\n",
      "Iter-46170, train loss-2.0542, acc-0.4400, valid loss-2.0167, acc-0.4686, test loss-1.9922, acc-0.4827\n",
      "Iter-46180, train loss-1.9096, acc-0.4800, valid loss-2.0167, acc-0.4688, test loss-1.9921, acc-0.4828\n",
      "Iter-46190, train loss-1.9525, acc-0.4800, valid loss-2.0166, acc-0.4688, test loss-1.9921, acc-0.4830\n",
      "Iter-46200, train loss-1.9984, acc-0.4800, valid loss-2.0166, acc-0.4690, test loss-1.9920, acc-0.4831\n",
      "Iter-46210, train loss-2.0946, acc-0.2600, valid loss-2.0165, acc-0.4690, test loss-1.9920, acc-0.4833\n",
      "Iter-46220, train loss-2.0162, acc-0.4600, valid loss-2.0165, acc-0.4692, test loss-1.9919, acc-0.4832\n",
      "Iter-46230, train loss-2.0616, acc-0.3800, valid loss-2.0164, acc-0.4688, test loss-1.9919, acc-0.4831\n",
      "Iter-46240, train loss-1.9357, acc-0.5400, valid loss-2.0164, acc-0.4690, test loss-1.9918, acc-0.4833\n",
      "Iter-46250, train loss-1.9620, acc-0.5400, valid loss-2.0164, acc-0.4692, test loss-1.9918, acc-0.4833\n",
      "Iter-46260, train loss-2.0167, acc-0.4000, valid loss-2.0163, acc-0.4692, test loss-1.9917, acc-0.4833\n",
      "Iter-46270, train loss-1.9667, acc-0.5000, valid loss-2.0163, acc-0.4692, test loss-1.9917, acc-0.4831\n",
      "Iter-46280, train loss-2.0272, acc-0.3800, valid loss-2.0162, acc-0.4692, test loss-1.9916, acc-0.4832\n",
      "Iter-46290, train loss-2.0835, acc-0.3600, valid loss-2.0162, acc-0.4690, test loss-1.9916, acc-0.4832\n",
      "Iter-46300, train loss-1.9831, acc-0.4800, valid loss-2.0162, acc-0.4690, test loss-1.9915, acc-0.4830\n",
      "Iter-46310, train loss-1.9779, acc-0.5600, valid loss-2.0161, acc-0.4692, test loss-1.9915, acc-0.4832\n",
      "Iter-46320, train loss-2.0413, acc-0.5200, valid loss-2.0161, acc-0.4690, test loss-1.9915, acc-0.4831\n",
      "Iter-46330, train loss-1.9745, acc-0.4800, valid loss-2.0160, acc-0.4692, test loss-1.9914, acc-0.4832\n",
      "Iter-46340, train loss-1.9560, acc-0.6000, valid loss-2.0160, acc-0.4690, test loss-1.9914, acc-0.4833\n",
      "Iter-46350, train loss-2.0364, acc-0.4200, valid loss-2.0159, acc-0.4690, test loss-1.9913, acc-0.4829\n",
      "Iter-46360, train loss-1.9664, acc-0.5000, valid loss-2.0159, acc-0.4692, test loss-1.9913, acc-0.4829\n",
      "Iter-46370, train loss-2.0370, acc-0.4400, valid loss-2.0159, acc-0.4692, test loss-1.9912, acc-0.4829\n",
      "Iter-46380, train loss-1.9965, acc-0.4800, valid loss-2.0158, acc-0.4690, test loss-1.9912, acc-0.4829\n",
      "Iter-46390, train loss-2.0040, acc-0.4400, valid loss-2.0158, acc-0.4692, test loss-1.9911, acc-0.4827\n",
      "Iter-46400, train loss-1.9793, acc-0.4400, valid loss-2.0157, acc-0.4688, test loss-1.9911, acc-0.4829\n",
      "Iter-46410, train loss-1.9997, acc-0.5200, valid loss-2.0157, acc-0.4684, test loss-1.9910, acc-0.4830\n",
      "Iter-46420, train loss-2.0826, acc-0.3800, valid loss-2.0156, acc-0.4688, test loss-1.9910, acc-0.4828\n",
      "Iter-46430, train loss-2.0103, acc-0.4400, valid loss-2.0156, acc-0.4688, test loss-1.9909, acc-0.4828\n",
      "Iter-46440, train loss-1.9878, acc-0.5200, valid loss-2.0156, acc-0.4690, test loss-1.9909, acc-0.4829\n",
      "Iter-46450, train loss-2.0163, acc-0.4400, valid loss-2.0155, acc-0.4688, test loss-1.9908, acc-0.4831\n",
      "Iter-46460, train loss-1.9479, acc-0.6000, valid loss-2.0155, acc-0.4686, test loss-1.9908, acc-0.4832\n",
      "Iter-46470, train loss-2.0122, acc-0.5400, valid loss-2.0154, acc-0.4692, test loss-1.9908, acc-0.4830\n",
      "Iter-46480, train loss-2.0031, acc-0.4200, valid loss-2.0154, acc-0.4690, test loss-1.9907, acc-0.4830\n",
      "Iter-46490, train loss-2.0061, acc-0.4000, valid loss-2.0153, acc-0.4686, test loss-1.9907, acc-0.4831\n",
      "Iter-46500, train loss-2.0328, acc-0.4600, valid loss-2.0153, acc-0.4686, test loss-1.9906, acc-0.4831\n",
      "Iter-46510, train loss-2.0014, acc-0.4800, valid loss-2.0153, acc-0.4684, test loss-1.9906, acc-0.4832\n",
      "Iter-46520, train loss-2.0254, acc-0.3600, valid loss-2.0152, acc-0.4684, test loss-1.9905, acc-0.4830\n",
      "Iter-46530, train loss-1.9828, acc-0.5200, valid loss-2.0152, acc-0.4684, test loss-1.9905, acc-0.4832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-46540, train loss-1.9994, acc-0.5200, valid loss-2.0151, acc-0.4684, test loss-1.9904, acc-0.4830\n",
      "Iter-46550, train loss-2.0311, acc-0.4200, valid loss-2.0151, acc-0.4684, test loss-1.9904, acc-0.4827\n",
      "Iter-46560, train loss-1.9619, acc-0.5400, valid loss-2.0150, acc-0.4688, test loss-1.9903, acc-0.4828\n",
      "Iter-46570, train loss-2.0439, acc-0.4800, valid loss-2.0150, acc-0.4686, test loss-1.9903, acc-0.4831\n",
      "Iter-46580, train loss-1.9704, acc-0.5200, valid loss-2.0150, acc-0.4686, test loss-1.9903, acc-0.4830\n",
      "Iter-46590, train loss-1.9873, acc-0.4600, valid loss-2.0149, acc-0.4686, test loss-1.9902, acc-0.4830\n",
      "Iter-46600, train loss-2.0133, acc-0.4800, valid loss-2.0149, acc-0.4690, test loss-1.9902, acc-0.4830\n",
      "Iter-46610, train loss-2.0334, acc-0.3200, valid loss-2.0148, acc-0.4690, test loss-1.9901, acc-0.4831\n",
      "Iter-46620, train loss-2.0456, acc-0.4600, valid loss-2.0148, acc-0.4688, test loss-1.9901, acc-0.4831\n",
      "Iter-46630, train loss-1.9560, acc-0.5600, valid loss-2.0148, acc-0.4688, test loss-1.9900, acc-0.4831\n",
      "Iter-46640, train loss-1.9672, acc-0.4600, valid loss-2.0147, acc-0.4688, test loss-1.9900, acc-0.4831\n",
      "Iter-46650, train loss-1.9305, acc-0.4800, valid loss-2.0147, acc-0.4686, test loss-1.9899, acc-0.4830\n",
      "Iter-46660, train loss-1.9644, acc-0.4400, valid loss-2.0146, acc-0.4686, test loss-1.9899, acc-0.4831\n",
      "Iter-46670, train loss-1.9686, acc-0.4800, valid loss-2.0146, acc-0.4688, test loss-1.9898, acc-0.4831\n",
      "Iter-46680, train loss-2.0277, acc-0.4000, valid loss-2.0145, acc-0.4682, test loss-1.9898, acc-0.4832\n",
      "Iter-46690, train loss-1.9919, acc-0.4200, valid loss-2.0145, acc-0.4680, test loss-1.9897, acc-0.4832\n",
      "Iter-46700, train loss-1.9871, acc-0.4000, valid loss-2.0145, acc-0.4680, test loss-1.9897, acc-0.4833\n",
      "Iter-46710, train loss-2.0227, acc-0.4000, valid loss-2.0144, acc-0.4686, test loss-1.9896, acc-0.4834\n",
      "Iter-46720, train loss-2.0009, acc-0.5000, valid loss-2.0144, acc-0.4684, test loss-1.9896, acc-0.4833\n",
      "Iter-46730, train loss-2.0358, acc-0.3400, valid loss-2.0143, acc-0.4686, test loss-1.9896, acc-0.4833\n",
      "Iter-46740, train loss-2.0181, acc-0.4200, valid loss-2.0143, acc-0.4686, test loss-1.9895, acc-0.4835\n",
      "Iter-46750, train loss-1.9919, acc-0.5200, valid loss-2.0142, acc-0.4688, test loss-1.9895, acc-0.4832\n",
      "Iter-46760, train loss-1.9474, acc-0.4600, valid loss-2.0142, acc-0.4688, test loss-1.9894, acc-0.4831\n",
      "Iter-46770, train loss-2.0178, acc-0.4200, valid loss-2.0142, acc-0.4684, test loss-1.9894, acc-0.4829\n",
      "Iter-46780, train loss-2.0676, acc-0.3400, valid loss-2.0141, acc-0.4684, test loss-1.9893, acc-0.4830\n",
      "Iter-46790, train loss-2.0070, acc-0.4400, valid loss-2.0141, acc-0.4686, test loss-1.9893, acc-0.4830\n",
      "Iter-46800, train loss-1.9709, acc-0.5200, valid loss-2.0140, acc-0.4686, test loss-1.9892, acc-0.4831\n",
      "Iter-46810, train loss-1.9777, acc-0.4200, valid loss-2.0140, acc-0.4686, test loss-1.9892, acc-0.4831\n",
      "Iter-46820, train loss-1.9631, acc-0.5400, valid loss-2.0139, acc-0.4688, test loss-1.9891, acc-0.4831\n",
      "Iter-46830, train loss-2.0047, acc-0.4400, valid loss-2.0139, acc-0.4688, test loss-1.9891, acc-0.4834\n",
      "Iter-46840, train loss-2.0201, acc-0.4800, valid loss-2.0139, acc-0.4688, test loss-1.9890, acc-0.4833\n",
      "Iter-46850, train loss-2.0137, acc-0.4600, valid loss-2.0138, acc-0.4688, test loss-1.9890, acc-0.4833\n",
      "Iter-46860, train loss-1.9952, acc-0.4200, valid loss-2.0138, acc-0.4688, test loss-1.9889, acc-0.4831\n",
      "Iter-46870, train loss-2.0045, acc-0.4800, valid loss-2.0137, acc-0.4686, test loss-1.9889, acc-0.4831\n",
      "Iter-46880, train loss-1.9697, acc-0.5000, valid loss-2.0137, acc-0.4684, test loss-1.9888, acc-0.4835\n",
      "Iter-46890, train loss-2.0713, acc-0.4000, valid loss-2.0136, acc-0.4684, test loss-1.9888, acc-0.4836\n",
      "Iter-46900, train loss-1.9853, acc-0.5000, valid loss-2.0136, acc-0.4684, test loss-1.9888, acc-0.4835\n",
      "Iter-46910, train loss-1.9791, acc-0.5000, valid loss-2.0136, acc-0.4684, test loss-1.9887, acc-0.4832\n",
      "Iter-46920, train loss-2.0579, acc-0.4200, valid loss-2.0135, acc-0.4682, test loss-1.9887, acc-0.4832\n",
      "Iter-46930, train loss-1.9909, acc-0.4600, valid loss-2.0135, acc-0.4684, test loss-1.9886, acc-0.4833\n",
      "Iter-46940, train loss-1.9700, acc-0.4000, valid loss-2.0134, acc-0.4680, test loss-1.9886, acc-0.4836\n",
      "Iter-46950, train loss-1.9489, acc-0.5400, valid loss-2.0134, acc-0.4678, test loss-1.9885, acc-0.4837\n",
      "Iter-46960, train loss-1.9786, acc-0.5400, valid loss-2.0134, acc-0.4682, test loss-1.9885, acc-0.4837\n",
      "Iter-46970, train loss-2.0032, acc-0.3600, valid loss-2.0133, acc-0.4684, test loss-1.9884, acc-0.4838\n",
      "Iter-46980, train loss-2.0017, acc-0.4800, valid loss-2.0133, acc-0.4684, test loss-1.9884, acc-0.4839\n",
      "Iter-46990, train loss-2.0235, acc-0.4400, valid loss-2.0132, acc-0.4682, test loss-1.9883, acc-0.4839\n",
      "Iter-47000, train loss-2.0475, acc-0.4800, valid loss-2.0132, acc-0.4682, test loss-1.9883, acc-0.4840\n",
      "Iter-47010, train loss-2.0760, acc-0.4200, valid loss-2.0131, acc-0.4684, test loss-1.9882, acc-0.4840\n",
      "Iter-47020, train loss-1.9633, acc-0.5200, valid loss-2.0131, acc-0.4684, test loss-1.9882, acc-0.4838\n",
      "Iter-47030, train loss-1.9640, acc-0.6000, valid loss-2.0131, acc-0.4680, test loss-1.9882, acc-0.4839\n",
      "Iter-47040, train loss-2.0122, acc-0.4200, valid loss-2.0130, acc-0.4684, test loss-1.9881, acc-0.4838\n",
      "Iter-47050, train loss-1.9384, acc-0.5600, valid loss-2.0130, acc-0.4684, test loss-1.9881, acc-0.4837\n",
      "Iter-47060, train loss-1.9863, acc-0.5200, valid loss-2.0129, acc-0.4684, test loss-1.9880, acc-0.4840\n",
      "Iter-47070, train loss-2.0210, acc-0.4200, valid loss-2.0129, acc-0.4686, test loss-1.9880, acc-0.4839\n",
      "Iter-47080, train loss-2.0161, acc-0.4400, valid loss-2.0128, acc-0.4684, test loss-1.9879, acc-0.4840\n",
      "Iter-47090, train loss-2.0040, acc-0.4200, valid loss-2.0128, acc-0.4684, test loss-1.9879, acc-0.4840\n",
      "Iter-47100, train loss-1.9415, acc-0.5600, valid loss-2.0127, acc-0.4688, test loss-1.9878, acc-0.4837\n",
      "Iter-47110, train loss-2.0124, acc-0.4800, valid loss-2.0127, acc-0.4688, test loss-1.9878, acc-0.4838\n",
      "Iter-47120, train loss-1.9991, acc-0.4800, valid loss-2.0127, acc-0.4688, test loss-1.9877, acc-0.4838\n",
      "Iter-47130, train loss-2.0063, acc-0.4600, valid loss-2.0126, acc-0.4688, test loss-1.9877, acc-0.4838\n",
      "Iter-47140, train loss-2.0361, acc-0.4200, valid loss-2.0126, acc-0.4690, test loss-1.9876, acc-0.4839\n",
      "Iter-47150, train loss-2.0069, acc-0.4400, valid loss-2.0125, acc-0.4690, test loss-1.9876, acc-0.4840\n",
      "Iter-47160, train loss-2.0204, acc-0.4400, valid loss-2.0125, acc-0.4690, test loss-1.9875, acc-0.4843\n",
      "Iter-47170, train loss-2.0436, acc-0.4000, valid loss-2.0125, acc-0.4688, test loss-1.9875, acc-0.4843\n",
      "Iter-47180, train loss-1.9982, acc-0.5200, valid loss-2.0124, acc-0.4690, test loss-1.9874, acc-0.4840\n",
      "Iter-47190, train loss-2.0075, acc-0.4400, valid loss-2.0124, acc-0.4692, test loss-1.9874, acc-0.4839\n",
      "Iter-47200, train loss-1.9131, acc-0.6400, valid loss-2.0123, acc-0.4688, test loss-1.9874, acc-0.4840\n",
      "Iter-47210, train loss-2.0374, acc-0.4600, valid loss-2.0123, acc-0.4690, test loss-1.9873, acc-0.4841\n",
      "Iter-47220, train loss-2.1248, acc-0.3400, valid loss-2.0122, acc-0.4690, test loss-1.9873, acc-0.4839\n",
      "Iter-47230, train loss-2.0472, acc-0.3800, valid loss-2.0122, acc-0.4690, test loss-1.9872, acc-0.4840\n",
      "Iter-47240, train loss-2.0186, acc-0.4200, valid loss-2.0122, acc-0.4690, test loss-1.9872, acc-0.4839\n",
      "Iter-47250, train loss-1.9853, acc-0.5200, valid loss-2.0121, acc-0.4692, test loss-1.9871, acc-0.4837\n",
      "Iter-47260, train loss-2.0549, acc-0.4800, valid loss-2.0121, acc-0.4692, test loss-1.9871, acc-0.4839\n",
      "Iter-47270, train loss-2.0045, acc-0.4600, valid loss-2.0120, acc-0.4692, test loss-1.9870, acc-0.4838\n",
      "Iter-47280, train loss-1.9880, acc-0.5200, valid loss-2.0120, acc-0.4690, test loss-1.9870, acc-0.4840\n",
      "Iter-47290, train loss-2.0018, acc-0.4600, valid loss-2.0120, acc-0.4690, test loss-1.9869, acc-0.4840\n",
      "Iter-47300, train loss-2.0195, acc-0.5000, valid loss-2.0119, acc-0.4692, test loss-1.9869, acc-0.4839\n",
      "Iter-47310, train loss-1.9880, acc-0.5400, valid loss-2.0119, acc-0.4698, test loss-1.9868, acc-0.4841\n",
      "Iter-47320, train loss-1.9200, acc-0.5000, valid loss-2.0118, acc-0.4696, test loss-1.9868, acc-0.4843\n",
      "Iter-47330, train loss-1.9800, acc-0.4600, valid loss-2.0118, acc-0.4698, test loss-1.9867, acc-0.4843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-47340, train loss-1.9782, acc-0.5000, valid loss-2.0117, acc-0.4698, test loss-1.9867, acc-0.4844\n",
      "Iter-47350, train loss-1.9693, acc-0.5600, valid loss-2.0117, acc-0.4698, test loss-1.9867, acc-0.4846\n",
      "Iter-47360, train loss-1.9959, acc-0.5400, valid loss-2.0117, acc-0.4696, test loss-1.9866, acc-0.4844\n",
      "Iter-47370, train loss-1.9974, acc-0.4600, valid loss-2.0116, acc-0.4694, test loss-1.9866, acc-0.4843\n",
      "Iter-47380, train loss-1.9767, acc-0.4200, valid loss-2.0116, acc-0.4700, test loss-1.9865, acc-0.4844\n",
      "Iter-47390, train loss-1.9203, acc-0.5000, valid loss-2.0115, acc-0.4704, test loss-1.9865, acc-0.4845\n",
      "Iter-47400, train loss-1.9852, acc-0.4800, valid loss-2.0115, acc-0.4700, test loss-1.9864, acc-0.4843\n",
      "Iter-47410, train loss-1.9266, acc-0.5600, valid loss-2.0114, acc-0.4702, test loss-1.9864, acc-0.4842\n",
      "Iter-47420, train loss-1.9970, acc-0.5200, valid loss-2.0114, acc-0.4704, test loss-1.9863, acc-0.4844\n",
      "Iter-47430, train loss-1.9893, acc-0.4800, valid loss-2.0114, acc-0.4704, test loss-1.9863, acc-0.4843\n",
      "Iter-47440, train loss-1.9664, acc-0.4800, valid loss-2.0113, acc-0.4700, test loss-1.9862, acc-0.4842\n",
      "Iter-47450, train loss-1.8991, acc-0.5800, valid loss-2.0113, acc-0.4698, test loss-1.9862, acc-0.4843\n",
      "Iter-47460, train loss-2.0614, acc-0.4600, valid loss-2.0112, acc-0.4698, test loss-1.9861, acc-0.4844\n",
      "Iter-47470, train loss-2.0531, acc-0.3800, valid loss-2.0112, acc-0.4698, test loss-1.9861, acc-0.4846\n",
      "Iter-47480, train loss-2.0094, acc-0.4400, valid loss-2.0111, acc-0.4700, test loss-1.9860, acc-0.4845\n",
      "Iter-47490, train loss-2.0713, acc-0.3200, valid loss-2.0111, acc-0.4700, test loss-1.9860, acc-0.4844\n",
      "Iter-47500, train loss-2.0021, acc-0.4800, valid loss-2.0111, acc-0.4698, test loss-1.9860, acc-0.4844\n",
      "Iter-47510, train loss-1.9803, acc-0.4200, valid loss-2.0110, acc-0.4696, test loss-1.9859, acc-0.4843\n",
      "Iter-47520, train loss-2.0084, acc-0.4800, valid loss-2.0110, acc-0.4700, test loss-1.9859, acc-0.4843\n",
      "Iter-47530, train loss-1.9989, acc-0.4400, valid loss-2.0109, acc-0.4700, test loss-1.9858, acc-0.4845\n",
      "Iter-47540, train loss-2.0565, acc-0.4600, valid loss-2.0109, acc-0.4702, test loss-1.9858, acc-0.4843\n",
      "Iter-47550, train loss-1.9551, acc-0.6400, valid loss-2.0109, acc-0.4698, test loss-1.9857, acc-0.4847\n",
      "Iter-47560, train loss-2.0175, acc-0.3600, valid loss-2.0108, acc-0.4700, test loss-1.9857, acc-0.4846\n",
      "Iter-47570, train loss-1.9977, acc-0.3000, valid loss-2.0108, acc-0.4698, test loss-1.9856, acc-0.4845\n",
      "Iter-47580, train loss-2.0216, acc-0.4400, valid loss-2.0107, acc-0.4702, test loss-1.9856, acc-0.4845\n",
      "Iter-47590, train loss-1.9468, acc-0.6200, valid loss-2.0107, acc-0.4700, test loss-1.9855, acc-0.4845\n",
      "Iter-47600, train loss-2.0493, acc-0.3800, valid loss-2.0106, acc-0.4702, test loss-1.9855, acc-0.4844\n",
      "Iter-47610, train loss-2.0014, acc-0.4000, valid loss-2.0106, acc-0.4702, test loss-1.9854, acc-0.4845\n",
      "Iter-47620, train loss-1.9614, acc-0.5000, valid loss-2.0106, acc-0.4702, test loss-1.9854, acc-0.4845\n",
      "Iter-47630, train loss-1.9813, acc-0.5200, valid loss-2.0105, acc-0.4700, test loss-1.9853, acc-0.4845\n",
      "Iter-47640, train loss-1.9456, acc-0.5600, valid loss-2.0105, acc-0.4702, test loss-1.9853, acc-0.4846\n",
      "Iter-47650, train loss-1.9300, acc-0.6200, valid loss-2.0104, acc-0.4706, test loss-1.9853, acc-0.4846\n",
      "Iter-47660, train loss-2.0644, acc-0.4800, valid loss-2.0104, acc-0.4704, test loss-1.9852, acc-0.4848\n",
      "Iter-47670, train loss-1.9407, acc-0.5400, valid loss-2.0103, acc-0.4704, test loss-1.9852, acc-0.4847\n",
      "Iter-47680, train loss-1.9473, acc-0.4600, valid loss-2.0103, acc-0.4710, test loss-1.9851, acc-0.4849\n",
      "Iter-47690, train loss-2.0098, acc-0.4000, valid loss-2.0103, acc-0.4704, test loss-1.9851, acc-0.4848\n",
      "Iter-47700, train loss-1.9938, acc-0.4800, valid loss-2.0102, acc-0.4706, test loss-1.9850, acc-0.4849\n",
      "Iter-47710, train loss-1.9733, acc-0.5400, valid loss-2.0102, acc-0.4706, test loss-1.9850, acc-0.4849\n",
      "Iter-47720, train loss-2.0482, acc-0.4200, valid loss-2.0101, acc-0.4706, test loss-1.9849, acc-0.4847\n",
      "Iter-47730, train loss-2.0646, acc-0.5200, valid loss-2.0101, acc-0.4706, test loss-1.9849, acc-0.4848\n",
      "Iter-47740, train loss-1.9521, acc-0.4800, valid loss-2.0101, acc-0.4702, test loss-1.9848, acc-0.4847\n",
      "Iter-47750, train loss-1.9642, acc-0.6000, valid loss-2.0100, acc-0.4704, test loss-1.9848, acc-0.4848\n",
      "Iter-47760, train loss-1.9300, acc-0.5000, valid loss-2.0100, acc-0.4704, test loss-1.9847, acc-0.4848\n",
      "Iter-47770, train loss-1.9867, acc-0.4600, valid loss-2.0099, acc-0.4706, test loss-1.9847, acc-0.4847\n",
      "Iter-47780, train loss-2.0727, acc-0.3800, valid loss-2.0099, acc-0.4700, test loss-1.9847, acc-0.4845\n",
      "Iter-47790, train loss-2.0359, acc-0.4600, valid loss-2.0098, acc-0.4698, test loss-1.9846, acc-0.4845\n",
      "Iter-47800, train loss-2.0699, acc-0.3400, valid loss-2.0098, acc-0.4700, test loss-1.9846, acc-0.4843\n",
      "Iter-47810, train loss-2.0681, acc-0.3600, valid loss-2.0098, acc-0.4698, test loss-1.9845, acc-0.4844\n",
      "Iter-47820, train loss-1.9819, acc-0.4800, valid loss-2.0097, acc-0.4700, test loss-1.9845, acc-0.4844\n",
      "Iter-47830, train loss-2.0112, acc-0.4400, valid loss-2.0097, acc-0.4702, test loss-1.9844, acc-0.4843\n",
      "Iter-47840, train loss-1.9944, acc-0.5800, valid loss-2.0096, acc-0.4700, test loss-1.9844, acc-0.4843\n",
      "Iter-47850, train loss-1.9694, acc-0.4600, valid loss-2.0096, acc-0.4698, test loss-1.9843, acc-0.4844\n",
      "Iter-47860, train loss-2.0062, acc-0.4600, valid loss-2.0096, acc-0.4698, test loss-1.9843, acc-0.4842\n",
      "Iter-47870, train loss-2.0040, acc-0.4800, valid loss-2.0095, acc-0.4698, test loss-1.9842, acc-0.4843\n",
      "Iter-47880, train loss-2.0917, acc-0.3800, valid loss-2.0095, acc-0.4698, test loss-1.9842, acc-0.4843\n",
      "Iter-47890, train loss-1.9649, acc-0.5800, valid loss-2.0094, acc-0.4698, test loss-1.9841, acc-0.4844\n",
      "Iter-47900, train loss-2.0492, acc-0.3000, valid loss-2.0094, acc-0.4698, test loss-1.9841, acc-0.4845\n",
      "Iter-47910, train loss-1.9723, acc-0.4600, valid loss-2.0093, acc-0.4698, test loss-1.9840, acc-0.4846\n",
      "Iter-47920, train loss-1.9947, acc-0.4000, valid loss-2.0093, acc-0.4698, test loss-1.9840, acc-0.4846\n",
      "Iter-47930, train loss-1.9449, acc-0.4600, valid loss-2.0092, acc-0.4696, test loss-1.9839, acc-0.4844\n",
      "Iter-47940, train loss-1.9984, acc-0.5200, valid loss-2.0092, acc-0.4696, test loss-1.9839, acc-0.4846\n",
      "Iter-47950, train loss-2.0044, acc-0.4800, valid loss-2.0092, acc-0.4698, test loss-1.9839, acc-0.4845\n",
      "Iter-47960, train loss-2.0181, acc-0.4800, valid loss-2.0091, acc-0.4698, test loss-1.9838, acc-0.4844\n",
      "Iter-47970, train loss-2.0333, acc-0.4800, valid loss-2.0091, acc-0.4696, test loss-1.9838, acc-0.4845\n",
      "Iter-47980, train loss-2.0376, acc-0.4200, valid loss-2.0090, acc-0.4696, test loss-1.9837, acc-0.4845\n",
      "Iter-47990, train loss-1.9568, acc-0.5800, valid loss-2.0090, acc-0.4694, test loss-1.9837, acc-0.4847\n",
      "Iter-48000, train loss-1.9727, acc-0.5200, valid loss-2.0090, acc-0.4694, test loss-1.9836, acc-0.4847\n",
      "Iter-48010, train loss-2.0120, acc-0.5000, valid loss-2.0089, acc-0.4696, test loss-1.9836, acc-0.4847\n",
      "Iter-48020, train loss-2.0335, acc-0.4400, valid loss-2.0089, acc-0.4698, test loss-1.9835, acc-0.4846\n",
      "Iter-48030, train loss-2.0558, acc-0.4000, valid loss-2.0088, acc-0.4698, test loss-1.9835, acc-0.4846\n",
      "Iter-48040, train loss-1.9088, acc-0.7000, valid loss-2.0088, acc-0.4702, test loss-1.9834, acc-0.4844\n",
      "Iter-48050, train loss-2.0092, acc-0.4800, valid loss-2.0088, acc-0.4702, test loss-1.9834, acc-0.4846\n",
      "Iter-48060, train loss-1.9388, acc-0.5600, valid loss-2.0087, acc-0.4706, test loss-1.9834, acc-0.4845\n",
      "Iter-48070, train loss-1.9647, acc-0.5000, valid loss-2.0087, acc-0.4704, test loss-1.9833, acc-0.4845\n",
      "Iter-48080, train loss-2.0075, acc-0.4800, valid loss-2.0086, acc-0.4706, test loss-1.9833, acc-0.4845\n",
      "Iter-48090, train loss-2.0094, acc-0.4800, valid loss-2.0086, acc-0.4706, test loss-1.9832, acc-0.4843\n",
      "Iter-48100, train loss-2.0492, acc-0.3600, valid loss-2.0085, acc-0.4704, test loss-1.9832, acc-0.4844\n",
      "Iter-48110, train loss-2.0510, acc-0.4600, valid loss-2.0085, acc-0.4706, test loss-1.9831, acc-0.4845\n",
      "Iter-48120, train loss-2.0436, acc-0.4400, valid loss-2.0085, acc-0.4710, test loss-1.9831, acc-0.4849\n",
      "Iter-48130, train loss-1.9819, acc-0.5600, valid loss-2.0084, acc-0.4708, test loss-1.9830, acc-0.4847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48140, train loss-1.9809, acc-0.5400, valid loss-2.0084, acc-0.4704, test loss-1.9830, acc-0.4847\n",
      "Iter-48150, train loss-2.0780, acc-0.2600, valid loss-2.0083, acc-0.4708, test loss-1.9830, acc-0.4848\n",
      "Iter-48160, train loss-2.0255, acc-0.3800, valid loss-2.0083, acc-0.4708, test loss-1.9829, acc-0.4850\n",
      "Iter-48170, train loss-2.0571, acc-0.3600, valid loss-2.0083, acc-0.4710, test loss-1.9829, acc-0.4851\n",
      "Iter-48180, train loss-2.0674, acc-0.2400, valid loss-2.0082, acc-0.4714, test loss-1.9828, acc-0.4850\n",
      "Iter-48190, train loss-2.0467, acc-0.4400, valid loss-2.0082, acc-0.4714, test loss-1.9828, acc-0.4851\n",
      "Iter-48200, train loss-1.9431, acc-0.5200, valid loss-2.0081, acc-0.4714, test loss-1.9827, acc-0.4851\n",
      "Iter-48210, train loss-1.9703, acc-0.4000, valid loss-2.0081, acc-0.4714, test loss-1.9827, acc-0.4850\n",
      "Iter-48220, train loss-1.9728, acc-0.5200, valid loss-2.0081, acc-0.4706, test loss-1.9826, acc-0.4850\n",
      "Iter-48230, train loss-1.9695, acc-0.4600, valid loss-2.0080, acc-0.4714, test loss-1.9826, acc-0.4850\n",
      "Iter-48240, train loss-2.0152, acc-0.5600, valid loss-2.0080, acc-0.4714, test loss-1.9825, acc-0.4851\n",
      "Iter-48250, train loss-1.9670, acc-0.5000, valid loss-2.0079, acc-0.4714, test loss-1.9825, acc-0.4852\n",
      "Iter-48260, train loss-1.9643, acc-0.4800, valid loss-2.0079, acc-0.4712, test loss-1.9825, acc-0.4851\n",
      "Iter-48270, train loss-2.0172, acc-0.5800, valid loss-2.0078, acc-0.4712, test loss-1.9824, acc-0.4852\n",
      "Iter-48280, train loss-2.0163, acc-0.4000, valid loss-2.0078, acc-0.4714, test loss-1.9824, acc-0.4852\n",
      "Iter-48290, train loss-2.0047, acc-0.4600, valid loss-2.0078, acc-0.4712, test loss-1.9823, acc-0.4851\n",
      "Iter-48300, train loss-2.0096, acc-0.4600, valid loss-2.0077, acc-0.4706, test loss-1.9823, acc-0.4851\n",
      "Iter-48310, train loss-2.0005, acc-0.4800, valid loss-2.0077, acc-0.4706, test loss-1.9822, acc-0.4852\n",
      "Iter-48320, train loss-2.0002, acc-0.4400, valid loss-2.0076, acc-0.4706, test loss-1.9822, acc-0.4851\n",
      "Iter-48330, train loss-1.9234, acc-0.5200, valid loss-2.0076, acc-0.4710, test loss-1.9821, acc-0.4850\n",
      "Iter-48340, train loss-2.0602, acc-0.4200, valid loss-2.0075, acc-0.4712, test loss-1.9821, acc-0.4852\n",
      "Iter-48350, train loss-2.0429, acc-0.4200, valid loss-2.0075, acc-0.4710, test loss-1.9820, acc-0.4852\n",
      "Iter-48360, train loss-1.9946, acc-0.4600, valid loss-2.0075, acc-0.4712, test loss-1.9820, acc-0.4854\n",
      "Iter-48370, train loss-2.0544, acc-0.3800, valid loss-2.0074, acc-0.4714, test loss-1.9819, acc-0.4855\n",
      "Iter-48380, train loss-1.9965, acc-0.5000, valid loss-2.0074, acc-0.4712, test loss-1.9819, acc-0.4854\n",
      "Iter-48390, train loss-2.0314, acc-0.3600, valid loss-2.0073, acc-0.4714, test loss-1.9819, acc-0.4857\n",
      "Iter-48400, train loss-1.9770, acc-0.4600, valid loss-2.0073, acc-0.4714, test loss-1.9818, acc-0.4858\n",
      "Iter-48410, train loss-1.9558, acc-0.5400, valid loss-2.0073, acc-0.4714, test loss-1.9818, acc-0.4857\n",
      "Iter-48420, train loss-1.9534, acc-0.5400, valid loss-2.0072, acc-0.4712, test loss-1.9817, acc-0.4857\n",
      "Iter-48430, train loss-1.9688, acc-0.4600, valid loss-2.0072, acc-0.4710, test loss-1.9817, acc-0.4858\n",
      "Iter-48440, train loss-1.9843, acc-0.5000, valid loss-2.0071, acc-0.4710, test loss-1.9816, acc-0.4857\n",
      "Iter-48450, train loss-2.0144, acc-0.4400, valid loss-2.0071, acc-0.4706, test loss-1.9816, acc-0.4855\n",
      "Iter-48460, train loss-1.9713, acc-0.5400, valid loss-2.0070, acc-0.4706, test loss-1.9815, acc-0.4856\n",
      "Iter-48470, train loss-1.9716, acc-0.3600, valid loss-2.0070, acc-0.4708, test loss-1.9815, acc-0.4857\n",
      "Iter-48480, train loss-1.9559, acc-0.5400, valid loss-2.0070, acc-0.4708, test loss-1.9814, acc-0.4858\n",
      "Iter-48490, train loss-2.0407, acc-0.4000, valid loss-2.0069, acc-0.4710, test loss-1.9814, acc-0.4859\n",
      "Iter-48500, train loss-2.0239, acc-0.4600, valid loss-2.0069, acc-0.4704, test loss-1.9813, acc-0.4858\n",
      "Iter-48510, train loss-1.9907, acc-0.4600, valid loss-2.0068, acc-0.4714, test loss-1.9813, acc-0.4858\n",
      "Iter-48520, train loss-2.0469, acc-0.4400, valid loss-2.0068, acc-0.4712, test loss-1.9813, acc-0.4859\n",
      "Iter-48530, train loss-1.9837, acc-0.4000, valid loss-2.0068, acc-0.4714, test loss-1.9812, acc-0.4859\n",
      "Iter-48540, train loss-1.9847, acc-0.5200, valid loss-2.0067, acc-0.4714, test loss-1.9812, acc-0.4859\n",
      "Iter-48550, train loss-2.0480, acc-0.4800, valid loss-2.0067, acc-0.4710, test loss-1.9811, acc-0.4860\n",
      "Iter-48560, train loss-2.0005, acc-0.5000, valid loss-2.0066, acc-0.4712, test loss-1.9811, acc-0.4859\n",
      "Iter-48570, train loss-2.0649, acc-0.4000, valid loss-2.0066, acc-0.4712, test loss-1.9810, acc-0.4859\n",
      "Iter-48580, train loss-1.9335, acc-0.5600, valid loss-2.0065, acc-0.4712, test loss-1.9810, acc-0.4858\n",
      "Iter-48590, train loss-2.1051, acc-0.3000, valid loss-2.0065, acc-0.4716, test loss-1.9809, acc-0.4858\n",
      "Iter-48600, train loss-2.0232, acc-0.4600, valid loss-2.0065, acc-0.4716, test loss-1.9809, acc-0.4858\n",
      "Iter-48610, train loss-1.9363, acc-0.5200, valid loss-2.0064, acc-0.4714, test loss-1.9809, acc-0.4859\n",
      "Iter-48620, train loss-1.9799, acc-0.4000, valid loss-2.0064, acc-0.4714, test loss-1.9808, acc-0.4857\n",
      "Iter-48630, train loss-2.0490, acc-0.4000, valid loss-2.0063, acc-0.4716, test loss-1.9808, acc-0.4857\n",
      "Iter-48640, train loss-1.9918, acc-0.4800, valid loss-2.0063, acc-0.4712, test loss-1.9807, acc-0.4858\n",
      "Iter-48650, train loss-2.0500, acc-0.4000, valid loss-2.0063, acc-0.4714, test loss-1.9807, acc-0.4857\n",
      "Iter-48660, train loss-1.9800, acc-0.4600, valid loss-2.0062, acc-0.4714, test loss-1.9806, acc-0.4858\n",
      "Iter-48670, train loss-1.9966, acc-0.4000, valid loss-2.0062, acc-0.4716, test loss-1.9806, acc-0.4857\n",
      "Iter-48680, train loss-2.0624, acc-0.4000, valid loss-2.0061, acc-0.4716, test loss-1.9805, acc-0.4859\n",
      "Iter-48690, train loss-1.9936, acc-0.4200, valid loss-2.0061, acc-0.4714, test loss-1.9805, acc-0.4859\n",
      "Iter-48700, train loss-2.0124, acc-0.5800, valid loss-2.0060, acc-0.4714, test loss-1.9805, acc-0.4858\n",
      "Iter-48710, train loss-1.9883, acc-0.5400, valid loss-2.0060, acc-0.4718, test loss-1.9804, acc-0.4858\n",
      "Iter-48720, train loss-2.0445, acc-0.5000, valid loss-2.0060, acc-0.4720, test loss-1.9804, acc-0.4857\n",
      "Iter-48730, train loss-1.9712, acc-0.5400, valid loss-2.0059, acc-0.4720, test loss-1.9803, acc-0.4857\n",
      "Iter-48740, train loss-2.0231, acc-0.4800, valid loss-2.0059, acc-0.4722, test loss-1.9803, acc-0.4858\n",
      "Iter-48750, train loss-2.0458, acc-0.4400, valid loss-2.0058, acc-0.4718, test loss-1.9802, acc-0.4858\n",
      "Iter-48760, train loss-2.0009, acc-0.5000, valid loss-2.0058, acc-0.4716, test loss-1.9802, acc-0.4858\n",
      "Iter-48770, train loss-2.0147, acc-0.4600, valid loss-2.0057, acc-0.4714, test loss-1.9801, acc-0.4856\n",
      "Iter-48780, train loss-2.0040, acc-0.4000, valid loss-2.0057, acc-0.4718, test loss-1.9801, acc-0.4858\n",
      "Iter-48790, train loss-2.0360, acc-0.4200, valid loss-2.0057, acc-0.4714, test loss-1.9800, acc-0.4855\n",
      "Iter-48800, train loss-1.9739, acc-0.5000, valid loss-2.0056, acc-0.4712, test loss-1.9800, acc-0.4857\n",
      "Iter-48810, train loss-2.0926, acc-0.3400, valid loss-2.0056, acc-0.4712, test loss-1.9800, acc-0.4856\n",
      "Iter-48820, train loss-1.9565, acc-0.5800, valid loss-2.0056, acc-0.4712, test loss-1.9799, acc-0.4857\n",
      "Iter-48830, train loss-1.9808, acc-0.4000, valid loss-2.0055, acc-0.4714, test loss-1.9799, acc-0.4858\n",
      "Iter-48840, train loss-1.9432, acc-0.5200, valid loss-2.0055, acc-0.4716, test loss-1.9798, acc-0.4859\n",
      "Iter-48850, train loss-1.9354, acc-0.5200, valid loss-2.0054, acc-0.4712, test loss-1.9798, acc-0.4860\n",
      "Iter-48860, train loss-1.9561, acc-0.5000, valid loss-2.0054, acc-0.4718, test loss-1.9797, acc-0.4861\n",
      "Iter-48870, train loss-1.9836, acc-0.4400, valid loss-2.0053, acc-0.4718, test loss-1.9797, acc-0.4859\n",
      "Iter-48880, train loss-1.9835, acc-0.5200, valid loss-2.0053, acc-0.4722, test loss-1.9796, acc-0.4862\n",
      "Iter-48890, train loss-1.9609, acc-0.5000, valid loss-2.0053, acc-0.4720, test loss-1.9796, acc-0.4859\n",
      "Iter-48900, train loss-1.9471, acc-0.5000, valid loss-2.0052, acc-0.4720, test loss-1.9795, acc-0.4860\n",
      "Iter-48910, train loss-2.0552, acc-0.5000, valid loss-2.0052, acc-0.4722, test loss-1.9795, acc-0.4860\n",
      "Iter-48920, train loss-1.9390, acc-0.5000, valid loss-2.0051, acc-0.4722, test loss-1.9794, acc-0.4861\n",
      "Iter-48930, train loss-1.9843, acc-0.5400, valid loss-2.0051, acc-0.4718, test loss-1.9794, acc-0.4859\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48940, train loss-1.9112, acc-0.5600, valid loss-2.0050, acc-0.4716, test loss-1.9794, acc-0.4861\n",
      "Iter-48950, train loss-1.9793, acc-0.4800, valid loss-2.0050, acc-0.4718, test loss-1.9793, acc-0.4860\n",
      "Iter-48960, train loss-2.0004, acc-0.5200, valid loss-2.0050, acc-0.4720, test loss-1.9793, acc-0.4860\n",
      "Iter-48970, train loss-2.0012, acc-0.4600, valid loss-2.0049, acc-0.4720, test loss-1.9792, acc-0.4860\n",
      "Iter-48980, train loss-1.9678, acc-0.4400, valid loss-2.0049, acc-0.4722, test loss-1.9792, acc-0.4860\n",
      "Iter-48990, train loss-2.0086, acc-0.4000, valid loss-2.0048, acc-0.4722, test loss-1.9791, acc-0.4858\n",
      "Iter-49000, train loss-2.0329, acc-0.4200, valid loss-2.0048, acc-0.4718, test loss-1.9791, acc-0.4859\n",
      "Iter-49010, train loss-1.9679, acc-0.5000, valid loss-2.0048, acc-0.4718, test loss-1.9790, acc-0.4861\n",
      "Iter-49020, train loss-2.0074, acc-0.3800, valid loss-2.0047, acc-0.4718, test loss-1.9790, acc-0.4861\n",
      "Iter-49030, train loss-1.9911, acc-0.4800, valid loss-2.0047, acc-0.4714, test loss-1.9789, acc-0.4861\n",
      "Iter-49040, train loss-2.0210, acc-0.4000, valid loss-2.0046, acc-0.4718, test loss-1.9789, acc-0.4862\n",
      "Iter-49050, train loss-1.9879, acc-0.5000, valid loss-2.0046, acc-0.4720, test loss-1.9789, acc-0.4861\n",
      "Iter-49060, train loss-2.0160, acc-0.4200, valid loss-2.0046, acc-0.4720, test loss-1.9788, acc-0.4861\n",
      "Iter-49070, train loss-2.0276, acc-0.4000, valid loss-2.0045, acc-0.4718, test loss-1.9788, acc-0.4862\n",
      "Iter-49080, train loss-2.0960, acc-0.3200, valid loss-2.0045, acc-0.4714, test loss-1.9787, acc-0.4864\n",
      "Iter-49090, train loss-2.0511, acc-0.4400, valid loss-2.0044, acc-0.4716, test loss-1.9787, acc-0.4864\n",
      "Iter-49100, train loss-1.9843, acc-0.5200, valid loss-2.0044, acc-0.4716, test loss-1.9786, acc-0.4864\n",
      "Iter-49110, train loss-1.9639, acc-0.5400, valid loss-2.0043, acc-0.4716, test loss-1.9786, acc-0.4863\n",
      "Iter-49120, train loss-1.9035, acc-0.5600, valid loss-2.0043, acc-0.4716, test loss-1.9785, acc-0.4863\n",
      "Iter-49130, train loss-1.9579, acc-0.5200, valid loss-2.0043, acc-0.4716, test loss-1.9785, acc-0.4865\n",
      "Iter-49140, train loss-1.9210, acc-0.6400, valid loss-2.0042, acc-0.4716, test loss-1.9784, acc-0.4864\n",
      "Iter-49150, train loss-1.9417, acc-0.5200, valid loss-2.0042, acc-0.4716, test loss-1.9784, acc-0.4863\n",
      "Iter-49160, train loss-2.0067, acc-0.4400, valid loss-2.0041, acc-0.4718, test loss-1.9784, acc-0.4865\n",
      "Iter-49170, train loss-1.9613, acc-0.4600, valid loss-2.0041, acc-0.4720, test loss-1.9783, acc-0.4865\n",
      "Iter-49180, train loss-2.0186, acc-0.4800, valid loss-2.0041, acc-0.4722, test loss-1.9783, acc-0.4865\n",
      "Iter-49190, train loss-1.9630, acc-0.5800, valid loss-2.0040, acc-0.4724, test loss-1.9782, acc-0.4865\n",
      "Iter-49200, train loss-2.0140, acc-0.5000, valid loss-2.0040, acc-0.4726, test loss-1.9782, acc-0.4864\n",
      "Iter-49210, train loss-2.0229, acc-0.4400, valid loss-2.0039, acc-0.4724, test loss-1.9781, acc-0.4865\n",
      "Iter-49220, train loss-2.0222, acc-0.4600, valid loss-2.0039, acc-0.4724, test loss-1.9781, acc-0.4867\n",
      "Iter-49230, train loss-2.0697, acc-0.3400, valid loss-2.0039, acc-0.4720, test loss-1.9780, acc-0.4865\n",
      "Iter-49240, train loss-1.9523, acc-0.5000, valid loss-2.0038, acc-0.4722, test loss-1.9780, acc-0.4866\n",
      "Iter-49250, train loss-2.1520, acc-0.4000, valid loss-2.0038, acc-0.4722, test loss-1.9780, acc-0.4865\n",
      "Iter-49260, train loss-1.9018, acc-0.5600, valid loss-2.0037, acc-0.4726, test loss-1.9779, acc-0.4865\n",
      "Iter-49270, train loss-2.0175, acc-0.4600, valid loss-2.0037, acc-0.4728, test loss-1.9779, acc-0.4864\n",
      "Iter-49280, train loss-1.9858, acc-0.4800, valid loss-2.0037, acc-0.4722, test loss-1.9778, acc-0.4863\n",
      "Iter-49290, train loss-1.9986, acc-0.4400, valid loss-2.0036, acc-0.4720, test loss-1.9778, acc-0.4867\n",
      "Iter-49300, train loss-1.9439, acc-0.5400, valid loss-2.0036, acc-0.4720, test loss-1.9777, acc-0.4864\n",
      "Iter-49310, train loss-1.9808, acc-0.5400, valid loss-2.0035, acc-0.4726, test loss-1.9777, acc-0.4863\n",
      "Iter-49320, train loss-2.0091, acc-0.4800, valid loss-2.0035, acc-0.4724, test loss-1.9776, acc-0.4863\n",
      "Iter-49330, train loss-2.1063, acc-0.3600, valid loss-2.0034, acc-0.4726, test loss-1.9776, acc-0.4865\n",
      "Iter-49340, train loss-2.0523, acc-0.4200, valid loss-2.0034, acc-0.4722, test loss-1.9775, acc-0.4865\n",
      "Iter-49350, train loss-2.0675, acc-0.3200, valid loss-2.0034, acc-0.4722, test loss-1.9775, acc-0.4865\n",
      "Iter-49360, train loss-1.9958, acc-0.6000, valid loss-2.0033, acc-0.4724, test loss-1.9775, acc-0.4865\n",
      "Iter-49370, train loss-1.9908, acc-0.5200, valid loss-2.0033, acc-0.4726, test loss-1.9774, acc-0.4864\n",
      "Iter-49380, train loss-1.9789, acc-0.4600, valid loss-2.0032, acc-0.4722, test loss-1.9774, acc-0.4863\n",
      "Iter-49390, train loss-2.0294, acc-0.3800, valid loss-2.0032, acc-0.4728, test loss-1.9773, acc-0.4863\n",
      "Iter-49400, train loss-2.0056, acc-0.4800, valid loss-2.0032, acc-0.4728, test loss-1.9773, acc-0.4865\n",
      "Iter-49410, train loss-2.0377, acc-0.4400, valid loss-2.0031, acc-0.4724, test loss-1.9772, acc-0.4864\n",
      "Iter-49420, train loss-2.0141, acc-0.4800, valid loss-2.0031, acc-0.4722, test loss-1.9772, acc-0.4869\n",
      "Iter-49430, train loss-2.0382, acc-0.5000, valid loss-2.0030, acc-0.4728, test loss-1.9771, acc-0.4866\n",
      "Iter-49440, train loss-2.0386, acc-0.3400, valid loss-2.0030, acc-0.4728, test loss-1.9771, acc-0.4867\n",
      "Iter-49450, train loss-1.9384, acc-0.4400, valid loss-2.0030, acc-0.4730, test loss-1.9770, acc-0.4868\n",
      "Iter-49460, train loss-1.9686, acc-0.6400, valid loss-2.0029, acc-0.4734, test loss-1.9770, acc-0.4872\n",
      "Iter-49470, train loss-2.0328, acc-0.3400, valid loss-2.0029, acc-0.4736, test loss-1.9770, acc-0.4870\n",
      "Iter-49480, train loss-1.9503, acc-0.4600, valid loss-2.0028, acc-0.4734, test loss-1.9769, acc-0.4870\n",
      "Iter-49490, train loss-1.9778, acc-0.4800, valid loss-2.0028, acc-0.4730, test loss-1.9769, acc-0.4868\n",
      "Iter-49500, train loss-1.9272, acc-0.6000, valid loss-2.0028, acc-0.4732, test loss-1.9768, acc-0.4870\n",
      "Iter-49510, train loss-1.9561, acc-0.4400, valid loss-2.0027, acc-0.4732, test loss-1.9768, acc-0.4869\n",
      "Iter-49520, train loss-1.9707, acc-0.4200, valid loss-2.0027, acc-0.4734, test loss-1.9767, acc-0.4868\n",
      "Iter-49530, train loss-2.0566, acc-0.3000, valid loss-2.0026, acc-0.4738, test loss-1.9767, acc-0.4869\n",
      "Iter-49540, train loss-2.0038, acc-0.5000, valid loss-2.0026, acc-0.4732, test loss-1.9766, acc-0.4870\n",
      "Iter-49550, train loss-1.9959, acc-0.4400, valid loss-2.0025, acc-0.4732, test loss-1.9766, acc-0.4871\n",
      "Iter-49560, train loss-2.0739, acc-0.3600, valid loss-2.0025, acc-0.4734, test loss-1.9766, acc-0.4872\n",
      "Iter-49570, train loss-1.9083, acc-0.5800, valid loss-2.0025, acc-0.4736, test loss-1.9765, acc-0.4873\n",
      "Iter-49580, train loss-1.9840, acc-0.4800, valid loss-2.0024, acc-0.4736, test loss-1.9765, acc-0.4874\n",
      "Iter-49590, train loss-1.9950, acc-0.5000, valid loss-2.0024, acc-0.4736, test loss-1.9764, acc-0.4874\n",
      "Iter-49600, train loss-2.0594, acc-0.3800, valid loss-2.0023, acc-0.4736, test loss-1.9764, acc-0.4874\n",
      "Iter-49610, train loss-1.9568, acc-0.4800, valid loss-2.0023, acc-0.4736, test loss-1.9763, acc-0.4874\n",
      "Iter-49620, train loss-2.0313, acc-0.4000, valid loss-2.0023, acc-0.4736, test loss-1.9763, acc-0.4874\n",
      "Iter-49630, train loss-2.0082, acc-0.3400, valid loss-2.0022, acc-0.4738, test loss-1.9762, acc-0.4874\n",
      "Iter-49640, train loss-2.0747, acc-0.3400, valid loss-2.0022, acc-0.4740, test loss-1.9762, acc-0.4875\n",
      "Iter-49650, train loss-1.9252, acc-0.5200, valid loss-2.0021, acc-0.4742, test loss-1.9761, acc-0.4874\n",
      "Iter-49660, train loss-1.9579, acc-0.4800, valid loss-2.0021, acc-0.4742, test loss-1.9761, acc-0.4875\n",
      "Iter-49670, train loss-1.9772, acc-0.5800, valid loss-2.0021, acc-0.4744, test loss-1.9760, acc-0.4876\n",
      "Iter-49680, train loss-1.9823, acc-0.4800, valid loss-2.0020, acc-0.4744, test loss-1.9760, acc-0.4875\n",
      "Iter-49690, train loss-2.0145, acc-0.4200, valid loss-2.0020, acc-0.4742, test loss-1.9760, acc-0.4874\n",
      "Iter-49700, train loss-1.9212, acc-0.6400, valid loss-2.0019, acc-0.4740, test loss-1.9759, acc-0.4875\n",
      "Iter-49710, train loss-1.9591, acc-0.5600, valid loss-2.0019, acc-0.4742, test loss-1.9759, acc-0.4874\n",
      "Iter-49720, train loss-2.0662, acc-0.5000, valid loss-2.0019, acc-0.4742, test loss-1.9758, acc-0.4874\n",
      "Iter-49730, train loss-2.0150, acc-0.5000, valid loss-2.0018, acc-0.4742, test loss-1.9758, acc-0.4876\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-49740, train loss-1.9847, acc-0.4000, valid loss-2.0018, acc-0.4738, test loss-1.9757, acc-0.4877\n",
      "Iter-49750, train loss-2.0100, acc-0.4800, valid loss-2.0017, acc-0.4736, test loss-1.9757, acc-0.4878\n",
      "Iter-49760, train loss-2.0250, acc-0.3600, valid loss-2.0017, acc-0.4742, test loss-1.9756, acc-0.4878\n",
      "Iter-49770, train loss-1.9328, acc-0.5200, valid loss-2.0016, acc-0.4742, test loss-1.9756, acc-0.4877\n",
      "Iter-49780, train loss-1.9765, acc-0.4400, valid loss-2.0016, acc-0.4738, test loss-1.9756, acc-0.4880\n",
      "Iter-49790, train loss-2.0504, acc-0.4200, valid loss-2.0016, acc-0.4742, test loss-1.9755, acc-0.4879\n",
      "Iter-49800, train loss-1.9748, acc-0.5600, valid loss-2.0015, acc-0.4744, test loss-1.9755, acc-0.4881\n",
      "Iter-49810, train loss-2.0391, acc-0.4000, valid loss-2.0015, acc-0.4742, test loss-1.9754, acc-0.4882\n",
      "Iter-49820, train loss-1.9507, acc-0.4000, valid loss-2.0014, acc-0.4740, test loss-1.9754, acc-0.4879\n",
      "Iter-49830, train loss-2.0151, acc-0.4400, valid loss-2.0014, acc-0.4740, test loss-1.9753, acc-0.4879\n",
      "Iter-49840, train loss-1.9106, acc-0.5600, valid loss-2.0014, acc-0.4744, test loss-1.9753, acc-0.4880\n",
      "Iter-49850, train loss-1.9879, acc-0.4800, valid loss-2.0013, acc-0.4750, test loss-1.9752, acc-0.4880\n",
      "Iter-49860, train loss-1.9963, acc-0.5200, valid loss-2.0013, acc-0.4752, test loss-1.9752, acc-0.4881\n",
      "Iter-49870, train loss-2.0089, acc-0.4400, valid loss-2.0012, acc-0.4746, test loss-1.9751, acc-0.4883\n",
      "Iter-49880, train loss-1.9859, acc-0.5600, valid loss-2.0012, acc-0.4752, test loss-1.9751, acc-0.4882\n",
      "Iter-49890, train loss-2.0078, acc-0.5000, valid loss-2.0012, acc-0.4744, test loss-1.9751, acc-0.4880\n",
      "Iter-49900, train loss-2.0415, acc-0.4000, valid loss-2.0011, acc-0.4748, test loss-1.9750, acc-0.4881\n",
      "Iter-49910, train loss-1.9967, acc-0.4200, valid loss-2.0011, acc-0.4748, test loss-1.9750, acc-0.4880\n",
      "Iter-49920, train loss-1.9795, acc-0.4200, valid loss-2.0010, acc-0.4746, test loss-1.9749, acc-0.4880\n",
      "Iter-49930, train loss-1.9301, acc-0.6400, valid loss-2.0010, acc-0.4746, test loss-1.9749, acc-0.4880\n",
      "Iter-49940, train loss-2.0161, acc-0.4600, valid loss-2.0010, acc-0.4748, test loss-1.9748, acc-0.4879\n",
      "Iter-49950, train loss-1.9359, acc-0.5600, valid loss-2.0009, acc-0.4748, test loss-1.9748, acc-0.4880\n",
      "Iter-49960, train loss-1.9970, acc-0.5200, valid loss-2.0009, acc-0.4748, test loss-1.9747, acc-0.4878\n",
      "Iter-49970, train loss-1.9572, acc-0.5200, valid loss-2.0008, acc-0.4748, test loss-1.9747, acc-0.4880\n",
      "Iter-49980, train loss-1.9846, acc-0.5200, valid loss-2.0008, acc-0.4746, test loss-1.9747, acc-0.4878\n",
      "Iter-49990, train loss-1.9489, acc-0.4400, valid loss-2.0007, acc-0.4748, test loss-1.9746, acc-0.4879\n",
      "Iter-50000, train loss-1.9970, acc-0.5400, valid loss-2.0007, acc-0.4748, test loss-1.9746, acc-0.4880\n",
      "Iter-50010, train loss-1.9734, acc-0.4000, valid loss-2.0007, acc-0.4756, test loss-1.9745, acc-0.4882\n",
      "Iter-50020, train loss-1.9265, acc-0.4600, valid loss-2.0006, acc-0.4748, test loss-1.9745, acc-0.4882\n",
      "Iter-50030, train loss-2.0132, acc-0.5000, valid loss-2.0006, acc-0.4754, test loss-1.9744, acc-0.4882\n",
      "Iter-50040, train loss-1.9886, acc-0.4800, valid loss-2.0005, acc-0.4754, test loss-1.9744, acc-0.4878\n",
      "Iter-50050, train loss-1.9978, acc-0.4800, valid loss-2.0005, acc-0.4750, test loss-1.9743, acc-0.4880\n",
      "Iter-50060, train loss-2.0062, acc-0.4400, valid loss-2.0005, acc-0.4750, test loss-1.9743, acc-0.4880\n",
      "Iter-50070, train loss-2.0308, acc-0.4800, valid loss-2.0004, acc-0.4756, test loss-1.9742, acc-0.4881\n",
      "Iter-50080, train loss-2.0313, acc-0.4600, valid loss-2.0004, acc-0.4756, test loss-1.9742, acc-0.4881\n",
      "Iter-50090, train loss-1.9225, acc-0.5800, valid loss-2.0003, acc-0.4754, test loss-1.9742, acc-0.4878\n",
      "Iter-50100, train loss-1.9771, acc-0.4200, valid loss-2.0003, acc-0.4756, test loss-1.9741, acc-0.4880\n",
      "Iter-50110, train loss-1.9673, acc-0.5600, valid loss-2.0003, acc-0.4756, test loss-1.9741, acc-0.4881\n",
      "Iter-50120, train loss-1.9659, acc-0.4600, valid loss-2.0002, acc-0.4752, test loss-1.9740, acc-0.4878\n",
      "Iter-50130, train loss-1.9974, acc-0.5800, valid loss-2.0002, acc-0.4756, test loss-1.9740, acc-0.4882\n",
      "Iter-50140, train loss-1.9456, acc-0.5000, valid loss-2.0001, acc-0.4754, test loss-1.9739, acc-0.4881\n",
      "Iter-50150, train loss-2.0302, acc-0.3800, valid loss-2.0001, acc-0.4754, test loss-1.9739, acc-0.4885\n",
      "Iter-50160, train loss-1.9375, acc-0.5200, valid loss-2.0000, acc-0.4752, test loss-1.9738, acc-0.4885\n",
      "Iter-50170, train loss-2.0723, acc-0.3800, valid loss-2.0000, acc-0.4756, test loss-1.9738, acc-0.4885\n",
      "Iter-50180, train loss-1.9463, acc-0.5600, valid loss-2.0000, acc-0.4756, test loss-1.9737, acc-0.4885\n",
      "Iter-50190, train loss-1.9871, acc-0.5000, valid loss-1.9999, acc-0.4760, test loss-1.9737, acc-0.4885\n",
      "Iter-50200, train loss-1.9662, acc-0.4200, valid loss-1.9999, acc-0.4758, test loss-1.9736, acc-0.4886\n",
      "Iter-50210, train loss-2.0840, acc-0.3600, valid loss-1.9998, acc-0.4762, test loss-1.9736, acc-0.4887\n",
      "Iter-50220, train loss-2.0192, acc-0.5600, valid loss-1.9998, acc-0.4762, test loss-1.9736, acc-0.4887\n",
      "Iter-50230, train loss-2.0902, acc-0.2800, valid loss-1.9998, acc-0.4762, test loss-1.9735, acc-0.4889\n",
      "Iter-50240, train loss-2.0137, acc-0.4200, valid loss-1.9997, acc-0.4762, test loss-1.9735, acc-0.4888\n",
      "Iter-50250, train loss-1.9611, acc-0.5000, valid loss-1.9997, acc-0.4762, test loss-1.9734, acc-0.4886\n",
      "Iter-50260, train loss-1.9673, acc-0.5400, valid loss-1.9997, acc-0.4760, test loss-1.9734, acc-0.4887\n",
      "Iter-50270, train loss-1.9665, acc-0.4400, valid loss-1.9996, acc-0.4756, test loss-1.9733, acc-0.4887\n",
      "Iter-50280, train loss-1.9064, acc-0.4600, valid loss-1.9996, acc-0.4764, test loss-1.9733, acc-0.4887\n",
      "Iter-50290, train loss-1.9415, acc-0.5200, valid loss-1.9995, acc-0.4764, test loss-1.9732, acc-0.4886\n",
      "Iter-50300, train loss-2.0440, acc-0.3600, valid loss-1.9995, acc-0.4762, test loss-1.9732, acc-0.4887\n",
      "Iter-50310, train loss-1.9557, acc-0.5000, valid loss-1.9994, acc-0.4758, test loss-1.9731, acc-0.4885\n",
      "Iter-50320, train loss-2.0099, acc-0.3600, valid loss-1.9994, acc-0.4756, test loss-1.9731, acc-0.4884\n",
      "Iter-50330, train loss-1.9226, acc-0.6000, valid loss-1.9993, acc-0.4760, test loss-1.9731, acc-0.4886\n",
      "Iter-50340, train loss-1.9423, acc-0.5400, valid loss-1.9993, acc-0.4762, test loss-1.9730, acc-0.4885\n",
      "Iter-50350, train loss-1.9835, acc-0.5200, valid loss-1.9993, acc-0.4762, test loss-1.9730, acc-0.4886\n",
      "Iter-50360, train loss-2.0069, acc-0.5200, valid loss-1.9992, acc-0.4762, test loss-1.9729, acc-0.4885\n",
      "Iter-50370, train loss-1.9497, acc-0.5200, valid loss-1.9992, acc-0.4764, test loss-1.9729, acc-0.4885\n",
      "Iter-50380, train loss-1.9834, acc-0.5000, valid loss-1.9991, acc-0.4764, test loss-1.9728, acc-0.4889\n",
      "Iter-50390, train loss-1.9880, acc-0.4600, valid loss-1.9991, acc-0.4764, test loss-1.9728, acc-0.4892\n",
      "Iter-50400, train loss-1.9554, acc-0.4800, valid loss-1.9990, acc-0.4764, test loss-1.9727, acc-0.4890\n",
      "Iter-50410, train loss-1.9973, acc-0.4600, valid loss-1.9990, acc-0.4762, test loss-1.9727, acc-0.4888\n",
      "Iter-50420, train loss-1.9244, acc-0.4000, valid loss-1.9990, acc-0.4762, test loss-1.9726, acc-0.4889\n",
      "Iter-50430, train loss-1.9652, acc-0.4400, valid loss-1.9989, acc-0.4762, test loss-1.9726, acc-0.4889\n",
      "Iter-50440, train loss-2.0485, acc-0.3600, valid loss-1.9989, acc-0.4762, test loss-1.9726, acc-0.4890\n",
      "Iter-50450, train loss-1.9727, acc-0.5200, valid loss-1.9988, acc-0.4758, test loss-1.9725, acc-0.4889\n",
      "Iter-50460, train loss-1.9903, acc-0.3800, valid loss-1.9988, acc-0.4756, test loss-1.9725, acc-0.4888\n",
      "Iter-50470, train loss-1.9615, acc-0.4400, valid loss-1.9988, acc-0.4756, test loss-1.9724, acc-0.4887\n",
      "Iter-50480, train loss-1.9822, acc-0.4400, valid loss-1.9987, acc-0.4762, test loss-1.9724, acc-0.4888\n",
      "Iter-50490, train loss-2.0093, acc-0.5200, valid loss-1.9987, acc-0.4758, test loss-1.9723, acc-0.4889\n",
      "Iter-50500, train loss-1.9891, acc-0.4200, valid loss-1.9986, acc-0.4758, test loss-1.9723, acc-0.4887\n",
      "Iter-50510, train loss-1.9645, acc-0.4600, valid loss-1.9986, acc-0.4756, test loss-1.9723, acc-0.4887\n",
      "Iter-50520, train loss-1.9442, acc-0.4600, valid loss-1.9986, acc-0.4756, test loss-1.9722, acc-0.4886\n",
      "Iter-50530, train loss-1.9664, acc-0.5000, valid loss-1.9985, acc-0.4756, test loss-1.9722, acc-0.4885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-50540, train loss-1.9659, acc-0.5000, valid loss-1.9985, acc-0.4758, test loss-1.9721, acc-0.4882\n",
      "Iter-50550, train loss-1.9604, acc-0.4400, valid loss-1.9984, acc-0.4758, test loss-1.9721, acc-0.4884\n",
      "Iter-50560, train loss-1.9402, acc-0.5000, valid loss-1.9984, acc-0.4756, test loss-1.9720, acc-0.4887\n",
      "Iter-50570, train loss-1.9324, acc-0.5800, valid loss-1.9984, acc-0.4752, test loss-1.9720, acc-0.4886\n",
      "Iter-50580, train loss-1.9845, acc-0.5000, valid loss-1.9983, acc-0.4758, test loss-1.9719, acc-0.4887\n",
      "Iter-50590, train loss-1.9657, acc-0.5400, valid loss-1.9983, acc-0.4756, test loss-1.9719, acc-0.4887\n",
      "Iter-50600, train loss-1.9201, acc-0.4800, valid loss-1.9982, acc-0.4756, test loss-1.9718, acc-0.4887\n",
      "Iter-50610, train loss-1.9945, acc-0.4600, valid loss-1.9982, acc-0.4758, test loss-1.9718, acc-0.4888\n",
      "Iter-50620, train loss-1.9436, acc-0.5600, valid loss-1.9981, acc-0.4756, test loss-1.9717, acc-0.4891\n",
      "Iter-50630, train loss-2.0487, acc-0.4600, valid loss-1.9981, acc-0.4754, test loss-1.9717, acc-0.4889\n",
      "Iter-50640, train loss-1.9817, acc-0.5000, valid loss-1.9981, acc-0.4754, test loss-1.9717, acc-0.4890\n",
      "Iter-50650, train loss-2.0627, acc-0.4000, valid loss-1.9980, acc-0.4752, test loss-1.9716, acc-0.4887\n",
      "Iter-50660, train loss-1.9766, acc-0.5000, valid loss-1.9980, acc-0.4758, test loss-1.9716, acc-0.4890\n",
      "Iter-50670, train loss-2.0001, acc-0.4800, valid loss-1.9979, acc-0.4760, test loss-1.9715, acc-0.4889\n",
      "Iter-50680, train loss-1.9803, acc-0.4600, valid loss-1.9979, acc-0.4762, test loss-1.9715, acc-0.4889\n",
      "Iter-50690, train loss-2.0305, acc-0.3800, valid loss-1.9979, acc-0.4762, test loss-1.9714, acc-0.4891\n",
      "Iter-50700, train loss-1.9189, acc-0.5600, valid loss-1.9978, acc-0.4758, test loss-1.9714, acc-0.4886\n",
      "Iter-50710, train loss-1.9587, acc-0.4600, valid loss-1.9978, acc-0.4758, test loss-1.9713, acc-0.4886\n",
      "Iter-50720, train loss-1.9988, acc-0.5400, valid loss-1.9977, acc-0.4758, test loss-1.9713, acc-0.4889\n",
      "Iter-50730, train loss-1.9738, acc-0.5600, valid loss-1.9977, acc-0.4754, test loss-1.9713, acc-0.4891\n",
      "Iter-50740, train loss-2.0386, acc-0.3400, valid loss-1.9977, acc-0.4756, test loss-1.9712, acc-0.4891\n",
      "Iter-50750, train loss-1.9895, acc-0.4200, valid loss-1.9976, acc-0.4754, test loss-1.9712, acc-0.4891\n",
      "Iter-50760, train loss-1.9474, acc-0.4400, valid loss-1.9976, acc-0.4756, test loss-1.9711, acc-0.4891\n",
      "Iter-50770, train loss-2.0148, acc-0.4200, valid loss-1.9975, acc-0.4756, test loss-1.9711, acc-0.4894\n",
      "Iter-50780, train loss-1.9731, acc-0.4600, valid loss-1.9975, acc-0.4756, test loss-1.9710, acc-0.4893\n",
      "Iter-50790, train loss-2.0196, acc-0.4600, valid loss-1.9975, acc-0.4754, test loss-1.9710, acc-0.4894\n",
      "Iter-50800, train loss-1.9162, acc-0.5400, valid loss-1.9974, acc-0.4752, test loss-1.9709, acc-0.4897\n",
      "Iter-50810, train loss-2.0463, acc-0.4600, valid loss-1.9974, acc-0.4756, test loss-1.9709, acc-0.4896\n",
      "Iter-50820, train loss-1.9569, acc-0.4200, valid loss-1.9973, acc-0.4750, test loss-1.9708, acc-0.4894\n",
      "Iter-50830, train loss-1.9423, acc-0.5800, valid loss-1.9973, acc-0.4756, test loss-1.9708, acc-0.4896\n",
      "Iter-50840, train loss-1.9396, acc-0.4600, valid loss-1.9973, acc-0.4756, test loss-1.9708, acc-0.4896\n",
      "Iter-50850, train loss-1.9125, acc-0.5400, valid loss-1.9972, acc-0.4756, test loss-1.9707, acc-0.4897\n",
      "Iter-50860, train loss-1.9574, acc-0.4000, valid loss-1.9972, acc-0.4760, test loss-1.9707, acc-0.4895\n",
      "Iter-50870, train loss-1.9336, acc-0.4000, valid loss-1.9971, acc-0.4758, test loss-1.9706, acc-0.4893\n",
      "Iter-50880, train loss-1.9700, acc-0.5600, valid loss-1.9971, acc-0.4760, test loss-1.9706, acc-0.4894\n",
      "Iter-50890, train loss-1.9857, acc-0.3800, valid loss-1.9971, acc-0.4760, test loss-1.9705, acc-0.4895\n",
      "Iter-50900, train loss-2.0337, acc-0.4000, valid loss-1.9970, acc-0.4758, test loss-1.9705, acc-0.4899\n",
      "Iter-50910, train loss-2.0075, acc-0.3600, valid loss-1.9970, acc-0.4760, test loss-1.9704, acc-0.4898\n",
      "Iter-50920, train loss-2.0542, acc-0.3600, valid loss-1.9969, acc-0.4760, test loss-1.9704, acc-0.4899\n",
      "Iter-50930, train loss-1.9343, acc-0.6400, valid loss-1.9969, acc-0.4764, test loss-1.9704, acc-0.4899\n",
      "Iter-50940, train loss-1.9274, acc-0.4600, valid loss-1.9969, acc-0.4760, test loss-1.9703, acc-0.4899\n",
      "Iter-50950, train loss-1.9903, acc-0.5200, valid loss-1.9968, acc-0.4762, test loss-1.9703, acc-0.4900\n",
      "Iter-50960, train loss-2.0170, acc-0.4000, valid loss-1.9968, acc-0.4760, test loss-1.9702, acc-0.4900\n",
      "Iter-50970, train loss-1.9766, acc-0.4600, valid loss-1.9967, acc-0.4760, test loss-1.9702, acc-0.4899\n",
      "Iter-50980, train loss-2.0249, acc-0.4600, valid loss-1.9967, acc-0.4760, test loss-1.9701, acc-0.4897\n",
      "Iter-50990, train loss-1.9324, acc-0.6000, valid loss-1.9967, acc-0.4760, test loss-1.9701, acc-0.4898\n",
      "Iter-51000, train loss-2.0362, acc-0.3000, valid loss-1.9966, acc-0.4760, test loss-1.9700, acc-0.4895\n",
      "Iter-51010, train loss-2.0165, acc-0.4800, valid loss-1.9966, acc-0.4760, test loss-1.9700, acc-0.4898\n",
      "Iter-51020, train loss-1.9682, acc-0.4400, valid loss-1.9965, acc-0.4760, test loss-1.9700, acc-0.4896\n",
      "Iter-51030, train loss-1.9868, acc-0.4800, valid loss-1.9965, acc-0.4758, test loss-1.9699, acc-0.4896\n",
      "Iter-51040, train loss-1.9606, acc-0.5400, valid loss-1.9965, acc-0.4758, test loss-1.9699, acc-0.4897\n",
      "Iter-51050, train loss-1.9743, acc-0.3800, valid loss-1.9964, acc-0.4760, test loss-1.9698, acc-0.4901\n",
      "Iter-51060, train loss-1.9403, acc-0.6000, valid loss-1.9964, acc-0.4760, test loss-1.9698, acc-0.4898\n",
      "Iter-51070, train loss-1.9065, acc-0.5400, valid loss-1.9963, acc-0.4760, test loss-1.9697, acc-0.4898\n",
      "Iter-51080, train loss-1.9804, acc-0.5400, valid loss-1.9963, acc-0.4760, test loss-1.9697, acc-0.4898\n",
      "Iter-51090, train loss-1.9868, acc-0.4000, valid loss-1.9963, acc-0.4760, test loss-1.9696, acc-0.4898\n",
      "Iter-51100, train loss-1.9497, acc-0.5200, valid loss-1.9962, acc-0.4762, test loss-1.9696, acc-0.4897\n",
      "Iter-51110, train loss-1.9356, acc-0.4600, valid loss-1.9962, acc-0.4762, test loss-1.9696, acc-0.4899\n",
      "Iter-51120, train loss-1.9688, acc-0.5000, valid loss-1.9961, acc-0.4758, test loss-1.9695, acc-0.4902\n",
      "Iter-51130, train loss-1.9440, acc-0.6000, valid loss-1.9961, acc-0.4754, test loss-1.9695, acc-0.4896\n",
      "Iter-51140, train loss-1.9376, acc-0.6200, valid loss-1.9961, acc-0.4758, test loss-1.9694, acc-0.4896\n",
      "Iter-51150, train loss-1.9602, acc-0.4200, valid loss-1.9960, acc-0.4756, test loss-1.9694, acc-0.4893\n",
      "Iter-51160, train loss-2.0009, acc-0.5200, valid loss-1.9960, acc-0.4758, test loss-1.9693, acc-0.4898\n",
      "Iter-51170, train loss-2.0475, acc-0.3600, valid loss-1.9959, acc-0.4756, test loss-1.9693, acc-0.4897\n",
      "Iter-51180, train loss-1.8991, acc-0.6800, valid loss-1.9959, acc-0.4756, test loss-1.9692, acc-0.4901\n",
      "Iter-51190, train loss-1.9834, acc-0.4800, valid loss-1.9959, acc-0.4758, test loss-1.9692, acc-0.4901\n",
      "Iter-51200, train loss-1.9655, acc-0.5400, valid loss-1.9958, acc-0.4760, test loss-1.9692, acc-0.4900\n",
      "Iter-51210, train loss-1.9550, acc-0.5200, valid loss-1.9958, acc-0.4762, test loss-1.9691, acc-0.4906\n",
      "Iter-51220, train loss-1.9703, acc-0.5800, valid loss-1.9957, acc-0.4764, test loss-1.9691, acc-0.4906\n",
      "Iter-51230, train loss-1.9820, acc-0.4800, valid loss-1.9957, acc-0.4760, test loss-1.9690, acc-0.4905\n",
      "Iter-51240, train loss-1.8728, acc-0.5400, valid loss-1.9957, acc-0.4762, test loss-1.9690, acc-0.4902\n",
      "Iter-51250, train loss-1.9890, acc-0.4400, valid loss-1.9956, acc-0.4762, test loss-1.9689, acc-0.4900\n",
      "Iter-51260, train loss-1.9471, acc-0.5200, valid loss-1.9956, acc-0.4760, test loss-1.9689, acc-0.4901\n",
      "Iter-51270, train loss-1.9789, acc-0.4400, valid loss-1.9955, acc-0.4762, test loss-1.9688, acc-0.4902\n",
      "Iter-51280, train loss-1.9254, acc-0.6200, valid loss-1.9955, acc-0.4762, test loss-1.9688, acc-0.4900\n",
      "Iter-51290, train loss-1.9950, acc-0.3800, valid loss-1.9954, acc-0.4768, test loss-1.9687, acc-0.4901\n",
      "Iter-51300, train loss-1.9790, acc-0.4400, valid loss-1.9954, acc-0.4764, test loss-1.9687, acc-0.4900\n",
      "Iter-51310, train loss-2.0096, acc-0.3800, valid loss-1.9954, acc-0.4766, test loss-1.9687, acc-0.4902\n",
      "Iter-51320, train loss-1.9486, acc-0.5000, valid loss-1.9953, acc-0.4768, test loss-1.9686, acc-0.4902\n",
      "Iter-51330, train loss-2.0461, acc-0.4800, valid loss-1.9953, acc-0.4768, test loss-1.9686, acc-0.4904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-51340, train loss-1.9662, acc-0.5200, valid loss-1.9952, acc-0.4768, test loss-1.9685, acc-0.4902\n",
      "Iter-51350, train loss-1.9801, acc-0.5000, valid loss-1.9952, acc-0.4766, test loss-1.9685, acc-0.4902\n",
      "Iter-51360, train loss-2.0678, acc-0.3200, valid loss-1.9952, acc-0.4768, test loss-1.9684, acc-0.4904\n",
      "Iter-51370, train loss-2.0289, acc-0.3200, valid loss-1.9951, acc-0.4766, test loss-1.9684, acc-0.4903\n",
      "Iter-51380, train loss-2.0253, acc-0.4000, valid loss-1.9951, acc-0.4766, test loss-1.9683, acc-0.4902\n",
      "Iter-51390, train loss-2.0414, acc-0.3200, valid loss-1.9950, acc-0.4766, test loss-1.9683, acc-0.4902\n",
      "Iter-51400, train loss-1.9448, acc-0.4600, valid loss-1.9950, acc-0.4764, test loss-1.9683, acc-0.4906\n",
      "Iter-51410, train loss-1.8866, acc-0.6000, valid loss-1.9949, acc-0.4764, test loss-1.9682, acc-0.4905\n",
      "Iter-51420, train loss-2.0086, acc-0.4400, valid loss-1.9949, acc-0.4764, test loss-1.9682, acc-0.4905\n",
      "Iter-51430, train loss-1.9273, acc-0.4400, valid loss-1.9949, acc-0.4768, test loss-1.9681, acc-0.4905\n",
      "Iter-51440, train loss-2.0529, acc-0.4800, valid loss-1.9948, acc-0.4766, test loss-1.9681, acc-0.4905\n",
      "Iter-51450, train loss-1.9526, acc-0.5000, valid loss-1.9948, acc-0.4768, test loss-1.9680, acc-0.4907\n",
      "Iter-51460, train loss-2.0091, acc-0.4600, valid loss-1.9947, acc-0.4770, test loss-1.9680, acc-0.4907\n",
      "Iter-51470, train loss-1.9296, acc-0.4600, valid loss-1.9947, acc-0.4770, test loss-1.9679, acc-0.4907\n",
      "Iter-51480, train loss-1.9491, acc-0.4200, valid loss-1.9947, acc-0.4768, test loss-1.9679, acc-0.4906\n",
      "Iter-51490, train loss-1.9738, acc-0.4800, valid loss-1.9946, acc-0.4772, test loss-1.9678, acc-0.4905\n",
      "Iter-51500, train loss-1.9642, acc-0.4800, valid loss-1.9946, acc-0.4772, test loss-1.9678, acc-0.4907\n",
      "Iter-51510, train loss-1.9461, acc-0.5200, valid loss-1.9945, acc-0.4774, test loss-1.9678, acc-0.4910\n",
      "Iter-51520, train loss-1.9671, acc-0.4800, valid loss-1.9945, acc-0.4772, test loss-1.9677, acc-0.4908\n",
      "Iter-51530, train loss-2.0122, acc-0.4400, valid loss-1.9945, acc-0.4772, test loss-1.9677, acc-0.4911\n",
      "Iter-51540, train loss-1.9920, acc-0.5200, valid loss-1.9944, acc-0.4770, test loss-1.9676, acc-0.4911\n",
      "Iter-51550, train loss-2.0094, acc-0.4200, valid loss-1.9944, acc-0.4776, test loss-1.9676, acc-0.4911\n",
      "Iter-51560, train loss-2.0471, acc-0.3200, valid loss-1.9943, acc-0.4774, test loss-1.9675, acc-0.4911\n",
      "Iter-51570, train loss-1.9659, acc-0.4800, valid loss-1.9943, acc-0.4770, test loss-1.9675, acc-0.4910\n",
      "Iter-51580, train loss-2.0702, acc-0.4000, valid loss-1.9943, acc-0.4770, test loss-1.9675, acc-0.4908\n",
      "Iter-51590, train loss-1.9823, acc-0.4600, valid loss-1.9942, acc-0.4768, test loss-1.9674, acc-0.4909\n",
      "Iter-51600, train loss-1.9789, acc-0.5200, valid loss-1.9942, acc-0.4770, test loss-1.9674, acc-0.4911\n",
      "Iter-51610, train loss-1.9590, acc-0.5400, valid loss-1.9941, acc-0.4774, test loss-1.9673, acc-0.4912\n",
      "Iter-51620, train loss-1.9435, acc-0.5200, valid loss-1.9941, acc-0.4776, test loss-1.9673, acc-0.4911\n",
      "Iter-51630, train loss-1.8655, acc-0.6000, valid loss-1.9941, acc-0.4772, test loss-1.9672, acc-0.4909\n",
      "Iter-51640, train loss-1.9311, acc-0.5000, valid loss-1.9940, acc-0.4778, test loss-1.9672, acc-0.4911\n",
      "Iter-51650, train loss-1.9399, acc-0.5200, valid loss-1.9940, acc-0.4778, test loss-1.9671, acc-0.4912\n",
      "Iter-51660, train loss-2.0023, acc-0.3200, valid loss-1.9939, acc-0.4778, test loss-1.9671, acc-0.4913\n",
      "Iter-51670, train loss-1.9603, acc-0.5000, valid loss-1.9939, acc-0.4780, test loss-1.9670, acc-0.4914\n",
      "Iter-51680, train loss-1.9722, acc-0.4800, valid loss-1.9939, acc-0.4778, test loss-1.9670, acc-0.4913\n",
      "Iter-51690, train loss-2.0213, acc-0.4200, valid loss-1.9938, acc-0.4780, test loss-1.9670, acc-0.4912\n",
      "Iter-51700, train loss-1.8831, acc-0.6400, valid loss-1.9938, acc-0.4780, test loss-1.9669, acc-0.4913\n",
      "Iter-51710, train loss-1.9085, acc-0.5800, valid loss-1.9937, acc-0.4782, test loss-1.9669, acc-0.4912\n",
      "Iter-51720, train loss-2.0921, acc-0.3400, valid loss-1.9937, acc-0.4780, test loss-1.9668, acc-0.4913\n",
      "Iter-51730, train loss-1.9757, acc-0.4200, valid loss-1.9937, acc-0.4780, test loss-1.9668, acc-0.4913\n",
      "Iter-51740, train loss-2.0066, acc-0.4600, valid loss-1.9936, acc-0.4780, test loss-1.9667, acc-0.4914\n",
      "Iter-51750, train loss-2.0825, acc-0.3400, valid loss-1.9936, acc-0.4778, test loss-1.9667, acc-0.4915\n",
      "Iter-51760, train loss-1.9636, acc-0.5200, valid loss-1.9935, acc-0.4782, test loss-1.9666, acc-0.4913\n",
      "Iter-51770, train loss-1.9302, acc-0.5000, valid loss-1.9935, acc-0.4778, test loss-1.9666, acc-0.4914\n",
      "Iter-51780, train loss-1.9722, acc-0.4200, valid loss-1.9935, acc-0.4780, test loss-1.9665, acc-0.4914\n",
      "Iter-51790, train loss-1.9641, acc-0.4600, valid loss-1.9934, acc-0.4782, test loss-1.9665, acc-0.4912\n",
      "Iter-51800, train loss-1.9435, acc-0.5600, valid loss-1.9934, acc-0.4780, test loss-1.9665, acc-0.4913\n",
      "Iter-51810, train loss-2.0173, acc-0.4000, valid loss-1.9933, acc-0.4784, test loss-1.9664, acc-0.4912\n",
      "Iter-51820, train loss-1.9967, acc-0.4600, valid loss-1.9933, acc-0.4784, test loss-1.9664, acc-0.4912\n",
      "Iter-51830, train loss-1.9658, acc-0.5000, valid loss-1.9933, acc-0.4784, test loss-1.9663, acc-0.4912\n",
      "Iter-51840, train loss-1.9676, acc-0.4400, valid loss-1.9932, acc-0.4784, test loss-1.9663, acc-0.4913\n",
      "Iter-51850, train loss-1.9407, acc-0.4400, valid loss-1.9932, acc-0.4784, test loss-1.9662, acc-0.4914\n",
      "Iter-51860, train loss-1.8942, acc-0.5800, valid loss-1.9931, acc-0.4784, test loss-1.9662, acc-0.4912\n",
      "Iter-51870, train loss-1.9472, acc-0.5200, valid loss-1.9931, acc-0.4784, test loss-1.9661, acc-0.4912\n",
      "Iter-51880, train loss-1.9054, acc-0.5600, valid loss-1.9931, acc-0.4784, test loss-1.9661, acc-0.4913\n",
      "Iter-51890, train loss-2.0135, acc-0.4400, valid loss-1.9930, acc-0.4784, test loss-1.9661, acc-0.4912\n",
      "Iter-51900, train loss-2.0252, acc-0.3800, valid loss-1.9930, acc-0.4784, test loss-1.9660, acc-0.4913\n",
      "Iter-51910, train loss-1.9148, acc-0.5800, valid loss-1.9929, acc-0.4782, test loss-1.9660, acc-0.4912\n",
      "Iter-51920, train loss-1.9424, acc-0.5600, valid loss-1.9929, acc-0.4784, test loss-1.9659, acc-0.4909\n",
      "Iter-51930, train loss-2.0692, acc-0.3800, valid loss-1.9928, acc-0.4788, test loss-1.9659, acc-0.4912\n",
      "Iter-51940, train loss-1.9637, acc-0.5200, valid loss-1.9928, acc-0.4784, test loss-1.9658, acc-0.4913\n",
      "Iter-51950, train loss-2.0633, acc-0.4000, valid loss-1.9928, acc-0.4782, test loss-1.9658, acc-0.4913\n",
      "Iter-51960, train loss-1.9836, acc-0.5800, valid loss-1.9927, acc-0.4784, test loss-1.9657, acc-0.4912\n",
      "Iter-51970, train loss-1.9869, acc-0.4800, valid loss-1.9927, acc-0.4784, test loss-1.9657, acc-0.4912\n",
      "Iter-51980, train loss-2.0446, acc-0.4200, valid loss-1.9927, acc-0.4784, test loss-1.9657, acc-0.4914\n",
      "Iter-51990, train loss-1.9374, acc-0.4800, valid loss-1.9926, acc-0.4784, test loss-1.9656, acc-0.4914\n",
      "Iter-52000, train loss-1.9404, acc-0.6000, valid loss-1.9926, acc-0.4784, test loss-1.9656, acc-0.4918\n",
      "Iter-52010, train loss-1.9909, acc-0.4000, valid loss-1.9925, acc-0.4782, test loss-1.9655, acc-0.4917\n",
      "Iter-52020, train loss-2.0541, acc-0.3800, valid loss-1.9925, acc-0.4780, test loss-1.9655, acc-0.4917\n",
      "Iter-52030, train loss-2.0109, acc-0.4800, valid loss-1.9925, acc-0.4780, test loss-1.9654, acc-0.4918\n",
      "Iter-52040, train loss-1.9898, acc-0.3600, valid loss-1.9924, acc-0.4778, test loss-1.9654, acc-0.4916\n",
      "Iter-52050, train loss-1.9609, acc-0.6000, valid loss-1.9924, acc-0.4778, test loss-1.9653, acc-0.4915\n",
      "Iter-52060, train loss-1.9777, acc-0.4200, valid loss-1.9923, acc-0.4782, test loss-1.9653, acc-0.4915\n",
      "Iter-52070, train loss-1.8800, acc-0.6400, valid loss-1.9923, acc-0.4780, test loss-1.9652, acc-0.4916\n",
      "Iter-52080, train loss-2.0314, acc-0.4000, valid loss-1.9922, acc-0.4782, test loss-1.9652, acc-0.4916\n",
      "Iter-52090, train loss-1.9633, acc-0.4400, valid loss-1.9922, acc-0.4780, test loss-1.9652, acc-0.4916\n",
      "Iter-52100, train loss-1.9245, acc-0.4800, valid loss-1.9922, acc-0.4782, test loss-1.9651, acc-0.4917\n",
      "Iter-52110, train loss-1.9555, acc-0.5200, valid loss-1.9921, acc-0.4780, test loss-1.9651, acc-0.4916\n",
      "Iter-52120, train loss-1.9239, acc-0.6000, valid loss-1.9921, acc-0.4780, test loss-1.9650, acc-0.4916\n",
      "Iter-52130, train loss-1.9885, acc-0.5000, valid loss-1.9920, acc-0.4778, test loss-1.9650, acc-0.4917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52140, train loss-2.0406, acc-0.4400, valid loss-1.9920, acc-0.4776, test loss-1.9649, acc-0.4916\n",
      "Iter-52150, train loss-1.9649, acc-0.5600, valid loss-1.9920, acc-0.4776, test loss-1.9649, acc-0.4915\n",
      "Iter-52160, train loss-1.9246, acc-0.5400, valid loss-1.9919, acc-0.4780, test loss-1.9649, acc-0.4915\n",
      "Iter-52170, train loss-2.0296, acc-0.4400, valid loss-1.9919, acc-0.4780, test loss-1.9648, acc-0.4915\n",
      "Iter-52180, train loss-1.9897, acc-0.4800, valid loss-1.9918, acc-0.4782, test loss-1.9648, acc-0.4915\n",
      "Iter-52190, train loss-1.9414, acc-0.4200, valid loss-1.9918, acc-0.4780, test loss-1.9647, acc-0.4916\n",
      "Iter-52200, train loss-1.9802, acc-0.4400, valid loss-1.9918, acc-0.4780, test loss-1.9647, acc-0.4917\n",
      "Iter-52210, train loss-1.9890, acc-0.4200, valid loss-1.9917, acc-0.4778, test loss-1.9646, acc-0.4918\n",
      "Iter-52220, train loss-1.9899, acc-0.5000, valid loss-1.9917, acc-0.4778, test loss-1.9646, acc-0.4919\n",
      "Iter-52230, train loss-1.9332, acc-0.5800, valid loss-1.9916, acc-0.4778, test loss-1.9645, acc-0.4919\n",
      "Iter-52240, train loss-2.0112, acc-0.5600, valid loss-1.9916, acc-0.4780, test loss-1.9645, acc-0.4919\n",
      "Iter-52250, train loss-1.9928, acc-0.4600, valid loss-1.9916, acc-0.4782, test loss-1.9645, acc-0.4920\n",
      "Iter-52260, train loss-2.0098, acc-0.4600, valid loss-1.9915, acc-0.4782, test loss-1.9644, acc-0.4920\n",
      "Iter-52270, train loss-2.0064, acc-0.5600, valid loss-1.9915, acc-0.4782, test loss-1.9644, acc-0.4920\n",
      "Iter-52280, train loss-1.9928, acc-0.4800, valid loss-1.9914, acc-0.4780, test loss-1.9643, acc-0.4919\n",
      "Iter-52290, train loss-2.0057, acc-0.4200, valid loss-1.9914, acc-0.4780, test loss-1.9643, acc-0.4919\n",
      "Iter-52300, train loss-1.9931, acc-0.4800, valid loss-1.9914, acc-0.4776, test loss-1.9642, acc-0.4919\n",
      "Iter-52310, train loss-2.0248, acc-0.5000, valid loss-1.9913, acc-0.4776, test loss-1.9642, acc-0.4920\n",
      "Iter-52320, train loss-2.0095, acc-0.3400, valid loss-1.9913, acc-0.4776, test loss-1.9642, acc-0.4920\n",
      "Iter-52330, train loss-2.0845, acc-0.4200, valid loss-1.9913, acc-0.4776, test loss-1.9641, acc-0.4920\n",
      "Iter-52340, train loss-1.9397, acc-0.6400, valid loss-1.9912, acc-0.4778, test loss-1.9641, acc-0.4918\n",
      "Iter-52350, train loss-1.9819, acc-0.5200, valid loss-1.9912, acc-0.4778, test loss-1.9640, acc-0.4919\n",
      "Iter-52360, train loss-2.0021, acc-0.4400, valid loss-1.9911, acc-0.4776, test loss-1.9640, acc-0.4919\n",
      "Iter-52370, train loss-1.9948, acc-0.4800, valid loss-1.9911, acc-0.4780, test loss-1.9639, acc-0.4917\n",
      "Iter-52380, train loss-2.0131, acc-0.5000, valid loss-1.9911, acc-0.4780, test loss-1.9639, acc-0.4917\n",
      "Iter-52390, train loss-1.9953, acc-0.4200, valid loss-1.9910, acc-0.4782, test loss-1.9638, acc-0.4915\n",
      "Iter-52400, train loss-1.9737, acc-0.5000, valid loss-1.9910, acc-0.4782, test loss-1.9638, acc-0.4917\n",
      "Iter-52410, train loss-1.9524, acc-0.5400, valid loss-1.9909, acc-0.4780, test loss-1.9638, acc-0.4917\n",
      "Iter-52420, train loss-1.9480, acc-0.6200, valid loss-1.9909, acc-0.4778, test loss-1.9637, acc-0.4918\n",
      "Iter-52430, train loss-1.9518, acc-0.5200, valid loss-1.9909, acc-0.4778, test loss-1.9637, acc-0.4918\n",
      "Iter-52440, train loss-1.9474, acc-0.5000, valid loss-1.9908, acc-0.4780, test loss-1.9636, acc-0.4918\n",
      "Iter-52450, train loss-1.9303, acc-0.5200, valid loss-1.9908, acc-0.4776, test loss-1.9636, acc-0.4916\n",
      "Iter-52460, train loss-2.0092, acc-0.4000, valid loss-1.9907, acc-0.4774, test loss-1.9635, acc-0.4918\n",
      "Iter-52470, train loss-1.9094, acc-0.5800, valid loss-1.9907, acc-0.4776, test loss-1.9635, acc-0.4918\n",
      "Iter-52480, train loss-2.0063, acc-0.4600, valid loss-1.9907, acc-0.4780, test loss-1.9635, acc-0.4918\n",
      "Iter-52490, train loss-2.0303, acc-0.4200, valid loss-1.9906, acc-0.4778, test loss-1.9634, acc-0.4919\n",
      "Iter-52500, train loss-1.9838, acc-0.5000, valid loss-1.9906, acc-0.4784, test loss-1.9634, acc-0.4918\n",
      "Iter-52510, train loss-1.9114, acc-0.5000, valid loss-1.9905, acc-0.4782, test loss-1.9633, acc-0.4917\n",
      "Iter-52520, train loss-1.9174, acc-0.4800, valid loss-1.9905, acc-0.4784, test loss-1.9633, acc-0.4917\n",
      "Iter-52530, train loss-1.9480, acc-0.4400, valid loss-1.9905, acc-0.4784, test loss-1.9632, acc-0.4922\n",
      "Iter-52540, train loss-1.9090, acc-0.5400, valid loss-1.9904, acc-0.4782, test loss-1.9632, acc-0.4923\n",
      "Iter-52550, train loss-1.9166, acc-0.5600, valid loss-1.9904, acc-0.4782, test loss-1.9631, acc-0.4924\n",
      "Iter-52560, train loss-2.0013, acc-0.4400, valid loss-1.9903, acc-0.4786, test loss-1.9631, acc-0.4925\n",
      "Iter-52570, train loss-2.1022, acc-0.3600, valid loss-1.9903, acc-0.4784, test loss-1.9631, acc-0.4924\n",
      "Iter-52580, train loss-1.9573, acc-0.6000, valid loss-1.9903, acc-0.4784, test loss-1.9630, acc-0.4923\n",
      "Iter-52590, train loss-1.9558, acc-0.4800, valid loss-1.9902, acc-0.4786, test loss-1.9630, acc-0.4924\n",
      "Iter-52600, train loss-1.9268, acc-0.5800, valid loss-1.9902, acc-0.4786, test loss-1.9629, acc-0.4924\n",
      "Iter-52610, train loss-2.0073, acc-0.4600, valid loss-1.9901, acc-0.4786, test loss-1.9629, acc-0.4924\n",
      "Iter-52620, train loss-1.9418, acc-0.5800, valid loss-1.9901, acc-0.4786, test loss-1.9628, acc-0.4924\n",
      "Iter-52630, train loss-1.9385, acc-0.5400, valid loss-1.9901, acc-0.4786, test loss-1.9628, acc-0.4923\n",
      "Iter-52640, train loss-2.0352, acc-0.4000, valid loss-1.9900, acc-0.4784, test loss-1.9628, acc-0.4924\n",
      "Iter-52650, train loss-1.9419, acc-0.5400, valid loss-1.9900, acc-0.4788, test loss-1.9627, acc-0.4923\n",
      "Iter-52660, train loss-1.9751, acc-0.4200, valid loss-1.9899, acc-0.4786, test loss-1.9627, acc-0.4923\n",
      "Iter-52670, train loss-1.9087, acc-0.6400, valid loss-1.9899, acc-0.4784, test loss-1.9626, acc-0.4923\n",
      "Iter-52680, train loss-1.9704, acc-0.4400, valid loss-1.9899, acc-0.4788, test loss-1.9626, acc-0.4923\n",
      "Iter-52690, train loss-1.9536, acc-0.5200, valid loss-1.9898, acc-0.4786, test loss-1.9625, acc-0.4923\n",
      "Iter-52700, train loss-2.0046, acc-0.4800, valid loss-1.9898, acc-0.4780, test loss-1.9625, acc-0.4922\n",
      "Iter-52710, train loss-1.9040, acc-0.5600, valid loss-1.9897, acc-0.4782, test loss-1.9625, acc-0.4921\n",
      "Iter-52720, train loss-1.9444, acc-0.5400, valid loss-1.9897, acc-0.4780, test loss-1.9624, acc-0.4918\n",
      "Iter-52730, train loss-2.0019, acc-0.5000, valid loss-1.9897, acc-0.4782, test loss-1.9624, acc-0.4918\n",
      "Iter-52740, train loss-1.9898, acc-0.5200, valid loss-1.9896, acc-0.4782, test loss-1.9623, acc-0.4919\n",
      "Iter-52750, train loss-2.0603, acc-0.4000, valid loss-1.9896, acc-0.4782, test loss-1.9623, acc-0.4916\n",
      "Iter-52760, train loss-1.9637, acc-0.4600, valid loss-1.9895, acc-0.4780, test loss-1.9622, acc-0.4919\n",
      "Iter-52770, train loss-1.9907, acc-0.5600, valid loss-1.9895, acc-0.4780, test loss-1.9622, acc-0.4918\n",
      "Iter-52780, train loss-1.9845, acc-0.4800, valid loss-1.9895, acc-0.4780, test loss-1.9622, acc-0.4918\n",
      "Iter-52790, train loss-2.0069, acc-0.4000, valid loss-1.9894, acc-0.4780, test loss-1.9621, acc-0.4915\n",
      "Iter-52800, train loss-1.9883, acc-0.5000, valid loss-1.9894, acc-0.4782, test loss-1.9621, acc-0.4917\n",
      "Iter-52810, train loss-1.9714, acc-0.5200, valid loss-1.9893, acc-0.4780, test loss-1.9620, acc-0.4915\n",
      "Iter-52820, train loss-2.0427, acc-0.4600, valid loss-1.9893, acc-0.4780, test loss-1.9620, acc-0.4918\n",
      "Iter-52830, train loss-2.0769, acc-0.3600, valid loss-1.9893, acc-0.4782, test loss-1.9619, acc-0.4917\n",
      "Iter-52840, train loss-2.0657, acc-0.3400, valid loss-1.9892, acc-0.4784, test loss-1.9619, acc-0.4919\n",
      "Iter-52850, train loss-1.9561, acc-0.3600, valid loss-1.9892, acc-0.4782, test loss-1.9619, acc-0.4919\n",
      "Iter-52860, train loss-1.9328, acc-0.5400, valid loss-1.9891, acc-0.4786, test loss-1.9618, acc-0.4922\n",
      "Iter-52870, train loss-2.0009, acc-0.3800, valid loss-1.9891, acc-0.4786, test loss-1.9618, acc-0.4922\n",
      "Iter-52880, train loss-1.9028, acc-0.6200, valid loss-1.9891, acc-0.4784, test loss-1.9617, acc-0.4922\n",
      "Iter-52890, train loss-1.9967, acc-0.4000, valid loss-1.9890, acc-0.4782, test loss-1.9617, acc-0.4924\n",
      "Iter-52900, train loss-1.9859, acc-0.4800, valid loss-1.9890, acc-0.4786, test loss-1.9616, acc-0.4920\n",
      "Iter-52910, train loss-2.0716, acc-0.3200, valid loss-1.9889, acc-0.4788, test loss-1.9616, acc-0.4924\n",
      "Iter-52920, train loss-2.0161, acc-0.5000, valid loss-1.9889, acc-0.4786, test loss-1.9616, acc-0.4926\n",
      "Iter-52930, train loss-1.9820, acc-0.5000, valid loss-1.9889, acc-0.4788, test loss-1.9615, acc-0.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52940, train loss-1.9756, acc-0.4600, valid loss-1.9888, acc-0.4786, test loss-1.9615, acc-0.4926\n",
      "Iter-52950, train loss-2.0252, acc-0.3800, valid loss-1.9888, acc-0.4786, test loss-1.9614, acc-0.4926\n",
      "Iter-52960, train loss-2.0192, acc-0.4000, valid loss-1.9887, acc-0.4790, test loss-1.9614, acc-0.4925\n",
      "Iter-52970, train loss-1.9683, acc-0.4600, valid loss-1.9887, acc-0.4788, test loss-1.9613, acc-0.4926\n",
      "Iter-52980, train loss-2.0561, acc-0.3400, valid loss-1.9887, acc-0.4788, test loss-1.9613, acc-0.4926\n",
      "Iter-52990, train loss-1.9313, acc-0.4600, valid loss-1.9886, acc-0.4786, test loss-1.9613, acc-0.4928\n",
      "Iter-53000, train loss-1.9692, acc-0.4400, valid loss-1.9886, acc-0.4788, test loss-1.9612, acc-0.4928\n",
      "Iter-53010, train loss-2.0494, acc-0.3600, valid loss-1.9886, acc-0.4788, test loss-1.9612, acc-0.4930\n",
      "Iter-53020, train loss-1.9154, acc-0.5000, valid loss-1.9885, acc-0.4788, test loss-1.9611, acc-0.4928\n",
      "Iter-53030, train loss-2.0213, acc-0.4600, valid loss-1.9885, acc-0.4788, test loss-1.9611, acc-0.4929\n",
      "Iter-53040, train loss-2.0415, acc-0.4400, valid loss-1.9884, acc-0.4788, test loss-1.9610, acc-0.4927\n",
      "Iter-53050, train loss-1.9360, acc-0.4600, valid loss-1.9884, acc-0.4786, test loss-1.9610, acc-0.4930\n",
      "Iter-53060, train loss-1.9330, acc-0.5400, valid loss-1.9884, acc-0.4786, test loss-1.9610, acc-0.4929\n",
      "Iter-53070, train loss-1.9434, acc-0.4400, valid loss-1.9883, acc-0.4788, test loss-1.9609, acc-0.4928\n",
      "Iter-53080, train loss-1.9391, acc-0.4000, valid loss-1.9883, acc-0.4788, test loss-1.9609, acc-0.4928\n",
      "Iter-53090, train loss-2.0078, acc-0.3600, valid loss-1.9882, acc-0.4790, test loss-1.9608, acc-0.4929\n",
      "Iter-53100, train loss-1.9758, acc-0.4000, valid loss-1.9882, acc-0.4790, test loss-1.9608, acc-0.4929\n",
      "Iter-53110, train loss-2.0092, acc-0.4600, valid loss-1.9882, acc-0.4792, test loss-1.9607, acc-0.4929\n",
      "Iter-53120, train loss-1.9668, acc-0.4800, valid loss-1.9881, acc-0.4790, test loss-1.9607, acc-0.4929\n",
      "Iter-53130, train loss-1.9676, acc-0.5400, valid loss-1.9881, acc-0.4792, test loss-1.9607, acc-0.4928\n",
      "Iter-53140, train loss-2.0004, acc-0.3800, valid loss-1.9880, acc-0.4790, test loss-1.9606, acc-0.4928\n",
      "Iter-53150, train loss-2.0103, acc-0.3600, valid loss-1.9880, acc-0.4788, test loss-1.9606, acc-0.4926\n",
      "Iter-53160, train loss-1.9874, acc-0.3800, valid loss-1.9880, acc-0.4790, test loss-1.9605, acc-0.4929\n",
      "Iter-53170, train loss-1.8788, acc-0.6200, valid loss-1.9879, acc-0.4790, test loss-1.9605, acc-0.4930\n",
      "Iter-53180, train loss-1.9811, acc-0.4800, valid loss-1.9879, acc-0.4790, test loss-1.9604, acc-0.4930\n",
      "Iter-53190, train loss-1.9326, acc-0.4800, valid loss-1.9878, acc-0.4790, test loss-1.9604, acc-0.4929\n",
      "Iter-53200, train loss-2.0022, acc-0.4000, valid loss-1.9878, acc-0.4790, test loss-1.9603, acc-0.4928\n",
      "Iter-53210, train loss-1.8842, acc-0.6600, valid loss-1.9878, acc-0.4790, test loss-1.9603, acc-0.4929\n",
      "Iter-53220, train loss-1.8957, acc-0.5600, valid loss-1.9877, acc-0.4790, test loss-1.9603, acc-0.4931\n",
      "Iter-53230, train loss-2.0093, acc-0.4600, valid loss-1.9877, acc-0.4792, test loss-1.9602, acc-0.4931\n",
      "Iter-53240, train loss-2.0016, acc-0.5400, valid loss-1.9877, acc-0.4790, test loss-1.9602, acc-0.4932\n",
      "Iter-53250, train loss-1.9436, acc-0.5200, valid loss-1.9876, acc-0.4792, test loss-1.9601, acc-0.4932\n",
      "Iter-53260, train loss-1.8985, acc-0.5800, valid loss-1.9876, acc-0.4790, test loss-1.9601, acc-0.4936\n",
      "Iter-53270, train loss-2.0486, acc-0.4600, valid loss-1.9875, acc-0.4794, test loss-1.9600, acc-0.4936\n",
      "Iter-53280, train loss-1.9697, acc-0.4400, valid loss-1.9875, acc-0.4792, test loss-1.9600, acc-0.4935\n",
      "Iter-53290, train loss-1.9746, acc-0.4800, valid loss-1.9874, acc-0.4792, test loss-1.9599, acc-0.4935\n",
      "Iter-53300, train loss-1.9991, acc-0.4400, valid loss-1.9874, acc-0.4792, test loss-1.9599, acc-0.4935\n",
      "Iter-53310, train loss-1.9861, acc-0.4400, valid loss-1.9874, acc-0.4792, test loss-1.9599, acc-0.4936\n",
      "Iter-53320, train loss-1.9533, acc-0.4000, valid loss-1.9873, acc-0.4790, test loss-1.9598, acc-0.4935\n",
      "Iter-53330, train loss-1.9976, acc-0.3800, valid loss-1.9873, acc-0.4792, test loss-1.9598, acc-0.4934\n",
      "Iter-53340, train loss-1.9288, acc-0.5200, valid loss-1.9872, acc-0.4790, test loss-1.9597, acc-0.4933\n",
      "Iter-53350, train loss-1.9567, acc-0.4600, valid loss-1.9872, acc-0.4790, test loss-1.9597, acc-0.4935\n",
      "Iter-53360, train loss-1.9989, acc-0.4400, valid loss-1.9872, acc-0.4790, test loss-1.9596, acc-0.4933\n",
      "Iter-53370, train loss-1.9409, acc-0.5400, valid loss-1.9871, acc-0.4792, test loss-1.9596, acc-0.4936\n",
      "Iter-53380, train loss-2.0213, acc-0.4400, valid loss-1.9871, acc-0.4790, test loss-1.9596, acc-0.4936\n",
      "Iter-53390, train loss-1.9049, acc-0.5800, valid loss-1.9871, acc-0.4792, test loss-1.9595, acc-0.4936\n",
      "Iter-53400, train loss-1.9967, acc-0.4200, valid loss-1.9870, acc-0.4794, test loss-1.9595, acc-0.4936\n",
      "Iter-53410, train loss-1.9315, acc-0.5200, valid loss-1.9870, acc-0.4792, test loss-1.9594, acc-0.4936\n",
      "Iter-53420, train loss-1.9428, acc-0.4800, valid loss-1.9869, acc-0.4800, test loss-1.9594, acc-0.4937\n",
      "Iter-53430, train loss-1.8839, acc-0.5400, valid loss-1.9869, acc-0.4796, test loss-1.9593, acc-0.4939\n",
      "Iter-53440, train loss-1.9871, acc-0.4000, valid loss-1.9869, acc-0.4798, test loss-1.9593, acc-0.4938\n",
      "Iter-53450, train loss-2.0143, acc-0.4200, valid loss-1.9868, acc-0.4798, test loss-1.9593, acc-0.4938\n",
      "Iter-53460, train loss-1.9146, acc-0.5600, valid loss-1.9868, acc-0.4796, test loss-1.9592, acc-0.4938\n",
      "Iter-53470, train loss-1.9208, acc-0.5800, valid loss-1.9867, acc-0.4798, test loss-1.9592, acc-0.4938\n",
      "Iter-53480, train loss-1.9854, acc-0.4400, valid loss-1.9867, acc-0.4798, test loss-1.9591, acc-0.4938\n",
      "Iter-53490, train loss-2.0266, acc-0.4600, valid loss-1.9867, acc-0.4798, test loss-1.9591, acc-0.4939\n",
      "Iter-53500, train loss-2.0291, acc-0.4800, valid loss-1.9866, acc-0.4796, test loss-1.9590, acc-0.4937\n",
      "Iter-53510, train loss-2.0127, acc-0.3600, valid loss-1.9866, acc-0.4796, test loss-1.9590, acc-0.4937\n",
      "Iter-53520, train loss-1.9617, acc-0.5600, valid loss-1.9865, acc-0.4794, test loss-1.9590, acc-0.4938\n",
      "Iter-53530, train loss-2.0646, acc-0.4400, valid loss-1.9865, acc-0.4796, test loss-1.9589, acc-0.4938\n",
      "Iter-53540, train loss-1.9450, acc-0.5400, valid loss-1.9865, acc-0.4798, test loss-1.9589, acc-0.4936\n",
      "Iter-53550, train loss-1.9459, acc-0.4600, valid loss-1.9864, acc-0.4798, test loss-1.9588, acc-0.4937\n",
      "Iter-53560, train loss-2.0130, acc-0.4200, valid loss-1.9864, acc-0.4798, test loss-1.9588, acc-0.4938\n",
      "Iter-53570, train loss-1.9841, acc-0.4800, valid loss-1.9864, acc-0.4798, test loss-1.9587, acc-0.4938\n",
      "Iter-53580, train loss-1.9675, acc-0.5200, valid loss-1.9863, acc-0.4796, test loss-1.9587, acc-0.4936\n",
      "Iter-53590, train loss-1.9613, acc-0.5600, valid loss-1.9863, acc-0.4796, test loss-1.9587, acc-0.4938\n",
      "Iter-53600, train loss-1.9794, acc-0.4000, valid loss-1.9862, acc-0.4798, test loss-1.9586, acc-0.4938\n",
      "Iter-53610, train loss-1.9199, acc-0.4800, valid loss-1.9862, acc-0.4796, test loss-1.9586, acc-0.4939\n",
      "Iter-53620, train loss-2.0134, acc-0.4200, valid loss-1.9861, acc-0.4796, test loss-1.9585, acc-0.4939\n",
      "Iter-53630, train loss-1.9798, acc-0.4400, valid loss-1.9861, acc-0.4798, test loss-1.9585, acc-0.4938\n",
      "Iter-53640, train loss-1.9603, acc-0.6000, valid loss-1.9861, acc-0.4798, test loss-1.9584, acc-0.4941\n",
      "Iter-53650, train loss-2.0298, acc-0.4600, valid loss-1.9860, acc-0.4796, test loss-1.9584, acc-0.4940\n",
      "Iter-53660, train loss-1.9850, acc-0.4400, valid loss-1.9860, acc-0.4798, test loss-1.9583, acc-0.4937\n",
      "Iter-53670, train loss-2.0097, acc-0.4400, valid loss-1.9860, acc-0.4798, test loss-1.9583, acc-0.4938\n",
      "Iter-53680, train loss-1.9633, acc-0.4600, valid loss-1.9859, acc-0.4798, test loss-1.9583, acc-0.4939\n",
      "Iter-53690, train loss-2.0086, acc-0.4200, valid loss-1.9859, acc-0.4798, test loss-1.9582, acc-0.4938\n",
      "Iter-53700, train loss-1.9592, acc-0.5400, valid loss-1.9858, acc-0.4796, test loss-1.9582, acc-0.4938\n",
      "Iter-53710, train loss-1.9703, acc-0.4800, valid loss-1.9858, acc-0.4794, test loss-1.9581, acc-0.4938\n",
      "Iter-53720, train loss-2.0188, acc-0.3800, valid loss-1.9858, acc-0.4794, test loss-1.9581, acc-0.4939\n",
      "Iter-53730, train loss-1.9696, acc-0.4000, valid loss-1.9857, acc-0.4796, test loss-1.9580, acc-0.4938\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-53740, train loss-1.8559, acc-0.6400, valid loss-1.9857, acc-0.4796, test loss-1.9580, acc-0.4938\n",
      "Iter-53750, train loss-1.9838, acc-0.4200, valid loss-1.9856, acc-0.4798, test loss-1.9580, acc-0.4939\n",
      "Iter-53760, train loss-1.9134, acc-0.4800, valid loss-1.9856, acc-0.4798, test loss-1.9579, acc-0.4941\n",
      "Iter-53770, train loss-2.0335, acc-0.4000, valid loss-1.9856, acc-0.4800, test loss-1.9579, acc-0.4940\n",
      "Iter-53780, train loss-1.9207, acc-0.4600, valid loss-1.9855, acc-0.4804, test loss-1.9578, acc-0.4941\n",
      "Iter-53790, train loss-2.0024, acc-0.5400, valid loss-1.9855, acc-0.4802, test loss-1.9578, acc-0.4941\n",
      "Iter-53800, train loss-1.9952, acc-0.4400, valid loss-1.9854, acc-0.4804, test loss-1.9577, acc-0.4943\n",
      "Iter-53810, train loss-2.0028, acc-0.4600, valid loss-1.9854, acc-0.4806, test loss-1.9577, acc-0.4942\n",
      "Iter-53820, train loss-2.0038, acc-0.4800, valid loss-1.9854, acc-0.4806, test loss-1.9577, acc-0.4942\n",
      "Iter-53830, train loss-2.0342, acc-0.4000, valid loss-1.9853, acc-0.4806, test loss-1.9576, acc-0.4941\n",
      "Iter-53840, train loss-1.9837, acc-0.4600, valid loss-1.9853, acc-0.4804, test loss-1.9576, acc-0.4941\n",
      "Iter-53850, train loss-1.9639, acc-0.4000, valid loss-1.9853, acc-0.4804, test loss-1.9575, acc-0.4941\n",
      "Iter-53860, train loss-2.0618, acc-0.4000, valid loss-1.9852, acc-0.4804, test loss-1.9575, acc-0.4939\n",
      "Iter-53870, train loss-1.9367, acc-0.5600, valid loss-1.9852, acc-0.4806, test loss-1.9574, acc-0.4941\n",
      "Iter-53880, train loss-2.0502, acc-0.4400, valid loss-1.9851, acc-0.4810, test loss-1.9574, acc-0.4941\n",
      "Iter-53890, train loss-1.9475, acc-0.4600, valid loss-1.9851, acc-0.4806, test loss-1.9574, acc-0.4942\n",
      "Iter-53900, train loss-1.9879, acc-0.5200, valid loss-1.9851, acc-0.4806, test loss-1.9573, acc-0.4943\n",
      "Iter-53910, train loss-1.9659, acc-0.5800, valid loss-1.9850, acc-0.4808, test loss-1.9573, acc-0.4942\n",
      "Iter-53920, train loss-1.9603, acc-0.4800, valid loss-1.9850, acc-0.4806, test loss-1.9572, acc-0.4942\n",
      "Iter-53930, train loss-1.9280, acc-0.5800, valid loss-1.9850, acc-0.4804, test loss-1.9572, acc-0.4943\n",
      "Iter-53940, train loss-1.9654, acc-0.4600, valid loss-1.9849, acc-0.4808, test loss-1.9571, acc-0.4942\n",
      "Iter-53950, train loss-1.9953, acc-0.5600, valid loss-1.9849, acc-0.4808, test loss-1.9571, acc-0.4942\n",
      "Iter-53960, train loss-2.0086, acc-0.4000, valid loss-1.9848, acc-0.4806, test loss-1.9571, acc-0.4944\n",
      "Iter-53970, train loss-1.8810, acc-0.5600, valid loss-1.9848, acc-0.4806, test loss-1.9570, acc-0.4943\n",
      "Iter-53980, train loss-1.9459, acc-0.5600, valid loss-1.9848, acc-0.4808, test loss-1.9570, acc-0.4944\n",
      "Iter-53990, train loss-2.0017, acc-0.5400, valid loss-1.9847, acc-0.4810, test loss-1.9569, acc-0.4944\n",
      "Iter-54000, train loss-2.0003, acc-0.4400, valid loss-1.9847, acc-0.4808, test loss-1.9569, acc-0.4945\n",
      "Iter-54010, train loss-1.9528, acc-0.4800, valid loss-1.9846, acc-0.4808, test loss-1.9568, acc-0.4947\n",
      "Iter-54020, train loss-1.9968, acc-0.5000, valid loss-1.9846, acc-0.4806, test loss-1.9568, acc-0.4943\n",
      "Iter-54030, train loss-1.9779, acc-0.4800, valid loss-1.9846, acc-0.4806, test loss-1.9568, acc-0.4945\n",
      "Iter-54040, train loss-1.8764, acc-0.6200, valid loss-1.9845, acc-0.4806, test loss-1.9567, acc-0.4943\n",
      "Iter-54050, train loss-1.9481, acc-0.5000, valid loss-1.9845, acc-0.4804, test loss-1.9567, acc-0.4941\n",
      "Iter-54060, train loss-1.9656, acc-0.5600, valid loss-1.9844, acc-0.4802, test loss-1.9566, acc-0.4941\n",
      "Iter-54070, train loss-1.9485, acc-0.5600, valid loss-1.9844, acc-0.4808, test loss-1.9566, acc-0.4940\n",
      "Iter-54080, train loss-1.8940, acc-0.6200, valid loss-1.9844, acc-0.4806, test loss-1.9565, acc-0.4943\n",
      "Iter-54090, train loss-1.9737, acc-0.5400, valid loss-1.9843, acc-0.4806, test loss-1.9565, acc-0.4944\n",
      "Iter-54100, train loss-1.9330, acc-0.5000, valid loss-1.9843, acc-0.4804, test loss-1.9565, acc-0.4944\n",
      "Iter-54110, train loss-2.0177, acc-0.4600, valid loss-1.9843, acc-0.4808, test loss-1.9564, acc-0.4944\n",
      "Iter-54120, train loss-1.9278, acc-0.5600, valid loss-1.9842, acc-0.4804, test loss-1.9564, acc-0.4944\n",
      "Iter-54130, train loss-2.0202, acc-0.4000, valid loss-1.9842, acc-0.4804, test loss-1.9563, acc-0.4943\n",
      "Iter-54140, train loss-1.9895, acc-0.4800, valid loss-1.9841, acc-0.4804, test loss-1.9563, acc-0.4946\n",
      "Iter-54150, train loss-1.9824, acc-0.5200, valid loss-1.9841, acc-0.4802, test loss-1.9562, acc-0.4946\n",
      "Iter-54160, train loss-1.9075, acc-0.6200, valid loss-1.9841, acc-0.4800, test loss-1.9562, acc-0.4947\n",
      "Iter-54170, train loss-1.9946, acc-0.4600, valid loss-1.9840, acc-0.4802, test loss-1.9561, acc-0.4945\n",
      "Iter-54180, train loss-1.9229, acc-0.5000, valid loss-1.9840, acc-0.4800, test loss-1.9561, acc-0.4947\n",
      "Iter-54190, train loss-1.9658, acc-0.5000, valid loss-1.9839, acc-0.4802, test loss-1.9561, acc-0.4945\n",
      "Iter-54200, train loss-1.9805, acc-0.5200, valid loss-1.9839, acc-0.4806, test loss-1.9560, acc-0.4948\n",
      "Iter-54210, train loss-1.9897, acc-0.5000, valid loss-1.9839, acc-0.4804, test loss-1.9560, acc-0.4950\n",
      "Iter-54220, train loss-1.9611, acc-0.5200, valid loss-1.9838, acc-0.4802, test loss-1.9559, acc-0.4949\n",
      "Iter-54230, train loss-2.0466, acc-0.4400, valid loss-1.9838, acc-0.4802, test loss-1.9559, acc-0.4949\n",
      "Iter-54240, train loss-2.0178, acc-0.4200, valid loss-1.9837, acc-0.4802, test loss-1.9558, acc-0.4949\n",
      "Iter-54250, train loss-1.9569, acc-0.4600, valid loss-1.9837, acc-0.4802, test loss-1.9558, acc-0.4949\n",
      "Iter-54260, train loss-2.0574, acc-0.4400, valid loss-1.9837, acc-0.4802, test loss-1.9558, acc-0.4949\n",
      "Iter-54270, train loss-1.8775, acc-0.5600, valid loss-1.9836, acc-0.4800, test loss-1.9557, acc-0.4951\n",
      "Iter-54280, train loss-2.0038, acc-0.4800, valid loss-1.9836, acc-0.4800, test loss-1.9557, acc-0.4950\n",
      "Iter-54290, train loss-1.9338, acc-0.5000, valid loss-1.9835, acc-0.4798, test loss-1.9556, acc-0.4950\n",
      "Iter-54300, train loss-1.9055, acc-0.5600, valid loss-1.9835, acc-0.4800, test loss-1.9556, acc-0.4950\n",
      "Iter-54310, train loss-2.0810, acc-0.3200, valid loss-1.9835, acc-0.4798, test loss-1.9555, acc-0.4951\n",
      "Iter-54320, train loss-1.9769, acc-0.5000, valid loss-1.9834, acc-0.4802, test loss-1.9555, acc-0.4949\n",
      "Iter-54330, train loss-1.9562, acc-0.4800, valid loss-1.9834, acc-0.4802, test loss-1.9555, acc-0.4949\n",
      "Iter-54340, train loss-1.9667, acc-0.5800, valid loss-1.9833, acc-0.4802, test loss-1.9554, acc-0.4948\n",
      "Iter-54350, train loss-1.9558, acc-0.5000, valid loss-1.9833, acc-0.4800, test loss-1.9554, acc-0.4947\n",
      "Iter-54360, train loss-1.9495, acc-0.5600, valid loss-1.9833, acc-0.4800, test loss-1.9553, acc-0.4948\n",
      "Iter-54370, train loss-1.9768, acc-0.4600, valid loss-1.9832, acc-0.4800, test loss-1.9553, acc-0.4947\n",
      "Iter-54380, train loss-1.9483, acc-0.5000, valid loss-1.9832, acc-0.4798, test loss-1.9552, acc-0.4949\n",
      "Iter-54390, train loss-1.9037, acc-0.4600, valid loss-1.9831, acc-0.4796, test loss-1.9552, acc-0.4948\n",
      "Iter-54400, train loss-1.9652, acc-0.4400, valid loss-1.9831, acc-0.4802, test loss-1.9551, acc-0.4949\n",
      "Iter-54410, train loss-1.9123, acc-0.4800, valid loss-1.9831, acc-0.4806, test loss-1.9551, acc-0.4946\n",
      "Iter-54420, train loss-1.8914, acc-0.5600, valid loss-1.9830, acc-0.4804, test loss-1.9551, acc-0.4948\n",
      "Iter-54430, train loss-1.9090, acc-0.5000, valid loss-1.9830, acc-0.4800, test loss-1.9550, acc-0.4949\n",
      "Iter-54440, train loss-2.0018, acc-0.4600, valid loss-1.9829, acc-0.4800, test loss-1.9550, acc-0.4949\n",
      "Iter-54450, train loss-1.9809, acc-0.5200, valid loss-1.9829, acc-0.4798, test loss-1.9549, acc-0.4946\n",
      "Iter-54460, train loss-1.9513, acc-0.5200, valid loss-1.9829, acc-0.4798, test loss-1.9549, acc-0.4945\n",
      "Iter-54470, train loss-1.9876, acc-0.4200, valid loss-1.9828, acc-0.4798, test loss-1.9548, acc-0.4945\n",
      "Iter-54480, train loss-1.9582, acc-0.5000, valid loss-1.9828, acc-0.4800, test loss-1.9548, acc-0.4947\n",
      "Iter-54490, train loss-1.9083, acc-0.5400, valid loss-1.9827, acc-0.4804, test loss-1.9547, acc-0.4948\n",
      "Iter-54500, train loss-1.9415, acc-0.4800, valid loss-1.9827, acc-0.4804, test loss-1.9547, acc-0.4948\n",
      "Iter-54510, train loss-1.9516, acc-0.4800, valid loss-1.9827, acc-0.4802, test loss-1.9547, acc-0.4949\n",
      "Iter-54520, train loss-1.9483, acc-0.5200, valid loss-1.9826, acc-0.4804, test loss-1.9546, acc-0.4949\n",
      "Iter-54530, train loss-1.9688, acc-0.5000, valid loss-1.9826, acc-0.4804, test loss-1.9546, acc-0.4949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-54540, train loss-1.8300, acc-0.6400, valid loss-1.9825, acc-0.4804, test loss-1.9545, acc-0.4948\n",
      "Iter-54550, train loss-1.8572, acc-0.5800, valid loss-1.9825, acc-0.4804, test loss-1.9545, acc-0.4948\n",
      "Iter-54560, train loss-1.9078, acc-0.5200, valid loss-1.9825, acc-0.4804, test loss-1.9544, acc-0.4947\n",
      "Iter-54570, train loss-1.9733, acc-0.5000, valid loss-1.9824, acc-0.4804, test loss-1.9544, acc-0.4950\n",
      "Iter-54580, train loss-1.9352, acc-0.5600, valid loss-1.9824, acc-0.4804, test loss-1.9544, acc-0.4950\n",
      "Iter-54590, train loss-1.9749, acc-0.5200, valid loss-1.9824, acc-0.4802, test loss-1.9543, acc-0.4950\n",
      "Iter-54600, train loss-1.9484, acc-0.6000, valid loss-1.9823, acc-0.4802, test loss-1.9543, acc-0.4950\n",
      "Iter-54610, train loss-1.9639, acc-0.4400, valid loss-1.9823, acc-0.4800, test loss-1.9542, acc-0.4951\n",
      "Iter-54620, train loss-1.9539, acc-0.4400, valid loss-1.9822, acc-0.4802, test loss-1.9542, acc-0.4953\n",
      "Iter-54630, train loss-1.9861, acc-0.3600, valid loss-1.9822, acc-0.4800, test loss-1.9541, acc-0.4952\n",
      "Iter-54640, train loss-1.8464, acc-0.6800, valid loss-1.9822, acc-0.4798, test loss-1.9541, acc-0.4953\n",
      "Iter-54650, train loss-1.9562, acc-0.5600, valid loss-1.9821, acc-0.4798, test loss-1.9540, acc-0.4955\n",
      "Iter-54660, train loss-1.8869, acc-0.5400, valid loss-1.9821, acc-0.4798, test loss-1.9540, acc-0.4953\n",
      "Iter-54670, train loss-2.0077, acc-0.5400, valid loss-1.9820, acc-0.4800, test loss-1.9540, acc-0.4953\n",
      "Iter-54680, train loss-1.9457, acc-0.4400, valid loss-1.9820, acc-0.4800, test loss-1.9539, acc-0.4956\n",
      "Iter-54690, train loss-1.9204, acc-0.5600, valid loss-1.9820, acc-0.4800, test loss-1.9539, acc-0.4956\n",
      "Iter-54700, train loss-2.0510, acc-0.4600, valid loss-1.9819, acc-0.4802, test loss-1.9538, acc-0.4955\n",
      "Iter-54710, train loss-1.9992, acc-0.4800, valid loss-1.9819, acc-0.4804, test loss-1.9538, acc-0.4957\n",
      "Iter-54720, train loss-1.8699, acc-0.5000, valid loss-1.9818, acc-0.4802, test loss-1.9537, acc-0.4955\n",
      "Iter-54730, train loss-1.9807, acc-0.4400, valid loss-1.9818, acc-0.4802, test loss-1.9537, acc-0.4957\n",
      "Iter-54740, train loss-1.9587, acc-0.4600, valid loss-1.9817, acc-0.4804, test loss-1.9536, acc-0.4954\n",
      "Iter-54750, train loss-1.9499, acc-0.5600, valid loss-1.9817, acc-0.4804, test loss-1.9536, acc-0.4956\n",
      "Iter-54760, train loss-1.9228, acc-0.5200, valid loss-1.9817, acc-0.4808, test loss-1.9536, acc-0.4957\n",
      "Iter-54770, train loss-1.9863, acc-0.4400, valid loss-1.9816, acc-0.4808, test loss-1.9535, acc-0.4957\n",
      "Iter-54780, train loss-1.9548, acc-0.4800, valid loss-1.9816, acc-0.4806, test loss-1.9535, acc-0.4957\n",
      "Iter-54790, train loss-1.9447, acc-0.4600, valid loss-1.9816, acc-0.4804, test loss-1.9534, acc-0.4957\n",
      "Iter-54800, train loss-1.9993, acc-0.4200, valid loss-1.9815, acc-0.4804, test loss-1.9534, acc-0.4957\n",
      "Iter-54810, train loss-1.9143, acc-0.5400, valid loss-1.9815, acc-0.4806, test loss-1.9533, acc-0.4957\n",
      "Iter-54820, train loss-1.9581, acc-0.4800, valid loss-1.9814, acc-0.4806, test loss-1.9533, acc-0.4960\n",
      "Iter-54830, train loss-1.9331, acc-0.4800, valid loss-1.9814, acc-0.4806, test loss-1.9533, acc-0.4958\n",
      "Iter-54840, train loss-1.9396, acc-0.5200, valid loss-1.9814, acc-0.4808, test loss-1.9532, acc-0.4958\n",
      "Iter-54850, train loss-1.9217, acc-0.5000, valid loss-1.9813, acc-0.4806, test loss-1.9532, acc-0.4959\n",
      "Iter-54860, train loss-1.9441, acc-0.4600, valid loss-1.9813, acc-0.4806, test loss-1.9531, acc-0.4960\n",
      "Iter-54870, train loss-1.9693, acc-0.5400, valid loss-1.9812, acc-0.4812, test loss-1.9531, acc-0.4961\n",
      "Iter-54880, train loss-2.0193, acc-0.3600, valid loss-1.9812, acc-0.4812, test loss-1.9530, acc-0.4960\n",
      "Iter-54890, train loss-2.0155, acc-0.4600, valid loss-1.9812, acc-0.4812, test loss-1.9530, acc-0.4960\n",
      "Iter-54900, train loss-2.0629, acc-0.3200, valid loss-1.9811, acc-0.4812, test loss-1.9530, acc-0.4960\n",
      "Iter-54910, train loss-2.0064, acc-0.4400, valid loss-1.9811, acc-0.4810, test loss-1.9529, acc-0.4960\n",
      "Iter-54920, train loss-1.9368, acc-0.5200, valid loss-1.9810, acc-0.4816, test loss-1.9529, acc-0.4960\n",
      "Iter-54930, train loss-1.9418, acc-0.5400, valid loss-1.9810, acc-0.4810, test loss-1.9528, acc-0.4964\n",
      "Iter-54940, train loss-1.9039, acc-0.4800, valid loss-1.9810, acc-0.4812, test loss-1.9528, acc-0.4963\n",
      "Iter-54950, train loss-1.9443, acc-0.4000, valid loss-1.9809, acc-0.4810, test loss-1.9527, acc-0.4964\n",
      "Iter-54960, train loss-2.0067, acc-0.5400, valid loss-1.9809, acc-0.4810, test loss-1.9527, acc-0.4963\n",
      "Iter-54970, train loss-1.9827, acc-0.4400, valid loss-1.9809, acc-0.4806, test loss-1.9527, acc-0.4962\n",
      "Iter-54980, train loss-1.9852, acc-0.5000, valid loss-1.9808, acc-0.4808, test loss-1.9526, acc-0.4963\n",
      "Iter-54990, train loss-1.9430, acc-0.5000, valid loss-1.9808, acc-0.4812, test loss-1.9526, acc-0.4964\n",
      "Iter-55000, train loss-2.0340, acc-0.4400, valid loss-1.9807, acc-0.4808, test loss-1.9525, acc-0.4965\n",
      "Iter-55010, train loss-2.0013, acc-0.3400, valid loss-1.9807, acc-0.4808, test loss-1.9525, acc-0.4961\n",
      "Iter-55020, train loss-1.9852, acc-0.5000, valid loss-1.9807, acc-0.4812, test loss-1.9525, acc-0.4961\n",
      "Iter-55030, train loss-1.9415, acc-0.4800, valid loss-1.9806, acc-0.4812, test loss-1.9524, acc-0.4965\n",
      "Iter-55040, train loss-1.9261, acc-0.5000, valid loss-1.9806, acc-0.4812, test loss-1.9524, acc-0.4966\n",
      "Iter-55050, train loss-1.9864, acc-0.4200, valid loss-1.9805, acc-0.4812, test loss-1.9523, acc-0.4962\n",
      "Iter-55060, train loss-2.0064, acc-0.4400, valid loss-1.9805, acc-0.4812, test loss-1.9523, acc-0.4965\n",
      "Iter-55070, train loss-2.0141, acc-0.4800, valid loss-1.9805, acc-0.4814, test loss-1.9522, acc-0.4965\n",
      "Iter-55080, train loss-1.9435, acc-0.5400, valid loss-1.9804, acc-0.4812, test loss-1.9522, acc-0.4964\n",
      "Iter-55090, train loss-1.9425, acc-0.5200, valid loss-1.9804, acc-0.4812, test loss-1.9522, acc-0.4966\n",
      "Iter-55100, train loss-1.9168, acc-0.6200, valid loss-1.9804, acc-0.4812, test loss-1.9521, acc-0.4964\n",
      "Iter-55110, train loss-1.9234, acc-0.5800, valid loss-1.9803, acc-0.4812, test loss-1.9521, acc-0.4967\n",
      "Iter-55120, train loss-1.9807, acc-0.4800, valid loss-1.9803, acc-0.4810, test loss-1.9520, acc-0.4967\n",
      "Iter-55130, train loss-2.0997, acc-0.2800, valid loss-1.9802, acc-0.4810, test loss-1.9520, acc-0.4963\n",
      "Iter-55140, train loss-1.9835, acc-0.4400, valid loss-1.9802, acc-0.4808, test loss-1.9519, acc-0.4966\n",
      "Iter-55150, train loss-1.9402, acc-0.4600, valid loss-1.9802, acc-0.4810, test loss-1.9519, acc-0.4965\n",
      "Iter-55160, train loss-1.9422, acc-0.5800, valid loss-1.9801, acc-0.4810, test loss-1.9519, acc-0.4966\n",
      "Iter-55170, train loss-1.9493, acc-0.5200, valid loss-1.9801, acc-0.4808, test loss-1.9518, acc-0.4963\n",
      "Iter-55180, train loss-2.0247, acc-0.5200, valid loss-1.9801, acc-0.4814, test loss-1.9518, acc-0.4964\n",
      "Iter-55190, train loss-1.9334, acc-0.5400, valid loss-1.9800, acc-0.4814, test loss-1.9517, acc-0.4965\n",
      "Iter-55200, train loss-2.0030, acc-0.4200, valid loss-1.9800, acc-0.4816, test loss-1.9517, acc-0.4966\n",
      "Iter-55210, train loss-1.8893, acc-0.6800, valid loss-1.9799, acc-0.4812, test loss-1.9516, acc-0.4967\n",
      "Iter-55220, train loss-1.9647, acc-0.4400, valid loss-1.9799, acc-0.4810, test loss-1.9516, acc-0.4965\n",
      "Iter-55230, train loss-1.9741, acc-0.5200, valid loss-1.9799, acc-0.4810, test loss-1.9516, acc-0.4964\n",
      "Iter-55240, train loss-1.9977, acc-0.4400, valid loss-1.9798, acc-0.4810, test loss-1.9515, acc-0.4965\n",
      "Iter-55250, train loss-1.9201, acc-0.5200, valid loss-1.9798, acc-0.4810, test loss-1.9515, acc-0.4964\n",
      "Iter-55260, train loss-2.0642, acc-0.4600, valid loss-1.9798, acc-0.4810, test loss-1.9514, acc-0.4962\n",
      "Iter-55270, train loss-2.0106, acc-0.4600, valid loss-1.9797, acc-0.4810, test loss-1.9514, acc-0.4963\n",
      "Iter-55280, train loss-1.9708, acc-0.5200, valid loss-1.9797, acc-0.4810, test loss-1.9514, acc-0.4963\n",
      "Iter-55290, train loss-1.9601, acc-0.5600, valid loss-1.9796, acc-0.4810, test loss-1.9513, acc-0.4961\n",
      "Iter-55300, train loss-1.9783, acc-0.4200, valid loss-1.9796, acc-0.4812, test loss-1.9513, acc-0.4961\n",
      "Iter-55310, train loss-1.9287, acc-0.5600, valid loss-1.9796, acc-0.4810, test loss-1.9512, acc-0.4960\n",
      "Iter-55320, train loss-2.0083, acc-0.4800, valid loss-1.9795, acc-0.4810, test loss-1.9512, acc-0.4962\n",
      "Iter-55330, train loss-1.9549, acc-0.5400, valid loss-1.9795, acc-0.4810, test loss-1.9511, acc-0.4963\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-55340, train loss-1.9427, acc-0.5200, valid loss-1.9794, acc-0.4808, test loss-1.9511, acc-0.4962\n",
      "Iter-55350, train loss-1.9603, acc-0.3200, valid loss-1.9794, acc-0.4806, test loss-1.9511, acc-0.4963\n",
      "Iter-55360, train loss-1.9898, acc-0.4400, valid loss-1.9794, acc-0.4806, test loss-1.9510, acc-0.4964\n",
      "Iter-55370, train loss-1.9793, acc-0.5400, valid loss-1.9793, acc-0.4806, test loss-1.9510, acc-0.4964\n",
      "Iter-55380, train loss-1.9655, acc-0.5200, valid loss-1.9793, acc-0.4808, test loss-1.9509, acc-0.4961\n",
      "Iter-55390, train loss-2.0105, acc-0.4400, valid loss-1.9793, acc-0.4808, test loss-1.9509, acc-0.4962\n",
      "Iter-55400, train loss-1.9553, acc-0.5000, valid loss-1.9792, acc-0.4804, test loss-1.9508, acc-0.4962\n",
      "Iter-55410, train loss-1.8998, acc-0.5200, valid loss-1.9792, acc-0.4808, test loss-1.9508, acc-0.4961\n",
      "Iter-55420, train loss-2.0194, acc-0.4800, valid loss-1.9791, acc-0.4806, test loss-1.9508, acc-0.4960\n",
      "Iter-55430, train loss-1.8969, acc-0.5800, valid loss-1.9791, acc-0.4804, test loss-1.9507, acc-0.4960\n",
      "Iter-55440, train loss-1.9515, acc-0.5000, valid loss-1.9791, acc-0.4804, test loss-1.9507, acc-0.4960\n",
      "Iter-55450, train loss-1.8954, acc-0.5600, valid loss-1.9790, acc-0.4806, test loss-1.9506, acc-0.4960\n",
      "Iter-55460, train loss-1.8433, acc-0.5800, valid loss-1.9790, acc-0.4806, test loss-1.9506, acc-0.4962\n",
      "Iter-55470, train loss-1.9769, acc-0.5400, valid loss-1.9790, acc-0.4806, test loss-1.9505, acc-0.4963\n",
      "Iter-55480, train loss-1.9920, acc-0.4200, valid loss-1.9789, acc-0.4806, test loss-1.9505, acc-0.4960\n",
      "Iter-55490, train loss-2.0077, acc-0.4600, valid loss-1.9789, acc-0.4806, test loss-1.9505, acc-0.4964\n",
      "Iter-55500, train loss-2.0490, acc-0.4000, valid loss-1.9788, acc-0.4808, test loss-1.9504, acc-0.4963\n",
      "Iter-55510, train loss-1.9397, acc-0.5200, valid loss-1.9788, acc-0.4808, test loss-1.9504, acc-0.4962\n",
      "Iter-55520, train loss-1.8867, acc-0.6200, valid loss-1.9788, acc-0.4812, test loss-1.9503, acc-0.4963\n",
      "Iter-55530, train loss-2.0010, acc-0.4600, valid loss-1.9787, acc-0.4810, test loss-1.9503, acc-0.4963\n",
      "Iter-55540, train loss-2.0114, acc-0.3800, valid loss-1.9787, acc-0.4812, test loss-1.9503, acc-0.4964\n",
      "Iter-55550, train loss-1.9786, acc-0.3600, valid loss-1.9786, acc-0.4810, test loss-1.9502, acc-0.4963\n",
      "Iter-55560, train loss-1.9410, acc-0.5000, valid loss-1.9786, acc-0.4808, test loss-1.9502, acc-0.4967\n",
      "Iter-55570, train loss-1.9016, acc-0.5600, valid loss-1.9786, acc-0.4808, test loss-1.9501, acc-0.4966\n",
      "Iter-55580, train loss-1.8727, acc-0.6000, valid loss-1.9785, acc-0.4810, test loss-1.9501, acc-0.4964\n",
      "Iter-55590, train loss-1.9409, acc-0.5000, valid loss-1.9785, acc-0.4810, test loss-1.9500, acc-0.4966\n",
      "Iter-55600, train loss-1.9610, acc-0.3800, valid loss-1.9784, acc-0.4810, test loss-1.9500, acc-0.4966\n",
      "Iter-55610, train loss-1.9321, acc-0.5400, valid loss-1.9784, acc-0.4812, test loss-1.9500, acc-0.4965\n",
      "Iter-55620, train loss-1.9397, acc-0.4800, valid loss-1.9783, acc-0.4814, test loss-1.9499, acc-0.4968\n",
      "Iter-55630, train loss-1.9726, acc-0.5000, valid loss-1.9783, acc-0.4812, test loss-1.9499, acc-0.4967\n",
      "Iter-55640, train loss-1.9730, acc-0.5000, valid loss-1.9783, acc-0.4812, test loss-1.9498, acc-0.4965\n",
      "Iter-55650, train loss-1.9323, acc-0.5200, valid loss-1.9782, acc-0.4812, test loss-1.9498, acc-0.4964\n",
      "Iter-55660, train loss-1.9332, acc-0.5600, valid loss-1.9782, acc-0.4814, test loss-1.9497, acc-0.4963\n",
      "Iter-55670, train loss-2.0383, acc-0.3600, valid loss-1.9782, acc-0.4812, test loss-1.9497, acc-0.4965\n",
      "Iter-55680, train loss-2.0312, acc-0.4200, valid loss-1.9781, acc-0.4812, test loss-1.9496, acc-0.4964\n",
      "Iter-55690, train loss-1.9768, acc-0.5200, valid loss-1.9781, acc-0.4814, test loss-1.9496, acc-0.4965\n",
      "Iter-55700, train loss-1.8870, acc-0.6000, valid loss-1.9780, acc-0.4814, test loss-1.9496, acc-0.4966\n",
      "Iter-55710, train loss-1.9575, acc-0.5200, valid loss-1.9780, acc-0.4816, test loss-1.9495, acc-0.4966\n",
      "Iter-55720, train loss-1.9323, acc-0.5000, valid loss-1.9780, acc-0.4814, test loss-1.9495, acc-0.4966\n",
      "Iter-55730, train loss-1.9556, acc-0.5000, valid loss-1.9779, acc-0.4816, test loss-1.9494, acc-0.4968\n",
      "Iter-55740, train loss-1.9580, acc-0.4600, valid loss-1.9779, acc-0.4814, test loss-1.9494, acc-0.4968\n",
      "Iter-55750, train loss-1.8940, acc-0.5600, valid loss-1.9778, acc-0.4812, test loss-1.9494, acc-0.4966\n",
      "Iter-55760, train loss-1.9971, acc-0.4800, valid loss-1.9778, acc-0.4812, test loss-1.9493, acc-0.4968\n",
      "Iter-55770, train loss-1.9784, acc-0.4200, valid loss-1.9778, acc-0.4812, test loss-1.9493, acc-0.4969\n",
      "Iter-55780, train loss-1.8914, acc-0.5600, valid loss-1.9777, acc-0.4814, test loss-1.9492, acc-0.4966\n",
      "Iter-55790, train loss-1.9240, acc-0.5200, valid loss-1.9777, acc-0.4816, test loss-1.9492, acc-0.4969\n",
      "Iter-55800, train loss-1.9155, acc-0.5800, valid loss-1.9777, acc-0.4814, test loss-1.9491, acc-0.4968\n",
      "Iter-55810, train loss-1.9458, acc-0.5800, valid loss-1.9776, acc-0.4818, test loss-1.9491, acc-0.4969\n",
      "Iter-55820, train loss-2.0188, acc-0.4200, valid loss-1.9776, acc-0.4820, test loss-1.9491, acc-0.4969\n",
      "Iter-55830, train loss-1.9202, acc-0.5000, valid loss-1.9775, acc-0.4820, test loss-1.9490, acc-0.4970\n",
      "Iter-55840, train loss-1.9469, acc-0.6200, valid loss-1.9775, acc-0.4820, test loss-1.9490, acc-0.4969\n",
      "Iter-55850, train loss-1.9488, acc-0.5000, valid loss-1.9775, acc-0.4824, test loss-1.9489, acc-0.4969\n",
      "Iter-55860, train loss-2.0565, acc-0.3600, valid loss-1.9774, acc-0.4822, test loss-1.9489, acc-0.4969\n",
      "Iter-55870, train loss-1.8874, acc-0.5800, valid loss-1.9774, acc-0.4822, test loss-1.9489, acc-0.4970\n",
      "Iter-55880, train loss-1.9622, acc-0.4200, valid loss-1.9774, acc-0.4824, test loss-1.9488, acc-0.4970\n",
      "Iter-55890, train loss-2.0194, acc-0.3600, valid loss-1.9773, acc-0.4826, test loss-1.9488, acc-0.4972\n",
      "Iter-55900, train loss-1.8813, acc-0.5400, valid loss-1.9773, acc-0.4826, test loss-1.9487, acc-0.4971\n",
      "Iter-55910, train loss-1.9960, acc-0.3600, valid loss-1.9772, acc-0.4824, test loss-1.9487, acc-0.4971\n",
      "Iter-55920, train loss-1.9073, acc-0.4600, valid loss-1.9772, acc-0.4824, test loss-1.9486, acc-0.4973\n",
      "Iter-55930, train loss-1.9615, acc-0.4600, valid loss-1.9772, acc-0.4828, test loss-1.9486, acc-0.4972\n",
      "Iter-55940, train loss-1.9624, acc-0.5600, valid loss-1.9771, acc-0.4826, test loss-1.9486, acc-0.4972\n",
      "Iter-55950, train loss-1.9153, acc-0.5200, valid loss-1.9771, acc-0.4826, test loss-1.9485, acc-0.4970\n",
      "Iter-55960, train loss-1.9640, acc-0.4200, valid loss-1.9771, acc-0.4822, test loss-1.9485, acc-0.4975\n",
      "Iter-55970, train loss-1.9950, acc-0.5200, valid loss-1.9770, acc-0.4826, test loss-1.9484, acc-0.4971\n",
      "Iter-55980, train loss-1.9525, acc-0.4400, valid loss-1.9770, acc-0.4828, test loss-1.9484, acc-0.4972\n",
      "Iter-55990, train loss-1.9818, acc-0.4600, valid loss-1.9769, acc-0.4830, test loss-1.9483, acc-0.4973\n",
      "Iter-56000, train loss-2.0118, acc-0.4600, valid loss-1.9769, acc-0.4834, test loss-1.9483, acc-0.4974\n",
      "Iter-56010, train loss-1.9928, acc-0.4000, valid loss-1.9769, acc-0.4834, test loss-1.9483, acc-0.4974\n",
      "Iter-56020, train loss-2.0467, acc-0.4000, valid loss-1.9768, acc-0.4834, test loss-1.9482, acc-0.4973\n",
      "Iter-56030, train loss-1.9274, acc-0.6000, valid loss-1.9768, acc-0.4834, test loss-1.9482, acc-0.4976\n",
      "Iter-56040, train loss-1.9536, acc-0.4600, valid loss-1.9767, acc-0.4834, test loss-1.9481, acc-0.4973\n",
      "Iter-56050, train loss-1.9747, acc-0.4400, valid loss-1.9767, acc-0.4830, test loss-1.9481, acc-0.4975\n",
      "Iter-56060, train loss-1.9129, acc-0.6000, valid loss-1.9767, acc-0.4830, test loss-1.9480, acc-0.4974\n",
      "Iter-56070, train loss-1.9369, acc-0.5600, valid loss-1.9766, acc-0.4828, test loss-1.9480, acc-0.4974\n",
      "Iter-56080, train loss-1.9035, acc-0.5800, valid loss-1.9766, acc-0.4828, test loss-1.9480, acc-0.4976\n",
      "Iter-56090, train loss-1.9514, acc-0.5200, valid loss-1.9766, acc-0.4828, test loss-1.9479, acc-0.4975\n",
      "Iter-56100, train loss-2.0001, acc-0.4400, valid loss-1.9765, acc-0.4828, test loss-1.9479, acc-0.4977\n",
      "Iter-56110, train loss-1.9273, acc-0.4400, valid loss-1.9765, acc-0.4828, test loss-1.9478, acc-0.4976\n",
      "Iter-56120, train loss-1.8913, acc-0.5800, valid loss-1.9764, acc-0.4828, test loss-1.9478, acc-0.4977\n",
      "Iter-56130, train loss-1.9596, acc-0.3800, valid loss-1.9764, acc-0.4826, test loss-1.9477, acc-0.4974\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56140, train loss-1.9790, acc-0.3800, valid loss-1.9764, acc-0.4826, test loss-1.9477, acc-0.4975\n",
      "Iter-56150, train loss-1.8737, acc-0.5200, valid loss-1.9763, acc-0.4826, test loss-1.9477, acc-0.4977\n",
      "Iter-56160, train loss-1.8664, acc-0.5800, valid loss-1.9763, acc-0.4824, test loss-1.9476, acc-0.4978\n",
      "Iter-56170, train loss-1.9186, acc-0.5600, valid loss-1.9762, acc-0.4826, test loss-1.9476, acc-0.4977\n",
      "Iter-56180, train loss-1.9334, acc-0.5400, valid loss-1.9762, acc-0.4834, test loss-1.9475, acc-0.4977\n",
      "Iter-56190, train loss-1.9040, acc-0.6000, valid loss-1.9762, acc-0.4834, test loss-1.9475, acc-0.4978\n",
      "Iter-56200, train loss-2.0054, acc-0.4000, valid loss-1.9761, acc-0.4832, test loss-1.9475, acc-0.4978\n",
      "Iter-56210, train loss-1.9441, acc-0.4600, valid loss-1.9761, acc-0.4832, test loss-1.9474, acc-0.4977\n",
      "Iter-56220, train loss-2.0059, acc-0.4600, valid loss-1.9761, acc-0.4832, test loss-1.9474, acc-0.4976\n",
      "Iter-56230, train loss-1.9670, acc-0.5200, valid loss-1.9760, acc-0.4832, test loss-1.9473, acc-0.4977\n",
      "Iter-56240, train loss-1.9234, acc-0.6000, valid loss-1.9760, acc-0.4834, test loss-1.9473, acc-0.4975\n",
      "Iter-56250, train loss-1.8809, acc-0.5800, valid loss-1.9759, acc-0.4834, test loss-1.9473, acc-0.4980\n",
      "Iter-56260, train loss-1.9316, acc-0.5600, valid loss-1.9759, acc-0.4834, test loss-1.9472, acc-0.4980\n",
      "Iter-56270, train loss-1.8876, acc-0.5200, valid loss-1.9759, acc-0.4834, test loss-1.9472, acc-0.4979\n",
      "Iter-56280, train loss-1.9216, acc-0.5800, valid loss-1.9758, acc-0.4834, test loss-1.9471, acc-0.4979\n",
      "Iter-56290, train loss-1.9259, acc-0.6000, valid loss-1.9758, acc-0.4836, test loss-1.9471, acc-0.4980\n",
      "Iter-56300, train loss-2.0129, acc-0.4400, valid loss-1.9757, acc-0.4834, test loss-1.9470, acc-0.4981\n",
      "Iter-56310, train loss-1.9481, acc-0.4400, valid loss-1.9757, acc-0.4834, test loss-1.9470, acc-0.4981\n",
      "Iter-56320, train loss-1.9149, acc-0.5200, valid loss-1.9757, acc-0.4834, test loss-1.9470, acc-0.4980\n",
      "Iter-56330, train loss-1.9971, acc-0.5000, valid loss-1.9756, acc-0.4834, test loss-1.9469, acc-0.4980\n",
      "Iter-56340, train loss-1.8565, acc-0.6000, valid loss-1.9756, acc-0.4838, test loss-1.9469, acc-0.4982\n",
      "Iter-56350, train loss-1.9258, acc-0.4400, valid loss-1.9756, acc-0.4834, test loss-1.9468, acc-0.4984\n",
      "Iter-56360, train loss-1.9984, acc-0.3600, valid loss-1.9755, acc-0.4836, test loss-1.9468, acc-0.4983\n",
      "Iter-56370, train loss-1.9940, acc-0.4800, valid loss-1.9755, acc-0.4836, test loss-1.9468, acc-0.4986\n",
      "Iter-56380, train loss-1.8992, acc-0.5600, valid loss-1.9754, acc-0.4834, test loss-1.9467, acc-0.4987\n",
      "Iter-56390, train loss-1.9231, acc-0.5000, valid loss-1.9754, acc-0.4836, test loss-1.9467, acc-0.4985\n",
      "Iter-56400, train loss-1.9799, acc-0.3800, valid loss-1.9754, acc-0.4832, test loss-1.9466, acc-0.4986\n",
      "Iter-56410, train loss-1.9493, acc-0.4800, valid loss-1.9753, acc-0.4832, test loss-1.9466, acc-0.4987\n",
      "Iter-56420, train loss-1.9567, acc-0.5000, valid loss-1.9753, acc-0.4836, test loss-1.9465, acc-0.4986\n",
      "Iter-56430, train loss-1.9088, acc-0.4800, valid loss-1.9753, acc-0.4834, test loss-1.9465, acc-0.4986\n",
      "Iter-56440, train loss-1.9194, acc-0.6000, valid loss-1.9752, acc-0.4834, test loss-1.9465, acc-0.4985\n",
      "Iter-56450, train loss-1.9260, acc-0.5000, valid loss-1.9752, acc-0.4834, test loss-1.9464, acc-0.4985\n",
      "Iter-56460, train loss-1.9180, acc-0.5800, valid loss-1.9751, acc-0.4834, test loss-1.9464, acc-0.4984\n",
      "Iter-56470, train loss-1.9438, acc-0.4400, valid loss-1.9751, acc-0.4834, test loss-1.9463, acc-0.4987\n",
      "Iter-56480, train loss-1.9309, acc-0.5600, valid loss-1.9751, acc-0.4834, test loss-1.9463, acc-0.4987\n",
      "Iter-56490, train loss-1.9225, acc-0.4400, valid loss-1.9750, acc-0.4834, test loss-1.9462, acc-0.4988\n",
      "Iter-56500, train loss-1.9911, acc-0.4600, valid loss-1.9750, acc-0.4834, test loss-1.9462, acc-0.4988\n",
      "Iter-56510, train loss-1.9771, acc-0.4600, valid loss-1.9749, acc-0.4834, test loss-1.9462, acc-0.4987\n",
      "Iter-56520, train loss-1.9257, acc-0.5000, valid loss-1.9749, acc-0.4832, test loss-1.9461, acc-0.4988\n",
      "Iter-56530, train loss-1.9738, acc-0.3800, valid loss-1.9749, acc-0.4832, test loss-1.9461, acc-0.4986\n",
      "Iter-56540, train loss-1.9982, acc-0.4800, valid loss-1.9748, acc-0.4832, test loss-1.9460, acc-0.4988\n",
      "Iter-56550, train loss-2.0533, acc-0.3200, valid loss-1.9748, acc-0.4832, test loss-1.9460, acc-0.4988\n",
      "Iter-56560, train loss-2.0133, acc-0.3800, valid loss-1.9748, acc-0.4834, test loss-1.9459, acc-0.4988\n",
      "Iter-56570, train loss-1.9153, acc-0.4400, valid loss-1.9747, acc-0.4834, test loss-1.9459, acc-0.4988\n",
      "Iter-56580, train loss-1.9939, acc-0.4800, valid loss-1.9747, acc-0.4834, test loss-1.9459, acc-0.4991\n",
      "Iter-56590, train loss-1.9947, acc-0.5400, valid loss-1.9746, acc-0.4832, test loss-1.9458, acc-0.4990\n",
      "Iter-56600, train loss-2.0366, acc-0.4200, valid loss-1.9746, acc-0.4832, test loss-1.9458, acc-0.4992\n",
      "Iter-56610, train loss-2.0069, acc-0.4600, valid loss-1.9746, acc-0.4836, test loss-1.9457, acc-0.4988\n",
      "Iter-56620, train loss-1.9530, acc-0.5400, valid loss-1.9745, acc-0.4834, test loss-1.9457, acc-0.4992\n",
      "Iter-56630, train loss-1.9545, acc-0.5200, valid loss-1.9745, acc-0.4836, test loss-1.9457, acc-0.4992\n",
      "Iter-56640, train loss-1.8970, acc-0.4600, valid loss-1.9744, acc-0.4834, test loss-1.9456, acc-0.4992\n",
      "Iter-56650, train loss-1.9580, acc-0.4400, valid loss-1.9744, acc-0.4838, test loss-1.9456, acc-0.4989\n",
      "Iter-56660, train loss-2.0241, acc-0.3000, valid loss-1.9744, acc-0.4836, test loss-1.9455, acc-0.4988\n",
      "Iter-56670, train loss-1.9482, acc-0.5800, valid loss-1.9743, acc-0.4838, test loss-1.9455, acc-0.4988\n",
      "Iter-56680, train loss-2.0154, acc-0.5600, valid loss-1.9743, acc-0.4838, test loss-1.9454, acc-0.4987\n",
      "Iter-56690, train loss-1.8803, acc-0.5800, valid loss-1.9742, acc-0.4836, test loss-1.9454, acc-0.4986\n",
      "Iter-56700, train loss-1.9525, acc-0.5000, valid loss-1.9742, acc-0.4842, test loss-1.9454, acc-0.4988\n",
      "Iter-56710, train loss-1.9767, acc-0.3600, valid loss-1.9742, acc-0.4842, test loss-1.9453, acc-0.4988\n",
      "Iter-56720, train loss-1.9166, acc-0.5400, valid loss-1.9741, acc-0.4844, test loss-1.9453, acc-0.4989\n",
      "Iter-56730, train loss-1.9836, acc-0.4400, valid loss-1.9741, acc-0.4844, test loss-1.9452, acc-0.4993\n",
      "Iter-56740, train loss-2.0132, acc-0.4800, valid loss-1.9741, acc-0.4844, test loss-1.9452, acc-0.4992\n",
      "Iter-56750, train loss-2.0099, acc-0.4000, valid loss-1.9740, acc-0.4840, test loss-1.9452, acc-0.4991\n",
      "Iter-56760, train loss-1.9233, acc-0.4800, valid loss-1.9740, acc-0.4844, test loss-1.9451, acc-0.4990\n",
      "Iter-56770, train loss-1.9440, acc-0.5000, valid loss-1.9740, acc-0.4842, test loss-1.9451, acc-0.4995\n",
      "Iter-56780, train loss-1.9624, acc-0.4200, valid loss-1.9739, acc-0.4846, test loss-1.9450, acc-0.4993\n",
      "Iter-56790, train loss-1.9751, acc-0.4200, valid loss-1.9739, acc-0.4844, test loss-1.9450, acc-0.4992\n",
      "Iter-56800, train loss-1.9253, acc-0.5000, valid loss-1.9738, acc-0.4844, test loss-1.9449, acc-0.4989\n",
      "Iter-56810, train loss-2.0249, acc-0.4800, valid loss-1.9738, acc-0.4842, test loss-1.9449, acc-0.4990\n",
      "Iter-56820, train loss-1.9544, acc-0.4800, valid loss-1.9738, acc-0.4844, test loss-1.9449, acc-0.4990\n",
      "Iter-56830, train loss-1.9929, acc-0.4400, valid loss-1.9737, acc-0.4838, test loss-1.9448, acc-0.4989\n",
      "Iter-56840, train loss-1.9721, acc-0.4800, valid loss-1.9737, acc-0.4840, test loss-1.9448, acc-0.4988\n",
      "Iter-56850, train loss-1.9684, acc-0.5000, valid loss-1.9737, acc-0.4838, test loss-1.9447, acc-0.4990\n",
      "Iter-56860, train loss-2.0236, acc-0.4400, valid loss-1.9736, acc-0.4838, test loss-1.9447, acc-0.4988\n",
      "Iter-56870, train loss-1.9991, acc-0.4200, valid loss-1.9736, acc-0.4838, test loss-1.9447, acc-0.4988\n",
      "Iter-56880, train loss-1.9102, acc-0.4600, valid loss-1.9735, acc-0.4842, test loss-1.9446, acc-0.4987\n",
      "Iter-56890, train loss-1.9132, acc-0.3800, valid loss-1.9735, acc-0.4838, test loss-1.9446, acc-0.4987\n",
      "Iter-56900, train loss-1.9489, acc-0.6000, valid loss-1.9735, acc-0.4844, test loss-1.9445, acc-0.4988\n",
      "Iter-56910, train loss-1.9262, acc-0.5200, valid loss-1.9734, acc-0.4844, test loss-1.9445, acc-0.4989\n",
      "Iter-56920, train loss-1.9779, acc-0.4800, valid loss-1.9734, acc-0.4842, test loss-1.9445, acc-0.4989\n",
      "Iter-56930, train loss-1.8934, acc-0.5400, valid loss-1.9734, acc-0.4842, test loss-1.9444, acc-0.4988\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56940, train loss-2.0227, acc-0.3400, valid loss-1.9733, acc-0.4838, test loss-1.9444, acc-0.4991\n",
      "Iter-56950, train loss-1.9232, acc-0.5200, valid loss-1.9733, acc-0.4838, test loss-1.9443, acc-0.4992\n",
      "Iter-56960, train loss-1.9128, acc-0.5200, valid loss-1.9732, acc-0.4838, test loss-1.9443, acc-0.4993\n",
      "Iter-56970, train loss-1.9390, acc-0.4400, valid loss-1.9732, acc-0.4838, test loss-1.9442, acc-0.4993\n",
      "Iter-56980, train loss-1.9652, acc-0.5200, valid loss-1.9732, acc-0.4838, test loss-1.9442, acc-0.4994\n",
      "Iter-56990, train loss-1.9379, acc-0.5000, valid loss-1.9731, acc-0.4836, test loss-1.9442, acc-0.4991\n",
      "Iter-57000, train loss-1.9157, acc-0.5600, valid loss-1.9731, acc-0.4836, test loss-1.9441, acc-0.4993\n",
      "Iter-57010, train loss-1.9406, acc-0.5000, valid loss-1.9730, acc-0.4838, test loss-1.9441, acc-0.4994\n",
      "Iter-57020, train loss-1.9332, acc-0.5600, valid loss-1.9730, acc-0.4834, test loss-1.9440, acc-0.4993\n",
      "Iter-57030, train loss-1.9539, acc-0.4400, valid loss-1.9730, acc-0.4836, test loss-1.9440, acc-0.4990\n",
      "Iter-57040, train loss-2.0032, acc-0.4600, valid loss-1.9729, acc-0.4836, test loss-1.9439, acc-0.4990\n",
      "Iter-57050, train loss-1.8832, acc-0.6400, valid loss-1.9729, acc-0.4836, test loss-1.9439, acc-0.4985\n",
      "Iter-57060, train loss-2.0149, acc-0.4200, valid loss-1.9728, acc-0.4836, test loss-1.9439, acc-0.4985\n",
      "Iter-57070, train loss-1.9672, acc-0.5200, valid loss-1.9728, acc-0.4836, test loss-1.9438, acc-0.4985\n",
      "Iter-57080, train loss-1.9849, acc-0.4200, valid loss-1.9728, acc-0.4836, test loss-1.9438, acc-0.4987\n",
      "Iter-57090, train loss-2.0210, acc-0.4000, valid loss-1.9727, acc-0.4838, test loss-1.9437, acc-0.4988\n",
      "Iter-57100, train loss-1.9858, acc-0.4000, valid loss-1.9727, acc-0.4836, test loss-1.9437, acc-0.4988\n",
      "Iter-57110, train loss-1.9291, acc-0.5400, valid loss-1.9726, acc-0.4838, test loss-1.9437, acc-0.4988\n",
      "Iter-57120, train loss-1.9380, acc-0.5000, valid loss-1.9726, acc-0.4840, test loss-1.9436, acc-0.4989\n",
      "Iter-57130, train loss-2.0195, acc-0.3400, valid loss-1.9726, acc-0.4840, test loss-1.9436, acc-0.4987\n",
      "Iter-57140, train loss-1.9879, acc-0.4400, valid loss-1.9725, acc-0.4836, test loss-1.9435, acc-0.4988\n",
      "Iter-57150, train loss-1.9450, acc-0.4800, valid loss-1.9725, acc-0.4838, test loss-1.9435, acc-0.4990\n",
      "Iter-57160, train loss-1.9711, acc-0.6400, valid loss-1.9725, acc-0.4838, test loss-1.9434, acc-0.4989\n",
      "Iter-57170, train loss-1.9918, acc-0.4600, valid loss-1.9724, acc-0.4838, test loss-1.9434, acc-0.4990\n",
      "Iter-57180, train loss-1.9827, acc-0.5200, valid loss-1.9724, acc-0.4836, test loss-1.9434, acc-0.4989\n",
      "Iter-57190, train loss-1.8932, acc-0.5600, valid loss-1.9724, acc-0.4836, test loss-1.9433, acc-0.4990\n",
      "Iter-57200, train loss-1.9431, acc-0.4200, valid loss-1.9723, acc-0.4836, test loss-1.9433, acc-0.4990\n",
      "Iter-57210, train loss-1.9149, acc-0.5200, valid loss-1.9723, acc-0.4836, test loss-1.9432, acc-0.4987\n",
      "Iter-57220, train loss-1.9613, acc-0.3800, valid loss-1.9722, acc-0.4836, test loss-1.9432, acc-0.4990\n",
      "Iter-57230, train loss-1.9511, acc-0.4400, valid loss-1.9722, acc-0.4840, test loss-1.9432, acc-0.4991\n",
      "Iter-57240, train loss-1.9103, acc-0.4200, valid loss-1.9722, acc-0.4840, test loss-1.9431, acc-0.4991\n",
      "Iter-57250, train loss-1.9152, acc-0.5000, valid loss-1.9721, acc-0.4840, test loss-1.9431, acc-0.4988\n",
      "Iter-57260, train loss-1.9722, acc-0.5200, valid loss-1.9721, acc-0.4840, test loss-1.9430, acc-0.4992\n",
      "Iter-57270, train loss-1.9976, acc-0.4200, valid loss-1.9720, acc-0.4840, test loss-1.9430, acc-0.4992\n",
      "Iter-57280, train loss-1.8855, acc-0.5600, valid loss-1.9720, acc-0.4842, test loss-1.9430, acc-0.4996\n",
      "Iter-57290, train loss-1.9411, acc-0.4600, valid loss-1.9720, acc-0.4842, test loss-1.9429, acc-0.4995\n",
      "Iter-57300, train loss-2.0128, acc-0.3800, valid loss-1.9719, acc-0.4840, test loss-1.9429, acc-0.4996\n",
      "Iter-57310, train loss-1.9599, acc-0.4600, valid loss-1.9719, acc-0.4844, test loss-1.9428, acc-0.4997\n",
      "Iter-57320, train loss-1.9192, acc-0.4600, valid loss-1.9719, acc-0.4842, test loss-1.9428, acc-0.4997\n",
      "Iter-57330, train loss-1.9093, acc-0.5200, valid loss-1.9718, acc-0.4842, test loss-1.9427, acc-0.4998\n",
      "Iter-57340, train loss-1.9405, acc-0.5800, valid loss-1.9718, acc-0.4840, test loss-1.9427, acc-0.4997\n",
      "Iter-57350, train loss-1.9825, acc-0.4400, valid loss-1.9717, acc-0.4842, test loss-1.9427, acc-0.4996\n",
      "Iter-57360, train loss-1.9805, acc-0.5200, valid loss-1.9717, acc-0.4842, test loss-1.9426, acc-0.4997\n",
      "Iter-57370, train loss-1.9239, acc-0.5000, valid loss-1.9717, acc-0.4842, test loss-1.9426, acc-0.4998\n",
      "Iter-57380, train loss-2.0084, acc-0.4600, valid loss-1.9716, acc-0.4846, test loss-1.9425, acc-0.4998\n",
      "Iter-57390, train loss-1.9741, acc-0.4800, valid loss-1.9716, acc-0.4844, test loss-1.9425, acc-0.4996\n",
      "Iter-57400, train loss-1.9538, acc-0.4000, valid loss-1.9716, acc-0.4842, test loss-1.9425, acc-0.4999\n",
      "Iter-57410, train loss-1.9254, acc-0.4600, valid loss-1.9715, acc-0.4842, test loss-1.9424, acc-0.4999\n",
      "Iter-57420, train loss-1.9443, acc-0.4400, valid loss-1.9715, acc-0.4842, test loss-1.9424, acc-0.4997\n",
      "Iter-57430, train loss-1.9313, acc-0.5000, valid loss-1.9715, acc-0.4842, test loss-1.9423, acc-0.4998\n",
      "Iter-57440, train loss-2.0159, acc-0.4400, valid loss-1.9714, acc-0.4842, test loss-1.9423, acc-0.4997\n",
      "Iter-57450, train loss-2.0221, acc-0.4400, valid loss-1.9714, acc-0.4838, test loss-1.9423, acc-0.4998\n",
      "Iter-57460, train loss-1.9727, acc-0.4600, valid loss-1.9714, acc-0.4846, test loss-1.9422, acc-0.4997\n",
      "Iter-57470, train loss-1.9279, acc-0.5600, valid loss-1.9713, acc-0.4844, test loss-1.9422, acc-0.4997\n",
      "Iter-57480, train loss-1.9244, acc-0.5600, valid loss-1.9713, acc-0.4842, test loss-1.9421, acc-0.4998\n",
      "Iter-57490, train loss-1.8664, acc-0.5400, valid loss-1.9712, acc-0.4840, test loss-1.9421, acc-0.4998\n",
      "Iter-57500, train loss-1.9608, acc-0.4800, valid loss-1.9712, acc-0.4842, test loss-1.9420, acc-0.4998\n",
      "Iter-57510, train loss-2.0272, acc-0.3200, valid loss-1.9712, acc-0.4844, test loss-1.9420, acc-0.4998\n",
      "Iter-57520, train loss-1.9606, acc-0.4800, valid loss-1.9711, acc-0.4840, test loss-1.9420, acc-0.4996\n",
      "Iter-57530, train loss-1.9592, acc-0.4600, valid loss-1.9711, acc-0.4840, test loss-1.9419, acc-0.4997\n",
      "Iter-57540, train loss-1.9549, acc-0.5600, valid loss-1.9711, acc-0.4844, test loss-1.9419, acc-0.4996\n",
      "Iter-57550, train loss-1.9344, acc-0.5000, valid loss-1.9710, acc-0.4840, test loss-1.9418, acc-0.4997\n",
      "Iter-57560, train loss-2.0100, acc-0.4800, valid loss-1.9710, acc-0.4840, test loss-1.9418, acc-0.4996\n",
      "Iter-57570, train loss-2.0204, acc-0.4000, valid loss-1.9709, acc-0.4844, test loss-1.9418, acc-0.4993\n",
      "Iter-57580, train loss-1.8975, acc-0.5000, valid loss-1.9709, acc-0.4844, test loss-1.9417, acc-0.4995\n",
      "Iter-57590, train loss-1.9411, acc-0.4400, valid loss-1.9709, acc-0.4846, test loss-1.9417, acc-0.4997\n",
      "Iter-57600, train loss-1.9704, acc-0.3800, valid loss-1.9708, acc-0.4846, test loss-1.9416, acc-0.4994\n",
      "Iter-57610, train loss-2.0285, acc-0.4000, valid loss-1.9708, acc-0.4848, test loss-1.9416, acc-0.4995\n",
      "Iter-57620, train loss-1.8754, acc-0.6000, valid loss-1.9708, acc-0.4848, test loss-1.9415, acc-0.4993\n",
      "Iter-57630, train loss-1.9782, acc-0.5000, valid loss-1.9707, acc-0.4844, test loss-1.9415, acc-0.4993\n",
      "Iter-57640, train loss-2.0080, acc-0.3800, valid loss-1.9707, acc-0.4844, test loss-1.9415, acc-0.4993\n",
      "Iter-57650, train loss-1.9295, acc-0.5200, valid loss-1.9706, acc-0.4846, test loss-1.9414, acc-0.4995\n",
      "Iter-57660, train loss-1.9511, acc-0.5000, valid loss-1.9706, acc-0.4844, test loss-1.9414, acc-0.4994\n",
      "Iter-57670, train loss-1.9748, acc-0.5000, valid loss-1.9706, acc-0.4850, test loss-1.9413, acc-0.4994\n",
      "Iter-57680, train loss-1.9477, acc-0.5400, valid loss-1.9705, acc-0.4846, test loss-1.9413, acc-0.4995\n",
      "Iter-57690, train loss-1.9594, acc-0.4800, valid loss-1.9705, acc-0.4850, test loss-1.9412, acc-0.4994\n",
      "Iter-57700, train loss-1.9737, acc-0.4600, valid loss-1.9705, acc-0.4848, test loss-1.9412, acc-0.4996\n",
      "Iter-57710, train loss-1.9784, acc-0.4600, valid loss-1.9704, acc-0.4848, test loss-1.9412, acc-0.4995\n",
      "Iter-57720, train loss-1.9121, acc-0.5400, valid loss-1.9704, acc-0.4846, test loss-1.9411, acc-0.4995\n",
      "Iter-57730, train loss-1.8885, acc-0.5400, valid loss-1.9703, acc-0.4846, test loss-1.9411, acc-0.4996\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-57740, train loss-1.9803, acc-0.5400, valid loss-1.9703, acc-0.4848, test loss-1.9410, acc-0.4995\n",
      "Iter-57750, train loss-1.9730, acc-0.5000, valid loss-1.9703, acc-0.4846, test loss-1.9410, acc-0.4996\n",
      "Iter-57760, train loss-1.9235, acc-0.5400, valid loss-1.9702, acc-0.4846, test loss-1.9410, acc-0.4995\n",
      "Iter-57770, train loss-1.9289, acc-0.4600, valid loss-1.9702, acc-0.4848, test loss-1.9409, acc-0.4997\n",
      "Iter-57780, train loss-1.9725, acc-0.4800, valid loss-1.9701, acc-0.4846, test loss-1.9409, acc-0.4997\n",
      "Iter-57790, train loss-1.9028, acc-0.4400, valid loss-1.9701, acc-0.4848, test loss-1.9408, acc-0.4999\n",
      "Iter-57800, train loss-1.9168, acc-0.5400, valid loss-1.9701, acc-0.4848, test loss-1.9408, acc-0.5000\n",
      "Iter-57810, train loss-1.9499, acc-0.4400, valid loss-1.9700, acc-0.4846, test loss-1.9408, acc-0.5000\n",
      "Iter-57820, train loss-1.9545, acc-0.4000, valid loss-1.9700, acc-0.4850, test loss-1.9407, acc-0.5000\n",
      "Iter-57830, train loss-1.9961, acc-0.5400, valid loss-1.9700, acc-0.4844, test loss-1.9407, acc-0.5000\n",
      "Iter-57840, train loss-2.0230, acc-0.5400, valid loss-1.9699, acc-0.4848, test loss-1.9406, acc-0.4999\n",
      "Iter-57850, train loss-1.8833, acc-0.6400, valid loss-1.9699, acc-0.4844, test loss-1.9406, acc-0.5000\n",
      "Iter-57860, train loss-1.9483, acc-0.6000, valid loss-1.9699, acc-0.4844, test loss-1.9405, acc-0.5001\n",
      "Iter-57870, train loss-1.9260, acc-0.5800, valid loss-1.9698, acc-0.4846, test loss-1.9405, acc-0.5000\n",
      "Iter-57880, train loss-1.9238, acc-0.5000, valid loss-1.9698, acc-0.4846, test loss-1.9405, acc-0.5000\n",
      "Iter-57890, train loss-2.0367, acc-0.3800, valid loss-1.9697, acc-0.4848, test loss-1.9404, acc-0.5001\n",
      "Iter-57900, train loss-1.9613, acc-0.4800, valid loss-1.9697, acc-0.4846, test loss-1.9404, acc-0.5001\n",
      "Iter-57910, train loss-1.9409, acc-0.5400, valid loss-1.9697, acc-0.4844, test loss-1.9403, acc-0.5001\n",
      "Iter-57920, train loss-1.9047, acc-0.5600, valid loss-1.9696, acc-0.4844, test loss-1.9403, acc-0.5001\n",
      "Iter-57930, train loss-2.0443, acc-0.3800, valid loss-1.9696, acc-0.4842, test loss-1.9403, acc-0.5000\n",
      "Iter-57940, train loss-1.9727, acc-0.5200, valid loss-1.9696, acc-0.4844, test loss-1.9402, acc-0.5000\n",
      "Iter-57950, train loss-1.9168, acc-0.5800, valid loss-1.9695, acc-0.4844, test loss-1.9402, acc-0.5002\n",
      "Iter-57960, train loss-1.9948, acc-0.4200, valid loss-1.9695, acc-0.4842, test loss-1.9401, acc-0.5001\n",
      "Iter-57970, train loss-2.0257, acc-0.3800, valid loss-1.9695, acc-0.4844, test loss-1.9401, acc-0.5002\n",
      "Iter-57980, train loss-1.8977, acc-0.5200, valid loss-1.9694, acc-0.4844, test loss-1.9401, acc-0.5001\n",
      "Iter-57990, train loss-1.9112, acc-0.5400, valid loss-1.9694, acc-0.4842, test loss-1.9400, acc-0.5001\n",
      "Iter-58000, train loss-1.8781, acc-0.5400, valid loss-1.9693, acc-0.4846, test loss-1.9400, acc-0.5002\n",
      "Iter-58010, train loss-1.8715, acc-0.5800, valid loss-1.9693, acc-0.4846, test loss-1.9399, acc-0.5001\n",
      "Iter-58020, train loss-2.0259, acc-0.3600, valid loss-1.9693, acc-0.4846, test loss-1.9399, acc-0.5002\n",
      "Iter-58030, train loss-1.9318, acc-0.6600, valid loss-1.9692, acc-0.4846, test loss-1.9399, acc-0.5003\n",
      "Iter-58040, train loss-1.9169, acc-0.4600, valid loss-1.9692, acc-0.4846, test loss-1.9398, acc-0.5002\n",
      "Iter-58050, train loss-1.9052, acc-0.5400, valid loss-1.9692, acc-0.4844, test loss-1.9398, acc-0.5003\n",
      "Iter-58060, train loss-1.9507, acc-0.5600, valid loss-1.9691, acc-0.4844, test loss-1.9397, acc-0.5004\n",
      "Iter-58070, train loss-1.9339, acc-0.5600, valid loss-1.9691, acc-0.4842, test loss-1.9397, acc-0.5004\n",
      "Iter-58080, train loss-1.9932, acc-0.4000, valid loss-1.9690, acc-0.4844, test loss-1.9396, acc-0.5004\n",
      "Iter-58090, train loss-2.0224, acc-0.3400, valid loss-1.9690, acc-0.4842, test loss-1.9396, acc-0.5003\n",
      "Iter-58100, train loss-1.9738, acc-0.4800, valid loss-1.9690, acc-0.4844, test loss-1.9396, acc-0.5005\n",
      "Iter-58110, train loss-1.9652, acc-0.4600, valid loss-1.9689, acc-0.4844, test loss-1.9395, acc-0.5004\n",
      "Iter-58120, train loss-1.9700, acc-0.5400, valid loss-1.9689, acc-0.4846, test loss-1.9395, acc-0.5006\n",
      "Iter-58130, train loss-1.9446, acc-0.5200, valid loss-1.9689, acc-0.4846, test loss-1.9394, acc-0.5006\n",
      "Iter-58140, train loss-1.9387, acc-0.4800, valid loss-1.9688, acc-0.4842, test loss-1.9394, acc-0.5005\n",
      "Iter-58150, train loss-2.0083, acc-0.4400, valid loss-1.9688, acc-0.4844, test loss-1.9394, acc-0.5008\n",
      "Iter-58160, train loss-2.0377, acc-0.4000, valid loss-1.9688, acc-0.4842, test loss-1.9393, acc-0.5006\n",
      "Iter-58170, train loss-1.9640, acc-0.5200, valid loss-1.9687, acc-0.4844, test loss-1.9393, acc-0.5008\n",
      "Iter-58180, train loss-2.0171, acc-0.4600, valid loss-1.9687, acc-0.4846, test loss-1.9392, acc-0.5008\n",
      "Iter-58190, train loss-1.9758, acc-0.4800, valid loss-1.9687, acc-0.4846, test loss-1.9392, acc-0.5007\n",
      "Iter-58200, train loss-2.0008, acc-0.4600, valid loss-1.9686, acc-0.4846, test loss-1.9392, acc-0.5006\n",
      "Iter-58210, train loss-1.9223, acc-0.4800, valid loss-1.9686, acc-0.4846, test loss-1.9391, acc-0.5006\n",
      "Iter-58220, train loss-1.9290, acc-0.5800, valid loss-1.9685, acc-0.4846, test loss-1.9391, acc-0.5006\n",
      "Iter-58230, train loss-1.9377, acc-0.4800, valid loss-1.9685, acc-0.4846, test loss-1.9390, acc-0.5005\n",
      "Iter-58240, train loss-2.0097, acc-0.4000, valid loss-1.9685, acc-0.4852, test loss-1.9390, acc-0.5004\n",
      "Iter-58250, train loss-1.9614, acc-0.4800, valid loss-1.9685, acc-0.4850, test loss-1.9390, acc-0.5004\n",
      "Iter-58260, train loss-1.9225, acc-0.5400, valid loss-1.9684, acc-0.4852, test loss-1.9389, acc-0.5006\n",
      "Iter-58270, train loss-1.9447, acc-0.4800, valid loss-1.9684, acc-0.4852, test loss-1.9389, acc-0.5005\n",
      "Iter-58280, train loss-1.9182, acc-0.4800, valid loss-1.9683, acc-0.4852, test loss-1.9388, acc-0.5002\n",
      "Iter-58290, train loss-2.0211, acc-0.4000, valid loss-1.9683, acc-0.4852, test loss-1.9388, acc-0.5003\n",
      "Iter-58300, train loss-1.9626, acc-0.4000, valid loss-1.9683, acc-0.4850, test loss-1.9387, acc-0.5003\n",
      "Iter-58310, train loss-2.0212, acc-0.5000, valid loss-1.9682, acc-0.4848, test loss-1.9387, acc-0.5004\n",
      "Iter-58320, train loss-2.0328, acc-0.4200, valid loss-1.9682, acc-0.4850, test loss-1.9387, acc-0.5004\n",
      "Iter-58330, train loss-1.9297, acc-0.4200, valid loss-1.9682, acc-0.4850, test loss-1.9386, acc-0.5004\n",
      "Iter-58340, train loss-1.9792, acc-0.4600, valid loss-1.9681, acc-0.4850, test loss-1.9386, acc-0.5002\n",
      "Iter-58350, train loss-1.9611, acc-0.5200, valid loss-1.9681, acc-0.4848, test loss-1.9385, acc-0.5002\n",
      "Iter-58360, train loss-2.0140, acc-0.4400, valid loss-1.9681, acc-0.4846, test loss-1.9385, acc-0.5002\n",
      "Iter-58370, train loss-1.9267, acc-0.5200, valid loss-1.9680, acc-0.4848, test loss-1.9385, acc-0.5002\n",
      "Iter-58380, train loss-2.0031, acc-0.5000, valid loss-1.9680, acc-0.4848, test loss-1.9384, acc-0.5003\n",
      "Iter-58390, train loss-1.9580, acc-0.4800, valid loss-1.9679, acc-0.4848, test loss-1.9384, acc-0.5003\n",
      "Iter-58400, train loss-1.9867, acc-0.4600, valid loss-1.9679, acc-0.4846, test loss-1.9383, acc-0.5003\n",
      "Iter-58410, train loss-1.9376, acc-0.5000, valid loss-1.9679, acc-0.4848, test loss-1.9383, acc-0.5006\n",
      "Iter-58420, train loss-1.9292, acc-0.5000, valid loss-1.9678, acc-0.4846, test loss-1.9383, acc-0.5004\n",
      "Iter-58430, train loss-1.9267, acc-0.5400, valid loss-1.9678, acc-0.4846, test loss-1.9382, acc-0.5004\n",
      "Iter-58440, train loss-1.9394, acc-0.5000, valid loss-1.9678, acc-0.4846, test loss-1.9382, acc-0.5005\n",
      "Iter-58450, train loss-1.9807, acc-0.4400, valid loss-1.9677, acc-0.4848, test loss-1.9381, acc-0.5003\n",
      "Iter-58460, train loss-1.9810, acc-0.4000, valid loss-1.9677, acc-0.4852, test loss-1.9381, acc-0.5003\n",
      "Iter-58470, train loss-1.9316, acc-0.5000, valid loss-1.9677, acc-0.4854, test loss-1.9381, acc-0.5004\n",
      "Iter-58480, train loss-1.8759, acc-0.6200, valid loss-1.9676, acc-0.4850, test loss-1.9380, acc-0.5003\n",
      "Iter-58490, train loss-1.9637, acc-0.4200, valid loss-1.9676, acc-0.4852, test loss-1.9380, acc-0.5004\n",
      "Iter-58500, train loss-1.9775, acc-0.5000, valid loss-1.9676, acc-0.4852, test loss-1.9379, acc-0.5002\n",
      "Iter-58510, train loss-1.9588, acc-0.4400, valid loss-1.9675, acc-0.4850, test loss-1.9379, acc-0.5004\n",
      "Iter-58520, train loss-2.0126, acc-0.5400, valid loss-1.9675, acc-0.4850, test loss-1.9379, acc-0.5003\n",
      "Iter-58530, train loss-1.9385, acc-0.4800, valid loss-1.9674, acc-0.4848, test loss-1.9378, acc-0.5006\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-58540, train loss-2.0314, acc-0.3400, valid loss-1.9674, acc-0.4850, test loss-1.9378, acc-0.5005\n",
      "Iter-58550, train loss-1.9839, acc-0.3200, valid loss-1.9674, acc-0.4850, test loss-1.9377, acc-0.5006\n",
      "Iter-58560, train loss-2.0097, acc-0.4400, valid loss-1.9673, acc-0.4850, test loss-1.9377, acc-0.5004\n",
      "Iter-58570, train loss-2.0017, acc-0.3600, valid loss-1.9673, acc-0.4848, test loss-1.9377, acc-0.4999\n",
      "Iter-58580, train loss-1.8685, acc-0.5800, valid loss-1.9673, acc-0.4848, test loss-1.9376, acc-0.4999\n",
      "Iter-58590, train loss-1.9592, acc-0.4200, valid loss-1.9672, acc-0.4850, test loss-1.9376, acc-0.5001\n",
      "Iter-58600, train loss-2.0083, acc-0.5000, valid loss-1.9672, acc-0.4850, test loss-1.9375, acc-0.5001\n",
      "Iter-58610, train loss-1.9944, acc-0.4600, valid loss-1.9672, acc-0.4850, test loss-1.9375, acc-0.5000\n",
      "Iter-58620, train loss-2.0268, acc-0.4600, valid loss-1.9671, acc-0.4850, test loss-1.9375, acc-0.5000\n",
      "Iter-58630, train loss-1.9278, acc-0.5200, valid loss-1.9671, acc-0.4850, test loss-1.9374, acc-0.5002\n",
      "Iter-58640, train loss-1.8931, acc-0.5600, valid loss-1.9670, acc-0.4850, test loss-1.9374, acc-0.5003\n",
      "Iter-58650, train loss-1.9863, acc-0.4400, valid loss-1.9670, acc-0.4848, test loss-1.9373, acc-0.5003\n",
      "Iter-58660, train loss-1.9803, acc-0.4400, valid loss-1.9670, acc-0.4850, test loss-1.9373, acc-0.5004\n",
      "Iter-58670, train loss-1.9939, acc-0.4600, valid loss-1.9669, acc-0.4850, test loss-1.9372, acc-0.5004\n",
      "Iter-58680, train loss-1.8959, acc-0.5000, valid loss-1.9669, acc-0.4848, test loss-1.9372, acc-0.5004\n",
      "Iter-58690, train loss-1.9219, acc-0.4600, valid loss-1.9668, acc-0.4850, test loss-1.9372, acc-0.5004\n",
      "Iter-58700, train loss-1.9556, acc-0.4400, valid loss-1.9668, acc-0.4850, test loss-1.9371, acc-0.5004\n",
      "Iter-58710, train loss-1.9191, acc-0.4800, valid loss-1.9668, acc-0.4848, test loss-1.9371, acc-0.5006\n",
      "Iter-58720, train loss-1.9392, acc-0.5000, valid loss-1.9667, acc-0.4848, test loss-1.9370, acc-0.5007\n",
      "Iter-58730, train loss-1.9738, acc-0.5200, valid loss-1.9667, acc-0.4848, test loss-1.9370, acc-0.5005\n",
      "Iter-58740, train loss-1.9877, acc-0.5400, valid loss-1.9667, acc-0.4846, test loss-1.9370, acc-0.5006\n",
      "Iter-58750, train loss-2.0108, acc-0.4000, valid loss-1.9666, acc-0.4846, test loss-1.9369, acc-0.5006\n",
      "Iter-58760, train loss-1.9330, acc-0.4200, valid loss-1.9666, acc-0.4846, test loss-1.9369, acc-0.5008\n",
      "Iter-58770, train loss-1.8534, acc-0.5800, valid loss-1.9665, acc-0.4846, test loss-1.9368, acc-0.5005\n",
      "Iter-58780, train loss-1.9155, acc-0.5400, valid loss-1.9665, acc-0.4848, test loss-1.9368, acc-0.5007\n",
      "Iter-58790, train loss-2.0315, acc-0.3400, valid loss-1.9665, acc-0.4848, test loss-1.9368, acc-0.5006\n",
      "Iter-58800, train loss-1.9661, acc-0.5000, valid loss-1.9664, acc-0.4848, test loss-1.9367, acc-0.5004\n",
      "Iter-58810, train loss-1.9962, acc-0.4400, valid loss-1.9664, acc-0.4846, test loss-1.9367, acc-0.5006\n",
      "Iter-58820, train loss-1.8566, acc-0.5600, valid loss-1.9664, acc-0.4846, test loss-1.9366, acc-0.5007\n",
      "Iter-58830, train loss-1.9768, acc-0.5000, valid loss-1.9663, acc-0.4848, test loss-1.9366, acc-0.5005\n",
      "Iter-58840, train loss-1.9468, acc-0.4800, valid loss-1.9663, acc-0.4848, test loss-1.9365, acc-0.5005\n",
      "Iter-58850, train loss-1.9948, acc-0.3400, valid loss-1.9662, acc-0.4844, test loss-1.9365, acc-0.5004\n",
      "Iter-58860, train loss-1.9626, acc-0.5400, valid loss-1.9662, acc-0.4842, test loss-1.9365, acc-0.5004\n",
      "Iter-58870, train loss-1.9403, acc-0.5400, valid loss-1.9662, acc-0.4844, test loss-1.9364, acc-0.5004\n",
      "Iter-58880, train loss-1.9584, acc-0.4600, valid loss-1.9661, acc-0.4846, test loss-1.9364, acc-0.5002\n",
      "Iter-58890, train loss-1.8999, acc-0.4800, valid loss-1.9661, acc-0.4842, test loss-1.9363, acc-0.5005\n",
      "Iter-58900, train loss-1.9179, acc-0.4600, valid loss-1.9661, acc-0.4840, test loss-1.9363, acc-0.5005\n",
      "Iter-58910, train loss-1.9611, acc-0.5000, valid loss-1.9660, acc-0.4846, test loss-1.9363, acc-0.5007\n",
      "Iter-58920, train loss-1.9683, acc-0.5000, valid loss-1.9660, acc-0.4848, test loss-1.9362, acc-0.5004\n",
      "Iter-58930, train loss-1.9378, acc-0.4800, valid loss-1.9659, acc-0.4848, test loss-1.9362, acc-0.5004\n",
      "Iter-58940, train loss-1.8926, acc-0.6000, valid loss-1.9659, acc-0.4846, test loss-1.9361, acc-0.5003\n",
      "Iter-58950, train loss-1.9231, acc-0.4600, valid loss-1.9659, acc-0.4848, test loss-1.9361, acc-0.5004\n",
      "Iter-58960, train loss-1.9422, acc-0.3800, valid loss-1.9658, acc-0.4852, test loss-1.9361, acc-0.5005\n",
      "Iter-58970, train loss-1.8686, acc-0.5200, valid loss-1.9658, acc-0.4848, test loss-1.9360, acc-0.5006\n",
      "Iter-58980, train loss-2.0250, acc-0.4000, valid loss-1.9658, acc-0.4850, test loss-1.9360, acc-0.5005\n",
      "Iter-58990, train loss-1.9481, acc-0.5000, valid loss-1.9657, acc-0.4846, test loss-1.9359, acc-0.5006\n",
      "Iter-59000, train loss-1.9187, acc-0.4800, valid loss-1.9657, acc-0.4846, test loss-1.9359, acc-0.5006\n",
      "Iter-59010, train loss-1.9123, acc-0.6000, valid loss-1.9656, acc-0.4844, test loss-1.9359, acc-0.5006\n",
      "Iter-59020, train loss-2.0134, acc-0.4400, valid loss-1.9656, acc-0.4844, test loss-1.9358, acc-0.5007\n",
      "Iter-59030, train loss-1.9420, acc-0.3800, valid loss-1.9656, acc-0.4844, test loss-1.9358, acc-0.5006\n",
      "Iter-59040, train loss-1.9163, acc-0.5400, valid loss-1.9655, acc-0.4844, test loss-1.9357, acc-0.5004\n",
      "Iter-59050, train loss-2.0115, acc-0.4200, valid loss-1.9655, acc-0.4848, test loss-1.9357, acc-0.5006\n",
      "Iter-59060, train loss-1.9419, acc-0.5000, valid loss-1.9655, acc-0.4846, test loss-1.9356, acc-0.5004\n",
      "Iter-59070, train loss-1.9575, acc-0.5200, valid loss-1.9654, acc-0.4846, test loss-1.9356, acc-0.5003\n",
      "Iter-59080, train loss-2.0076, acc-0.4800, valid loss-1.9654, acc-0.4844, test loss-1.9356, acc-0.5005\n",
      "Iter-59090, train loss-1.9241, acc-0.5800, valid loss-1.9654, acc-0.4844, test loss-1.9355, acc-0.5006\n",
      "Iter-59100, train loss-1.9677, acc-0.5400, valid loss-1.9653, acc-0.4844, test loss-1.9355, acc-0.5005\n",
      "Iter-59110, train loss-1.9785, acc-0.5000, valid loss-1.9653, acc-0.4846, test loss-1.9354, acc-0.5005\n",
      "Iter-59120, train loss-1.8985, acc-0.5800, valid loss-1.9652, acc-0.4848, test loss-1.9354, acc-0.5006\n",
      "Iter-59130, train loss-2.0206, acc-0.4600, valid loss-1.9652, acc-0.4848, test loss-1.9354, acc-0.5006\n",
      "Iter-59140, train loss-1.9578, acc-0.5200, valid loss-1.9652, acc-0.4848, test loss-1.9353, acc-0.5007\n",
      "Iter-59150, train loss-1.9541, acc-0.4200, valid loss-1.9651, acc-0.4848, test loss-1.9353, acc-0.5008\n",
      "Iter-59160, train loss-2.0010, acc-0.3800, valid loss-1.9651, acc-0.4850, test loss-1.9352, acc-0.5008\n",
      "Iter-59170, train loss-2.0080, acc-0.4600, valid loss-1.9651, acc-0.4850, test loss-1.9352, acc-0.5009\n",
      "Iter-59180, train loss-1.8843, acc-0.5800, valid loss-1.9650, acc-0.4848, test loss-1.9352, acc-0.5011\n",
      "Iter-59190, train loss-1.9315, acc-0.4400, valid loss-1.9650, acc-0.4850, test loss-1.9351, acc-0.5010\n",
      "Iter-59200, train loss-1.9134, acc-0.5800, valid loss-1.9649, acc-0.4848, test loss-1.9351, acc-0.5004\n",
      "Iter-59210, train loss-1.8657, acc-0.5600, valid loss-1.9649, acc-0.4850, test loss-1.9350, acc-0.5006\n",
      "Iter-59220, train loss-1.9942, acc-0.3400, valid loss-1.9649, acc-0.4848, test loss-1.9350, acc-0.5007\n",
      "Iter-59230, train loss-1.8658, acc-0.6400, valid loss-1.9648, acc-0.4846, test loss-1.9350, acc-0.5007\n",
      "Iter-59240, train loss-2.0195, acc-0.4000, valid loss-1.9648, acc-0.4846, test loss-1.9349, acc-0.5005\n",
      "Iter-59250, train loss-1.9359, acc-0.5200, valid loss-1.9648, acc-0.4846, test loss-1.9349, acc-0.5005\n",
      "Iter-59260, train loss-1.9284, acc-0.4400, valid loss-1.9647, acc-0.4850, test loss-1.9348, acc-0.5008\n",
      "Iter-59270, train loss-1.9870, acc-0.5200, valid loss-1.9647, acc-0.4850, test loss-1.9348, acc-0.5005\n",
      "Iter-59280, train loss-1.8995, acc-0.5800, valid loss-1.9646, acc-0.4850, test loss-1.9348, acc-0.5005\n",
      "Iter-59290, train loss-1.9989, acc-0.4400, valid loss-1.9646, acc-0.4846, test loss-1.9347, acc-0.5005\n",
      "Iter-59300, train loss-2.0012, acc-0.5400, valid loss-1.9646, acc-0.4850, test loss-1.9347, acc-0.5005\n",
      "Iter-59310, train loss-1.9552, acc-0.4800, valid loss-1.9645, acc-0.4848, test loss-1.9346, acc-0.5006\n",
      "Iter-59320, train loss-1.9149, acc-0.5000, valid loss-1.9645, acc-0.4848, test loss-1.9346, acc-0.5006\n",
      "Iter-59330, train loss-2.0167, acc-0.4000, valid loss-1.9645, acc-0.4850, test loss-1.9345, acc-0.5004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-59340, train loss-1.8921, acc-0.6000, valid loss-1.9644, acc-0.4852, test loss-1.9345, acc-0.5006\n",
      "Iter-59350, train loss-1.9708, acc-0.3800, valid loss-1.9644, acc-0.4852, test loss-1.9345, acc-0.5007\n",
      "Iter-59360, train loss-1.9422, acc-0.4800, valid loss-1.9643, acc-0.4850, test loss-1.9344, acc-0.5008\n",
      "Iter-59370, train loss-1.9271, acc-0.4800, valid loss-1.9643, acc-0.4850, test loss-1.9344, acc-0.5009\n",
      "Iter-59380, train loss-1.9261, acc-0.4400, valid loss-1.9643, acc-0.4850, test loss-1.9343, acc-0.5010\n",
      "Iter-59390, train loss-1.8922, acc-0.5200, valid loss-1.9642, acc-0.4848, test loss-1.9343, acc-0.5011\n",
      "Iter-59400, train loss-1.9287, acc-0.4800, valid loss-1.9642, acc-0.4852, test loss-1.9343, acc-0.5011\n",
      "Iter-59410, train loss-1.9091, acc-0.6000, valid loss-1.9642, acc-0.4854, test loss-1.9342, acc-0.5014\n",
      "Iter-59420, train loss-2.0656, acc-0.4000, valid loss-1.9641, acc-0.4852, test loss-1.9342, acc-0.5013\n",
      "Iter-59430, train loss-1.9851, acc-0.3400, valid loss-1.9641, acc-0.4852, test loss-1.9341, acc-0.5014\n",
      "Iter-59440, train loss-1.8832, acc-0.6000, valid loss-1.9640, acc-0.4854, test loss-1.9341, acc-0.5016\n",
      "Iter-59450, train loss-1.9428, acc-0.4000, valid loss-1.9640, acc-0.4854, test loss-1.9341, acc-0.5016\n",
      "Iter-59460, train loss-2.0079, acc-0.5000, valid loss-1.9640, acc-0.4852, test loss-1.9340, acc-0.5018\n",
      "Iter-59470, train loss-1.8892, acc-0.6200, valid loss-1.9639, acc-0.4856, test loss-1.9340, acc-0.5016\n",
      "Iter-59480, train loss-1.9118, acc-0.5000, valid loss-1.9639, acc-0.4854, test loss-1.9339, acc-0.5016\n",
      "Iter-59490, train loss-1.9759, acc-0.4200, valid loss-1.9639, acc-0.4856, test loss-1.9339, acc-0.5017\n",
      "Iter-59500, train loss-1.9041, acc-0.5400, valid loss-1.9638, acc-0.4858, test loss-1.9338, acc-0.5019\n",
      "Iter-59510, train loss-2.0454, acc-0.3800, valid loss-1.9638, acc-0.4856, test loss-1.9338, acc-0.5018\n",
      "Iter-59520, train loss-1.9955, acc-0.4400, valid loss-1.9637, acc-0.4862, test loss-1.9338, acc-0.5020\n",
      "Iter-59530, train loss-2.0327, acc-0.4200, valid loss-1.9637, acc-0.4862, test loss-1.9337, acc-0.5021\n",
      "Iter-59540, train loss-1.8751, acc-0.5400, valid loss-1.9637, acc-0.4860, test loss-1.9337, acc-0.5020\n",
      "Iter-59550, train loss-1.8941, acc-0.5600, valid loss-1.9636, acc-0.4860, test loss-1.9336, acc-0.5019\n",
      "Iter-59560, train loss-1.9296, acc-0.4600, valid loss-1.9636, acc-0.4858, test loss-1.9336, acc-0.5019\n",
      "Iter-59570, train loss-1.9444, acc-0.3600, valid loss-1.9636, acc-0.4856, test loss-1.9336, acc-0.5021\n",
      "Iter-59580, train loss-1.8881, acc-0.5800, valid loss-1.9635, acc-0.4856, test loss-1.9335, acc-0.5020\n",
      "Iter-59590, train loss-1.8980, acc-0.5200, valid loss-1.9635, acc-0.4856, test loss-1.9335, acc-0.5020\n",
      "Iter-59600, train loss-1.8695, acc-0.5400, valid loss-1.9634, acc-0.4856, test loss-1.9334, acc-0.5021\n",
      "Iter-59610, train loss-1.9480, acc-0.4400, valid loss-1.9634, acc-0.4856, test loss-1.9334, acc-0.5021\n",
      "Iter-59620, train loss-2.0003, acc-0.3800, valid loss-1.9634, acc-0.4858, test loss-1.9333, acc-0.5021\n",
      "Iter-59630, train loss-1.9674, acc-0.4800, valid loss-1.9633, acc-0.4856, test loss-1.9333, acc-0.5020\n",
      "Iter-59640, train loss-2.0097, acc-0.4200, valid loss-1.9633, acc-0.4856, test loss-1.9333, acc-0.5022\n",
      "Iter-59650, train loss-1.9031, acc-0.5800, valid loss-1.9633, acc-0.4856, test loss-1.9332, acc-0.5020\n",
      "Iter-59660, train loss-1.8888, acc-0.4600, valid loss-1.9632, acc-0.4858, test loss-1.9332, acc-0.5021\n",
      "Iter-59670, train loss-1.9696, acc-0.5200, valid loss-1.9632, acc-0.4860, test loss-1.9331, acc-0.5025\n",
      "Iter-59680, train loss-1.8718, acc-0.5600, valid loss-1.9631, acc-0.4858, test loss-1.9331, acc-0.5022\n",
      "Iter-59690, train loss-1.9748, acc-0.4600, valid loss-1.9631, acc-0.4860, test loss-1.9331, acc-0.5023\n",
      "Iter-59700, train loss-1.9631, acc-0.4800, valid loss-1.9631, acc-0.4860, test loss-1.9330, acc-0.5023\n",
      "Iter-59710, train loss-1.9497, acc-0.4000, valid loss-1.9630, acc-0.4862, test loss-1.9330, acc-0.5024\n",
      "Iter-59720, train loss-1.9563, acc-0.4800, valid loss-1.9630, acc-0.4860, test loss-1.9329, acc-0.5023\n",
      "Iter-59730, train loss-1.8952, acc-0.5000, valid loss-1.9630, acc-0.4860, test loss-1.9329, acc-0.5023\n",
      "Iter-59740, train loss-1.9111, acc-0.5000, valid loss-1.9629, acc-0.4862, test loss-1.9329, acc-0.5022\n",
      "Iter-59750, train loss-1.9143, acc-0.4600, valid loss-1.9629, acc-0.4862, test loss-1.9328, acc-0.5020\n",
      "Iter-59760, train loss-1.9606, acc-0.4800, valid loss-1.9628, acc-0.4866, test loss-1.9328, acc-0.5020\n",
      "Iter-59770, train loss-1.9668, acc-0.4400, valid loss-1.9628, acc-0.4864, test loss-1.9327, acc-0.5023\n",
      "Iter-59780, train loss-1.9391, acc-0.5200, valid loss-1.9628, acc-0.4864, test loss-1.9327, acc-0.5023\n",
      "Iter-59790, train loss-1.9554, acc-0.4800, valid loss-1.9627, acc-0.4864, test loss-1.9327, acc-0.5022\n",
      "Iter-59800, train loss-2.0201, acc-0.4000, valid loss-1.9627, acc-0.4862, test loss-1.9326, acc-0.5024\n",
      "Iter-59810, train loss-1.9228, acc-0.5600, valid loss-1.9627, acc-0.4862, test loss-1.9326, acc-0.5023\n",
      "Iter-59820, train loss-1.9874, acc-0.4200, valid loss-1.9626, acc-0.4862, test loss-1.9325, acc-0.5024\n",
      "Iter-59830, train loss-1.8773, acc-0.5600, valid loss-1.9626, acc-0.4862, test loss-1.9325, acc-0.5023\n",
      "Iter-59840, train loss-1.8914, acc-0.5600, valid loss-1.9625, acc-0.4862, test loss-1.9325, acc-0.5024\n",
      "Iter-59850, train loss-1.9841, acc-0.3800, valid loss-1.9625, acc-0.4862, test loss-1.9324, acc-0.5026\n",
      "Iter-59860, train loss-1.8869, acc-0.5000, valid loss-1.9625, acc-0.4864, test loss-1.9324, acc-0.5023\n",
      "Iter-59870, train loss-1.9586, acc-0.4000, valid loss-1.9624, acc-0.4864, test loss-1.9323, acc-0.5023\n",
      "Iter-59880, train loss-1.9602, acc-0.5400, valid loss-1.9624, acc-0.4864, test loss-1.9323, acc-0.5023\n",
      "Iter-59890, train loss-1.9487, acc-0.4400, valid loss-1.9624, acc-0.4864, test loss-1.9323, acc-0.5024\n",
      "Iter-59900, train loss-1.9433, acc-0.5000, valid loss-1.9623, acc-0.4868, test loss-1.9322, acc-0.5024\n",
      "Iter-59910, train loss-1.9151, acc-0.4800, valid loss-1.9623, acc-0.4866, test loss-1.9322, acc-0.5024\n",
      "Iter-59920, train loss-1.9169, acc-0.5200, valid loss-1.9622, acc-0.4864, test loss-1.9321, acc-0.5024\n",
      "Iter-59930, train loss-2.0398, acc-0.4200, valid loss-1.9622, acc-0.4862, test loss-1.9321, acc-0.5024\n",
      "Iter-59940, train loss-1.9849, acc-0.4600, valid loss-1.9622, acc-0.4864, test loss-1.9321, acc-0.5024\n",
      "Iter-59950, train loss-1.9635, acc-0.4600, valid loss-1.9621, acc-0.4864, test loss-1.9320, acc-0.5024\n",
      "Iter-59960, train loss-1.9128, acc-0.5600, valid loss-1.9621, acc-0.4864, test loss-1.9320, acc-0.5024\n",
      "Iter-59970, train loss-1.9246, acc-0.4600, valid loss-1.9621, acc-0.4864, test loss-1.9319, acc-0.5024\n",
      "Iter-59980, train loss-1.9880, acc-0.4200, valid loss-1.9620, acc-0.4864, test loss-1.9319, acc-0.5024\n",
      "Iter-59990, train loss-1.9383, acc-0.4400, valid loss-1.9620, acc-0.4864, test loss-1.9319, acc-0.5025\n",
      "Iter-60000, train loss-1.9021, acc-0.5400, valid loss-1.9619, acc-0.4864, test loss-1.9318, acc-0.5022\n",
      "Iter-60010, train loss-1.9429, acc-0.4600, valid loss-1.9619, acc-0.4866, test loss-1.9318, acc-0.5021\n",
      "Iter-60020, train loss-1.9595, acc-0.4200, valid loss-1.9619, acc-0.4862, test loss-1.9317, acc-0.5021\n",
      "Iter-60030, train loss-2.0668, acc-0.4000, valid loss-1.9618, acc-0.4866, test loss-1.9317, acc-0.5023\n",
      "Iter-60040, train loss-1.9758, acc-0.4800, valid loss-1.9618, acc-0.4866, test loss-1.9317, acc-0.5023\n",
      "Iter-60050, train loss-1.9755, acc-0.5600, valid loss-1.9618, acc-0.4868, test loss-1.9316, acc-0.5021\n",
      "Iter-60060, train loss-1.9191, acc-0.5200, valid loss-1.9617, acc-0.4866, test loss-1.9316, acc-0.5024\n",
      "Iter-60070, train loss-1.9419, acc-0.5800, valid loss-1.9617, acc-0.4868, test loss-1.9315, acc-0.5024\n",
      "Iter-60080, train loss-1.9486, acc-0.4800, valid loss-1.9617, acc-0.4864, test loss-1.9315, acc-0.5023\n",
      "Iter-60090, train loss-2.0045, acc-0.3800, valid loss-1.9616, acc-0.4864, test loss-1.9315, acc-0.5022\n",
      "Iter-60100, train loss-2.0042, acc-0.4400, valid loss-1.9616, acc-0.4864, test loss-1.9314, acc-0.5022\n",
      "Iter-60110, train loss-2.0363, acc-0.4000, valid loss-1.9616, acc-0.4868, test loss-1.9314, acc-0.5022\n",
      "Iter-60120, train loss-1.9966, acc-0.4600, valid loss-1.9615, acc-0.4868, test loss-1.9314, acc-0.5021\n",
      "Iter-60130, train loss-1.9816, acc-0.4000, valid loss-1.9615, acc-0.4866, test loss-1.9313, acc-0.5023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60140, train loss-1.9904, acc-0.4600, valid loss-1.9615, acc-0.4864, test loss-1.9313, acc-0.5023\n",
      "Iter-60150, train loss-1.9006, acc-0.5000, valid loss-1.9614, acc-0.4866, test loss-1.9312, acc-0.5022\n",
      "Iter-60160, train loss-1.9091, acc-0.5800, valid loss-1.9614, acc-0.4864, test loss-1.9312, acc-0.5022\n",
      "Iter-60170, train loss-1.9610, acc-0.5200, valid loss-1.9613, acc-0.4868, test loss-1.9312, acc-0.5024\n",
      "Iter-60180, train loss-1.9903, acc-0.4200, valid loss-1.9613, acc-0.4870, test loss-1.9311, acc-0.5023\n",
      "Iter-60190, train loss-1.9138, acc-0.5600, valid loss-1.9613, acc-0.4870, test loss-1.9311, acc-0.5025\n",
      "Iter-60200, train loss-1.9091, acc-0.5000, valid loss-1.9612, acc-0.4868, test loss-1.9310, acc-0.5024\n",
      "Iter-60210, train loss-1.9152, acc-0.5400, valid loss-1.9612, acc-0.4866, test loss-1.9310, acc-0.5024\n",
      "Iter-60220, train loss-1.9460, acc-0.4600, valid loss-1.9612, acc-0.4866, test loss-1.9310, acc-0.5024\n",
      "Iter-60230, train loss-1.9471, acc-0.5400, valid loss-1.9611, acc-0.4866, test loss-1.9309, acc-0.5024\n",
      "Iter-60240, train loss-1.9627, acc-0.4400, valid loss-1.9611, acc-0.4866, test loss-1.9309, acc-0.5026\n",
      "Iter-60250, train loss-1.9063, acc-0.5800, valid loss-1.9611, acc-0.4866, test loss-1.9308, acc-0.5025\n",
      "Iter-60260, train loss-1.9242, acc-0.6000, valid loss-1.9610, acc-0.4864, test loss-1.9308, acc-0.5024\n",
      "Iter-60270, train loss-1.9250, acc-0.4800, valid loss-1.9610, acc-0.4866, test loss-1.9307, acc-0.5026\n",
      "Iter-60280, train loss-1.9182, acc-0.4800, valid loss-1.9610, acc-0.4870, test loss-1.9307, acc-0.5025\n",
      "Iter-60290, train loss-1.9694, acc-0.5000, valid loss-1.9609, acc-0.4864, test loss-1.9307, acc-0.5026\n",
      "Iter-60300, train loss-1.9758, acc-0.3800, valid loss-1.9609, acc-0.4864, test loss-1.9306, acc-0.5027\n",
      "Iter-60310, train loss-1.9020, acc-0.5200, valid loss-1.9609, acc-0.4866, test loss-1.9306, acc-0.5028\n",
      "Iter-60320, train loss-1.9421, acc-0.5600, valid loss-1.9608, acc-0.4866, test loss-1.9306, acc-0.5027\n",
      "Iter-60330, train loss-1.9554, acc-0.5000, valid loss-1.9608, acc-0.4866, test loss-1.9305, acc-0.5028\n",
      "Iter-60340, train loss-1.9825, acc-0.5800, valid loss-1.9607, acc-0.4866, test loss-1.9305, acc-0.5030\n",
      "Iter-60350, train loss-1.9831, acc-0.3800, valid loss-1.9607, acc-0.4866, test loss-1.9304, acc-0.5029\n",
      "Iter-60360, train loss-1.9031, acc-0.4400, valid loss-1.9607, acc-0.4866, test loss-1.9304, acc-0.5030\n",
      "Iter-60370, train loss-1.9692, acc-0.4000, valid loss-1.9606, acc-0.4868, test loss-1.9303, acc-0.5029\n",
      "Iter-60380, train loss-1.9359, acc-0.5000, valid loss-1.9606, acc-0.4868, test loss-1.9303, acc-0.5030\n",
      "Iter-60390, train loss-1.9230, acc-0.5600, valid loss-1.9605, acc-0.4870, test loss-1.9303, acc-0.5026\n",
      "Iter-60400, train loss-1.9176, acc-0.5400, valid loss-1.9605, acc-0.4870, test loss-1.9302, acc-0.5030\n",
      "Iter-60410, train loss-1.9934, acc-0.4800, valid loss-1.9605, acc-0.4870, test loss-1.9302, acc-0.5028\n",
      "Iter-60420, train loss-1.9102, acc-0.4800, valid loss-1.9604, acc-0.4870, test loss-1.9301, acc-0.5027\n",
      "Iter-60430, train loss-1.9912, acc-0.5000, valid loss-1.9604, acc-0.4868, test loss-1.9301, acc-0.5026\n",
      "Iter-60440, train loss-2.0028, acc-0.4200, valid loss-1.9604, acc-0.4868, test loss-1.9301, acc-0.5027\n",
      "Iter-60450, train loss-1.9195, acc-0.5200, valid loss-1.9603, acc-0.4868, test loss-1.9300, acc-0.5028\n",
      "Iter-60460, train loss-1.9352, acc-0.4200, valid loss-1.9603, acc-0.4866, test loss-1.9300, acc-0.5026\n",
      "Iter-60470, train loss-1.8783, acc-0.6000, valid loss-1.9603, acc-0.4868, test loss-1.9300, acc-0.5023\n",
      "Iter-60480, train loss-1.9743, acc-0.3800, valid loss-1.9602, acc-0.4866, test loss-1.9299, acc-0.5023\n",
      "Iter-60490, train loss-1.9834, acc-0.3800, valid loss-1.9602, acc-0.4866, test loss-1.9299, acc-0.5024\n",
      "Iter-60500, train loss-1.9567, acc-0.5400, valid loss-1.9602, acc-0.4866, test loss-1.9298, acc-0.5025\n",
      "Iter-60510, train loss-1.8847, acc-0.6200, valid loss-1.9601, acc-0.4868, test loss-1.9298, acc-0.5024\n",
      "Iter-60520, train loss-1.8963, acc-0.5200, valid loss-1.9601, acc-0.4870, test loss-1.9298, acc-0.5023\n",
      "Iter-60530, train loss-1.9086, acc-0.5200, valid loss-1.9600, acc-0.4870, test loss-1.9297, acc-0.5027\n",
      "Iter-60540, train loss-1.9925, acc-0.4200, valid loss-1.9600, acc-0.4866, test loss-1.9297, acc-0.5023\n",
      "Iter-60550, train loss-2.0735, acc-0.2800, valid loss-1.9600, acc-0.4870, test loss-1.9296, acc-0.5026\n",
      "Iter-60560, train loss-1.9874, acc-0.4400, valid loss-1.9599, acc-0.4870, test loss-1.9296, acc-0.5026\n",
      "Iter-60570, train loss-1.9489, acc-0.5000, valid loss-1.9599, acc-0.4870, test loss-1.9296, acc-0.5026\n",
      "Iter-60580, train loss-1.9256, acc-0.5400, valid loss-1.9599, acc-0.4868, test loss-1.9295, acc-0.5025\n",
      "Iter-60590, train loss-1.9883, acc-0.4200, valid loss-1.9598, acc-0.4868, test loss-1.9295, acc-0.5027\n",
      "Iter-60600, train loss-1.8819, acc-0.5600, valid loss-1.9598, acc-0.4866, test loss-1.9294, acc-0.5025\n",
      "Iter-60610, train loss-2.0189, acc-0.4200, valid loss-1.9598, acc-0.4868, test loss-1.9294, acc-0.5026\n",
      "Iter-60620, train loss-1.8943, acc-0.5200, valid loss-1.9597, acc-0.4870, test loss-1.9294, acc-0.5025\n",
      "Iter-60630, train loss-1.9083, acc-0.5400, valid loss-1.9597, acc-0.4866, test loss-1.9293, acc-0.5027\n",
      "Iter-60640, train loss-1.8435, acc-0.5800, valid loss-1.9596, acc-0.4868, test loss-1.9293, acc-0.5024\n",
      "Iter-60650, train loss-1.9591, acc-0.4400, valid loss-1.9596, acc-0.4868, test loss-1.9292, acc-0.5026\n",
      "Iter-60660, train loss-1.9216, acc-0.4800, valid loss-1.9596, acc-0.4866, test loss-1.9292, acc-0.5027\n",
      "Iter-60670, train loss-1.9109, acc-0.4800, valid loss-1.9595, acc-0.4870, test loss-1.9292, acc-0.5028\n",
      "Iter-60680, train loss-1.9598, acc-0.4200, valid loss-1.9595, acc-0.4864, test loss-1.9291, acc-0.5028\n",
      "Iter-60690, train loss-1.9224, acc-0.4600, valid loss-1.9595, acc-0.4868, test loss-1.9291, acc-0.5028\n",
      "Iter-60700, train loss-1.9386, acc-0.4200, valid loss-1.9594, acc-0.4870, test loss-1.9290, acc-0.5032\n",
      "Iter-60710, train loss-2.0613, acc-0.3800, valid loss-1.9594, acc-0.4868, test loss-1.9290, acc-0.5030\n",
      "Iter-60720, train loss-1.9300, acc-0.5400, valid loss-1.9594, acc-0.4868, test loss-1.9290, acc-0.5029\n",
      "Iter-60730, train loss-1.9344, acc-0.5800, valid loss-1.9593, acc-0.4868, test loss-1.9289, acc-0.5032\n",
      "Iter-60740, train loss-1.9203, acc-0.5200, valid loss-1.9593, acc-0.4870, test loss-1.9289, acc-0.5031\n",
      "Iter-60750, train loss-1.9843, acc-0.4200, valid loss-1.9592, acc-0.4870, test loss-1.9288, acc-0.5029\n",
      "Iter-60760, train loss-1.9620, acc-0.4400, valid loss-1.9592, acc-0.4870, test loss-1.9288, acc-0.5028\n",
      "Iter-60770, train loss-1.9556, acc-0.5200, valid loss-1.9592, acc-0.4868, test loss-1.9288, acc-0.5025\n",
      "Iter-60780, train loss-1.9631, acc-0.4800, valid loss-1.9591, acc-0.4866, test loss-1.9287, acc-0.5025\n",
      "Iter-60790, train loss-2.0369, acc-0.3800, valid loss-1.9591, acc-0.4868, test loss-1.9287, acc-0.5023\n",
      "Iter-60800, train loss-1.9353, acc-0.4400, valid loss-1.9590, acc-0.4870, test loss-1.9286, acc-0.5021\n",
      "Iter-60810, train loss-1.9290, acc-0.5400, valid loss-1.9590, acc-0.4868, test loss-1.9286, acc-0.5022\n",
      "Iter-60820, train loss-2.0372, acc-0.4000, valid loss-1.9590, acc-0.4870, test loss-1.9286, acc-0.5026\n",
      "Iter-60830, train loss-1.9339, acc-0.4200, valid loss-1.9589, acc-0.4868, test loss-1.9285, acc-0.5026\n",
      "Iter-60840, train loss-2.0418, acc-0.3400, valid loss-1.9589, acc-0.4868, test loss-1.9285, acc-0.5025\n",
      "Iter-60850, train loss-1.9868, acc-0.4400, valid loss-1.9589, acc-0.4868, test loss-1.9284, acc-0.5026\n",
      "Iter-60860, train loss-1.8670, acc-0.6000, valid loss-1.9588, acc-0.4868, test loss-1.9284, acc-0.5025\n",
      "Iter-60870, train loss-1.9394, acc-0.4200, valid loss-1.9588, acc-0.4868, test loss-1.9284, acc-0.5026\n",
      "Iter-60880, train loss-1.9493, acc-0.4600, valid loss-1.9588, acc-0.4868, test loss-1.9283, acc-0.5029\n",
      "Iter-60890, train loss-1.9794, acc-0.4600, valid loss-1.9587, acc-0.4868, test loss-1.9283, acc-0.5029\n",
      "Iter-60900, train loss-1.9240, acc-0.5000, valid loss-1.9587, acc-0.4868, test loss-1.9283, acc-0.5028\n",
      "Iter-60910, train loss-1.9549, acc-0.4800, valid loss-1.9587, acc-0.4868, test loss-1.9282, acc-0.5029\n",
      "Iter-60920, train loss-1.9103, acc-0.6000, valid loss-1.9586, acc-0.4868, test loss-1.9282, acc-0.5027\n",
      "Iter-60930, train loss-1.9571, acc-0.4400, valid loss-1.9586, acc-0.4866, test loss-1.9281, acc-0.5027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60940, train loss-1.9417, acc-0.5200, valid loss-1.9585, acc-0.4864, test loss-1.9281, acc-0.5027\n",
      "Iter-60950, train loss-1.8840, acc-0.5600, valid loss-1.9585, acc-0.4862, test loss-1.9280, acc-0.5026\n",
      "Iter-60960, train loss-1.9326, acc-0.4200, valid loss-1.9585, acc-0.4862, test loss-1.9280, acc-0.5026\n",
      "Iter-60970, train loss-1.9516, acc-0.5400, valid loss-1.9584, acc-0.4866, test loss-1.9280, acc-0.5029\n",
      "Iter-60980, train loss-1.9426, acc-0.5400, valid loss-1.9584, acc-0.4868, test loss-1.9279, acc-0.5030\n",
      "Iter-60990, train loss-1.8906, acc-0.4800, valid loss-1.9584, acc-0.4868, test loss-1.9279, acc-0.5030\n",
      "Iter-61000, train loss-1.9601, acc-0.4200, valid loss-1.9583, acc-0.4870, test loss-1.9278, acc-0.5030\n",
      "Iter-61010, train loss-1.8943, acc-0.5800, valid loss-1.9583, acc-0.4864, test loss-1.9278, acc-0.5029\n",
      "Iter-61020, train loss-2.0055, acc-0.4200, valid loss-1.9583, acc-0.4862, test loss-1.9278, acc-0.5028\n",
      "Iter-61030, train loss-2.0095, acc-0.3600, valid loss-1.9582, acc-0.4864, test loss-1.9277, acc-0.5027\n",
      "Iter-61040, train loss-1.9929, acc-0.4600, valid loss-1.9582, acc-0.4862, test loss-1.9277, acc-0.5024\n",
      "Iter-61050, train loss-2.0372, acc-0.4200, valid loss-1.9582, acc-0.4862, test loss-1.9277, acc-0.5025\n",
      "Iter-61060, train loss-1.9607, acc-0.5000, valid loss-1.9581, acc-0.4862, test loss-1.9276, acc-0.5025\n",
      "Iter-61070, train loss-1.9832, acc-0.4600, valid loss-1.9581, acc-0.4864, test loss-1.9276, acc-0.5024\n",
      "Iter-61080, train loss-1.8923, acc-0.5400, valid loss-1.9581, acc-0.4864, test loss-1.9275, acc-0.5022\n",
      "Iter-61090, train loss-1.9688, acc-0.5000, valid loss-1.9580, acc-0.4862, test loss-1.9275, acc-0.5024\n",
      "Iter-61100, train loss-1.8837, acc-0.4600, valid loss-1.9580, acc-0.4862, test loss-1.9275, acc-0.5026\n",
      "Iter-61110, train loss-1.9520, acc-0.5200, valid loss-1.9579, acc-0.4858, test loss-1.9274, acc-0.5026\n",
      "Iter-61120, train loss-1.9904, acc-0.4400, valid loss-1.9579, acc-0.4858, test loss-1.9274, acc-0.5030\n",
      "Iter-61130, train loss-1.9918, acc-0.4400, valid loss-1.9579, acc-0.4858, test loss-1.9273, acc-0.5032\n",
      "Iter-61140, train loss-1.8721, acc-0.5800, valid loss-1.9578, acc-0.4858, test loss-1.9273, acc-0.5031\n",
      "Iter-61150, train loss-2.0806, acc-0.2800, valid loss-1.9578, acc-0.4856, test loss-1.9273, acc-0.5029\n",
      "Iter-61160, train loss-2.0126, acc-0.4200, valid loss-1.9578, acc-0.4856, test loss-1.9272, acc-0.5031\n",
      "Iter-61170, train loss-1.8998, acc-0.5200, valid loss-1.9577, acc-0.4852, test loss-1.9272, acc-0.5029\n",
      "Iter-61180, train loss-1.8642, acc-0.5400, valid loss-1.9577, acc-0.4856, test loss-1.9271, acc-0.5028\n",
      "Iter-61190, train loss-1.9375, acc-0.4400, valid loss-1.9577, acc-0.4854, test loss-1.9271, acc-0.5030\n",
      "Iter-61200, train loss-1.9212, acc-0.5600, valid loss-1.9576, acc-0.4854, test loss-1.9271, acc-0.5031\n",
      "Iter-61210, train loss-1.9128, acc-0.5400, valid loss-1.9576, acc-0.4854, test loss-1.9270, acc-0.5031\n",
      "Iter-61220, train loss-2.0181, acc-0.4600, valid loss-1.9575, acc-0.4852, test loss-1.9270, acc-0.5032\n",
      "Iter-61230, train loss-1.9805, acc-0.5600, valid loss-1.9575, acc-0.4854, test loss-1.9269, acc-0.5028\n",
      "Iter-61240, train loss-2.0152, acc-0.3600, valid loss-1.9575, acc-0.4856, test loss-1.9269, acc-0.5030\n",
      "Iter-61250, train loss-1.9641, acc-0.4800, valid loss-1.9574, acc-0.4856, test loss-1.9269, acc-0.5031\n",
      "Iter-61260, train loss-1.9613, acc-0.4600, valid loss-1.9574, acc-0.4856, test loss-1.9268, acc-0.5034\n",
      "Iter-61270, train loss-1.9180, acc-0.5000, valid loss-1.9574, acc-0.4856, test loss-1.9268, acc-0.5035\n",
      "Iter-61280, train loss-1.9576, acc-0.4800, valid loss-1.9573, acc-0.4856, test loss-1.9267, acc-0.5033\n",
      "Iter-61290, train loss-1.9591, acc-0.5400, valid loss-1.9573, acc-0.4856, test loss-1.9267, acc-0.5032\n",
      "Iter-61300, train loss-2.0091, acc-0.4400, valid loss-1.9573, acc-0.4858, test loss-1.9267, acc-0.5034\n",
      "Iter-61310, train loss-2.0511, acc-0.3400, valid loss-1.9572, acc-0.4858, test loss-1.9266, acc-0.5034\n",
      "Iter-61320, train loss-1.9712, acc-0.4600, valid loss-1.9572, acc-0.4858, test loss-1.9266, acc-0.5036\n",
      "Iter-61330, train loss-1.9394, acc-0.5000, valid loss-1.9572, acc-0.4862, test loss-1.9265, acc-0.5034\n",
      "Iter-61340, train loss-1.9067, acc-0.4600, valid loss-1.9571, acc-0.4860, test loss-1.9265, acc-0.5036\n",
      "Iter-61350, train loss-1.9888, acc-0.3800, valid loss-1.9571, acc-0.4862, test loss-1.9265, acc-0.5036\n",
      "Iter-61360, train loss-1.8964, acc-0.5200, valid loss-1.9571, acc-0.4860, test loss-1.9264, acc-0.5035\n",
      "Iter-61370, train loss-2.0213, acc-0.4200, valid loss-1.9570, acc-0.4860, test loss-1.9264, acc-0.5035\n",
      "Iter-61380, train loss-1.8205, acc-0.6400, valid loss-1.9570, acc-0.4860, test loss-1.9263, acc-0.5033\n",
      "Iter-61390, train loss-1.9341, acc-0.4400, valid loss-1.9569, acc-0.4864, test loss-1.9263, acc-0.5035\n",
      "Iter-61400, train loss-1.9417, acc-0.4800, valid loss-1.9569, acc-0.4862, test loss-1.9263, acc-0.5038\n",
      "Iter-61410, train loss-1.9174, acc-0.5200, valid loss-1.9569, acc-0.4862, test loss-1.9262, acc-0.5037\n",
      "Iter-61420, train loss-1.9597, acc-0.5200, valid loss-1.9568, acc-0.4860, test loss-1.9262, acc-0.5037\n",
      "Iter-61430, train loss-1.9482, acc-0.4800, valid loss-1.9568, acc-0.4862, test loss-1.9261, acc-0.5037\n",
      "Iter-61440, train loss-1.9693, acc-0.4400, valid loss-1.9568, acc-0.4862, test loss-1.9261, acc-0.5038\n",
      "Iter-61450, train loss-1.9565, acc-0.4800, valid loss-1.9567, acc-0.4860, test loss-1.9261, acc-0.5037\n",
      "Iter-61460, train loss-2.0292, acc-0.3600, valid loss-1.9567, acc-0.4862, test loss-1.9260, acc-0.5039\n",
      "Iter-61470, train loss-1.9115, acc-0.5600, valid loss-1.9566, acc-0.4860, test loss-1.9260, acc-0.5039\n",
      "Iter-61480, train loss-1.9792, acc-0.5200, valid loss-1.9566, acc-0.4862, test loss-1.9260, acc-0.5040\n",
      "Iter-61490, train loss-1.9528, acc-0.4600, valid loss-1.9566, acc-0.4860, test loss-1.9259, acc-0.5040\n",
      "Iter-61500, train loss-1.9789, acc-0.4400, valid loss-1.9565, acc-0.4860, test loss-1.9259, acc-0.5038\n",
      "Iter-61510, train loss-1.9452, acc-0.4200, valid loss-1.9565, acc-0.4862, test loss-1.9258, acc-0.5039\n",
      "Iter-61520, train loss-1.8826, acc-0.5400, valid loss-1.9565, acc-0.4864, test loss-1.9258, acc-0.5039\n",
      "Iter-61530, train loss-1.9432, acc-0.4400, valid loss-1.9564, acc-0.4862, test loss-1.9258, acc-0.5040\n",
      "Iter-61540, train loss-1.9166, acc-0.4600, valid loss-1.9564, acc-0.4862, test loss-1.9257, acc-0.5039\n",
      "Iter-61550, train loss-1.9559, acc-0.4400, valid loss-1.9564, acc-0.4860, test loss-1.9257, acc-0.5040\n",
      "Iter-61560, train loss-1.9594, acc-0.4200, valid loss-1.9563, acc-0.4860, test loss-1.9256, acc-0.5040\n",
      "Iter-61570, train loss-1.9117, acc-0.5200, valid loss-1.9563, acc-0.4856, test loss-1.9256, acc-0.5040\n",
      "Iter-61580, train loss-1.8483, acc-0.5600, valid loss-1.9563, acc-0.4858, test loss-1.9256, acc-0.5039\n",
      "Iter-61590, train loss-1.9848, acc-0.3800, valid loss-1.9562, acc-0.4860, test loss-1.9255, acc-0.5040\n",
      "Iter-61600, train loss-1.9590, acc-0.4800, valid loss-1.9562, acc-0.4862, test loss-1.9255, acc-0.5040\n",
      "Iter-61610, train loss-1.8601, acc-0.5800, valid loss-1.9562, acc-0.4862, test loss-1.9254, acc-0.5040\n",
      "Iter-61620, train loss-1.9007, acc-0.5400, valid loss-1.9561, acc-0.4860, test loss-1.9254, acc-0.5041\n",
      "Iter-61630, train loss-1.9371, acc-0.4400, valid loss-1.9561, acc-0.4856, test loss-1.9254, acc-0.5040\n",
      "Iter-61640, train loss-1.9471, acc-0.5200, valid loss-1.9560, acc-0.4858, test loss-1.9253, acc-0.5043\n",
      "Iter-61650, train loss-1.9914, acc-0.4400, valid loss-1.9560, acc-0.4856, test loss-1.9253, acc-0.5041\n",
      "Iter-61660, train loss-1.9423, acc-0.5200, valid loss-1.9560, acc-0.4856, test loss-1.9252, acc-0.5041\n",
      "Iter-61670, train loss-2.0237, acc-0.3800, valid loss-1.9559, acc-0.4856, test loss-1.9252, acc-0.5041\n",
      "Iter-61680, train loss-2.0470, acc-0.3400, valid loss-1.9559, acc-0.4854, test loss-1.9252, acc-0.5041\n",
      "Iter-61690, train loss-1.9887, acc-0.4600, valid loss-1.9559, acc-0.4856, test loss-1.9251, acc-0.5040\n",
      "Iter-61700, train loss-1.9273, acc-0.3800, valid loss-1.9558, acc-0.4862, test loss-1.9251, acc-0.5041\n",
      "Iter-61710, train loss-2.0091, acc-0.4000, valid loss-1.9558, acc-0.4862, test loss-1.9250, acc-0.5042\n",
      "Iter-61720, train loss-1.8624, acc-0.5800, valid loss-1.9558, acc-0.4864, test loss-1.9250, acc-0.5043\n",
      "Iter-61730, train loss-1.9535, acc-0.4800, valid loss-1.9557, acc-0.4864, test loss-1.9250, acc-0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-61740, train loss-1.9095, acc-0.5200, valid loss-1.9557, acc-0.4864, test loss-1.9249, acc-0.5042\n",
      "Iter-61750, train loss-1.9375, acc-0.5000, valid loss-1.9556, acc-0.4864, test loss-1.9249, acc-0.5042\n",
      "Iter-61760, train loss-1.9114, acc-0.5200, valid loss-1.9556, acc-0.4864, test loss-1.9249, acc-0.5042\n",
      "Iter-61770, train loss-1.8547, acc-0.5400, valid loss-1.9556, acc-0.4864, test loss-1.9248, acc-0.5041\n",
      "Iter-61780, train loss-1.8563, acc-0.5000, valid loss-1.9555, acc-0.4864, test loss-1.9248, acc-0.5041\n",
      "Iter-61790, train loss-1.9449, acc-0.4400, valid loss-1.9555, acc-0.4866, test loss-1.9247, acc-0.5041\n",
      "Iter-61800, train loss-1.9396, acc-0.4800, valid loss-1.9555, acc-0.4866, test loss-1.9247, acc-0.5041\n",
      "Iter-61810, train loss-2.0005, acc-0.5000, valid loss-1.9554, acc-0.4864, test loss-1.9247, acc-0.5040\n",
      "Iter-61820, train loss-1.9534, acc-0.4800, valid loss-1.9554, acc-0.4866, test loss-1.9246, acc-0.5040\n",
      "Iter-61830, train loss-1.9356, acc-0.5200, valid loss-1.9554, acc-0.4864, test loss-1.9246, acc-0.5041\n",
      "Iter-61840, train loss-1.9732, acc-0.4600, valid loss-1.9553, acc-0.4866, test loss-1.9245, acc-0.5039\n",
      "Iter-61850, train loss-1.9467, acc-0.5400, valid loss-1.9553, acc-0.4868, test loss-1.9245, acc-0.5038\n",
      "Iter-61860, train loss-1.8921, acc-0.5400, valid loss-1.9552, acc-0.4868, test loss-1.9245, acc-0.5041\n",
      "Iter-61870, train loss-1.9447, acc-0.4000, valid loss-1.9552, acc-0.4868, test loss-1.9244, acc-0.5043\n",
      "Iter-61880, train loss-1.9400, acc-0.4600, valid loss-1.9552, acc-0.4870, test loss-1.9244, acc-0.5042\n",
      "Iter-61890, train loss-1.9648, acc-0.5000, valid loss-1.9551, acc-0.4868, test loss-1.9243, acc-0.5041\n",
      "Iter-61900, train loss-1.9367, acc-0.5000, valid loss-1.9551, acc-0.4870, test loss-1.9243, acc-0.5043\n",
      "Iter-61910, train loss-1.9111, acc-0.5000, valid loss-1.9551, acc-0.4870, test loss-1.9243, acc-0.5042\n",
      "Iter-61920, train loss-1.9949, acc-0.4800, valid loss-1.9550, acc-0.4870, test loss-1.9242, acc-0.5043\n",
      "Iter-61930, train loss-2.0457, acc-0.4000, valid loss-1.9550, acc-0.4870, test loss-1.9242, acc-0.5043\n",
      "Iter-61940, train loss-1.9540, acc-0.5000, valid loss-1.9550, acc-0.4870, test loss-1.9241, acc-0.5044\n",
      "Iter-61950, train loss-1.9671, acc-0.4400, valid loss-1.9549, acc-0.4870, test loss-1.9241, acc-0.5043\n",
      "Iter-61960, train loss-1.9555, acc-0.4200, valid loss-1.9549, acc-0.4872, test loss-1.9241, acc-0.5044\n",
      "Iter-61970, train loss-1.8969, acc-0.5600, valid loss-1.9549, acc-0.4870, test loss-1.9240, acc-0.5044\n",
      "Iter-61980, train loss-1.9076, acc-0.5200, valid loss-1.9548, acc-0.4868, test loss-1.9240, acc-0.5043\n",
      "Iter-61990, train loss-1.9516, acc-0.5200, valid loss-1.9548, acc-0.4864, test loss-1.9240, acc-0.5044\n",
      "Iter-62000, train loss-1.9380, acc-0.4200, valid loss-1.9547, acc-0.4864, test loss-1.9239, acc-0.5044\n",
      "Iter-62010, train loss-1.8999, acc-0.5400, valid loss-1.9547, acc-0.4866, test loss-1.9239, acc-0.5043\n",
      "Iter-62020, train loss-1.9653, acc-0.3800, valid loss-1.9547, acc-0.4866, test loss-1.9238, acc-0.5043\n",
      "Iter-62030, train loss-2.0297, acc-0.4000, valid loss-1.9546, acc-0.4866, test loss-1.9238, acc-0.5043\n",
      "Iter-62040, train loss-1.9431, acc-0.4600, valid loss-1.9546, acc-0.4866, test loss-1.9238, acc-0.5043\n",
      "Iter-62050, train loss-1.9083, acc-0.5400, valid loss-1.9546, acc-0.4866, test loss-1.9237, acc-0.5043\n",
      "Iter-62060, train loss-1.9934, acc-0.4800, valid loss-1.9545, acc-0.4866, test loss-1.9237, acc-0.5041\n",
      "Iter-62070, train loss-1.9422, acc-0.4400, valid loss-1.9545, acc-0.4868, test loss-1.9236, acc-0.5040\n",
      "Iter-62080, train loss-1.9191, acc-0.5400, valid loss-1.9544, acc-0.4870, test loss-1.9236, acc-0.5043\n",
      "Iter-62090, train loss-1.9495, acc-0.4600, valid loss-1.9544, acc-0.4868, test loss-1.9236, acc-0.5042\n",
      "Iter-62100, train loss-1.9587, acc-0.4400, valid loss-1.9544, acc-0.4870, test loss-1.9235, acc-0.5043\n",
      "Iter-62110, train loss-1.8941, acc-0.5800, valid loss-1.9543, acc-0.4872, test loss-1.9235, acc-0.5042\n",
      "Iter-62120, train loss-1.8284, acc-0.5800, valid loss-1.9543, acc-0.4872, test loss-1.9234, acc-0.5041\n",
      "Iter-62130, train loss-1.9576, acc-0.5000, valid loss-1.9543, acc-0.4868, test loss-1.9234, acc-0.5041\n",
      "Iter-62140, train loss-1.9097, acc-0.5000, valid loss-1.9542, acc-0.4870, test loss-1.9234, acc-0.5043\n",
      "Iter-62150, train loss-1.9459, acc-0.4400, valid loss-1.9542, acc-0.4868, test loss-1.9233, acc-0.5042\n",
      "Iter-62160, train loss-1.9797, acc-0.4600, valid loss-1.9542, acc-0.4868, test loss-1.9233, acc-0.5043\n",
      "Iter-62170, train loss-1.9499, acc-0.4600, valid loss-1.9541, acc-0.4868, test loss-1.9232, acc-0.5040\n",
      "Iter-62180, train loss-1.9998, acc-0.5400, valid loss-1.9541, acc-0.4872, test loss-1.9232, acc-0.5040\n",
      "Iter-62190, train loss-1.9746, acc-0.4400, valid loss-1.9541, acc-0.4870, test loss-1.9232, acc-0.5038\n",
      "Iter-62200, train loss-1.9724, acc-0.5200, valid loss-1.9540, acc-0.4868, test loss-1.9231, acc-0.5041\n",
      "Iter-62210, train loss-1.9368, acc-0.5400, valid loss-1.9540, acc-0.4870, test loss-1.9231, acc-0.5039\n",
      "Iter-62220, train loss-1.8782, acc-0.6000, valid loss-1.9540, acc-0.4870, test loss-1.9231, acc-0.5038\n",
      "Iter-62230, train loss-1.9415, acc-0.4200, valid loss-1.9539, acc-0.4870, test loss-1.9230, acc-0.5039\n",
      "Iter-62240, train loss-2.0125, acc-0.3200, valid loss-1.9539, acc-0.4870, test loss-1.9230, acc-0.5038\n",
      "Iter-62250, train loss-1.9110, acc-0.5400, valid loss-1.9538, acc-0.4870, test loss-1.9229, acc-0.5039\n",
      "Iter-62260, train loss-1.8856, acc-0.5800, valid loss-1.9538, acc-0.4872, test loss-1.9229, acc-0.5040\n",
      "Iter-62270, train loss-2.0307, acc-0.4200, valid loss-1.9538, acc-0.4872, test loss-1.9229, acc-0.5040\n",
      "Iter-62280, train loss-1.9382, acc-0.5600, valid loss-1.9537, acc-0.4874, test loss-1.9228, acc-0.5039\n",
      "Iter-62290, train loss-1.9195, acc-0.5200, valid loss-1.9537, acc-0.4872, test loss-1.9228, acc-0.5038\n",
      "Iter-62300, train loss-2.0029, acc-0.4400, valid loss-1.9537, acc-0.4868, test loss-1.9227, acc-0.5041\n",
      "Iter-62310, train loss-1.9669, acc-0.3600, valid loss-1.9536, acc-0.4872, test loss-1.9227, acc-0.5041\n",
      "Iter-62320, train loss-1.8921, acc-0.5400, valid loss-1.9536, acc-0.4874, test loss-1.9227, acc-0.5039\n",
      "Iter-62330, train loss-1.9152, acc-0.6200, valid loss-1.9536, acc-0.4872, test loss-1.9226, acc-0.5039\n",
      "Iter-62340, train loss-1.9612, acc-0.4000, valid loss-1.9535, acc-0.4872, test loss-1.9226, acc-0.5040\n",
      "Iter-62350, train loss-1.8962, acc-0.5400, valid loss-1.9535, acc-0.4870, test loss-1.9225, acc-0.5041\n",
      "Iter-62360, train loss-1.9707, acc-0.5000, valid loss-1.9534, acc-0.4874, test loss-1.9225, acc-0.5041\n",
      "Iter-62370, train loss-1.9278, acc-0.4400, valid loss-1.9534, acc-0.4874, test loss-1.9225, acc-0.5042\n",
      "Iter-62380, train loss-1.9323, acc-0.4000, valid loss-1.9534, acc-0.4874, test loss-1.9224, acc-0.5042\n",
      "Iter-62390, train loss-1.9680, acc-0.4000, valid loss-1.9533, acc-0.4874, test loss-1.9224, acc-0.5041\n",
      "Iter-62400, train loss-1.9395, acc-0.5200, valid loss-1.9533, acc-0.4870, test loss-1.9224, acc-0.5041\n",
      "Iter-62410, train loss-1.9033, acc-0.5400, valid loss-1.9533, acc-0.4876, test loss-1.9223, acc-0.5040\n",
      "Iter-62420, train loss-1.9979, acc-0.5200, valid loss-1.9532, acc-0.4876, test loss-1.9223, acc-0.5040\n",
      "Iter-62430, train loss-1.8906, acc-0.5400, valid loss-1.9532, acc-0.4874, test loss-1.9222, acc-0.5040\n",
      "Iter-62440, train loss-1.9622, acc-0.4800, valid loss-1.9532, acc-0.4868, test loss-1.9222, acc-0.5041\n",
      "Iter-62450, train loss-2.0448, acc-0.3600, valid loss-1.9531, acc-0.4872, test loss-1.9222, acc-0.5040\n",
      "Iter-62460, train loss-1.8992, acc-0.6200, valid loss-1.9531, acc-0.4874, test loss-1.9221, acc-0.5040\n",
      "Iter-62470, train loss-1.8291, acc-0.6400, valid loss-1.9531, acc-0.4870, test loss-1.9221, acc-0.5041\n",
      "Iter-62480, train loss-1.9341, acc-0.4800, valid loss-1.9530, acc-0.4870, test loss-1.9220, acc-0.5041\n",
      "Iter-62490, train loss-1.9973, acc-0.4800, valid loss-1.9530, acc-0.4870, test loss-1.9220, acc-0.5042\n",
      "Iter-62500, train loss-1.9728, acc-0.4600, valid loss-1.9530, acc-0.4868, test loss-1.9220, acc-0.5040\n",
      "Iter-62510, train loss-1.9946, acc-0.4600, valid loss-1.9529, acc-0.4870, test loss-1.9219, acc-0.5041\n",
      "Iter-62520, train loss-1.9487, acc-0.5000, valid loss-1.9529, acc-0.4870, test loss-1.9219, acc-0.5043\n",
      "Iter-62530, train loss-1.9406, acc-0.4200, valid loss-1.9529, acc-0.4872, test loss-1.9219, acc-0.5043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-62540, train loss-2.0093, acc-0.4600, valid loss-1.9528, acc-0.4872, test loss-1.9218, acc-0.5044\n",
      "Iter-62550, train loss-1.9559, acc-0.4400, valid loss-1.9528, acc-0.4874, test loss-1.9218, acc-0.5045\n",
      "Iter-62560, train loss-2.0614, acc-0.3000, valid loss-1.9528, acc-0.4874, test loss-1.9217, acc-0.5046\n",
      "Iter-62570, train loss-1.9843, acc-0.3600, valid loss-1.9527, acc-0.4874, test loss-1.9217, acc-0.5043\n",
      "Iter-62580, train loss-1.9095, acc-0.4000, valid loss-1.9527, acc-0.4876, test loss-1.9217, acc-0.5043\n",
      "Iter-62590, train loss-1.9664, acc-0.3600, valid loss-1.9527, acc-0.4874, test loss-1.9216, acc-0.5044\n",
      "Iter-62600, train loss-1.9512, acc-0.4600, valid loss-1.9526, acc-0.4872, test loss-1.9216, acc-0.5044\n",
      "Iter-62610, train loss-1.9042, acc-0.4800, valid loss-1.9526, acc-0.4872, test loss-1.9215, acc-0.5044\n",
      "Iter-62620, train loss-1.9710, acc-0.4600, valid loss-1.9526, acc-0.4874, test loss-1.9215, acc-0.5047\n",
      "Iter-62630, train loss-1.9671, acc-0.4200, valid loss-1.9525, acc-0.4872, test loss-1.9215, acc-0.5045\n",
      "Iter-62640, train loss-1.9843, acc-0.4200, valid loss-1.9525, acc-0.4876, test loss-1.9214, acc-0.5046\n",
      "Iter-62650, train loss-1.8619, acc-0.5200, valid loss-1.9524, acc-0.4874, test loss-1.9214, acc-0.5045\n",
      "Iter-62660, train loss-1.9598, acc-0.4800, valid loss-1.9524, acc-0.4874, test loss-1.9213, acc-0.5044\n",
      "Iter-62670, train loss-1.8874, acc-0.5600, valid loss-1.9524, acc-0.4876, test loss-1.9213, acc-0.5045\n",
      "Iter-62680, train loss-2.0311, acc-0.4200, valid loss-1.9523, acc-0.4876, test loss-1.9213, acc-0.5045\n",
      "Iter-62690, train loss-1.9166, acc-0.5000, valid loss-1.9523, acc-0.4874, test loss-1.9212, acc-0.5045\n",
      "Iter-62700, train loss-1.9265, acc-0.4800, valid loss-1.9523, acc-0.4874, test loss-1.9212, acc-0.5044\n",
      "Iter-62710, train loss-1.9382, acc-0.4200, valid loss-1.9522, acc-0.4874, test loss-1.9212, acc-0.5044\n",
      "Iter-62720, train loss-1.8589, acc-0.6400, valid loss-1.9522, acc-0.4874, test loss-1.9211, acc-0.5043\n",
      "Iter-62730, train loss-1.9663, acc-0.4600, valid loss-1.9522, acc-0.4872, test loss-1.9211, acc-0.5044\n",
      "Iter-62740, train loss-1.8358, acc-0.5800, valid loss-1.9521, acc-0.4872, test loss-1.9210, acc-0.5044\n",
      "Iter-62750, train loss-1.9244, acc-0.5200, valid loss-1.9521, acc-0.4872, test loss-1.9210, acc-0.5044\n",
      "Iter-62760, train loss-1.9524, acc-0.4400, valid loss-1.9521, acc-0.4872, test loss-1.9210, acc-0.5045\n",
      "Iter-62770, train loss-1.9974, acc-0.4800, valid loss-1.9520, acc-0.4872, test loss-1.9209, acc-0.5043\n",
      "Iter-62780, train loss-1.8855, acc-0.4600, valid loss-1.9520, acc-0.4872, test loss-1.9209, acc-0.5042\n",
      "Iter-62790, train loss-1.9410, acc-0.5000, valid loss-1.9519, acc-0.4872, test loss-1.9208, acc-0.5041\n",
      "Iter-62800, train loss-1.8462, acc-0.6200, valid loss-1.9519, acc-0.4872, test loss-1.9208, acc-0.5040\n",
      "Iter-62810, train loss-1.9419, acc-0.4200, valid loss-1.9519, acc-0.4874, test loss-1.9208, acc-0.5040\n",
      "Iter-62820, train loss-1.9808, acc-0.4800, valid loss-1.9518, acc-0.4874, test loss-1.9207, acc-0.5043\n",
      "Iter-62830, train loss-1.8673, acc-0.5400, valid loss-1.9518, acc-0.4874, test loss-1.9207, acc-0.5045\n",
      "Iter-62840, train loss-1.9178, acc-0.4600, valid loss-1.9518, acc-0.4874, test loss-1.9206, acc-0.5042\n",
      "Iter-62850, train loss-1.9511, acc-0.5600, valid loss-1.9517, acc-0.4874, test loss-1.9206, acc-0.5040\n",
      "Iter-62860, train loss-1.8875, acc-0.5800, valid loss-1.9517, acc-0.4876, test loss-1.9206, acc-0.5039\n",
      "Iter-62870, train loss-1.9252, acc-0.4200, valid loss-1.9517, acc-0.4876, test loss-1.9205, acc-0.5040\n",
      "Iter-62880, train loss-1.9425, acc-0.4400, valid loss-1.9516, acc-0.4876, test loss-1.9205, acc-0.5040\n",
      "Iter-62890, train loss-1.9185, acc-0.5400, valid loss-1.9516, acc-0.4876, test loss-1.9204, acc-0.5039\n",
      "Iter-62900, train loss-1.8626, acc-0.6000, valid loss-1.9515, acc-0.4872, test loss-1.9204, acc-0.5038\n",
      "Iter-62910, train loss-1.9565, acc-0.4600, valid loss-1.9515, acc-0.4868, test loss-1.9204, acc-0.5038\n",
      "Iter-62920, train loss-1.9961, acc-0.4000, valid loss-1.9515, acc-0.4868, test loss-1.9203, acc-0.5038\n",
      "Iter-62930, train loss-1.8864, acc-0.5600, valid loss-1.9514, acc-0.4872, test loss-1.9203, acc-0.5038\n",
      "Iter-62940, train loss-1.8928, acc-0.5600, valid loss-1.9514, acc-0.4872, test loss-1.9202, acc-0.5038\n",
      "Iter-62950, train loss-1.9390, acc-0.4800, valid loss-1.9514, acc-0.4868, test loss-1.9202, acc-0.5039\n",
      "Iter-62960, train loss-1.9204, acc-0.4800, valid loss-1.9513, acc-0.4872, test loss-1.9202, acc-0.5041\n",
      "Iter-62970, train loss-2.0181, acc-0.4400, valid loss-1.9513, acc-0.4872, test loss-1.9201, acc-0.5042\n",
      "Iter-62980, train loss-1.9041, acc-0.5400, valid loss-1.9513, acc-0.4874, test loss-1.9201, acc-0.5043\n",
      "Iter-62990, train loss-1.9710, acc-0.4800, valid loss-1.9512, acc-0.4874, test loss-1.9200, acc-0.5042\n",
      "Iter-63000, train loss-1.9723, acc-0.4200, valid loss-1.9512, acc-0.4872, test loss-1.9200, acc-0.5042\n",
      "Iter-63010, train loss-1.9285, acc-0.4400, valid loss-1.9512, acc-0.4876, test loss-1.9200, acc-0.5044\n",
      "Iter-63020, train loss-1.8743, acc-0.4600, valid loss-1.9511, acc-0.4876, test loss-1.9199, acc-0.5042\n",
      "Iter-63030, train loss-1.9352, acc-0.5200, valid loss-1.9511, acc-0.4878, test loss-1.9199, acc-0.5042\n",
      "Iter-63040, train loss-1.9633, acc-0.3800, valid loss-1.9510, acc-0.4878, test loss-1.9199, acc-0.5042\n",
      "Iter-63050, train loss-1.9723, acc-0.5800, valid loss-1.9510, acc-0.4874, test loss-1.9198, acc-0.5040\n",
      "Iter-63060, train loss-1.9626, acc-0.4000, valid loss-1.9510, acc-0.4874, test loss-1.9198, acc-0.5040\n",
      "Iter-63070, train loss-1.8996, acc-0.4800, valid loss-1.9510, acc-0.4874, test loss-1.9197, acc-0.5043\n",
      "Iter-63080, train loss-1.9795, acc-0.3800, valid loss-1.9509, acc-0.4874, test loss-1.9197, acc-0.5045\n",
      "Iter-63090, train loss-1.8915, acc-0.4800, valid loss-1.9509, acc-0.4876, test loss-1.9197, acc-0.5044\n",
      "Iter-63100, train loss-1.9356, acc-0.5000, valid loss-1.9509, acc-0.4878, test loss-1.9196, acc-0.5045\n",
      "Iter-63110, train loss-1.8653, acc-0.5200, valid loss-1.9508, acc-0.4876, test loss-1.9196, acc-0.5043\n",
      "Iter-63120, train loss-1.9599, acc-0.5200, valid loss-1.9508, acc-0.4878, test loss-1.9195, acc-0.5044\n",
      "Iter-63130, train loss-1.9705, acc-0.5200, valid loss-1.9508, acc-0.4878, test loss-1.9195, acc-0.5045\n",
      "Iter-63140, train loss-1.9849, acc-0.4800, valid loss-1.9507, acc-0.4880, test loss-1.9195, acc-0.5046\n",
      "Iter-63150, train loss-1.9401, acc-0.3600, valid loss-1.9507, acc-0.4882, test loss-1.9194, acc-0.5048\n",
      "Iter-63160, train loss-1.9569, acc-0.4800, valid loss-1.9506, acc-0.4876, test loss-1.9194, acc-0.5046\n",
      "Iter-63170, train loss-1.8995, acc-0.4200, valid loss-1.9506, acc-0.4876, test loss-1.9194, acc-0.5045\n",
      "Iter-63180, train loss-1.9647, acc-0.4200, valid loss-1.9506, acc-0.4876, test loss-1.9193, acc-0.5050\n",
      "Iter-63190, train loss-1.9754, acc-0.4400, valid loss-1.9505, acc-0.4874, test loss-1.9193, acc-0.5047\n",
      "Iter-63200, train loss-1.9540, acc-0.5200, valid loss-1.9505, acc-0.4874, test loss-1.9192, acc-0.5048\n",
      "Iter-63210, train loss-1.8980, acc-0.5200, valid loss-1.9505, acc-0.4874, test loss-1.9192, acc-0.5047\n",
      "Iter-63220, train loss-1.9698, acc-0.4800, valid loss-1.9504, acc-0.4874, test loss-1.9192, acc-0.5046\n",
      "Iter-63230, train loss-1.9315, acc-0.4800, valid loss-1.9504, acc-0.4872, test loss-1.9191, acc-0.5047\n",
      "Iter-63240, train loss-1.8825, acc-0.5600, valid loss-1.9504, acc-0.4870, test loss-1.9191, acc-0.5049\n",
      "Iter-63250, train loss-2.0059, acc-0.4000, valid loss-1.9503, acc-0.4870, test loss-1.9191, acc-0.5049\n",
      "Iter-63260, train loss-1.8917, acc-0.5400, valid loss-1.9503, acc-0.4870, test loss-1.9190, acc-0.5050\n",
      "Iter-63270, train loss-1.8756, acc-0.5800, valid loss-1.9503, acc-0.4868, test loss-1.9190, acc-0.5046\n",
      "Iter-63280, train loss-1.9062, acc-0.4600, valid loss-1.9502, acc-0.4868, test loss-1.9189, acc-0.5045\n",
      "Iter-63290, train loss-1.9485, acc-0.5200, valid loss-1.9502, acc-0.4870, test loss-1.9189, acc-0.5044\n",
      "Iter-63300, train loss-1.8957, acc-0.5800, valid loss-1.9502, acc-0.4872, test loss-1.9189, acc-0.5044\n",
      "Iter-63310, train loss-1.9023, acc-0.6000, valid loss-1.9501, acc-0.4868, test loss-1.9188, acc-0.5045\n",
      "Iter-63320, train loss-1.9936, acc-0.4600, valid loss-1.9501, acc-0.4872, test loss-1.9188, acc-0.5045\n",
      "Iter-63330, train loss-1.8822, acc-0.6400, valid loss-1.9501, acc-0.4872, test loss-1.9187, acc-0.5044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-63340, train loss-1.8403, acc-0.6200, valid loss-1.9500, acc-0.4872, test loss-1.9187, acc-0.5046\n",
      "Iter-63350, train loss-1.9931, acc-0.3400, valid loss-1.9500, acc-0.4870, test loss-1.9187, acc-0.5044\n",
      "Iter-63360, train loss-2.0001, acc-0.4000, valid loss-1.9499, acc-0.4868, test loss-1.9186, acc-0.5044\n",
      "Iter-63370, train loss-2.0427, acc-0.3000, valid loss-1.9499, acc-0.4868, test loss-1.9186, acc-0.5044\n",
      "Iter-63380, train loss-1.8544, acc-0.5600, valid loss-1.9499, acc-0.4874, test loss-1.9185, acc-0.5044\n",
      "Iter-63390, train loss-1.8785, acc-0.6000, valid loss-1.9498, acc-0.4874, test loss-1.9185, acc-0.5046\n",
      "Iter-63400, train loss-1.9227, acc-0.4200, valid loss-1.9498, acc-0.4874, test loss-1.9185, acc-0.5045\n",
      "Iter-63410, train loss-1.9024, acc-0.5000, valid loss-1.9498, acc-0.4878, test loss-1.9184, acc-0.5045\n",
      "Iter-63420, train loss-1.9881, acc-0.4400, valid loss-1.9497, acc-0.4876, test loss-1.9184, acc-0.5045\n",
      "Iter-63430, train loss-2.0483, acc-0.4000, valid loss-1.9497, acc-0.4876, test loss-1.9183, acc-0.5045\n",
      "Iter-63440, train loss-1.9123, acc-0.6000, valid loss-1.9497, acc-0.4878, test loss-1.9183, acc-0.5045\n",
      "Iter-63450, train loss-1.8807, acc-0.5800, valid loss-1.9496, acc-0.4880, test loss-1.9183, acc-0.5046\n",
      "Iter-63460, train loss-2.0125, acc-0.4600, valid loss-1.9496, acc-0.4882, test loss-1.9182, acc-0.5046\n",
      "Iter-63470, train loss-1.8696, acc-0.5200, valid loss-1.9495, acc-0.4880, test loss-1.9182, acc-0.5045\n",
      "Iter-63480, train loss-1.9588, acc-0.4200, valid loss-1.9495, acc-0.4880, test loss-1.9181, acc-0.5046\n",
      "Iter-63490, train loss-1.9051, acc-0.5800, valid loss-1.9495, acc-0.4882, test loss-1.9181, acc-0.5045\n",
      "Iter-63500, train loss-1.8766, acc-0.6400, valid loss-1.9494, acc-0.4882, test loss-1.9181, acc-0.5046\n",
      "Iter-63510, train loss-1.9018, acc-0.4800, valid loss-1.9494, acc-0.4884, test loss-1.9180, acc-0.5046\n",
      "Iter-63520, train loss-1.9435, acc-0.4400, valid loss-1.9494, acc-0.4880, test loss-1.9180, acc-0.5046\n",
      "Iter-63530, train loss-1.9046, acc-0.4600, valid loss-1.9493, acc-0.4878, test loss-1.9179, acc-0.5045\n",
      "Iter-63540, train loss-1.9678, acc-0.4600, valid loss-1.9493, acc-0.4880, test loss-1.9179, acc-0.5047\n",
      "Iter-63550, train loss-2.0354, acc-0.3600, valid loss-1.9492, acc-0.4882, test loss-1.9179, acc-0.5047\n",
      "Iter-63560, train loss-1.9059, acc-0.5600, valid loss-1.9492, acc-0.4884, test loss-1.9178, acc-0.5045\n",
      "Iter-63570, train loss-1.9060, acc-0.6200, valid loss-1.9492, acc-0.4882, test loss-1.9178, acc-0.5046\n",
      "Iter-63580, train loss-1.9694, acc-0.4000, valid loss-1.9491, acc-0.4882, test loss-1.9178, acc-0.5048\n",
      "Iter-63590, train loss-1.9532, acc-0.4400, valid loss-1.9491, acc-0.4884, test loss-1.9177, acc-0.5049\n",
      "Iter-63600, train loss-1.8992, acc-0.5400, valid loss-1.9491, acc-0.4882, test loss-1.9177, acc-0.5048\n",
      "Iter-63610, train loss-1.8515, acc-0.5800, valid loss-1.9490, acc-0.4882, test loss-1.9176, acc-0.5048\n",
      "Iter-63620, train loss-1.8483, acc-0.5000, valid loss-1.9490, acc-0.4884, test loss-1.9176, acc-0.5048\n",
      "Iter-63630, train loss-1.9002, acc-0.5800, valid loss-1.9490, acc-0.4884, test loss-1.9176, acc-0.5047\n",
      "Iter-63640, train loss-2.0046, acc-0.4200, valid loss-1.9489, acc-0.4886, test loss-1.9175, acc-0.5047\n",
      "Iter-63650, train loss-1.9081, acc-0.4600, valid loss-1.9489, acc-0.4886, test loss-1.9175, acc-0.5049\n",
      "Iter-63660, train loss-1.8917, acc-0.4800, valid loss-1.9489, acc-0.4886, test loss-1.9174, acc-0.5048\n",
      "Iter-63670, train loss-1.9505, acc-0.4600, valid loss-1.9488, acc-0.4888, test loss-1.9174, acc-0.5048\n",
      "Iter-63680, train loss-1.8769, acc-0.4800, valid loss-1.9488, acc-0.4886, test loss-1.9174, acc-0.5048\n",
      "Iter-63690, train loss-1.8763, acc-0.5200, valid loss-1.9487, acc-0.4888, test loss-1.9173, acc-0.5048\n",
      "Iter-63700, train loss-1.9547, acc-0.5000, valid loss-1.9487, acc-0.4888, test loss-1.9173, acc-0.5048\n",
      "Iter-63710, train loss-2.0357, acc-0.4200, valid loss-1.9487, acc-0.4888, test loss-1.9172, acc-0.5048\n",
      "Iter-63720, train loss-1.9551, acc-0.4400, valid loss-1.9486, acc-0.4888, test loss-1.9172, acc-0.5048\n",
      "Iter-63730, train loss-1.8405, acc-0.4800, valid loss-1.9486, acc-0.4888, test loss-1.9172, acc-0.5048\n",
      "Iter-63740, train loss-1.9799, acc-0.3800, valid loss-1.9486, acc-0.4886, test loss-1.9171, acc-0.5048\n",
      "Iter-63750, train loss-1.9446, acc-0.5000, valid loss-1.9485, acc-0.4884, test loss-1.9171, acc-0.5046\n",
      "Iter-63760, train loss-1.8274, acc-0.6800, valid loss-1.9485, acc-0.4886, test loss-1.9170, acc-0.5046\n",
      "Iter-63770, train loss-1.9233, acc-0.5800, valid loss-1.9485, acc-0.4884, test loss-1.9170, acc-0.5047\n",
      "Iter-63780, train loss-1.9574, acc-0.5200, valid loss-1.9484, acc-0.4884, test loss-1.9170, acc-0.5047\n",
      "Iter-63790, train loss-1.9483, acc-0.5000, valid loss-1.9484, acc-0.4886, test loss-1.9169, acc-0.5048\n",
      "Iter-63800, train loss-1.9984, acc-0.4600, valid loss-1.9484, acc-0.4884, test loss-1.9169, acc-0.5048\n",
      "Iter-63810, train loss-1.9891, acc-0.4400, valid loss-1.9483, acc-0.4880, test loss-1.9168, acc-0.5049\n",
      "Iter-63820, train loss-1.9335, acc-0.4200, valid loss-1.9483, acc-0.4880, test loss-1.9168, acc-0.5050\n",
      "Iter-63830, train loss-1.9322, acc-0.5200, valid loss-1.9483, acc-0.4880, test loss-1.9168, acc-0.5050\n",
      "Iter-63840, train loss-1.8980, acc-0.5600, valid loss-1.9483, acc-0.4882, test loss-1.9167, acc-0.5053\n",
      "Iter-63850, train loss-1.8885, acc-0.5400, valid loss-1.9482, acc-0.4882, test loss-1.9167, acc-0.5051\n",
      "Iter-63860, train loss-1.9484, acc-0.4600, valid loss-1.9482, acc-0.4880, test loss-1.9167, acc-0.5053\n",
      "Iter-63870, train loss-1.9182, acc-0.4800, valid loss-1.9482, acc-0.4878, test loss-1.9166, acc-0.5053\n",
      "Iter-63880, train loss-1.8656, acc-0.5200, valid loss-1.9481, acc-0.4878, test loss-1.9166, acc-0.5055\n",
      "Iter-63890, train loss-1.8759, acc-0.5600, valid loss-1.9481, acc-0.4878, test loss-1.9165, acc-0.5056\n",
      "Iter-63900, train loss-1.9361, acc-0.4800, valid loss-1.9480, acc-0.4880, test loss-1.9165, acc-0.5056\n",
      "Iter-63910, train loss-2.0003, acc-0.4000, valid loss-1.9480, acc-0.4880, test loss-1.9165, acc-0.5055\n",
      "Iter-63920, train loss-1.8777, acc-0.5600, valid loss-1.9480, acc-0.4882, test loss-1.9164, acc-0.5054\n",
      "Iter-63930, train loss-1.9230, acc-0.4600, valid loss-1.9479, acc-0.4882, test loss-1.9164, acc-0.5054\n",
      "Iter-63940, train loss-1.9396, acc-0.5800, valid loss-1.9479, acc-0.4880, test loss-1.9164, acc-0.5053\n",
      "Iter-63950, train loss-1.8767, acc-0.5600, valid loss-1.9479, acc-0.4882, test loss-1.9163, acc-0.5054\n",
      "Iter-63960, train loss-1.9139, acc-0.5200, valid loss-1.9478, acc-0.4880, test loss-1.9163, acc-0.5054\n",
      "Iter-63970, train loss-1.9332, acc-0.4800, valid loss-1.9478, acc-0.4880, test loss-1.9162, acc-0.5054\n",
      "Iter-63980, train loss-1.9668, acc-0.5200, valid loss-1.9478, acc-0.4880, test loss-1.9162, acc-0.5055\n",
      "Iter-63990, train loss-1.9232, acc-0.4600, valid loss-1.9477, acc-0.4880, test loss-1.9162, acc-0.5052\n",
      "Iter-64000, train loss-1.8711, acc-0.5600, valid loss-1.9477, acc-0.4880, test loss-1.9161, acc-0.5054\n",
      "Iter-64010, train loss-1.8932, acc-0.5200, valid loss-1.9477, acc-0.4880, test loss-1.9161, acc-0.5052\n",
      "Iter-64020, train loss-1.9367, acc-0.4800, valid loss-1.9476, acc-0.4880, test loss-1.9161, acc-0.5054\n",
      "Iter-64030, train loss-1.8515, acc-0.5600, valid loss-1.9476, acc-0.4880, test loss-1.9160, acc-0.5053\n",
      "Iter-64040, train loss-1.8835, acc-0.6600, valid loss-1.9476, acc-0.4880, test loss-1.9160, acc-0.5052\n",
      "Iter-64050, train loss-1.9740, acc-0.3800, valid loss-1.9475, acc-0.4880, test loss-1.9159, acc-0.5053\n",
      "Iter-64060, train loss-1.8622, acc-0.6200, valid loss-1.9475, acc-0.4882, test loss-1.9159, acc-0.5054\n",
      "Iter-64070, train loss-1.9231, acc-0.4800, valid loss-1.9475, acc-0.4882, test loss-1.9159, acc-0.5053\n",
      "Iter-64080, train loss-1.9727, acc-0.4200, valid loss-1.9474, acc-0.4882, test loss-1.9158, acc-0.5053\n",
      "Iter-64090, train loss-1.8744, acc-0.5600, valid loss-1.9474, acc-0.4882, test loss-1.9158, acc-0.5054\n",
      "Iter-64100, train loss-1.9588, acc-0.3800, valid loss-1.9473, acc-0.4882, test loss-1.9157, acc-0.5054\n",
      "Iter-64110, train loss-1.9529, acc-0.3800, valid loss-1.9473, acc-0.4884, test loss-1.9157, acc-0.5054\n",
      "Iter-64120, train loss-2.0350, acc-0.3800, valid loss-1.9473, acc-0.4884, test loss-1.9157, acc-0.5054\n",
      "Iter-64130, train loss-1.9174, acc-0.4600, valid loss-1.9473, acc-0.4886, test loss-1.9156, acc-0.5055\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-64140, train loss-1.9118, acc-0.5200, valid loss-1.9472, acc-0.4884, test loss-1.9156, acc-0.5054\n",
      "Iter-64150, train loss-1.9423, acc-0.5400, valid loss-1.9472, acc-0.4886, test loss-1.9156, acc-0.5054\n",
      "Iter-64160, train loss-1.9336, acc-0.4200, valid loss-1.9471, acc-0.4886, test loss-1.9155, acc-0.5055\n",
      "Iter-64170, train loss-1.9128, acc-0.5400, valid loss-1.9471, acc-0.4886, test loss-1.9155, acc-0.5054\n",
      "Iter-64180, train loss-1.8614, acc-0.5400, valid loss-1.9471, acc-0.4884, test loss-1.9154, acc-0.5054\n",
      "Iter-64190, train loss-1.7797, acc-0.7200, valid loss-1.9470, acc-0.4886, test loss-1.9154, acc-0.5054\n",
      "Iter-64200, train loss-1.9448, acc-0.3800, valid loss-1.9470, acc-0.4884, test loss-1.9154, acc-0.5053\n",
      "Iter-64210, train loss-1.9657, acc-0.4800, valid loss-1.9470, acc-0.4882, test loss-1.9153, acc-0.5053\n",
      "Iter-64220, train loss-1.9300, acc-0.5000, valid loss-1.9469, acc-0.4882, test loss-1.9153, acc-0.5054\n",
      "Iter-64230, train loss-1.9421, acc-0.4800, valid loss-1.9469, acc-0.4884, test loss-1.9152, acc-0.5056\n",
      "Iter-64240, train loss-1.8954, acc-0.5400, valid loss-1.9469, acc-0.4886, test loss-1.9152, acc-0.5054\n",
      "Iter-64250, train loss-1.9124, acc-0.5600, valid loss-1.9468, acc-0.4884, test loss-1.9152, acc-0.5054\n",
      "Iter-64260, train loss-1.9523, acc-0.3800, valid loss-1.9468, acc-0.4884, test loss-1.9151, acc-0.5054\n",
      "Iter-64270, train loss-1.9144, acc-0.6200, valid loss-1.9467, acc-0.4886, test loss-1.9151, acc-0.5053\n",
      "Iter-64280, train loss-2.0230, acc-0.4200, valid loss-1.9467, acc-0.4886, test loss-1.9150, acc-0.5054\n",
      "Iter-64290, train loss-1.9658, acc-0.4400, valid loss-1.9467, acc-0.4884, test loss-1.9150, acc-0.5052\n",
      "Iter-64300, train loss-1.8301, acc-0.6400, valid loss-1.9466, acc-0.4886, test loss-1.9150, acc-0.5053\n",
      "Iter-64310, train loss-1.9708, acc-0.3800, valid loss-1.9466, acc-0.4886, test loss-1.9149, acc-0.5053\n",
      "Iter-64320, train loss-1.9707, acc-0.4400, valid loss-1.9466, acc-0.4888, test loss-1.9149, acc-0.5052\n",
      "Iter-64330, train loss-1.8405, acc-0.6400, valid loss-1.9465, acc-0.4888, test loss-1.9148, acc-0.5052\n",
      "Iter-64340, train loss-1.9661, acc-0.5400, valid loss-1.9465, acc-0.4890, test loss-1.9148, acc-0.5052\n",
      "Iter-64350, train loss-1.8874, acc-0.5400, valid loss-1.9465, acc-0.4890, test loss-1.9148, acc-0.5051\n",
      "Iter-64360, train loss-1.8963, acc-0.5400, valid loss-1.9464, acc-0.4890, test loss-1.9147, acc-0.5052\n",
      "Iter-64370, train loss-1.9899, acc-0.5200, valid loss-1.9464, acc-0.4886, test loss-1.9147, acc-0.5053\n",
      "Iter-64380, train loss-1.8552, acc-0.6200, valid loss-1.9464, acc-0.4888, test loss-1.9147, acc-0.5053\n",
      "Iter-64390, train loss-1.9510, acc-0.4800, valid loss-1.9463, acc-0.4888, test loss-1.9146, acc-0.5054\n",
      "Iter-64400, train loss-2.0607, acc-0.3400, valid loss-1.9463, acc-0.4890, test loss-1.9146, acc-0.5053\n",
      "Iter-64410, train loss-1.8051, acc-0.5800, valid loss-1.9463, acc-0.4892, test loss-1.9145, acc-0.5053\n",
      "Iter-64420, train loss-1.9273, acc-0.4400, valid loss-1.9462, acc-0.4892, test loss-1.9145, acc-0.5054\n",
      "Iter-64430, train loss-1.8962, acc-0.4800, valid loss-1.9462, acc-0.4890, test loss-1.9145, acc-0.5053\n",
      "Iter-64440, train loss-2.0026, acc-0.3800, valid loss-1.9461, acc-0.4888, test loss-1.9144, acc-0.5056\n",
      "Iter-64450, train loss-1.9819, acc-0.3800, valid loss-1.9461, acc-0.4888, test loss-1.9144, acc-0.5054\n",
      "Iter-64460, train loss-1.9058, acc-0.4200, valid loss-1.9461, acc-0.4888, test loss-1.9144, acc-0.5055\n",
      "Iter-64470, train loss-1.9782, acc-0.4200, valid loss-1.9461, acc-0.4888, test loss-1.9143, acc-0.5055\n",
      "Iter-64480, train loss-1.9109, acc-0.5000, valid loss-1.9460, acc-0.4892, test loss-1.9143, acc-0.5055\n",
      "Iter-64490, train loss-1.8912, acc-0.4400, valid loss-1.9460, acc-0.4892, test loss-1.9142, acc-0.5054\n",
      "Iter-64500, train loss-1.9831, acc-0.4400, valid loss-1.9459, acc-0.4890, test loss-1.9142, acc-0.5054\n",
      "Iter-64510, train loss-1.9284, acc-0.5400, valid loss-1.9459, acc-0.4890, test loss-1.9142, acc-0.5054\n",
      "Iter-64520, train loss-1.9235, acc-0.5000, valid loss-1.9459, acc-0.4890, test loss-1.9141, acc-0.5054\n",
      "Iter-64530, train loss-1.9413, acc-0.3600, valid loss-1.9458, acc-0.4888, test loss-1.9141, acc-0.5056\n",
      "Iter-64540, train loss-1.9604, acc-0.4600, valid loss-1.9458, acc-0.4888, test loss-1.9141, acc-0.5057\n",
      "Iter-64550, train loss-1.9225, acc-0.5200, valid loss-1.9458, acc-0.4888, test loss-1.9140, acc-0.5055\n",
      "Iter-64560, train loss-1.9303, acc-0.4400, valid loss-1.9457, acc-0.4890, test loss-1.9140, acc-0.5055\n",
      "Iter-64570, train loss-1.8427, acc-0.5200, valid loss-1.9457, acc-0.4890, test loss-1.9139, acc-0.5056\n",
      "Iter-64580, train loss-1.9423, acc-0.5000, valid loss-1.9457, acc-0.4890, test loss-1.9139, acc-0.5057\n",
      "Iter-64590, train loss-1.8905, acc-0.5000, valid loss-1.9456, acc-0.4888, test loss-1.9139, acc-0.5055\n",
      "Iter-64600, train loss-1.9688, acc-0.5400, valid loss-1.9456, acc-0.4888, test loss-1.9138, acc-0.5055\n",
      "Iter-64610, train loss-1.9205, acc-0.5000, valid loss-1.9456, acc-0.4890, test loss-1.9138, acc-0.5055\n",
      "Iter-64620, train loss-1.9845, acc-0.4000, valid loss-1.9455, acc-0.4890, test loss-1.9137, acc-0.5054\n",
      "Iter-64630, train loss-1.9645, acc-0.4200, valid loss-1.9455, acc-0.4892, test loss-1.9137, acc-0.5057\n",
      "Iter-64640, train loss-1.9536, acc-0.4400, valid loss-1.9454, acc-0.4890, test loss-1.9137, acc-0.5054\n",
      "Iter-64650, train loss-1.9986, acc-0.3800, valid loss-1.9454, acc-0.4892, test loss-1.9136, acc-0.5055\n",
      "Iter-64660, train loss-1.8222, acc-0.6400, valid loss-1.9454, acc-0.4888, test loss-1.9136, acc-0.5054\n",
      "Iter-64670, train loss-2.0008, acc-0.2800, valid loss-1.9453, acc-0.4888, test loss-1.9136, acc-0.5054\n",
      "Iter-64680, train loss-1.9167, acc-0.4800, valid loss-1.9453, acc-0.4888, test loss-1.9135, acc-0.5054\n",
      "Iter-64690, train loss-1.9036, acc-0.4800, valid loss-1.9453, acc-0.4894, test loss-1.9135, acc-0.5056\n",
      "Iter-64700, train loss-1.9307, acc-0.5600, valid loss-1.9452, acc-0.4890, test loss-1.9134, acc-0.5056\n",
      "Iter-64710, train loss-1.9616, acc-0.3600, valid loss-1.9452, acc-0.4890, test loss-1.9134, acc-0.5055\n",
      "Iter-64720, train loss-1.8939, acc-0.4800, valid loss-1.9452, acc-0.4888, test loss-1.9134, acc-0.5055\n",
      "Iter-64730, train loss-1.8491, acc-0.6400, valid loss-1.9451, acc-0.4892, test loss-1.9133, acc-0.5055\n",
      "Iter-64740, train loss-1.9757, acc-0.4000, valid loss-1.9451, acc-0.4892, test loss-1.9133, acc-0.5056\n",
      "Iter-64750, train loss-1.9006, acc-0.5600, valid loss-1.9451, acc-0.4892, test loss-1.9133, acc-0.5056\n",
      "Iter-64760, train loss-1.9320, acc-0.4200, valid loss-1.9450, acc-0.4890, test loss-1.9132, acc-0.5055\n",
      "Iter-64770, train loss-1.9035, acc-0.4600, valid loss-1.9450, acc-0.4890, test loss-1.9132, acc-0.5055\n",
      "Iter-64780, train loss-1.9330, acc-0.5400, valid loss-1.9450, acc-0.4890, test loss-1.9131, acc-0.5056\n",
      "Iter-64790, train loss-2.0377, acc-0.3600, valid loss-1.9449, acc-0.4890, test loss-1.9131, acc-0.5057\n",
      "Iter-64800, train loss-1.9671, acc-0.4600, valid loss-1.9449, acc-0.4888, test loss-1.9131, acc-0.5057\n",
      "Iter-64810, train loss-1.8382, acc-0.6000, valid loss-1.9449, acc-0.4886, test loss-1.9130, acc-0.5053\n",
      "Iter-64820, train loss-1.8988, acc-0.6000, valid loss-1.9448, acc-0.4888, test loss-1.9130, acc-0.5055\n",
      "Iter-64830, train loss-1.9584, acc-0.3600, valid loss-1.9448, acc-0.4888, test loss-1.9129, acc-0.5054\n",
      "Iter-64840, train loss-1.9251, acc-0.5400, valid loss-1.9448, acc-0.4886, test loss-1.9129, acc-0.5054\n",
      "Iter-64850, train loss-1.9411, acc-0.5000, valid loss-1.9447, acc-0.4886, test loss-1.9129, acc-0.5053\n",
      "Iter-64860, train loss-1.8582, acc-0.6800, valid loss-1.9447, acc-0.4886, test loss-1.9128, acc-0.5053\n",
      "Iter-64870, train loss-1.9147, acc-0.3800, valid loss-1.9447, acc-0.4886, test loss-1.9128, acc-0.5055\n",
      "Iter-64880, train loss-1.8514, acc-0.5800, valid loss-1.9446, acc-0.4888, test loss-1.9127, acc-0.5054\n",
      "Iter-64890, train loss-2.0791, acc-0.4400, valid loss-1.9446, acc-0.4890, test loss-1.9127, acc-0.5056\n",
      "Iter-64900, train loss-1.9421, acc-0.5000, valid loss-1.9445, acc-0.4888, test loss-1.9127, acc-0.5057\n",
      "Iter-64910, train loss-1.9881, acc-0.3800, valid loss-1.9445, acc-0.4888, test loss-1.9126, acc-0.5057\n",
      "Iter-64920, train loss-1.8762, acc-0.5800, valid loss-1.9445, acc-0.4888, test loss-1.9126, acc-0.5056\n",
      "Iter-64930, train loss-1.9877, acc-0.4000, valid loss-1.9444, acc-0.4888, test loss-1.9126, acc-0.5056\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-64940, train loss-1.9112, acc-0.4200, valid loss-1.9444, acc-0.4886, test loss-1.9125, acc-0.5057\n",
      "Iter-64950, train loss-1.9707, acc-0.4400, valid loss-1.9444, acc-0.4886, test loss-1.9125, acc-0.5057\n",
      "Iter-64960, train loss-1.9788, acc-0.3800, valid loss-1.9444, acc-0.4886, test loss-1.9124, acc-0.5057\n",
      "Iter-64970, train loss-1.9131, acc-0.4600, valid loss-1.9443, acc-0.4886, test loss-1.9124, acc-0.5058\n",
      "Iter-64980, train loss-1.9224, acc-0.5800, valid loss-1.9443, acc-0.4888, test loss-1.9124, acc-0.5058\n",
      "Iter-64990, train loss-1.9481, acc-0.3800, valid loss-1.9443, acc-0.4886, test loss-1.9123, acc-0.5061\n",
      "Iter-65000, train loss-1.9195, acc-0.6400, valid loss-1.9442, acc-0.4886, test loss-1.9123, acc-0.5060\n",
      "Iter-65010, train loss-1.9252, acc-0.5000, valid loss-1.9442, acc-0.4888, test loss-1.9123, acc-0.5059\n",
      "Iter-65020, train loss-1.9099, acc-0.5200, valid loss-1.9442, acc-0.4888, test loss-1.9122, acc-0.5060\n",
      "Iter-65030, train loss-1.9202, acc-0.5000, valid loss-1.9441, acc-0.4890, test loss-1.9122, acc-0.5061\n",
      "Iter-65040, train loss-1.9115, acc-0.4600, valid loss-1.9441, acc-0.4886, test loss-1.9121, acc-0.5060\n",
      "Iter-65050, train loss-1.9653, acc-0.4800, valid loss-1.9440, acc-0.4886, test loss-1.9121, acc-0.5059\n",
      "Iter-65060, train loss-1.9822, acc-0.5200, valid loss-1.9440, acc-0.4884, test loss-1.9121, acc-0.5060\n",
      "Iter-65070, train loss-1.9271, acc-0.5800, valid loss-1.9440, acc-0.4884, test loss-1.9120, acc-0.5059\n",
      "Iter-65080, train loss-1.9229, acc-0.4600, valid loss-1.9440, acc-0.4884, test loss-1.9120, acc-0.5062\n",
      "Iter-65090, train loss-1.8783, acc-0.6400, valid loss-1.9439, acc-0.4884, test loss-1.9120, acc-0.5061\n",
      "Iter-65100, train loss-1.9101, acc-0.4800, valid loss-1.9439, acc-0.4884, test loss-1.9119, acc-0.5063\n",
      "Iter-65110, train loss-1.9062, acc-0.4200, valid loss-1.9438, acc-0.4884, test loss-1.9119, acc-0.5063\n",
      "Iter-65120, train loss-1.8958, acc-0.6200, valid loss-1.9438, acc-0.4888, test loss-1.9118, acc-0.5062\n",
      "Iter-65130, train loss-1.8643, acc-0.5800, valid loss-1.9438, acc-0.4888, test loss-1.9118, acc-0.5062\n",
      "Iter-65140, train loss-1.8451, acc-0.5000, valid loss-1.9437, acc-0.4888, test loss-1.9118, acc-0.5061\n",
      "Iter-65150, train loss-1.9569, acc-0.5200, valid loss-1.9437, acc-0.4886, test loss-1.9117, acc-0.5061\n",
      "Iter-65160, train loss-1.8919, acc-0.5000, valid loss-1.9437, acc-0.4888, test loss-1.9117, acc-0.5062\n",
      "Iter-65170, train loss-2.0172, acc-0.4200, valid loss-1.9436, acc-0.4886, test loss-1.9116, acc-0.5061\n",
      "Iter-65180, train loss-1.9021, acc-0.5400, valid loss-1.9436, acc-0.4888, test loss-1.9116, acc-0.5059\n",
      "Iter-65190, train loss-2.0340, acc-0.3800, valid loss-1.9436, acc-0.4888, test loss-1.9116, acc-0.5062\n",
      "Iter-65200, train loss-1.9486, acc-0.4800, valid loss-1.9435, acc-0.4888, test loss-1.9115, acc-0.5062\n",
      "Iter-65210, train loss-1.9526, acc-0.4600, valid loss-1.9435, acc-0.4888, test loss-1.9115, acc-0.5061\n",
      "Iter-65220, train loss-1.9004, acc-0.6000, valid loss-1.9435, acc-0.4886, test loss-1.9115, acc-0.5062\n",
      "Iter-65230, train loss-1.9374, acc-0.4400, valid loss-1.9434, acc-0.4886, test loss-1.9114, acc-0.5062\n",
      "Iter-65240, train loss-2.0097, acc-0.3400, valid loss-1.9434, acc-0.4890, test loss-1.9114, acc-0.5062\n",
      "Iter-65250, train loss-1.9657, acc-0.4800, valid loss-1.9434, acc-0.4888, test loss-1.9113, acc-0.5063\n",
      "Iter-65260, train loss-1.8777, acc-0.5400, valid loss-1.9433, acc-0.4888, test loss-1.9113, acc-0.5063\n",
      "Iter-65270, train loss-1.9962, acc-0.4600, valid loss-1.9433, acc-0.4888, test loss-1.9113, acc-0.5063\n",
      "Iter-65280, train loss-1.9514, acc-0.4600, valid loss-1.9433, acc-0.4888, test loss-1.9112, acc-0.5061\n",
      "Iter-65290, train loss-1.9483, acc-0.5400, valid loss-1.9432, acc-0.4888, test loss-1.9112, acc-0.5063\n",
      "Iter-65300, train loss-1.9369, acc-0.4400, valid loss-1.9432, acc-0.4888, test loss-1.9112, acc-0.5063\n",
      "Iter-65310, train loss-1.9236, acc-0.5000, valid loss-1.9432, acc-0.4888, test loss-1.9111, acc-0.5064\n",
      "Iter-65320, train loss-1.8911, acc-0.5400, valid loss-1.9431, acc-0.4888, test loss-1.9111, acc-0.5063\n",
      "Iter-65330, train loss-1.8805, acc-0.5800, valid loss-1.9431, acc-0.4888, test loss-1.9110, acc-0.5063\n",
      "Iter-65340, train loss-1.9432, acc-0.5600, valid loss-1.9430, acc-0.4888, test loss-1.9110, acc-0.5063\n",
      "Iter-65350, train loss-1.8139, acc-0.5800, valid loss-1.9430, acc-0.4894, test loss-1.9110, acc-0.5063\n",
      "Iter-65360, train loss-1.8705, acc-0.5000, valid loss-1.9430, acc-0.4890, test loss-1.9109, acc-0.5066\n",
      "Iter-65370, train loss-1.9511, acc-0.3800, valid loss-1.9429, acc-0.4890, test loss-1.9109, acc-0.5066\n",
      "Iter-65380, train loss-1.8992, acc-0.4400, valid loss-1.9429, acc-0.4894, test loss-1.9108, acc-0.5066\n",
      "Iter-65390, train loss-1.8844, acc-0.6000, valid loss-1.9429, acc-0.4894, test loss-1.9108, acc-0.5067\n",
      "Iter-65400, train loss-1.9044, acc-0.4600, valid loss-1.9428, acc-0.4894, test loss-1.9108, acc-0.5066\n",
      "Iter-65410, train loss-1.8856, acc-0.5600, valid loss-1.9428, acc-0.4890, test loss-1.9107, acc-0.5066\n",
      "Iter-65420, train loss-1.9373, acc-0.4400, valid loss-1.9428, acc-0.4892, test loss-1.9107, acc-0.5066\n",
      "Iter-65430, train loss-1.9513, acc-0.4000, valid loss-1.9427, acc-0.4894, test loss-1.9107, acc-0.5066\n",
      "Iter-65440, train loss-1.9962, acc-0.4000, valid loss-1.9427, acc-0.4892, test loss-1.9106, acc-0.5064\n",
      "Iter-65450, train loss-1.8985, acc-0.5000, valid loss-1.9427, acc-0.4890, test loss-1.9106, acc-0.5065\n",
      "Iter-65460, train loss-1.9563, acc-0.4400, valid loss-1.9426, acc-0.4892, test loss-1.9105, acc-0.5066\n",
      "Iter-65470, train loss-1.9158, acc-0.4800, valid loss-1.9426, acc-0.4892, test loss-1.9105, acc-0.5067\n",
      "Iter-65480, train loss-2.0154, acc-0.4000, valid loss-1.9426, acc-0.4894, test loss-1.9105, acc-0.5066\n",
      "Iter-65490, train loss-1.9592, acc-0.4200, valid loss-1.9425, acc-0.4892, test loss-1.9104, acc-0.5067\n",
      "Iter-65500, train loss-1.9323, acc-0.4000, valid loss-1.9425, acc-0.4894, test loss-1.9104, acc-0.5066\n",
      "Iter-65510, train loss-1.9670, acc-0.4400, valid loss-1.9425, acc-0.4894, test loss-1.9104, acc-0.5066\n",
      "Iter-65520, train loss-1.9372, acc-0.4800, valid loss-1.9424, acc-0.4890, test loss-1.9103, acc-0.5069\n",
      "Iter-65530, train loss-1.8682, acc-0.4800, valid loss-1.9424, acc-0.4892, test loss-1.9103, acc-0.5068\n",
      "Iter-65540, train loss-2.0275, acc-0.4400, valid loss-1.9424, acc-0.4892, test loss-1.9102, acc-0.5069\n",
      "Iter-65550, train loss-1.9416, acc-0.4200, valid loss-1.9423, acc-0.4892, test loss-1.9102, acc-0.5069\n",
      "Iter-65560, train loss-1.9579, acc-0.4400, valid loss-1.9423, acc-0.4892, test loss-1.9102, acc-0.5069\n",
      "Iter-65570, train loss-1.9218, acc-0.4400, valid loss-1.9423, acc-0.4892, test loss-1.9101, acc-0.5069\n",
      "Iter-65580, train loss-1.9302, acc-0.5200, valid loss-1.9422, acc-0.4892, test loss-1.9101, acc-0.5069\n",
      "Iter-65590, train loss-1.9997, acc-0.3800, valid loss-1.9422, acc-0.4894, test loss-1.9101, acc-0.5068\n",
      "Iter-65600, train loss-1.9383, acc-0.5400, valid loss-1.9422, acc-0.4892, test loss-1.9100, acc-0.5069\n",
      "Iter-65610, train loss-2.0000, acc-0.4000, valid loss-1.9421, acc-0.4892, test loss-1.9100, acc-0.5069\n",
      "Iter-65620, train loss-1.8829, acc-0.5400, valid loss-1.9421, acc-0.4894, test loss-1.9099, acc-0.5068\n",
      "Iter-65630, train loss-1.9538, acc-0.5200, valid loss-1.9421, acc-0.4894, test loss-1.9099, acc-0.5070\n",
      "Iter-65640, train loss-1.8122, acc-0.5800, valid loss-1.9420, acc-0.4894, test loss-1.9099, acc-0.5069\n",
      "Iter-65650, train loss-1.9070, acc-0.4400, valid loss-1.9420, acc-0.4898, test loss-1.9098, acc-0.5070\n",
      "Iter-65660, train loss-1.8756, acc-0.6000, valid loss-1.9419, acc-0.4896, test loss-1.9098, acc-0.5071\n",
      "Iter-65670, train loss-1.9553, acc-0.4600, valid loss-1.9419, acc-0.4898, test loss-1.9097, acc-0.5069\n",
      "Iter-65680, train loss-1.8421, acc-0.6600, valid loss-1.9419, acc-0.4896, test loss-1.9097, acc-0.5069\n",
      "Iter-65690, train loss-1.9188, acc-0.4000, valid loss-1.9418, acc-0.4898, test loss-1.9097, acc-0.5068\n",
      "Iter-65700, train loss-1.8694, acc-0.5000, valid loss-1.9418, acc-0.4898, test loss-1.9096, acc-0.5069\n",
      "Iter-65710, train loss-1.9598, acc-0.4800, valid loss-1.9418, acc-0.4898, test loss-1.9096, acc-0.5065\n",
      "Iter-65720, train loss-2.0294, acc-0.4600, valid loss-1.9417, acc-0.4898, test loss-1.9096, acc-0.5069\n",
      "Iter-65730, train loss-1.8515, acc-0.6000, valid loss-1.9417, acc-0.4898, test loss-1.9095, acc-0.5068\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-65740, train loss-1.9603, acc-0.3600, valid loss-1.9417, acc-0.4898, test loss-1.9095, acc-0.5066\n",
      "Iter-65750, train loss-1.9235, acc-0.5000, valid loss-1.9416, acc-0.4898, test loss-1.9094, acc-0.5065\n",
      "Iter-65760, train loss-1.9391, acc-0.4200, valid loss-1.9416, acc-0.4898, test loss-1.9094, acc-0.5066\n",
      "Iter-65770, train loss-1.9176, acc-0.5200, valid loss-1.9416, acc-0.4898, test loss-1.9094, acc-0.5065\n",
      "Iter-65780, train loss-2.0112, acc-0.4600, valid loss-1.9415, acc-0.4898, test loss-1.9093, acc-0.5066\n",
      "Iter-65790, train loss-1.9294, acc-0.4600, valid loss-1.9415, acc-0.4898, test loss-1.9093, acc-0.5067\n",
      "Iter-65800, train loss-1.9123, acc-0.6400, valid loss-1.9415, acc-0.4898, test loss-1.9092, acc-0.5068\n",
      "Iter-65810, train loss-1.9438, acc-0.3600, valid loss-1.9414, acc-0.4898, test loss-1.9092, acc-0.5067\n",
      "Iter-65820, train loss-1.9914, acc-0.4800, valid loss-1.9414, acc-0.4898, test loss-1.9092, acc-0.5068\n",
      "Iter-65830, train loss-1.8979, acc-0.5400, valid loss-1.9414, acc-0.4900, test loss-1.9091, acc-0.5066\n",
      "Iter-65840, train loss-1.9708, acc-0.5000, valid loss-1.9413, acc-0.4898, test loss-1.9091, acc-0.5067\n",
      "Iter-65850, train loss-1.9322, acc-0.5800, valid loss-1.9413, acc-0.4902, test loss-1.9091, acc-0.5067\n",
      "Iter-65860, train loss-1.9002, acc-0.4800, valid loss-1.9413, acc-0.4902, test loss-1.9090, acc-0.5069\n",
      "Iter-65870, train loss-1.9289, acc-0.4800, valid loss-1.9412, acc-0.4898, test loss-1.9090, acc-0.5070\n",
      "Iter-65880, train loss-1.9960, acc-0.4800, valid loss-1.9412, acc-0.4900, test loss-1.9089, acc-0.5071\n",
      "Iter-65890, train loss-1.8396, acc-0.6400, valid loss-1.9412, acc-0.4898, test loss-1.9089, acc-0.5070\n",
      "Iter-65900, train loss-1.9525, acc-0.3800, valid loss-1.9411, acc-0.4898, test loss-1.9089, acc-0.5069\n",
      "Iter-65910, train loss-1.9209, acc-0.5000, valid loss-1.9411, acc-0.4902, test loss-1.9088, acc-0.5071\n",
      "Iter-65920, train loss-1.9163, acc-0.3400, valid loss-1.9411, acc-0.4904, test loss-1.9088, acc-0.5075\n",
      "Iter-65930, train loss-1.8949, acc-0.4600, valid loss-1.9410, acc-0.4906, test loss-1.9088, acc-0.5075\n",
      "Iter-65940, train loss-2.0141, acc-0.3200, valid loss-1.9410, acc-0.4906, test loss-1.9087, acc-0.5071\n",
      "Iter-65950, train loss-1.9707, acc-0.4000, valid loss-1.9410, acc-0.4906, test loss-1.9087, acc-0.5072\n",
      "Iter-65960, train loss-1.9758, acc-0.4400, valid loss-1.9409, acc-0.4902, test loss-1.9086, acc-0.5073\n",
      "Iter-65970, train loss-2.0001, acc-0.3200, valid loss-1.9409, acc-0.4904, test loss-1.9086, acc-0.5073\n",
      "Iter-65980, train loss-1.9267, acc-0.4200, valid loss-1.9409, acc-0.4904, test loss-1.9086, acc-0.5074\n",
      "Iter-65990, train loss-1.9153, acc-0.3800, valid loss-1.9408, acc-0.4906, test loss-1.9085, acc-0.5075\n",
      "Iter-66000, train loss-1.8970, acc-0.5200, valid loss-1.9408, acc-0.4906, test loss-1.9085, acc-0.5075\n",
      "Iter-66010, train loss-1.9343, acc-0.4800, valid loss-1.9408, acc-0.4906, test loss-1.9085, acc-0.5073\n",
      "Iter-66020, train loss-1.9550, acc-0.5600, valid loss-1.9407, acc-0.4906, test loss-1.9084, acc-0.5075\n",
      "Iter-66030, train loss-1.9102, acc-0.4200, valid loss-1.9407, acc-0.4904, test loss-1.9084, acc-0.5074\n",
      "Iter-66040, train loss-1.9565, acc-0.3200, valid loss-1.9407, acc-0.4904, test loss-1.9084, acc-0.5074\n",
      "Iter-66050, train loss-1.9061, acc-0.5800, valid loss-1.9406, acc-0.4902, test loss-1.9083, acc-0.5074\n",
      "Iter-66060, train loss-1.9487, acc-0.5000, valid loss-1.9406, acc-0.4906, test loss-1.9083, acc-0.5074\n",
      "Iter-66070, train loss-1.9039, acc-0.4800, valid loss-1.9406, acc-0.4906, test loss-1.9082, acc-0.5074\n",
      "Iter-66080, train loss-1.9219, acc-0.5000, valid loss-1.9405, acc-0.4902, test loss-1.9082, acc-0.5074\n",
      "Iter-66090, train loss-1.8694, acc-0.5000, valid loss-1.9405, acc-0.4900, test loss-1.9082, acc-0.5071\n",
      "Iter-66100, train loss-1.9822, acc-0.5600, valid loss-1.9405, acc-0.4900, test loss-1.9081, acc-0.5073\n",
      "Iter-66110, train loss-1.9417, acc-0.5000, valid loss-1.9404, acc-0.4900, test loss-1.9081, acc-0.5073\n",
      "Iter-66120, train loss-2.0513, acc-0.3600, valid loss-1.9404, acc-0.4900, test loss-1.9080, acc-0.5074\n",
      "Iter-66130, train loss-1.8542, acc-0.5200, valid loss-1.9403, acc-0.4902, test loss-1.9080, acc-0.5073\n",
      "Iter-66140, train loss-1.8933, acc-0.5400, valid loss-1.9403, acc-0.4902, test loss-1.9080, acc-0.5073\n",
      "Iter-66150, train loss-1.9851, acc-0.4200, valid loss-1.9403, acc-0.4902, test loss-1.9079, acc-0.5074\n",
      "Iter-66160, train loss-1.8739, acc-0.6200, valid loss-1.9402, acc-0.4900, test loss-1.9079, acc-0.5072\n",
      "Iter-66170, train loss-1.9599, acc-0.4000, valid loss-1.9402, acc-0.4896, test loss-1.9079, acc-0.5072\n",
      "Iter-66180, train loss-1.9686, acc-0.4600, valid loss-1.9402, acc-0.4898, test loss-1.9078, acc-0.5072\n",
      "Iter-66190, train loss-1.8654, acc-0.4600, valid loss-1.9401, acc-0.4904, test loss-1.9078, acc-0.5071\n",
      "Iter-66200, train loss-1.9222, acc-0.4800, valid loss-1.9401, acc-0.4904, test loss-1.9077, acc-0.5072\n",
      "Iter-66210, train loss-1.8470, acc-0.5600, valid loss-1.9401, acc-0.4902, test loss-1.9077, acc-0.5073\n",
      "Iter-66220, train loss-1.9782, acc-0.4200, valid loss-1.9400, acc-0.4900, test loss-1.9077, acc-0.5072\n",
      "Iter-66230, train loss-1.9914, acc-0.3800, valid loss-1.9400, acc-0.4902, test loss-1.9076, acc-0.5073\n",
      "Iter-66240, train loss-1.9189, acc-0.5400, valid loss-1.9400, acc-0.4902, test loss-1.9076, acc-0.5072\n",
      "Iter-66250, train loss-1.9955, acc-0.4600, valid loss-1.9399, acc-0.4902, test loss-1.9076, acc-0.5072\n",
      "Iter-66260, train loss-1.9185, acc-0.4600, valid loss-1.9399, acc-0.4898, test loss-1.9075, acc-0.5071\n",
      "Iter-66270, train loss-1.8928, acc-0.5600, valid loss-1.9399, acc-0.4900, test loss-1.9075, acc-0.5072\n",
      "Iter-66280, train loss-1.8586, acc-0.5800, valid loss-1.9398, acc-0.4900, test loss-1.9074, acc-0.5073\n",
      "Iter-66290, train loss-1.9373, acc-0.4000, valid loss-1.9398, acc-0.4898, test loss-1.9074, acc-0.5071\n",
      "Iter-66300, train loss-1.9251, acc-0.5600, valid loss-1.9398, acc-0.4902, test loss-1.9074, acc-0.5070\n",
      "Iter-66310, train loss-1.8786, acc-0.4400, valid loss-1.9397, acc-0.4902, test loss-1.9073, acc-0.5070\n",
      "Iter-66320, train loss-1.8444, acc-0.5400, valid loss-1.9397, acc-0.4902, test loss-1.9073, acc-0.5070\n",
      "Iter-66330, train loss-1.9471, acc-0.4800, valid loss-1.9397, acc-0.4900, test loss-1.9073, acc-0.5070\n",
      "Iter-66340, train loss-1.8688, acc-0.5200, valid loss-1.9396, acc-0.4900, test loss-1.9072, acc-0.5071\n",
      "Iter-66350, train loss-1.9198, acc-0.5200, valid loss-1.9396, acc-0.4902, test loss-1.9072, acc-0.5071\n",
      "Iter-66360, train loss-1.8478, acc-0.5200, valid loss-1.9396, acc-0.4902, test loss-1.9071, acc-0.5070\n",
      "Iter-66370, train loss-1.9284, acc-0.5600, valid loss-1.9395, acc-0.4900, test loss-1.9071, acc-0.5069\n",
      "Iter-66380, train loss-1.8911, acc-0.4400, valid loss-1.9395, acc-0.4902, test loss-1.9071, acc-0.5067\n",
      "Iter-66390, train loss-1.9422, acc-0.5200, valid loss-1.9395, acc-0.4898, test loss-1.9070, acc-0.5068\n",
      "Iter-66400, train loss-1.8756, acc-0.4800, valid loss-1.9394, acc-0.4898, test loss-1.9070, acc-0.5066\n",
      "Iter-66410, train loss-1.9879, acc-0.3800, valid loss-1.9394, acc-0.4896, test loss-1.9070, acc-0.5066\n",
      "Iter-66420, train loss-2.0398, acc-0.3800, valid loss-1.9394, acc-0.4898, test loss-1.9069, acc-0.5065\n",
      "Iter-66430, train loss-1.8848, acc-0.5000, valid loss-1.9393, acc-0.4898, test loss-1.9069, acc-0.5064\n",
      "Iter-66440, train loss-1.9849, acc-0.5400, valid loss-1.9393, acc-0.4898, test loss-1.9068, acc-0.5065\n",
      "Iter-66450, train loss-1.9538, acc-0.4400, valid loss-1.9392, acc-0.4898, test loss-1.9068, acc-0.5066\n",
      "Iter-66460, train loss-1.8761, acc-0.5400, valid loss-1.9392, acc-0.4898, test loss-1.9068, acc-0.5064\n",
      "Iter-66470, train loss-1.9282, acc-0.4400, valid loss-1.9392, acc-0.4898, test loss-1.9067, acc-0.5066\n",
      "Iter-66480, train loss-1.8685, acc-0.5200, valid loss-1.9391, acc-0.4898, test loss-1.9067, acc-0.5067\n",
      "Iter-66490, train loss-1.9333, acc-0.4800, valid loss-1.9391, acc-0.4902, test loss-1.9067, acc-0.5067\n",
      "Iter-66500, train loss-2.0417, acc-0.3600, valid loss-1.9391, acc-0.4902, test loss-1.9066, acc-0.5068\n",
      "Iter-66510, train loss-1.8673, acc-0.5200, valid loss-1.9390, acc-0.4898, test loss-1.9066, acc-0.5069\n",
      "Iter-66520, train loss-1.9362, acc-0.4800, valid loss-1.9390, acc-0.4898, test loss-1.9065, acc-0.5066\n",
      "Iter-66530, train loss-1.9010, acc-0.4600, valid loss-1.9390, acc-0.4898, test loss-1.9065, acc-0.5066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-66540, train loss-2.0282, acc-0.3800, valid loss-1.9389, acc-0.4900, test loss-1.9065, acc-0.5069\n",
      "Iter-66550, train loss-1.9228, acc-0.4800, valid loss-1.9389, acc-0.4898, test loss-1.9064, acc-0.5068\n",
      "Iter-66560, train loss-1.9272, acc-0.4000, valid loss-1.9389, acc-0.4900, test loss-1.9064, acc-0.5068\n",
      "Iter-66570, train loss-1.9264, acc-0.5200, valid loss-1.9388, acc-0.4900, test loss-1.9064, acc-0.5068\n",
      "Iter-66580, train loss-1.8415, acc-0.4800, valid loss-1.9388, acc-0.4902, test loss-1.9063, acc-0.5069\n",
      "Iter-66590, train loss-1.9302, acc-0.5200, valid loss-1.9388, acc-0.4904, test loss-1.9063, acc-0.5069\n",
      "Iter-66600, train loss-1.8663, acc-0.6000, valid loss-1.9387, acc-0.4902, test loss-1.9062, acc-0.5069\n",
      "Iter-66610, train loss-1.8663, acc-0.6000, valid loss-1.9387, acc-0.4904, test loss-1.9062, acc-0.5070\n",
      "Iter-66620, train loss-1.8723, acc-0.5800, valid loss-1.9387, acc-0.4900, test loss-1.9062, acc-0.5070\n",
      "Iter-66630, train loss-1.9010, acc-0.4600, valid loss-1.9386, acc-0.4900, test loss-1.9061, acc-0.5070\n",
      "Iter-66640, train loss-2.0253, acc-0.3800, valid loss-1.9386, acc-0.4906, test loss-1.9061, acc-0.5070\n",
      "Iter-66650, train loss-1.9103, acc-0.5000, valid loss-1.9386, acc-0.4904, test loss-1.9061, acc-0.5071\n",
      "Iter-66660, train loss-1.9305, acc-0.5800, valid loss-1.9385, acc-0.4904, test loss-1.9060, acc-0.5072\n",
      "Iter-66670, train loss-1.9784, acc-0.4000, valid loss-1.9385, acc-0.4904, test loss-1.9060, acc-0.5072\n",
      "Iter-66680, train loss-1.9329, acc-0.5200, valid loss-1.9385, acc-0.4906, test loss-1.9059, acc-0.5072\n",
      "Iter-66690, train loss-1.8687, acc-0.6000, valid loss-1.9384, acc-0.4904, test loss-1.9059, acc-0.5069\n",
      "Iter-66700, train loss-1.8974, acc-0.5200, valid loss-1.9384, acc-0.4906, test loss-1.9059, acc-0.5070\n",
      "Iter-66710, train loss-1.9500, acc-0.4600, valid loss-1.9384, acc-0.4906, test loss-1.9058, acc-0.5072\n",
      "Iter-66720, train loss-1.8845, acc-0.5200, valid loss-1.9383, acc-0.4906, test loss-1.9058, acc-0.5072\n",
      "Iter-66730, train loss-1.9557, acc-0.5400, valid loss-1.9383, acc-0.4906, test loss-1.9058, acc-0.5075\n",
      "Iter-66740, train loss-1.9228, acc-0.4800, valid loss-1.9383, acc-0.4906, test loss-1.9057, acc-0.5077\n",
      "Iter-66750, train loss-1.9150, acc-0.5400, valid loss-1.9382, acc-0.4906, test loss-1.9057, acc-0.5076\n",
      "Iter-66760, train loss-1.9719, acc-0.4600, valid loss-1.9382, acc-0.4906, test loss-1.9056, acc-0.5075\n",
      "Iter-66770, train loss-1.8807, acc-0.5000, valid loss-1.9382, acc-0.4906, test loss-1.9056, acc-0.5074\n",
      "Iter-66780, train loss-1.8216, acc-0.6400, valid loss-1.9381, acc-0.4906, test loss-1.9056, acc-0.5077\n",
      "Iter-66790, train loss-1.9615, acc-0.3800, valid loss-1.9381, acc-0.4904, test loss-1.9055, acc-0.5075\n",
      "Iter-66800, train loss-1.9905, acc-0.3600, valid loss-1.9381, acc-0.4906, test loss-1.9055, acc-0.5076\n",
      "Iter-66810, train loss-2.0407, acc-0.4000, valid loss-1.9380, acc-0.4908, test loss-1.9055, acc-0.5077\n",
      "Iter-66820, train loss-1.8861, acc-0.5400, valid loss-1.9380, acc-0.4906, test loss-1.9054, acc-0.5075\n",
      "Iter-66830, train loss-1.8889, acc-0.5800, valid loss-1.9380, acc-0.4906, test loss-1.9054, acc-0.5073\n",
      "Iter-66840, train loss-1.9802, acc-0.3400, valid loss-1.9379, acc-0.4908, test loss-1.9054, acc-0.5075\n",
      "Iter-66850, train loss-1.9579, acc-0.3600, valid loss-1.9379, acc-0.4908, test loss-1.9053, acc-0.5073\n",
      "Iter-66860, train loss-1.9384, acc-0.5400, valid loss-1.9379, acc-0.4906, test loss-1.9053, acc-0.5073\n",
      "Iter-66870, train loss-1.8746, acc-0.4400, valid loss-1.9378, acc-0.4906, test loss-1.9052, acc-0.5075\n",
      "Iter-66880, train loss-1.8860, acc-0.4600, valid loss-1.9378, acc-0.4908, test loss-1.9052, acc-0.5074\n",
      "Iter-66890, train loss-1.9275, acc-0.5200, valid loss-1.9378, acc-0.4910, test loss-1.9052, acc-0.5075\n",
      "Iter-66900, train loss-2.0242, acc-0.4600, valid loss-1.9377, acc-0.4906, test loss-1.9051, acc-0.5075\n",
      "Iter-66910, train loss-2.0155, acc-0.4200, valid loss-1.9377, acc-0.4906, test loss-1.9051, acc-0.5076\n",
      "Iter-66920, train loss-1.8728, acc-0.5400, valid loss-1.9377, acc-0.4906, test loss-1.9051, acc-0.5077\n",
      "Iter-66930, train loss-1.9243, acc-0.5600, valid loss-1.9376, acc-0.4908, test loss-1.9050, acc-0.5077\n",
      "Iter-66940, train loss-2.0137, acc-0.4200, valid loss-1.9376, acc-0.4906, test loss-1.9050, acc-0.5075\n",
      "Iter-66950, train loss-1.9218, acc-0.5000, valid loss-1.9376, acc-0.4904, test loss-1.9049, acc-0.5075\n",
      "Iter-66960, train loss-1.8881, acc-0.5600, valid loss-1.9375, acc-0.4904, test loss-1.9049, acc-0.5075\n",
      "Iter-66970, train loss-1.9734, acc-0.4200, valid loss-1.9375, acc-0.4902, test loss-1.9049, acc-0.5076\n",
      "Iter-66980, train loss-1.9340, acc-0.5200, valid loss-1.9375, acc-0.4902, test loss-1.9048, acc-0.5077\n",
      "Iter-66990, train loss-1.9031, acc-0.4600, valid loss-1.9374, acc-0.4904, test loss-1.9048, acc-0.5076\n",
      "Iter-67000, train loss-1.9864, acc-0.4600, valid loss-1.9374, acc-0.4902, test loss-1.9048, acc-0.5075\n",
      "Iter-67010, train loss-1.9175, acc-0.4200, valid loss-1.9374, acc-0.4904, test loss-1.9047, acc-0.5075\n",
      "Iter-67020, train loss-1.8944, acc-0.5400, valid loss-1.9373, acc-0.4904, test loss-1.9047, acc-0.5077\n",
      "Iter-67030, train loss-1.8964, acc-0.4600, valid loss-1.9373, acc-0.4906, test loss-1.9047, acc-0.5075\n",
      "Iter-67040, train loss-1.8064, acc-0.5400, valid loss-1.9373, acc-0.4904, test loss-1.9046, acc-0.5076\n",
      "Iter-67050, train loss-1.9542, acc-0.4600, valid loss-1.9372, acc-0.4908, test loss-1.9046, acc-0.5075\n",
      "Iter-67060, train loss-1.9019, acc-0.5400, valid loss-1.9372, acc-0.4910, test loss-1.9045, acc-0.5077\n",
      "Iter-67070, train loss-1.9107, acc-0.5000, valid loss-1.9372, acc-0.4908, test loss-1.9045, acc-0.5079\n",
      "Iter-67080, train loss-1.9530, acc-0.4000, valid loss-1.9371, acc-0.4910, test loss-1.9045, acc-0.5076\n",
      "Iter-67090, train loss-1.9070, acc-0.4400, valid loss-1.9371, acc-0.4910, test loss-1.9044, acc-0.5078\n",
      "Iter-67100, train loss-1.8784, acc-0.5200, valid loss-1.9371, acc-0.4910, test loss-1.9044, acc-0.5079\n",
      "Iter-67110, train loss-1.9748, acc-0.4800, valid loss-1.9370, acc-0.4916, test loss-1.9044, acc-0.5078\n",
      "Iter-67120, train loss-1.9310, acc-0.4800, valid loss-1.9370, acc-0.4916, test loss-1.9043, acc-0.5079\n",
      "Iter-67130, train loss-1.9336, acc-0.5000, valid loss-1.9370, acc-0.4920, test loss-1.9043, acc-0.5081\n",
      "Iter-67140, train loss-1.9482, acc-0.4800, valid loss-1.9369, acc-0.4914, test loss-1.9042, acc-0.5080\n",
      "Iter-67150, train loss-1.9414, acc-0.4600, valid loss-1.9369, acc-0.4912, test loss-1.9042, acc-0.5080\n",
      "Iter-67160, train loss-1.9437, acc-0.5200, valid loss-1.9369, acc-0.4916, test loss-1.9042, acc-0.5080\n",
      "Iter-67170, train loss-1.8633, acc-0.5200, valid loss-1.9368, acc-0.4910, test loss-1.9041, acc-0.5080\n",
      "Iter-67180, train loss-1.8672, acc-0.5200, valid loss-1.9368, acc-0.4914, test loss-1.9041, acc-0.5080\n",
      "Iter-67190, train loss-1.9240, acc-0.5600, valid loss-1.9368, acc-0.4918, test loss-1.9041, acc-0.5080\n",
      "Iter-67200, train loss-1.9170, acc-0.5200, valid loss-1.9367, acc-0.4910, test loss-1.9040, acc-0.5080\n",
      "Iter-67210, train loss-1.9260, acc-0.4400, valid loss-1.9367, acc-0.4908, test loss-1.9040, acc-0.5080\n",
      "Iter-67220, train loss-2.0057, acc-0.4000, valid loss-1.9367, acc-0.4910, test loss-1.9039, acc-0.5080\n",
      "Iter-67230, train loss-1.9180, acc-0.5000, valid loss-1.9366, acc-0.4908, test loss-1.9039, acc-0.5080\n",
      "Iter-67240, train loss-1.9165, acc-0.5200, valid loss-1.9366, acc-0.4910, test loss-1.9039, acc-0.5080\n",
      "Iter-67250, train loss-1.7957, acc-0.6400, valid loss-1.9365, acc-0.4910, test loss-1.9038, acc-0.5080\n",
      "Iter-67260, train loss-1.9582, acc-0.4800, valid loss-1.9365, acc-0.4910, test loss-1.9038, acc-0.5081\n",
      "Iter-67270, train loss-1.9606, acc-0.4400, valid loss-1.9365, acc-0.4910, test loss-1.9038, acc-0.5081\n",
      "Iter-67280, train loss-1.9399, acc-0.4600, valid loss-1.9365, acc-0.4912, test loss-1.9037, acc-0.5080\n",
      "Iter-67290, train loss-1.8979, acc-0.4400, valid loss-1.9364, acc-0.4914, test loss-1.9037, acc-0.5080\n",
      "Iter-67300, train loss-1.8675, acc-0.6600, valid loss-1.9364, acc-0.4914, test loss-1.9037, acc-0.5081\n",
      "Iter-67310, train loss-1.9399, acc-0.4800, valid loss-1.9364, acc-0.4910, test loss-1.9036, acc-0.5080\n",
      "Iter-67320, train loss-1.9518, acc-0.4000, valid loss-1.9363, acc-0.4916, test loss-1.9036, acc-0.5082\n",
      "Iter-67330, train loss-1.8939, acc-0.5200, valid loss-1.9363, acc-0.4916, test loss-1.9035, acc-0.5081\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-67340, train loss-1.9460, acc-0.4200, valid loss-1.9362, acc-0.4914, test loss-1.9035, acc-0.5084\n",
      "Iter-67350, train loss-1.9124, acc-0.5600, valid loss-1.9362, acc-0.4914, test loss-1.9035, acc-0.5082\n",
      "Iter-67360, train loss-1.7975, acc-0.6200, valid loss-1.9362, acc-0.4914, test loss-1.9034, acc-0.5081\n",
      "Iter-67370, train loss-1.8487, acc-0.5800, valid loss-1.9361, acc-0.4914, test loss-1.9034, acc-0.5082\n",
      "Iter-67380, train loss-1.9473, acc-0.5000, valid loss-1.9361, acc-0.4914, test loss-1.9033, acc-0.5083\n",
      "Iter-67390, train loss-2.0145, acc-0.3800, valid loss-1.9361, acc-0.4914, test loss-1.9033, acc-0.5082\n",
      "Iter-67400, train loss-1.9016, acc-0.5800, valid loss-1.9360, acc-0.4910, test loss-1.9033, acc-0.5083\n",
      "Iter-67410, train loss-1.9312, acc-0.5600, valid loss-1.9360, acc-0.4912, test loss-1.9032, acc-0.5083\n",
      "Iter-67420, train loss-1.9120, acc-0.5000, valid loss-1.9360, acc-0.4912, test loss-1.9032, acc-0.5081\n",
      "Iter-67430, train loss-1.9598, acc-0.4000, valid loss-1.9359, acc-0.4910, test loss-1.9032, acc-0.5082\n",
      "Iter-67440, train loss-1.8554, acc-0.5600, valid loss-1.9359, acc-0.4910, test loss-1.9031, acc-0.5079\n",
      "Iter-67450, train loss-1.8386, acc-0.5600, valid loss-1.9359, acc-0.4908, test loss-1.9031, acc-0.5081\n",
      "Iter-67460, train loss-2.0326, acc-0.4000, valid loss-1.9358, acc-0.4912, test loss-1.9031, acc-0.5082\n",
      "Iter-67470, train loss-1.9131, acc-0.5400, valid loss-1.9358, acc-0.4910, test loss-1.9030, acc-0.5079\n",
      "Iter-67480, train loss-1.8540, acc-0.6000, valid loss-1.9358, acc-0.4912, test loss-1.9030, acc-0.5080\n",
      "Iter-67490, train loss-1.9033, acc-0.4600, valid loss-1.9357, acc-0.4914, test loss-1.9029, acc-0.5080\n",
      "Iter-67500, train loss-1.8860, acc-0.5200, valid loss-1.9357, acc-0.4916, test loss-1.9029, acc-0.5079\n",
      "Iter-67510, train loss-1.8571, acc-0.5600, valid loss-1.9357, acc-0.4916, test loss-1.9029, acc-0.5082\n",
      "Iter-67520, train loss-1.9213, acc-0.5200, valid loss-1.9356, acc-0.4914, test loss-1.9028, acc-0.5083\n",
      "Iter-67530, train loss-1.8798, acc-0.6200, valid loss-1.9356, acc-0.4914, test loss-1.9028, acc-0.5082\n",
      "Iter-67540, train loss-1.8984, acc-0.5800, valid loss-1.9356, acc-0.4912, test loss-1.9028, acc-0.5082\n",
      "Iter-67550, train loss-1.8359, acc-0.6000, valid loss-1.9355, acc-0.4912, test loss-1.9027, acc-0.5082\n",
      "Iter-67560, train loss-1.8131, acc-0.4800, valid loss-1.9355, acc-0.4914, test loss-1.9027, acc-0.5082\n",
      "Iter-67570, train loss-1.9114, acc-0.5400, valid loss-1.9355, acc-0.4914, test loss-1.9026, acc-0.5083\n",
      "Iter-67580, train loss-1.9216, acc-0.4200, valid loss-1.9354, acc-0.4916, test loss-1.9026, acc-0.5083\n",
      "Iter-67590, train loss-1.8901, acc-0.5200, valid loss-1.9354, acc-0.4916, test loss-1.9026, acc-0.5085\n",
      "Iter-67600, train loss-1.9274, acc-0.4400, valid loss-1.9354, acc-0.4916, test loss-1.9025, acc-0.5084\n",
      "Iter-67610, train loss-1.9686, acc-0.5000, valid loss-1.9353, acc-0.4916, test loss-1.9025, acc-0.5084\n",
      "Iter-67620, train loss-1.8988, acc-0.5400, valid loss-1.9353, acc-0.4914, test loss-1.9025, acc-0.5084\n",
      "Iter-67630, train loss-1.9351, acc-0.5200, valid loss-1.9353, acc-0.4912, test loss-1.9024, acc-0.5084\n",
      "Iter-67640, train loss-1.9041, acc-0.5600, valid loss-1.9352, acc-0.4912, test loss-1.9024, acc-0.5083\n",
      "Iter-67650, train loss-1.9015, acc-0.5000, valid loss-1.9352, acc-0.4914, test loss-1.9024, acc-0.5083\n",
      "Iter-67660, train loss-1.9221, acc-0.4200, valid loss-1.9352, acc-0.4912, test loss-1.9023, acc-0.5085\n",
      "Iter-67670, train loss-1.9723, acc-0.4200, valid loss-1.9351, acc-0.4914, test loss-1.9023, acc-0.5083\n",
      "Iter-67680, train loss-1.9098, acc-0.5200, valid loss-1.9351, acc-0.4912, test loss-1.9022, acc-0.5083\n",
      "Iter-67690, train loss-1.9237, acc-0.5200, valid loss-1.9351, acc-0.4914, test loss-1.9022, acc-0.5086\n",
      "Iter-67700, train loss-1.9275, acc-0.4800, valid loss-1.9350, acc-0.4912, test loss-1.9022, acc-0.5083\n",
      "Iter-67710, train loss-1.9210, acc-0.4200, valid loss-1.9350, acc-0.4912, test loss-1.9021, acc-0.5085\n",
      "Iter-67720, train loss-1.9651, acc-0.4600, valid loss-1.9350, acc-0.4910, test loss-1.9021, acc-0.5083\n",
      "Iter-67730, train loss-2.0467, acc-0.4200, valid loss-1.9349, acc-0.4910, test loss-1.9021, acc-0.5083\n",
      "Iter-67740, train loss-1.9462, acc-0.5200, valid loss-1.9349, acc-0.4912, test loss-1.9020, acc-0.5081\n",
      "Iter-67750, train loss-1.8538, acc-0.5800, valid loss-1.9349, acc-0.4912, test loss-1.9020, acc-0.5080\n",
      "Iter-67760, train loss-1.8902, acc-0.5800, valid loss-1.9349, acc-0.4912, test loss-1.9019, acc-0.5081\n",
      "Iter-67770, train loss-1.9941, acc-0.4000, valid loss-1.9348, acc-0.4912, test loss-1.9019, acc-0.5080\n",
      "Iter-67780, train loss-1.9547, acc-0.4800, valid loss-1.9348, acc-0.4910, test loss-1.9019, acc-0.5082\n",
      "Iter-67790, train loss-1.9018, acc-0.5200, valid loss-1.9347, acc-0.4912, test loss-1.9018, acc-0.5081\n",
      "Iter-67800, train loss-1.9076, acc-0.5600, valid loss-1.9347, acc-0.4912, test loss-1.9018, acc-0.5081\n",
      "Iter-67810, train loss-1.9117, acc-0.5000, valid loss-1.9347, acc-0.4912, test loss-1.9018, acc-0.5081\n",
      "Iter-67820, train loss-1.9279, acc-0.4800, valid loss-1.9346, acc-0.4912, test loss-1.9017, acc-0.5080\n",
      "Iter-67830, train loss-1.9243, acc-0.4400, valid loss-1.9346, acc-0.4912, test loss-1.9017, acc-0.5081\n",
      "Iter-67840, train loss-1.9376, acc-0.4800, valid loss-1.9346, acc-0.4910, test loss-1.9016, acc-0.5080\n",
      "Iter-67850, train loss-1.9319, acc-0.4800, valid loss-1.9346, acc-0.4910, test loss-1.9016, acc-0.5080\n",
      "Iter-67860, train loss-1.9955, acc-0.4000, valid loss-1.9345, acc-0.4908, test loss-1.9016, acc-0.5081\n",
      "Iter-67870, train loss-2.0033, acc-0.3800, valid loss-1.9345, acc-0.4910, test loss-1.9015, acc-0.5079\n",
      "Iter-67880, train loss-1.8231, acc-0.5800, valid loss-1.9344, acc-0.4910, test loss-1.9015, acc-0.5079\n",
      "Iter-67890, train loss-1.9654, acc-0.4000, valid loss-1.9344, acc-0.4910, test loss-1.9015, acc-0.5078\n",
      "Iter-67900, train loss-1.8853, acc-0.5800, valid loss-1.9344, acc-0.4910, test loss-1.9014, acc-0.5079\n",
      "Iter-67910, train loss-1.9274, acc-0.5400, valid loss-1.9343, acc-0.4910, test loss-1.9014, acc-0.5077\n",
      "Iter-67920, train loss-1.8643, acc-0.5400, valid loss-1.9343, acc-0.4908, test loss-1.9014, acc-0.5076\n",
      "Iter-67930, train loss-1.9471, acc-0.5600, valid loss-1.9343, acc-0.4906, test loss-1.9013, acc-0.5078\n",
      "Iter-67940, train loss-1.8777, acc-0.6000, valid loss-1.9343, acc-0.4906, test loss-1.9013, acc-0.5078\n",
      "Iter-67950, train loss-1.8958, acc-0.5600, valid loss-1.9342, acc-0.4908, test loss-1.9012, acc-0.5080\n",
      "Iter-67960, train loss-1.9161, acc-0.4600, valid loss-1.9342, acc-0.4906, test loss-1.9012, acc-0.5080\n",
      "Iter-67970, train loss-1.9426, acc-0.5200, valid loss-1.9342, acc-0.4906, test loss-1.9012, acc-0.5080\n",
      "Iter-67980, train loss-1.8945, acc-0.4600, valid loss-1.9341, acc-0.4906, test loss-1.9011, acc-0.5079\n",
      "Iter-67990, train loss-1.9688, acc-0.3200, valid loss-1.9341, acc-0.4904, test loss-1.9011, acc-0.5078\n",
      "Iter-68000, train loss-2.0026, acc-0.3600, valid loss-1.9340, acc-0.4904, test loss-1.9011, acc-0.5077\n",
      "Iter-68010, train loss-1.9085, acc-0.4800, valid loss-1.9340, acc-0.4904, test loss-1.9010, acc-0.5079\n",
      "Iter-68020, train loss-2.0286, acc-0.4000, valid loss-1.9340, acc-0.4904, test loss-1.9010, acc-0.5079\n",
      "Iter-68030, train loss-1.9341, acc-0.4600, valid loss-1.9340, acc-0.4904, test loss-1.9010, acc-0.5082\n",
      "Iter-68040, train loss-1.9869, acc-0.4800, valid loss-1.9339, acc-0.4904, test loss-1.9009, acc-0.5082\n",
      "Iter-68050, train loss-1.8950, acc-0.5000, valid loss-1.9339, acc-0.4904, test loss-1.9009, acc-0.5082\n",
      "Iter-68060, train loss-1.9291, acc-0.4800, valid loss-1.9339, acc-0.4906, test loss-1.9008, acc-0.5080\n",
      "Iter-68070, train loss-1.9426, acc-0.4800, valid loss-1.9338, acc-0.4904, test loss-1.9008, acc-0.5080\n",
      "Iter-68080, train loss-2.0074, acc-0.4800, valid loss-1.9338, acc-0.4906, test loss-1.9008, acc-0.5081\n",
      "Iter-68090, train loss-1.8952, acc-0.3800, valid loss-1.9337, acc-0.4906, test loss-1.9007, acc-0.5081\n",
      "Iter-68100, train loss-1.9538, acc-0.4800, valid loss-1.9337, acc-0.4910, test loss-1.9007, acc-0.5083\n",
      "Iter-68110, train loss-1.9148, acc-0.4800, valid loss-1.9337, acc-0.4910, test loss-1.9007, acc-0.5080\n",
      "Iter-68120, train loss-1.8577, acc-0.5400, valid loss-1.9336, acc-0.4908, test loss-1.9006, acc-0.5080\n",
      "Iter-68130, train loss-1.9006, acc-0.6000, valid loss-1.9336, acc-0.4908, test loss-1.9006, acc-0.5082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-68140, train loss-1.9393, acc-0.4000, valid loss-1.9336, acc-0.4912, test loss-1.9005, acc-0.5082\n",
      "Iter-68150, train loss-1.9741, acc-0.4600, valid loss-1.9336, acc-0.4908, test loss-1.9005, acc-0.5082\n",
      "Iter-68160, train loss-1.8582, acc-0.5200, valid loss-1.9335, acc-0.4908, test loss-1.9005, acc-0.5082\n",
      "Iter-68170, train loss-1.8366, acc-0.6200, valid loss-1.9335, acc-0.4908, test loss-1.9004, acc-0.5082\n",
      "Iter-68180, train loss-1.8810, acc-0.6400, valid loss-1.9334, acc-0.4908, test loss-1.9004, acc-0.5084\n",
      "Iter-68190, train loss-1.9582, acc-0.4800, valid loss-1.9334, acc-0.4908, test loss-1.9004, acc-0.5085\n",
      "Iter-68200, train loss-1.8603, acc-0.5800, valid loss-1.9334, acc-0.4906, test loss-1.9003, acc-0.5086\n",
      "Iter-68210, train loss-1.9522, acc-0.4200, valid loss-1.9333, acc-0.4908, test loss-1.9003, acc-0.5084\n",
      "Iter-68220, train loss-1.9361, acc-0.5200, valid loss-1.9333, acc-0.4908, test loss-1.9002, acc-0.5084\n",
      "Iter-68230, train loss-1.8918, acc-0.5600, valid loss-1.9333, acc-0.4908, test loss-1.9002, acc-0.5086\n",
      "Iter-68240, train loss-1.9361, acc-0.4600, valid loss-1.9333, acc-0.4910, test loss-1.9002, acc-0.5084\n",
      "Iter-68250, train loss-1.9348, acc-0.5200, valid loss-1.9332, acc-0.4910, test loss-1.9001, acc-0.5083\n",
      "Iter-68260, train loss-1.9074, acc-0.5600, valid loss-1.9332, acc-0.4910, test loss-1.9001, acc-0.5082\n",
      "Iter-68270, train loss-1.8777, acc-0.6200, valid loss-1.9332, acc-0.4910, test loss-1.9001, acc-0.5082\n",
      "Iter-68280, train loss-1.8191, acc-0.6600, valid loss-1.9331, acc-0.4910, test loss-1.9000, acc-0.5084\n",
      "Iter-68290, train loss-1.9695, acc-0.4600, valid loss-1.9331, acc-0.4910, test loss-1.9000, acc-0.5083\n",
      "Iter-68300, train loss-1.8646, acc-0.5200, valid loss-1.9331, acc-0.4910, test loss-1.9000, acc-0.5085\n",
      "Iter-68310, train loss-1.8995, acc-0.5000, valid loss-1.9330, acc-0.4910, test loss-1.8999, acc-0.5085\n",
      "Iter-68320, train loss-1.8917, acc-0.4800, valid loss-1.9330, acc-0.4910, test loss-1.8999, acc-0.5084\n",
      "Iter-68330, train loss-1.8853, acc-0.6000, valid loss-1.9329, acc-0.4910, test loss-1.8998, acc-0.5085\n",
      "Iter-68340, train loss-1.9234, acc-0.4400, valid loss-1.9329, acc-0.4910, test loss-1.8998, acc-0.5086\n",
      "Iter-68350, train loss-1.9913, acc-0.3600, valid loss-1.9329, acc-0.4910, test loss-1.8998, acc-0.5084\n",
      "Iter-68360, train loss-1.9426, acc-0.4400, valid loss-1.9328, acc-0.4910, test loss-1.8997, acc-0.5084\n",
      "Iter-68370, train loss-1.9406, acc-0.4400, valid loss-1.9328, acc-0.4910, test loss-1.8997, acc-0.5086\n",
      "Iter-68380, train loss-1.8554, acc-0.4800, valid loss-1.9328, acc-0.4910, test loss-1.8996, acc-0.5087\n",
      "Iter-68390, train loss-1.8746, acc-0.5000, valid loss-1.9327, acc-0.4910, test loss-1.8996, acc-0.5085\n",
      "Iter-68400, train loss-1.9233, acc-0.4400, valid loss-1.9327, acc-0.4910, test loss-1.8996, acc-0.5086\n",
      "Iter-68410, train loss-1.8622, acc-0.5600, valid loss-1.9327, acc-0.4910, test loss-1.8995, acc-0.5086\n",
      "Iter-68420, train loss-1.8961, acc-0.5000, valid loss-1.9326, acc-0.4910, test loss-1.8995, acc-0.5087\n",
      "Iter-68430, train loss-1.8660, acc-0.6600, valid loss-1.9326, acc-0.4910, test loss-1.8995, acc-0.5087\n",
      "Iter-68440, train loss-1.8598, acc-0.5600, valid loss-1.9326, acc-0.4910, test loss-1.8994, acc-0.5087\n",
      "Iter-68450, train loss-1.9248, acc-0.4200, valid loss-1.9325, acc-0.4910, test loss-1.8994, acc-0.5087\n",
      "Iter-68460, train loss-1.9941, acc-0.4400, valid loss-1.9325, acc-0.4910, test loss-1.8993, acc-0.5086\n",
      "Iter-68470, train loss-1.8996, acc-0.4400, valid loss-1.9325, acc-0.4910, test loss-1.8993, acc-0.5088\n",
      "Iter-68480, train loss-1.8419, acc-0.5200, valid loss-1.9324, acc-0.4910, test loss-1.8993, acc-0.5085\n",
      "Iter-68490, train loss-1.8994, acc-0.5000, valid loss-1.9324, acc-0.4910, test loss-1.8992, acc-0.5084\n",
      "Iter-68500, train loss-1.8878, acc-0.5200, valid loss-1.9324, acc-0.4910, test loss-1.8992, acc-0.5086\n",
      "Iter-68510, train loss-1.8441, acc-0.5000, valid loss-1.9323, acc-0.4910, test loss-1.8992, acc-0.5087\n",
      "Iter-68520, train loss-1.8357, acc-0.6200, valid loss-1.9323, acc-0.4910, test loss-1.8991, acc-0.5087\n",
      "Iter-68530, train loss-1.8312, acc-0.6600, valid loss-1.9323, acc-0.4910, test loss-1.8991, acc-0.5086\n",
      "Iter-68540, train loss-1.8464, acc-0.4800, valid loss-1.9322, acc-0.4910, test loss-1.8991, acc-0.5086\n",
      "Iter-68550, train loss-1.8395, acc-0.5600, valid loss-1.9322, acc-0.4910, test loss-1.8990, acc-0.5085\n",
      "Iter-68560, train loss-1.9070, acc-0.5000, valid loss-1.9322, acc-0.4910, test loss-1.8990, acc-0.5085\n",
      "Iter-68570, train loss-1.8264, acc-0.6600, valid loss-1.9321, acc-0.4910, test loss-1.8989, acc-0.5085\n",
      "Iter-68580, train loss-1.8998, acc-0.4800, valid loss-1.9321, acc-0.4910, test loss-1.8989, acc-0.5085\n",
      "Iter-68590, train loss-1.9561, acc-0.4800, valid loss-1.9321, acc-0.4910, test loss-1.8989, acc-0.5085\n",
      "Iter-68600, train loss-1.9444, acc-0.3800, valid loss-1.9320, acc-0.4908, test loss-1.8988, acc-0.5085\n",
      "Iter-68610, train loss-1.8827, acc-0.4600, valid loss-1.9320, acc-0.4908, test loss-1.8988, acc-0.5085\n",
      "Iter-68620, train loss-1.9123, acc-0.5600, valid loss-1.9320, acc-0.4910, test loss-1.8988, acc-0.5086\n",
      "Iter-68630, train loss-1.9001, acc-0.5400, valid loss-1.9319, acc-0.4910, test loss-1.8987, acc-0.5086\n",
      "Iter-68640, train loss-1.8481, acc-0.5400, valid loss-1.9319, acc-0.4908, test loss-1.8987, acc-0.5085\n",
      "Iter-68650, train loss-1.8842, acc-0.5400, valid loss-1.9318, acc-0.4910, test loss-1.8987, acc-0.5086\n",
      "Iter-68660, train loss-1.8269, acc-0.5600, valid loss-1.9318, acc-0.4910, test loss-1.8986, acc-0.5083\n",
      "Iter-68670, train loss-1.8808, acc-0.5200, valid loss-1.9318, acc-0.4912, test loss-1.8986, acc-0.5084\n",
      "Iter-68680, train loss-1.9245, acc-0.5000, valid loss-1.9317, acc-0.4912, test loss-1.8985, acc-0.5085\n",
      "Iter-68690, train loss-1.9599, acc-0.4200, valid loss-1.9317, acc-0.4912, test loss-1.8985, acc-0.5087\n",
      "Iter-68700, train loss-1.8558, acc-0.5600, valid loss-1.9317, acc-0.4912, test loss-1.8985, acc-0.5084\n",
      "Iter-68710, train loss-2.0112, acc-0.5200, valid loss-1.9316, acc-0.4912, test loss-1.8984, acc-0.5084\n",
      "Iter-68720, train loss-1.8536, acc-0.5200, valid loss-1.9316, acc-0.4912, test loss-1.8984, acc-0.5084\n",
      "Iter-68730, train loss-1.9002, acc-0.5200, valid loss-1.9316, acc-0.4914, test loss-1.8984, acc-0.5085\n",
      "Iter-68740, train loss-1.8967, acc-0.5000, valid loss-1.9315, acc-0.4912, test loss-1.8983, acc-0.5086\n",
      "Iter-68750, train loss-1.8214, acc-0.6200, valid loss-1.9315, acc-0.4912, test loss-1.8983, acc-0.5086\n",
      "Iter-68760, train loss-1.9443, acc-0.4600, valid loss-1.9315, acc-0.4912, test loss-1.8983, acc-0.5087\n",
      "Iter-68770, train loss-2.0261, acc-0.4000, valid loss-1.9314, acc-0.4914, test loss-1.8982, acc-0.5086\n",
      "Iter-68780, train loss-1.9660, acc-0.4600, valid loss-1.9314, acc-0.4912, test loss-1.8982, acc-0.5086\n",
      "Iter-68790, train loss-1.8508, acc-0.5000, valid loss-1.9314, acc-0.4912, test loss-1.8981, acc-0.5088\n",
      "Iter-68800, train loss-1.8346, acc-0.6000, valid loss-1.9313, acc-0.4912, test loss-1.8981, acc-0.5087\n",
      "Iter-68810, train loss-1.8829, acc-0.4800, valid loss-1.9313, acc-0.4912, test loss-1.8981, acc-0.5086\n",
      "Iter-68820, train loss-1.8863, acc-0.4800, valid loss-1.9313, acc-0.4912, test loss-1.8980, acc-0.5087\n",
      "Iter-68830, train loss-1.8707, acc-0.4800, valid loss-1.9313, acc-0.4912, test loss-1.8980, acc-0.5088\n",
      "Iter-68840, train loss-1.9099, acc-0.4800, valid loss-1.9312, acc-0.4912, test loss-1.8980, acc-0.5089\n",
      "Iter-68850, train loss-1.9140, acc-0.5200, valid loss-1.9312, acc-0.4912, test loss-1.8979, acc-0.5086\n",
      "Iter-68860, train loss-1.8662, acc-0.5400, valid loss-1.9311, acc-0.4912, test loss-1.8979, acc-0.5087\n",
      "Iter-68870, train loss-1.8874, acc-0.5000, valid loss-1.9311, acc-0.4912, test loss-1.8979, acc-0.5088\n",
      "Iter-68880, train loss-1.9965, acc-0.3600, valid loss-1.9311, acc-0.4912, test loss-1.8978, acc-0.5087\n",
      "Iter-68890, train loss-1.9031, acc-0.5400, valid loss-1.9310, acc-0.4912, test loss-1.8978, acc-0.5086\n",
      "Iter-68900, train loss-1.9663, acc-0.5200, valid loss-1.9310, acc-0.4912, test loss-1.8977, acc-0.5088\n",
      "Iter-68910, train loss-2.0110, acc-0.4000, valid loss-1.9310, acc-0.4912, test loss-1.8977, acc-0.5088\n",
      "Iter-68920, train loss-1.8753, acc-0.5400, valid loss-1.9309, acc-0.4910, test loss-1.8977, acc-0.5088\n",
      "Iter-68930, train loss-1.9756, acc-0.4400, valid loss-1.9309, acc-0.4910, test loss-1.8976, acc-0.5088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-68940, train loss-1.9387, acc-0.4800, valid loss-1.9309, acc-0.4910, test loss-1.8976, acc-0.5088\n",
      "Iter-68950, train loss-1.8661, acc-0.4200, valid loss-1.9308, acc-0.4910, test loss-1.8976, acc-0.5087\n",
      "Iter-68960, train loss-1.9319, acc-0.4800, valid loss-1.9308, acc-0.4910, test loss-1.8975, acc-0.5089\n",
      "Iter-68970, train loss-1.8735, acc-0.5800, valid loss-1.9308, acc-0.4910, test loss-1.8975, acc-0.5090\n",
      "Iter-68980, train loss-1.9314, acc-0.4000, valid loss-1.9307, acc-0.4910, test loss-1.8974, acc-0.5091\n",
      "Iter-68990, train loss-1.8141, acc-0.6200, valid loss-1.9307, acc-0.4910, test loss-1.8974, acc-0.5091\n",
      "Iter-69000, train loss-1.8509, acc-0.5400, valid loss-1.9307, acc-0.4912, test loss-1.8974, acc-0.5090\n",
      "Iter-69010, train loss-2.0222, acc-0.4200, valid loss-1.9306, acc-0.4914, test loss-1.8973, acc-0.5090\n",
      "Iter-69020, train loss-1.9062, acc-0.5200, valid loss-1.9306, acc-0.4916, test loss-1.8973, acc-0.5092\n",
      "Iter-69030, train loss-2.0093, acc-0.4400, valid loss-1.9306, acc-0.4916, test loss-1.8973, acc-0.5091\n",
      "Iter-69040, train loss-1.9562, acc-0.4600, valid loss-1.9305, acc-0.4916, test loss-1.8972, acc-0.5088\n",
      "Iter-69050, train loss-1.9130, acc-0.5600, valid loss-1.9305, acc-0.4916, test loss-1.8972, acc-0.5090\n",
      "Iter-69060, train loss-1.8340, acc-0.6600, valid loss-1.9305, acc-0.4914, test loss-1.8972, acc-0.5091\n",
      "Iter-69070, train loss-2.0234, acc-0.3600, valid loss-1.9304, acc-0.4912, test loss-1.8971, acc-0.5092\n",
      "Iter-69080, train loss-1.8829, acc-0.5400, valid loss-1.9304, acc-0.4914, test loss-1.8971, acc-0.5091\n",
      "Iter-69090, train loss-1.8854, acc-0.4600, valid loss-1.9304, acc-0.4912, test loss-1.8971, acc-0.5089\n",
      "Iter-69100, train loss-1.8867, acc-0.5200, valid loss-1.9303, acc-0.4914, test loss-1.8970, acc-0.5088\n",
      "Iter-69110, train loss-1.9018, acc-0.5400, valid loss-1.9303, acc-0.4914, test loss-1.8970, acc-0.5090\n",
      "Iter-69120, train loss-1.8662, acc-0.5000, valid loss-1.9303, acc-0.4916, test loss-1.8969, acc-0.5091\n",
      "Iter-69130, train loss-1.9026, acc-0.4000, valid loss-1.9302, acc-0.4916, test loss-1.8969, acc-0.5092\n",
      "Iter-69140, train loss-1.9112, acc-0.4600, valid loss-1.9302, acc-0.4914, test loss-1.8969, acc-0.5093\n",
      "Iter-69150, train loss-1.8172, acc-0.4600, valid loss-1.9302, acc-0.4914, test loss-1.8968, acc-0.5093\n",
      "Iter-69160, train loss-1.7992, acc-0.5200, valid loss-1.9301, acc-0.4916, test loss-1.8968, acc-0.5094\n",
      "Iter-69170, train loss-1.9127, acc-0.5600, valid loss-1.9301, acc-0.4916, test loss-1.8968, acc-0.5094\n",
      "Iter-69180, train loss-1.8122, acc-0.5000, valid loss-1.9301, acc-0.4916, test loss-1.8967, acc-0.5093\n",
      "Iter-69190, train loss-1.9067, acc-0.4400, valid loss-1.9300, acc-0.4914, test loss-1.8967, acc-0.5093\n",
      "Iter-69200, train loss-1.9695, acc-0.4600, valid loss-1.9300, acc-0.4914, test loss-1.8966, acc-0.5094\n",
      "Iter-69210, train loss-1.9018, acc-0.5200, valid loss-1.9300, acc-0.4914, test loss-1.8966, acc-0.5093\n",
      "Iter-69220, train loss-1.9062, acc-0.6000, valid loss-1.9299, acc-0.4914, test loss-1.8966, acc-0.5094\n",
      "Iter-69230, train loss-1.9369, acc-0.4200, valid loss-1.9299, acc-0.4914, test loss-1.8965, acc-0.5094\n",
      "Iter-69240, train loss-1.8320, acc-0.6000, valid loss-1.9299, acc-0.4914, test loss-1.8965, acc-0.5093\n",
      "Iter-69250, train loss-1.9003, acc-0.5800, valid loss-1.9299, acc-0.4914, test loss-1.8965, acc-0.5094\n",
      "Iter-69260, train loss-1.8032, acc-0.6200, valid loss-1.9298, acc-0.4912, test loss-1.8964, acc-0.5094\n",
      "Iter-69270, train loss-1.8455, acc-0.5200, valid loss-1.9298, acc-0.4912, test loss-1.8964, acc-0.5092\n",
      "Iter-69280, train loss-1.9418, acc-0.4200, valid loss-1.9298, acc-0.4912, test loss-1.8964, acc-0.5092\n",
      "Iter-69290, train loss-1.8691, acc-0.6000, valid loss-1.9297, acc-0.4912, test loss-1.8963, acc-0.5093\n",
      "Iter-69300, train loss-1.9476, acc-0.5200, valid loss-1.9297, acc-0.4912, test loss-1.8963, acc-0.5091\n",
      "Iter-69310, train loss-1.9285, acc-0.4400, valid loss-1.9296, acc-0.4910, test loss-1.8962, acc-0.5093\n",
      "Iter-69320, train loss-1.8839, acc-0.4400, valid loss-1.9296, acc-0.4914, test loss-1.8962, acc-0.5093\n",
      "Iter-69330, train loss-2.0201, acc-0.4400, valid loss-1.9296, acc-0.4914, test loss-1.8962, acc-0.5093\n",
      "Iter-69340, train loss-1.8908, acc-0.6400, valid loss-1.9296, acc-0.4914, test loss-1.8961, acc-0.5093\n",
      "Iter-69350, train loss-1.9051, acc-0.4600, valid loss-1.9295, acc-0.4912, test loss-1.8961, acc-0.5093\n",
      "Iter-69360, train loss-1.8743, acc-0.5600, valid loss-1.9295, acc-0.4914, test loss-1.8961, acc-0.5092\n",
      "Iter-69370, train loss-1.9002, acc-0.5600, valid loss-1.9295, acc-0.4914, test loss-1.8960, acc-0.5093\n",
      "Iter-69380, train loss-1.8669, acc-0.5800, valid loss-1.9294, acc-0.4914, test loss-1.8960, acc-0.5094\n",
      "Iter-69390, train loss-1.8976, acc-0.5000, valid loss-1.9294, acc-0.4912, test loss-1.8960, acc-0.5094\n",
      "Iter-69400, train loss-1.9153, acc-0.4600, valid loss-1.9294, acc-0.4912, test loss-1.8959, acc-0.5095\n",
      "Iter-69410, train loss-1.8814, acc-0.5400, valid loss-1.9293, acc-0.4910, test loss-1.8959, acc-0.5094\n",
      "Iter-69420, train loss-1.7822, acc-0.6200, valid loss-1.9293, acc-0.4914, test loss-1.8958, acc-0.5094\n",
      "Iter-69430, train loss-1.9615, acc-0.4000, valid loss-1.9293, acc-0.4914, test loss-1.8958, acc-0.5094\n",
      "Iter-69440, train loss-1.8917, acc-0.4800, valid loss-1.9292, acc-0.4914, test loss-1.8958, acc-0.5094\n",
      "Iter-69450, train loss-1.8841, acc-0.4600, valid loss-1.9292, acc-0.4914, test loss-1.8957, acc-0.5094\n",
      "Iter-69460, train loss-1.8845, acc-0.5400, valid loss-1.9292, acc-0.4912, test loss-1.8957, acc-0.5095\n",
      "Iter-69470, train loss-1.9585, acc-0.4600, valid loss-1.9291, acc-0.4912, test loss-1.8957, acc-0.5093\n",
      "Iter-69480, train loss-1.7795, acc-0.6000, valid loss-1.9291, acc-0.4912, test loss-1.8956, acc-0.5093\n",
      "Iter-69490, train loss-1.8904, acc-0.5000, valid loss-1.9291, acc-0.4912, test loss-1.8956, acc-0.5093\n",
      "Iter-69500, train loss-1.8562, acc-0.5600, valid loss-1.9290, acc-0.4914, test loss-1.8955, acc-0.5092\n",
      "Iter-69510, train loss-1.9613, acc-0.3600, valid loss-1.9290, acc-0.4914, test loss-1.8955, acc-0.5092\n",
      "Iter-69520, train loss-1.9534, acc-0.4600, valid loss-1.9290, acc-0.4914, test loss-1.8955, acc-0.5092\n",
      "Iter-69530, train loss-1.8582, acc-0.5600, valid loss-1.9289, acc-0.4914, test loss-1.8954, acc-0.5091\n",
      "Iter-69540, train loss-1.9484, acc-0.4200, valid loss-1.9289, acc-0.4914, test loss-1.8954, acc-0.5090\n",
      "Iter-69550, train loss-1.9121, acc-0.4200, valid loss-1.9289, acc-0.4914, test loss-1.8954, acc-0.5090\n",
      "Iter-69560, train loss-1.8882, acc-0.4600, valid loss-1.9288, acc-0.4912, test loss-1.8953, acc-0.5090\n",
      "Iter-69570, train loss-1.9140, acc-0.4400, valid loss-1.9288, acc-0.4914, test loss-1.8953, acc-0.5090\n",
      "Iter-69580, train loss-1.9038, acc-0.5200, valid loss-1.9288, acc-0.4916, test loss-1.8953, acc-0.5092\n",
      "Iter-69590, train loss-1.9434, acc-0.5200, valid loss-1.9287, acc-0.4916, test loss-1.8952, acc-0.5090\n",
      "Iter-69600, train loss-1.9166, acc-0.5400, valid loss-1.9287, acc-0.4916, test loss-1.8952, acc-0.5092\n",
      "Iter-69610, train loss-1.9489, acc-0.5000, valid loss-1.9287, acc-0.4916, test loss-1.8951, acc-0.5093\n",
      "Iter-69620, train loss-1.9707, acc-0.3800, valid loss-1.9286, acc-0.4916, test loss-1.8951, acc-0.5093\n",
      "Iter-69630, train loss-1.9901, acc-0.4800, valid loss-1.9286, acc-0.4914, test loss-1.8951, acc-0.5093\n",
      "Iter-69640, train loss-1.9692, acc-0.4600, valid loss-1.9286, acc-0.4916, test loss-1.8950, acc-0.5092\n",
      "Iter-69650, train loss-1.9679, acc-0.4000, valid loss-1.9285, acc-0.4916, test loss-1.8950, acc-0.5091\n",
      "Iter-69660, train loss-1.9194, acc-0.5000, valid loss-1.9285, acc-0.4916, test loss-1.8950, acc-0.5090\n",
      "Iter-69670, train loss-1.9150, acc-0.5200, valid loss-1.9285, acc-0.4914, test loss-1.8949, acc-0.5091\n",
      "Iter-69680, train loss-1.8177, acc-0.5800, valid loss-1.9284, acc-0.4916, test loss-1.8949, acc-0.5090\n",
      "Iter-69690, train loss-1.9713, acc-0.4400, valid loss-1.9284, acc-0.4916, test loss-1.8949, acc-0.5091\n",
      "Iter-69700, train loss-1.8747, acc-0.5200, valid loss-1.9284, acc-0.4914, test loss-1.8948, acc-0.5093\n",
      "Iter-69710, train loss-1.8689, acc-0.4800, valid loss-1.9283, acc-0.4914, test loss-1.8948, acc-0.5094\n",
      "Iter-69720, train loss-1.8897, acc-0.6400, valid loss-1.9283, acc-0.4914, test loss-1.8947, acc-0.5094\n",
      "Iter-69730, train loss-1.9275, acc-0.4400, valid loss-1.9283, acc-0.4912, test loss-1.8947, acc-0.5094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-69740, train loss-1.9748, acc-0.4000, valid loss-1.9282, acc-0.4914, test loss-1.8947, acc-0.5094\n",
      "Iter-69750, train loss-1.8881, acc-0.5800, valid loss-1.9282, acc-0.4914, test loss-1.8946, acc-0.5094\n",
      "Iter-69760, train loss-1.8817, acc-0.5000, valid loss-1.9282, acc-0.4914, test loss-1.8946, acc-0.5092\n",
      "Iter-69770, train loss-1.9028, acc-0.5200, valid loss-1.9282, acc-0.4916, test loss-1.8946, acc-0.5093\n",
      "Iter-69780, train loss-1.9067, acc-0.4800, valid loss-1.9281, acc-0.4914, test loss-1.8945, acc-0.5093\n",
      "Iter-69790, train loss-1.9465, acc-0.4000, valid loss-1.9281, acc-0.4914, test loss-1.8945, acc-0.5091\n",
      "Iter-69800, train loss-1.9427, acc-0.3800, valid loss-1.9281, acc-0.4916, test loss-1.8945, acc-0.5095\n",
      "Iter-69810, train loss-1.9014, acc-0.5200, valid loss-1.9280, acc-0.4914, test loss-1.8944, acc-0.5094\n",
      "Iter-69820, train loss-1.9791, acc-0.3400, valid loss-1.9280, acc-0.4914, test loss-1.8944, acc-0.5095\n",
      "Iter-69830, train loss-1.8552, acc-0.5800, valid loss-1.9280, acc-0.4916, test loss-1.8944, acc-0.5095\n",
      "Iter-69840, train loss-1.9400, acc-0.5200, valid loss-1.9279, acc-0.4918, test loss-1.8943, acc-0.5096\n",
      "Iter-69850, train loss-1.8811, acc-0.5800, valid loss-1.9279, acc-0.4918, test loss-1.8943, acc-0.5096\n",
      "Iter-69860, train loss-1.8480, acc-0.5800, valid loss-1.9279, acc-0.4918, test loss-1.8942, acc-0.5096\n",
      "Iter-69870, train loss-1.8853, acc-0.5400, valid loss-1.9278, acc-0.4918, test loss-1.8942, acc-0.5096\n",
      "Iter-69880, train loss-1.9782, acc-0.4800, valid loss-1.9278, acc-0.4918, test loss-1.8942, acc-0.5096\n",
      "Iter-69890, train loss-1.8370, acc-0.5000, valid loss-1.9278, acc-0.4918, test loss-1.8941, acc-0.5095\n",
      "Iter-69900, train loss-1.8562, acc-0.6000, valid loss-1.9277, acc-0.4918, test loss-1.8941, acc-0.5096\n",
      "Iter-69910, train loss-1.9644, acc-0.4400, valid loss-1.9277, acc-0.4918, test loss-1.8941, acc-0.5095\n",
      "Iter-69920, train loss-1.8821, acc-0.5200, valid loss-1.9277, acc-0.4918, test loss-1.8940, acc-0.5093\n",
      "Iter-69930, train loss-1.9094, acc-0.5400, valid loss-1.9276, acc-0.4920, test loss-1.8940, acc-0.5093\n",
      "Iter-69940, train loss-1.9196, acc-0.5000, valid loss-1.9276, acc-0.4918, test loss-1.8940, acc-0.5093\n",
      "Iter-69950, train loss-1.9456, acc-0.5000, valid loss-1.9276, acc-0.4920, test loss-1.8939, acc-0.5093\n",
      "Iter-69960, train loss-1.8785, acc-0.5800, valid loss-1.9275, acc-0.4916, test loss-1.8939, acc-0.5094\n",
      "Iter-69970, train loss-1.9381, acc-0.4000, valid loss-1.9275, acc-0.4918, test loss-1.8938, acc-0.5094\n",
      "Iter-69980, train loss-1.8846, acc-0.5000, valid loss-1.9275, acc-0.4916, test loss-1.8938, acc-0.5094\n",
      "Iter-69990, train loss-1.9557, acc-0.5200, valid loss-1.9274, acc-0.4918, test loss-1.8938, acc-0.5094\n",
      "Iter-70000, train loss-1.9007, acc-0.4600, valid loss-1.9274, acc-0.4914, test loss-1.8937, acc-0.5095\n",
      "Iter-70010, train loss-1.8070, acc-0.6400, valid loss-1.9274, acc-0.4916, test loss-1.8937, acc-0.5094\n",
      "Iter-70020, train loss-1.8646, acc-0.4800, valid loss-1.9273, acc-0.4912, test loss-1.8937, acc-0.5093\n",
      "Iter-70030, train loss-1.9721, acc-0.3600, valid loss-1.9273, acc-0.4912, test loss-1.8936, acc-0.5093\n",
      "Iter-70040, train loss-1.9357, acc-0.4600, valid loss-1.9273, acc-0.4912, test loss-1.8936, acc-0.5094\n",
      "Iter-70050, train loss-1.7850, acc-0.5600, valid loss-1.9272, acc-0.4912, test loss-1.8936, acc-0.5094\n",
      "Iter-70060, train loss-1.9083, acc-0.5000, valid loss-1.9272, acc-0.4912, test loss-1.8935, acc-0.5094\n",
      "Iter-70070, train loss-1.8853, acc-0.5000, valid loss-1.9272, acc-0.4912, test loss-1.8935, acc-0.5094\n",
      "Iter-70080, train loss-1.8290, acc-0.6000, valid loss-1.9271, acc-0.4918, test loss-1.8934, acc-0.5094\n",
      "Iter-70090, train loss-1.8894, acc-0.5000, valid loss-1.9271, acc-0.4918, test loss-1.8934, acc-0.5093\n",
      "Iter-70100, train loss-1.9576, acc-0.4600, valid loss-1.9271, acc-0.4916, test loss-1.8934, acc-0.5093\n",
      "Iter-70110, train loss-1.8523, acc-0.5000, valid loss-1.9270, acc-0.4916, test loss-1.8933, acc-0.5092\n",
      "Iter-70120, train loss-1.8892, acc-0.4800, valid loss-1.9270, acc-0.4916, test loss-1.8933, acc-0.5092\n",
      "Iter-70130, train loss-2.0035, acc-0.4400, valid loss-1.9270, acc-0.4918, test loss-1.8933, acc-0.5091\n",
      "Iter-70140, train loss-1.9425, acc-0.5000, valid loss-1.9269, acc-0.4918, test loss-1.8932, acc-0.5091\n",
      "Iter-70150, train loss-1.9258, acc-0.4200, valid loss-1.9269, acc-0.4918, test loss-1.8932, acc-0.5091\n",
      "Iter-70160, train loss-1.9493, acc-0.4800, valid loss-1.9269, acc-0.4920, test loss-1.8932, acc-0.5092\n",
      "Iter-70170, train loss-1.9195, acc-0.4600, valid loss-1.9268, acc-0.4920, test loss-1.8931, acc-0.5093\n",
      "Iter-70180, train loss-1.8800, acc-0.5000, valid loss-1.9268, acc-0.4922, test loss-1.8931, acc-0.5093\n",
      "Iter-70190, train loss-1.9129, acc-0.5800, valid loss-1.9268, acc-0.4922, test loss-1.8930, acc-0.5091\n",
      "Iter-70200, train loss-1.9213, acc-0.4600, valid loss-1.9267, acc-0.4920, test loss-1.8930, acc-0.5093\n",
      "Iter-70210, train loss-1.9319, acc-0.4000, valid loss-1.9267, acc-0.4922, test loss-1.8930, acc-0.5093\n",
      "Iter-70220, train loss-1.9136, acc-0.4600, valid loss-1.9267, acc-0.4922, test loss-1.8929, acc-0.5093\n",
      "Iter-70230, train loss-1.8178, acc-0.6200, valid loss-1.9266, acc-0.4922, test loss-1.8929, acc-0.5093\n",
      "Iter-70240, train loss-1.9331, acc-0.3800, valid loss-1.9266, acc-0.4922, test loss-1.8929, acc-0.5094\n",
      "Iter-70250, train loss-1.8521, acc-0.4600, valid loss-1.9266, acc-0.4922, test loss-1.8928, acc-0.5093\n",
      "Iter-70260, train loss-2.0233, acc-0.3600, valid loss-1.9266, acc-0.4922, test loss-1.8928, acc-0.5094\n",
      "Iter-70270, train loss-1.8054, acc-0.6600, valid loss-1.9265, acc-0.4920, test loss-1.8928, acc-0.5093\n",
      "Iter-70280, train loss-1.8772, acc-0.4800, valid loss-1.9265, acc-0.4920, test loss-1.8927, acc-0.5093\n",
      "Iter-70290, train loss-1.9340, acc-0.4000, valid loss-1.9265, acc-0.4924, test loss-1.8927, acc-0.5094\n",
      "Iter-70300, train loss-1.9191, acc-0.4800, valid loss-1.9264, acc-0.4924, test loss-1.8926, acc-0.5094\n",
      "Iter-70310, train loss-1.8586, acc-0.5800, valid loss-1.9264, acc-0.4924, test loss-1.8926, acc-0.5094\n",
      "Iter-70320, train loss-1.8677, acc-0.5600, valid loss-1.9264, acc-0.4924, test loss-1.8926, acc-0.5094\n",
      "Iter-70330, train loss-1.8401, acc-0.5400, valid loss-1.9263, acc-0.4924, test loss-1.8925, acc-0.5094\n",
      "Iter-70340, train loss-1.9033, acc-0.4200, valid loss-1.9263, acc-0.4922, test loss-1.8925, acc-0.5094\n",
      "Iter-70350, train loss-1.9107, acc-0.5000, valid loss-1.9263, acc-0.4922, test loss-1.8925, acc-0.5095\n",
      "Iter-70360, train loss-1.9098, acc-0.4800, valid loss-1.9262, acc-0.4918, test loss-1.8924, acc-0.5094\n",
      "Iter-70370, train loss-1.8268, acc-0.7200, valid loss-1.9262, acc-0.4922, test loss-1.8924, acc-0.5093\n",
      "Iter-70380, train loss-1.8942, acc-0.4400, valid loss-1.9262, acc-0.4922, test loss-1.8924, acc-0.5093\n",
      "Iter-70390, train loss-1.9488, acc-0.4600, valid loss-1.9261, acc-0.4922, test loss-1.8923, acc-0.5092\n",
      "Iter-70400, train loss-1.8281, acc-0.4600, valid loss-1.9261, acc-0.4924, test loss-1.8923, acc-0.5094\n",
      "Iter-70410, train loss-1.9433, acc-0.4200, valid loss-1.9261, acc-0.4924, test loss-1.8922, acc-0.5093\n",
      "Iter-70420, train loss-1.8999, acc-0.6000, valid loss-1.9260, acc-0.4920, test loss-1.8922, acc-0.5093\n",
      "Iter-70430, train loss-1.8570, acc-0.5400, valid loss-1.9260, acc-0.4922, test loss-1.8922, acc-0.5093\n",
      "Iter-70440, train loss-1.9597, acc-0.4800, valid loss-1.9260, acc-0.4922, test loss-1.8921, acc-0.5093\n",
      "Iter-70450, train loss-1.8853, acc-0.6000, valid loss-1.9259, acc-0.4924, test loss-1.8921, acc-0.5093\n",
      "Iter-70460, train loss-1.9360, acc-0.4000, valid loss-1.9259, acc-0.4924, test loss-1.8921, acc-0.5094\n",
      "Iter-70470, train loss-1.8587, acc-0.5000, valid loss-1.9259, acc-0.4924, test loss-1.8920, acc-0.5095\n",
      "Iter-70480, train loss-1.9015, acc-0.5200, valid loss-1.9258, acc-0.4924, test loss-1.8920, acc-0.5094\n",
      "Iter-70490, train loss-1.9100, acc-0.5200, valid loss-1.9258, acc-0.4924, test loss-1.8919, acc-0.5094\n",
      "Iter-70500, train loss-1.8390, acc-0.5800, valid loss-1.9257, acc-0.4924, test loss-1.8919, acc-0.5095\n",
      "Iter-70510, train loss-1.9093, acc-0.5400, valid loss-1.9257, acc-0.4924, test loss-1.8919, acc-0.5095\n",
      "Iter-70520, train loss-1.9463, acc-0.4800, valid loss-1.9257, acc-0.4924, test loss-1.8918, acc-0.5097\n",
      "Iter-70530, train loss-1.8807, acc-0.4600, valid loss-1.9257, acc-0.4924, test loss-1.8918, acc-0.5097\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-70540, train loss-1.8772, acc-0.5200, valid loss-1.9256, acc-0.4924, test loss-1.8918, acc-0.5097\n",
      "Iter-70550, train loss-1.9675, acc-0.4000, valid loss-1.9256, acc-0.4926, test loss-1.8917, acc-0.5097\n",
      "Iter-70560, train loss-1.8310, acc-0.6000, valid loss-1.9256, acc-0.4924, test loss-1.8917, acc-0.5096\n",
      "Iter-70570, train loss-1.9335, acc-0.5200, valid loss-1.9255, acc-0.4924, test loss-1.8917, acc-0.5095\n",
      "Iter-70580, train loss-1.8856, acc-0.5200, valid loss-1.9255, acc-0.4926, test loss-1.8916, acc-0.5095\n",
      "Iter-70590, train loss-1.9510, acc-0.5400, valid loss-1.9255, acc-0.4924, test loss-1.8916, acc-0.5095\n",
      "Iter-70600, train loss-1.8461, acc-0.5600, valid loss-1.9254, acc-0.4926, test loss-1.8915, acc-0.5096\n",
      "Iter-70610, train loss-1.8737, acc-0.5600, valid loss-1.9254, acc-0.4924, test loss-1.8915, acc-0.5096\n",
      "Iter-70620, train loss-1.9113, acc-0.5400, valid loss-1.9254, acc-0.4926, test loss-1.8915, acc-0.5096\n",
      "Iter-70630, train loss-1.8666, acc-0.6200, valid loss-1.9253, acc-0.4924, test loss-1.8914, acc-0.5096\n",
      "Iter-70640, train loss-1.9203, acc-0.4800, valid loss-1.9253, acc-0.4924, test loss-1.8914, acc-0.5096\n",
      "Iter-70650, train loss-1.9030, acc-0.5400, valid loss-1.9253, acc-0.4924, test loss-1.8914, acc-0.5097\n",
      "Iter-70660, train loss-1.8855, acc-0.5400, valid loss-1.9252, acc-0.4924, test loss-1.8913, acc-0.5097\n",
      "Iter-70670, train loss-1.9603, acc-0.4000, valid loss-1.9252, acc-0.4924, test loss-1.8913, acc-0.5098\n",
      "Iter-70680, train loss-1.9406, acc-0.4200, valid loss-1.9252, acc-0.4924, test loss-1.8913, acc-0.5098\n",
      "Iter-70690, train loss-1.8668, acc-0.5200, valid loss-1.9251, acc-0.4922, test loss-1.8912, acc-0.5098\n",
      "Iter-70700, train loss-1.8100, acc-0.6800, valid loss-1.9251, acc-0.4922, test loss-1.8912, acc-0.5098\n",
      "Iter-70710, train loss-1.9668, acc-0.3800, valid loss-1.9251, acc-0.4922, test loss-1.8912, acc-0.5097\n",
      "Iter-70720, train loss-1.8569, acc-0.5400, valid loss-1.9250, acc-0.4924, test loss-1.8911, acc-0.5097\n",
      "Iter-70730, train loss-1.8557, acc-0.4000, valid loss-1.9250, acc-0.4924, test loss-1.8911, acc-0.5097\n",
      "Iter-70740, train loss-1.9183, acc-0.5000, valid loss-1.9250, acc-0.4924, test loss-1.8911, acc-0.5096\n",
      "Iter-70750, train loss-1.9214, acc-0.4800, valid loss-1.9249, acc-0.4922, test loss-1.8910, acc-0.5098\n",
      "Iter-70760, train loss-1.8126, acc-0.6400, valid loss-1.9249, acc-0.4922, test loss-1.8910, acc-0.5100\n",
      "Iter-70770, train loss-1.8801, acc-0.6200, valid loss-1.9249, acc-0.4922, test loss-1.8909, acc-0.5100\n",
      "Iter-70780, train loss-1.8687, acc-0.5800, valid loss-1.9248, acc-0.4922, test loss-1.8909, acc-0.5098\n",
      "Iter-70790, train loss-1.8458, acc-0.6000, valid loss-1.9248, acc-0.4922, test loss-1.8909, acc-0.5098\n",
      "Iter-70800, train loss-1.9009, acc-0.5400, valid loss-1.9248, acc-0.4920, test loss-1.8908, acc-0.5097\n",
      "Iter-70810, train loss-1.8229, acc-0.5600, valid loss-1.9247, acc-0.4920, test loss-1.8908, acc-0.5097\n",
      "Iter-70820, train loss-1.8945, acc-0.4800, valid loss-1.9247, acc-0.4922, test loss-1.8908, acc-0.5099\n",
      "Iter-70830, train loss-1.7889, acc-0.5600, valid loss-1.9247, acc-0.4920, test loss-1.8907, acc-0.5099\n",
      "Iter-70840, train loss-1.8919, acc-0.5000, valid loss-1.9246, acc-0.4922, test loss-1.8907, acc-0.5099\n",
      "Iter-70850, train loss-1.8302, acc-0.5200, valid loss-1.9246, acc-0.4922, test loss-1.8907, acc-0.5099\n",
      "Iter-70860, train loss-1.8232, acc-0.6000, valid loss-1.9246, acc-0.4922, test loss-1.8906, acc-0.5097\n",
      "Iter-70870, train loss-1.9501, acc-0.4200, valid loss-1.9245, acc-0.4920, test loss-1.8906, acc-0.5095\n",
      "Iter-70880, train loss-1.8840, acc-0.5200, valid loss-1.9245, acc-0.4922, test loss-1.8905, acc-0.5098\n",
      "Iter-70890, train loss-1.8866, acc-0.4800, valid loss-1.9245, acc-0.4924, test loss-1.8905, acc-0.5096\n",
      "Iter-70900, train loss-1.9701, acc-0.5000, valid loss-1.9244, acc-0.4924, test loss-1.8905, acc-0.5097\n",
      "Iter-70910, train loss-1.9137, acc-0.4800, valid loss-1.9244, acc-0.4926, test loss-1.8904, acc-0.5098\n",
      "Iter-70920, train loss-1.8354, acc-0.5200, valid loss-1.9244, acc-0.4924, test loss-1.8904, acc-0.5098\n",
      "Iter-70930, train loss-1.9688, acc-0.4200, valid loss-1.9243, acc-0.4926, test loss-1.8904, acc-0.5101\n",
      "Iter-70940, train loss-1.9434, acc-0.3600, valid loss-1.9243, acc-0.4924, test loss-1.8903, acc-0.5100\n",
      "Iter-70950, train loss-1.8904, acc-0.4400, valid loss-1.9243, acc-0.4926, test loss-1.8903, acc-0.5099\n",
      "Iter-70960, train loss-1.8918, acc-0.6400, valid loss-1.9242, acc-0.4924, test loss-1.8903, acc-0.5099\n",
      "Iter-70970, train loss-2.0187, acc-0.4400, valid loss-1.9242, acc-0.4924, test loss-1.8902, acc-0.5097\n",
      "Iter-70980, train loss-1.9305, acc-0.4000, valid loss-1.9242, acc-0.4924, test loss-1.8902, acc-0.5097\n",
      "Iter-70990, train loss-1.9047, acc-0.5600, valid loss-1.9241, acc-0.4924, test loss-1.8902, acc-0.5098\n",
      "Iter-71000, train loss-1.8644, acc-0.5000, valid loss-1.9241, acc-0.4924, test loss-1.8901, acc-0.5098\n",
      "Iter-71010, train loss-1.9362, acc-0.5000, valid loss-1.9241, acc-0.4926, test loss-1.8901, acc-0.5099\n",
      "Iter-71020, train loss-1.8770, acc-0.5200, valid loss-1.9240, acc-0.4926, test loss-1.8900, acc-0.5101\n",
      "Iter-71030, train loss-1.9190, acc-0.4600, valid loss-1.9240, acc-0.4926, test loss-1.8900, acc-0.5100\n",
      "Iter-71040, train loss-1.9513, acc-0.4400, valid loss-1.9240, acc-0.4926, test loss-1.8900, acc-0.5098\n",
      "Iter-71050, train loss-1.9597, acc-0.3200, valid loss-1.9239, acc-0.4926, test loss-1.8899, acc-0.5098\n",
      "Iter-71060, train loss-1.8994, acc-0.4400, valid loss-1.9239, acc-0.4926, test loss-1.8899, acc-0.5098\n",
      "Iter-71070, train loss-1.9157, acc-0.5000, valid loss-1.9239, acc-0.4926, test loss-1.8899, acc-0.5098\n",
      "Iter-71080, train loss-1.8388, acc-0.4800, valid loss-1.9238, acc-0.4926, test loss-1.8898, acc-0.5098\n",
      "Iter-71090, train loss-1.8068, acc-0.5800, valid loss-1.9238, acc-0.4926, test loss-1.8898, acc-0.5098\n",
      "Iter-71100, train loss-1.8683, acc-0.5800, valid loss-1.9238, acc-0.4926, test loss-1.8898, acc-0.5098\n",
      "Iter-71110, train loss-1.8548, acc-0.4600, valid loss-1.9238, acc-0.4926, test loss-1.8897, acc-0.5098\n",
      "Iter-71120, train loss-1.9707, acc-0.4400, valid loss-1.9237, acc-0.4926, test loss-1.8897, acc-0.5098\n",
      "Iter-71130, train loss-1.8651, acc-0.5200, valid loss-1.9237, acc-0.4926, test loss-1.8897, acc-0.5099\n",
      "Iter-71140, train loss-1.9343, acc-0.4600, valid loss-1.9237, acc-0.4926, test loss-1.8896, acc-0.5099\n",
      "Iter-71150, train loss-1.8575, acc-0.5400, valid loss-1.9236, acc-0.4926, test loss-1.8896, acc-0.5099\n",
      "Iter-71160, train loss-1.8680, acc-0.5800, valid loss-1.9236, acc-0.4926, test loss-1.8895, acc-0.5100\n",
      "Iter-71170, train loss-1.9914, acc-0.4000, valid loss-1.9236, acc-0.4926, test loss-1.8895, acc-0.5099\n",
      "Iter-71180, train loss-1.8812, acc-0.4800, valid loss-1.9235, acc-0.4924, test loss-1.8895, acc-0.5099\n",
      "Iter-71190, train loss-1.8849, acc-0.5200, valid loss-1.9235, acc-0.4926, test loss-1.8894, acc-0.5099\n",
      "Iter-71200, train loss-1.8815, acc-0.6000, valid loss-1.9235, acc-0.4924, test loss-1.8894, acc-0.5100\n",
      "Iter-71210, train loss-1.8442, acc-0.5600, valid loss-1.9234, acc-0.4924, test loss-1.8894, acc-0.5099\n",
      "Iter-71220, train loss-1.9034, acc-0.5200, valid loss-1.9234, acc-0.4924, test loss-1.8893, acc-0.5100\n",
      "Iter-71230, train loss-1.8835, acc-0.5200, valid loss-1.9234, acc-0.4924, test loss-1.8893, acc-0.5100\n",
      "Iter-71240, train loss-1.9119, acc-0.5600, valid loss-1.9233, acc-0.4924, test loss-1.8893, acc-0.5100\n",
      "Iter-71250, train loss-1.9189, acc-0.3800, valid loss-1.9233, acc-0.4924, test loss-1.8892, acc-0.5098\n",
      "Iter-71260, train loss-1.9431, acc-0.4400, valid loss-1.9233, acc-0.4924, test loss-1.8892, acc-0.5099\n",
      "Iter-71270, train loss-1.8837, acc-0.5000, valid loss-1.9232, acc-0.4924, test loss-1.8892, acc-0.5099\n",
      "Iter-71280, train loss-1.8820, acc-0.5400, valid loss-1.9232, acc-0.4924, test loss-1.8891, acc-0.5099\n",
      "Iter-71290, train loss-1.9223, acc-0.5000, valid loss-1.9232, acc-0.4924, test loss-1.8891, acc-0.5100\n",
      "Iter-71300, train loss-1.9231, acc-0.4200, valid loss-1.9231, acc-0.4924, test loss-1.8891, acc-0.5100\n",
      "Iter-71310, train loss-1.8553, acc-0.5600, valid loss-1.9231, acc-0.4922, test loss-1.8890, acc-0.5100\n",
      "Iter-71320, train loss-1.9943, acc-0.3200, valid loss-1.9231, acc-0.4922, test loss-1.8890, acc-0.5098\n",
      "Iter-71330, train loss-1.8822, acc-0.4600, valid loss-1.9231, acc-0.4922, test loss-1.8889, acc-0.5099\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-71340, train loss-1.8799, acc-0.6000, valid loss-1.9230, acc-0.4920, test loss-1.8889, acc-0.5102\n",
      "Iter-71350, train loss-1.9784, acc-0.4200, valid loss-1.9230, acc-0.4920, test loss-1.8889, acc-0.5101\n",
      "Iter-71360, train loss-1.9051, acc-0.4400, valid loss-1.9230, acc-0.4922, test loss-1.8888, acc-0.5101\n",
      "Iter-71370, train loss-1.8970, acc-0.5000, valid loss-1.9229, acc-0.4922, test loss-1.8888, acc-0.5102\n",
      "Iter-71380, train loss-1.8675, acc-0.4800, valid loss-1.9229, acc-0.4920, test loss-1.8888, acc-0.5100\n",
      "Iter-71390, train loss-1.8675, acc-0.5800, valid loss-1.9229, acc-0.4922, test loss-1.8887, acc-0.5101\n",
      "Iter-71400, train loss-1.9287, acc-0.4800, valid loss-1.9228, acc-0.4918, test loss-1.8887, acc-0.5103\n",
      "Iter-71410, train loss-1.9163, acc-0.5000, valid loss-1.9228, acc-0.4918, test loss-1.8887, acc-0.5100\n",
      "Iter-71420, train loss-1.9055, acc-0.6000, valid loss-1.9228, acc-0.4920, test loss-1.8886, acc-0.5101\n",
      "Iter-71430, train loss-2.0293, acc-0.4000, valid loss-1.9227, acc-0.4920, test loss-1.8886, acc-0.5100\n",
      "Iter-71440, train loss-1.8538, acc-0.5600, valid loss-1.9227, acc-0.4922, test loss-1.8886, acc-0.5101\n",
      "Iter-71450, train loss-1.8247, acc-0.6400, valid loss-1.9227, acc-0.4920, test loss-1.8885, acc-0.5101\n",
      "Iter-71460, train loss-1.9038, acc-0.4600, valid loss-1.9226, acc-0.4920, test loss-1.8885, acc-0.5101\n",
      "Iter-71470, train loss-1.8740, acc-0.5200, valid loss-1.9226, acc-0.4920, test loss-1.8885, acc-0.5101\n",
      "Iter-71480, train loss-1.9561, acc-0.4200, valid loss-1.9226, acc-0.4918, test loss-1.8884, acc-0.5102\n",
      "Iter-71490, train loss-1.8958, acc-0.5200, valid loss-1.9225, acc-0.4920, test loss-1.8884, acc-0.5101\n",
      "Iter-71500, train loss-1.9365, acc-0.3800, valid loss-1.9225, acc-0.4922, test loss-1.8884, acc-0.5102\n",
      "Iter-71510, train loss-1.8895, acc-0.4800, valid loss-1.9225, acc-0.4918, test loss-1.8883, acc-0.5101\n",
      "Iter-71520, train loss-1.9990, acc-0.5200, valid loss-1.9224, acc-0.4920, test loss-1.8883, acc-0.5100\n",
      "Iter-71530, train loss-1.9386, acc-0.5000, valid loss-1.9224, acc-0.4922, test loss-1.8882, acc-0.5099\n",
      "Iter-71540, train loss-1.9158, acc-0.5200, valid loss-1.9224, acc-0.4920, test loss-1.8882, acc-0.5100\n",
      "Iter-71550, train loss-1.9254, acc-0.5200, valid loss-1.9223, acc-0.4920, test loss-1.8882, acc-0.5100\n",
      "Iter-71560, train loss-1.8819, acc-0.5600, valid loss-1.9223, acc-0.4922, test loss-1.8881, acc-0.5099\n",
      "Iter-71570, train loss-1.9222, acc-0.4400, valid loss-1.9223, acc-0.4916, test loss-1.8881, acc-0.5100\n",
      "Iter-71580, train loss-1.9252, acc-0.5200, valid loss-1.9223, acc-0.4920, test loss-1.8881, acc-0.5099\n",
      "Iter-71590, train loss-1.8195, acc-0.6200, valid loss-1.9222, acc-0.4920, test loss-1.8880, acc-0.5098\n",
      "Iter-71600, train loss-1.8871, acc-0.5400, valid loss-1.9222, acc-0.4920, test loss-1.8880, acc-0.5099\n",
      "Iter-71610, train loss-1.8511, acc-0.5200, valid loss-1.9222, acc-0.4918, test loss-1.8880, acc-0.5099\n",
      "Iter-71620, train loss-1.9869, acc-0.4200, valid loss-1.9221, acc-0.4920, test loss-1.8879, acc-0.5099\n",
      "Iter-71630, train loss-2.0067, acc-0.4000, valid loss-1.9221, acc-0.4918, test loss-1.8879, acc-0.5099\n",
      "Iter-71640, train loss-1.9336, acc-0.5400, valid loss-1.9220, acc-0.4918, test loss-1.8879, acc-0.5099\n",
      "Iter-71650, train loss-1.8577, acc-0.4800, valid loss-1.9220, acc-0.4918, test loss-1.8878, acc-0.5099\n",
      "Iter-71660, train loss-1.8232, acc-0.6000, valid loss-1.9220, acc-0.4918, test loss-1.8878, acc-0.5099\n",
      "Iter-71670, train loss-1.8718, acc-0.5000, valid loss-1.9219, acc-0.4918, test loss-1.8877, acc-0.5100\n",
      "Iter-71680, train loss-1.9349, acc-0.4800, valid loss-1.9219, acc-0.4918, test loss-1.8877, acc-0.5098\n",
      "Iter-71690, train loss-1.9142, acc-0.4200, valid loss-1.9219, acc-0.4916, test loss-1.8877, acc-0.5098\n",
      "Iter-71700, train loss-1.9463, acc-0.3400, valid loss-1.9219, acc-0.4916, test loss-1.8876, acc-0.5099\n",
      "Iter-71710, train loss-2.0051, acc-0.4400, valid loss-1.9218, acc-0.4916, test loss-1.8876, acc-0.5100\n",
      "Iter-71720, train loss-2.0579, acc-0.3800, valid loss-1.9218, acc-0.4916, test loss-1.8876, acc-0.5100\n",
      "Iter-71730, train loss-1.9588, acc-0.5000, valid loss-1.9218, acc-0.4914, test loss-1.8875, acc-0.5100\n",
      "Iter-71740, train loss-1.9621, acc-0.3800, valid loss-1.9217, acc-0.4916, test loss-1.8875, acc-0.5100\n",
      "Iter-71750, train loss-1.8813, acc-0.6200, valid loss-1.9217, acc-0.4914, test loss-1.8875, acc-0.5099\n",
      "Iter-71760, train loss-1.9103, acc-0.4800, valid loss-1.9217, acc-0.4914, test loss-1.8874, acc-0.5100\n",
      "Iter-71770, train loss-1.8429, acc-0.6200, valid loss-1.9216, acc-0.4912, test loss-1.8874, acc-0.5100\n",
      "Iter-71780, train loss-1.9814, acc-0.4800, valid loss-1.9216, acc-0.4914, test loss-1.8874, acc-0.5099\n",
      "Iter-71790, train loss-1.9038, acc-0.5200, valid loss-1.9216, acc-0.4918, test loss-1.8873, acc-0.5100\n",
      "Iter-71800, train loss-1.9307, acc-0.4400, valid loss-1.9215, acc-0.4916, test loss-1.8873, acc-0.5101\n",
      "Iter-71810, train loss-1.9695, acc-0.3800, valid loss-1.9215, acc-0.4918, test loss-1.8873, acc-0.5100\n",
      "Iter-71820, train loss-1.9151, acc-0.4000, valid loss-1.9215, acc-0.4918, test loss-1.8872, acc-0.5101\n",
      "Iter-71830, train loss-1.8228, acc-0.5200, valid loss-1.9214, acc-0.4918, test loss-1.8872, acc-0.5100\n",
      "Iter-71840, train loss-1.8229, acc-0.5000, valid loss-1.9214, acc-0.4918, test loss-1.8871, acc-0.5102\n",
      "Iter-71850, train loss-1.8378, acc-0.5400, valid loss-1.9214, acc-0.4920, test loss-1.8871, acc-0.5102\n",
      "Iter-71860, train loss-1.8505, acc-0.4800, valid loss-1.9213, acc-0.4922, test loss-1.8871, acc-0.5103\n",
      "Iter-71870, train loss-1.7986, acc-0.6400, valid loss-1.9213, acc-0.4924, test loss-1.8870, acc-0.5103\n",
      "Iter-71880, train loss-1.8954, acc-0.4800, valid loss-1.9213, acc-0.4924, test loss-1.8870, acc-0.5101\n",
      "Iter-71890, train loss-1.8942, acc-0.4800, valid loss-1.9212, acc-0.4924, test loss-1.8870, acc-0.5102\n",
      "Iter-71900, train loss-1.8909, acc-0.4200, valid loss-1.9212, acc-0.4924, test loss-1.8869, acc-0.5102\n",
      "Iter-71910, train loss-1.9440, acc-0.4200, valid loss-1.9212, acc-0.4926, test loss-1.8869, acc-0.5102\n",
      "Iter-71920, train loss-1.9067, acc-0.4800, valid loss-1.9211, acc-0.4924, test loss-1.8869, acc-0.5103\n",
      "Iter-71930, train loss-1.9899, acc-0.4200, valid loss-1.9211, acc-0.4926, test loss-1.8868, acc-0.5103\n",
      "Iter-71940, train loss-1.8343, acc-0.5200, valid loss-1.9211, acc-0.4922, test loss-1.8868, acc-0.5103\n",
      "Iter-71950, train loss-1.9939, acc-0.5200, valid loss-1.9210, acc-0.4922, test loss-1.8868, acc-0.5103\n",
      "Iter-71960, train loss-1.8983, acc-0.4600, valid loss-1.9210, acc-0.4926, test loss-1.8867, acc-0.5105\n",
      "Iter-71970, train loss-1.8721, acc-0.6000, valid loss-1.9210, acc-0.4926, test loss-1.8867, acc-0.5104\n",
      "Iter-71980, train loss-1.9764, acc-0.3600, valid loss-1.9209, acc-0.4924, test loss-1.8867, acc-0.5104\n",
      "Iter-71990, train loss-1.9507, acc-0.4600, valid loss-1.9209, acc-0.4922, test loss-1.8866, acc-0.5104\n",
      "Iter-72000, train loss-1.8563, acc-0.5000, valid loss-1.9209, acc-0.4920, test loss-1.8866, acc-0.5103\n",
      "Iter-72010, train loss-1.8779, acc-0.4600, valid loss-1.9208, acc-0.4920, test loss-1.8865, acc-0.5103\n",
      "Iter-72020, train loss-1.9380, acc-0.5200, valid loss-1.9208, acc-0.4922, test loss-1.8865, acc-0.5104\n",
      "Iter-72030, train loss-1.9289, acc-0.4600, valid loss-1.9208, acc-0.4922, test loss-1.8865, acc-0.5104\n",
      "Iter-72040, train loss-1.9387, acc-0.4400, valid loss-1.9207, acc-0.4920, test loss-1.8864, acc-0.5103\n",
      "Iter-72050, train loss-1.9132, acc-0.4800, valid loss-1.9207, acc-0.4920, test loss-1.8864, acc-0.5102\n",
      "Iter-72060, train loss-1.9133, acc-0.5000, valid loss-1.9207, acc-0.4920, test loss-1.8864, acc-0.5103\n",
      "Iter-72070, train loss-1.8793, acc-0.4400, valid loss-1.9207, acc-0.4920, test loss-1.8863, acc-0.5101\n",
      "Iter-72080, train loss-1.9106, acc-0.5200, valid loss-1.9206, acc-0.4918, test loss-1.8863, acc-0.5102\n",
      "Iter-72090, train loss-1.9769, acc-0.4200, valid loss-1.9206, acc-0.4920, test loss-1.8863, acc-0.5101\n",
      "Iter-72100, train loss-1.8360, acc-0.5000, valid loss-1.9206, acc-0.4920, test loss-1.8862, acc-0.5103\n",
      "Iter-72110, train loss-2.0080, acc-0.3000, valid loss-1.9205, acc-0.4924, test loss-1.8862, acc-0.5101\n",
      "Iter-72120, train loss-1.8213, acc-0.5000, valid loss-1.9205, acc-0.4920, test loss-1.8862, acc-0.5102\n",
      "Iter-72130, train loss-1.9260, acc-0.4200, valid loss-1.9205, acc-0.4920, test loss-1.8861, acc-0.5103\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-72140, train loss-1.9013, acc-0.4400, valid loss-1.9204, acc-0.4922, test loss-1.8861, acc-0.5102\n",
      "Iter-72150, train loss-1.8601, acc-0.4800, valid loss-1.9204, acc-0.4922, test loss-1.8861, acc-0.5103\n",
      "Iter-72160, train loss-1.8402, acc-0.5800, valid loss-1.9204, acc-0.4920, test loss-1.8860, acc-0.5101\n",
      "Iter-72170, train loss-1.8584, acc-0.6000, valid loss-1.9203, acc-0.4922, test loss-1.8860, acc-0.5102\n",
      "Iter-72180, train loss-1.8828, acc-0.4400, valid loss-1.9203, acc-0.4924, test loss-1.8859, acc-0.5103\n",
      "Iter-72190, train loss-1.8627, acc-0.5600, valid loss-1.9203, acc-0.4924, test loss-1.8859, acc-0.5103\n",
      "Iter-72200, train loss-1.8448, acc-0.5400, valid loss-1.9202, acc-0.4922, test loss-1.8859, acc-0.5104\n",
      "Iter-72210, train loss-1.8973, acc-0.5400, valid loss-1.9202, acc-0.4922, test loss-1.8858, acc-0.5103\n",
      "Iter-72220, train loss-1.9303, acc-0.4800, valid loss-1.9202, acc-0.4920, test loss-1.8858, acc-0.5102\n",
      "Iter-72230, train loss-1.8997, acc-0.5400, valid loss-1.9201, acc-0.4920, test loss-1.8858, acc-0.5104\n",
      "Iter-72240, train loss-1.9643, acc-0.3800, valid loss-1.9201, acc-0.4920, test loss-1.8857, acc-0.5104\n",
      "Iter-72250, train loss-1.8742, acc-0.4600, valid loss-1.9201, acc-0.4922, test loss-1.8857, acc-0.5105\n",
      "Iter-72260, train loss-1.8396, acc-0.5200, valid loss-1.9200, acc-0.4920, test loss-1.8857, acc-0.5105\n",
      "Iter-72270, train loss-1.8533, acc-0.5000, valid loss-1.9200, acc-0.4924, test loss-1.8856, acc-0.5103\n",
      "Iter-72280, train loss-1.8930, acc-0.5200, valid loss-1.9200, acc-0.4922, test loss-1.8856, acc-0.5104\n",
      "Iter-72290, train loss-1.9874, acc-0.3400, valid loss-1.9199, acc-0.4922, test loss-1.8856, acc-0.5104\n",
      "Iter-72300, train loss-1.8952, acc-0.4800, valid loss-1.9199, acc-0.4922, test loss-1.8855, acc-0.5104\n",
      "Iter-72310, train loss-1.8490, acc-0.5400, valid loss-1.9199, acc-0.4922, test loss-1.8855, acc-0.5104\n",
      "Iter-72320, train loss-1.8247, acc-0.6400, valid loss-1.9198, acc-0.4924, test loss-1.8854, acc-0.5104\n",
      "Iter-72330, train loss-1.9000, acc-0.5800, valid loss-1.9198, acc-0.4924, test loss-1.8854, acc-0.5104\n",
      "Iter-72340, train loss-1.9241, acc-0.5400, valid loss-1.9198, acc-0.4922, test loss-1.8854, acc-0.5103\n",
      "Iter-72350, train loss-1.9777, acc-0.4600, valid loss-1.9197, acc-0.4922, test loss-1.8853, acc-0.5104\n",
      "Iter-72360, train loss-1.8921, acc-0.5600, valid loss-1.9197, acc-0.4924, test loss-1.8853, acc-0.5103\n",
      "Iter-72370, train loss-1.8706, acc-0.5000, valid loss-1.9197, acc-0.4922, test loss-1.8853, acc-0.5103\n",
      "Iter-72380, train loss-1.9845, acc-0.5200, valid loss-1.9196, acc-0.4922, test loss-1.8852, acc-0.5104\n",
      "Iter-72390, train loss-1.8538, acc-0.5600, valid loss-1.9196, acc-0.4920, test loss-1.8852, acc-0.5104\n",
      "Iter-72400, train loss-1.9110, acc-0.5200, valid loss-1.9196, acc-0.4922, test loss-1.8852, acc-0.5104\n",
      "Iter-72410, train loss-1.8833, acc-0.4200, valid loss-1.9195, acc-0.4924, test loss-1.8851, acc-0.5104\n",
      "Iter-72420, train loss-1.8518, acc-0.5800, valid loss-1.9195, acc-0.4922, test loss-1.8851, acc-0.5104\n",
      "Iter-72430, train loss-1.8959, acc-0.5000, valid loss-1.9195, acc-0.4924, test loss-1.8851, acc-0.5104\n",
      "Iter-72440, train loss-1.9027, acc-0.6000, valid loss-1.9194, acc-0.4926, test loss-1.8850, acc-0.5104\n",
      "Iter-72450, train loss-1.8687, acc-0.4000, valid loss-1.9194, acc-0.4926, test loss-1.8850, acc-0.5105\n",
      "Iter-72460, train loss-1.9121, acc-0.4600, valid loss-1.9194, acc-0.4926, test loss-1.8850, acc-0.5105\n",
      "Iter-72470, train loss-1.8366, acc-0.6000, valid loss-1.9194, acc-0.4926, test loss-1.8849, acc-0.5105\n",
      "Iter-72480, train loss-1.8633, acc-0.5200, valid loss-1.9193, acc-0.4926, test loss-1.8849, acc-0.5104\n",
      "Iter-72490, train loss-1.8458, acc-0.6000, valid loss-1.9193, acc-0.4924, test loss-1.8848, acc-0.5105\n",
      "Iter-72500, train loss-1.8532, acc-0.5600, valid loss-1.9192, acc-0.4924, test loss-1.8848, acc-0.5106\n",
      "Iter-72510, train loss-1.8935, acc-0.5600, valid loss-1.9192, acc-0.4926, test loss-1.8848, acc-0.5105\n",
      "Iter-72520, train loss-1.8968, acc-0.5400, valid loss-1.9192, acc-0.4928, test loss-1.8847, acc-0.5106\n",
      "Iter-72530, train loss-1.8229, acc-0.5800, valid loss-1.9191, acc-0.4924, test loss-1.8847, acc-0.5105\n",
      "Iter-72540, train loss-1.9887, acc-0.3800, valid loss-1.9191, acc-0.4924, test loss-1.8847, acc-0.5106\n",
      "Iter-72550, train loss-1.9054, acc-0.5000, valid loss-1.9191, acc-0.4924, test loss-1.8846, acc-0.5105\n",
      "Iter-72560, train loss-1.9226, acc-0.4600, valid loss-1.9190, acc-0.4924, test loss-1.8846, acc-0.5105\n",
      "Iter-72570, train loss-1.9702, acc-0.5200, valid loss-1.9190, acc-0.4926, test loss-1.8846, acc-0.5105\n",
      "Iter-72580, train loss-1.9458, acc-0.4600, valid loss-1.9190, acc-0.4926, test loss-1.8845, acc-0.5105\n",
      "Iter-72590, train loss-1.8928, acc-0.4600, valid loss-1.9190, acc-0.4924, test loss-1.8845, acc-0.5106\n",
      "Iter-72600, train loss-2.0012, acc-0.4400, valid loss-1.9189, acc-0.4928, test loss-1.8845, acc-0.5106\n",
      "Iter-72610, train loss-1.8526, acc-0.5800, valid loss-1.9189, acc-0.4926, test loss-1.8844, acc-0.5105\n",
      "Iter-72620, train loss-1.8085, acc-0.5400, valid loss-1.9189, acc-0.4926, test loss-1.8844, acc-0.5107\n",
      "Iter-72630, train loss-1.9461, acc-0.5200, valid loss-1.9188, acc-0.4928, test loss-1.8843, acc-0.5107\n",
      "Iter-72640, train loss-1.9872, acc-0.3800, valid loss-1.9188, acc-0.4930, test loss-1.8843, acc-0.5107\n",
      "Iter-72650, train loss-1.9025, acc-0.5200, valid loss-1.9188, acc-0.4928, test loss-1.8843, acc-0.5107\n",
      "Iter-72660, train loss-1.8990, acc-0.5000, valid loss-1.9187, acc-0.4930, test loss-1.8842, acc-0.5107\n",
      "Iter-72670, train loss-1.9418, acc-0.4200, valid loss-1.9187, acc-0.4928, test loss-1.8842, acc-0.5105\n",
      "Iter-72680, train loss-1.8871, acc-0.6400, valid loss-1.9187, acc-0.4928, test loss-1.8842, acc-0.5107\n",
      "Iter-72690, train loss-2.0169, acc-0.4000, valid loss-1.9186, acc-0.4928, test loss-1.8841, acc-0.5105\n",
      "Iter-72700, train loss-1.8633, acc-0.5400, valid loss-1.9186, acc-0.4928, test loss-1.8841, acc-0.5108\n",
      "Iter-72710, train loss-1.8868, acc-0.5400, valid loss-1.9186, acc-0.4926, test loss-1.8841, acc-0.5107\n",
      "Iter-72720, train loss-1.8860, acc-0.4600, valid loss-1.9185, acc-0.4926, test loss-1.8840, acc-0.5108\n",
      "Iter-72730, train loss-1.9209, acc-0.5400, valid loss-1.9185, acc-0.4930, test loss-1.8840, acc-0.5108\n",
      "Iter-72740, train loss-1.8774, acc-0.5400, valid loss-1.9185, acc-0.4930, test loss-1.8840, acc-0.5108\n",
      "Iter-72750, train loss-1.9145, acc-0.4800, valid loss-1.9184, acc-0.4930, test loss-1.8839, acc-0.5107\n",
      "Iter-72760, train loss-1.9957, acc-0.3200, valid loss-1.9184, acc-0.4930, test loss-1.8839, acc-0.5108\n",
      "Iter-72770, train loss-1.9471, acc-0.4400, valid loss-1.9184, acc-0.4930, test loss-1.8839, acc-0.5108\n",
      "Iter-72780, train loss-1.8412, acc-0.5600, valid loss-1.9184, acc-0.4930, test loss-1.8838, acc-0.5108\n",
      "Iter-72790, train loss-1.9284, acc-0.4600, valid loss-1.9183, acc-0.4928, test loss-1.8838, acc-0.5108\n",
      "Iter-72800, train loss-1.9390, acc-0.4600, valid loss-1.9183, acc-0.4930, test loss-1.8838, acc-0.5105\n",
      "Iter-72810, train loss-1.8749, acc-0.5200, valid loss-1.9183, acc-0.4930, test loss-1.8837, acc-0.5107\n",
      "Iter-72820, train loss-1.8876, acc-0.5400, valid loss-1.9182, acc-0.4930, test loss-1.8837, acc-0.5108\n",
      "Iter-72830, train loss-1.9503, acc-0.4800, valid loss-1.9182, acc-0.4930, test loss-1.8836, acc-0.5107\n",
      "Iter-72840, train loss-1.8592, acc-0.4800, valid loss-1.9182, acc-0.4930, test loss-1.8836, acc-0.5108\n",
      "Iter-72850, train loss-1.9311, acc-0.5000, valid loss-1.9181, acc-0.4928, test loss-1.8836, acc-0.5105\n",
      "Iter-72860, train loss-1.9225, acc-0.4000, valid loss-1.9181, acc-0.4926, test loss-1.8835, acc-0.5106\n",
      "Iter-72870, train loss-1.8522, acc-0.5200, valid loss-1.9181, acc-0.4928, test loss-1.8835, acc-0.5106\n",
      "Iter-72880, train loss-1.8369, acc-0.5800, valid loss-1.9180, acc-0.4928, test loss-1.8835, acc-0.5108\n",
      "Iter-72890, train loss-1.9621, acc-0.4400, valid loss-1.9180, acc-0.4928, test loss-1.8834, acc-0.5108\n",
      "Iter-72900, train loss-1.8843, acc-0.5200, valid loss-1.9180, acc-0.4928, test loss-1.8834, acc-0.5106\n",
      "Iter-72910, train loss-1.9457, acc-0.5000, valid loss-1.9179, acc-0.4928, test loss-1.8834, acc-0.5106\n",
      "Iter-72920, train loss-1.9130, acc-0.5200, valid loss-1.9179, acc-0.4928, test loss-1.8833, acc-0.5106\n",
      "Iter-72930, train loss-1.8830, acc-0.4800, valid loss-1.9179, acc-0.4928, test loss-1.8833, acc-0.5106\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-72940, train loss-1.8764, acc-0.4600, valid loss-1.9178, acc-0.4928, test loss-1.8833, acc-0.5106\n",
      "Iter-72950, train loss-1.9273, acc-0.4400, valid loss-1.9178, acc-0.4926, test loss-1.8832, acc-0.5106\n",
      "Iter-72960, train loss-1.9163, acc-0.4400, valid loss-1.9178, acc-0.4926, test loss-1.8832, acc-0.5106\n",
      "Iter-72970, train loss-1.9211, acc-0.4800, valid loss-1.9177, acc-0.4928, test loss-1.8832, acc-0.5108\n",
      "Iter-72980, train loss-1.8150, acc-0.5400, valid loss-1.9177, acc-0.4928, test loss-1.8831, acc-0.5108\n",
      "Iter-72990, train loss-1.9649, acc-0.4400, valid loss-1.9177, acc-0.4928, test loss-1.8831, acc-0.5109\n",
      "Iter-73000, train loss-1.9353, acc-0.4600, valid loss-1.9176, acc-0.4928, test loss-1.8831, acc-0.5108\n",
      "Iter-73010, train loss-1.9632, acc-0.4000, valid loss-1.9176, acc-0.4928, test loss-1.8830, acc-0.5110\n",
      "Iter-73020, train loss-1.8451, acc-0.4800, valid loss-1.9176, acc-0.4928, test loss-1.8830, acc-0.5109\n",
      "Iter-73030, train loss-2.0208, acc-0.4000, valid loss-1.9176, acc-0.4928, test loss-1.8829, acc-0.5109\n",
      "Iter-73040, train loss-1.9000, acc-0.5400, valid loss-1.9175, acc-0.4928, test loss-1.8829, acc-0.5110\n",
      "Iter-73050, train loss-1.9674, acc-0.4000, valid loss-1.9175, acc-0.4928, test loss-1.8829, acc-0.5111\n",
      "Iter-73060, train loss-1.9040, acc-0.5400, valid loss-1.9175, acc-0.4928, test loss-1.8828, acc-0.5111\n",
      "Iter-73070, train loss-1.8988, acc-0.5000, valid loss-1.9174, acc-0.4928, test loss-1.8828, acc-0.5110\n",
      "Iter-73080, train loss-1.8434, acc-0.5600, valid loss-1.9174, acc-0.4928, test loss-1.8828, acc-0.5107\n",
      "Iter-73090, train loss-1.9439, acc-0.3800, valid loss-1.9174, acc-0.4928, test loss-1.8827, acc-0.5108\n",
      "Iter-73100, train loss-1.9250, acc-0.5800, valid loss-1.9173, acc-0.4928, test loss-1.8827, acc-0.5107\n",
      "Iter-73110, train loss-1.8949, acc-0.4600, valid loss-1.9173, acc-0.4928, test loss-1.8827, acc-0.5106\n",
      "Iter-73120, train loss-1.9791, acc-0.4600, valid loss-1.9173, acc-0.4928, test loss-1.8826, acc-0.5108\n",
      "Iter-73130, train loss-1.8607, acc-0.5800, valid loss-1.9172, acc-0.4928, test loss-1.8826, acc-0.5109\n",
      "Iter-73140, train loss-1.8576, acc-0.5000, valid loss-1.9172, acc-0.4928, test loss-1.8826, acc-0.5109\n",
      "Iter-73150, train loss-1.9360, acc-0.5000, valid loss-1.9172, acc-0.4928, test loss-1.8825, acc-0.5109\n",
      "Iter-73160, train loss-1.8496, acc-0.5600, valid loss-1.9171, acc-0.4928, test loss-1.8825, acc-0.5109\n",
      "Iter-73170, train loss-1.9364, acc-0.5000, valid loss-1.9171, acc-0.4928, test loss-1.8825, acc-0.5109\n",
      "Iter-73180, train loss-1.9119, acc-0.5400, valid loss-1.9171, acc-0.4928, test loss-1.8824, acc-0.5109\n",
      "Iter-73190, train loss-1.9227, acc-0.5000, valid loss-1.9170, acc-0.4928, test loss-1.8824, acc-0.5111\n",
      "Iter-73200, train loss-1.8821, acc-0.4800, valid loss-1.9170, acc-0.4928, test loss-1.8823, acc-0.5113\n",
      "Iter-73210, train loss-1.8221, acc-0.5600, valid loss-1.9170, acc-0.4928, test loss-1.8823, acc-0.5113\n",
      "Iter-73220, train loss-2.0648, acc-0.3200, valid loss-1.9170, acc-0.4928, test loss-1.8823, acc-0.5114\n",
      "Iter-73230, train loss-1.8368, acc-0.5600, valid loss-1.9169, acc-0.4926, test loss-1.8822, acc-0.5114\n",
      "Iter-73240, train loss-1.9792, acc-0.3200, valid loss-1.9169, acc-0.4930, test loss-1.8822, acc-0.5115\n",
      "Iter-73250, train loss-1.9055, acc-0.4600, valid loss-1.9169, acc-0.4930, test loss-1.8822, acc-0.5114\n",
      "Iter-73260, train loss-1.8933, acc-0.5400, valid loss-1.9168, acc-0.4928, test loss-1.8821, acc-0.5115\n",
      "Iter-73270, train loss-1.8883, acc-0.4800, valid loss-1.9168, acc-0.4928, test loss-1.8821, acc-0.5112\n",
      "Iter-73280, train loss-1.9009, acc-0.4400, valid loss-1.9168, acc-0.4932, test loss-1.8821, acc-0.5114\n",
      "Iter-73290, train loss-1.9232, acc-0.5000, valid loss-1.9167, acc-0.4934, test loss-1.8820, acc-0.5114\n",
      "Iter-73300, train loss-1.8323, acc-0.5000, valid loss-1.9167, acc-0.4936, test loss-1.8820, acc-0.5112\n",
      "Iter-73310, train loss-1.8740, acc-0.5600, valid loss-1.9167, acc-0.4936, test loss-1.8820, acc-0.5111\n",
      "Iter-73320, train loss-1.8870, acc-0.4600, valid loss-1.9166, acc-0.4936, test loss-1.8819, acc-0.5110\n",
      "Iter-73330, train loss-1.8549, acc-0.5000, valid loss-1.9166, acc-0.4936, test loss-1.8819, acc-0.5112\n",
      "Iter-73340, train loss-1.9074, acc-0.4800, valid loss-1.9166, acc-0.4934, test loss-1.8819, acc-0.5112\n",
      "Iter-73350, train loss-1.8879, acc-0.3400, valid loss-1.9165, acc-0.4934, test loss-1.8818, acc-0.5112\n",
      "Iter-73360, train loss-1.9818, acc-0.4000, valid loss-1.9165, acc-0.4934, test loss-1.8818, acc-0.5109\n",
      "Iter-73370, train loss-1.9015, acc-0.4600, valid loss-1.9165, acc-0.4936, test loss-1.8818, acc-0.5110\n",
      "Iter-73380, train loss-1.8384, acc-0.4800, valid loss-1.9164, acc-0.4936, test loss-1.8817, acc-0.5111\n",
      "Iter-73390, train loss-1.8919, acc-0.5000, valid loss-1.9164, acc-0.4936, test loss-1.8817, acc-0.5111\n",
      "Iter-73400, train loss-1.8323, acc-0.5600, valid loss-1.9164, acc-0.4936, test loss-1.8817, acc-0.5111\n",
      "Iter-73410, train loss-1.8629, acc-0.4800, valid loss-1.9163, acc-0.4934, test loss-1.8816, acc-0.5111\n",
      "Iter-73420, train loss-1.8709, acc-0.5000, valid loss-1.9163, acc-0.4936, test loss-1.8816, acc-0.5112\n",
      "Iter-73430, train loss-1.8824, acc-0.5400, valid loss-1.9163, acc-0.4934, test loss-1.8815, acc-0.5113\n",
      "Iter-73440, train loss-1.8325, acc-0.5400, valid loss-1.9162, acc-0.4936, test loss-1.8815, acc-0.5110\n",
      "Iter-73450, train loss-1.7925, acc-0.5400, valid loss-1.9162, acc-0.4936, test loss-1.8815, acc-0.5111\n",
      "Iter-73460, train loss-1.8825, acc-0.5600, valid loss-1.9162, acc-0.4934, test loss-1.8814, acc-0.5115\n",
      "Iter-73470, train loss-1.8860, acc-0.5800, valid loss-1.9161, acc-0.4938, test loss-1.8814, acc-0.5114\n",
      "Iter-73480, train loss-1.9136, acc-0.5200, valid loss-1.9161, acc-0.4934, test loss-1.8814, acc-0.5113\n",
      "Iter-73490, train loss-1.9293, acc-0.5000, valid loss-1.9161, acc-0.4936, test loss-1.8813, acc-0.5111\n",
      "Iter-73500, train loss-1.8524, acc-0.5400, valid loss-1.9160, acc-0.4938, test loss-1.8813, acc-0.5112\n",
      "Iter-73510, train loss-1.9028, acc-0.5200, valid loss-1.9160, acc-0.4936, test loss-1.8813, acc-0.5111\n",
      "Iter-73520, train loss-1.7877, acc-0.6600, valid loss-1.9160, acc-0.4936, test loss-1.8812, acc-0.5111\n",
      "Iter-73530, train loss-1.9952, acc-0.4200, valid loss-1.9159, acc-0.4936, test loss-1.8812, acc-0.5111\n",
      "Iter-73540, train loss-1.8957, acc-0.5200, valid loss-1.9159, acc-0.4936, test loss-1.8812, acc-0.5110\n",
      "Iter-73550, train loss-1.8203, acc-0.5600, valid loss-1.9159, acc-0.4936, test loss-1.8811, acc-0.5112\n",
      "Iter-73560, train loss-1.9111, acc-0.4800, valid loss-1.9158, acc-0.4936, test loss-1.8811, acc-0.5110\n",
      "Iter-73570, train loss-1.8755, acc-0.4800, valid loss-1.9158, acc-0.4938, test loss-1.8811, acc-0.5112\n",
      "Iter-73580, train loss-1.8434, acc-0.4800, valid loss-1.9158, acc-0.4936, test loss-1.8810, acc-0.5113\n",
      "Iter-73590, train loss-1.9544, acc-0.4400, valid loss-1.9157, acc-0.4936, test loss-1.8810, acc-0.5112\n",
      "Iter-73600, train loss-1.9406, acc-0.5000, valid loss-1.9157, acc-0.4938, test loss-1.8810, acc-0.5113\n",
      "Iter-73610, train loss-1.8367, acc-0.4400, valid loss-1.9157, acc-0.4938, test loss-1.8809, acc-0.5113\n",
      "Iter-73620, train loss-1.8946, acc-0.4800, valid loss-1.9156, acc-0.4938, test loss-1.8809, acc-0.5111\n",
      "Iter-73630, train loss-1.9966, acc-0.4000, valid loss-1.9156, acc-0.4936, test loss-1.8808, acc-0.5111\n",
      "Iter-73640, train loss-1.8495, acc-0.5600, valid loss-1.9156, acc-0.4940, test loss-1.8808, acc-0.5111\n",
      "Iter-73650, train loss-1.8574, acc-0.6000, valid loss-1.9156, acc-0.4936, test loss-1.8808, acc-0.5112\n",
      "Iter-73660, train loss-1.9451, acc-0.3000, valid loss-1.9155, acc-0.4936, test loss-1.8807, acc-0.5111\n",
      "Iter-73670, train loss-1.8955, acc-0.4800, valid loss-1.9155, acc-0.4936, test loss-1.8807, acc-0.5111\n",
      "Iter-73680, train loss-1.8744, acc-0.4400, valid loss-1.9155, acc-0.4934, test loss-1.8807, acc-0.5112\n",
      "Iter-73690, train loss-1.9285, acc-0.4400, valid loss-1.9154, acc-0.4934, test loss-1.8806, acc-0.5110\n",
      "Iter-73700, train loss-1.8932, acc-0.4600, valid loss-1.9154, acc-0.4934, test loss-1.8806, acc-0.5110\n",
      "Iter-73710, train loss-2.0806, acc-0.3600, valid loss-1.9154, acc-0.4936, test loss-1.8806, acc-0.5109\n",
      "Iter-73720, train loss-1.8193, acc-0.5400, valid loss-1.9153, acc-0.4936, test loss-1.8805, acc-0.5111\n",
      "Iter-73730, train loss-1.8702, acc-0.5400, valid loss-1.9153, acc-0.4934, test loss-1.8805, acc-0.5110\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-73740, train loss-1.8839, acc-0.4800, valid loss-1.9153, acc-0.4934, test loss-1.8805, acc-0.5111\n",
      "Iter-73750, train loss-1.8169, acc-0.4800, valid loss-1.9152, acc-0.4934, test loss-1.8804, acc-0.5113\n",
      "Iter-73760, train loss-1.9334, acc-0.5200, valid loss-1.9152, acc-0.4934, test loss-1.8804, acc-0.5112\n",
      "Iter-73770, train loss-1.9906, acc-0.4600, valid loss-1.9152, acc-0.4934, test loss-1.8804, acc-0.5114\n",
      "Iter-73780, train loss-1.8585, acc-0.6400, valid loss-1.9151, acc-0.4934, test loss-1.8803, acc-0.5114\n",
      "Iter-73790, train loss-1.8817, acc-0.5400, valid loss-1.9151, acc-0.4934, test loss-1.8803, acc-0.5113\n",
      "Iter-73800, train loss-1.8906, acc-0.5000, valid loss-1.9151, acc-0.4930, test loss-1.8803, acc-0.5113\n",
      "Iter-73810, train loss-1.9215, acc-0.4400, valid loss-1.9151, acc-0.4930, test loss-1.8802, acc-0.5112\n",
      "Iter-73820, train loss-1.9657, acc-0.4200, valid loss-1.9150, acc-0.4930, test loss-1.8802, acc-0.5114\n",
      "Iter-73830, train loss-1.8784, acc-0.5200, valid loss-1.9150, acc-0.4930, test loss-1.8802, acc-0.5112\n",
      "Iter-73840, train loss-1.9789, acc-0.3800, valid loss-1.9150, acc-0.4928, test loss-1.8801, acc-0.5112\n",
      "Iter-73850, train loss-1.8838, acc-0.5000, valid loss-1.9149, acc-0.4928, test loss-1.8801, acc-0.5111\n",
      "Iter-73860, train loss-1.9198, acc-0.4000, valid loss-1.9149, acc-0.4930, test loss-1.8800, acc-0.5114\n",
      "Iter-73870, train loss-1.9307, acc-0.4800, valid loss-1.9149, acc-0.4932, test loss-1.8800, acc-0.5115\n",
      "Iter-73880, train loss-1.8773, acc-0.5200, valid loss-1.9148, acc-0.4928, test loss-1.8800, acc-0.5113\n",
      "Iter-73890, train loss-1.9433, acc-0.5400, valid loss-1.9148, acc-0.4932, test loss-1.8799, acc-0.5114\n",
      "Iter-73900, train loss-1.9395, acc-0.3800, valid loss-1.9148, acc-0.4934, test loss-1.8799, acc-0.5112\n",
      "Iter-73910, train loss-1.8454, acc-0.5600, valid loss-1.9147, acc-0.4934, test loss-1.8799, acc-0.5113\n",
      "Iter-73920, train loss-1.8793, acc-0.4600, valid loss-1.9147, acc-0.4934, test loss-1.8798, acc-0.5113\n",
      "Iter-73930, train loss-1.7752, acc-0.7000, valid loss-1.9147, acc-0.4930, test loss-1.8798, acc-0.5112\n",
      "Iter-73940, train loss-1.8812, acc-0.4800, valid loss-1.9146, acc-0.4930, test loss-1.8798, acc-0.5112\n",
      "Iter-73950, train loss-1.8622, acc-0.6200, valid loss-1.9146, acc-0.4930, test loss-1.8797, acc-0.5112\n",
      "Iter-73960, train loss-1.9069, acc-0.4200, valid loss-1.9146, acc-0.4930, test loss-1.8797, acc-0.5112\n",
      "Iter-73970, train loss-1.8738, acc-0.4800, valid loss-1.9145, acc-0.4930, test loss-1.8797, acc-0.5112\n",
      "Iter-73980, train loss-1.8709, acc-0.5000, valid loss-1.9145, acc-0.4930, test loss-1.8796, acc-0.5112\n",
      "Iter-73990, train loss-1.8587, acc-0.5400, valid loss-1.9145, acc-0.4928, test loss-1.8796, acc-0.5112\n",
      "Iter-74000, train loss-1.7871, acc-0.5800, valid loss-1.9144, acc-0.4930, test loss-1.8796, acc-0.5114\n",
      "Iter-74010, train loss-1.9158, acc-0.4000, valid loss-1.9144, acc-0.4932, test loss-1.8795, acc-0.5114\n",
      "Iter-74020, train loss-1.9027, acc-0.5400, valid loss-1.9144, acc-0.4932, test loss-1.8795, acc-0.5114\n",
      "Iter-74030, train loss-1.9809, acc-0.4200, valid loss-1.9143, acc-0.4928, test loss-1.8794, acc-0.5113\n",
      "Iter-74040, train loss-1.9134, acc-0.5600, valid loss-1.9143, acc-0.4930, test loss-1.8794, acc-0.5114\n",
      "Iter-74050, train loss-1.9264, acc-0.4000, valid loss-1.9143, acc-0.4928, test loss-1.8794, acc-0.5114\n",
      "Iter-74060, train loss-1.9244, acc-0.5200, valid loss-1.9143, acc-0.4928, test loss-1.8793, acc-0.5113\n",
      "Iter-74070, train loss-1.9017, acc-0.5000, valid loss-1.9142, acc-0.4926, test loss-1.8793, acc-0.5113\n",
      "Iter-74080, train loss-1.9246, acc-0.4800, valid loss-1.9142, acc-0.4928, test loss-1.8793, acc-0.5113\n",
      "Iter-74090, train loss-1.8786, acc-0.4600, valid loss-1.9142, acc-0.4924, test loss-1.8792, acc-0.5113\n",
      "Iter-74100, train loss-1.8845, acc-0.5200, valid loss-1.9141, acc-0.4924, test loss-1.8792, acc-0.5113\n",
      "Iter-74110, train loss-1.9581, acc-0.5200, valid loss-1.9141, acc-0.4924, test loss-1.8792, acc-0.5112\n",
      "Iter-74120, train loss-1.8867, acc-0.5400, valid loss-1.9141, acc-0.4924, test loss-1.8791, acc-0.5113\n",
      "Iter-74130, train loss-1.9779, acc-0.4400, valid loss-1.9140, acc-0.4924, test loss-1.8791, acc-0.5113\n",
      "Iter-74140, train loss-2.0114, acc-0.4400, valid loss-1.9140, acc-0.4922, test loss-1.8791, acc-0.5114\n",
      "Iter-74150, train loss-1.8327, acc-0.5600, valid loss-1.9140, acc-0.4922, test loss-1.8790, acc-0.5114\n",
      "Iter-74160, train loss-1.8451, acc-0.5800, valid loss-1.9139, acc-0.4922, test loss-1.8790, acc-0.5114\n",
      "Iter-74170, train loss-2.0586, acc-0.3600, valid loss-1.9139, acc-0.4922, test loss-1.8790, acc-0.5113\n",
      "Iter-74180, train loss-1.9080, acc-0.5000, valid loss-1.9139, acc-0.4922, test loss-1.8789, acc-0.5112\n",
      "Iter-74190, train loss-1.8934, acc-0.4400, valid loss-1.9139, acc-0.4920, test loss-1.8789, acc-0.5111\n",
      "Iter-74200, train loss-1.8897, acc-0.5200, valid loss-1.9138, acc-0.4922, test loss-1.8789, acc-0.5110\n",
      "Iter-74210, train loss-2.0137, acc-0.3600, valid loss-1.9138, acc-0.4920, test loss-1.8788, acc-0.5114\n",
      "Iter-74220, train loss-1.9430, acc-0.3800, valid loss-1.9138, acc-0.4920, test loss-1.8788, acc-0.5113\n",
      "Iter-74230, train loss-1.9006, acc-0.5600, valid loss-1.9137, acc-0.4920, test loss-1.8788, acc-0.5114\n",
      "Iter-74240, train loss-1.9000, acc-0.4600, valid loss-1.9137, acc-0.4920, test loss-1.8787, acc-0.5114\n",
      "Iter-74250, train loss-1.9588, acc-0.3800, valid loss-1.9137, acc-0.4918, test loss-1.8787, acc-0.5114\n",
      "Iter-74260, train loss-1.8529, acc-0.4400, valid loss-1.9136, acc-0.4920, test loss-1.8787, acc-0.5112\n",
      "Iter-74270, train loss-1.8772, acc-0.5000, valid loss-1.9136, acc-0.4920, test loss-1.8786, acc-0.5116\n",
      "Iter-74280, train loss-1.9561, acc-0.4400, valid loss-1.9136, acc-0.4918, test loss-1.8786, acc-0.5116\n",
      "Iter-74290, train loss-1.9381, acc-0.4400, valid loss-1.9135, acc-0.4918, test loss-1.8785, acc-0.5114\n",
      "Iter-74300, train loss-1.9170, acc-0.4600, valid loss-1.9135, acc-0.4920, test loss-1.8785, acc-0.5115\n",
      "Iter-74310, train loss-1.8628, acc-0.5000, valid loss-1.9135, acc-0.4922, test loss-1.8785, acc-0.5117\n",
      "Iter-74320, train loss-1.8340, acc-0.6200, valid loss-1.9134, acc-0.4922, test loss-1.8784, acc-0.5113\n",
      "Iter-74330, train loss-1.8182, acc-0.6000, valid loss-1.9134, acc-0.4922, test loss-1.8784, acc-0.5114\n",
      "Iter-74340, train loss-1.9353, acc-0.4600, valid loss-1.9134, acc-0.4920, test loss-1.8784, acc-0.5117\n",
      "Iter-74350, train loss-1.9512, acc-0.5400, valid loss-1.9133, acc-0.4920, test loss-1.8783, acc-0.5117\n",
      "Iter-74360, train loss-1.9491, acc-0.4800, valid loss-1.9133, acc-0.4920, test loss-1.8783, acc-0.5117\n",
      "Iter-74370, train loss-1.8957, acc-0.5000, valid loss-1.9133, acc-0.4920, test loss-1.8783, acc-0.5117\n",
      "Iter-74380, train loss-1.9537, acc-0.4200, valid loss-1.9132, acc-0.4920, test loss-1.8782, acc-0.5117\n",
      "Iter-74390, train loss-1.9414, acc-0.4600, valid loss-1.9132, acc-0.4922, test loss-1.8782, acc-0.5116\n",
      "Iter-74400, train loss-1.8230, acc-0.5800, valid loss-1.9132, acc-0.4922, test loss-1.8782, acc-0.5115\n",
      "Iter-74410, train loss-1.8582, acc-0.5000, valid loss-1.9131, acc-0.4924, test loss-1.8781, acc-0.5114\n",
      "Iter-74420, train loss-1.9655, acc-0.4600, valid loss-1.9131, acc-0.4922, test loss-1.8781, acc-0.5114\n",
      "Iter-74430, train loss-1.9101, acc-0.5000, valid loss-1.9131, acc-0.4922, test loss-1.8781, acc-0.5115\n",
      "Iter-74440, train loss-1.8969, acc-0.5200, valid loss-1.9130, acc-0.4924, test loss-1.8780, acc-0.5115\n",
      "Iter-74450, train loss-1.8896, acc-0.4200, valid loss-1.9130, acc-0.4926, test loss-1.8780, acc-0.5115\n",
      "Iter-74460, train loss-1.9697, acc-0.4400, valid loss-1.9130, acc-0.4926, test loss-1.8780, acc-0.5113\n",
      "Iter-74470, train loss-1.8198, acc-0.3800, valid loss-1.9130, acc-0.4930, test loss-1.8779, acc-0.5113\n",
      "Iter-74480, train loss-1.9140, acc-0.4400, valid loss-1.9129, acc-0.4930, test loss-1.8779, acc-0.5113\n",
      "Iter-74490, train loss-1.9023, acc-0.4800, valid loss-1.9129, acc-0.4930, test loss-1.8779, acc-0.5114\n",
      "Iter-74500, train loss-1.8234, acc-0.4400, valid loss-1.9129, acc-0.4932, test loss-1.8778, acc-0.5113\n",
      "Iter-74510, train loss-1.9771, acc-0.3600, valid loss-1.9128, acc-0.4932, test loss-1.8778, acc-0.5113\n",
      "Iter-74520, train loss-1.8856, acc-0.5800, valid loss-1.9128, acc-0.4936, test loss-1.8778, acc-0.5113\n",
      "Iter-74530, train loss-1.8771, acc-0.5200, valid loss-1.9128, acc-0.4934, test loss-1.8777, acc-0.5113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-74540, train loss-1.9070, acc-0.4400, valid loss-1.9127, acc-0.4932, test loss-1.8777, acc-0.5113\n",
      "Iter-74550, train loss-2.0949, acc-0.4000, valid loss-1.9127, acc-0.4936, test loss-1.8776, acc-0.5112\n",
      "Iter-74560, train loss-1.8856, acc-0.5400, valid loss-1.9127, acc-0.4936, test loss-1.8776, acc-0.5111\n",
      "Iter-74570, train loss-1.9705, acc-0.3800, valid loss-1.9126, acc-0.4936, test loss-1.8776, acc-0.5111\n",
      "Iter-74580, train loss-1.8898, acc-0.4800, valid loss-1.9126, acc-0.4936, test loss-1.8775, acc-0.5109\n",
      "Iter-74590, train loss-1.9110, acc-0.4200, valid loss-1.9126, acc-0.4936, test loss-1.8775, acc-0.5109\n",
      "Iter-74600, train loss-1.8620, acc-0.4800, valid loss-1.9125, acc-0.4936, test loss-1.8775, acc-0.5110\n",
      "Iter-74610, train loss-1.9471, acc-0.4800, valid loss-1.9125, acc-0.4936, test loss-1.8774, acc-0.5111\n",
      "Iter-74620, train loss-1.9041, acc-0.4400, valid loss-1.9125, acc-0.4936, test loss-1.8774, acc-0.5111\n",
      "Iter-74630, train loss-1.9054, acc-0.4800, valid loss-1.9124, acc-0.4936, test loss-1.8774, acc-0.5111\n",
      "Iter-74640, train loss-1.8499, acc-0.5800, valid loss-1.9124, acc-0.4936, test loss-1.8773, acc-0.5111\n",
      "Iter-74650, train loss-1.9275, acc-0.4200, valid loss-1.9124, acc-0.4934, test loss-1.8773, acc-0.5108\n",
      "Iter-74660, train loss-1.8698, acc-0.4800, valid loss-1.9123, acc-0.4934, test loss-1.8773, acc-0.5111\n",
      "Iter-74670, train loss-1.8311, acc-0.6400, valid loss-1.9123, acc-0.4934, test loss-1.8772, acc-0.5112\n",
      "Iter-74680, train loss-1.8794, acc-0.6000, valid loss-1.9123, acc-0.4934, test loss-1.8772, acc-0.5113\n",
      "Iter-74690, train loss-1.9220, acc-0.5000, valid loss-1.9123, acc-0.4936, test loss-1.8772, acc-0.5113\n",
      "Iter-74700, train loss-1.7752, acc-0.6200, valid loss-1.9122, acc-0.4932, test loss-1.8771, acc-0.5113\n",
      "Iter-74710, train loss-1.8598, acc-0.5400, valid loss-1.9122, acc-0.4934, test loss-1.8771, acc-0.5113\n",
      "Iter-74720, train loss-1.8881, acc-0.4800, valid loss-1.9122, acc-0.4934, test loss-1.8771, acc-0.5113\n",
      "Iter-74730, train loss-1.8891, acc-0.5200, valid loss-1.9121, acc-0.4932, test loss-1.8770, acc-0.5113\n",
      "Iter-74740, train loss-1.9111, acc-0.5400, valid loss-1.9121, acc-0.4932, test loss-1.8770, acc-0.5113\n",
      "Iter-74750, train loss-1.9264, acc-0.5000, valid loss-1.9121, acc-0.4934, test loss-1.8770, acc-0.5113\n",
      "Iter-74760, train loss-1.9983, acc-0.4600, valid loss-1.9120, acc-0.4934, test loss-1.8769, acc-0.5113\n",
      "Iter-74770, train loss-1.7988, acc-0.6600, valid loss-1.9120, acc-0.4934, test loss-1.8769, acc-0.5114\n",
      "Iter-74780, train loss-1.9454, acc-0.4200, valid loss-1.9120, acc-0.4936, test loss-1.8769, acc-0.5113\n",
      "Iter-74790, train loss-1.8939, acc-0.4800, valid loss-1.9119, acc-0.4932, test loss-1.8768, acc-0.5112\n",
      "Iter-74800, train loss-1.9375, acc-0.4800, valid loss-1.9119, acc-0.4930, test loss-1.8768, acc-0.5113\n",
      "Iter-74810, train loss-1.8902, acc-0.5000, valid loss-1.9119, acc-0.4930, test loss-1.8768, acc-0.5114\n",
      "Iter-74820, train loss-1.9921, acc-0.4600, valid loss-1.9119, acc-0.4930, test loss-1.8767, acc-0.5115\n",
      "Iter-74830, train loss-1.9298, acc-0.4400, valid loss-1.9118, acc-0.4928, test loss-1.8767, acc-0.5115\n",
      "Iter-74840, train loss-1.8067, acc-0.5600, valid loss-1.9118, acc-0.4928, test loss-1.8767, acc-0.5117\n",
      "Iter-74850, train loss-1.8174, acc-0.5000, valid loss-1.9117, acc-0.4928, test loss-1.8766, acc-0.5116\n",
      "Iter-74860, train loss-1.8356, acc-0.5000, valid loss-1.9117, acc-0.4928, test loss-1.8766, acc-0.5116\n",
      "Iter-74870, train loss-1.8465, acc-0.5800, valid loss-1.9117, acc-0.4934, test loss-1.8765, acc-0.5116\n",
      "Iter-74880, train loss-1.9569, acc-0.4600, valid loss-1.9117, acc-0.4934, test loss-1.8765, acc-0.5119\n",
      "Iter-74890, train loss-1.9272, acc-0.5000, valid loss-1.9116, acc-0.4934, test loss-1.8765, acc-0.5118\n",
      "Iter-74900, train loss-1.9121, acc-0.4400, valid loss-1.9116, acc-0.4936, test loss-1.8764, acc-0.5118\n",
      "Iter-74910, train loss-1.7600, acc-0.7200, valid loss-1.9116, acc-0.4938, test loss-1.8764, acc-0.5116\n",
      "Iter-74920, train loss-1.8297, acc-0.5400, valid loss-1.9115, acc-0.4936, test loss-1.8764, acc-0.5116\n",
      "Iter-74930, train loss-1.8708, acc-0.6000, valid loss-1.9115, acc-0.4936, test loss-1.8763, acc-0.5116\n",
      "Iter-74940, train loss-1.9672, acc-0.4200, valid loss-1.9115, acc-0.4936, test loss-1.8763, acc-0.5116\n",
      "Iter-74950, train loss-1.8194, acc-0.5600, valid loss-1.9114, acc-0.4936, test loss-1.8763, acc-0.5118\n",
      "Iter-74960, train loss-1.9324, acc-0.5200, valid loss-1.9114, acc-0.4936, test loss-1.8762, acc-0.5117\n",
      "Iter-74970, train loss-1.8906, acc-0.5800, valid loss-1.9114, acc-0.4938, test loss-1.8762, acc-0.5117\n",
      "Iter-74980, train loss-1.8261, acc-0.5600, valid loss-1.9114, acc-0.4936, test loss-1.8762, acc-0.5117\n",
      "Iter-74990, train loss-1.8034, acc-0.6000, valid loss-1.9113, acc-0.4936, test loss-1.8761, acc-0.5117\n",
      "Iter-75000, train loss-1.8656, acc-0.5400, valid loss-1.9113, acc-0.4936, test loss-1.8761, acc-0.5117\n",
      "Iter-75010, train loss-1.9207, acc-0.4600, valid loss-1.9113, acc-0.4936, test loss-1.8761, acc-0.5117\n",
      "Iter-75020, train loss-1.8329, acc-0.5600, valid loss-1.9112, acc-0.4936, test loss-1.8760, acc-0.5116\n",
      "Iter-75030, train loss-1.8991, acc-0.4400, valid loss-1.9112, acc-0.4938, test loss-1.8760, acc-0.5117\n",
      "Iter-75040, train loss-1.9365, acc-0.4000, valid loss-1.9112, acc-0.4938, test loss-1.8760, acc-0.5118\n",
      "Iter-75050, train loss-1.9036, acc-0.4800, valid loss-1.9111, acc-0.4938, test loss-1.8759, acc-0.5118\n",
      "Iter-75060, train loss-1.7780, acc-0.6600, valid loss-1.9111, acc-0.4938, test loss-1.8759, acc-0.5119\n",
      "Iter-75070, train loss-1.9577, acc-0.4400, valid loss-1.9111, acc-0.4938, test loss-1.8759, acc-0.5118\n",
      "Iter-75080, train loss-1.8652, acc-0.5000, valid loss-1.9110, acc-0.4938, test loss-1.8758, acc-0.5118\n",
      "Iter-75090, train loss-1.9921, acc-0.5200, valid loss-1.9110, acc-0.4938, test loss-1.8758, acc-0.5118\n",
      "Iter-75100, train loss-1.9497, acc-0.4400, valid loss-1.9110, acc-0.4938, test loss-1.8758, acc-0.5117\n",
      "Iter-75110, train loss-1.9025, acc-0.4200, valid loss-1.9109, acc-0.4938, test loss-1.8757, acc-0.5117\n",
      "Iter-75120, train loss-1.9021, acc-0.5800, valid loss-1.9109, acc-0.4938, test loss-1.8757, acc-0.5118\n",
      "Iter-75130, train loss-1.9718, acc-0.4800, valid loss-1.9109, acc-0.4938, test loss-1.8757, acc-0.5119\n",
      "Iter-75140, train loss-1.9410, acc-0.4600, valid loss-1.9109, acc-0.4938, test loss-1.8756, acc-0.5120\n",
      "Iter-75150, train loss-1.9027, acc-0.5800, valid loss-1.9108, acc-0.4938, test loss-1.8756, acc-0.5120\n",
      "Iter-75160, train loss-1.9720, acc-0.4800, valid loss-1.9108, acc-0.4938, test loss-1.8756, acc-0.5118\n",
      "Iter-75170, train loss-1.8380, acc-0.4400, valid loss-1.9108, acc-0.4938, test loss-1.8755, acc-0.5119\n",
      "Iter-75180, train loss-1.8063, acc-0.5800, valid loss-1.9107, acc-0.4940, test loss-1.8755, acc-0.5118\n",
      "Iter-75190, train loss-1.9316, acc-0.4600, valid loss-1.9107, acc-0.4940, test loss-1.8754, acc-0.5118\n",
      "Iter-75200, train loss-1.9449, acc-0.4400, valid loss-1.9107, acc-0.4940, test loss-1.8754, acc-0.5119\n",
      "Iter-75210, train loss-1.7819, acc-0.5600, valid loss-1.9106, acc-0.4940, test loss-1.8754, acc-0.5117\n",
      "Iter-75220, train loss-1.9067, acc-0.5400, valid loss-1.9106, acc-0.4940, test loss-1.8753, acc-0.5119\n",
      "Iter-75230, train loss-1.9459, acc-0.4400, valid loss-1.9106, acc-0.4936, test loss-1.8753, acc-0.5122\n",
      "Iter-75240, train loss-1.8868, acc-0.5000, valid loss-1.9105, acc-0.4938, test loss-1.8753, acc-0.5121\n",
      "Iter-75250, train loss-1.8642, acc-0.5200, valid loss-1.9105, acc-0.4940, test loss-1.8752, acc-0.5122\n",
      "Iter-75260, train loss-1.8409, acc-0.6400, valid loss-1.9105, acc-0.4938, test loss-1.8752, acc-0.5122\n",
      "Iter-75270, train loss-1.8754, acc-0.4800, valid loss-1.9104, acc-0.4938, test loss-1.8752, acc-0.5123\n",
      "Iter-75280, train loss-1.8802, acc-0.5400, valid loss-1.9104, acc-0.4938, test loss-1.8751, acc-0.5123\n",
      "Iter-75290, train loss-1.7730, acc-0.6600, valid loss-1.9104, acc-0.4938, test loss-1.8751, acc-0.5121\n",
      "Iter-75300, train loss-1.8802, acc-0.4600, valid loss-1.9103, acc-0.4938, test loss-1.8751, acc-0.5121\n",
      "Iter-75310, train loss-1.8073, acc-0.5200, valid loss-1.9103, acc-0.4938, test loss-1.8750, acc-0.5122\n",
      "Iter-75320, train loss-1.8854, acc-0.5000, valid loss-1.9103, acc-0.4932, test loss-1.8750, acc-0.5122\n",
      "Iter-75330, train loss-1.9934, acc-0.3800, valid loss-1.9102, acc-0.4938, test loss-1.8750, acc-0.5122\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-75340, train loss-1.9444, acc-0.4600, valid loss-1.9102, acc-0.4934, test loss-1.8749, acc-0.5121\n",
      "Iter-75350, train loss-1.9467, acc-0.4800, valid loss-1.9102, acc-0.4936, test loss-1.8749, acc-0.5122\n",
      "Iter-75360, train loss-1.9592, acc-0.4400, valid loss-1.9102, acc-0.4934, test loss-1.8748, acc-0.5122\n",
      "Iter-75370, train loss-1.8882, acc-0.5600, valid loss-1.9101, acc-0.4934, test loss-1.8748, acc-0.5122\n",
      "Iter-75380, train loss-1.8834, acc-0.4800, valid loss-1.9101, acc-0.4934, test loss-1.8748, acc-0.5123\n",
      "Iter-75390, train loss-1.8705, acc-0.6000, valid loss-1.9101, acc-0.4936, test loss-1.8747, acc-0.5122\n",
      "Iter-75400, train loss-1.9538, acc-0.4000, valid loss-1.9100, acc-0.4936, test loss-1.8747, acc-0.5123\n",
      "Iter-75410, train loss-1.8522, acc-0.5600, valid loss-1.9100, acc-0.4934, test loss-1.8747, acc-0.5123\n",
      "Iter-75420, train loss-1.9854, acc-0.4000, valid loss-1.9100, acc-0.4936, test loss-1.8746, acc-0.5122\n",
      "Iter-75430, train loss-1.9587, acc-0.3800, valid loss-1.9099, acc-0.4934, test loss-1.8746, acc-0.5122\n",
      "Iter-75440, train loss-1.8831, acc-0.5600, valid loss-1.9099, acc-0.4932, test loss-1.8746, acc-0.5122\n",
      "Iter-75450, train loss-1.8998, acc-0.4800, valid loss-1.9099, acc-0.4932, test loss-1.8745, acc-0.5122\n",
      "Iter-75460, train loss-1.7959, acc-0.5600, valid loss-1.9099, acc-0.4932, test loss-1.8745, acc-0.5122\n",
      "Iter-75470, train loss-1.9309, acc-0.4200, valid loss-1.9098, acc-0.4932, test loss-1.8745, acc-0.5122\n",
      "Iter-75480, train loss-1.8473, acc-0.5400, valid loss-1.9098, acc-0.4932, test loss-1.8744, acc-0.5122\n",
      "Iter-75490, train loss-1.9121, acc-0.5200, valid loss-1.9098, acc-0.4932, test loss-1.8744, acc-0.5122\n",
      "Iter-75500, train loss-1.9231, acc-0.4400, valid loss-1.9097, acc-0.4932, test loss-1.8744, acc-0.5122\n",
      "Iter-75510, train loss-1.9521, acc-0.4800, valid loss-1.9097, acc-0.4930, test loss-1.8743, acc-0.5122\n",
      "Iter-75520, train loss-1.8735, acc-0.5600, valid loss-1.9097, acc-0.4930, test loss-1.8743, acc-0.5122\n",
      "Iter-75530, train loss-1.9235, acc-0.4200, valid loss-1.9096, acc-0.4932, test loss-1.8743, acc-0.5122\n",
      "Iter-75540, train loss-1.8736, acc-0.5800, valid loss-1.9096, acc-0.4932, test loss-1.8742, acc-0.5121\n",
      "Iter-75550, train loss-1.8992, acc-0.4800, valid loss-1.9096, acc-0.4932, test loss-1.8742, acc-0.5121\n",
      "Iter-75560, train loss-1.8691, acc-0.4600, valid loss-1.9095, acc-0.4932, test loss-1.8742, acc-0.5121\n",
      "Iter-75570, train loss-1.8933, acc-0.5000, valid loss-1.9095, acc-0.4932, test loss-1.8741, acc-0.5121\n",
      "Iter-75580, train loss-2.0013, acc-0.3200, valid loss-1.9095, acc-0.4932, test loss-1.8741, acc-0.5122\n",
      "Iter-75590, train loss-1.9114, acc-0.5000, valid loss-1.9094, acc-0.4932, test loss-1.8741, acc-0.5122\n",
      "Iter-75600, train loss-1.9075, acc-0.4600, valid loss-1.9094, acc-0.4932, test loss-1.8740, acc-0.5123\n",
      "Iter-75610, train loss-1.9317, acc-0.4200, valid loss-1.9094, acc-0.4936, test loss-1.8740, acc-0.5122\n",
      "Iter-75620, train loss-1.8642, acc-0.5600, valid loss-1.9094, acc-0.4934, test loss-1.8740, acc-0.5122\n",
      "Iter-75630, train loss-2.0347, acc-0.3600, valid loss-1.9093, acc-0.4936, test loss-1.8739, acc-0.5122\n",
      "Iter-75640, train loss-1.8919, acc-0.5600, valid loss-1.9093, acc-0.4936, test loss-1.8739, acc-0.5122\n",
      "Iter-75650, train loss-1.9707, acc-0.3600, valid loss-1.9093, acc-0.4936, test loss-1.8739, acc-0.5123\n",
      "Iter-75660, train loss-1.8736, acc-0.5000, valid loss-1.9092, acc-0.4936, test loss-1.8738, acc-0.5122\n",
      "Iter-75670, train loss-1.9737, acc-0.5200, valid loss-1.9092, acc-0.4938, test loss-1.8738, acc-0.5123\n",
      "Iter-75680, train loss-1.8639, acc-0.5800, valid loss-1.9092, acc-0.4936, test loss-1.8738, acc-0.5123\n",
      "Iter-75690, train loss-1.9615, acc-0.4400, valid loss-1.9091, acc-0.4938, test loss-1.8737, acc-0.5124\n",
      "Iter-75700, train loss-1.8103, acc-0.5800, valid loss-1.9091, acc-0.4936, test loss-1.8737, acc-0.5124\n",
      "Iter-75710, train loss-1.9474, acc-0.4000, valid loss-1.9091, acc-0.4938, test loss-1.8736, acc-0.5124\n",
      "Iter-75720, train loss-1.9553, acc-0.3600, valid loss-1.9090, acc-0.4940, test loss-1.8736, acc-0.5125\n",
      "Iter-75730, train loss-1.8469, acc-0.5800, valid loss-1.9090, acc-0.4938, test loss-1.8736, acc-0.5124\n",
      "Iter-75740, train loss-1.8827, acc-0.5000, valid loss-1.9090, acc-0.4940, test loss-1.8735, acc-0.5124\n",
      "Iter-75750, train loss-1.8968, acc-0.4600, valid loss-1.9089, acc-0.4940, test loss-1.8735, acc-0.5126\n",
      "Iter-75760, train loss-1.8669, acc-0.4800, valid loss-1.9089, acc-0.4936, test loss-1.8735, acc-0.5124\n",
      "Iter-75770, train loss-1.7732, acc-0.6200, valid loss-1.9089, acc-0.4938, test loss-1.8734, acc-0.5124\n",
      "Iter-75780, train loss-1.9046, acc-0.5400, valid loss-1.9088, acc-0.4940, test loss-1.8734, acc-0.5123\n",
      "Iter-75790, train loss-1.9016, acc-0.4800, valid loss-1.9088, acc-0.4940, test loss-1.8734, acc-0.5124\n",
      "Iter-75800, train loss-1.8661, acc-0.4400, valid loss-1.9088, acc-0.4942, test loss-1.8733, acc-0.5125\n",
      "Iter-75810, train loss-1.8880, acc-0.5200, valid loss-1.9088, acc-0.4942, test loss-1.8733, acc-0.5126\n",
      "Iter-75820, train loss-1.8970, acc-0.5000, valid loss-1.9087, acc-0.4942, test loss-1.8733, acc-0.5126\n",
      "Iter-75830, train loss-1.9248, acc-0.6000, valid loss-1.9087, acc-0.4940, test loss-1.8732, acc-0.5124\n",
      "Iter-75840, train loss-1.8429, acc-0.5000, valid loss-1.9087, acc-0.4938, test loss-1.8732, acc-0.5125\n",
      "Iter-75850, train loss-1.9109, acc-0.5200, valid loss-1.9086, acc-0.4940, test loss-1.8732, acc-0.5126\n",
      "Iter-75860, train loss-1.8308, acc-0.5400, valid loss-1.9086, acc-0.4936, test loss-1.8731, acc-0.5124\n",
      "Iter-75870, train loss-1.9510, acc-0.3200, valid loss-1.9086, acc-0.4938, test loss-1.8731, acc-0.5125\n",
      "Iter-75880, train loss-1.9186, acc-0.5400, valid loss-1.9085, acc-0.4938, test loss-1.8731, acc-0.5125\n",
      "Iter-75890, train loss-1.8636, acc-0.5600, valid loss-1.9085, acc-0.4938, test loss-1.8730, acc-0.5126\n",
      "Iter-75900, train loss-1.9540, acc-0.4800, valid loss-1.9085, acc-0.4938, test loss-1.8730, acc-0.5128\n",
      "Iter-75910, train loss-1.8566, acc-0.5400, valid loss-1.9084, acc-0.4936, test loss-1.8730, acc-0.5128\n",
      "Iter-75920, train loss-1.9761, acc-0.3200, valid loss-1.9084, acc-0.4936, test loss-1.8729, acc-0.5128\n",
      "Iter-75930, train loss-1.8776, acc-0.4800, valid loss-1.9084, acc-0.4940, test loss-1.8729, acc-0.5129\n",
      "Iter-75940, train loss-1.9230, acc-0.5400, valid loss-1.9083, acc-0.4940, test loss-1.8729, acc-0.5129\n",
      "Iter-75950, train loss-1.8503, acc-0.5000, valid loss-1.9083, acc-0.4938, test loss-1.8728, acc-0.5129\n",
      "Iter-75960, train loss-1.8918, acc-0.4800, valid loss-1.9083, acc-0.4938, test loss-1.8728, acc-0.5129\n",
      "Iter-75970, train loss-1.8594, acc-0.6400, valid loss-1.9083, acc-0.4934, test loss-1.8728, acc-0.5128\n",
      "Iter-75980, train loss-1.9188, acc-0.5400, valid loss-1.9082, acc-0.4932, test loss-1.8727, acc-0.5128\n",
      "Iter-75990, train loss-1.8931, acc-0.4800, valid loss-1.9082, acc-0.4940, test loss-1.8727, acc-0.5128\n",
      "Iter-76000, train loss-1.7858, acc-0.5400, valid loss-1.9082, acc-0.4938, test loss-1.8727, acc-0.5127\n",
      "Iter-76010, train loss-1.7837, acc-0.5800, valid loss-1.9081, acc-0.4938, test loss-1.8726, acc-0.5128\n",
      "Iter-76020, train loss-1.9507, acc-0.5200, valid loss-1.9081, acc-0.4938, test loss-1.8726, acc-0.5128\n",
      "Iter-76030, train loss-1.9963, acc-0.3400, valid loss-1.9081, acc-0.4938, test loss-1.8726, acc-0.5127\n",
      "Iter-76040, train loss-1.8744, acc-0.5400, valid loss-1.9080, acc-0.4938, test loss-1.8725, acc-0.5127\n",
      "Iter-76050, train loss-1.9534, acc-0.4200, valid loss-1.9080, acc-0.4940, test loss-1.8725, acc-0.5126\n",
      "Iter-76060, train loss-1.9470, acc-0.4400, valid loss-1.9080, acc-0.4940, test loss-1.8725, acc-0.5127\n",
      "Iter-76070, train loss-1.8861, acc-0.6200, valid loss-1.9080, acc-0.4940, test loss-1.8724, acc-0.5126\n",
      "Iter-76080, train loss-1.9110, acc-0.4800, valid loss-1.9079, acc-0.4938, test loss-1.8724, acc-0.5126\n",
      "Iter-76090, train loss-1.8870, acc-0.5000, valid loss-1.9079, acc-0.4938, test loss-1.8723, acc-0.5126\n",
      "Iter-76100, train loss-1.8177, acc-0.5600, valid loss-1.9079, acc-0.4938, test loss-1.8723, acc-0.5127\n",
      "Iter-76110, train loss-1.9936, acc-0.4200, valid loss-1.9078, acc-0.4938, test loss-1.8723, acc-0.5127\n",
      "Iter-76120, train loss-1.8473, acc-0.6000, valid loss-1.9078, acc-0.4938, test loss-1.8722, acc-0.5127\n",
      "Iter-76130, train loss-2.0114, acc-0.3200, valid loss-1.9078, acc-0.4938, test loss-1.8722, acc-0.5127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-76140, train loss-1.8542, acc-0.4600, valid loss-1.9077, acc-0.4938, test loss-1.8722, acc-0.5129\n",
      "Iter-76150, train loss-1.8497, acc-0.5200, valid loss-1.9077, acc-0.4938, test loss-1.8721, acc-0.5129\n",
      "Iter-76160, train loss-1.8759, acc-0.5800, valid loss-1.9077, acc-0.4938, test loss-1.8721, acc-0.5129\n",
      "Iter-76170, train loss-1.8630, acc-0.5400, valid loss-1.9076, acc-0.4936, test loss-1.8721, acc-0.5129\n",
      "Iter-76180, train loss-1.8938, acc-0.5200, valid loss-1.9076, acc-0.4936, test loss-1.8720, acc-0.5128\n",
      "Iter-76190, train loss-1.8633, acc-0.5000, valid loss-1.9076, acc-0.4936, test loss-1.8720, acc-0.5128\n",
      "Iter-76200, train loss-1.8496, acc-0.5400, valid loss-1.9075, acc-0.4938, test loss-1.8720, acc-0.5128\n",
      "Iter-76210, train loss-1.9272, acc-0.5200, valid loss-1.9075, acc-0.4938, test loss-1.8719, acc-0.5127\n",
      "Iter-76220, train loss-1.8725, acc-0.5000, valid loss-1.9075, acc-0.4938, test loss-1.8719, acc-0.5128\n",
      "Iter-76230, train loss-1.9116, acc-0.4600, valid loss-1.9074, acc-0.4938, test loss-1.8719, acc-0.5128\n",
      "Iter-76240, train loss-1.8077, acc-0.5200, valid loss-1.9074, acc-0.4940, test loss-1.8718, acc-0.5128\n",
      "Iter-76250, train loss-1.9108, acc-0.5600, valid loss-1.9074, acc-0.4938, test loss-1.8718, acc-0.5127\n",
      "Iter-76260, train loss-1.9297, acc-0.4600, valid loss-1.9073, acc-0.4938, test loss-1.8718, acc-0.5127\n",
      "Iter-76270, train loss-1.8457, acc-0.5600, valid loss-1.9073, acc-0.4938, test loss-1.8717, acc-0.5127\n",
      "Iter-76280, train loss-1.8352, acc-0.5200, valid loss-1.9073, acc-0.4938, test loss-1.8717, acc-0.5127\n",
      "Iter-76290, train loss-1.7901, acc-0.6000, valid loss-1.9073, acc-0.4938, test loss-1.8717, acc-0.5127\n",
      "Iter-76300, train loss-1.9072, acc-0.4800, valid loss-1.9072, acc-0.4938, test loss-1.8716, acc-0.5127\n",
      "Iter-76310, train loss-1.8917, acc-0.5000, valid loss-1.9072, acc-0.4938, test loss-1.8716, acc-0.5127\n",
      "Iter-76320, train loss-1.9060, acc-0.4200, valid loss-1.9072, acc-0.4938, test loss-1.8716, acc-0.5127\n",
      "Iter-76330, train loss-1.7795, acc-0.6600, valid loss-1.9071, acc-0.4940, test loss-1.8715, acc-0.5127\n",
      "Iter-76340, train loss-1.9301, acc-0.4200, valid loss-1.9071, acc-0.4942, test loss-1.8715, acc-0.5128\n",
      "Iter-76350, train loss-1.8863, acc-0.6200, valid loss-1.9071, acc-0.4942, test loss-1.8715, acc-0.5128\n",
      "Iter-76360, train loss-1.8777, acc-0.4400, valid loss-1.9070, acc-0.4942, test loss-1.8714, acc-0.5128\n",
      "Iter-76370, train loss-1.8809, acc-0.5800, valid loss-1.9070, acc-0.4940, test loss-1.8714, acc-0.5127\n",
      "Iter-76380, train loss-1.8909, acc-0.6200, valid loss-1.9070, acc-0.4942, test loss-1.8714, acc-0.5129\n",
      "Iter-76390, train loss-1.9207, acc-0.5200, valid loss-1.9070, acc-0.4942, test loss-1.8713, acc-0.5129\n",
      "Iter-76400, train loss-1.8501, acc-0.5000, valid loss-1.9069, acc-0.4942, test loss-1.8713, acc-0.5127\n",
      "Iter-76410, train loss-1.8885, acc-0.5800, valid loss-1.9069, acc-0.4942, test loss-1.8713, acc-0.5128\n",
      "Iter-76420, train loss-1.8407, acc-0.4800, valid loss-1.9069, acc-0.4942, test loss-1.8712, acc-0.5128\n",
      "Iter-76430, train loss-1.8852, acc-0.5000, valid loss-1.9068, acc-0.4942, test loss-1.8712, acc-0.5130\n",
      "Iter-76440, train loss-1.9067, acc-0.4600, valid loss-1.9068, acc-0.4942, test loss-1.8712, acc-0.5130\n",
      "Iter-76450, train loss-1.9339, acc-0.5000, valid loss-1.9068, acc-0.4940, test loss-1.8711, acc-0.5131\n",
      "Iter-76460, train loss-1.8748, acc-0.5000, valid loss-1.9067, acc-0.4940, test loss-1.8711, acc-0.5129\n",
      "Iter-76470, train loss-1.8613, acc-0.6400, valid loss-1.9067, acc-0.4942, test loss-1.8711, acc-0.5129\n",
      "Iter-76480, train loss-1.9235, acc-0.3600, valid loss-1.9067, acc-0.4942, test loss-1.8710, acc-0.5131\n",
      "Iter-76490, train loss-1.9394, acc-0.4400, valid loss-1.9066, acc-0.4942, test loss-1.8710, acc-0.5131\n",
      "Iter-76500, train loss-1.8961, acc-0.6000, valid loss-1.9066, acc-0.4942, test loss-1.8710, acc-0.5130\n",
      "Iter-76510, train loss-1.9083, acc-0.5000, valid loss-1.9066, acc-0.4942, test loss-1.8709, acc-0.5130\n",
      "Iter-76520, train loss-1.8929, acc-0.4400, valid loss-1.9065, acc-0.4944, test loss-1.8709, acc-0.5131\n",
      "Iter-76530, train loss-1.9339, acc-0.5600, valid loss-1.9065, acc-0.4942, test loss-1.8708, acc-0.5130\n",
      "Iter-76540, train loss-1.8310, acc-0.4400, valid loss-1.9065, acc-0.4942, test loss-1.8708, acc-0.5132\n",
      "Iter-76550, train loss-1.9014, acc-0.5200, valid loss-1.9065, acc-0.4944, test loss-1.8708, acc-0.5131\n",
      "Iter-76560, train loss-1.8198, acc-0.4800, valid loss-1.9064, acc-0.4946, test loss-1.8707, acc-0.5131\n",
      "Iter-76570, train loss-1.8737, acc-0.5600, valid loss-1.9064, acc-0.4944, test loss-1.8707, acc-0.5131\n",
      "Iter-76580, train loss-1.9467, acc-0.4600, valid loss-1.9064, acc-0.4946, test loss-1.8707, acc-0.5130\n",
      "Iter-76590, train loss-1.8753, acc-0.4600, valid loss-1.9063, acc-0.4946, test loss-1.8706, acc-0.5131\n",
      "Iter-76600, train loss-1.9493, acc-0.5000, valid loss-1.9063, acc-0.4946, test loss-1.8706, acc-0.5130\n",
      "Iter-76610, train loss-1.7821, acc-0.6200, valid loss-1.9063, acc-0.4944, test loss-1.8706, acc-0.5132\n",
      "Iter-76620, train loss-1.8183, acc-0.5200, valid loss-1.9062, acc-0.4944, test loss-1.8705, acc-0.5131\n",
      "Iter-76630, train loss-1.8388, acc-0.5800, valid loss-1.9062, acc-0.4944, test loss-1.8705, acc-0.5131\n",
      "Iter-76640, train loss-1.9712, acc-0.3400, valid loss-1.9062, acc-0.4944, test loss-1.8705, acc-0.5130\n",
      "Iter-76650, train loss-1.7867, acc-0.7000, valid loss-1.9062, acc-0.4944, test loss-1.8704, acc-0.5131\n",
      "Iter-76660, train loss-1.9269, acc-0.4800, valid loss-1.9061, acc-0.4944, test loss-1.8704, acc-0.5130\n",
      "Iter-76670, train loss-1.9006, acc-0.5600, valid loss-1.9061, acc-0.4940, test loss-1.8704, acc-0.5130\n",
      "Iter-76680, train loss-1.9334, acc-0.4200, valid loss-1.9061, acc-0.4940, test loss-1.8703, acc-0.5131\n",
      "Iter-76690, train loss-1.9525, acc-0.4600, valid loss-1.9060, acc-0.4938, test loss-1.8703, acc-0.5131\n",
      "Iter-76700, train loss-1.9848, acc-0.4200, valid loss-1.9060, acc-0.4940, test loss-1.8703, acc-0.5129\n",
      "Iter-76710, train loss-1.8103, acc-0.6000, valid loss-1.9060, acc-0.4940, test loss-1.8702, acc-0.5129\n",
      "Iter-76720, train loss-1.9043, acc-0.4800, valid loss-1.9059, acc-0.4942, test loss-1.8702, acc-0.5129\n",
      "Iter-76730, train loss-1.8918, acc-0.4800, valid loss-1.9059, acc-0.4940, test loss-1.8702, acc-0.5129\n",
      "Iter-76740, train loss-1.8194, acc-0.7000, valid loss-1.9059, acc-0.4940, test loss-1.8701, acc-0.5131\n",
      "Iter-76750, train loss-1.8880, acc-0.4800, valid loss-1.9058, acc-0.4942, test loss-1.8701, acc-0.5129\n",
      "Iter-76760, train loss-2.0212, acc-0.3000, valid loss-1.9058, acc-0.4942, test loss-1.8701, acc-0.5130\n",
      "Iter-76770, train loss-1.9040, acc-0.4800, valid loss-1.9058, acc-0.4942, test loss-1.8700, acc-0.5131\n",
      "Iter-76780, train loss-1.8936, acc-0.4800, valid loss-1.9058, acc-0.4942, test loss-1.8700, acc-0.5131\n",
      "Iter-76790, train loss-1.9457, acc-0.4200, valid loss-1.9057, acc-0.4940, test loss-1.8700, acc-0.5131\n",
      "Iter-76800, train loss-1.8013, acc-0.5800, valid loss-1.9057, acc-0.4942, test loss-1.8699, acc-0.5131\n",
      "Iter-76810, train loss-1.7520, acc-0.6000, valid loss-1.9057, acc-0.4940, test loss-1.8699, acc-0.5129\n",
      "Iter-76820, train loss-1.9670, acc-0.3800, valid loss-1.9056, acc-0.4942, test loss-1.8699, acc-0.5129\n",
      "Iter-76830, train loss-1.8964, acc-0.4400, valid loss-1.9056, acc-0.4942, test loss-1.8698, acc-0.5130\n",
      "Iter-76840, train loss-1.9264, acc-0.4200, valid loss-1.9056, acc-0.4940, test loss-1.8698, acc-0.5131\n",
      "Iter-76850, train loss-1.8926, acc-0.5000, valid loss-1.9055, acc-0.4940, test loss-1.8698, acc-0.5131\n",
      "Iter-76860, train loss-1.9072, acc-0.5800, valid loss-1.9055, acc-0.4940, test loss-1.8697, acc-0.5131\n",
      "Iter-76870, train loss-1.9304, acc-0.3600, valid loss-1.9055, acc-0.4942, test loss-1.8697, acc-0.5132\n",
      "Iter-76880, train loss-1.8176, acc-0.5800, valid loss-1.9054, acc-0.4940, test loss-1.8697, acc-0.5131\n",
      "Iter-76890, train loss-1.8571, acc-0.5200, valid loss-1.9054, acc-0.4940, test loss-1.8696, acc-0.5132\n",
      "Iter-76900, train loss-1.8077, acc-0.5800, valid loss-1.9054, acc-0.4940, test loss-1.8696, acc-0.5130\n",
      "Iter-76910, train loss-1.7953, acc-0.5400, valid loss-1.9053, acc-0.4938, test loss-1.8696, acc-0.5129\n",
      "Iter-76920, train loss-1.8825, acc-0.5000, valid loss-1.9053, acc-0.4938, test loss-1.8695, acc-0.5129\n",
      "Iter-76930, train loss-1.8420, acc-0.6000, valid loss-1.9053, acc-0.4934, test loss-1.8695, acc-0.5129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-76940, train loss-1.9329, acc-0.5000, valid loss-1.9052, acc-0.4934, test loss-1.8695, acc-0.5129\n",
      "Iter-76950, train loss-1.8737, acc-0.5600, valid loss-1.9052, acc-0.4934, test loss-1.8694, acc-0.5129\n",
      "Iter-76960, train loss-1.9694, acc-0.3600, valid loss-1.9052, acc-0.4934, test loss-1.8694, acc-0.5129\n",
      "Iter-76970, train loss-1.9306, acc-0.4000, valid loss-1.9052, acc-0.4936, test loss-1.8694, acc-0.5129\n",
      "Iter-76980, train loss-1.9557, acc-0.5200, valid loss-1.9051, acc-0.4936, test loss-1.8693, acc-0.5129\n",
      "Iter-76990, train loss-1.9486, acc-0.3600, valid loss-1.9051, acc-0.4936, test loss-1.8693, acc-0.5129\n",
      "Iter-77000, train loss-1.9636, acc-0.3600, valid loss-1.9051, acc-0.4936, test loss-1.8693, acc-0.5130\n",
      "Iter-77010, train loss-1.8569, acc-0.5400, valid loss-1.9050, acc-0.4936, test loss-1.8692, acc-0.5132\n",
      "Iter-77020, train loss-1.9583, acc-0.4200, valid loss-1.9050, acc-0.4936, test loss-1.8692, acc-0.5132\n",
      "Iter-77030, train loss-1.8652, acc-0.5400, valid loss-1.9050, acc-0.4938, test loss-1.8692, acc-0.5132\n",
      "Iter-77040, train loss-1.8378, acc-0.5400, valid loss-1.9049, acc-0.4938, test loss-1.8691, acc-0.5133\n",
      "Iter-77050, train loss-1.8484, acc-0.5200, valid loss-1.9049, acc-0.4938, test loss-1.8691, acc-0.5133\n",
      "Iter-77060, train loss-1.8927, acc-0.5200, valid loss-1.9049, acc-0.4940, test loss-1.8691, acc-0.5132\n",
      "Iter-77070, train loss-1.8435, acc-0.5400, valid loss-1.9048, acc-0.4940, test loss-1.8690, acc-0.5133\n",
      "Iter-77080, train loss-1.9316, acc-0.4400, valid loss-1.9048, acc-0.4938, test loss-1.8690, acc-0.5132\n",
      "Iter-77090, train loss-1.8370, acc-0.5200, valid loss-1.9048, acc-0.4942, test loss-1.8690, acc-0.5133\n",
      "Iter-77100, train loss-1.9033, acc-0.4800, valid loss-1.9048, acc-0.4940, test loss-1.8689, acc-0.5139\n",
      "Iter-77110, train loss-1.9035, acc-0.4600, valid loss-1.9047, acc-0.4938, test loss-1.8689, acc-0.5137\n",
      "Iter-77120, train loss-1.8518, acc-0.4800, valid loss-1.9047, acc-0.4938, test loss-1.8689, acc-0.5137\n",
      "Iter-77130, train loss-1.8224, acc-0.6200, valid loss-1.9047, acc-0.4938, test loss-1.8688, acc-0.5136\n",
      "Iter-77140, train loss-1.9642, acc-0.4200, valid loss-1.9046, acc-0.4938, test loss-1.8688, acc-0.5137\n",
      "Iter-77150, train loss-1.8883, acc-0.4600, valid loss-1.9046, acc-0.4936, test loss-1.8688, acc-0.5137\n",
      "Iter-77160, train loss-1.8666, acc-0.5400, valid loss-1.9046, acc-0.4934, test loss-1.8687, acc-0.5138\n",
      "Iter-77170, train loss-1.9576, acc-0.4200, valid loss-1.9045, acc-0.4934, test loss-1.8687, acc-0.5137\n",
      "Iter-77180, train loss-1.8824, acc-0.5200, valid loss-1.9045, acc-0.4934, test loss-1.8687, acc-0.5136\n",
      "Iter-77190, train loss-1.8407, acc-0.5400, valid loss-1.9045, acc-0.4936, test loss-1.8686, acc-0.5135\n",
      "Iter-77200, train loss-1.8733, acc-0.5800, valid loss-1.9045, acc-0.4934, test loss-1.8686, acc-0.5132\n",
      "Iter-77210, train loss-1.9367, acc-0.4200, valid loss-1.9044, acc-0.4938, test loss-1.8686, acc-0.5135\n",
      "Iter-77220, train loss-1.8978, acc-0.4200, valid loss-1.9044, acc-0.4932, test loss-1.8685, acc-0.5135\n",
      "Iter-77230, train loss-1.9814, acc-0.4600, valid loss-1.9044, acc-0.4934, test loss-1.8685, acc-0.5135\n",
      "Iter-77240, train loss-1.9003, acc-0.5400, valid loss-1.9043, acc-0.4934, test loss-1.8685, acc-0.5137\n",
      "Iter-77250, train loss-1.7073, acc-0.6000, valid loss-1.9043, acc-0.4934, test loss-1.8684, acc-0.5135\n",
      "Iter-77260, train loss-1.9436, acc-0.4200, valid loss-1.9043, acc-0.4934, test loss-1.8684, acc-0.5133\n",
      "Iter-77270, train loss-1.8785, acc-0.4800, valid loss-1.9042, acc-0.4938, test loss-1.8684, acc-0.5135\n",
      "Iter-77280, train loss-1.6885, acc-0.7800, valid loss-1.9042, acc-0.4936, test loss-1.8683, acc-0.5135\n",
      "Iter-77290, train loss-1.8077, acc-0.5600, valid loss-1.9042, acc-0.4936, test loss-1.8683, acc-0.5131\n",
      "Iter-77300, train loss-1.8359, acc-0.5000, valid loss-1.9041, acc-0.4936, test loss-1.8683, acc-0.5131\n",
      "Iter-77310, train loss-1.9362, acc-0.4400, valid loss-1.9041, acc-0.4932, test loss-1.8682, acc-0.5128\n",
      "Iter-77320, train loss-1.8618, acc-0.6000, valid loss-1.9041, acc-0.4932, test loss-1.8682, acc-0.5127\n",
      "Iter-77330, train loss-1.8792, acc-0.5000, valid loss-1.9041, acc-0.4932, test loss-1.8682, acc-0.5129\n",
      "Iter-77340, train loss-1.8441, acc-0.5000, valid loss-1.9040, acc-0.4936, test loss-1.8681, acc-0.5129\n",
      "Iter-77350, train loss-1.8968, acc-0.4600, valid loss-1.9040, acc-0.4936, test loss-1.8681, acc-0.5129\n",
      "Iter-77360, train loss-1.8818, acc-0.5000, valid loss-1.9040, acc-0.4932, test loss-1.8681, acc-0.5128\n",
      "Iter-77370, train loss-1.8456, acc-0.5400, valid loss-1.9039, acc-0.4936, test loss-1.8680, acc-0.5130\n",
      "Iter-77380, train loss-1.8187, acc-0.6600, valid loss-1.9039, acc-0.4934, test loss-1.8680, acc-0.5132\n",
      "Iter-77390, train loss-2.0101, acc-0.4600, valid loss-1.9039, acc-0.4936, test loss-1.8680, acc-0.5132\n",
      "Iter-77400, train loss-1.8936, acc-0.4600, valid loss-1.9038, acc-0.4936, test loss-1.8679, acc-0.5135\n",
      "Iter-77410, train loss-1.8928, acc-0.4400, valid loss-1.9038, acc-0.4940, test loss-1.8679, acc-0.5136\n",
      "Iter-77420, train loss-1.9101, acc-0.4200, valid loss-1.9038, acc-0.4938, test loss-1.8679, acc-0.5136\n",
      "Iter-77430, train loss-1.8464, acc-0.5400, valid loss-1.9038, acc-0.4938, test loss-1.8678, acc-0.5136\n",
      "Iter-77440, train loss-1.7707, acc-0.5600, valid loss-1.9037, acc-0.4938, test loss-1.8678, acc-0.5134\n",
      "Iter-77450, train loss-1.9153, acc-0.5400, valid loss-1.9037, acc-0.4936, test loss-1.8678, acc-0.5131\n",
      "Iter-77460, train loss-1.8823, acc-0.5400, valid loss-1.9037, acc-0.4936, test loss-1.8677, acc-0.5129\n",
      "Iter-77470, train loss-1.9382, acc-0.3800, valid loss-1.9036, acc-0.4938, test loss-1.8677, acc-0.5130\n",
      "Iter-77480, train loss-1.9122, acc-0.5000, valid loss-1.9036, acc-0.4940, test loss-1.8677, acc-0.5133\n",
      "Iter-77490, train loss-1.8831, acc-0.5200, valid loss-1.9036, acc-0.4938, test loss-1.8676, acc-0.5130\n",
      "Iter-77500, train loss-1.8910, acc-0.4600, valid loss-1.9035, acc-0.4938, test loss-1.8676, acc-0.5129\n",
      "Iter-77510, train loss-1.9746, acc-0.4200, valid loss-1.9035, acc-0.4938, test loss-1.8676, acc-0.5131\n",
      "Iter-77520, train loss-1.8691, acc-0.4600, valid loss-1.9035, acc-0.4940, test loss-1.8675, acc-0.5131\n",
      "Iter-77530, train loss-1.9009, acc-0.4800, valid loss-1.9035, acc-0.4940, test loss-1.8675, acc-0.5132\n",
      "Iter-77540, train loss-1.8940, acc-0.5200, valid loss-1.9034, acc-0.4940, test loss-1.8675, acc-0.5131\n",
      "Iter-77550, train loss-1.8597, acc-0.4800, valid loss-1.9034, acc-0.4938, test loss-1.8674, acc-0.5130\n",
      "Iter-77560, train loss-1.8448, acc-0.4800, valid loss-1.9034, acc-0.4938, test loss-1.8674, acc-0.5132\n",
      "Iter-77570, train loss-1.8507, acc-0.5000, valid loss-1.9033, acc-0.4940, test loss-1.8674, acc-0.5132\n",
      "Iter-77580, train loss-1.8233, acc-0.6800, valid loss-1.9033, acc-0.4940, test loss-1.8673, acc-0.5133\n",
      "Iter-77590, train loss-1.8616, acc-0.5400, valid loss-1.9033, acc-0.4942, test loss-1.8673, acc-0.5131\n",
      "Iter-77600, train loss-1.8122, acc-0.5000, valid loss-1.9032, acc-0.4944, test loss-1.8673, acc-0.5135\n",
      "Iter-77610, train loss-1.8899, acc-0.5000, valid loss-1.9032, acc-0.4946, test loss-1.8672, acc-0.5135\n",
      "Iter-77620, train loss-1.9065, acc-0.4200, valid loss-1.9032, acc-0.4946, test loss-1.8672, acc-0.5135\n",
      "Iter-77630, train loss-1.8475, acc-0.5200, valid loss-1.9032, acc-0.4946, test loss-1.8672, acc-0.5134\n",
      "Iter-77640, train loss-1.8836, acc-0.5000, valid loss-1.9031, acc-0.4946, test loss-1.8671, acc-0.5136\n",
      "Iter-77650, train loss-1.9871, acc-0.4000, valid loss-1.9031, acc-0.4946, test loss-1.8671, acc-0.5136\n",
      "Iter-77660, train loss-1.9146, acc-0.5200, valid loss-1.9031, acc-0.4948, test loss-1.8671, acc-0.5137\n",
      "Iter-77670, train loss-1.8345, acc-0.5200, valid loss-1.9030, acc-0.4948, test loss-1.8670, acc-0.5137\n",
      "Iter-77680, train loss-1.8670, acc-0.4400, valid loss-1.9030, acc-0.4950, test loss-1.8670, acc-0.5137\n",
      "Iter-77690, train loss-1.9506, acc-0.4600, valid loss-1.9030, acc-0.4950, test loss-1.8670, acc-0.5138\n",
      "Iter-77700, train loss-1.8853, acc-0.3800, valid loss-1.9030, acc-0.4948, test loss-1.8669, acc-0.5138\n",
      "Iter-77710, train loss-1.8677, acc-0.5400, valid loss-1.9029, acc-0.4950, test loss-1.8669, acc-0.5138\n",
      "Iter-77720, train loss-1.8583, acc-0.6200, valid loss-1.9029, acc-0.4948, test loss-1.8669, acc-0.5137\n",
      "Iter-77730, train loss-1.8296, acc-0.5600, valid loss-1.9029, acc-0.4948, test loss-1.8668, acc-0.5137\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-77740, train loss-1.9376, acc-0.4200, valid loss-1.9028, acc-0.4948, test loss-1.8668, acc-0.5137\n",
      "Iter-77750, train loss-1.8667, acc-0.4800, valid loss-1.9028, acc-0.4946, test loss-1.8668, acc-0.5137\n",
      "Iter-77760, train loss-1.7949, acc-0.4600, valid loss-1.9028, acc-0.4946, test loss-1.8667, acc-0.5137\n",
      "Iter-77770, train loss-1.8868, acc-0.4400, valid loss-1.9027, acc-0.4944, test loss-1.8667, acc-0.5137\n",
      "Iter-77780, train loss-1.9621, acc-0.4000, valid loss-1.9027, acc-0.4942, test loss-1.8667, acc-0.5138\n",
      "Iter-77790, train loss-1.9014, acc-0.4600, valid loss-1.9027, acc-0.4942, test loss-1.8666, acc-0.5138\n",
      "Iter-77800, train loss-1.7698, acc-0.6000, valid loss-1.9026, acc-0.4942, test loss-1.8666, acc-0.5136\n",
      "Iter-77810, train loss-1.8255, acc-0.5200, valid loss-1.9026, acc-0.4942, test loss-1.8666, acc-0.5136\n",
      "Iter-77820, train loss-1.8202, acc-0.6200, valid loss-1.9026, acc-0.4942, test loss-1.8665, acc-0.5136\n",
      "Iter-77830, train loss-1.8352, acc-0.5400, valid loss-1.9025, acc-0.4942, test loss-1.8665, acc-0.5137\n",
      "Iter-77840, train loss-1.9334, acc-0.5000, valid loss-1.9025, acc-0.4944, test loss-1.8665, acc-0.5135\n",
      "Iter-77850, train loss-1.8967, acc-0.4800, valid loss-1.9025, acc-0.4944, test loss-1.8664, acc-0.5136\n",
      "Iter-77860, train loss-1.8891, acc-0.4600, valid loss-1.9025, acc-0.4942, test loss-1.8664, acc-0.5134\n",
      "Iter-77870, train loss-1.9418, acc-0.3800, valid loss-1.9024, acc-0.4942, test loss-1.8664, acc-0.5135\n",
      "Iter-77880, train loss-1.8564, acc-0.5400, valid loss-1.9024, acc-0.4942, test loss-1.8663, acc-0.5133\n",
      "Iter-77890, train loss-1.8693, acc-0.5400, valid loss-1.9024, acc-0.4942, test loss-1.8663, acc-0.5135\n",
      "Iter-77900, train loss-1.9562, acc-0.5200, valid loss-1.9023, acc-0.4942, test loss-1.8663, acc-0.5133\n",
      "Iter-77910, train loss-1.8305, acc-0.5600, valid loss-1.9023, acc-0.4940, test loss-1.8662, acc-0.5134\n",
      "Iter-77920, train loss-1.9580, acc-0.4800, valid loss-1.9023, acc-0.4940, test loss-1.8662, acc-0.5134\n",
      "Iter-77930, train loss-1.8779, acc-0.4600, valid loss-1.9022, acc-0.4938, test loss-1.8662, acc-0.5134\n",
      "Iter-77940, train loss-1.8497, acc-0.4600, valid loss-1.9022, acc-0.4938, test loss-1.8661, acc-0.5133\n",
      "Iter-77950, train loss-1.9128, acc-0.4400, valid loss-1.9022, acc-0.4940, test loss-1.8661, acc-0.5130\n",
      "Iter-77960, train loss-1.8538, acc-0.4800, valid loss-1.9022, acc-0.4940, test loss-1.8661, acc-0.5131\n",
      "Iter-77970, train loss-1.8615, acc-0.5200, valid loss-1.9021, acc-0.4938, test loss-1.8660, acc-0.5131\n",
      "Iter-77980, train loss-1.8936, acc-0.4400, valid loss-1.9021, acc-0.4936, test loss-1.8660, acc-0.5129\n",
      "Iter-77990, train loss-1.8862, acc-0.4200, valid loss-1.9021, acc-0.4936, test loss-1.8660, acc-0.5130\n",
      "Iter-78000, train loss-1.8092, acc-0.5600, valid loss-1.9020, acc-0.4936, test loss-1.8659, acc-0.5131\n",
      "Iter-78010, train loss-1.8218, acc-0.5800, valid loss-1.9020, acc-0.4936, test loss-1.8659, acc-0.5130\n",
      "Iter-78020, train loss-1.8807, acc-0.5000, valid loss-1.9020, acc-0.4936, test loss-1.8659, acc-0.5131\n",
      "Iter-78030, train loss-1.8850, acc-0.4000, valid loss-1.9019, acc-0.4938, test loss-1.8658, acc-0.5132\n",
      "Iter-78040, train loss-1.8908, acc-0.4000, valid loss-1.9019, acc-0.4940, test loss-1.8658, acc-0.5132\n",
      "Iter-78050, train loss-1.8812, acc-0.4800, valid loss-1.9019, acc-0.4942, test loss-1.8658, acc-0.5136\n",
      "Iter-78060, train loss-1.8895, acc-0.4400, valid loss-1.9018, acc-0.4940, test loss-1.8657, acc-0.5131\n",
      "Iter-78070, train loss-1.8644, acc-0.4800, valid loss-1.9018, acc-0.4938, test loss-1.8657, acc-0.5130\n",
      "Iter-78080, train loss-1.8759, acc-0.5200, valid loss-1.9018, acc-0.4938, test loss-1.8657, acc-0.5131\n",
      "Iter-78090, train loss-1.8900, acc-0.6000, valid loss-1.9017, acc-0.4938, test loss-1.8656, acc-0.5129\n",
      "Iter-78100, train loss-1.8540, acc-0.5400, valid loss-1.9017, acc-0.4940, test loss-1.8656, acc-0.5130\n",
      "Iter-78110, train loss-1.9107, acc-0.4600, valid loss-1.9017, acc-0.4938, test loss-1.8656, acc-0.5129\n",
      "Iter-78120, train loss-2.0019, acc-0.4200, valid loss-1.9017, acc-0.4942, test loss-1.8655, acc-0.5128\n",
      "Iter-78130, train loss-1.9117, acc-0.4400, valid loss-1.9016, acc-0.4940, test loss-1.8655, acc-0.5127\n",
      "Iter-78140, train loss-1.8756, acc-0.4200, valid loss-1.9016, acc-0.4940, test loss-1.8655, acc-0.5128\n",
      "Iter-78150, train loss-1.7856, acc-0.6200, valid loss-1.9016, acc-0.4940, test loss-1.8654, acc-0.5129\n",
      "Iter-78160, train loss-1.8992, acc-0.4200, valid loss-1.9015, acc-0.4940, test loss-1.8654, acc-0.5127\n",
      "Iter-78170, train loss-1.8372, acc-0.5600, valid loss-1.9015, acc-0.4940, test loss-1.8654, acc-0.5127\n",
      "Iter-78180, train loss-1.7859, acc-0.5600, valid loss-1.9015, acc-0.4940, test loss-1.8653, acc-0.5129\n",
      "Iter-78190, train loss-1.8209, acc-0.5800, valid loss-1.9015, acc-0.4940, test loss-1.8653, acc-0.5131\n",
      "Iter-78200, train loss-1.8717, acc-0.5600, valid loss-1.9014, acc-0.4942, test loss-1.8653, acc-0.5130\n",
      "Iter-78210, train loss-1.9425, acc-0.4400, valid loss-1.9014, acc-0.4942, test loss-1.8652, acc-0.5131\n",
      "Iter-78220, train loss-1.9484, acc-0.4800, valid loss-1.9014, acc-0.4942, test loss-1.8652, acc-0.5132\n",
      "Iter-78230, train loss-1.8032, acc-0.5200, valid loss-1.9013, acc-0.4944, test loss-1.8652, acc-0.5130\n",
      "Iter-78240, train loss-1.8772, acc-0.4600, valid loss-1.9013, acc-0.4944, test loss-1.8651, acc-0.5131\n",
      "Iter-78250, train loss-1.9537, acc-0.4800, valid loss-1.9013, acc-0.4944, test loss-1.8651, acc-0.5132\n",
      "Iter-78260, train loss-1.8483, acc-0.5800, valid loss-1.9012, acc-0.4944, test loss-1.8651, acc-0.5130\n",
      "Iter-78270, train loss-1.8857, acc-0.5600, valid loss-1.9012, acc-0.4942, test loss-1.8650, acc-0.5134\n",
      "Iter-78280, train loss-1.9047, acc-0.5200, valid loss-1.9012, acc-0.4942, test loss-1.8650, acc-0.5134\n",
      "Iter-78290, train loss-1.8872, acc-0.4400, valid loss-1.9011, acc-0.4940, test loss-1.8650, acc-0.5135\n",
      "Iter-78300, train loss-1.8441, acc-0.6000, valid loss-1.9011, acc-0.4940, test loss-1.8649, acc-0.5134\n",
      "Iter-78310, train loss-1.9115, acc-0.5600, valid loss-1.9011, acc-0.4942, test loss-1.8649, acc-0.5133\n",
      "Iter-78320, train loss-1.9091, acc-0.5200, valid loss-1.9010, acc-0.4942, test loss-1.8649, acc-0.5134\n",
      "Iter-78330, train loss-1.8523, acc-0.5200, valid loss-1.9010, acc-0.4942, test loss-1.8648, acc-0.5135\n",
      "Iter-78340, train loss-1.9006, acc-0.5200, valid loss-1.9010, acc-0.4942, test loss-1.8648, acc-0.5133\n",
      "Iter-78350, train loss-1.9476, acc-0.4400, valid loss-1.9010, acc-0.4944, test loss-1.8648, acc-0.5134\n",
      "Iter-78360, train loss-1.7861, acc-0.6000, valid loss-1.9009, acc-0.4944, test loss-1.8647, acc-0.5132\n",
      "Iter-78370, train loss-1.9262, acc-0.4400, valid loss-1.9009, acc-0.4942, test loss-1.8647, acc-0.5132\n",
      "Iter-78380, train loss-1.9678, acc-0.4200, valid loss-1.9009, acc-0.4942, test loss-1.8647, acc-0.5133\n",
      "Iter-78390, train loss-1.8296, acc-0.4600, valid loss-1.9008, acc-0.4942, test loss-1.8646, acc-0.5133\n",
      "Iter-78400, train loss-1.9093, acc-0.5200, valid loss-1.9008, acc-0.4946, test loss-1.8646, acc-0.5134\n",
      "Iter-78410, train loss-1.9778, acc-0.4800, valid loss-1.9008, acc-0.4946, test loss-1.8646, acc-0.5135\n",
      "Iter-78420, train loss-1.9337, acc-0.4600, valid loss-1.9007, acc-0.4944, test loss-1.8645, acc-0.5136\n",
      "Iter-78430, train loss-1.8650, acc-0.4800, valid loss-1.9007, acc-0.4944, test loss-1.8645, acc-0.5134\n",
      "Iter-78440, train loss-1.9214, acc-0.5000, valid loss-1.9007, acc-0.4944, test loss-1.8645, acc-0.5133\n",
      "Iter-78450, train loss-1.8272, acc-0.5600, valid loss-1.9007, acc-0.4942, test loss-1.8644, acc-0.5134\n",
      "Iter-78460, train loss-1.7719, acc-0.6000, valid loss-1.9006, acc-0.4942, test loss-1.8644, acc-0.5135\n",
      "Iter-78470, train loss-1.9167, acc-0.4600, valid loss-1.9006, acc-0.4940, test loss-1.8644, acc-0.5135\n",
      "Iter-78480, train loss-1.7467, acc-0.6200, valid loss-1.9006, acc-0.4936, test loss-1.8643, acc-0.5135\n",
      "Iter-78490, train loss-1.8109, acc-0.6000, valid loss-1.9005, acc-0.4938, test loss-1.8643, acc-0.5135\n",
      "Iter-78500, train loss-1.8412, acc-0.5000, valid loss-1.9005, acc-0.4940, test loss-1.8643, acc-0.5135\n",
      "Iter-78510, train loss-1.8697, acc-0.4800, valid loss-1.9005, acc-0.4942, test loss-1.8642, acc-0.5133\n",
      "Iter-78520, train loss-1.8918, acc-0.4600, valid loss-1.9004, acc-0.4942, test loss-1.8642, acc-0.5134\n",
      "Iter-78530, train loss-1.8433, acc-0.5000, valid loss-1.9004, acc-0.4940, test loss-1.8642, acc-0.5133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-78540, train loss-1.8554, acc-0.6600, valid loss-1.9004, acc-0.4940, test loss-1.8641, acc-0.5134\n",
      "Iter-78550, train loss-1.9009, acc-0.5600, valid loss-1.9003, acc-0.4942, test loss-1.8641, acc-0.5134\n",
      "Iter-78560, train loss-1.8880, acc-0.5200, valid loss-1.9003, acc-0.4942, test loss-1.8641, acc-0.5134\n",
      "Iter-78570, train loss-1.9176, acc-0.4800, valid loss-1.9003, acc-0.4944, test loss-1.8640, acc-0.5133\n",
      "Iter-78580, train loss-1.8951, acc-0.4400, valid loss-1.9002, acc-0.4944, test loss-1.8640, acc-0.5134\n",
      "Iter-78590, train loss-1.8564, acc-0.4000, valid loss-1.9002, acc-0.4946, test loss-1.8640, acc-0.5134\n",
      "Iter-78600, train loss-1.7895, acc-0.5600, valid loss-1.9002, acc-0.4946, test loss-1.8639, acc-0.5134\n",
      "Iter-78610, train loss-1.8896, acc-0.4000, valid loss-1.9002, acc-0.4946, test loss-1.8639, acc-0.5134\n",
      "Iter-78620, train loss-1.7940, acc-0.5800, valid loss-1.9001, acc-0.4946, test loss-1.8639, acc-0.5134\n",
      "Iter-78630, train loss-1.8813, acc-0.5600, valid loss-1.9001, acc-0.4946, test loss-1.8638, acc-0.5134\n",
      "Iter-78640, train loss-1.9262, acc-0.5600, valid loss-1.9001, acc-0.4946, test loss-1.8638, acc-0.5134\n",
      "Iter-78650, train loss-2.0084, acc-0.3400, valid loss-1.9000, acc-0.4948, test loss-1.8638, acc-0.5135\n",
      "Iter-78660, train loss-1.8298, acc-0.5000, valid loss-1.9000, acc-0.4948, test loss-1.8637, acc-0.5136\n",
      "Iter-78670, train loss-1.8626, acc-0.5200, valid loss-1.9000, acc-0.4948, test loss-1.8637, acc-0.5136\n",
      "Iter-78680, train loss-1.9320, acc-0.4200, valid loss-1.9000, acc-0.4948, test loss-1.8637, acc-0.5135\n",
      "Iter-78690, train loss-1.8039, acc-0.5800, valid loss-1.8999, acc-0.4946, test loss-1.8636, acc-0.5134\n",
      "Iter-78700, train loss-1.8475, acc-0.5800, valid loss-1.8999, acc-0.4948, test loss-1.8636, acc-0.5134\n",
      "Iter-78710, train loss-1.8845, acc-0.5200, valid loss-1.8999, acc-0.4944, test loss-1.8636, acc-0.5136\n",
      "Iter-78720, train loss-1.8830, acc-0.4800, valid loss-1.8998, acc-0.4944, test loss-1.8636, acc-0.5135\n",
      "Iter-78730, train loss-1.8581, acc-0.5600, valid loss-1.8998, acc-0.4946, test loss-1.8635, acc-0.5136\n",
      "Iter-78740, train loss-1.9202, acc-0.5000, valid loss-1.8998, acc-0.4946, test loss-1.8635, acc-0.5136\n",
      "Iter-78750, train loss-1.8189, acc-0.5400, valid loss-1.8997, acc-0.4946, test loss-1.8635, acc-0.5134\n",
      "Iter-78760, train loss-1.8336, acc-0.5400, valid loss-1.8997, acc-0.4940, test loss-1.8634, acc-0.5134\n",
      "Iter-78770, train loss-2.0065, acc-0.4200, valid loss-1.8997, acc-0.4942, test loss-1.8634, acc-0.5134\n",
      "Iter-78780, train loss-1.8539, acc-0.5800, valid loss-1.8996, acc-0.4942, test loss-1.8633, acc-0.5136\n",
      "Iter-78790, train loss-1.8639, acc-0.4600, valid loss-1.8996, acc-0.4944, test loss-1.8633, acc-0.5134\n",
      "Iter-78800, train loss-1.8287, acc-0.5200, valid loss-1.8996, acc-0.4944, test loss-1.8633, acc-0.5135\n",
      "Iter-78810, train loss-1.8706, acc-0.5600, valid loss-1.8996, acc-0.4944, test loss-1.8632, acc-0.5136\n",
      "Iter-78820, train loss-1.9822, acc-0.3800, valid loss-1.8995, acc-0.4946, test loss-1.8632, acc-0.5138\n",
      "Iter-78830, train loss-1.8799, acc-0.5000, valid loss-1.8995, acc-0.4944, test loss-1.8632, acc-0.5137\n",
      "Iter-78840, train loss-1.9035, acc-0.4000, valid loss-1.8995, acc-0.4940, test loss-1.8631, acc-0.5138\n",
      "Iter-78850, train loss-1.9581, acc-0.4600, valid loss-1.8994, acc-0.4940, test loss-1.8631, acc-0.5138\n",
      "Iter-78860, train loss-1.8962, acc-0.5600, valid loss-1.8994, acc-0.4942, test loss-1.8631, acc-0.5138\n",
      "Iter-78870, train loss-1.8762, acc-0.5400, valid loss-1.8994, acc-0.4942, test loss-1.8631, acc-0.5138\n",
      "Iter-78880, train loss-1.9397, acc-0.5000, valid loss-1.8993, acc-0.4942, test loss-1.8630, acc-0.5137\n",
      "Iter-78890, train loss-1.7992, acc-0.5600, valid loss-1.8993, acc-0.4938, test loss-1.8630, acc-0.5138\n",
      "Iter-78900, train loss-1.8394, acc-0.5200, valid loss-1.8993, acc-0.4940, test loss-1.8630, acc-0.5136\n",
      "Iter-78910, train loss-1.9168, acc-0.4600, valid loss-1.8993, acc-0.4940, test loss-1.8629, acc-0.5137\n",
      "Iter-78920, train loss-1.8992, acc-0.4800, valid loss-1.8992, acc-0.4940, test loss-1.8629, acc-0.5138\n",
      "Iter-78930, train loss-1.8810, acc-0.5400, valid loss-1.8992, acc-0.4940, test loss-1.8629, acc-0.5137\n",
      "Iter-78940, train loss-2.0212, acc-0.4400, valid loss-1.8992, acc-0.4940, test loss-1.8628, acc-0.5137\n",
      "Iter-78950, train loss-1.8221, acc-0.5600, valid loss-1.8991, acc-0.4942, test loss-1.8628, acc-0.5138\n",
      "Iter-78960, train loss-1.9518, acc-0.4800, valid loss-1.8991, acc-0.4942, test loss-1.8628, acc-0.5138\n",
      "Iter-78970, train loss-1.8120, acc-0.5800, valid loss-1.8991, acc-0.4942, test loss-1.8627, acc-0.5138\n",
      "Iter-78980, train loss-1.7829, acc-0.5600, valid loss-1.8990, acc-0.4942, test loss-1.8627, acc-0.5137\n",
      "Iter-78990, train loss-1.8889, acc-0.4600, valid loss-1.8990, acc-0.4940, test loss-1.8627, acc-0.5136\n",
      "Iter-79000, train loss-1.8988, acc-0.3800, valid loss-1.8990, acc-0.4940, test loss-1.8626, acc-0.5136\n",
      "Iter-79010, train loss-1.8011, acc-0.5800, valid loss-1.8989, acc-0.4940, test loss-1.8626, acc-0.5135\n",
      "Iter-79020, train loss-1.8714, acc-0.5200, valid loss-1.8989, acc-0.4942, test loss-1.8626, acc-0.5132\n",
      "Iter-79030, train loss-1.9059, acc-0.4800, valid loss-1.8989, acc-0.4944, test loss-1.8625, acc-0.5132\n",
      "Iter-79040, train loss-1.8166, acc-0.5400, valid loss-1.8988, acc-0.4946, test loss-1.8625, acc-0.5132\n",
      "Iter-79050, train loss-1.8560, acc-0.5600, valid loss-1.8988, acc-0.4940, test loss-1.8625, acc-0.5133\n",
      "Iter-79060, train loss-1.9035, acc-0.4200, valid loss-1.8988, acc-0.4942, test loss-1.8624, acc-0.5132\n",
      "Iter-79070, train loss-1.7521, acc-0.5800, valid loss-1.8988, acc-0.4944, test loss-1.8624, acc-0.5132\n",
      "Iter-79080, train loss-1.9080, acc-0.3800, valid loss-1.8987, acc-0.4944, test loss-1.8624, acc-0.5132\n",
      "Iter-79090, train loss-1.8757, acc-0.6000, valid loss-1.8987, acc-0.4942, test loss-1.8623, acc-0.5132\n",
      "Iter-79100, train loss-1.9094, acc-0.5400, valid loss-1.8987, acc-0.4942, test loss-1.8623, acc-0.5131\n",
      "Iter-79110, train loss-1.8336, acc-0.5400, valid loss-1.8986, acc-0.4942, test loss-1.8623, acc-0.5132\n",
      "Iter-79120, train loss-1.9027, acc-0.4200, valid loss-1.8986, acc-0.4940, test loss-1.8622, acc-0.5132\n",
      "Iter-79130, train loss-1.9435, acc-0.5600, valid loss-1.8986, acc-0.4940, test loss-1.8622, acc-0.5131\n",
      "Iter-79140, train loss-1.8220, acc-0.5400, valid loss-1.8985, acc-0.4944, test loss-1.8622, acc-0.5128\n",
      "Iter-79150, train loss-2.0910, acc-0.3000, valid loss-1.8985, acc-0.4944, test loss-1.8621, acc-0.5130\n",
      "Iter-79160, train loss-1.8836, acc-0.6000, valid loss-1.8985, acc-0.4946, test loss-1.8621, acc-0.5128\n",
      "Iter-79170, train loss-1.9132, acc-0.5400, valid loss-1.8985, acc-0.4944, test loss-1.8621, acc-0.5129\n",
      "Iter-79180, train loss-1.8842, acc-0.5000, valid loss-1.8984, acc-0.4946, test loss-1.8620, acc-0.5128\n",
      "Iter-79190, train loss-1.8418, acc-0.5600, valid loss-1.8984, acc-0.4946, test loss-1.8620, acc-0.5127\n",
      "Iter-79200, train loss-1.8408, acc-0.5000, valid loss-1.8984, acc-0.4944, test loss-1.8620, acc-0.5129\n",
      "Iter-79210, train loss-1.7933, acc-0.6600, valid loss-1.8983, acc-0.4946, test loss-1.8619, acc-0.5127\n",
      "Iter-79220, train loss-1.8317, acc-0.4800, valid loss-1.8983, acc-0.4948, test loss-1.8619, acc-0.5129\n",
      "Iter-79230, train loss-1.8201, acc-0.5000, valid loss-1.8983, acc-0.4948, test loss-1.8619, acc-0.5130\n",
      "Iter-79240, train loss-1.8857, acc-0.4400, valid loss-1.8982, acc-0.4948, test loss-1.8618, acc-0.5129\n",
      "Iter-79250, train loss-1.9057, acc-0.5400, valid loss-1.8982, acc-0.4950, test loss-1.8618, acc-0.5131\n",
      "Iter-79260, train loss-2.0179, acc-0.4000, valid loss-1.8982, acc-0.4950, test loss-1.8618, acc-0.5131\n",
      "Iter-79270, train loss-1.8792, acc-0.5000, valid loss-1.8981, acc-0.4950, test loss-1.8617, acc-0.5130\n",
      "Iter-79280, train loss-1.9220, acc-0.4400, valid loss-1.8981, acc-0.4950, test loss-1.8617, acc-0.5131\n",
      "Iter-79290, train loss-1.7332, acc-0.6400, valid loss-1.8981, acc-0.4950, test loss-1.8617, acc-0.5131\n",
      "Iter-79300, train loss-1.9148, acc-0.4200, valid loss-1.8981, acc-0.4950, test loss-1.8616, acc-0.5132\n",
      "Iter-79310, train loss-1.8021, acc-0.5800, valid loss-1.8980, acc-0.4950, test loss-1.8616, acc-0.5130\n",
      "Iter-79320, train loss-1.7962, acc-0.4600, valid loss-1.8980, acc-0.4948, test loss-1.8616, acc-0.5129\n",
      "Iter-79330, train loss-1.8348, acc-0.6000, valid loss-1.8980, acc-0.4948, test loss-1.8615, acc-0.5129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-79340, train loss-1.8907, acc-0.4800, valid loss-1.8979, acc-0.4950, test loss-1.8615, acc-0.5127\n",
      "Iter-79350, train loss-1.8610, acc-0.5200, valid loss-1.8979, acc-0.4946, test loss-1.8615, acc-0.5129\n",
      "Iter-79360, train loss-1.8668, acc-0.5600, valid loss-1.8979, acc-0.4944, test loss-1.8614, acc-0.5127\n",
      "Iter-79370, train loss-1.8245, acc-0.4600, valid loss-1.8978, acc-0.4946, test loss-1.8614, acc-0.5129\n",
      "Iter-79380, train loss-1.8616, acc-0.5000, valid loss-1.8978, acc-0.4950, test loss-1.8614, acc-0.5130\n",
      "Iter-79390, train loss-1.8436, acc-0.5600, valid loss-1.8978, acc-0.4950, test loss-1.8613, acc-0.5128\n",
      "Iter-79400, train loss-1.9792, acc-0.3400, valid loss-1.8978, acc-0.4950, test loss-1.8613, acc-0.5131\n",
      "Iter-79410, train loss-1.7976, acc-0.4800, valid loss-1.8977, acc-0.4948, test loss-1.8613, acc-0.5130\n",
      "Iter-79420, train loss-1.8089, acc-0.5600, valid loss-1.8977, acc-0.4950, test loss-1.8612, acc-0.5130\n",
      "Iter-79430, train loss-1.7962, acc-0.5800, valid loss-1.8977, acc-0.4950, test loss-1.8612, acc-0.5130\n",
      "Iter-79440, train loss-1.8759, acc-0.4600, valid loss-1.8976, acc-0.4952, test loss-1.8612, acc-0.5131\n",
      "Iter-79450, train loss-1.8596, acc-0.4600, valid loss-1.8976, acc-0.4958, test loss-1.8611, acc-0.5132\n",
      "Iter-79460, train loss-1.8673, acc-0.5800, valid loss-1.8976, acc-0.4958, test loss-1.8611, acc-0.5133\n",
      "Iter-79470, train loss-1.9507, acc-0.4200, valid loss-1.8975, acc-0.4958, test loss-1.8611, acc-0.5132\n",
      "Iter-79480, train loss-1.8408, acc-0.4800, valid loss-1.8975, acc-0.4958, test loss-1.8610, acc-0.5133\n",
      "Iter-79490, train loss-1.8489, acc-0.4600, valid loss-1.8975, acc-0.4956, test loss-1.8610, acc-0.5134\n",
      "Iter-79500, train loss-1.8808, acc-0.5200, valid loss-1.8975, acc-0.4956, test loss-1.8610, acc-0.5132\n",
      "Iter-79510, train loss-1.9271, acc-0.4400, valid loss-1.8974, acc-0.4956, test loss-1.8610, acc-0.5133\n",
      "Iter-79520, train loss-1.8476, acc-0.5200, valid loss-1.8974, acc-0.4954, test loss-1.8609, acc-0.5131\n",
      "Iter-79530, train loss-1.9377, acc-0.4800, valid loss-1.8974, acc-0.4954, test loss-1.8609, acc-0.5133\n",
      "Iter-79540, train loss-1.8699, acc-0.4600, valid loss-1.8973, acc-0.4956, test loss-1.8608, acc-0.5135\n",
      "Iter-79550, train loss-1.8886, acc-0.5600, valid loss-1.8973, acc-0.4956, test loss-1.8608, acc-0.5134\n",
      "Iter-79560, train loss-1.8487, acc-0.5200, valid loss-1.8973, acc-0.4958, test loss-1.8608, acc-0.5136\n",
      "Iter-79570, train loss-1.9585, acc-0.4000, valid loss-1.8972, acc-0.4956, test loss-1.8607, acc-0.5134\n",
      "Iter-79580, train loss-1.9413, acc-0.4600, valid loss-1.8972, acc-0.4956, test loss-1.8607, acc-0.5132\n",
      "Iter-79590, train loss-1.8575, acc-0.5400, valid loss-1.8972, acc-0.4956, test loss-1.8607, acc-0.5132\n",
      "Iter-79600, train loss-1.9460, acc-0.4400, valid loss-1.8972, acc-0.4956, test loss-1.8607, acc-0.5131\n",
      "Iter-79610, train loss-1.8334, acc-0.6000, valid loss-1.8971, acc-0.4954, test loss-1.8606, acc-0.5131\n",
      "Iter-79620, train loss-1.8473, acc-0.5600, valid loss-1.8971, acc-0.4954, test loss-1.8606, acc-0.5132\n",
      "Iter-79630, train loss-1.7947, acc-0.6000, valid loss-1.8971, acc-0.4954, test loss-1.8606, acc-0.5131\n",
      "Iter-79640, train loss-1.7981, acc-0.6600, valid loss-1.8970, acc-0.4954, test loss-1.8605, acc-0.5132\n",
      "Iter-79650, train loss-1.8606, acc-0.5000, valid loss-1.8970, acc-0.4956, test loss-1.8605, acc-0.5134\n",
      "Iter-79660, train loss-1.8587, acc-0.5800, valid loss-1.8970, acc-0.4954, test loss-1.8605, acc-0.5133\n",
      "Iter-79670, train loss-1.9245, acc-0.4200, valid loss-1.8969, acc-0.4956, test loss-1.8604, acc-0.5134\n",
      "Iter-79680, train loss-1.9873, acc-0.4000, valid loss-1.8969, acc-0.4956, test loss-1.8604, acc-0.5134\n",
      "Iter-79690, train loss-1.9662, acc-0.3400, valid loss-1.8969, acc-0.4954, test loss-1.8604, acc-0.5133\n",
      "Iter-79700, train loss-1.7650, acc-0.6400, valid loss-1.8969, acc-0.4954, test loss-1.8603, acc-0.5132\n",
      "Iter-79710, train loss-1.9022, acc-0.5200, valid loss-1.8968, acc-0.4952, test loss-1.8603, acc-0.5134\n",
      "Iter-79720, train loss-1.8798, acc-0.4800, valid loss-1.8968, acc-0.4954, test loss-1.8603, acc-0.5132\n",
      "Iter-79730, train loss-1.7561, acc-0.5000, valid loss-1.8968, acc-0.4954, test loss-1.8602, acc-0.5133\n",
      "Iter-79740, train loss-1.8778, acc-0.5000, valid loss-1.8967, acc-0.4954, test loss-1.8602, acc-0.5135\n",
      "Iter-79750, train loss-1.8392, acc-0.5600, valid loss-1.8967, acc-0.4952, test loss-1.8602, acc-0.5135\n",
      "Iter-79760, train loss-1.9496, acc-0.4400, valid loss-1.8967, acc-0.4954, test loss-1.8601, acc-0.5134\n",
      "Iter-79770, train loss-1.8272, acc-0.5800, valid loss-1.8967, acc-0.4952, test loss-1.8601, acc-0.5130\n",
      "Iter-79780, train loss-1.8910, acc-0.4000, valid loss-1.8966, acc-0.4954, test loss-1.8601, acc-0.5130\n",
      "Iter-79790, train loss-1.8652, acc-0.5400, valid loss-1.8966, acc-0.4954, test loss-1.8600, acc-0.5131\n",
      "Iter-79800, train loss-2.0406, acc-0.2800, valid loss-1.8966, acc-0.4954, test loss-1.8600, acc-0.5133\n",
      "Iter-79810, train loss-1.8484, acc-0.5400, valid loss-1.8965, acc-0.4954, test loss-1.8600, acc-0.5132\n",
      "Iter-79820, train loss-1.9037, acc-0.5200, valid loss-1.8965, acc-0.4954, test loss-1.8599, acc-0.5134\n",
      "Iter-79830, train loss-1.8206, acc-0.5600, valid loss-1.8965, acc-0.4954, test loss-1.8599, acc-0.5131\n",
      "Iter-79840, train loss-1.9644, acc-0.3800, valid loss-1.8964, acc-0.4956, test loss-1.8599, acc-0.5134\n",
      "Iter-79850, train loss-1.8130, acc-0.5600, valid loss-1.8964, acc-0.4956, test loss-1.8598, acc-0.5133\n",
      "Iter-79860, train loss-1.7723, acc-0.6000, valid loss-1.8964, acc-0.4956, test loss-1.8598, acc-0.5131\n",
      "Iter-79870, train loss-1.9619, acc-0.4000, valid loss-1.8963, acc-0.4954, test loss-1.8598, acc-0.5131\n",
      "Iter-79880, train loss-1.9403, acc-0.4400, valid loss-1.8963, acc-0.4954, test loss-1.8597, acc-0.5133\n",
      "Iter-79890, train loss-1.9571, acc-0.4000, valid loss-1.8963, acc-0.4954, test loss-1.8597, acc-0.5133\n",
      "Iter-79900, train loss-1.8640, acc-0.5200, valid loss-1.8963, acc-0.4954, test loss-1.8597, acc-0.5132\n",
      "Iter-79910, train loss-1.8902, acc-0.4600, valid loss-1.8962, acc-0.4954, test loss-1.8596, acc-0.5130\n",
      "Iter-79920, train loss-1.8453, acc-0.5200, valid loss-1.8962, acc-0.4956, test loss-1.8596, acc-0.5131\n",
      "Iter-79930, train loss-1.9201, acc-0.5800, valid loss-1.8962, acc-0.4956, test loss-1.8596, acc-0.5131\n",
      "Iter-79940, train loss-1.8960, acc-0.5000, valid loss-1.8961, acc-0.4956, test loss-1.8595, acc-0.5130\n",
      "Iter-79950, train loss-1.8510, acc-0.4400, valid loss-1.8961, acc-0.4954, test loss-1.8595, acc-0.5130\n",
      "Iter-79960, train loss-1.9439, acc-0.5000, valid loss-1.8961, acc-0.4956, test loss-1.8595, acc-0.5131\n",
      "Iter-79970, train loss-1.8324, acc-0.4400, valid loss-1.8960, acc-0.4954, test loss-1.8594, acc-0.5132\n",
      "Iter-79980, train loss-1.7867, acc-0.5600, valid loss-1.8960, acc-0.4952, test loss-1.8594, acc-0.5132\n",
      "Iter-79990, train loss-1.8778, acc-0.4200, valid loss-1.8960, acc-0.4954, test loss-1.8594, acc-0.5131\n",
      "Iter-80000, train loss-1.8751, acc-0.4800, valid loss-1.8960, acc-0.4958, test loss-1.8593, acc-0.5133\n",
      "Iter-80010, train loss-1.8334, acc-0.5200, valid loss-1.8959, acc-0.4956, test loss-1.8593, acc-0.5131\n",
      "Iter-80020, train loss-1.9510, acc-0.4400, valid loss-1.8959, acc-0.4952, test loss-1.8593, acc-0.5133\n",
      "Iter-80030, train loss-1.8856, acc-0.4800, valid loss-1.8959, acc-0.4948, test loss-1.8592, acc-0.5133\n",
      "Iter-80040, train loss-1.8918, acc-0.4800, valid loss-1.8958, acc-0.4948, test loss-1.8592, acc-0.5133\n",
      "Iter-80050, train loss-1.8318, acc-0.5800, valid loss-1.8958, acc-0.4950, test loss-1.8592, acc-0.5133\n",
      "Iter-80060, train loss-1.9381, acc-0.5200, valid loss-1.8958, acc-0.4952, test loss-1.8591, acc-0.5132\n",
      "Iter-80070, train loss-1.9462, acc-0.4200, valid loss-1.8957, acc-0.4950, test loss-1.8591, acc-0.5132\n",
      "Iter-80080, train loss-1.8728, acc-0.4400, valid loss-1.8957, acc-0.4952, test loss-1.8591, acc-0.5133\n",
      "Iter-80090, train loss-1.8446, acc-0.5400, valid loss-1.8957, acc-0.4952, test loss-1.8590, acc-0.5133\n",
      "Iter-80100, train loss-1.7532, acc-0.5600, valid loss-1.8957, acc-0.4954, test loss-1.8590, acc-0.5134\n",
      "Iter-80110, train loss-1.8104, acc-0.6200, valid loss-1.8956, acc-0.4954, test loss-1.8590, acc-0.5135\n",
      "Iter-80120, train loss-1.8533, acc-0.6000, valid loss-1.8956, acc-0.4954, test loss-1.8589, acc-0.5134\n",
      "Iter-80130, train loss-1.8925, acc-0.5400, valid loss-1.8956, acc-0.4958, test loss-1.8589, acc-0.5134\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-80140, train loss-1.8297, acc-0.5800, valid loss-1.8955, acc-0.4956, test loss-1.8589, acc-0.5133\n",
      "Iter-80150, train loss-1.8731, acc-0.5400, valid loss-1.8955, acc-0.4954, test loss-1.8588, acc-0.5134\n",
      "Iter-80160, train loss-1.8748, acc-0.4400, valid loss-1.8955, acc-0.4956, test loss-1.8588, acc-0.5131\n",
      "Iter-80170, train loss-1.8734, acc-0.4600, valid loss-1.8955, acc-0.4954, test loss-1.8588, acc-0.5132\n",
      "Iter-80180, train loss-1.8045, acc-0.5200, valid loss-1.8954, acc-0.4958, test loss-1.8588, acc-0.5131\n",
      "Iter-80190, train loss-1.8498, acc-0.6200, valid loss-1.8954, acc-0.4954, test loss-1.8587, acc-0.5132\n",
      "Iter-80200, train loss-1.9655, acc-0.4000, valid loss-1.8954, acc-0.4954, test loss-1.8587, acc-0.5134\n",
      "Iter-80210, train loss-1.9374, acc-0.4800, valid loss-1.8953, acc-0.4956, test loss-1.8587, acc-0.5134\n",
      "Iter-80220, train loss-1.9075, acc-0.5200, valid loss-1.8953, acc-0.4956, test loss-1.8586, acc-0.5134\n",
      "Iter-80230, train loss-1.7931, acc-0.5800, valid loss-1.8953, acc-0.4956, test loss-1.8586, acc-0.5134\n",
      "Iter-80240, train loss-1.9124, acc-0.5000, valid loss-1.8953, acc-0.4958, test loss-1.8586, acc-0.5137\n",
      "Iter-80250, train loss-1.9157, acc-0.3000, valid loss-1.8952, acc-0.4958, test loss-1.8585, acc-0.5135\n",
      "Iter-80260, train loss-1.8740, acc-0.4800, valid loss-1.8952, acc-0.4958, test loss-1.8585, acc-0.5136\n",
      "Iter-80270, train loss-1.9091, acc-0.4400, valid loss-1.8952, acc-0.4958, test loss-1.8585, acc-0.5135\n",
      "Iter-80280, train loss-1.8364, acc-0.5600, valid loss-1.8951, acc-0.4958, test loss-1.8584, acc-0.5135\n",
      "Iter-80290, train loss-1.8439, acc-0.5000, valid loss-1.8951, acc-0.4958, test loss-1.8584, acc-0.5138\n",
      "Iter-80300, train loss-1.8213, acc-0.5000, valid loss-1.8951, acc-0.4956, test loss-1.8584, acc-0.5135\n",
      "Iter-80310, train loss-1.8927, acc-0.4600, valid loss-1.8950, acc-0.4956, test loss-1.8583, acc-0.5134\n",
      "Iter-80320, train loss-1.9490, acc-0.3600, valid loss-1.8950, acc-0.4956, test loss-1.8583, acc-0.5138\n",
      "Iter-80330, train loss-1.8509, acc-0.5000, valid loss-1.8950, acc-0.4956, test loss-1.8583, acc-0.5137\n",
      "Iter-80340, train loss-1.8662, acc-0.5000, valid loss-1.8950, acc-0.4954, test loss-1.8582, acc-0.5135\n",
      "Iter-80350, train loss-1.8767, acc-0.4400, valid loss-1.8949, acc-0.4954, test loss-1.8582, acc-0.5136\n",
      "Iter-80360, train loss-1.7545, acc-0.6800, valid loss-1.8949, acc-0.4954, test loss-1.8582, acc-0.5136\n",
      "Iter-80370, train loss-1.8344, acc-0.5400, valid loss-1.8949, acc-0.4956, test loss-1.8581, acc-0.5135\n",
      "Iter-80380, train loss-1.9491, acc-0.4200, valid loss-1.8948, acc-0.4950, test loss-1.8581, acc-0.5134\n",
      "Iter-80390, train loss-1.8473, acc-0.5000, valid loss-1.8948, acc-0.4954, test loss-1.8581, acc-0.5134\n",
      "Iter-80400, train loss-1.9417, acc-0.5600, valid loss-1.8948, acc-0.4956, test loss-1.8580, acc-0.5134\n",
      "Iter-80410, train loss-1.8737, acc-0.3600, valid loss-1.8947, acc-0.4956, test loss-1.8580, acc-0.5136\n",
      "Iter-80420, train loss-1.8982, acc-0.4400, valid loss-1.8947, acc-0.4956, test loss-1.8580, acc-0.5132\n",
      "Iter-80430, train loss-1.8357, acc-0.4800, valid loss-1.8947, acc-0.4956, test loss-1.8579, acc-0.5133\n",
      "Iter-80440, train loss-1.8562, acc-0.5400, valid loss-1.8946, acc-0.4958, test loss-1.8579, acc-0.5132\n",
      "Iter-80450, train loss-1.9223, acc-0.4800, valid loss-1.8946, acc-0.4958, test loss-1.8579, acc-0.5132\n",
      "Iter-80460, train loss-1.8560, acc-0.4200, valid loss-1.8946, acc-0.4958, test loss-1.8578, acc-0.5133\n",
      "Iter-80470, train loss-1.7504, acc-0.5400, valid loss-1.8946, acc-0.4958, test loss-1.8578, acc-0.5135\n",
      "Iter-80480, train loss-1.8822, acc-0.4800, valid loss-1.8945, acc-0.4958, test loss-1.8578, acc-0.5134\n",
      "Iter-80490, train loss-1.8541, acc-0.5200, valid loss-1.8945, acc-0.4958, test loss-1.8577, acc-0.5133\n",
      "Iter-80500, train loss-1.9162, acc-0.4200, valid loss-1.8945, acc-0.4958, test loss-1.8577, acc-0.5134\n",
      "Iter-80510, train loss-1.7790, acc-0.5600, valid loss-1.8944, acc-0.4960, test loss-1.8577, acc-0.5135\n",
      "Iter-80520, train loss-1.8018, acc-0.6000, valid loss-1.8944, acc-0.4962, test loss-1.8576, acc-0.5134\n",
      "Iter-80530, train loss-1.8806, acc-0.5200, valid loss-1.8944, acc-0.4962, test loss-1.8576, acc-0.5134\n",
      "Iter-80540, train loss-1.9762, acc-0.4400, valid loss-1.8944, acc-0.4962, test loss-1.8576, acc-0.5134\n",
      "Iter-80550, train loss-1.8374, acc-0.5600, valid loss-1.8943, acc-0.4960, test loss-1.8575, acc-0.5135\n",
      "Iter-80560, train loss-1.8833, acc-0.4800, valid loss-1.8943, acc-0.4962, test loss-1.8575, acc-0.5136\n",
      "Iter-80570, train loss-1.8765, acc-0.5000, valid loss-1.8943, acc-0.4962, test loss-1.8575, acc-0.5135\n",
      "Iter-80580, train loss-1.8463, acc-0.5600, valid loss-1.8942, acc-0.4962, test loss-1.8574, acc-0.5135\n",
      "Iter-80590, train loss-1.8636, acc-0.4000, valid loss-1.8942, acc-0.4962, test loss-1.8574, acc-0.5136\n",
      "Iter-80600, train loss-1.9461, acc-0.5000, valid loss-1.8942, acc-0.4962, test loss-1.8574, acc-0.5136\n",
      "Iter-80610, train loss-1.9795, acc-0.3400, valid loss-1.8941, acc-0.4964, test loss-1.8573, acc-0.5136\n",
      "Iter-80620, train loss-1.9961, acc-0.4400, valid loss-1.8941, acc-0.4966, test loss-1.8573, acc-0.5136\n",
      "Iter-80630, train loss-1.9296, acc-0.4400, valid loss-1.8941, acc-0.4966, test loss-1.8573, acc-0.5137\n",
      "Iter-80640, train loss-1.9251, acc-0.4600, valid loss-1.8940, acc-0.4964, test loss-1.8572, acc-0.5137\n",
      "Iter-80650, train loss-1.7829, acc-0.6200, valid loss-1.8940, acc-0.4964, test loss-1.8572, acc-0.5137\n",
      "Iter-80660, train loss-1.8636, acc-0.4800, valid loss-1.8940, acc-0.4964, test loss-1.8572, acc-0.5137\n",
      "Iter-80670, train loss-1.9330, acc-0.4800, valid loss-1.8940, acc-0.4966, test loss-1.8571, acc-0.5138\n",
      "Iter-80680, train loss-1.8676, acc-0.5200, valid loss-1.8939, acc-0.4966, test loss-1.8571, acc-0.5138\n",
      "Iter-80690, train loss-1.8774, acc-0.5000, valid loss-1.8939, acc-0.4966, test loss-1.8571, acc-0.5138\n",
      "Iter-80700, train loss-1.9695, acc-0.3800, valid loss-1.8939, acc-0.4966, test loss-1.8570, acc-0.5139\n",
      "Iter-80710, train loss-1.8192, acc-0.5400, valid loss-1.8938, acc-0.4966, test loss-1.8570, acc-0.5138\n",
      "Iter-80720, train loss-1.8654, acc-0.4600, valid loss-1.8938, acc-0.4964, test loss-1.8570, acc-0.5139\n",
      "Iter-80730, train loss-1.9102, acc-0.5200, valid loss-1.8938, acc-0.4964, test loss-1.8569, acc-0.5138\n",
      "Iter-80740, train loss-1.9189, acc-0.6200, valid loss-1.8937, acc-0.4960, test loss-1.8569, acc-0.5139\n",
      "Iter-80750, train loss-1.8919, acc-0.4800, valid loss-1.8937, acc-0.4962, test loss-1.8569, acc-0.5137\n",
      "Iter-80760, train loss-1.9429, acc-0.3600, valid loss-1.8937, acc-0.4964, test loss-1.8569, acc-0.5137\n",
      "Iter-80770, train loss-1.8568, acc-0.5600, valid loss-1.8937, acc-0.4964, test loss-1.8568, acc-0.5137\n",
      "Iter-80780, train loss-1.8510, acc-0.5600, valid loss-1.8936, acc-0.4964, test loss-1.8568, acc-0.5137\n",
      "Iter-80790, train loss-1.8983, acc-0.4200, valid loss-1.8936, acc-0.4962, test loss-1.8568, acc-0.5136\n",
      "Iter-80800, train loss-1.7807, acc-0.5400, valid loss-1.8936, acc-0.4962, test loss-1.8567, acc-0.5136\n",
      "Iter-80810, train loss-1.8588, acc-0.5600, valid loss-1.8935, acc-0.4962, test loss-1.8567, acc-0.5136\n",
      "Iter-80820, train loss-1.8471, acc-0.6000, valid loss-1.8935, acc-0.4962, test loss-1.8567, acc-0.5137\n",
      "Iter-80830, train loss-1.8317, acc-0.5200, valid loss-1.8935, acc-0.4962, test loss-1.8566, acc-0.5137\n",
      "Iter-80840, train loss-2.0111, acc-0.4800, valid loss-1.8934, acc-0.4962, test loss-1.8566, acc-0.5137\n",
      "Iter-80850, train loss-1.9965, acc-0.4200, valid loss-1.8934, acc-0.4962, test loss-1.8566, acc-0.5137\n",
      "Iter-80860, train loss-1.8578, acc-0.5000, valid loss-1.8934, acc-0.4956, test loss-1.8565, acc-0.5136\n",
      "Iter-80870, train loss-1.9397, acc-0.4800, valid loss-1.8934, acc-0.4964, test loss-1.8565, acc-0.5138\n",
      "Iter-80880, train loss-1.8843, acc-0.5000, valid loss-1.8933, acc-0.4960, test loss-1.8565, acc-0.5137\n",
      "Iter-80890, train loss-1.8394, acc-0.4400, valid loss-1.8933, acc-0.4956, test loss-1.8564, acc-0.5137\n",
      "Iter-80900, train loss-1.6890, acc-0.7000, valid loss-1.8933, acc-0.4958, test loss-1.8564, acc-0.5137\n",
      "Iter-80910, train loss-1.8680, acc-0.6200, valid loss-1.8932, acc-0.4958, test loss-1.8564, acc-0.5137\n",
      "Iter-80920, train loss-1.8422, acc-0.4800, valid loss-1.8932, acc-0.4958, test loss-1.8563, acc-0.5137\n",
      "Iter-80930, train loss-1.8806, acc-0.4600, valid loss-1.8932, acc-0.4958, test loss-1.8563, acc-0.5136\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-80940, train loss-1.8642, acc-0.5600, valid loss-1.8931, acc-0.4954, test loss-1.8563, acc-0.5135\n",
      "Iter-80950, train loss-1.7364, acc-0.5800, valid loss-1.8931, acc-0.4954, test loss-1.8562, acc-0.5137\n",
      "Iter-80960, train loss-1.7979, acc-0.5600, valid loss-1.8931, acc-0.4956, test loss-1.8562, acc-0.5137\n",
      "Iter-80970, train loss-1.8188, acc-0.6000, valid loss-1.8930, acc-0.4954, test loss-1.8562, acc-0.5135\n",
      "Iter-80980, train loss-1.8613, acc-0.4800, valid loss-1.8930, acc-0.4956, test loss-1.8561, acc-0.5136\n",
      "Iter-80990, train loss-1.8637, acc-0.5000, valid loss-1.8930, acc-0.4960, test loss-1.8561, acc-0.5135\n",
      "Iter-81000, train loss-1.8529, acc-0.6000, valid loss-1.8930, acc-0.4960, test loss-1.8561, acc-0.5136\n",
      "Iter-81010, train loss-1.8869, acc-0.5200, valid loss-1.8929, acc-0.4958, test loss-1.8560, acc-0.5135\n",
      "Iter-81020, train loss-1.7663, acc-0.6200, valid loss-1.8929, acc-0.4962, test loss-1.8560, acc-0.5135\n",
      "Iter-81030, train loss-1.8587, acc-0.5200, valid loss-1.8929, acc-0.4960, test loss-1.8560, acc-0.5135\n",
      "Iter-81040, train loss-1.7978, acc-0.5600, valid loss-1.8928, acc-0.4962, test loss-1.8559, acc-0.5135\n",
      "Iter-81050, train loss-1.9108, acc-0.5000, valid loss-1.8928, acc-0.4958, test loss-1.8559, acc-0.5135\n",
      "Iter-81060, train loss-1.7554, acc-0.6200, valid loss-1.8928, acc-0.4960, test loss-1.8559, acc-0.5135\n",
      "Iter-81070, train loss-1.9317, acc-0.3800, valid loss-1.8928, acc-0.4960, test loss-1.8559, acc-0.5134\n",
      "Iter-81080, train loss-1.8454, acc-0.5800, valid loss-1.8927, acc-0.4960, test loss-1.8558, acc-0.5135\n",
      "Iter-81090, train loss-1.8434, acc-0.6400, valid loss-1.8927, acc-0.4962, test loss-1.8558, acc-0.5135\n",
      "Iter-81100, train loss-1.8649, acc-0.5000, valid loss-1.8927, acc-0.4960, test loss-1.8558, acc-0.5135\n",
      "Iter-81110, train loss-1.8928, acc-0.5400, valid loss-1.8926, acc-0.4958, test loss-1.8557, acc-0.5135\n",
      "Iter-81120, train loss-1.8156, acc-0.5600, valid loss-1.8926, acc-0.4958, test loss-1.8557, acc-0.5135\n",
      "Iter-81130, train loss-1.8657, acc-0.5400, valid loss-1.8926, acc-0.4958, test loss-1.8557, acc-0.5135\n",
      "Iter-81140, train loss-1.8661, acc-0.5200, valid loss-1.8926, acc-0.4960, test loss-1.8556, acc-0.5136\n",
      "Iter-81150, train loss-1.8862, acc-0.4200, valid loss-1.8925, acc-0.4960, test loss-1.8556, acc-0.5136\n",
      "Iter-81160, train loss-1.8714, acc-0.5600, valid loss-1.8925, acc-0.4960, test loss-1.8556, acc-0.5135\n",
      "Iter-81170, train loss-1.7658, acc-0.6600, valid loss-1.8925, acc-0.4962, test loss-1.8555, acc-0.5137\n",
      "Iter-81180, train loss-1.8358, acc-0.5000, valid loss-1.8924, acc-0.4960, test loss-1.8555, acc-0.5136\n",
      "Iter-81190, train loss-1.8635, acc-0.4800, valid loss-1.8924, acc-0.4958, test loss-1.8555, acc-0.5137\n",
      "Iter-81200, train loss-1.9132, acc-0.4200, valid loss-1.8924, acc-0.4956, test loss-1.8554, acc-0.5138\n",
      "Iter-81210, train loss-1.8387, acc-0.4800, valid loss-1.8923, acc-0.4960, test loss-1.8554, acc-0.5139\n",
      "Iter-81220, train loss-1.8937, acc-0.5600, valid loss-1.8923, acc-0.4960, test loss-1.8554, acc-0.5138\n",
      "Iter-81230, train loss-1.8457, acc-0.4800, valid loss-1.8923, acc-0.4954, test loss-1.8553, acc-0.5138\n",
      "Iter-81240, train loss-1.9175, acc-0.5600, valid loss-1.8923, acc-0.4954, test loss-1.8553, acc-0.5138\n",
      "Iter-81250, train loss-1.8159, acc-0.5000, valid loss-1.8922, acc-0.4954, test loss-1.8553, acc-0.5139\n",
      "Iter-81260, train loss-1.7806, acc-0.6000, valid loss-1.8922, acc-0.4956, test loss-1.8552, acc-0.5139\n",
      "Iter-81270, train loss-1.7872, acc-0.5000, valid loss-1.8922, acc-0.4956, test loss-1.8552, acc-0.5139\n",
      "Iter-81280, train loss-1.8912, acc-0.4400, valid loss-1.8921, acc-0.4956, test loss-1.8552, acc-0.5139\n",
      "Iter-81290, train loss-1.9015, acc-0.4600, valid loss-1.8921, acc-0.4958, test loss-1.8551, acc-0.5138\n",
      "Iter-81300, train loss-1.9268, acc-0.5000, valid loss-1.8921, acc-0.4958, test loss-1.8551, acc-0.5138\n",
      "Iter-81310, train loss-1.9801, acc-0.4000, valid loss-1.8921, acc-0.4958, test loss-1.8551, acc-0.5138\n",
      "Iter-81320, train loss-1.8680, acc-0.5200, valid loss-1.8920, acc-0.4956, test loss-1.8550, acc-0.5140\n",
      "Iter-81330, train loss-1.8260, acc-0.6000, valid loss-1.8920, acc-0.4954, test loss-1.8550, acc-0.5140\n",
      "Iter-81340, train loss-1.8534, acc-0.5800, valid loss-1.8920, acc-0.4950, test loss-1.8550, acc-0.5138\n",
      "Iter-81350, train loss-1.7145, acc-0.6800, valid loss-1.8919, acc-0.4956, test loss-1.8550, acc-0.5139\n",
      "Iter-81360, train loss-1.8473, acc-0.5400, valid loss-1.8919, acc-0.4954, test loss-1.8549, acc-0.5137\n",
      "Iter-81370, train loss-1.8083, acc-0.4800, valid loss-1.8919, acc-0.4954, test loss-1.8549, acc-0.5137\n",
      "Iter-81380, train loss-1.8603, acc-0.4600, valid loss-1.8918, acc-0.4956, test loss-1.8549, acc-0.5137\n",
      "Iter-81390, train loss-1.8574, acc-0.4400, valid loss-1.8918, acc-0.4956, test loss-1.8548, acc-0.5137\n",
      "Iter-81400, train loss-1.7610, acc-0.6400, valid loss-1.8918, acc-0.4958, test loss-1.8548, acc-0.5138\n",
      "Iter-81410, train loss-1.8466, acc-0.4000, valid loss-1.8917, acc-0.4958, test loss-1.8548, acc-0.5138\n",
      "Iter-81420, train loss-1.9290, acc-0.4000, valid loss-1.8917, acc-0.4956, test loss-1.8547, acc-0.5137\n",
      "Iter-81430, train loss-1.8385, acc-0.4000, valid loss-1.8917, acc-0.4958, test loss-1.8547, acc-0.5140\n",
      "Iter-81440, train loss-1.8023, acc-0.6000, valid loss-1.8917, acc-0.4960, test loss-1.8547, acc-0.5140\n",
      "Iter-81450, train loss-1.9584, acc-0.4400, valid loss-1.8916, acc-0.4954, test loss-1.8546, acc-0.5139\n",
      "Iter-81460, train loss-1.7953, acc-0.6000, valid loss-1.8916, acc-0.4954, test loss-1.8546, acc-0.5138\n",
      "Iter-81470, train loss-1.8361, acc-0.6000, valid loss-1.8916, acc-0.4958, test loss-1.8546, acc-0.5139\n",
      "Iter-81480, train loss-1.9584, acc-0.3200, valid loss-1.8915, acc-0.4956, test loss-1.8545, acc-0.5140\n",
      "Iter-81490, train loss-1.9159, acc-0.4800, valid loss-1.8915, acc-0.4960, test loss-1.8545, acc-0.5142\n",
      "Iter-81500, train loss-1.8462, acc-0.6000, valid loss-1.8915, acc-0.4962, test loss-1.8545, acc-0.5140\n",
      "Iter-81510, train loss-1.8951, acc-0.5400, valid loss-1.8915, acc-0.4958, test loss-1.8544, acc-0.5141\n",
      "Iter-81520, train loss-1.9017, acc-0.5000, valid loss-1.8914, acc-0.4962, test loss-1.8544, acc-0.5141\n",
      "Iter-81530, train loss-1.8502, acc-0.5400, valid loss-1.8914, acc-0.4966, test loss-1.8544, acc-0.5142\n",
      "Iter-81540, train loss-1.9230, acc-0.4600, valid loss-1.8914, acc-0.4964, test loss-1.8543, acc-0.5143\n",
      "Iter-81550, train loss-1.8917, acc-0.5000, valid loss-1.8913, acc-0.4960, test loss-1.8543, acc-0.5142\n",
      "Iter-81560, train loss-1.8283, acc-0.4800, valid loss-1.8913, acc-0.4964, test loss-1.8543, acc-0.5141\n",
      "Iter-81570, train loss-1.9003, acc-0.4000, valid loss-1.8913, acc-0.4962, test loss-1.8542, acc-0.5141\n",
      "Iter-81580, train loss-1.9102, acc-0.4600, valid loss-1.8913, acc-0.4964, test loss-1.8542, acc-0.5142\n",
      "Iter-81590, train loss-1.9043, acc-0.4400, valid loss-1.8912, acc-0.4966, test loss-1.8542, acc-0.5143\n",
      "Iter-81600, train loss-1.7282, acc-0.6200, valid loss-1.8912, acc-0.4966, test loss-1.8541, acc-0.5144\n",
      "Iter-81610, train loss-1.8432, acc-0.5600, valid loss-1.8912, acc-0.4966, test loss-1.8541, acc-0.5145\n",
      "Iter-81620, train loss-1.7294, acc-0.6400, valid loss-1.8911, acc-0.4966, test loss-1.8541, acc-0.5143\n",
      "Iter-81630, train loss-1.8507, acc-0.4400, valid loss-1.8911, acc-0.4964, test loss-1.8540, acc-0.5144\n",
      "Iter-81640, train loss-1.8173, acc-0.6000, valid loss-1.8911, acc-0.4966, test loss-1.8540, acc-0.5146\n",
      "Iter-81650, train loss-1.7775, acc-0.5800, valid loss-1.8911, acc-0.4964, test loss-1.8540, acc-0.5145\n",
      "Iter-81660, train loss-1.9177, acc-0.3600, valid loss-1.8910, acc-0.4966, test loss-1.8540, acc-0.5143\n",
      "Iter-81670, train loss-1.9083, acc-0.5600, valid loss-1.8910, acc-0.4964, test loss-1.8539, acc-0.5144\n",
      "Iter-81680, train loss-1.8622, acc-0.4800, valid loss-1.8910, acc-0.4966, test loss-1.8539, acc-0.5144\n",
      "Iter-81690, train loss-1.9634, acc-0.4200, valid loss-1.8909, acc-0.4966, test loss-1.8539, acc-0.5143\n",
      "Iter-81700, train loss-1.8963, acc-0.4600, valid loss-1.8909, acc-0.4966, test loss-1.8538, acc-0.5142\n",
      "Iter-81710, train loss-1.8115, acc-0.5600, valid loss-1.8909, acc-0.4966, test loss-1.8538, acc-0.5143\n",
      "Iter-81720, train loss-1.7912, acc-0.6000, valid loss-1.8908, acc-0.4966, test loss-1.8538, acc-0.5142\n",
      "Iter-81730, train loss-1.8795, acc-0.4000, valid loss-1.8908, acc-0.4966, test loss-1.8537, acc-0.5142\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-81740, train loss-1.8240, acc-0.5400, valid loss-1.8908, acc-0.4968, test loss-1.8537, acc-0.5142\n",
      "Iter-81750, train loss-1.7300, acc-0.5600, valid loss-1.8908, acc-0.4966, test loss-1.8537, acc-0.5140\n",
      "Iter-81760, train loss-1.8180, acc-0.5600, valid loss-1.8907, acc-0.4966, test loss-1.8536, acc-0.5140\n",
      "Iter-81770, train loss-1.8848, acc-0.5600, valid loss-1.8907, acc-0.4966, test loss-1.8536, acc-0.5140\n",
      "Iter-81780, train loss-1.9138, acc-0.4000, valid loss-1.8907, acc-0.4966, test loss-1.8536, acc-0.5140\n",
      "Iter-81790, train loss-1.8688, acc-0.4800, valid loss-1.8906, acc-0.4966, test loss-1.8535, acc-0.5140\n",
      "Iter-81800, train loss-1.7551, acc-0.6000, valid loss-1.8906, acc-0.4968, test loss-1.8535, acc-0.5140\n",
      "Iter-81810, train loss-1.8271, acc-0.5200, valid loss-1.8906, acc-0.4966, test loss-1.8535, acc-0.5140\n",
      "Iter-81820, train loss-1.8555, acc-0.5800, valid loss-1.8906, acc-0.4966, test loss-1.8534, acc-0.5140\n",
      "Iter-81830, train loss-1.9090, acc-0.4800, valid loss-1.8905, acc-0.4968, test loss-1.8534, acc-0.5142\n",
      "Iter-81840, train loss-1.8225, acc-0.4800, valid loss-1.8905, acc-0.4970, test loss-1.8534, acc-0.5141\n",
      "Iter-81850, train loss-1.8347, acc-0.5800, valid loss-1.8905, acc-0.4966, test loss-1.8533, acc-0.5142\n",
      "Iter-81860, train loss-1.8266, acc-0.6000, valid loss-1.8904, acc-0.4966, test loss-1.8533, acc-0.5142\n",
      "Iter-81870, train loss-1.8866, acc-0.4200, valid loss-1.8904, acc-0.4966, test loss-1.8533, acc-0.5143\n",
      "Iter-81880, train loss-1.8724, acc-0.5200, valid loss-1.8904, acc-0.4966, test loss-1.8532, acc-0.5142\n",
      "Iter-81890, train loss-1.9283, acc-0.4200, valid loss-1.8904, acc-0.4966, test loss-1.8532, acc-0.5143\n",
      "Iter-81900, train loss-1.8763, acc-0.5200, valid loss-1.8903, acc-0.4968, test loss-1.8532, acc-0.5142\n",
      "Iter-81910, train loss-1.8186, acc-0.5000, valid loss-1.8903, acc-0.4968, test loss-1.8531, acc-0.5142\n",
      "Iter-81920, train loss-1.8756, acc-0.4400, valid loss-1.8903, acc-0.4966, test loss-1.8531, acc-0.5142\n",
      "Iter-81930, train loss-1.9435, acc-0.4800, valid loss-1.8902, acc-0.4968, test loss-1.8531, acc-0.5142\n",
      "Iter-81940, train loss-1.8650, acc-0.5000, valid loss-1.8902, acc-0.4970, test loss-1.8530, acc-0.5143\n",
      "Iter-81950, train loss-1.8310, acc-0.5000, valid loss-1.8902, acc-0.4968, test loss-1.8530, acc-0.5144\n",
      "Iter-81960, train loss-1.9428, acc-0.4800, valid loss-1.8901, acc-0.4970, test loss-1.8530, acc-0.5144\n",
      "Iter-81970, train loss-1.8244, acc-0.5400, valid loss-1.8901, acc-0.4970, test loss-1.8530, acc-0.5144\n",
      "Iter-81980, train loss-1.8844, acc-0.4400, valid loss-1.8901, acc-0.4970, test loss-1.8529, acc-0.5144\n",
      "Iter-81990, train loss-1.8397, acc-0.5000, valid loss-1.8901, acc-0.4970, test loss-1.8529, acc-0.5144\n",
      "Iter-82000, train loss-1.7992, acc-0.6600, valid loss-1.8900, acc-0.4970, test loss-1.8529, acc-0.5144\n",
      "Iter-82010, train loss-1.8661, acc-0.5200, valid loss-1.8900, acc-0.4970, test loss-1.8528, acc-0.5144\n",
      "Iter-82020, train loss-1.7260, acc-0.6400, valid loss-1.8900, acc-0.4968, test loss-1.8528, acc-0.5144\n",
      "Iter-82030, train loss-1.7973, acc-0.6200, valid loss-1.8899, acc-0.4968, test loss-1.8528, acc-0.5144\n",
      "Iter-82040, train loss-1.7826, acc-0.5600, valid loss-1.8899, acc-0.4970, test loss-1.8527, acc-0.5143\n",
      "Iter-82050, train loss-1.8181, acc-0.4400, valid loss-1.8899, acc-0.4970, test loss-1.8527, acc-0.5144\n",
      "Iter-82060, train loss-1.8675, acc-0.4800, valid loss-1.8899, acc-0.4972, test loss-1.8527, acc-0.5145\n",
      "Iter-82070, train loss-1.7629, acc-0.6600, valid loss-1.8898, acc-0.4970, test loss-1.8526, acc-0.5145\n",
      "Iter-82080, train loss-1.8070, acc-0.5000, valid loss-1.8898, acc-0.4970, test loss-1.8526, acc-0.5147\n",
      "Iter-82090, train loss-1.9437, acc-0.5200, valid loss-1.8898, acc-0.4970, test loss-1.8526, acc-0.5146\n",
      "Iter-82100, train loss-1.8423, acc-0.5400, valid loss-1.8897, acc-0.4970, test loss-1.8525, acc-0.5146\n",
      "Iter-82110, train loss-1.9039, acc-0.4200, valid loss-1.8897, acc-0.4972, test loss-1.8525, acc-0.5145\n",
      "Iter-82120, train loss-1.9025, acc-0.5200, valid loss-1.8897, acc-0.4972, test loss-1.8525, acc-0.5145\n",
      "Iter-82130, train loss-1.9946, acc-0.4800, valid loss-1.8897, acc-0.4970, test loss-1.8524, acc-0.5144\n",
      "Iter-82140, train loss-1.8642, acc-0.5800, valid loss-1.8896, acc-0.4972, test loss-1.8524, acc-0.5146\n",
      "Iter-82150, train loss-1.9160, acc-0.5600, valid loss-1.8896, acc-0.4972, test loss-1.8524, acc-0.5145\n",
      "Iter-82160, train loss-1.9574, acc-0.3600, valid loss-1.8896, acc-0.4972, test loss-1.8523, acc-0.5147\n",
      "Iter-82170, train loss-1.9234, acc-0.5800, valid loss-1.8895, acc-0.4972, test loss-1.8523, acc-0.5145\n",
      "Iter-82180, train loss-1.8017, acc-0.4400, valid loss-1.8895, acc-0.4972, test loss-1.8523, acc-0.5147\n",
      "Iter-82190, train loss-1.8147, acc-0.5400, valid loss-1.8895, acc-0.4972, test loss-1.8522, acc-0.5148\n",
      "Iter-82200, train loss-1.7718, acc-0.5600, valid loss-1.8894, acc-0.4972, test loss-1.8522, acc-0.5148\n",
      "Iter-82210, train loss-1.8502, acc-0.5600, valid loss-1.8894, acc-0.4974, test loss-1.8522, acc-0.5145\n",
      "Iter-82220, train loss-1.8623, acc-0.5400, valid loss-1.8894, acc-0.4974, test loss-1.8522, acc-0.5146\n",
      "Iter-82230, train loss-1.8576, acc-0.4800, valid loss-1.8893, acc-0.4972, test loss-1.8521, acc-0.5145\n",
      "Iter-82240, train loss-1.8587, acc-0.5800, valid loss-1.8893, acc-0.4970, test loss-1.8521, acc-0.5146\n",
      "Iter-82250, train loss-1.8392, acc-0.5800, valid loss-1.8893, acc-0.4972, test loss-1.8521, acc-0.5145\n",
      "Iter-82260, train loss-1.9095, acc-0.5400, valid loss-1.8893, acc-0.4972, test loss-1.8520, acc-0.5147\n",
      "Iter-82270, train loss-1.9343, acc-0.4600, valid loss-1.8892, acc-0.4970, test loss-1.8520, acc-0.5146\n",
      "Iter-82280, train loss-1.9114, acc-0.5200, valid loss-1.8892, acc-0.4970, test loss-1.8520, acc-0.5145\n",
      "Iter-82290, train loss-1.8570, acc-0.4200, valid loss-1.8892, acc-0.4968, test loss-1.8519, acc-0.5144\n",
      "Iter-82300, train loss-1.8214, acc-0.5400, valid loss-1.8891, acc-0.4966, test loss-1.8519, acc-0.5147\n",
      "Iter-82310, train loss-1.8639, acc-0.4600, valid loss-1.8891, acc-0.4970, test loss-1.8519, acc-0.5145\n",
      "Iter-82320, train loss-1.9166, acc-0.5600, valid loss-1.8891, acc-0.4966, test loss-1.8518, acc-0.5147\n",
      "Iter-82330, train loss-1.8931, acc-0.5200, valid loss-1.8891, acc-0.4966, test loss-1.8518, acc-0.5147\n",
      "Iter-82340, train loss-1.8380, acc-0.5800, valid loss-1.8890, acc-0.4966, test loss-1.8518, acc-0.5146\n",
      "Iter-82350, train loss-1.8860, acc-0.4200, valid loss-1.8890, acc-0.4966, test loss-1.8517, acc-0.5147\n",
      "Iter-82360, train loss-1.8151, acc-0.5200, valid loss-1.8890, acc-0.4968, test loss-1.8517, acc-0.5147\n",
      "Iter-82370, train loss-1.8337, acc-0.5200, valid loss-1.8889, acc-0.4964, test loss-1.8517, acc-0.5147\n",
      "Iter-82380, train loss-1.8768, acc-0.4200, valid loss-1.8889, acc-0.4968, test loss-1.8516, acc-0.5146\n",
      "Iter-82390, train loss-1.8628, acc-0.5200, valid loss-1.8889, acc-0.4966, test loss-1.8516, acc-0.5148\n",
      "Iter-82400, train loss-1.8594, acc-0.6200, valid loss-1.8889, acc-0.4966, test loss-1.8516, acc-0.5147\n",
      "Iter-82410, train loss-1.8566, acc-0.5000, valid loss-1.8888, acc-0.4968, test loss-1.8516, acc-0.5147\n",
      "Iter-82420, train loss-1.9520, acc-0.4600, valid loss-1.8888, acc-0.4970, test loss-1.8515, acc-0.5147\n",
      "Iter-82430, train loss-1.8499, acc-0.5200, valid loss-1.8888, acc-0.4972, test loss-1.8515, acc-0.5147\n",
      "Iter-82440, train loss-1.9645, acc-0.4600, valid loss-1.8888, acc-0.4972, test loss-1.8515, acc-0.5147\n",
      "Iter-82450, train loss-1.8981, acc-0.4400, valid loss-1.8887, acc-0.4972, test loss-1.8514, acc-0.5147\n",
      "Iter-82460, train loss-1.8081, acc-0.5600, valid loss-1.8887, acc-0.4972, test loss-1.8514, acc-0.5147\n",
      "Iter-82470, train loss-1.8645, acc-0.6200, valid loss-1.8887, acc-0.4974, test loss-1.8514, acc-0.5147\n",
      "Iter-82480, train loss-2.0322, acc-0.3400, valid loss-1.8886, acc-0.4974, test loss-1.8513, acc-0.5148\n",
      "Iter-82490, train loss-1.8346, acc-0.5200, valid loss-1.8886, acc-0.4972, test loss-1.8513, acc-0.5148\n",
      "Iter-82500, train loss-1.9187, acc-0.4800, valid loss-1.8886, acc-0.4972, test loss-1.8513, acc-0.5148\n",
      "Iter-82510, train loss-1.9102, acc-0.4600, valid loss-1.8886, acc-0.4974, test loss-1.8512, acc-0.5148\n",
      "Iter-82520, train loss-1.9153, acc-0.4400, valid loss-1.8885, acc-0.4972, test loss-1.8512, acc-0.5146\n",
      "Iter-82530, train loss-1.9269, acc-0.4200, valid loss-1.8885, acc-0.4972, test loss-1.8512, acc-0.5146\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-82540, train loss-1.8797, acc-0.5200, valid loss-1.8885, acc-0.4974, test loss-1.8511, acc-0.5147\n",
      "Iter-82550, train loss-1.9086, acc-0.4400, valid loss-1.8884, acc-0.4974, test loss-1.8511, acc-0.5148\n",
      "Iter-82560, train loss-1.8544, acc-0.5200, valid loss-1.8884, acc-0.4972, test loss-1.8511, acc-0.5148\n",
      "Iter-82570, train loss-1.8082, acc-0.4800, valid loss-1.8884, acc-0.4974, test loss-1.8510, acc-0.5149\n",
      "Iter-82580, train loss-1.9271, acc-0.4600, valid loss-1.8884, acc-0.4970, test loss-1.8510, acc-0.5149\n",
      "Iter-82590, train loss-1.9234, acc-0.4600, valid loss-1.8883, acc-0.4972, test loss-1.8510, acc-0.5149\n",
      "Iter-82600, train loss-1.8438, acc-0.5000, valid loss-1.8883, acc-0.4970, test loss-1.8510, acc-0.5151\n",
      "Iter-82610, train loss-1.8030, acc-0.6200, valid loss-1.8883, acc-0.4970, test loss-1.8509, acc-0.5149\n",
      "Iter-82620, train loss-1.8041, acc-0.5800, valid loss-1.8882, acc-0.4970, test loss-1.8509, acc-0.5152\n",
      "Iter-82630, train loss-1.8745, acc-0.5000, valid loss-1.8882, acc-0.4970, test loss-1.8509, acc-0.5149\n",
      "Iter-82640, train loss-1.8328, acc-0.5000, valid loss-1.8882, acc-0.4970, test loss-1.8508, acc-0.5149\n",
      "Iter-82650, train loss-1.7531, acc-0.7000, valid loss-1.8882, acc-0.4970, test loss-1.8508, acc-0.5150\n",
      "Iter-82660, train loss-1.8831, acc-0.6000, valid loss-1.8881, acc-0.4972, test loss-1.8508, acc-0.5150\n",
      "Iter-82670, train loss-1.8087, acc-0.6000, valid loss-1.8881, acc-0.4972, test loss-1.8507, acc-0.5149\n",
      "Iter-82680, train loss-1.9549, acc-0.4200, valid loss-1.8881, acc-0.4970, test loss-1.8507, acc-0.5149\n",
      "Iter-82690, train loss-1.8624, acc-0.4600, valid loss-1.8880, acc-0.4972, test loss-1.8507, acc-0.5148\n",
      "Iter-82700, train loss-1.9166, acc-0.4400, valid loss-1.8880, acc-0.4972, test loss-1.8506, acc-0.5147\n",
      "Iter-82710, train loss-1.9259, acc-0.4200, valid loss-1.8880, acc-0.4972, test loss-1.8506, acc-0.5148\n",
      "Iter-82720, train loss-1.9390, acc-0.4000, valid loss-1.8880, acc-0.4972, test loss-1.8506, acc-0.5147\n",
      "Iter-82730, train loss-1.9644, acc-0.4600, valid loss-1.8879, acc-0.4970, test loss-1.8505, acc-0.5149\n",
      "Iter-82740, train loss-1.8882, acc-0.4600, valid loss-1.8879, acc-0.4970, test loss-1.8505, acc-0.5149\n",
      "Iter-82750, train loss-1.7942, acc-0.5600, valid loss-1.8879, acc-0.4968, test loss-1.8505, acc-0.5149\n",
      "Iter-82760, train loss-1.7635, acc-0.6800, valid loss-1.8878, acc-0.4970, test loss-1.8504, acc-0.5149\n",
      "Iter-82770, train loss-1.7869, acc-0.5600, valid loss-1.8878, acc-0.4968, test loss-1.8504, acc-0.5149\n",
      "Iter-82780, train loss-1.8542, acc-0.6000, valid loss-1.8878, acc-0.4970, test loss-1.8504, acc-0.5149\n",
      "Iter-82790, train loss-1.8935, acc-0.5200, valid loss-1.8878, acc-0.4968, test loss-1.8503, acc-0.5149\n",
      "Iter-82800, train loss-1.9688, acc-0.4000, valid loss-1.8877, acc-0.4968, test loss-1.8503, acc-0.5149\n",
      "Iter-82810, train loss-1.8252, acc-0.5200, valid loss-1.8877, acc-0.4970, test loss-1.8503, acc-0.5149\n",
      "Iter-82820, train loss-1.9219, acc-0.5200, valid loss-1.8877, acc-0.4968, test loss-1.8503, acc-0.5150\n",
      "Iter-82830, train loss-1.9528, acc-0.4200, valid loss-1.8876, acc-0.4970, test loss-1.8502, acc-0.5148\n",
      "Iter-82840, train loss-1.9118, acc-0.4800, valid loss-1.8876, acc-0.4970, test loss-1.8502, acc-0.5149\n",
      "Iter-82850, train loss-1.8988, acc-0.4400, valid loss-1.8876, acc-0.4968, test loss-1.8502, acc-0.5150\n",
      "Iter-82860, train loss-1.8472, acc-0.4400, valid loss-1.8875, acc-0.4968, test loss-1.8501, acc-0.5150\n",
      "Iter-82870, train loss-1.8878, acc-0.5400, valid loss-1.8875, acc-0.4968, test loss-1.8501, acc-0.5150\n",
      "Iter-82880, train loss-1.7888, acc-0.5400, valid loss-1.8875, acc-0.4968, test loss-1.8501, acc-0.5150\n",
      "Iter-82890, train loss-1.8606, acc-0.5600, valid loss-1.8875, acc-0.4968, test loss-1.8500, acc-0.5150\n",
      "Iter-82900, train loss-1.8838, acc-0.4200, valid loss-1.8874, acc-0.4968, test loss-1.8500, acc-0.5150\n",
      "Iter-82910, train loss-1.8619, acc-0.5800, valid loss-1.8874, acc-0.4968, test loss-1.8500, acc-0.5150\n",
      "Iter-82920, train loss-1.8751, acc-0.5400, valid loss-1.8874, acc-0.4968, test loss-1.8499, acc-0.5150\n",
      "Iter-82930, train loss-1.9275, acc-0.4400, valid loss-1.8873, acc-0.4968, test loss-1.8499, acc-0.5151\n",
      "Iter-82940, train loss-1.7735, acc-0.5400, valid loss-1.8873, acc-0.4968, test loss-1.8499, acc-0.5151\n",
      "Iter-82950, train loss-1.7902, acc-0.5600, valid loss-1.8873, acc-0.4970, test loss-1.8498, acc-0.5151\n",
      "Iter-82960, train loss-1.9114, acc-0.5200, valid loss-1.8873, acc-0.4970, test loss-1.8498, acc-0.5150\n",
      "Iter-82970, train loss-1.7678, acc-0.6800, valid loss-1.8872, acc-0.4970, test loss-1.8498, acc-0.5149\n",
      "Iter-82980, train loss-1.9904, acc-0.3800, valid loss-1.8872, acc-0.4972, test loss-1.8497, acc-0.5150\n",
      "Iter-82990, train loss-1.9661, acc-0.5000, valid loss-1.8872, acc-0.4972, test loss-1.8497, acc-0.5151\n",
      "Iter-83000, train loss-1.8140, acc-0.6000, valid loss-1.8872, acc-0.4972, test loss-1.8497, acc-0.5151\n",
      "Iter-83010, train loss-1.8744, acc-0.4800, valid loss-1.8871, acc-0.4972, test loss-1.8496, acc-0.5150\n",
      "Iter-83020, train loss-1.8858, acc-0.5400, valid loss-1.8871, acc-0.4970, test loss-1.8496, acc-0.5152\n",
      "Iter-83030, train loss-1.9839, acc-0.3200, valid loss-1.8871, acc-0.4970, test loss-1.8496, acc-0.5152\n",
      "Iter-83040, train loss-1.8573, acc-0.5000, valid loss-1.8870, acc-0.4970, test loss-1.8496, acc-0.5152\n",
      "Iter-83050, train loss-1.9549, acc-0.4800, valid loss-1.8870, acc-0.4966, test loss-1.8495, acc-0.5152\n",
      "Iter-83060, train loss-1.9117, acc-0.4400, valid loss-1.8870, acc-0.4966, test loss-1.8495, acc-0.5152\n",
      "Iter-83070, train loss-1.8417, acc-0.4800, valid loss-1.8869, acc-0.4966, test loss-1.8495, acc-0.5152\n",
      "Iter-83080, train loss-1.7680, acc-0.5400, valid loss-1.8869, acc-0.4966, test loss-1.8494, acc-0.5151\n",
      "Iter-83090, train loss-1.9137, acc-0.5400, valid loss-1.8869, acc-0.4964, test loss-1.8494, acc-0.5152\n",
      "Iter-83100, train loss-1.8344, acc-0.4800, valid loss-1.8868, acc-0.4966, test loss-1.8494, acc-0.5152\n",
      "Iter-83110, train loss-1.8792, acc-0.5400, valid loss-1.8868, acc-0.4964, test loss-1.8493, acc-0.5152\n",
      "Iter-83120, train loss-1.8601, acc-0.4800, valid loss-1.8868, acc-0.4962, test loss-1.8493, acc-0.5151\n",
      "Iter-83130, train loss-1.7915, acc-0.4800, valid loss-1.8868, acc-0.4962, test loss-1.8493, acc-0.5151\n",
      "Iter-83140, train loss-1.9334, acc-0.5200, valid loss-1.8867, acc-0.4964, test loss-1.8492, acc-0.5152\n",
      "Iter-83150, train loss-1.9124, acc-0.4800, valid loss-1.8867, acc-0.4966, test loss-1.8492, acc-0.5152\n",
      "Iter-83160, train loss-1.8587, acc-0.6200, valid loss-1.8867, acc-0.4968, test loss-1.8492, acc-0.5152\n",
      "Iter-83170, train loss-1.8668, acc-0.5400, valid loss-1.8866, acc-0.4968, test loss-1.8491, acc-0.5151\n",
      "Iter-83180, train loss-1.9029, acc-0.4600, valid loss-1.8866, acc-0.4964, test loss-1.8491, acc-0.5151\n",
      "Iter-83190, train loss-1.8834, acc-0.4800, valid loss-1.8866, acc-0.4964, test loss-1.8491, acc-0.5151\n",
      "Iter-83200, train loss-1.8614, acc-0.5400, valid loss-1.8866, acc-0.4966, test loss-1.8490, acc-0.5150\n",
      "Iter-83210, train loss-1.8890, acc-0.5000, valid loss-1.8865, acc-0.4968, test loss-1.8490, acc-0.5151\n",
      "Iter-83220, train loss-1.8476, acc-0.4600, valid loss-1.8865, acc-0.4968, test loss-1.8490, acc-0.5152\n",
      "Iter-83230, train loss-1.7838, acc-0.6600, valid loss-1.8865, acc-0.4970, test loss-1.8489, acc-0.5152\n",
      "Iter-83240, train loss-1.8700, acc-0.5000, valid loss-1.8864, acc-0.4972, test loss-1.8489, acc-0.5153\n",
      "Iter-83250, train loss-1.9142, acc-0.5200, valid loss-1.8864, acc-0.4970, test loss-1.8489, acc-0.5153\n",
      "Iter-83260, train loss-1.9422, acc-0.4000, valid loss-1.8864, acc-0.4968, test loss-1.8488, acc-0.5154\n",
      "Iter-83270, train loss-1.8307, acc-0.5000, valid loss-1.8864, acc-0.4970, test loss-1.8488, acc-0.5153\n",
      "Iter-83280, train loss-1.9746, acc-0.3400, valid loss-1.8863, acc-0.4972, test loss-1.8488, acc-0.5153\n",
      "Iter-83290, train loss-1.8734, acc-0.5000, valid loss-1.8863, acc-0.4972, test loss-1.8487, acc-0.5153\n",
      "Iter-83300, train loss-1.8417, acc-0.5400, valid loss-1.8863, acc-0.4970, test loss-1.8487, acc-0.5152\n",
      "Iter-83310, train loss-1.8566, acc-0.5200, valid loss-1.8862, acc-0.4972, test loss-1.8487, acc-0.5151\n",
      "Iter-83320, train loss-1.8568, acc-0.5400, valid loss-1.8862, acc-0.4970, test loss-1.8486, acc-0.5151\n",
      "Iter-83330, train loss-1.7590, acc-0.5400, valid loss-1.8862, acc-0.4974, test loss-1.8486, acc-0.5152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-83340, train loss-1.8381, acc-0.6600, valid loss-1.8862, acc-0.4976, test loss-1.8486, acc-0.5152\n",
      "Iter-83350, train loss-1.7687, acc-0.4800, valid loss-1.8861, acc-0.4974, test loss-1.8486, acc-0.5153\n",
      "Iter-83360, train loss-1.8630, acc-0.5400, valid loss-1.8861, acc-0.4976, test loss-1.8485, acc-0.5152\n",
      "Iter-83370, train loss-1.8708, acc-0.4400, valid loss-1.8861, acc-0.4978, test loss-1.8485, acc-0.5153\n",
      "Iter-83380, train loss-1.9543, acc-0.4200, valid loss-1.8860, acc-0.4976, test loss-1.8485, acc-0.5153\n",
      "Iter-83390, train loss-1.8645, acc-0.5000, valid loss-1.8860, acc-0.4978, test loss-1.8484, acc-0.5153\n",
      "Iter-83400, train loss-1.9078, acc-0.4400, valid loss-1.8860, acc-0.4974, test loss-1.8484, acc-0.5150\n",
      "Iter-83410, train loss-1.8634, acc-0.5000, valid loss-1.8859, acc-0.4978, test loss-1.8484, acc-0.5150\n",
      "Iter-83420, train loss-1.9052, acc-0.4600, valid loss-1.8859, acc-0.4976, test loss-1.8483, acc-0.5152\n",
      "Iter-83430, train loss-1.9130, acc-0.4400, valid loss-1.8859, acc-0.4976, test loss-1.8483, acc-0.5153\n",
      "Iter-83440, train loss-1.9328, acc-0.4200, valid loss-1.8859, acc-0.4978, test loss-1.8483, acc-0.5153\n",
      "Iter-83450, train loss-1.8672, acc-0.5200, valid loss-1.8858, acc-0.4980, test loss-1.8482, acc-0.5153\n",
      "Iter-83460, train loss-1.8673, acc-0.5400, valid loss-1.8858, acc-0.4978, test loss-1.8482, acc-0.5152\n",
      "Iter-83470, train loss-1.8216, acc-0.5800, valid loss-1.8858, acc-0.4978, test loss-1.8482, acc-0.5152\n",
      "Iter-83480, train loss-1.8839, acc-0.4600, valid loss-1.8857, acc-0.4976, test loss-1.8481, acc-0.5153\n",
      "Iter-83490, train loss-1.9443, acc-0.4800, valid loss-1.8857, acc-0.4978, test loss-1.8481, acc-0.5153\n",
      "Iter-83500, train loss-1.8505, acc-0.5200, valid loss-1.8857, acc-0.4978, test loss-1.8481, acc-0.5154\n",
      "Iter-83510, train loss-1.9156, acc-0.3200, valid loss-1.8857, acc-0.4980, test loss-1.8480, acc-0.5153\n",
      "Iter-83520, train loss-1.9590, acc-0.4200, valid loss-1.8856, acc-0.4980, test loss-1.8480, acc-0.5152\n",
      "Iter-83530, train loss-1.9874, acc-0.3800, valid loss-1.8856, acc-0.4980, test loss-1.8480, acc-0.5153\n",
      "Iter-83540, train loss-1.7714, acc-0.7000, valid loss-1.8856, acc-0.4980, test loss-1.8480, acc-0.5153\n",
      "Iter-83550, train loss-1.8024, acc-0.5800, valid loss-1.8855, acc-0.4980, test loss-1.8479, acc-0.5153\n",
      "Iter-83560, train loss-1.7772, acc-0.6600, valid loss-1.8855, acc-0.4980, test loss-1.8479, acc-0.5153\n",
      "Iter-83570, train loss-1.8194, acc-0.6600, valid loss-1.8855, acc-0.4980, test loss-1.8479, acc-0.5153\n",
      "Iter-83580, train loss-1.8488, acc-0.5000, valid loss-1.8855, acc-0.4978, test loss-1.8478, acc-0.5153\n",
      "Iter-83590, train loss-1.8799, acc-0.4800, valid loss-1.8854, acc-0.4980, test loss-1.8478, acc-0.5155\n",
      "Iter-83600, train loss-1.9103, acc-0.4600, valid loss-1.8854, acc-0.4980, test loss-1.8478, acc-0.5153\n",
      "Iter-83610, train loss-1.7678, acc-0.5400, valid loss-1.8854, acc-0.4982, test loss-1.8477, acc-0.5153\n",
      "Iter-83620, train loss-1.9210, acc-0.5200, valid loss-1.8853, acc-0.4982, test loss-1.8477, acc-0.5152\n",
      "Iter-83630, train loss-1.9039, acc-0.5000, valid loss-1.8853, acc-0.4980, test loss-1.8477, acc-0.5154\n",
      "Iter-83640, train loss-1.8913, acc-0.4400, valid loss-1.8853, acc-0.4980, test loss-1.8476, acc-0.5153\n",
      "Iter-83650, train loss-1.8819, acc-0.5400, valid loss-1.8853, acc-0.4980, test loss-1.8476, acc-0.5154\n",
      "Iter-83660, train loss-1.7986, acc-0.4800, valid loss-1.8852, acc-0.4978, test loss-1.8476, acc-0.5156\n",
      "Iter-83670, train loss-1.8434, acc-0.5600, valid loss-1.8852, acc-0.4980, test loss-1.8475, acc-0.5156\n",
      "Iter-83680, train loss-1.8751, acc-0.4600, valid loss-1.8852, acc-0.4982, test loss-1.8475, acc-0.5156\n",
      "Iter-83690, train loss-1.8565, acc-0.5200, valid loss-1.8851, acc-0.4982, test loss-1.8475, acc-0.5156\n",
      "Iter-83700, train loss-1.7965, acc-0.5200, valid loss-1.8851, acc-0.4982, test loss-1.8474, acc-0.5157\n",
      "Iter-83710, train loss-1.8698, acc-0.5000, valid loss-1.8851, acc-0.4982, test loss-1.8474, acc-0.5159\n",
      "Iter-83720, train loss-1.7792, acc-0.5400, valid loss-1.8851, acc-0.4980, test loss-1.8474, acc-0.5158\n",
      "Iter-83730, train loss-1.9135, acc-0.5400, valid loss-1.8850, acc-0.4980, test loss-1.8473, acc-0.5156\n",
      "Iter-83740, train loss-1.8988, acc-0.4800, valid loss-1.8850, acc-0.4978, test loss-1.8473, acc-0.5156\n",
      "Iter-83750, train loss-1.9109, acc-0.4600, valid loss-1.8850, acc-0.4978, test loss-1.8473, acc-0.5160\n",
      "Iter-83760, train loss-1.8374, acc-0.5200, valid loss-1.8849, acc-0.4978, test loss-1.8473, acc-0.5156\n",
      "Iter-83770, train loss-1.8531, acc-0.5600, valid loss-1.8849, acc-0.4978, test loss-1.8472, acc-0.5156\n",
      "Iter-83780, train loss-1.8848, acc-0.4000, valid loss-1.8849, acc-0.4982, test loss-1.8472, acc-0.5156\n",
      "Iter-83790, train loss-1.8654, acc-0.4200, valid loss-1.8849, acc-0.4982, test loss-1.8472, acc-0.5156\n",
      "Iter-83800, train loss-1.8084, acc-0.5600, valid loss-1.8848, acc-0.4980, test loss-1.8471, acc-0.5156\n",
      "Iter-83810, train loss-1.8016, acc-0.5000, valid loss-1.8848, acc-0.4984, test loss-1.8471, acc-0.5154\n",
      "Iter-83820, train loss-1.8602, acc-0.5400, valid loss-1.8848, acc-0.4982, test loss-1.8471, acc-0.5155\n",
      "Iter-83830, train loss-1.8643, acc-0.5400, valid loss-1.8847, acc-0.4982, test loss-1.8470, acc-0.5157\n",
      "Iter-83840, train loss-1.8755, acc-0.4800, valid loss-1.8847, acc-0.4982, test loss-1.8470, acc-0.5157\n",
      "Iter-83850, train loss-1.8953, acc-0.4400, valid loss-1.8847, acc-0.4982, test loss-1.8470, acc-0.5157\n",
      "Iter-83860, train loss-1.8487, acc-0.4200, valid loss-1.8847, acc-0.4980, test loss-1.8469, acc-0.5158\n",
      "Iter-83870, train loss-1.8687, acc-0.4000, valid loss-1.8846, acc-0.4978, test loss-1.8469, acc-0.5159\n",
      "Iter-83880, train loss-1.9743, acc-0.3600, valid loss-1.8846, acc-0.4980, test loss-1.8469, acc-0.5159\n",
      "Iter-83890, train loss-1.8921, acc-0.5000, valid loss-1.8846, acc-0.4980, test loss-1.8468, acc-0.5160\n",
      "Iter-83900, train loss-1.8876, acc-0.5400, valid loss-1.8845, acc-0.4980, test loss-1.8468, acc-0.5162\n",
      "Iter-83910, train loss-1.7095, acc-0.6200, valid loss-1.8845, acc-0.4980, test loss-1.8468, acc-0.5161\n",
      "Iter-83920, train loss-1.8259, acc-0.6000, valid loss-1.8845, acc-0.4980, test loss-1.8467, acc-0.5161\n",
      "Iter-83930, train loss-1.8697, acc-0.4600, valid loss-1.8845, acc-0.4980, test loss-1.8467, acc-0.5160\n",
      "Iter-83940, train loss-1.8863, acc-0.4800, valid loss-1.8844, acc-0.4980, test loss-1.8467, acc-0.5160\n",
      "Iter-83950, train loss-1.7813, acc-0.5400, valid loss-1.8844, acc-0.4980, test loss-1.8467, acc-0.5162\n",
      "Iter-83960, train loss-1.8429, acc-0.5000, valid loss-1.8844, acc-0.4980, test loss-1.8466, acc-0.5160\n",
      "Iter-83970, train loss-1.9255, acc-0.4200, valid loss-1.8843, acc-0.4980, test loss-1.8466, acc-0.5160\n",
      "Iter-83980, train loss-1.8906, acc-0.4600, valid loss-1.8843, acc-0.4980, test loss-1.8466, acc-0.5162\n",
      "Iter-83990, train loss-1.9294, acc-0.4000, valid loss-1.8843, acc-0.4980, test loss-1.8465, acc-0.5162\n",
      "Iter-84000, train loss-1.8009, acc-0.6200, valid loss-1.8843, acc-0.4980, test loss-1.8465, acc-0.5162\n",
      "Iter-84010, train loss-1.8835, acc-0.4800, valid loss-1.8842, acc-0.4980, test loss-1.8465, acc-0.5163\n",
      "Iter-84020, train loss-1.8195, acc-0.5800, valid loss-1.8842, acc-0.4980, test loss-1.8464, acc-0.5161\n",
      "Iter-84030, train loss-1.9191, acc-0.4400, valid loss-1.8842, acc-0.4980, test loss-1.8464, acc-0.5161\n",
      "Iter-84040, train loss-1.7903, acc-0.5200, valid loss-1.8841, acc-0.4978, test loss-1.8464, acc-0.5161\n",
      "Iter-84050, train loss-1.8774, acc-0.5400, valid loss-1.8841, acc-0.4978, test loss-1.8463, acc-0.5163\n",
      "Iter-84060, train loss-1.8896, acc-0.4600, valid loss-1.8841, acc-0.4978, test loss-1.8463, acc-0.5161\n",
      "Iter-84070, train loss-1.8036, acc-0.6200, valid loss-1.8841, acc-0.4976, test loss-1.8463, acc-0.5162\n",
      "Iter-84080, train loss-1.9296, acc-0.3600, valid loss-1.8840, acc-0.4976, test loss-1.8462, acc-0.5163\n",
      "Iter-84090, train loss-1.8635, acc-0.6200, valid loss-1.8840, acc-0.4976, test loss-1.8462, acc-0.5162\n",
      "Iter-84100, train loss-1.8934, acc-0.5000, valid loss-1.8840, acc-0.4976, test loss-1.8462, acc-0.5160\n",
      "Iter-84110, train loss-1.7322, acc-0.6600, valid loss-1.8839, acc-0.4976, test loss-1.8462, acc-0.5162\n",
      "Iter-84120, train loss-1.7982, acc-0.6200, valid loss-1.8839, acc-0.4976, test loss-1.8461, acc-0.5164\n",
      "Iter-84130, train loss-1.8694, acc-0.5800, valid loss-1.8839, acc-0.4976, test loss-1.8461, acc-0.5160\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-84140, train loss-1.7774, acc-0.6000, valid loss-1.8839, acc-0.4980, test loss-1.8461, acc-0.5161\n",
      "Iter-84150, train loss-1.8327, acc-0.5400, valid loss-1.8838, acc-0.4976, test loss-1.8460, acc-0.5162\n",
      "Iter-84160, train loss-1.7252, acc-0.6000, valid loss-1.8838, acc-0.4976, test loss-1.8460, acc-0.5161\n",
      "Iter-84170, train loss-1.8234, acc-0.5600, valid loss-1.8838, acc-0.4976, test loss-1.8460, acc-0.5159\n",
      "Iter-84180, train loss-1.8281, acc-0.5600, valid loss-1.8837, acc-0.4976, test loss-1.8459, acc-0.5159\n",
      "Iter-84190, train loss-1.8132, acc-0.5600, valid loss-1.8837, acc-0.4980, test loss-1.8459, acc-0.5159\n",
      "Iter-84200, train loss-1.9607, acc-0.4000, valid loss-1.8837, acc-0.4980, test loss-1.8459, acc-0.5159\n",
      "Iter-84210, train loss-1.8910, acc-0.5000, valid loss-1.8836, acc-0.4978, test loss-1.8458, acc-0.5159\n",
      "Iter-84220, train loss-1.8543, acc-0.4800, valid loss-1.8836, acc-0.4980, test loss-1.8458, acc-0.5159\n",
      "Iter-84230, train loss-1.8171, acc-0.5600, valid loss-1.8836, acc-0.4980, test loss-1.8458, acc-0.5159\n",
      "Iter-84240, train loss-1.8885, acc-0.4600, valid loss-1.8836, acc-0.4978, test loss-1.8457, acc-0.5159\n",
      "Iter-84250, train loss-1.8780, acc-0.4600, valid loss-1.8835, acc-0.4980, test loss-1.8457, acc-0.5159\n",
      "Iter-84260, train loss-1.8012, acc-0.4800, valid loss-1.8835, acc-0.4980, test loss-1.8457, acc-0.5160\n",
      "Iter-84270, train loss-1.9093, acc-0.4400, valid loss-1.8835, acc-0.4982, test loss-1.8456, acc-0.5159\n",
      "Iter-84280, train loss-1.8733, acc-0.5600, valid loss-1.8834, acc-0.4980, test loss-1.8456, acc-0.5160\n",
      "Iter-84290, train loss-1.8152, acc-0.5800, valid loss-1.8834, acc-0.4982, test loss-1.8456, acc-0.5159\n",
      "Iter-84300, train loss-1.7912, acc-0.4600, valid loss-1.8834, acc-0.4984, test loss-1.8456, acc-0.5161\n",
      "Iter-84310, train loss-1.9307, acc-0.5000, valid loss-1.8834, acc-0.4980, test loss-1.8455, acc-0.5160\n",
      "Iter-84320, train loss-1.8780, acc-0.4800, valid loss-1.8833, acc-0.4980, test loss-1.8455, acc-0.5160\n",
      "Iter-84330, train loss-1.9161, acc-0.5400, valid loss-1.8833, acc-0.4980, test loss-1.8455, acc-0.5161\n",
      "Iter-84340, train loss-1.8211, acc-0.5800, valid loss-1.8833, acc-0.4982, test loss-1.8454, acc-0.5159\n",
      "Iter-84350, train loss-1.8551, acc-0.4600, valid loss-1.8833, acc-0.4978, test loss-1.8454, acc-0.5161\n",
      "Iter-84360, train loss-1.9698, acc-0.3800, valid loss-1.8832, acc-0.4980, test loss-1.8454, acc-0.5162\n",
      "Iter-84370, train loss-1.8389, acc-0.4400, valid loss-1.8832, acc-0.4980, test loss-1.8453, acc-0.5161\n",
      "Iter-84380, train loss-1.9189, acc-0.5200, valid loss-1.8832, acc-0.4982, test loss-1.8453, acc-0.5159\n",
      "Iter-84390, train loss-1.8136, acc-0.5600, valid loss-1.8831, acc-0.4980, test loss-1.8453, acc-0.5161\n",
      "Iter-84400, train loss-1.9506, acc-0.3400, valid loss-1.8831, acc-0.4980, test loss-1.8452, acc-0.5161\n",
      "Iter-84410, train loss-1.8727, acc-0.6000, valid loss-1.8831, acc-0.4978, test loss-1.8452, acc-0.5164\n",
      "Iter-84420, train loss-1.7683, acc-0.6400, valid loss-1.8831, acc-0.4978, test loss-1.8452, acc-0.5162\n",
      "Iter-84430, train loss-1.8185, acc-0.5600, valid loss-1.8830, acc-0.4978, test loss-1.8451, acc-0.5163\n",
      "Iter-84440, train loss-1.9182, acc-0.4800, valid loss-1.8830, acc-0.4978, test loss-1.8451, acc-0.5163\n",
      "Iter-84450, train loss-1.9351, acc-0.4200, valid loss-1.8830, acc-0.4980, test loss-1.8451, acc-0.5163\n",
      "Iter-84460, train loss-1.8379, acc-0.5200, valid loss-1.8829, acc-0.4980, test loss-1.8451, acc-0.5162\n",
      "Iter-84470, train loss-1.8605, acc-0.5600, valid loss-1.8829, acc-0.4980, test loss-1.8450, acc-0.5162\n",
      "Iter-84480, train loss-1.8667, acc-0.4000, valid loss-1.8829, acc-0.4980, test loss-1.8450, acc-0.5160\n",
      "Iter-84490, train loss-1.8916, acc-0.4800, valid loss-1.8828, acc-0.4980, test loss-1.8450, acc-0.5161\n",
      "Iter-84500, train loss-1.9161, acc-0.4400, valid loss-1.8828, acc-0.4980, test loss-1.8449, acc-0.5162\n",
      "Iter-84510, train loss-1.8248, acc-0.5400, valid loss-1.8828, acc-0.4980, test loss-1.8449, acc-0.5161\n",
      "Iter-84520, train loss-1.9062, acc-0.4400, valid loss-1.8828, acc-0.4978, test loss-1.8449, acc-0.5162\n",
      "Iter-84530, train loss-1.8258, acc-0.5200, valid loss-1.8827, acc-0.4978, test loss-1.8448, acc-0.5162\n",
      "Iter-84540, train loss-1.8433, acc-0.6000, valid loss-1.8827, acc-0.4978, test loss-1.8448, acc-0.5164\n",
      "Iter-84550, train loss-1.7583, acc-0.6200, valid loss-1.8827, acc-0.4980, test loss-1.8448, acc-0.5162\n",
      "Iter-84560, train loss-1.9011, acc-0.5200, valid loss-1.8827, acc-0.4978, test loss-1.8447, acc-0.5163\n",
      "Iter-84570, train loss-1.8605, acc-0.5200, valid loss-1.8826, acc-0.4978, test loss-1.8447, acc-0.5162\n",
      "Iter-84580, train loss-1.7637, acc-0.6400, valid loss-1.8826, acc-0.4978, test loss-1.8447, acc-0.5163\n",
      "Iter-84590, train loss-1.9930, acc-0.3400, valid loss-1.8826, acc-0.4978, test loss-1.8446, acc-0.5162\n",
      "Iter-84600, train loss-1.8907, acc-0.5400, valid loss-1.8825, acc-0.4978, test loss-1.8446, acc-0.5162\n",
      "Iter-84610, train loss-1.8662, acc-0.4400, valid loss-1.8825, acc-0.4978, test loss-1.8446, acc-0.5163\n",
      "Iter-84620, train loss-1.8913, acc-0.5200, valid loss-1.8825, acc-0.4978, test loss-1.8445, acc-0.5163\n",
      "Iter-84630, train loss-1.9377, acc-0.5000, valid loss-1.8825, acc-0.4980, test loss-1.8445, acc-0.5162\n",
      "Iter-84640, train loss-1.8556, acc-0.4000, valid loss-1.8824, acc-0.4980, test loss-1.8445, acc-0.5162\n",
      "Iter-84650, train loss-1.9031, acc-0.4600, valid loss-1.8824, acc-0.4980, test loss-1.8445, acc-0.5160\n",
      "Iter-84660, train loss-1.9624, acc-0.4200, valid loss-1.8824, acc-0.4980, test loss-1.8444, acc-0.5162\n",
      "Iter-84670, train loss-1.7764, acc-0.5000, valid loss-1.8823, acc-0.4980, test loss-1.8444, acc-0.5162\n",
      "Iter-84680, train loss-1.8814, acc-0.4400, valid loss-1.8823, acc-0.4978, test loss-1.8444, acc-0.5163\n",
      "Iter-84690, train loss-1.9315, acc-0.4000, valid loss-1.8823, acc-0.4978, test loss-1.8443, acc-0.5162\n",
      "Iter-84700, train loss-1.8991, acc-0.4800, valid loss-1.8823, acc-0.4978, test loss-1.8443, acc-0.5163\n",
      "Iter-84710, train loss-1.8713, acc-0.5400, valid loss-1.8822, acc-0.4978, test loss-1.8443, acc-0.5164\n",
      "Iter-84720, train loss-1.8353, acc-0.5800, valid loss-1.8822, acc-0.4978, test loss-1.8442, acc-0.5164\n",
      "Iter-84730, train loss-1.9260, acc-0.5200, valid loss-1.8822, acc-0.4978, test loss-1.8442, acc-0.5165\n",
      "Iter-84740, train loss-1.8536, acc-0.5000, valid loss-1.8822, acc-0.4978, test loss-1.8442, acc-0.5163\n",
      "Iter-84750, train loss-1.9019, acc-0.4400, valid loss-1.8821, acc-0.4978, test loss-1.8441, acc-0.5163\n",
      "Iter-84760, train loss-1.8590, acc-0.4800, valid loss-1.8821, acc-0.4980, test loss-1.8441, acc-0.5162\n",
      "Iter-84770, train loss-1.8744, acc-0.5600, valid loss-1.8821, acc-0.4980, test loss-1.8441, acc-0.5161\n",
      "Iter-84780, train loss-1.7812, acc-0.6200, valid loss-1.8820, acc-0.4980, test loss-1.8441, acc-0.5161\n",
      "Iter-84790, train loss-1.8364, acc-0.4600, valid loss-1.8820, acc-0.4980, test loss-1.8440, acc-0.5160\n",
      "Iter-84800, train loss-1.8302, acc-0.5600, valid loss-1.8820, acc-0.4980, test loss-1.8440, acc-0.5161\n",
      "Iter-84810, train loss-1.8937, acc-0.4800, valid loss-1.8820, acc-0.4980, test loss-1.8440, acc-0.5160\n",
      "Iter-84820, train loss-1.7993, acc-0.5800, valid loss-1.8819, acc-0.4980, test loss-1.8439, acc-0.5159\n",
      "Iter-84830, train loss-1.8680, acc-0.5400, valid loss-1.8819, acc-0.4980, test loss-1.8439, acc-0.5159\n",
      "Iter-84840, train loss-1.9683, acc-0.3200, valid loss-1.8819, acc-0.4980, test loss-1.8439, acc-0.5159\n",
      "Iter-84850, train loss-1.9381, acc-0.4600, valid loss-1.8818, acc-0.4982, test loss-1.8438, acc-0.5160\n",
      "Iter-84860, train loss-1.9516, acc-0.4400, valid loss-1.8818, acc-0.4982, test loss-1.8438, acc-0.5158\n",
      "Iter-84870, train loss-1.8295, acc-0.4800, valid loss-1.8818, acc-0.4982, test loss-1.8438, acc-0.5159\n",
      "Iter-84880, train loss-1.9032, acc-0.4000, valid loss-1.8818, acc-0.4982, test loss-1.8437, acc-0.5158\n",
      "Iter-84890, train loss-1.8479, acc-0.4800, valid loss-1.8817, acc-0.4982, test loss-1.8437, acc-0.5158\n",
      "Iter-84900, train loss-1.8275, acc-0.5800, valid loss-1.8817, acc-0.4982, test loss-1.8437, acc-0.5157\n",
      "Iter-84910, train loss-1.8227, acc-0.6000, valid loss-1.8817, acc-0.4982, test loss-1.8437, acc-0.5158\n",
      "Iter-84920, train loss-1.7688, acc-0.5600, valid loss-1.8816, acc-0.4982, test loss-1.8436, acc-0.5158\n",
      "Iter-84930, train loss-1.7867, acc-0.5200, valid loss-1.8816, acc-0.4980, test loss-1.8436, acc-0.5158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-84940, train loss-1.7967, acc-0.5200, valid loss-1.8816, acc-0.4980, test loss-1.8436, acc-0.5160\n",
      "Iter-84950, train loss-1.8528, acc-0.5400, valid loss-1.8815, acc-0.4980, test loss-1.8435, acc-0.5160\n",
      "Iter-84960, train loss-1.9069, acc-0.4600, valid loss-1.8815, acc-0.4980, test loss-1.8435, acc-0.5162\n",
      "Iter-84970, train loss-1.8648, acc-0.5200, valid loss-1.8815, acc-0.4980, test loss-1.8435, acc-0.5160\n",
      "Iter-84980, train loss-2.0174, acc-0.4600, valid loss-1.8815, acc-0.4980, test loss-1.8434, acc-0.5161\n",
      "Iter-84990, train loss-2.0368, acc-0.3000, valid loss-1.8814, acc-0.4980, test loss-1.8434, acc-0.5163\n",
      "Iter-85000, train loss-1.8604, acc-0.5400, valid loss-1.8814, acc-0.4982, test loss-1.8434, acc-0.5164\n",
      "Iter-85010, train loss-1.8281, acc-0.5600, valid loss-1.8814, acc-0.4982, test loss-1.8433, acc-0.5163\n",
      "Iter-85020, train loss-1.8267, acc-0.4200, valid loss-1.8813, acc-0.4984, test loss-1.8433, acc-0.5162\n",
      "Iter-85030, train loss-1.7987, acc-0.5800, valid loss-1.8813, acc-0.4982, test loss-1.8433, acc-0.5164\n",
      "Iter-85040, train loss-1.7851, acc-0.5200, valid loss-1.8813, acc-0.4982, test loss-1.8432, acc-0.5162\n",
      "Iter-85050, train loss-1.8312, acc-0.5600, valid loss-1.8812, acc-0.4982, test loss-1.8432, acc-0.5162\n",
      "Iter-85060, train loss-1.8482, acc-0.4600, valid loss-1.8812, acc-0.4980, test loss-1.8432, acc-0.5162\n",
      "Iter-85070, train loss-1.9038, acc-0.4800, valid loss-1.8812, acc-0.4980, test loss-1.8432, acc-0.5162\n",
      "Iter-85080, train loss-1.9227, acc-0.3400, valid loss-1.8812, acc-0.4982, test loss-1.8431, acc-0.5163\n",
      "Iter-85090, train loss-1.8640, acc-0.5400, valid loss-1.8811, acc-0.4980, test loss-1.8431, acc-0.5164\n",
      "Iter-85100, train loss-1.7996, acc-0.5400, valid loss-1.8811, acc-0.4980, test loss-1.8431, acc-0.5166\n",
      "Iter-85110, train loss-1.7938, acc-0.5000, valid loss-1.8811, acc-0.4980, test loss-1.8430, acc-0.5165\n",
      "Iter-85120, train loss-1.7882, acc-0.6200, valid loss-1.8810, acc-0.4982, test loss-1.8430, acc-0.5166\n",
      "Iter-85130, train loss-1.9171, acc-0.4600, valid loss-1.8810, acc-0.4982, test loss-1.8430, acc-0.5164\n",
      "Iter-85140, train loss-1.8725, acc-0.5000, valid loss-1.8810, acc-0.4982, test loss-1.8429, acc-0.5165\n",
      "Iter-85150, train loss-1.8884, acc-0.4200, valid loss-1.8810, acc-0.4982, test loss-1.8429, acc-0.5164\n",
      "Iter-85160, train loss-1.9184, acc-0.5600, valid loss-1.8809, acc-0.4982, test loss-1.8429, acc-0.5165\n",
      "Iter-85170, train loss-1.9525, acc-0.4000, valid loss-1.8809, acc-0.4982, test loss-1.8428, acc-0.5163\n",
      "Iter-85180, train loss-1.7832, acc-0.5600, valid loss-1.8809, acc-0.4984, test loss-1.8428, acc-0.5165\n",
      "Iter-85190, train loss-1.9301, acc-0.4200, valid loss-1.8808, acc-0.4984, test loss-1.8428, acc-0.5165\n",
      "Iter-85200, train loss-1.8887, acc-0.4000, valid loss-1.8808, acc-0.4984, test loss-1.8428, acc-0.5166\n",
      "Iter-85210, train loss-1.8915, acc-0.4200, valid loss-1.8808, acc-0.4984, test loss-1.8427, acc-0.5166\n",
      "Iter-85220, train loss-1.8158, acc-0.6000, valid loss-1.8808, acc-0.4984, test loss-1.8427, acc-0.5166\n",
      "Iter-85230, train loss-1.8793, acc-0.4800, valid loss-1.8807, acc-0.4984, test loss-1.8427, acc-0.5165\n",
      "Iter-85240, train loss-1.8311, acc-0.5600, valid loss-1.8807, acc-0.4984, test loss-1.8426, acc-0.5166\n",
      "Iter-85250, train loss-1.8036, acc-0.5000, valid loss-1.8807, acc-0.4984, test loss-1.8426, acc-0.5166\n",
      "Iter-85260, train loss-1.9623, acc-0.4200, valid loss-1.8806, acc-0.4984, test loss-1.8426, acc-0.5166\n",
      "Iter-85270, train loss-1.9780, acc-0.4000, valid loss-1.8806, acc-0.4984, test loss-1.8425, acc-0.5166\n",
      "Iter-85280, train loss-1.8940, acc-0.4400, valid loss-1.8806, acc-0.4984, test loss-1.8425, acc-0.5167\n",
      "Iter-85290, train loss-1.9033, acc-0.4600, valid loss-1.8806, acc-0.4986, test loss-1.8425, acc-0.5167\n",
      "Iter-85300, train loss-1.7965, acc-0.6600, valid loss-1.8805, acc-0.4986, test loss-1.8424, acc-0.5169\n",
      "Iter-85310, train loss-1.9184, acc-0.3800, valid loss-1.8805, acc-0.4986, test loss-1.8424, acc-0.5167\n",
      "Iter-85320, train loss-1.7596, acc-0.5400, valid loss-1.8805, acc-0.4986, test loss-1.8424, acc-0.5166\n",
      "Iter-85330, train loss-1.7966, acc-0.5200, valid loss-1.8804, acc-0.4986, test loss-1.8423, acc-0.5167\n",
      "Iter-85340, train loss-1.9143, acc-0.3000, valid loss-1.8804, acc-0.4986, test loss-1.8423, acc-0.5168\n",
      "Iter-85350, train loss-1.8582, acc-0.4800, valid loss-1.8804, acc-0.4982, test loss-1.8423, acc-0.5169\n",
      "Iter-85360, train loss-1.8180, acc-0.6400, valid loss-1.8803, acc-0.4984, test loss-1.8423, acc-0.5167\n",
      "Iter-85370, train loss-1.8259, acc-0.6000, valid loss-1.8803, acc-0.4984, test loss-1.8422, acc-0.5168\n",
      "Iter-85380, train loss-1.8410, acc-0.5400, valid loss-1.8803, acc-0.4984, test loss-1.8422, acc-0.5167\n",
      "Iter-85390, train loss-1.8610, acc-0.5400, valid loss-1.8803, acc-0.4984, test loss-1.8422, acc-0.5169\n",
      "Iter-85400, train loss-1.8233, acc-0.4600, valid loss-1.8802, acc-0.4986, test loss-1.8421, acc-0.5166\n",
      "Iter-85410, train loss-1.8382, acc-0.5200, valid loss-1.8802, acc-0.4984, test loss-1.8421, acc-0.5168\n",
      "Iter-85420, train loss-1.9098, acc-0.4200, valid loss-1.8802, acc-0.4986, test loss-1.8421, acc-0.5166\n",
      "Iter-85430, train loss-1.8988, acc-0.4400, valid loss-1.8801, acc-0.4986, test loss-1.8420, acc-0.5167\n",
      "Iter-85440, train loss-1.9493, acc-0.5000, valid loss-1.8801, acc-0.4986, test loss-1.8420, acc-0.5169\n",
      "Iter-85450, train loss-1.8706, acc-0.5200, valid loss-1.8801, acc-0.4986, test loss-1.8420, acc-0.5169\n",
      "Iter-85460, train loss-1.8449, acc-0.5400, valid loss-1.8801, acc-0.4986, test loss-1.8419, acc-0.5169\n",
      "Iter-85470, train loss-1.9936, acc-0.3800, valid loss-1.8800, acc-0.4984, test loss-1.8419, acc-0.5170\n",
      "Iter-85480, train loss-1.8168, acc-0.5600, valid loss-1.8800, acc-0.4986, test loss-1.8419, acc-0.5170\n",
      "Iter-85490, train loss-1.7923, acc-0.5200, valid loss-1.8800, acc-0.4986, test loss-1.8418, acc-0.5169\n",
      "Iter-85500, train loss-1.9431, acc-0.4200, valid loss-1.8800, acc-0.4986, test loss-1.8418, acc-0.5171\n",
      "Iter-85510, train loss-1.8673, acc-0.5600, valid loss-1.8799, acc-0.4986, test loss-1.8418, acc-0.5171\n",
      "Iter-85520, train loss-1.8104, acc-0.6400, valid loss-1.8799, acc-0.4988, test loss-1.8417, acc-0.5172\n",
      "Iter-85530, train loss-1.8183, acc-0.4400, valid loss-1.8799, acc-0.4986, test loss-1.8417, acc-0.5173\n",
      "Iter-85540, train loss-1.8370, acc-0.5000, valid loss-1.8798, acc-0.4986, test loss-1.8417, acc-0.5172\n",
      "Iter-85550, train loss-1.8951, acc-0.5400, valid loss-1.8798, acc-0.4986, test loss-1.8417, acc-0.5170\n",
      "Iter-85560, train loss-1.7775, acc-0.6000, valid loss-1.8798, acc-0.4986, test loss-1.8416, acc-0.5171\n",
      "Iter-85570, train loss-1.8790, acc-0.6000, valid loss-1.8798, acc-0.4986, test loss-1.8416, acc-0.5171\n",
      "Iter-85580, train loss-1.8153, acc-0.4400, valid loss-1.8797, acc-0.4984, test loss-1.8416, acc-0.5172\n",
      "Iter-85590, train loss-1.8749, acc-0.4600, valid loss-1.8797, acc-0.4984, test loss-1.8415, acc-0.5172\n",
      "Iter-85600, train loss-1.7609, acc-0.5400, valid loss-1.8797, acc-0.4980, test loss-1.8415, acc-0.5171\n",
      "Iter-85610, train loss-1.8414, acc-0.5400, valid loss-1.8796, acc-0.4984, test loss-1.8415, acc-0.5171\n",
      "Iter-85620, train loss-1.8909, acc-0.4600, valid loss-1.8796, acc-0.4980, test loss-1.8414, acc-0.5167\n",
      "Iter-85630, train loss-1.7873, acc-0.5000, valid loss-1.8796, acc-0.4986, test loss-1.8414, acc-0.5169\n",
      "Iter-85640, train loss-1.8170, acc-0.5800, valid loss-1.8796, acc-0.4984, test loss-1.8414, acc-0.5169\n",
      "Iter-85650, train loss-1.8028, acc-0.5000, valid loss-1.8795, acc-0.4986, test loss-1.8413, acc-0.5169\n",
      "Iter-85660, train loss-1.9668, acc-0.4200, valid loss-1.8795, acc-0.4986, test loss-1.8413, acc-0.5168\n",
      "Iter-85670, train loss-1.8290, acc-0.5200, valid loss-1.8795, acc-0.4982, test loss-1.8413, acc-0.5168\n",
      "Iter-85680, train loss-1.8567, acc-0.5400, valid loss-1.8794, acc-0.4982, test loss-1.8413, acc-0.5168\n",
      "Iter-85690, train loss-1.8480, acc-0.4800, valid loss-1.8794, acc-0.4984, test loss-1.8412, acc-0.5169\n",
      "Iter-85700, train loss-1.8486, acc-0.5000, valid loss-1.8794, acc-0.4986, test loss-1.8412, acc-0.5170\n",
      "Iter-85710, train loss-1.7742, acc-0.6000, valid loss-1.8794, acc-0.4986, test loss-1.8412, acc-0.5168\n",
      "Iter-85720, train loss-1.8302, acc-0.4600, valid loss-1.8793, acc-0.4986, test loss-1.8411, acc-0.5168\n",
      "Iter-85730, train loss-1.8318, acc-0.5800, valid loss-1.8793, acc-0.4988, test loss-1.8411, acc-0.5168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-85740, train loss-1.7815, acc-0.5000, valid loss-1.8793, acc-0.4984, test loss-1.8411, acc-0.5167\n",
      "Iter-85750, train loss-1.9066, acc-0.5000, valid loss-1.8793, acc-0.4986, test loss-1.8410, acc-0.5166\n",
      "Iter-85760, train loss-1.7910, acc-0.6400, valid loss-1.8792, acc-0.4988, test loss-1.8410, acc-0.5168\n",
      "Iter-85770, train loss-1.9136, acc-0.4200, valid loss-1.8792, acc-0.4988, test loss-1.8410, acc-0.5166\n",
      "Iter-85780, train loss-1.7583, acc-0.5200, valid loss-1.8792, acc-0.4986, test loss-1.8409, acc-0.5166\n",
      "Iter-85790, train loss-1.7838, acc-0.6400, valid loss-1.8791, acc-0.4986, test loss-1.8409, acc-0.5165\n",
      "Iter-85800, train loss-1.8263, acc-0.5000, valid loss-1.8791, acc-0.4988, test loss-1.8409, acc-0.5166\n",
      "Iter-85810, train loss-1.8774, acc-0.4800, valid loss-1.8791, acc-0.4988, test loss-1.8409, acc-0.5168\n",
      "Iter-85820, train loss-1.8696, acc-0.5400, valid loss-1.8791, acc-0.4986, test loss-1.8408, acc-0.5167\n",
      "Iter-85830, train loss-1.8520, acc-0.4800, valid loss-1.8790, acc-0.4986, test loss-1.8408, acc-0.5168\n",
      "Iter-85840, train loss-1.7936, acc-0.5200, valid loss-1.8790, acc-0.4982, test loss-1.8408, acc-0.5168\n",
      "Iter-85850, train loss-1.8770, acc-0.4600, valid loss-1.8790, acc-0.4982, test loss-1.8407, acc-0.5167\n",
      "Iter-85860, train loss-1.9625, acc-0.4200, valid loss-1.8790, acc-0.4982, test loss-1.8407, acc-0.5168\n",
      "Iter-85870, train loss-1.9717, acc-0.4200, valid loss-1.8789, acc-0.4982, test loss-1.8407, acc-0.5168\n",
      "Iter-85880, train loss-1.9176, acc-0.5000, valid loss-1.8789, acc-0.4982, test loss-1.8406, acc-0.5167\n",
      "Iter-85890, train loss-1.8195, acc-0.6600, valid loss-1.8789, acc-0.4982, test loss-1.8406, acc-0.5167\n",
      "Iter-85900, train loss-1.8958, acc-0.4000, valid loss-1.8788, acc-0.4980, test loss-1.8406, acc-0.5166\n",
      "Iter-85910, train loss-1.7513, acc-0.6200, valid loss-1.8788, acc-0.4982, test loss-1.8405, acc-0.5166\n",
      "Iter-85920, train loss-1.8957, acc-0.4400, valid loss-1.8788, acc-0.4982, test loss-1.8405, acc-0.5167\n",
      "Iter-85930, train loss-1.8200, acc-0.5200, valid loss-1.8788, acc-0.4982, test loss-1.8405, acc-0.5165\n",
      "Iter-85940, train loss-1.9230, acc-0.4600, valid loss-1.8787, acc-0.4984, test loss-1.8404, acc-0.5164\n",
      "Iter-85950, train loss-1.9049, acc-0.5000, valid loss-1.8787, acc-0.4984, test loss-1.8404, acc-0.5165\n",
      "Iter-85960, train loss-1.8867, acc-0.5400, valid loss-1.8787, acc-0.4984, test loss-1.8404, acc-0.5165\n",
      "Iter-85970, train loss-1.9248, acc-0.4000, valid loss-1.8787, acc-0.4984, test loss-1.8404, acc-0.5167\n",
      "Iter-85980, train loss-1.8646, acc-0.4800, valid loss-1.8786, acc-0.4986, test loss-1.8403, acc-0.5167\n",
      "Iter-85990, train loss-1.7828, acc-0.6600, valid loss-1.8786, acc-0.4984, test loss-1.8403, acc-0.5169\n",
      "Iter-86000, train loss-1.8717, acc-0.5000, valid loss-1.8786, acc-0.4982, test loss-1.8403, acc-0.5170\n",
      "Iter-86010, train loss-1.8981, acc-0.4000, valid loss-1.8785, acc-0.4984, test loss-1.8402, acc-0.5168\n",
      "Iter-86020, train loss-1.8470, acc-0.4600, valid loss-1.8785, acc-0.4984, test loss-1.8402, acc-0.5168\n",
      "Iter-86030, train loss-1.7242, acc-0.7000, valid loss-1.8785, acc-0.4984, test loss-1.8402, acc-0.5167\n",
      "Iter-86040, train loss-1.8588, acc-0.5200, valid loss-1.8785, acc-0.4986, test loss-1.8401, acc-0.5168\n",
      "Iter-86050, train loss-1.8595, acc-0.6200, valid loss-1.8784, acc-0.4986, test loss-1.8401, acc-0.5166\n",
      "Iter-86060, train loss-1.7881, acc-0.5800, valid loss-1.8784, acc-0.4984, test loss-1.8401, acc-0.5166\n",
      "Iter-86070, train loss-1.8576, acc-0.4800, valid loss-1.8784, acc-0.4984, test loss-1.8401, acc-0.5167\n",
      "Iter-86080, train loss-1.9848, acc-0.4000, valid loss-1.8783, acc-0.4984, test loss-1.8400, acc-0.5165\n",
      "Iter-86090, train loss-1.9000, acc-0.3800, valid loss-1.8783, acc-0.4984, test loss-1.8400, acc-0.5166\n",
      "Iter-86100, train loss-1.8933, acc-0.5600, valid loss-1.8783, acc-0.4984, test loss-1.8400, acc-0.5167\n",
      "Iter-86110, train loss-1.9143, acc-0.5800, valid loss-1.8783, acc-0.4984, test loss-1.8399, acc-0.5167\n",
      "Iter-86120, train loss-1.9403, acc-0.4200, valid loss-1.8782, acc-0.4984, test loss-1.8399, acc-0.5170\n",
      "Iter-86130, train loss-1.8702, acc-0.6000, valid loss-1.8782, acc-0.4984, test loss-1.8399, acc-0.5169\n",
      "Iter-86140, train loss-1.8801, acc-0.4000, valid loss-1.8782, acc-0.4984, test loss-1.8398, acc-0.5168\n",
      "Iter-86150, train loss-1.9375, acc-0.4400, valid loss-1.8782, acc-0.4984, test loss-1.8398, acc-0.5169\n",
      "Iter-86160, train loss-1.9410, acc-0.3600, valid loss-1.8781, acc-0.4984, test loss-1.8398, acc-0.5168\n",
      "Iter-86170, train loss-1.9026, acc-0.4600, valid loss-1.8781, acc-0.4984, test loss-1.8397, acc-0.5169\n",
      "Iter-86180, train loss-1.7640, acc-0.5800, valid loss-1.8781, acc-0.4984, test loss-1.8397, acc-0.5169\n",
      "Iter-86190, train loss-1.9170, acc-0.4400, valid loss-1.8780, acc-0.4984, test loss-1.8397, acc-0.5169\n",
      "Iter-86200, train loss-1.7842, acc-0.6000, valid loss-1.8780, acc-0.4984, test loss-1.8397, acc-0.5167\n",
      "Iter-86210, train loss-1.9940, acc-0.3600, valid loss-1.8780, acc-0.4984, test loss-1.8396, acc-0.5168\n",
      "Iter-86220, train loss-1.7803, acc-0.6000, valid loss-1.8780, acc-0.4984, test loss-1.8396, acc-0.5168\n",
      "Iter-86230, train loss-1.8230, acc-0.5000, valid loss-1.8779, acc-0.4984, test loss-1.8396, acc-0.5168\n",
      "Iter-86240, train loss-1.8946, acc-0.4200, valid loss-1.8779, acc-0.4984, test loss-1.8395, acc-0.5168\n",
      "Iter-86250, train loss-1.9064, acc-0.4200, valid loss-1.8779, acc-0.4984, test loss-1.8395, acc-0.5168\n",
      "Iter-86260, train loss-1.8653, acc-0.5200, valid loss-1.8779, acc-0.4986, test loss-1.8395, acc-0.5167\n",
      "Iter-86270, train loss-1.7969, acc-0.5800, valid loss-1.8778, acc-0.4986, test loss-1.8394, acc-0.5167\n",
      "Iter-86280, train loss-1.9557, acc-0.4400, valid loss-1.8778, acc-0.4984, test loss-1.8394, acc-0.5168\n",
      "Iter-86290, train loss-1.9041, acc-0.4600, valid loss-1.8778, acc-0.4984, test loss-1.8394, acc-0.5168\n",
      "Iter-86300, train loss-1.7647, acc-0.5600, valid loss-1.8777, acc-0.4986, test loss-1.8393, acc-0.5171\n",
      "Iter-86310, train loss-1.9014, acc-0.4800, valid loss-1.8777, acc-0.4984, test loss-1.8393, acc-0.5170\n",
      "Iter-86320, train loss-1.8752, acc-0.4200, valid loss-1.8777, acc-0.4986, test loss-1.8393, acc-0.5169\n",
      "Iter-86330, train loss-1.8549, acc-0.4200, valid loss-1.8777, acc-0.4986, test loss-1.8392, acc-0.5169\n",
      "Iter-86340, train loss-1.8556, acc-0.4600, valid loss-1.8776, acc-0.4986, test loss-1.8392, acc-0.5168\n",
      "Iter-86350, train loss-1.7657, acc-0.6000, valid loss-1.8776, acc-0.4986, test loss-1.8392, acc-0.5168\n",
      "Iter-86360, train loss-1.8405, acc-0.6000, valid loss-1.8776, acc-0.4986, test loss-1.8392, acc-0.5168\n",
      "Iter-86370, train loss-1.8190, acc-0.6000, valid loss-1.8776, acc-0.4986, test loss-1.8391, acc-0.5169\n",
      "Iter-86380, train loss-1.8453, acc-0.4000, valid loss-1.8775, acc-0.4986, test loss-1.8391, acc-0.5168\n",
      "Iter-86390, train loss-1.9093, acc-0.5200, valid loss-1.8775, acc-0.4986, test loss-1.8391, acc-0.5168\n",
      "Iter-86400, train loss-1.8733, acc-0.4800, valid loss-1.8775, acc-0.4986, test loss-1.8390, acc-0.5168\n",
      "Iter-86410, train loss-1.8169, acc-0.4800, valid loss-1.8774, acc-0.4988, test loss-1.8390, acc-0.5170\n",
      "Iter-86420, train loss-2.0104, acc-0.4200, valid loss-1.8774, acc-0.4988, test loss-1.8390, acc-0.5170\n",
      "Iter-86430, train loss-1.8423, acc-0.5600, valid loss-1.8774, acc-0.4986, test loss-1.8389, acc-0.5170\n",
      "Iter-86440, train loss-1.9395, acc-0.4800, valid loss-1.8774, acc-0.4986, test loss-1.8389, acc-0.5170\n",
      "Iter-86450, train loss-1.8309, acc-0.5000, valid loss-1.8773, acc-0.4986, test loss-1.8389, acc-0.5170\n",
      "Iter-86460, train loss-1.9214, acc-0.5400, valid loss-1.8773, acc-0.4986, test loss-1.8388, acc-0.5174\n",
      "Iter-86470, train loss-1.9051, acc-0.5600, valid loss-1.8773, acc-0.4988, test loss-1.8388, acc-0.5172\n",
      "Iter-86480, train loss-1.8137, acc-0.5000, valid loss-1.8773, acc-0.4986, test loss-1.8388, acc-0.5172\n",
      "Iter-86490, train loss-1.9172, acc-0.5200, valid loss-1.8772, acc-0.4986, test loss-1.8388, acc-0.5171\n",
      "Iter-86500, train loss-1.8616, acc-0.4400, valid loss-1.8772, acc-0.4988, test loss-1.8387, acc-0.5173\n",
      "Iter-86510, train loss-1.8897, acc-0.4600, valid loss-1.8772, acc-0.4988, test loss-1.8387, acc-0.5170\n",
      "Iter-86520, train loss-1.8160, acc-0.5200, valid loss-1.8771, acc-0.4988, test loss-1.8387, acc-0.5168\n",
      "Iter-86530, train loss-1.8749, acc-0.5000, valid loss-1.8771, acc-0.4988, test loss-1.8386, acc-0.5170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-86540, train loss-1.7983, acc-0.5600, valid loss-1.8771, acc-0.4988, test loss-1.8386, acc-0.5170\n",
      "Iter-86550, train loss-1.9014, acc-0.3800, valid loss-1.8771, acc-0.4988, test loss-1.8386, acc-0.5170\n",
      "Iter-86560, train loss-1.8709, acc-0.5000, valid loss-1.8770, acc-0.4988, test loss-1.8385, acc-0.5171\n",
      "Iter-86570, train loss-1.8270, acc-0.5600, valid loss-1.8770, acc-0.4988, test loss-1.8385, acc-0.5171\n",
      "Iter-86580, train loss-1.8677, acc-0.4400, valid loss-1.8770, acc-0.4986, test loss-1.8385, acc-0.5170\n",
      "Iter-86590, train loss-1.7935, acc-0.4400, valid loss-1.8770, acc-0.4986, test loss-1.8384, acc-0.5169\n",
      "Iter-86600, train loss-1.8612, acc-0.6000, valid loss-1.8769, acc-0.4986, test loss-1.8384, acc-0.5170\n",
      "Iter-86610, train loss-1.8784, acc-0.3800, valid loss-1.8769, acc-0.4986, test loss-1.8384, acc-0.5168\n",
      "Iter-86620, train loss-1.8268, acc-0.5000, valid loss-1.8769, acc-0.4986, test loss-1.8383, acc-0.5169\n",
      "Iter-86630, train loss-1.8562, acc-0.4200, valid loss-1.8768, acc-0.4986, test loss-1.8383, acc-0.5168\n",
      "Iter-86640, train loss-1.8753, acc-0.5200, valid loss-1.8768, acc-0.4986, test loss-1.8383, acc-0.5168\n",
      "Iter-86650, train loss-1.7904, acc-0.5000, valid loss-1.8768, acc-0.4986, test loss-1.8383, acc-0.5168\n",
      "Iter-86660, train loss-1.8956, acc-0.5200, valid loss-1.8768, acc-0.4986, test loss-1.8382, acc-0.5168\n",
      "Iter-86670, train loss-1.9426, acc-0.4400, valid loss-1.8767, acc-0.4988, test loss-1.8382, acc-0.5169\n",
      "Iter-86680, train loss-1.8513, acc-0.5400, valid loss-1.8767, acc-0.4988, test loss-1.8382, acc-0.5169\n",
      "Iter-86690, train loss-1.7507, acc-0.5800, valid loss-1.8767, acc-0.4986, test loss-1.8381, acc-0.5168\n",
      "Iter-86700, train loss-1.8532, acc-0.5000, valid loss-1.8767, acc-0.4986, test loss-1.8381, acc-0.5168\n",
      "Iter-86710, train loss-1.8213, acc-0.5200, valid loss-1.8766, acc-0.4984, test loss-1.8381, acc-0.5168\n",
      "Iter-86720, train loss-1.8434, acc-0.5200, valid loss-1.8766, acc-0.4986, test loss-1.8380, acc-0.5169\n",
      "Iter-86730, train loss-1.8110, acc-0.4800, valid loss-1.8766, acc-0.4988, test loss-1.8380, acc-0.5169\n",
      "Iter-86740, train loss-1.8651, acc-0.5200, valid loss-1.8765, acc-0.4988, test loss-1.8380, acc-0.5169\n",
      "Iter-86750, train loss-1.7802, acc-0.6000, valid loss-1.8765, acc-0.4986, test loss-1.8380, acc-0.5167\n",
      "Iter-86760, train loss-1.8591, acc-0.4400, valid loss-1.8765, acc-0.4988, test loss-1.8379, acc-0.5167\n",
      "Iter-86770, train loss-1.7211, acc-0.7200, valid loss-1.8764, acc-0.4988, test loss-1.8379, acc-0.5165\n",
      "Iter-86780, train loss-1.8123, acc-0.5600, valid loss-1.8764, acc-0.4988, test loss-1.8379, acc-0.5163\n",
      "Iter-86790, train loss-1.8590, acc-0.6000, valid loss-1.8764, acc-0.4988, test loss-1.8378, acc-0.5166\n",
      "Iter-86800, train loss-1.9447, acc-0.3600, valid loss-1.8764, acc-0.4988, test loss-1.8378, acc-0.5167\n",
      "Iter-86810, train loss-1.8092, acc-0.6000, valid loss-1.8763, acc-0.4988, test loss-1.8378, acc-0.5167\n",
      "Iter-86820, train loss-1.9495, acc-0.4400, valid loss-1.8763, acc-0.4986, test loss-1.8377, acc-0.5170\n",
      "Iter-86830, train loss-1.9108, acc-0.5200, valid loss-1.8763, acc-0.4984, test loss-1.8377, acc-0.5169\n",
      "Iter-86840, train loss-1.8141, acc-0.4600, valid loss-1.8762, acc-0.4988, test loss-1.8377, acc-0.5166\n",
      "Iter-86850, train loss-1.9487, acc-0.5400, valid loss-1.8762, acc-0.4988, test loss-1.8376, acc-0.5166\n",
      "Iter-86860, train loss-1.7052, acc-0.6800, valid loss-1.8762, acc-0.4986, test loss-1.8376, acc-0.5164\n",
      "Iter-86870, train loss-1.8649, acc-0.5200, valid loss-1.8762, acc-0.4986, test loss-1.8376, acc-0.5167\n",
      "Iter-86880, train loss-1.8211, acc-0.5800, valid loss-1.8761, acc-0.4986, test loss-1.8376, acc-0.5168\n",
      "Iter-86890, train loss-1.8170, acc-0.4400, valid loss-1.8761, acc-0.4984, test loss-1.8375, acc-0.5166\n",
      "Iter-86900, train loss-1.8535, acc-0.5000, valid loss-1.8761, acc-0.4986, test loss-1.8375, acc-0.5169\n",
      "Iter-86910, train loss-1.7844, acc-0.6200, valid loss-1.8761, acc-0.4988, test loss-1.8375, acc-0.5166\n",
      "Iter-86920, train loss-1.8701, acc-0.4800, valid loss-1.8760, acc-0.4988, test loss-1.8374, acc-0.5167\n",
      "Iter-86930, train loss-1.8028, acc-0.5000, valid loss-1.8760, acc-0.4990, test loss-1.8374, acc-0.5165\n",
      "Iter-86940, train loss-1.8630, acc-0.5400, valid loss-1.8760, acc-0.4990, test loss-1.8374, acc-0.5166\n",
      "Iter-86950, train loss-1.8397, acc-0.6400, valid loss-1.8759, acc-0.4990, test loss-1.8373, acc-0.5166\n",
      "Iter-86960, train loss-1.9312, acc-0.3600, valid loss-1.8759, acc-0.4990, test loss-1.8373, acc-0.5164\n",
      "Iter-86970, train loss-1.8783, acc-0.4600, valid loss-1.8759, acc-0.4988, test loss-1.8373, acc-0.5165\n",
      "Iter-86980, train loss-1.9224, acc-0.4000, valid loss-1.8759, acc-0.4986, test loss-1.8373, acc-0.5165\n",
      "Iter-86990, train loss-1.8930, acc-0.4800, valid loss-1.8758, acc-0.4986, test loss-1.8372, acc-0.5165\n",
      "Iter-87000, train loss-1.7813, acc-0.5800, valid loss-1.8758, acc-0.4984, test loss-1.8372, acc-0.5166\n",
      "Iter-87010, train loss-1.7833, acc-0.6400, valid loss-1.8758, acc-0.4984, test loss-1.8372, acc-0.5166\n",
      "Iter-87020, train loss-1.8624, acc-0.5200, valid loss-1.8757, acc-0.4984, test loss-1.8371, acc-0.5164\n",
      "Iter-87030, train loss-1.8230, acc-0.4400, valid loss-1.8757, acc-0.4984, test loss-1.8371, acc-0.5163\n",
      "Iter-87040, train loss-1.8253, acc-0.5600, valid loss-1.8757, acc-0.4986, test loss-1.8371, acc-0.5164\n",
      "Iter-87050, train loss-1.8701, acc-0.5000, valid loss-1.8757, acc-0.4984, test loss-1.8370, acc-0.5165\n",
      "Iter-87060, train loss-1.7540, acc-0.6000, valid loss-1.8756, acc-0.4982, test loss-1.8370, acc-0.5165\n",
      "Iter-87070, train loss-1.8494, acc-0.5400, valid loss-1.8756, acc-0.4984, test loss-1.8370, acc-0.5165\n",
      "Iter-87080, train loss-1.8571, acc-0.4000, valid loss-1.8756, acc-0.4984, test loss-1.8369, acc-0.5165\n",
      "Iter-87090, train loss-1.8399, acc-0.5400, valid loss-1.8756, acc-0.4984, test loss-1.8369, acc-0.5167\n",
      "Iter-87100, train loss-1.9034, acc-0.5200, valid loss-1.8755, acc-0.4986, test loss-1.8369, acc-0.5167\n",
      "Iter-87110, train loss-1.8209, acc-0.5800, valid loss-1.8755, acc-0.4986, test loss-1.8369, acc-0.5166\n",
      "Iter-87120, train loss-1.8108, acc-0.5800, valid loss-1.8755, acc-0.4986, test loss-1.8368, acc-0.5168\n",
      "Iter-87130, train loss-1.7832, acc-0.6200, valid loss-1.8754, acc-0.4986, test loss-1.8368, acc-0.5164\n",
      "Iter-87140, train loss-1.7088, acc-0.6200, valid loss-1.8754, acc-0.4986, test loss-1.8368, acc-0.5165\n",
      "Iter-87150, train loss-1.8563, acc-0.5200, valid loss-1.8754, acc-0.4986, test loss-1.8367, acc-0.5165\n",
      "Iter-87160, train loss-1.9093, acc-0.4800, valid loss-1.8753, acc-0.4982, test loss-1.8367, acc-0.5166\n",
      "Iter-87170, train loss-1.8585, acc-0.4800, valid loss-1.8753, acc-0.4982, test loss-1.8367, acc-0.5166\n",
      "Iter-87180, train loss-1.8641, acc-0.4800, valid loss-1.8753, acc-0.4984, test loss-1.8366, acc-0.5168\n",
      "Iter-87190, train loss-1.8358, acc-0.5200, valid loss-1.8753, acc-0.4984, test loss-1.8366, acc-0.5168\n",
      "Iter-87200, train loss-1.8289, acc-0.5600, valid loss-1.8752, acc-0.4986, test loss-1.8366, acc-0.5165\n",
      "Iter-87210, train loss-1.9009, acc-0.6000, valid loss-1.8752, acc-0.4986, test loss-1.8365, acc-0.5165\n",
      "Iter-87220, train loss-1.8322, acc-0.5600, valid loss-1.8752, acc-0.4984, test loss-1.8365, acc-0.5168\n",
      "Iter-87230, train loss-1.8851, acc-0.4400, valid loss-1.8752, acc-0.4980, test loss-1.8365, acc-0.5168\n",
      "Iter-87240, train loss-1.9068, acc-0.4600, valid loss-1.8751, acc-0.4980, test loss-1.8365, acc-0.5167\n",
      "Iter-87250, train loss-1.8931, acc-0.4600, valid loss-1.8751, acc-0.4984, test loss-1.8364, acc-0.5166\n",
      "Iter-87260, train loss-1.8263, acc-0.5800, valid loss-1.8751, acc-0.4982, test loss-1.8364, acc-0.5167\n",
      "Iter-87270, train loss-1.7810, acc-0.5200, valid loss-1.8750, acc-0.4982, test loss-1.8364, acc-0.5168\n",
      "Iter-87280, train loss-1.7928, acc-0.6200, valid loss-1.8750, acc-0.4982, test loss-1.8363, acc-0.5165\n",
      "Iter-87290, train loss-1.8805, acc-0.4400, valid loss-1.8750, acc-0.4982, test loss-1.8363, acc-0.5166\n",
      "Iter-87300, train loss-1.8970, acc-0.5000, valid loss-1.8750, acc-0.4982, test loss-1.8363, acc-0.5165\n",
      "Iter-87310, train loss-1.8562, acc-0.5000, valid loss-1.8749, acc-0.4982, test loss-1.8362, acc-0.5165\n",
      "Iter-87320, train loss-1.9408, acc-0.4000, valid loss-1.8749, acc-0.4982, test loss-1.8362, acc-0.5165\n",
      "Iter-87330, train loss-1.8604, acc-0.5800, valid loss-1.8749, acc-0.4980, test loss-1.8362, acc-0.5167\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-87340, train loss-1.8332, acc-0.5200, valid loss-1.8749, acc-0.4982, test loss-1.8361, acc-0.5166\n",
      "Iter-87350, train loss-1.8554, acc-0.4600, valid loss-1.8748, acc-0.4982, test loss-1.8361, acc-0.5167\n",
      "Iter-87360, train loss-1.9063, acc-0.5200, valid loss-1.8748, acc-0.4984, test loss-1.8361, acc-0.5165\n",
      "Iter-87370, train loss-1.8832, acc-0.5000, valid loss-1.8748, acc-0.4986, test loss-1.8361, acc-0.5169\n",
      "Iter-87380, train loss-1.8027, acc-0.4600, valid loss-1.8747, acc-0.4986, test loss-1.8360, acc-0.5166\n",
      "Iter-87390, train loss-1.8574, acc-0.4400, valid loss-1.8747, acc-0.4984, test loss-1.8360, acc-0.5167\n",
      "Iter-87400, train loss-1.7901, acc-0.5400, valid loss-1.8747, acc-0.4986, test loss-1.8360, acc-0.5167\n",
      "Iter-87410, train loss-1.7956, acc-0.5600, valid loss-1.8747, acc-0.4984, test loss-1.8359, acc-0.5168\n",
      "Iter-87420, train loss-1.8224, acc-0.5600, valid loss-1.8746, acc-0.4982, test loss-1.8359, acc-0.5165\n",
      "Iter-87430, train loss-1.7643, acc-0.6400, valid loss-1.8746, acc-0.4982, test loss-1.8359, acc-0.5168\n",
      "Iter-87440, train loss-1.9783, acc-0.5200, valid loss-1.8746, acc-0.4982, test loss-1.8358, acc-0.5168\n",
      "Iter-87450, train loss-1.9014, acc-0.3200, valid loss-1.8746, acc-0.4984, test loss-1.8358, acc-0.5168\n",
      "Iter-87460, train loss-1.8861, acc-0.4200, valid loss-1.8745, acc-0.4984, test loss-1.8358, acc-0.5167\n",
      "Iter-87470, train loss-1.8881, acc-0.4600, valid loss-1.8745, acc-0.4984, test loss-1.8358, acc-0.5167\n",
      "Iter-87480, train loss-1.8048, acc-0.5800, valid loss-1.8745, acc-0.4984, test loss-1.8357, acc-0.5168\n",
      "Iter-87490, train loss-1.7870, acc-0.5600, valid loss-1.8744, acc-0.4984, test loss-1.8357, acc-0.5167\n",
      "Iter-87500, train loss-1.9009, acc-0.5400, valid loss-1.8744, acc-0.4984, test loss-1.8357, acc-0.5168\n",
      "Iter-87510, train loss-1.9629, acc-0.4200, valid loss-1.8744, acc-0.4984, test loss-1.8356, acc-0.5168\n",
      "Iter-87520, train loss-1.8657, acc-0.5200, valid loss-1.8744, acc-0.4988, test loss-1.8356, acc-0.5166\n",
      "Iter-87530, train loss-1.8367, acc-0.5400, valid loss-1.8743, acc-0.4984, test loss-1.8356, acc-0.5169\n",
      "Iter-87540, train loss-1.8274, acc-0.5200, valid loss-1.8743, acc-0.4984, test loss-1.8355, acc-0.5169\n",
      "Iter-87550, train loss-1.9701, acc-0.4600, valid loss-1.8743, acc-0.4982, test loss-1.8355, acc-0.5173\n",
      "Iter-87560, train loss-1.7808, acc-0.6000, valid loss-1.8743, acc-0.4982, test loss-1.8355, acc-0.5173\n",
      "Iter-87570, train loss-1.9197, acc-0.5000, valid loss-1.8742, acc-0.4982, test loss-1.8354, acc-0.5173\n",
      "Iter-87580, train loss-1.7433, acc-0.6400, valid loss-1.8742, acc-0.4984, test loss-1.8354, acc-0.5172\n",
      "Iter-87590, train loss-1.8955, acc-0.4800, valid loss-1.8742, acc-0.4984, test loss-1.8354, acc-0.5173\n",
      "Iter-87600, train loss-1.7983, acc-0.5000, valid loss-1.8741, acc-0.4986, test loss-1.8354, acc-0.5174\n",
      "Iter-87610, train loss-1.8753, acc-0.4600, valid loss-1.8741, acc-0.4984, test loss-1.8353, acc-0.5173\n",
      "Iter-87620, train loss-1.8047, acc-0.4800, valid loss-1.8741, acc-0.4986, test loss-1.8353, acc-0.5173\n",
      "Iter-87630, train loss-1.8976, acc-0.3600, valid loss-1.8741, acc-0.4986, test loss-1.8353, acc-0.5172\n",
      "Iter-87640, train loss-1.8560, acc-0.5000, valid loss-1.8740, acc-0.4986, test loss-1.8352, acc-0.5171\n",
      "Iter-87650, train loss-1.8972, acc-0.4400, valid loss-1.8740, acc-0.4988, test loss-1.8352, acc-0.5170\n",
      "Iter-87660, train loss-1.8054, acc-0.5000, valid loss-1.8740, acc-0.4990, test loss-1.8352, acc-0.5172\n",
      "Iter-87670, train loss-1.8833, acc-0.5000, valid loss-1.8740, acc-0.4986, test loss-1.8351, acc-0.5172\n",
      "Iter-87680, train loss-1.8950, acc-0.3600, valid loss-1.8739, acc-0.4988, test loss-1.8351, acc-0.5172\n",
      "Iter-87690, train loss-1.8534, acc-0.5200, valid loss-1.8739, acc-0.4988, test loss-1.8351, acc-0.5173\n",
      "Iter-87700, train loss-1.8743, acc-0.5400, valid loss-1.8739, acc-0.4988, test loss-1.8350, acc-0.5173\n",
      "Iter-87710, train loss-1.8857, acc-0.5000, valid loss-1.8738, acc-0.4988, test loss-1.8350, acc-0.5170\n",
      "Iter-87720, train loss-1.8043, acc-0.6200, valid loss-1.8738, acc-0.4988, test loss-1.8350, acc-0.5171\n",
      "Iter-87730, train loss-1.8305, acc-0.5200, valid loss-1.8738, acc-0.4988, test loss-1.8350, acc-0.5172\n",
      "Iter-87740, train loss-1.7899, acc-0.5400, valid loss-1.8737, acc-0.4992, test loss-1.8349, acc-0.5174\n",
      "Iter-87750, train loss-1.7700, acc-0.5600, valid loss-1.8737, acc-0.4992, test loss-1.8349, acc-0.5174\n",
      "Iter-87760, train loss-1.9146, acc-0.4000, valid loss-1.8737, acc-0.4992, test loss-1.8349, acc-0.5172\n",
      "Iter-87770, train loss-1.8405, acc-0.5000, valid loss-1.8737, acc-0.4992, test loss-1.8348, acc-0.5174\n",
      "Iter-87780, train loss-1.8674, acc-0.4800, valid loss-1.8736, acc-0.4992, test loss-1.8348, acc-0.5175\n",
      "Iter-87790, train loss-1.8302, acc-0.5400, valid loss-1.8736, acc-0.4990, test loss-1.8348, acc-0.5175\n",
      "Iter-87800, train loss-1.7901, acc-0.6400, valid loss-1.8736, acc-0.4990, test loss-1.8347, acc-0.5175\n",
      "Iter-87810, train loss-1.9382, acc-0.4400, valid loss-1.8736, acc-0.4990, test loss-1.8347, acc-0.5173\n",
      "Iter-87820, train loss-1.8506, acc-0.5000, valid loss-1.8735, acc-0.4988, test loss-1.8347, acc-0.5174\n",
      "Iter-87830, train loss-1.8725, acc-0.5200, valid loss-1.8735, acc-0.4990, test loss-1.8347, acc-0.5174\n",
      "Iter-87840, train loss-1.8121, acc-0.5400, valid loss-1.8735, acc-0.4990, test loss-1.8346, acc-0.5174\n",
      "Iter-87850, train loss-1.8489, acc-0.5400, valid loss-1.8734, acc-0.4990, test loss-1.8346, acc-0.5173\n",
      "Iter-87860, train loss-1.8812, acc-0.4600, valid loss-1.8734, acc-0.4990, test loss-1.8346, acc-0.5174\n",
      "Iter-87870, train loss-1.8606, acc-0.4600, valid loss-1.8734, acc-0.4992, test loss-1.8345, acc-0.5174\n",
      "Iter-87880, train loss-1.8365, acc-0.4600, valid loss-1.8734, acc-0.4990, test loss-1.8345, acc-0.5174\n",
      "Iter-87890, train loss-1.8368, acc-0.5200, valid loss-1.8733, acc-0.4992, test loss-1.8345, acc-0.5176\n",
      "Iter-87900, train loss-1.8894, acc-0.5200, valid loss-1.8733, acc-0.4992, test loss-1.8344, acc-0.5176\n",
      "Iter-87910, train loss-1.8362, acc-0.5200, valid loss-1.8733, acc-0.4990, test loss-1.8344, acc-0.5176\n",
      "Iter-87920, train loss-1.8000, acc-0.5600, valid loss-1.8732, acc-0.4992, test loss-1.8344, acc-0.5175\n",
      "Iter-87930, train loss-1.8646, acc-0.4600, valid loss-1.8732, acc-0.4992, test loss-1.8343, acc-0.5176\n",
      "Iter-87940, train loss-1.8977, acc-0.5000, valid loss-1.8732, acc-0.4992, test loss-1.8343, acc-0.5174\n",
      "Iter-87950, train loss-1.9570, acc-0.4400, valid loss-1.8732, acc-0.4994, test loss-1.8343, acc-0.5175\n",
      "Iter-87960, train loss-1.8297, acc-0.4600, valid loss-1.8731, acc-0.4992, test loss-1.8343, acc-0.5175\n",
      "Iter-87970, train loss-1.7946, acc-0.5400, valid loss-1.8731, acc-0.4992, test loss-1.8342, acc-0.5174\n",
      "Iter-87980, train loss-1.8256, acc-0.4400, valid loss-1.8731, acc-0.4990, test loss-1.8342, acc-0.5174\n",
      "Iter-87990, train loss-1.7517, acc-0.5400, valid loss-1.8730, acc-0.4990, test loss-1.8342, acc-0.5173\n",
      "Iter-88000, train loss-1.7704, acc-0.5600, valid loss-1.8730, acc-0.4986, test loss-1.8341, acc-0.5175\n",
      "Iter-88010, train loss-1.8416, acc-0.5600, valid loss-1.8730, acc-0.4990, test loss-1.8341, acc-0.5175\n",
      "Iter-88020, train loss-1.8216, acc-0.5600, valid loss-1.8730, acc-0.4992, test loss-1.8341, acc-0.5175\n",
      "Iter-88030, train loss-1.7414, acc-0.5600, valid loss-1.8729, acc-0.4990, test loss-1.8340, acc-0.5177\n",
      "Iter-88040, train loss-1.8561, acc-0.4600, valid loss-1.8729, acc-0.4988, test loss-1.8340, acc-0.5173\n",
      "Iter-88050, train loss-1.8032, acc-0.5800, valid loss-1.8729, acc-0.4988, test loss-1.8340, acc-0.5174\n",
      "Iter-88060, train loss-1.8351, acc-0.4800, valid loss-1.8728, acc-0.4988, test loss-1.8340, acc-0.5174\n",
      "Iter-88070, train loss-1.8907, acc-0.4000, valid loss-1.8728, acc-0.4988, test loss-1.8339, acc-0.5173\n",
      "Iter-88080, train loss-1.9668, acc-0.4400, valid loss-1.8728, acc-0.4988, test loss-1.8339, acc-0.5172\n",
      "Iter-88090, train loss-1.6875, acc-0.6400, valid loss-1.8728, acc-0.4986, test loss-1.8339, acc-0.5171\n",
      "Iter-88100, train loss-1.8005, acc-0.6000, valid loss-1.8727, acc-0.4988, test loss-1.8338, acc-0.5171\n",
      "Iter-88110, train loss-1.7817, acc-0.5600, valid loss-1.8727, acc-0.4990, test loss-1.8338, acc-0.5170\n",
      "Iter-88120, train loss-1.9676, acc-0.3400, valid loss-1.8727, acc-0.4988, test loss-1.8338, acc-0.5172\n",
      "Iter-88130, train loss-1.7866, acc-0.5000, valid loss-1.8726, acc-0.4988, test loss-1.8337, acc-0.5171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-88140, train loss-1.8580, acc-0.5200, valid loss-1.8726, acc-0.4990, test loss-1.8337, acc-0.5171\n",
      "Iter-88150, train loss-1.8660, acc-0.4400, valid loss-1.8726, acc-0.4988, test loss-1.8337, acc-0.5169\n",
      "Iter-88160, train loss-1.8044, acc-0.5200, valid loss-1.8726, acc-0.4988, test loss-1.8337, acc-0.5172\n",
      "Iter-88170, train loss-1.7331, acc-0.6400, valid loss-1.8725, acc-0.4988, test loss-1.8336, acc-0.5171\n",
      "Iter-88180, train loss-1.8044, acc-0.5400, valid loss-1.8725, acc-0.4988, test loss-1.8336, acc-0.5170\n",
      "Iter-88190, train loss-1.8211, acc-0.5000, valid loss-1.8725, acc-0.4986, test loss-1.8336, acc-0.5171\n",
      "Iter-88200, train loss-1.8710, acc-0.4600, valid loss-1.8724, acc-0.4988, test loss-1.8335, acc-0.5170\n",
      "Iter-88210, train loss-1.8181, acc-0.4400, valid loss-1.8724, acc-0.4988, test loss-1.8335, acc-0.5171\n",
      "Iter-88220, train loss-1.8428, acc-0.5400, valid loss-1.8724, acc-0.4988, test loss-1.8335, acc-0.5170\n",
      "Iter-88230, train loss-1.8983, acc-0.3800, valid loss-1.8724, acc-0.4986, test loss-1.8334, acc-0.5171\n",
      "Iter-88240, train loss-1.8482, acc-0.5000, valid loss-1.8723, acc-0.4986, test loss-1.8334, acc-0.5171\n",
      "Iter-88250, train loss-1.7450, acc-0.6800, valid loss-1.8723, acc-0.4986, test loss-1.8334, acc-0.5172\n",
      "Iter-88260, train loss-1.8575, acc-0.4800, valid loss-1.8723, acc-0.4986, test loss-1.8334, acc-0.5170\n",
      "Iter-88270, train loss-1.8045, acc-0.6000, valid loss-1.8722, acc-0.4984, test loss-1.8333, acc-0.5169\n",
      "Iter-88280, train loss-1.8773, acc-0.5400, valid loss-1.8722, acc-0.4982, test loss-1.8333, acc-0.5170\n",
      "Iter-88290, train loss-1.9301, acc-0.5000, valid loss-1.8722, acc-0.4984, test loss-1.8333, acc-0.5170\n",
      "Iter-88300, train loss-1.8519, acc-0.5400, valid loss-1.8722, acc-0.4988, test loss-1.8332, acc-0.5170\n",
      "Iter-88310, train loss-1.8697, acc-0.4600, valid loss-1.8721, acc-0.4986, test loss-1.8332, acc-0.5169\n",
      "Iter-88320, train loss-1.9878, acc-0.3400, valid loss-1.8721, acc-0.4986, test loss-1.8332, acc-0.5170\n",
      "Iter-88330, train loss-1.8776, acc-0.4600, valid loss-1.8721, acc-0.4986, test loss-1.8332, acc-0.5170\n",
      "Iter-88340, train loss-1.8268, acc-0.5400, valid loss-1.8721, acc-0.4986, test loss-1.8331, acc-0.5170\n",
      "Iter-88350, train loss-1.8635, acc-0.5200, valid loss-1.8720, acc-0.4986, test loss-1.8331, acc-0.5172\n",
      "Iter-88360, train loss-1.8534, acc-0.5000, valid loss-1.8720, acc-0.4986, test loss-1.8331, acc-0.5173\n",
      "Iter-88370, train loss-2.0002, acc-0.3800, valid loss-1.8720, acc-0.4986, test loss-1.8330, acc-0.5172\n",
      "Iter-88380, train loss-1.9272, acc-0.3800, valid loss-1.8720, acc-0.4986, test loss-1.8330, acc-0.5171\n",
      "Iter-88390, train loss-1.9285, acc-0.4800, valid loss-1.8719, acc-0.4988, test loss-1.8330, acc-0.5173\n",
      "Iter-88400, train loss-1.8035, acc-0.4400, valid loss-1.8719, acc-0.4988, test loss-1.8330, acc-0.5170\n",
      "Iter-88410, train loss-1.8650, acc-0.5000, valid loss-1.8719, acc-0.4986, test loss-1.8329, acc-0.5170\n",
      "Iter-88420, train loss-1.9120, acc-0.5600, valid loss-1.8718, acc-0.4986, test loss-1.8329, acc-0.5175\n",
      "Iter-88430, train loss-1.8534, acc-0.4800, valid loss-1.8718, acc-0.4990, test loss-1.8329, acc-0.5174\n",
      "Iter-88440, train loss-1.9170, acc-0.5000, valid loss-1.8718, acc-0.4986, test loss-1.8328, acc-0.5175\n",
      "Iter-88450, train loss-1.9205, acc-0.4600, valid loss-1.8718, acc-0.4984, test loss-1.8328, acc-0.5175\n",
      "Iter-88460, train loss-1.7809, acc-0.6000, valid loss-1.8717, acc-0.4984, test loss-1.8328, acc-0.5175\n",
      "Iter-88470, train loss-1.8584, acc-0.4800, valid loss-1.8717, acc-0.4984, test loss-1.8327, acc-0.5172\n",
      "Iter-88480, train loss-1.8165, acc-0.5600, valid loss-1.8717, acc-0.4988, test loss-1.8327, acc-0.5175\n",
      "Iter-88490, train loss-1.8009, acc-0.5600, valid loss-1.8717, acc-0.4982, test loss-1.8327, acc-0.5173\n",
      "Iter-88500, train loss-1.8214, acc-0.5600, valid loss-1.8716, acc-0.4984, test loss-1.8327, acc-0.5173\n",
      "Iter-88510, train loss-1.8458, acc-0.4600, valid loss-1.8716, acc-0.4984, test loss-1.8326, acc-0.5173\n",
      "Iter-88520, train loss-1.8409, acc-0.4600, valid loss-1.8716, acc-0.4980, test loss-1.8326, acc-0.5173\n",
      "Iter-88530, train loss-1.7716, acc-0.5600, valid loss-1.8715, acc-0.4984, test loss-1.8326, acc-0.5175\n",
      "Iter-88540, train loss-1.8537, acc-0.6200, valid loss-1.8715, acc-0.4986, test loss-1.8325, acc-0.5176\n",
      "Iter-88550, train loss-1.9278, acc-0.4200, valid loss-1.8715, acc-0.4990, test loss-1.8325, acc-0.5177\n",
      "Iter-88560, train loss-1.8569, acc-0.5200, valid loss-1.8715, acc-0.4988, test loss-1.8325, acc-0.5178\n",
      "Iter-88570, train loss-1.7497, acc-0.6000, valid loss-1.8714, acc-0.4990, test loss-1.8324, acc-0.5178\n",
      "Iter-88580, train loss-1.8481, acc-0.4600, valid loss-1.8714, acc-0.4988, test loss-1.8324, acc-0.5176\n",
      "Iter-88590, train loss-1.9882, acc-0.3200, valid loss-1.8714, acc-0.4988, test loss-1.8324, acc-0.5174\n",
      "Iter-88600, train loss-1.8294, acc-0.5400, valid loss-1.8714, acc-0.4988, test loss-1.8324, acc-0.5177\n",
      "Iter-88610, train loss-1.8093, acc-0.5400, valid loss-1.8713, acc-0.4990, test loss-1.8323, acc-0.5178\n",
      "Iter-88620, train loss-1.8189, acc-0.5600, valid loss-1.8713, acc-0.4988, test loss-1.8323, acc-0.5175\n",
      "Iter-88630, train loss-1.7971, acc-0.5600, valid loss-1.8713, acc-0.4986, test loss-1.8323, acc-0.5172\n",
      "Iter-88640, train loss-1.8583, acc-0.4200, valid loss-1.8712, acc-0.4988, test loss-1.8322, acc-0.5174\n",
      "Iter-88650, train loss-1.8267, acc-0.5800, valid loss-1.8712, acc-0.4990, test loss-1.8322, acc-0.5175\n",
      "Iter-88660, train loss-1.7470, acc-0.5600, valid loss-1.8712, acc-0.4988, test loss-1.8322, acc-0.5175\n",
      "Iter-88670, train loss-1.8211, acc-0.5200, valid loss-1.8712, acc-0.4990, test loss-1.8322, acc-0.5176\n",
      "Iter-88680, train loss-1.8774, acc-0.5000, valid loss-1.8711, acc-0.4990, test loss-1.8321, acc-0.5175\n",
      "Iter-88690, train loss-1.8558, acc-0.4200, valid loss-1.8711, acc-0.4990, test loss-1.8321, acc-0.5176\n",
      "Iter-88700, train loss-1.8017, acc-0.5800, valid loss-1.8711, acc-0.4990, test loss-1.8321, acc-0.5174\n",
      "Iter-88710, train loss-1.8230, acc-0.4400, valid loss-1.8711, acc-0.4988, test loss-1.8320, acc-0.5174\n",
      "Iter-88720, train loss-1.9340, acc-0.3200, valid loss-1.8710, acc-0.4990, test loss-1.8320, acc-0.5174\n",
      "Iter-88730, train loss-1.9524, acc-0.4400, valid loss-1.8710, acc-0.4990, test loss-1.8320, acc-0.5176\n",
      "Iter-88740, train loss-1.9242, acc-0.4000, valid loss-1.8710, acc-0.4990, test loss-1.8319, acc-0.5175\n",
      "Iter-88750, train loss-1.8809, acc-0.4400, valid loss-1.8709, acc-0.4988, test loss-1.8319, acc-0.5175\n",
      "Iter-88760, train loss-1.8378, acc-0.5000, valid loss-1.8709, acc-0.4990, test loss-1.8319, acc-0.5174\n",
      "Iter-88770, train loss-1.8075, acc-0.6000, valid loss-1.8709, acc-0.4990, test loss-1.8319, acc-0.5175\n",
      "Iter-88780, train loss-1.7721, acc-0.5200, valid loss-1.8709, acc-0.4990, test loss-1.8318, acc-0.5173\n",
      "Iter-88790, train loss-1.8129, acc-0.6000, valid loss-1.8708, acc-0.4990, test loss-1.8318, acc-0.5175\n",
      "Iter-88800, train loss-1.7382, acc-0.5600, valid loss-1.8708, acc-0.4990, test loss-1.8318, acc-0.5172\n",
      "Iter-88810, train loss-1.8419, acc-0.5200, valid loss-1.8708, acc-0.4988, test loss-1.8317, acc-0.5170\n",
      "Iter-88820, train loss-1.8777, acc-0.5200, valid loss-1.8708, acc-0.4988, test loss-1.8317, acc-0.5171\n",
      "Iter-88830, train loss-1.9092, acc-0.4200, valid loss-1.8707, acc-0.4988, test loss-1.8317, acc-0.5174\n",
      "Iter-88840, train loss-1.8149, acc-0.6400, valid loss-1.8707, acc-0.4988, test loss-1.8316, acc-0.5172\n",
      "Iter-88850, train loss-1.8990, acc-0.4600, valid loss-1.8707, acc-0.4990, test loss-1.8316, acc-0.5172\n",
      "Iter-88860, train loss-1.7236, acc-0.4800, valid loss-1.8706, acc-0.4990, test loss-1.8316, acc-0.5171\n",
      "Iter-88870, train loss-1.8717, acc-0.4400, valid loss-1.8706, acc-0.4990, test loss-1.8316, acc-0.5171\n",
      "Iter-88880, train loss-1.8215, acc-0.5000, valid loss-1.8706, acc-0.4990, test loss-1.8315, acc-0.5172\n",
      "Iter-88890, train loss-1.8597, acc-0.4600, valid loss-1.8706, acc-0.4990, test loss-1.8315, acc-0.5174\n",
      "Iter-88900, train loss-1.7634, acc-0.6200, valid loss-1.8705, acc-0.4990, test loss-1.8315, acc-0.5173\n",
      "Iter-88910, train loss-1.8254, acc-0.6000, valid loss-1.8705, acc-0.4990, test loss-1.8314, acc-0.5171\n",
      "Iter-88920, train loss-1.8498, acc-0.5000, valid loss-1.8705, acc-0.4990, test loss-1.8314, acc-0.5171\n",
      "Iter-88930, train loss-1.7945, acc-0.5200, valid loss-1.8705, acc-0.4990, test loss-1.8314, acc-0.5172\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-88940, train loss-1.8898, acc-0.4200, valid loss-1.8704, acc-0.4990, test loss-1.8313, acc-0.5170\n",
      "Iter-88950, train loss-1.8494, acc-0.4800, valid loss-1.8704, acc-0.4990, test loss-1.8313, acc-0.5170\n",
      "Iter-88960, train loss-1.8844, acc-0.4600, valid loss-1.8704, acc-0.4990, test loss-1.8313, acc-0.5168\n",
      "Iter-88970, train loss-1.8005, acc-0.5600, valid loss-1.8703, acc-0.4990, test loss-1.8313, acc-0.5168\n",
      "Iter-88980, train loss-1.7829, acc-0.5400, valid loss-1.8703, acc-0.4990, test loss-1.8312, acc-0.5168\n",
      "Iter-88990, train loss-1.9218, acc-0.4800, valid loss-1.8703, acc-0.4990, test loss-1.8312, acc-0.5169\n",
      "Iter-89000, train loss-1.7914, acc-0.5600, valid loss-1.8703, acc-0.4990, test loss-1.8312, acc-0.5169\n",
      "Iter-89010, train loss-1.8164, acc-0.5400, valid loss-1.8702, acc-0.4990, test loss-1.8311, acc-0.5171\n",
      "Iter-89020, train loss-1.7966, acc-0.5400, valid loss-1.8702, acc-0.4992, test loss-1.8311, acc-0.5171\n",
      "Iter-89030, train loss-1.8547, acc-0.5400, valid loss-1.8702, acc-0.4992, test loss-1.8311, acc-0.5171\n",
      "Iter-89040, train loss-1.9241, acc-0.3800, valid loss-1.8702, acc-0.4988, test loss-1.8310, acc-0.5171\n",
      "Iter-89050, train loss-1.8512, acc-0.5000, valid loss-1.8701, acc-0.4988, test loss-1.8310, acc-0.5171\n",
      "Iter-89060, train loss-1.8226, acc-0.4600, valid loss-1.8701, acc-0.4990, test loss-1.8310, acc-0.5169\n",
      "Iter-89070, train loss-1.8712, acc-0.5600, valid loss-1.8701, acc-0.4990, test loss-1.8310, acc-0.5171\n",
      "Iter-89080, train loss-1.8982, acc-0.5200, valid loss-1.8701, acc-0.4988, test loss-1.8309, acc-0.5173\n",
      "Iter-89090, train loss-1.7557, acc-0.5600, valid loss-1.8700, acc-0.4988, test loss-1.8309, acc-0.5170\n",
      "Iter-89100, train loss-1.9524, acc-0.3400, valid loss-1.8700, acc-0.4988, test loss-1.8309, acc-0.5172\n",
      "Iter-89110, train loss-1.8349, acc-0.5000, valid loss-1.8700, acc-0.4990, test loss-1.8308, acc-0.5173\n",
      "Iter-89120, train loss-1.9111, acc-0.4200, valid loss-1.8699, acc-0.4992, test loss-1.8308, acc-0.5174\n",
      "Iter-89130, train loss-1.8626, acc-0.5200, valid loss-1.8699, acc-0.4990, test loss-1.8308, acc-0.5174\n",
      "Iter-89140, train loss-1.8170, acc-0.4800, valid loss-1.8699, acc-0.4990, test loss-1.8307, acc-0.5172\n",
      "Iter-89150, train loss-1.8595, acc-0.4400, valid loss-1.8699, acc-0.4990, test loss-1.8307, acc-0.5172\n",
      "Iter-89160, train loss-1.8301, acc-0.5200, valid loss-1.8698, acc-0.4990, test loss-1.8307, acc-0.5172\n",
      "Iter-89170, train loss-1.8132, acc-0.5000, valid loss-1.8698, acc-0.4990, test loss-1.8307, acc-0.5172\n",
      "Iter-89180, train loss-1.8794, acc-0.5200, valid loss-1.8698, acc-0.4986, test loss-1.8306, acc-0.5172\n",
      "Iter-89190, train loss-1.7676, acc-0.6000, valid loss-1.8698, acc-0.4986, test loss-1.8306, acc-0.5173\n",
      "Iter-89200, train loss-1.8562, acc-0.5600, valid loss-1.8697, acc-0.4986, test loss-1.8306, acc-0.5174\n",
      "Iter-89210, train loss-1.8345, acc-0.4000, valid loss-1.8697, acc-0.4986, test loss-1.8305, acc-0.5174\n",
      "Iter-89220, train loss-1.8367, acc-0.4800, valid loss-1.8697, acc-0.4988, test loss-1.8305, acc-0.5174\n",
      "Iter-89230, train loss-1.8259, acc-0.5200, valid loss-1.8696, acc-0.4986, test loss-1.8305, acc-0.5172\n",
      "Iter-89240, train loss-1.7833, acc-0.6000, valid loss-1.8696, acc-0.4986, test loss-1.8304, acc-0.5173\n",
      "Iter-89250, train loss-1.8184, acc-0.4800, valid loss-1.8696, acc-0.4986, test loss-1.8304, acc-0.5172\n",
      "Iter-89260, train loss-1.9035, acc-0.4600, valid loss-1.8696, acc-0.4990, test loss-1.8304, acc-0.5171\n",
      "Iter-89270, train loss-1.8807, acc-0.4200, valid loss-1.8695, acc-0.4990, test loss-1.8304, acc-0.5174\n",
      "Iter-89280, train loss-1.8046, acc-0.5600, valid loss-1.8695, acc-0.4990, test loss-1.8303, acc-0.5173\n",
      "Iter-89290, train loss-1.9144, acc-0.4800, valid loss-1.8695, acc-0.4990, test loss-1.8303, acc-0.5174\n",
      "Iter-89300, train loss-1.8699, acc-0.5400, valid loss-1.8695, acc-0.4990, test loss-1.8303, acc-0.5175\n",
      "Iter-89310, train loss-1.8089, acc-0.4800, valid loss-1.8694, acc-0.4992, test loss-1.8302, acc-0.5174\n",
      "Iter-89320, train loss-1.7998, acc-0.5200, valid loss-1.8694, acc-0.4992, test loss-1.8302, acc-0.5174\n",
      "Iter-89330, train loss-1.9030, acc-0.4400, valid loss-1.8694, acc-0.4992, test loss-1.8302, acc-0.5174\n",
      "Iter-89340, train loss-1.9198, acc-0.4200, valid loss-1.8694, acc-0.4992, test loss-1.8302, acc-0.5175\n",
      "Iter-89350, train loss-1.8176, acc-0.5000, valid loss-1.8693, acc-0.4994, test loss-1.8301, acc-0.5175\n",
      "Iter-89360, train loss-1.7921, acc-0.6200, valid loss-1.8693, acc-0.4994, test loss-1.8301, acc-0.5174\n",
      "Iter-89370, train loss-1.8818, acc-0.4200, valid loss-1.8693, acc-0.4994, test loss-1.8301, acc-0.5174\n",
      "Iter-89380, train loss-1.8316, acc-0.5800, valid loss-1.8693, acc-0.4994, test loss-1.8300, acc-0.5175\n",
      "Iter-89390, train loss-1.8786, acc-0.4800, valid loss-1.8692, acc-0.4994, test loss-1.8300, acc-0.5174\n",
      "Iter-89400, train loss-1.9178, acc-0.3800, valid loss-1.8692, acc-0.4994, test loss-1.8300, acc-0.5173\n",
      "Iter-89410, train loss-1.8409, acc-0.5200, valid loss-1.8692, acc-0.4994, test loss-1.8299, acc-0.5174\n",
      "Iter-89420, train loss-1.8902, acc-0.4400, valid loss-1.8691, acc-0.4994, test loss-1.8299, acc-0.5174\n",
      "Iter-89430, train loss-1.8735, acc-0.4600, valid loss-1.8691, acc-0.4992, test loss-1.8299, acc-0.5176\n",
      "Iter-89440, train loss-1.9446, acc-0.4400, valid loss-1.8691, acc-0.4994, test loss-1.8299, acc-0.5176\n",
      "Iter-89450, train loss-1.9065, acc-0.4800, valid loss-1.8691, acc-0.4994, test loss-1.8298, acc-0.5176\n",
      "Iter-89460, train loss-1.7798, acc-0.5000, valid loss-1.8690, acc-0.4994, test loss-1.8298, acc-0.5174\n",
      "Iter-89470, train loss-1.9224, acc-0.5000, valid loss-1.8690, acc-0.4994, test loss-1.8298, acc-0.5175\n",
      "Iter-89480, train loss-1.8507, acc-0.5000, valid loss-1.8690, acc-0.4994, test loss-1.8297, acc-0.5174\n",
      "Iter-89490, train loss-1.8990, acc-0.4200, valid loss-1.8690, acc-0.4990, test loss-1.8297, acc-0.5176\n",
      "Iter-89500, train loss-1.8469, acc-0.5200, valid loss-1.8689, acc-0.4988, test loss-1.8297, acc-0.5176\n",
      "Iter-89510, train loss-1.8568, acc-0.5400, valid loss-1.8689, acc-0.4990, test loss-1.8296, acc-0.5177\n",
      "Iter-89520, train loss-1.7748, acc-0.6400, valid loss-1.8689, acc-0.4988, test loss-1.8296, acc-0.5177\n",
      "Iter-89530, train loss-1.8181, acc-0.5600, valid loss-1.8688, acc-0.4988, test loss-1.8296, acc-0.5177\n",
      "Iter-89540, train loss-1.8344, acc-0.4800, valid loss-1.8688, acc-0.4988, test loss-1.8295, acc-0.5175\n",
      "Iter-89550, train loss-1.8958, acc-0.4600, valid loss-1.8688, acc-0.4990, test loss-1.8295, acc-0.5176\n",
      "Iter-89560, train loss-1.9271, acc-0.4600, valid loss-1.8688, acc-0.4988, test loss-1.8295, acc-0.5173\n",
      "Iter-89570, train loss-1.8919, acc-0.5000, valid loss-1.8687, acc-0.4992, test loss-1.8295, acc-0.5175\n",
      "Iter-89580, train loss-1.9044, acc-0.4200, valid loss-1.8687, acc-0.4992, test loss-1.8294, acc-0.5174\n",
      "Iter-89590, train loss-1.9179, acc-0.3600, valid loss-1.8687, acc-0.4990, test loss-1.8294, acc-0.5175\n",
      "Iter-89600, train loss-1.9126, acc-0.5000, valid loss-1.8687, acc-0.4992, test loss-1.8294, acc-0.5175\n",
      "Iter-89610, train loss-1.7134, acc-0.6000, valid loss-1.8686, acc-0.4992, test loss-1.8293, acc-0.5176\n",
      "Iter-89620, train loss-1.7922, acc-0.5400, valid loss-1.8686, acc-0.4992, test loss-1.8293, acc-0.5175\n",
      "Iter-89630, train loss-1.7751, acc-0.5200, valid loss-1.8686, acc-0.4994, test loss-1.8293, acc-0.5175\n",
      "Iter-89640, train loss-1.8070, acc-0.5200, valid loss-1.8685, acc-0.4994, test loss-1.8292, acc-0.5176\n",
      "Iter-89650, train loss-1.7466, acc-0.5600, valid loss-1.8685, acc-0.4994, test loss-1.8292, acc-0.5176\n",
      "Iter-89660, train loss-1.8830, acc-0.4200, valid loss-1.8685, acc-0.4994, test loss-1.8292, acc-0.5177\n",
      "Iter-89670, train loss-1.9366, acc-0.3800, valid loss-1.8685, acc-0.4994, test loss-1.8292, acc-0.5173\n",
      "Iter-89680, train loss-1.8295, acc-0.5800, valid loss-1.8684, acc-0.4994, test loss-1.8291, acc-0.5176\n",
      "Iter-89690, train loss-1.7810, acc-0.6600, valid loss-1.8684, acc-0.4994, test loss-1.8291, acc-0.5177\n",
      "Iter-89700, train loss-1.7381, acc-0.4800, valid loss-1.8684, acc-0.4992, test loss-1.8291, acc-0.5178\n",
      "Iter-89710, train loss-1.7420, acc-0.5600, valid loss-1.8684, acc-0.4994, test loss-1.8290, acc-0.5177\n",
      "Iter-89720, train loss-1.9263, acc-0.5000, valid loss-1.8683, acc-0.4992, test loss-1.8290, acc-0.5174\n",
      "Iter-89730, train loss-1.8613, acc-0.5000, valid loss-1.8683, acc-0.4990, test loss-1.8290, acc-0.5174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-89740, train loss-1.9546, acc-0.3800, valid loss-1.8683, acc-0.4990, test loss-1.8289, acc-0.5177\n",
      "Iter-89750, train loss-1.9393, acc-0.3800, valid loss-1.8682, acc-0.4994, test loss-1.8289, acc-0.5172\n",
      "Iter-89760, train loss-1.8549, acc-0.5000, valid loss-1.8682, acc-0.4992, test loss-1.8289, acc-0.5173\n",
      "Iter-89770, train loss-1.8157, acc-0.5200, valid loss-1.8682, acc-0.4994, test loss-1.8289, acc-0.5176\n",
      "Iter-89780, train loss-1.8801, acc-0.4000, valid loss-1.8682, acc-0.4996, test loss-1.8288, acc-0.5174\n",
      "Iter-89790, train loss-1.7743, acc-0.5200, valid loss-1.8681, acc-0.4996, test loss-1.8288, acc-0.5176\n",
      "Iter-89800, train loss-1.8691, acc-0.4600, valid loss-1.8681, acc-0.4996, test loss-1.8288, acc-0.5175\n",
      "Iter-89810, train loss-1.8134, acc-0.5400, valid loss-1.8681, acc-0.4996, test loss-1.8287, acc-0.5177\n",
      "Iter-89820, train loss-1.8547, acc-0.5600, valid loss-1.8680, acc-0.4996, test loss-1.8287, acc-0.5175\n",
      "Iter-89830, train loss-1.8759, acc-0.5800, valid loss-1.8680, acc-0.4996, test loss-1.8287, acc-0.5177\n",
      "Iter-89840, train loss-1.9243, acc-0.4600, valid loss-1.8680, acc-0.4996, test loss-1.8287, acc-0.5177\n",
      "Iter-89850, train loss-1.8300, acc-0.4600, valid loss-1.8680, acc-0.4996, test loss-1.8286, acc-0.5175\n",
      "Iter-89860, train loss-1.7823, acc-0.5000, valid loss-1.8679, acc-0.4996, test loss-1.8286, acc-0.5175\n",
      "Iter-89870, train loss-1.8906, acc-0.5000, valid loss-1.8679, acc-0.4994, test loss-1.8286, acc-0.5176\n",
      "Iter-89880, train loss-1.8955, acc-0.4800, valid loss-1.8679, acc-0.4996, test loss-1.8285, acc-0.5174\n",
      "Iter-89890, train loss-1.8089, acc-0.5800, valid loss-1.8678, acc-0.4996, test loss-1.8285, acc-0.5176\n",
      "Iter-89900, train loss-1.7712, acc-0.5800, valid loss-1.8678, acc-0.4996, test loss-1.8285, acc-0.5175\n",
      "Iter-89910, train loss-1.7804, acc-0.5800, valid loss-1.8678, acc-0.4996, test loss-1.8284, acc-0.5177\n",
      "Iter-89920, train loss-1.8285, acc-0.5200, valid loss-1.8678, acc-0.4996, test loss-1.8284, acc-0.5176\n",
      "Iter-89930, train loss-1.8522, acc-0.4600, valid loss-1.8677, acc-0.4996, test loss-1.8284, acc-0.5176\n",
      "Iter-89940, train loss-1.9441, acc-0.3600, valid loss-1.8677, acc-0.4996, test loss-1.8284, acc-0.5175\n",
      "Iter-89950, train loss-1.7300, acc-0.6000, valid loss-1.8677, acc-0.4996, test loss-1.8283, acc-0.5177\n",
      "Iter-89960, train loss-1.7809, acc-0.5000, valid loss-1.8677, acc-0.4996, test loss-1.8283, acc-0.5177\n",
      "Iter-89970, train loss-1.8910, acc-0.4000, valid loss-1.8676, acc-0.4996, test loss-1.8283, acc-0.5177\n",
      "Iter-89980, train loss-1.8592, acc-0.5000, valid loss-1.8676, acc-0.4994, test loss-1.8282, acc-0.5180\n",
      "Iter-89990, train loss-1.9029, acc-0.4600, valid loss-1.8676, acc-0.4994, test loss-1.8282, acc-0.5180\n",
      "Iter-90000, train loss-1.7259, acc-0.6600, valid loss-1.8676, acc-0.4992, test loss-1.8282, acc-0.5181\n",
      "Iter-90010, train loss-1.8685, acc-0.4600, valid loss-1.8675, acc-0.4994, test loss-1.8281, acc-0.5183\n",
      "Iter-90020, train loss-1.7866, acc-0.5400, valid loss-1.8675, acc-0.4994, test loss-1.8281, acc-0.5183\n",
      "Iter-90030, train loss-1.8938, acc-0.5000, valid loss-1.8675, acc-0.4994, test loss-1.8281, acc-0.5184\n",
      "Iter-90040, train loss-1.8227, acc-0.4600, valid loss-1.8674, acc-0.4994, test loss-1.8281, acc-0.5182\n",
      "Iter-90050, train loss-1.7536, acc-0.5200, valid loss-1.8674, acc-0.4994, test loss-1.8280, acc-0.5181\n",
      "Iter-90060, train loss-1.7253, acc-0.5400, valid loss-1.8674, acc-0.4994, test loss-1.8280, acc-0.5181\n",
      "Iter-90070, train loss-1.8847, acc-0.4200, valid loss-1.8674, acc-0.4994, test loss-1.8280, acc-0.5181\n",
      "Iter-90080, train loss-1.8200, acc-0.5000, valid loss-1.8673, acc-0.4994, test loss-1.8279, acc-0.5182\n",
      "Iter-90090, train loss-1.7337, acc-0.5800, valid loss-1.8673, acc-0.4992, test loss-1.8279, acc-0.5183\n",
      "Iter-90100, train loss-1.8892, acc-0.4600, valid loss-1.8673, acc-0.4994, test loss-1.8279, acc-0.5183\n",
      "Iter-90110, train loss-1.7573, acc-0.5400, valid loss-1.8673, acc-0.4994, test loss-1.8278, acc-0.5181\n",
      "Iter-90120, train loss-1.8784, acc-0.4400, valid loss-1.8672, acc-0.4996, test loss-1.8278, acc-0.5182\n",
      "Iter-90130, train loss-1.9050, acc-0.3800, valid loss-1.8672, acc-0.4994, test loss-1.8278, acc-0.5182\n",
      "Iter-90140, train loss-1.8563, acc-0.5800, valid loss-1.8672, acc-0.4992, test loss-1.8278, acc-0.5182\n",
      "Iter-90150, train loss-1.8556, acc-0.5400, valid loss-1.8672, acc-0.4994, test loss-1.8277, acc-0.5183\n",
      "Iter-90160, train loss-1.8755, acc-0.4000, valid loss-1.8671, acc-0.4996, test loss-1.8277, acc-0.5182\n",
      "Iter-90170, train loss-1.8355, acc-0.4200, valid loss-1.8671, acc-0.4992, test loss-1.8277, acc-0.5183\n",
      "Iter-90180, train loss-1.7619, acc-0.5200, valid loss-1.8671, acc-0.4992, test loss-1.8276, acc-0.5182\n",
      "Iter-90190, train loss-1.8878, acc-0.5000, valid loss-1.8670, acc-0.4994, test loss-1.8276, acc-0.5183\n",
      "Iter-90200, train loss-1.8474, acc-0.5600, valid loss-1.8670, acc-0.4996, test loss-1.8276, acc-0.5184\n",
      "Iter-90210, train loss-1.8229, acc-0.4200, valid loss-1.8670, acc-0.4998, test loss-1.8275, acc-0.5186\n",
      "Iter-90220, train loss-1.7982, acc-0.5200, valid loss-1.8670, acc-0.4994, test loss-1.8275, acc-0.5185\n",
      "Iter-90230, train loss-1.8867, acc-0.4400, valid loss-1.8669, acc-0.4994, test loss-1.8275, acc-0.5184\n",
      "Iter-90240, train loss-1.8397, acc-0.5000, valid loss-1.8669, acc-0.4996, test loss-1.8275, acc-0.5183\n",
      "Iter-90250, train loss-1.8236, acc-0.5200, valid loss-1.8669, acc-0.4996, test loss-1.8274, acc-0.5184\n",
      "Iter-90260, train loss-1.8707, acc-0.4800, valid loss-1.8669, acc-0.4996, test loss-1.8274, acc-0.5186\n",
      "Iter-90270, train loss-1.8023, acc-0.5800, valid loss-1.8668, acc-0.4998, test loss-1.8274, acc-0.5185\n",
      "Iter-90280, train loss-1.8473, acc-0.4800, valid loss-1.8668, acc-0.4998, test loss-1.8273, acc-0.5186\n",
      "Iter-90290, train loss-1.7566, acc-0.7200, valid loss-1.8668, acc-0.4998, test loss-1.8273, acc-0.5185\n",
      "Iter-90300, train loss-1.8298, acc-0.5200, valid loss-1.8667, acc-0.4994, test loss-1.8273, acc-0.5185\n",
      "Iter-90310, train loss-1.7549, acc-0.6800, valid loss-1.8667, acc-0.4996, test loss-1.8272, acc-0.5185\n",
      "Iter-90320, train loss-1.8663, acc-0.5200, valid loss-1.8667, acc-0.4996, test loss-1.8272, acc-0.5184\n",
      "Iter-90330, train loss-1.7930, acc-0.5200, valid loss-1.8667, acc-0.4994, test loss-1.8272, acc-0.5185\n",
      "Iter-90340, train loss-1.8450, acc-0.5200, valid loss-1.8666, acc-0.4996, test loss-1.8272, acc-0.5185\n",
      "Iter-90350, train loss-1.8256, acc-0.5000, valid loss-1.8666, acc-0.4994, test loss-1.8271, acc-0.5186\n",
      "Iter-90360, train loss-1.7764, acc-0.4600, valid loss-1.8666, acc-0.4996, test loss-1.8271, acc-0.5186\n",
      "Iter-90370, train loss-1.8654, acc-0.5200, valid loss-1.8666, acc-0.4996, test loss-1.8271, acc-0.5184\n",
      "Iter-90380, train loss-1.8358, acc-0.5000, valid loss-1.8665, acc-0.4994, test loss-1.8270, acc-0.5187\n",
      "Iter-90390, train loss-1.8176, acc-0.5600, valid loss-1.8665, acc-0.4996, test loss-1.8270, acc-0.5184\n",
      "Iter-90400, train loss-1.9261, acc-0.4200, valid loss-1.8665, acc-0.4996, test loss-1.8270, acc-0.5185\n",
      "Iter-90410, train loss-1.8086, acc-0.6000, valid loss-1.8664, acc-0.4994, test loss-1.8269, acc-0.5187\n",
      "Iter-90420, train loss-1.7562, acc-0.5400, valid loss-1.8664, acc-0.4996, test loss-1.8269, acc-0.5187\n",
      "Iter-90430, train loss-1.9401, acc-0.4800, valid loss-1.8664, acc-0.4996, test loss-1.8269, acc-0.5187\n",
      "Iter-90440, train loss-1.8709, acc-0.3800, valid loss-1.8664, acc-0.4996, test loss-1.8269, acc-0.5187\n",
      "Iter-90450, train loss-1.7742, acc-0.4800, valid loss-1.8663, acc-0.4996, test loss-1.8268, acc-0.5186\n",
      "Iter-90460, train loss-1.8329, acc-0.4400, valid loss-1.8663, acc-0.4996, test loss-1.8268, acc-0.5187\n",
      "Iter-90470, train loss-1.8988, acc-0.4800, valid loss-1.8663, acc-0.4996, test loss-1.8268, acc-0.5186\n",
      "Iter-90480, train loss-1.7960, acc-0.5600, valid loss-1.8662, acc-0.4996, test loss-1.8267, acc-0.5187\n",
      "Iter-90490, train loss-1.7773, acc-0.6000, valid loss-1.8662, acc-0.4996, test loss-1.8267, acc-0.5187\n",
      "Iter-90500, train loss-1.7941, acc-0.5800, valid loss-1.8662, acc-0.5000, test loss-1.8267, acc-0.5186\n",
      "Iter-90510, train loss-1.7600, acc-0.6000, valid loss-1.8662, acc-0.5002, test loss-1.8266, acc-0.5187\n",
      "Iter-90520, train loss-1.8924, acc-0.5400, valid loss-1.8661, acc-0.4996, test loss-1.8266, acc-0.5188\n",
      "Iter-90530, train loss-1.8667, acc-0.5200, valid loss-1.8661, acc-0.5002, test loss-1.8266, acc-0.5187\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-90540, train loss-1.8368, acc-0.5400, valid loss-1.8661, acc-0.5002, test loss-1.8266, acc-0.5186\n",
      "Iter-90550, train loss-1.9018, acc-0.3800, valid loss-1.8661, acc-0.5004, test loss-1.8265, acc-0.5186\n",
      "Iter-90560, train loss-1.8335, acc-0.4800, valid loss-1.8660, acc-0.5004, test loss-1.8265, acc-0.5185\n",
      "Iter-90570, train loss-1.9753, acc-0.4200, valid loss-1.8660, acc-0.5002, test loss-1.8265, acc-0.5187\n",
      "Iter-90580, train loss-1.8445, acc-0.5200, valid loss-1.8660, acc-0.5002, test loss-1.8264, acc-0.5187\n",
      "Iter-90590, train loss-1.8266, acc-0.4600, valid loss-1.8659, acc-0.5000, test loss-1.8264, acc-0.5188\n",
      "Iter-90600, train loss-1.8826, acc-0.4200, valid loss-1.8659, acc-0.5002, test loss-1.8264, acc-0.5187\n",
      "Iter-90610, train loss-1.8946, acc-0.4400, valid loss-1.8659, acc-0.5000, test loss-1.8263, acc-0.5187\n",
      "Iter-90620, train loss-1.8847, acc-0.5400, valid loss-1.8659, acc-0.5000, test loss-1.8263, acc-0.5187\n",
      "Iter-90630, train loss-1.7914, acc-0.5800, valid loss-1.8658, acc-0.5000, test loss-1.8263, acc-0.5188\n",
      "Iter-90640, train loss-1.8263, acc-0.5200, valid loss-1.8658, acc-0.5000, test loss-1.8263, acc-0.5190\n",
      "Iter-90650, train loss-1.7893, acc-0.6200, valid loss-1.8658, acc-0.5000, test loss-1.8262, acc-0.5191\n",
      "Iter-90660, train loss-1.7720, acc-0.5400, valid loss-1.8658, acc-0.5000, test loss-1.8262, acc-0.5189\n",
      "Iter-90670, train loss-1.9705, acc-0.3800, valid loss-1.8657, acc-0.4998, test loss-1.8262, acc-0.5190\n",
      "Iter-90680, train loss-1.8727, acc-0.5400, valid loss-1.8657, acc-0.4998, test loss-1.8261, acc-0.5188\n",
      "Iter-90690, train loss-1.8841, acc-0.4800, valid loss-1.8657, acc-0.4998, test loss-1.8261, acc-0.5190\n",
      "Iter-90700, train loss-1.7767, acc-0.5400, valid loss-1.8656, acc-0.5000, test loss-1.8261, acc-0.5188\n",
      "Iter-90710, train loss-1.9030, acc-0.4800, valid loss-1.8656, acc-0.5002, test loss-1.8260, acc-0.5189\n",
      "Iter-90720, train loss-1.8566, acc-0.5600, valid loss-1.8656, acc-0.5002, test loss-1.8260, acc-0.5187\n",
      "Iter-90730, train loss-1.8231, acc-0.5200, valid loss-1.8656, acc-0.5002, test loss-1.8260, acc-0.5188\n",
      "Iter-90740, train loss-1.7869, acc-0.6000, valid loss-1.8655, acc-0.5002, test loss-1.8260, acc-0.5189\n",
      "Iter-90750, train loss-1.8420, acc-0.5200, valid loss-1.8655, acc-0.5002, test loss-1.8259, acc-0.5189\n",
      "Iter-90760, train loss-1.9504, acc-0.4000, valid loss-1.8655, acc-0.5002, test loss-1.8259, acc-0.5189\n",
      "Iter-90770, train loss-1.8370, acc-0.5200, valid loss-1.8655, acc-0.5002, test loss-1.8259, acc-0.5193\n",
      "Iter-90780, train loss-1.7966, acc-0.5000, valid loss-1.8654, acc-0.5004, test loss-1.8258, acc-0.5190\n",
      "Iter-90790, train loss-2.0042, acc-0.4600, valid loss-1.8654, acc-0.5004, test loss-1.8258, acc-0.5192\n",
      "Iter-90800, train loss-1.8248, acc-0.4600, valid loss-1.8654, acc-0.5006, test loss-1.8258, acc-0.5192\n",
      "Iter-90810, train loss-1.8534, acc-0.5000, valid loss-1.8653, acc-0.5002, test loss-1.8257, acc-0.5192\n",
      "Iter-90820, train loss-1.8778, acc-0.4800, valid loss-1.8653, acc-0.5002, test loss-1.8257, acc-0.5192\n",
      "Iter-90830, train loss-1.7476, acc-0.6000, valid loss-1.8653, acc-0.5004, test loss-1.8257, acc-0.5193\n",
      "Iter-90840, train loss-1.7221, acc-0.6000, valid loss-1.8653, acc-0.5002, test loss-1.8257, acc-0.5193\n",
      "Iter-90850, train loss-1.8103, acc-0.5600, valid loss-1.8652, acc-0.5002, test loss-1.8256, acc-0.5192\n",
      "Iter-90860, train loss-1.8755, acc-0.4600, valid loss-1.8652, acc-0.5002, test loss-1.8256, acc-0.5194\n",
      "Iter-90870, train loss-1.8618, acc-0.5400, valid loss-1.8652, acc-0.5002, test loss-1.8256, acc-0.5194\n",
      "Iter-90880, train loss-1.8624, acc-0.4800, valid loss-1.8651, acc-0.5004, test loss-1.8255, acc-0.5194\n",
      "Iter-90890, train loss-1.9036, acc-0.4200, valid loss-1.8651, acc-0.5006, test loss-1.8255, acc-0.5192\n",
      "Iter-90900, train loss-1.9349, acc-0.4400, valid loss-1.8651, acc-0.5006, test loss-1.8255, acc-0.5192\n",
      "Iter-90910, train loss-1.8029, acc-0.6000, valid loss-1.8651, acc-0.5006, test loss-1.8254, acc-0.5190\n",
      "Iter-90920, train loss-1.9020, acc-0.5000, valid loss-1.8650, acc-0.5004, test loss-1.8254, acc-0.5193\n",
      "Iter-90930, train loss-1.7909, acc-0.4800, valid loss-1.8650, acc-0.5004, test loss-1.8254, acc-0.5191\n",
      "Iter-90940, train loss-1.8272, acc-0.5200, valid loss-1.8650, acc-0.5002, test loss-1.8254, acc-0.5192\n",
      "Iter-90950, train loss-1.7804, acc-0.6800, valid loss-1.8649, acc-0.5002, test loss-1.8253, acc-0.5192\n",
      "Iter-90960, train loss-1.8652, acc-0.5200, valid loss-1.8649, acc-0.5002, test loss-1.8253, acc-0.5191\n",
      "Iter-90970, train loss-1.9172, acc-0.4400, valid loss-1.8649, acc-0.5002, test loss-1.8253, acc-0.5193\n",
      "Iter-90980, train loss-1.7940, acc-0.5800, valid loss-1.8649, acc-0.5002, test loss-1.8252, acc-0.5193\n",
      "Iter-90990, train loss-1.9849, acc-0.4000, valid loss-1.8648, acc-0.5002, test loss-1.8252, acc-0.5194\n",
      "Iter-91000, train loss-1.7512, acc-0.6200, valid loss-1.8648, acc-0.5002, test loss-1.8252, acc-0.5193\n",
      "Iter-91010, train loss-1.8199, acc-0.5000, valid loss-1.8648, acc-0.5004, test loss-1.8251, acc-0.5194\n",
      "Iter-91020, train loss-1.8419, acc-0.4400, valid loss-1.8648, acc-0.5002, test loss-1.8251, acc-0.5195\n",
      "Iter-91030, train loss-1.7343, acc-0.6400, valid loss-1.8647, acc-0.5000, test loss-1.8251, acc-0.5196\n",
      "Iter-91040, train loss-1.7747, acc-0.4600, valid loss-1.8647, acc-0.5000, test loss-1.8251, acc-0.5195\n",
      "Iter-91050, train loss-1.8912, acc-0.4600, valid loss-1.8647, acc-0.5000, test loss-1.8250, acc-0.5196\n",
      "Iter-91060, train loss-1.8490, acc-0.4800, valid loss-1.8647, acc-0.5000, test loss-1.8250, acc-0.5197\n",
      "Iter-91070, train loss-1.8156, acc-0.5200, valid loss-1.8646, acc-0.5000, test loss-1.8250, acc-0.5198\n",
      "Iter-91080, train loss-1.7972, acc-0.6600, valid loss-1.8646, acc-0.5000, test loss-1.8249, acc-0.5198\n",
      "Iter-91090, train loss-1.8962, acc-0.5000, valid loss-1.8646, acc-0.5000, test loss-1.8249, acc-0.5199\n",
      "Iter-91100, train loss-1.9360, acc-0.4000, valid loss-1.8645, acc-0.5000, test loss-1.8249, acc-0.5199\n",
      "Iter-91110, train loss-1.8894, acc-0.4400, valid loss-1.8645, acc-0.5000, test loss-1.8249, acc-0.5200\n",
      "Iter-91120, train loss-1.8609, acc-0.5600, valid loss-1.8645, acc-0.4998, test loss-1.8248, acc-0.5202\n",
      "Iter-91130, train loss-1.7884, acc-0.5600, valid loss-1.8645, acc-0.4998, test loss-1.8248, acc-0.5201\n",
      "Iter-91140, train loss-1.8316, acc-0.5200, valid loss-1.8644, acc-0.5000, test loss-1.8248, acc-0.5200\n",
      "Iter-91150, train loss-1.8559, acc-0.5400, valid loss-1.8644, acc-0.5000, test loss-1.8247, acc-0.5200\n",
      "Iter-91160, train loss-1.7793, acc-0.6400, valid loss-1.8644, acc-0.4998, test loss-1.8247, acc-0.5201\n",
      "Iter-91170, train loss-1.7912, acc-0.5600, valid loss-1.8644, acc-0.4998, test loss-1.8247, acc-0.5199\n",
      "Iter-91180, train loss-1.8389, acc-0.4400, valid loss-1.8643, acc-0.4998, test loss-1.8246, acc-0.5199\n",
      "Iter-91190, train loss-1.8666, acc-0.4200, valid loss-1.8643, acc-0.4998, test loss-1.8246, acc-0.5200\n",
      "Iter-91200, train loss-1.8129, acc-0.5400, valid loss-1.8643, acc-0.4998, test loss-1.8246, acc-0.5201\n",
      "Iter-91210, train loss-1.8199, acc-0.5200, valid loss-1.8643, acc-0.4998, test loss-1.8246, acc-0.5199\n",
      "Iter-91220, train loss-1.8852, acc-0.4600, valid loss-1.8642, acc-0.4998, test loss-1.8245, acc-0.5201\n",
      "Iter-91230, train loss-1.8107, acc-0.5800, valid loss-1.8642, acc-0.4996, test loss-1.8245, acc-0.5202\n",
      "Iter-91240, train loss-1.9087, acc-0.4800, valid loss-1.8642, acc-0.4996, test loss-1.8245, acc-0.5200\n",
      "Iter-91250, train loss-1.8763, acc-0.4600, valid loss-1.8642, acc-0.5000, test loss-1.8244, acc-0.5201\n",
      "Iter-91260, train loss-1.7625, acc-0.6600, valid loss-1.8641, acc-0.5000, test loss-1.8244, acc-0.5199\n",
      "Iter-91270, train loss-1.8992, acc-0.3800, valid loss-1.8641, acc-0.4998, test loss-1.8244, acc-0.5202\n",
      "Iter-91280, train loss-1.8623, acc-0.5000, valid loss-1.8641, acc-0.5002, test loss-1.8244, acc-0.5201\n",
      "Iter-91290, train loss-1.8848, acc-0.4000, valid loss-1.8641, acc-0.5000, test loss-1.8243, acc-0.5202\n",
      "Iter-91300, train loss-1.7889, acc-0.5400, valid loss-1.8640, acc-0.4998, test loss-1.8243, acc-0.5200\n",
      "Iter-91310, train loss-1.8712, acc-0.4600, valid loss-1.8640, acc-0.4998, test loss-1.8243, acc-0.5200\n",
      "Iter-91320, train loss-1.7817, acc-0.5400, valid loss-1.8640, acc-0.4998, test loss-1.8242, acc-0.5202\n",
      "Iter-91330, train loss-1.8551, acc-0.5200, valid loss-1.8640, acc-0.5002, test loss-1.8242, acc-0.5200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-91340, train loss-1.8728, acc-0.4400, valid loss-1.8639, acc-0.5002, test loss-1.8242, acc-0.5202\n",
      "Iter-91350, train loss-1.8676, acc-0.4400, valid loss-1.8639, acc-0.5002, test loss-1.8241, acc-0.5203\n",
      "Iter-91360, train loss-1.7695, acc-0.4800, valid loss-1.8639, acc-0.5000, test loss-1.8241, acc-0.5201\n",
      "Iter-91370, train loss-1.8528, acc-0.4000, valid loss-1.8638, acc-0.5000, test loss-1.8241, acc-0.5202\n",
      "Iter-91380, train loss-1.8904, acc-0.3800, valid loss-1.8638, acc-0.5000, test loss-1.8241, acc-0.5200\n",
      "Iter-91390, train loss-1.8836, acc-0.4800, valid loss-1.8638, acc-0.5000, test loss-1.8240, acc-0.5201\n",
      "Iter-91400, train loss-1.9484, acc-0.4000, valid loss-1.8638, acc-0.5000, test loss-1.8240, acc-0.5200\n",
      "Iter-91410, train loss-1.9060, acc-0.4000, valid loss-1.8637, acc-0.5000, test loss-1.8240, acc-0.5201\n",
      "Iter-91420, train loss-1.7507, acc-0.6400, valid loss-1.8637, acc-0.5002, test loss-1.8239, acc-0.5201\n",
      "Iter-91430, train loss-1.8400, acc-0.5400, valid loss-1.8637, acc-0.5000, test loss-1.8239, acc-0.5201\n",
      "Iter-91440, train loss-1.9217, acc-0.5000, valid loss-1.8636, acc-0.5000, test loss-1.8239, acc-0.5200\n",
      "Iter-91450, train loss-1.7822, acc-0.5600, valid loss-1.8636, acc-0.5002, test loss-1.8239, acc-0.5202\n",
      "Iter-91460, train loss-1.8518, acc-0.4800, valid loss-1.8636, acc-0.5002, test loss-1.8238, acc-0.5203\n",
      "Iter-91470, train loss-1.7767, acc-0.5200, valid loss-1.8636, acc-0.5000, test loss-1.8238, acc-0.5203\n",
      "Iter-91480, train loss-1.8328, acc-0.5400, valid loss-1.8635, acc-0.5000, test loss-1.8238, acc-0.5203\n",
      "Iter-91490, train loss-1.9289, acc-0.4200, valid loss-1.8635, acc-0.5000, test loss-1.8237, acc-0.5203\n",
      "Iter-91500, train loss-1.9678, acc-0.3400, valid loss-1.8635, acc-0.5002, test loss-1.8237, acc-0.5204\n",
      "Iter-91510, train loss-1.8876, acc-0.5000, valid loss-1.8635, acc-0.5000, test loss-1.8237, acc-0.5202\n",
      "Iter-91520, train loss-1.8769, acc-0.5400, valid loss-1.8634, acc-0.5000, test loss-1.8237, acc-0.5202\n",
      "Iter-91530, train loss-1.7852, acc-0.4600, valid loss-1.8634, acc-0.5000, test loss-1.8236, acc-0.5203\n",
      "Iter-91540, train loss-1.8760, acc-0.4600, valid loss-1.8634, acc-0.5002, test loss-1.8236, acc-0.5204\n",
      "Iter-91550, train loss-1.8426, acc-0.5600, valid loss-1.8634, acc-0.5002, test loss-1.8236, acc-0.5204\n",
      "Iter-91560, train loss-1.7690, acc-0.6000, valid loss-1.8633, acc-0.5002, test loss-1.8235, acc-0.5202\n",
      "Iter-91570, train loss-1.8347, acc-0.5000, valid loss-1.8633, acc-0.5002, test loss-1.8235, acc-0.5201\n",
      "Iter-91580, train loss-1.9127, acc-0.4600, valid loss-1.8633, acc-0.5000, test loss-1.8235, acc-0.5201\n",
      "Iter-91590, train loss-1.9358, acc-0.3800, valid loss-1.8633, acc-0.5002, test loss-1.8235, acc-0.5202\n",
      "Iter-91600, train loss-1.9029, acc-0.5600, valid loss-1.8632, acc-0.5000, test loss-1.8234, acc-0.5203\n",
      "Iter-91610, train loss-1.8096, acc-0.5200, valid loss-1.8632, acc-0.5000, test loss-1.8234, acc-0.5204\n",
      "Iter-91620, train loss-1.8932, acc-0.5200, valid loss-1.8632, acc-0.5000, test loss-1.8234, acc-0.5201\n",
      "Iter-91630, train loss-1.9405, acc-0.4600, valid loss-1.8632, acc-0.5000, test loss-1.8233, acc-0.5203\n",
      "Iter-91640, train loss-1.8776, acc-0.4800, valid loss-1.8631, acc-0.5000, test loss-1.8233, acc-0.5203\n",
      "Iter-91650, train loss-1.7503, acc-0.5400, valid loss-1.8631, acc-0.5000, test loss-1.8233, acc-0.5202\n",
      "Iter-91660, train loss-1.7871, acc-0.5200, valid loss-1.8631, acc-0.5000, test loss-1.8232, acc-0.5201\n",
      "Iter-91670, train loss-1.7672, acc-0.5800, valid loss-1.8630, acc-0.5000, test loss-1.8232, acc-0.5202\n",
      "Iter-91680, train loss-1.8925, acc-0.5000, valid loss-1.8630, acc-0.5000, test loss-1.8232, acc-0.5201\n",
      "Iter-91690, train loss-1.8466, acc-0.5000, valid loss-1.8630, acc-0.5000, test loss-1.8232, acc-0.5200\n",
      "Iter-91700, train loss-1.8009, acc-0.5200, valid loss-1.8630, acc-0.5000, test loss-1.8231, acc-0.5199\n",
      "Iter-91710, train loss-1.8617, acc-0.5800, valid loss-1.8629, acc-0.5000, test loss-1.8231, acc-0.5198\n",
      "Iter-91720, train loss-1.8281, acc-0.4800, valid loss-1.8629, acc-0.5000, test loss-1.8231, acc-0.5201\n",
      "Iter-91730, train loss-1.8615, acc-0.5000, valid loss-1.8629, acc-0.5000, test loss-1.8230, acc-0.5198\n",
      "Iter-91740, train loss-1.8313, acc-0.4400, valid loss-1.8629, acc-0.5000, test loss-1.8230, acc-0.5199\n",
      "Iter-91750, train loss-1.9022, acc-0.4200, valid loss-1.8628, acc-0.5000, test loss-1.8230, acc-0.5198\n",
      "Iter-91760, train loss-1.7605, acc-0.6200, valid loss-1.8628, acc-0.5000, test loss-1.8229, acc-0.5201\n",
      "Iter-91770, train loss-1.8867, acc-0.4800, valid loss-1.8628, acc-0.4998, test loss-1.8229, acc-0.5203\n",
      "Iter-91780, train loss-1.9610, acc-0.4200, valid loss-1.8628, acc-0.4998, test loss-1.8229, acc-0.5201\n",
      "Iter-91790, train loss-1.7844, acc-0.6200, valid loss-1.8627, acc-0.4996, test loss-1.8229, acc-0.5203\n",
      "Iter-91800, train loss-1.8325, acc-0.5600, valid loss-1.8627, acc-0.4998, test loss-1.8228, acc-0.5203\n",
      "Iter-91810, train loss-1.8699, acc-0.4600, valid loss-1.8627, acc-0.4998, test loss-1.8228, acc-0.5202\n",
      "Iter-91820, train loss-1.8454, acc-0.5600, valid loss-1.8626, acc-0.4998, test loss-1.8228, acc-0.5201\n",
      "Iter-91830, train loss-1.8755, acc-0.4800, valid loss-1.8626, acc-0.5000, test loss-1.8227, acc-0.5201\n",
      "Iter-91840, train loss-1.8904, acc-0.5000, valid loss-1.8626, acc-0.5002, test loss-1.8227, acc-0.5202\n",
      "Iter-91850, train loss-1.7932, acc-0.4800, valid loss-1.8626, acc-0.5000, test loss-1.8227, acc-0.5202\n",
      "Iter-91860, train loss-1.8444, acc-0.5200, valid loss-1.8625, acc-0.5000, test loss-1.8227, acc-0.5201\n",
      "Iter-91870, train loss-1.7838, acc-0.5200, valid loss-1.8625, acc-0.5000, test loss-1.8226, acc-0.5200\n",
      "Iter-91880, train loss-1.8254, acc-0.5600, valid loss-1.8625, acc-0.5000, test loss-1.8226, acc-0.5202\n",
      "Iter-91890, train loss-1.7984, acc-0.4400, valid loss-1.8625, acc-0.5000, test loss-1.8226, acc-0.5202\n",
      "Iter-91900, train loss-1.7485, acc-0.6200, valid loss-1.8624, acc-0.5000, test loss-1.8225, acc-0.5201\n",
      "Iter-91910, train loss-1.9641, acc-0.3600, valid loss-1.8624, acc-0.5000, test loss-1.8225, acc-0.5202\n",
      "Iter-91920, train loss-1.8911, acc-0.4200, valid loss-1.8624, acc-0.5000, test loss-1.8225, acc-0.5202\n",
      "Iter-91930, train loss-1.8679, acc-0.4600, valid loss-1.8623, acc-0.5000, test loss-1.8224, acc-0.5202\n",
      "Iter-91940, train loss-1.9024, acc-0.4800, valid loss-1.8623, acc-0.5000, test loss-1.8224, acc-0.5202\n",
      "Iter-91950, train loss-1.8995, acc-0.4200, valid loss-1.8623, acc-0.5000, test loss-1.8224, acc-0.5203\n",
      "Iter-91960, train loss-1.9118, acc-0.4400, valid loss-1.8623, acc-0.5004, test loss-1.8224, acc-0.5203\n",
      "Iter-91970, train loss-1.9269, acc-0.4800, valid loss-1.8622, acc-0.5006, test loss-1.8223, acc-0.5204\n",
      "Iter-91980, train loss-1.8911, acc-0.4400, valid loss-1.8622, acc-0.5006, test loss-1.8223, acc-0.5203\n",
      "Iter-91990, train loss-1.7582, acc-0.5800, valid loss-1.8622, acc-0.5006, test loss-1.8223, acc-0.5203\n",
      "Iter-92000, train loss-1.8386, acc-0.4600, valid loss-1.8622, acc-0.5006, test loss-1.8222, acc-0.5204\n",
      "Iter-92010, train loss-1.7104, acc-0.6800, valid loss-1.8621, acc-0.5006, test loss-1.8222, acc-0.5203\n",
      "Iter-92020, train loss-1.8685, acc-0.4400, valid loss-1.8621, acc-0.5004, test loss-1.8222, acc-0.5203\n",
      "Iter-92030, train loss-1.8420, acc-0.4200, valid loss-1.8621, acc-0.5004, test loss-1.8221, acc-0.5204\n",
      "Iter-92040, train loss-1.9268, acc-0.4400, valid loss-1.8620, acc-0.5004, test loss-1.8221, acc-0.5204\n",
      "Iter-92050, train loss-1.7328, acc-0.6200, valid loss-1.8620, acc-0.5004, test loss-1.8221, acc-0.5204\n",
      "Iter-92060, train loss-1.7736, acc-0.5200, valid loss-1.8620, acc-0.5002, test loss-1.8221, acc-0.5203\n",
      "Iter-92070, train loss-1.8467, acc-0.4400, valid loss-1.8620, acc-0.5000, test loss-1.8220, acc-0.5202\n",
      "Iter-92080, train loss-1.9622, acc-0.4200, valid loss-1.8619, acc-0.5000, test loss-1.8220, acc-0.5203\n",
      "Iter-92090, train loss-1.8640, acc-0.5000, valid loss-1.8619, acc-0.5000, test loss-1.8220, acc-0.5203\n",
      "Iter-92100, train loss-1.8822, acc-0.5600, valid loss-1.8619, acc-0.5002, test loss-1.8219, acc-0.5203\n",
      "Iter-92110, train loss-1.7826, acc-0.5200, valid loss-1.8619, acc-0.5002, test loss-1.8219, acc-0.5201\n",
      "Iter-92120, train loss-1.8614, acc-0.5200, valid loss-1.8618, acc-0.5006, test loss-1.8219, acc-0.5203\n",
      "Iter-92130, train loss-1.8084, acc-0.6000, valid loss-1.8618, acc-0.5004, test loss-1.8219, acc-0.5203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-92140, train loss-1.9045, acc-0.4200, valid loss-1.8618, acc-0.5006, test loss-1.8218, acc-0.5204\n",
      "Iter-92150, train loss-1.8125, acc-0.5000, valid loss-1.8618, acc-0.5004, test loss-1.8218, acc-0.5204\n",
      "Iter-92160, train loss-1.9127, acc-0.4800, valid loss-1.8617, acc-0.5004, test loss-1.8218, acc-0.5204\n",
      "Iter-92170, train loss-1.9210, acc-0.3800, valid loss-1.8617, acc-0.5004, test loss-1.8217, acc-0.5204\n",
      "Iter-92180, train loss-1.8703, acc-0.4200, valid loss-1.8617, acc-0.5002, test loss-1.8217, acc-0.5203\n",
      "Iter-92190, train loss-1.7896, acc-0.5400, valid loss-1.8617, acc-0.5002, test loss-1.8217, acc-0.5205\n",
      "Iter-92200, train loss-1.8412, acc-0.4600, valid loss-1.8616, acc-0.5004, test loss-1.8217, acc-0.5204\n",
      "Iter-92210, train loss-1.7859, acc-0.5200, valid loss-1.8616, acc-0.5004, test loss-1.8216, acc-0.5204\n",
      "Iter-92220, train loss-1.8899, acc-0.4400, valid loss-1.8616, acc-0.5004, test loss-1.8216, acc-0.5204\n",
      "Iter-92230, train loss-1.8139, acc-0.4800, valid loss-1.8615, acc-0.5004, test loss-1.8216, acc-0.5204\n",
      "Iter-92240, train loss-1.8095, acc-0.4800, valid loss-1.8615, acc-0.5004, test loss-1.8215, acc-0.5205\n",
      "Iter-92250, train loss-1.7411, acc-0.6200, valid loss-1.8615, acc-0.5004, test loss-1.8215, acc-0.5203\n",
      "Iter-92260, train loss-1.8365, acc-0.5400, valid loss-1.8615, acc-0.5006, test loss-1.8215, acc-0.5206\n",
      "Iter-92270, train loss-1.9472, acc-0.3000, valid loss-1.8614, acc-0.5006, test loss-1.8214, acc-0.5206\n",
      "Iter-92280, train loss-1.8984, acc-0.5200, valid loss-1.8614, acc-0.5006, test loss-1.8214, acc-0.5205\n",
      "Iter-92290, train loss-1.9394, acc-0.3200, valid loss-1.8614, acc-0.5006, test loss-1.8214, acc-0.5207\n",
      "Iter-92300, train loss-1.8751, acc-0.5400, valid loss-1.8614, acc-0.5006, test loss-1.8214, acc-0.5207\n",
      "Iter-92310, train loss-1.8934, acc-0.4600, valid loss-1.8613, acc-0.5006, test loss-1.8213, acc-0.5208\n",
      "Iter-92320, train loss-1.8144, acc-0.6000, valid loss-1.8613, acc-0.5006, test loss-1.8213, acc-0.5207\n",
      "Iter-92330, train loss-1.9296, acc-0.4400, valid loss-1.8613, acc-0.5006, test loss-1.8213, acc-0.5207\n",
      "Iter-92340, train loss-1.8718, acc-0.4200, valid loss-1.8613, acc-0.5004, test loss-1.8213, acc-0.5203\n",
      "Iter-92350, train loss-1.7317, acc-0.5600, valid loss-1.8612, acc-0.5004, test loss-1.8212, acc-0.5203\n",
      "Iter-92360, train loss-1.7798, acc-0.6600, valid loss-1.8612, acc-0.5004, test loss-1.8212, acc-0.5204\n",
      "Iter-92370, train loss-1.8422, acc-0.5200, valid loss-1.8612, acc-0.5006, test loss-1.8212, acc-0.5205\n",
      "Iter-92380, train loss-1.9184, acc-0.4600, valid loss-1.8612, acc-0.5006, test loss-1.8211, acc-0.5203\n",
      "Iter-92390, train loss-1.9118, acc-0.4000, valid loss-1.8611, acc-0.5006, test loss-1.8211, acc-0.5203\n",
      "Iter-92400, train loss-1.9254, acc-0.4400, valid loss-1.8611, acc-0.5006, test loss-1.8211, acc-0.5203\n",
      "Iter-92410, train loss-1.8649, acc-0.4600, valid loss-1.8611, acc-0.5004, test loss-1.8210, acc-0.5204\n",
      "Iter-92420, train loss-1.8383, acc-0.5600, valid loss-1.8610, acc-0.5008, test loss-1.8210, acc-0.5201\n",
      "Iter-92430, train loss-1.8526, acc-0.6000, valid loss-1.8610, acc-0.5004, test loss-1.8210, acc-0.5203\n",
      "Iter-92440, train loss-1.8039, acc-0.6000, valid loss-1.8610, acc-0.5004, test loss-1.8210, acc-0.5202\n",
      "Iter-92450, train loss-1.7660, acc-0.5800, valid loss-1.8610, acc-0.5006, test loss-1.8209, acc-0.5202\n",
      "Iter-92460, train loss-1.8755, acc-0.4400, valid loss-1.8609, acc-0.5004, test loss-1.8209, acc-0.5203\n",
      "Iter-92470, train loss-1.8570, acc-0.5000, valid loss-1.8609, acc-0.5006, test loss-1.8209, acc-0.5203\n",
      "Iter-92480, train loss-1.8091, acc-0.6000, valid loss-1.8609, acc-0.5004, test loss-1.8208, acc-0.5203\n",
      "Iter-92490, train loss-1.9511, acc-0.4400, valid loss-1.8609, acc-0.5004, test loss-1.8208, acc-0.5205\n",
      "Iter-92500, train loss-1.8549, acc-0.5400, valid loss-1.8608, acc-0.5004, test loss-1.8208, acc-0.5205\n",
      "Iter-92510, train loss-1.8041, acc-0.5600, valid loss-1.8608, acc-0.5002, test loss-1.8208, acc-0.5205\n",
      "Iter-92520, train loss-1.7810, acc-0.5600, valid loss-1.8608, acc-0.5002, test loss-1.8207, acc-0.5206\n",
      "Iter-92530, train loss-1.7518, acc-0.6000, valid loss-1.8608, acc-0.5004, test loss-1.8207, acc-0.5208\n",
      "Iter-92540, train loss-1.8472, acc-0.4600, valid loss-1.8607, acc-0.5000, test loss-1.8207, acc-0.5207\n",
      "Iter-92550, train loss-1.8303, acc-0.5200, valid loss-1.8607, acc-0.5000, test loss-1.8206, acc-0.5207\n",
      "Iter-92560, train loss-1.7843, acc-0.6800, valid loss-1.8607, acc-0.5000, test loss-1.8206, acc-0.5206\n",
      "Iter-92570, train loss-1.8772, acc-0.4400, valid loss-1.8607, acc-0.4998, test loss-1.8206, acc-0.5207\n",
      "Iter-92580, train loss-1.8134, acc-0.5000, valid loss-1.8606, acc-0.4998, test loss-1.8206, acc-0.5205\n",
      "Iter-92590, train loss-1.8607, acc-0.4800, valid loss-1.8606, acc-0.4998, test loss-1.8205, acc-0.5205\n",
      "Iter-92600, train loss-1.7644, acc-0.4800, valid loss-1.8606, acc-0.4998, test loss-1.8205, acc-0.5204\n",
      "Iter-92610, train loss-1.7986, acc-0.4800, valid loss-1.8605, acc-0.5002, test loss-1.8205, acc-0.5205\n",
      "Iter-92620, train loss-1.7659, acc-0.5600, valid loss-1.8605, acc-0.4998, test loss-1.8204, acc-0.5204\n",
      "Iter-92630, train loss-1.8198, acc-0.5200, valid loss-1.8605, acc-0.5002, test loss-1.8204, acc-0.5205\n",
      "Iter-92640, train loss-1.8477, acc-0.4800, valid loss-1.8605, acc-0.5002, test loss-1.8204, acc-0.5206\n",
      "Iter-92650, train loss-1.9801, acc-0.4400, valid loss-1.8604, acc-0.5002, test loss-1.8204, acc-0.5205\n",
      "Iter-92660, train loss-1.8738, acc-0.5000, valid loss-1.8604, acc-0.5004, test loss-1.8203, acc-0.5206\n",
      "Iter-92670, train loss-1.8100, acc-0.5200, valid loss-1.8604, acc-0.5002, test loss-1.8203, acc-0.5206\n",
      "Iter-92680, train loss-1.9517, acc-0.4400, valid loss-1.8604, acc-0.5004, test loss-1.8203, acc-0.5207\n",
      "Iter-92690, train loss-1.7645, acc-0.5200, valid loss-1.8603, acc-0.5004, test loss-1.8202, acc-0.5206\n",
      "Iter-92700, train loss-1.9209, acc-0.4000, valid loss-1.8603, acc-0.5004, test loss-1.8202, acc-0.5207\n",
      "Iter-92710, train loss-1.7506, acc-0.5200, valid loss-1.8603, acc-0.5004, test loss-1.8202, acc-0.5206\n",
      "Iter-92720, train loss-1.8411, acc-0.5600, valid loss-1.8603, acc-0.5006, test loss-1.8202, acc-0.5206\n",
      "Iter-92730, train loss-1.8694, acc-0.4400, valid loss-1.8602, acc-0.5006, test loss-1.8201, acc-0.5207\n",
      "Iter-92740, train loss-1.7464, acc-0.5400, valid loss-1.8602, acc-0.5006, test loss-1.8201, acc-0.5207\n",
      "Iter-92750, train loss-1.8031, acc-0.5400, valid loss-1.8602, acc-0.5006, test loss-1.8201, acc-0.5208\n",
      "Iter-92760, train loss-1.8247, acc-0.5000, valid loss-1.8602, acc-0.5008, test loss-1.8200, acc-0.5210\n",
      "Iter-92770, train loss-1.8963, acc-0.5000, valid loss-1.8601, acc-0.5004, test loss-1.8200, acc-0.5209\n",
      "Iter-92780, train loss-1.9474, acc-0.4400, valid loss-1.8601, acc-0.5006, test loss-1.8200, acc-0.5207\n",
      "Iter-92790, train loss-1.7106, acc-0.5200, valid loss-1.8601, acc-0.5004, test loss-1.8200, acc-0.5208\n",
      "Iter-92800, train loss-1.8915, acc-0.4800, valid loss-1.8601, acc-0.5004, test loss-1.8199, acc-0.5209\n",
      "Iter-92810, train loss-1.7964, acc-0.5000, valid loss-1.8600, acc-0.5006, test loss-1.8199, acc-0.5208\n",
      "Iter-92820, train loss-2.0037, acc-0.4200, valid loss-1.8600, acc-0.5006, test loss-1.8199, acc-0.5209\n",
      "Iter-92830, train loss-1.8436, acc-0.4000, valid loss-1.8600, acc-0.5004, test loss-1.8198, acc-0.5209\n",
      "Iter-92840, train loss-1.7902, acc-0.5200, valid loss-1.8600, acc-0.5002, test loss-1.8198, acc-0.5209\n",
      "Iter-92850, train loss-1.7958, acc-0.5200, valid loss-1.8599, acc-0.5004, test loss-1.8198, acc-0.5209\n",
      "Iter-92860, train loss-1.7664, acc-0.5800, valid loss-1.8599, acc-0.5002, test loss-1.8198, acc-0.5210\n",
      "Iter-92870, train loss-1.8286, acc-0.6000, valid loss-1.8599, acc-0.5004, test loss-1.8197, acc-0.5210\n",
      "Iter-92880, train loss-1.9329, acc-0.4200, valid loss-1.8598, acc-0.5002, test loss-1.8197, acc-0.5211\n",
      "Iter-92890, train loss-1.8958, acc-0.4800, valid loss-1.8598, acc-0.5004, test loss-1.8197, acc-0.5210\n",
      "Iter-92900, train loss-1.8519, acc-0.4800, valid loss-1.8598, acc-0.5002, test loss-1.8196, acc-0.5211\n",
      "Iter-92910, train loss-1.8645, acc-0.4800, valid loss-1.8598, acc-0.5002, test loss-1.8196, acc-0.5211\n",
      "Iter-92920, train loss-1.9118, acc-0.5000, valid loss-1.8597, acc-0.5002, test loss-1.8196, acc-0.5211\n",
      "Iter-92930, train loss-1.7467, acc-0.5400, valid loss-1.8597, acc-0.5004, test loss-1.8196, acc-0.5212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-92940, train loss-1.8206, acc-0.5600, valid loss-1.8597, acc-0.5004, test loss-1.8195, acc-0.5213\n",
      "Iter-92950, train loss-1.9276, acc-0.4200, valid loss-1.8597, acc-0.5004, test loss-1.8195, acc-0.5213\n",
      "Iter-92960, train loss-1.8163, acc-0.5800, valid loss-1.8596, acc-0.5004, test loss-1.8195, acc-0.5214\n",
      "Iter-92970, train loss-1.7403, acc-0.5000, valid loss-1.8596, acc-0.5004, test loss-1.8194, acc-0.5214\n",
      "Iter-92980, train loss-2.0204, acc-0.4200, valid loss-1.8596, acc-0.5000, test loss-1.8194, acc-0.5213\n",
      "Iter-92990, train loss-1.7395, acc-0.6000, valid loss-1.8596, acc-0.5002, test loss-1.8194, acc-0.5212\n",
      "Iter-93000, train loss-1.8311, acc-0.5200, valid loss-1.8595, acc-0.5002, test loss-1.8194, acc-0.5213\n",
      "Iter-93010, train loss-1.9159, acc-0.3600, valid loss-1.8595, acc-0.5002, test loss-1.8193, acc-0.5213\n",
      "Iter-93020, train loss-1.8834, acc-0.5600, valid loss-1.8595, acc-0.5002, test loss-1.8193, acc-0.5214\n",
      "Iter-93030, train loss-1.7789, acc-0.5800, valid loss-1.8594, acc-0.5002, test loss-1.8193, acc-0.5215\n",
      "Iter-93040, train loss-1.7854, acc-0.6200, valid loss-1.8594, acc-0.5002, test loss-1.8192, acc-0.5212\n",
      "Iter-93050, train loss-1.7547, acc-0.4800, valid loss-1.8594, acc-0.5002, test loss-1.8192, acc-0.5214\n",
      "Iter-93060, train loss-1.8837, acc-0.4000, valid loss-1.8594, acc-0.5002, test loss-1.8192, acc-0.5213\n",
      "Iter-93070, train loss-1.7766, acc-0.5600, valid loss-1.8593, acc-0.5002, test loss-1.8192, acc-0.5212\n",
      "Iter-93080, train loss-1.8965, acc-0.5600, valid loss-1.8593, acc-0.5004, test loss-1.8191, acc-0.5211\n",
      "Iter-93090, train loss-1.9541, acc-0.4400, valid loss-1.8593, acc-0.5004, test loss-1.8191, acc-0.5211\n",
      "Iter-93100, train loss-1.9804, acc-0.3800, valid loss-1.8593, acc-0.5004, test loss-1.8191, acc-0.5209\n",
      "Iter-93110, train loss-1.8889, acc-0.4200, valid loss-1.8592, acc-0.5004, test loss-1.8190, acc-0.5210\n",
      "Iter-93120, train loss-1.8065, acc-0.4400, valid loss-1.8592, acc-0.5002, test loss-1.8190, acc-0.5210\n",
      "Iter-93130, train loss-1.8398, acc-0.5400, valid loss-1.8592, acc-0.5004, test loss-1.8190, acc-0.5214\n",
      "Iter-93140, train loss-1.8144, acc-0.5000, valid loss-1.8592, acc-0.5002, test loss-1.8189, acc-0.5211\n",
      "Iter-93150, train loss-1.7811, acc-0.6000, valid loss-1.8591, acc-0.5006, test loss-1.8189, acc-0.5212\n",
      "Iter-93160, train loss-1.8250, acc-0.5400, valid loss-1.8591, acc-0.5008, test loss-1.8189, acc-0.5210\n",
      "Iter-93170, train loss-1.8711, acc-0.4200, valid loss-1.8591, acc-0.5008, test loss-1.8189, acc-0.5211\n",
      "Iter-93180, train loss-1.7962, acc-0.5000, valid loss-1.8591, acc-0.5010, test loss-1.8188, acc-0.5214\n",
      "Iter-93190, train loss-1.8219, acc-0.4800, valid loss-1.8590, acc-0.5006, test loss-1.8188, acc-0.5214\n",
      "Iter-93200, train loss-1.8061, acc-0.5600, valid loss-1.8590, acc-0.5010, test loss-1.8188, acc-0.5214\n",
      "Iter-93210, train loss-1.8638, acc-0.5000, valid loss-1.8590, acc-0.5010, test loss-1.8187, acc-0.5213\n",
      "Iter-93220, train loss-1.7215, acc-0.5600, valid loss-1.8589, acc-0.5006, test loss-1.8187, acc-0.5213\n",
      "Iter-93230, train loss-1.9577, acc-0.4000, valid loss-1.8589, acc-0.5010, test loss-1.8187, acc-0.5213\n",
      "Iter-93240, train loss-1.7771, acc-0.5600, valid loss-1.8589, acc-0.5010, test loss-1.8186, acc-0.5211\n",
      "Iter-93250, train loss-1.7718, acc-0.5400, valid loss-1.8589, acc-0.5006, test loss-1.8186, acc-0.5211\n",
      "Iter-93260, train loss-1.7950, acc-0.5400, valid loss-1.8588, acc-0.5008, test loss-1.8186, acc-0.5212\n",
      "Iter-93270, train loss-1.8205, acc-0.4600, valid loss-1.8588, acc-0.5006, test loss-1.8186, acc-0.5213\n",
      "Iter-93280, train loss-1.7316, acc-0.6200, valid loss-1.8588, acc-0.5008, test loss-1.8185, acc-0.5213\n",
      "Iter-93290, train loss-1.9463, acc-0.4600, valid loss-1.8588, acc-0.5010, test loss-1.8185, acc-0.5213\n",
      "Iter-93300, train loss-1.8921, acc-0.5800, valid loss-1.8587, acc-0.5006, test loss-1.8185, acc-0.5212\n",
      "Iter-93310, train loss-1.9197, acc-0.4200, valid loss-1.8587, acc-0.5008, test loss-1.8184, acc-0.5213\n",
      "Iter-93320, train loss-1.8530, acc-0.5200, valid loss-1.8587, acc-0.5008, test loss-1.8184, acc-0.5212\n",
      "Iter-93330, train loss-1.7492, acc-0.5600, valid loss-1.8587, acc-0.5006, test loss-1.8184, acc-0.5212\n",
      "Iter-93340, train loss-1.8629, acc-0.4800, valid loss-1.8586, acc-0.5008, test loss-1.8184, acc-0.5215\n",
      "Iter-93350, train loss-1.8241, acc-0.4800, valid loss-1.8586, acc-0.5006, test loss-1.8183, acc-0.5213\n",
      "Iter-93360, train loss-1.8210, acc-0.6000, valid loss-1.8586, acc-0.5006, test loss-1.8183, acc-0.5216\n",
      "Iter-93370, train loss-1.9372, acc-0.4400, valid loss-1.8585, acc-0.5006, test loss-1.8183, acc-0.5216\n",
      "Iter-93380, train loss-1.8779, acc-0.5000, valid loss-1.8585, acc-0.5006, test loss-1.8183, acc-0.5215\n",
      "Iter-93390, train loss-1.8886, acc-0.4600, valid loss-1.8585, acc-0.5006, test loss-1.8182, acc-0.5216\n",
      "Iter-93400, train loss-1.8370, acc-0.5600, valid loss-1.8585, acc-0.5008, test loss-1.8182, acc-0.5217\n",
      "Iter-93410, train loss-1.7586, acc-0.6200, valid loss-1.8584, acc-0.5006, test loss-1.8182, acc-0.5216\n",
      "Iter-93420, train loss-1.6925, acc-0.6200, valid loss-1.8584, acc-0.5008, test loss-1.8181, acc-0.5215\n",
      "Iter-93430, train loss-1.8115, acc-0.5400, valid loss-1.8584, acc-0.5010, test loss-1.8181, acc-0.5216\n",
      "Iter-93440, train loss-1.8788, acc-0.5800, valid loss-1.8584, acc-0.5008, test loss-1.8181, acc-0.5215\n",
      "Iter-93450, train loss-1.7720, acc-0.5600, valid loss-1.8583, acc-0.5006, test loss-1.8181, acc-0.5216\n",
      "Iter-93460, train loss-1.9015, acc-0.4200, valid loss-1.8583, acc-0.5004, test loss-1.8180, acc-0.5214\n",
      "Iter-93470, train loss-1.8027, acc-0.5000, valid loss-1.8583, acc-0.5006, test loss-1.8180, acc-0.5215\n",
      "Iter-93480, train loss-1.9740, acc-0.4000, valid loss-1.8583, acc-0.5006, test loss-1.8180, acc-0.5215\n",
      "Iter-93490, train loss-1.9484, acc-0.4200, valid loss-1.8582, acc-0.5006, test loss-1.8179, acc-0.5214\n",
      "Iter-93500, train loss-1.7917, acc-0.6200, valid loss-1.8582, acc-0.5006, test loss-1.8179, acc-0.5215\n",
      "Iter-93510, train loss-1.8610, acc-0.5400, valid loss-1.8582, acc-0.5006, test loss-1.8179, acc-0.5215\n",
      "Iter-93520, train loss-1.8162, acc-0.5800, valid loss-1.8582, acc-0.5010, test loss-1.8179, acc-0.5215\n",
      "Iter-93530, train loss-1.7126, acc-0.5800, valid loss-1.8582, acc-0.5008, test loss-1.8178, acc-0.5214\n",
      "Iter-93540, train loss-1.8785, acc-0.4400, valid loss-1.8581, acc-0.5008, test loss-1.8178, acc-0.5214\n",
      "Iter-93550, train loss-1.8719, acc-0.4800, valid loss-1.8581, acc-0.5008, test loss-1.8178, acc-0.5214\n",
      "Iter-93560, train loss-1.8496, acc-0.4800, valid loss-1.8581, acc-0.5010, test loss-1.8177, acc-0.5214\n",
      "Iter-93570, train loss-1.9037, acc-0.4200, valid loss-1.8581, acc-0.5010, test loss-1.8177, acc-0.5213\n",
      "Iter-93580, train loss-1.8585, acc-0.4400, valid loss-1.8580, acc-0.5010, test loss-1.8177, acc-0.5213\n",
      "Iter-93590, train loss-1.7546, acc-0.5600, valid loss-1.8580, acc-0.5010, test loss-1.8177, acc-0.5214\n",
      "Iter-93600, train loss-1.9069, acc-0.4400, valid loss-1.8580, acc-0.5010, test loss-1.8176, acc-0.5214\n",
      "Iter-93610, train loss-1.8434, acc-0.5000, valid loss-1.8579, acc-0.5008, test loss-1.8176, acc-0.5215\n",
      "Iter-93620, train loss-1.7843, acc-0.5800, valid loss-1.8579, acc-0.5010, test loss-1.8176, acc-0.5214\n",
      "Iter-93630, train loss-1.7774, acc-0.5600, valid loss-1.8579, acc-0.5008, test loss-1.8175, acc-0.5214\n",
      "Iter-93640, train loss-1.8464, acc-0.6000, valid loss-1.8579, acc-0.5008, test loss-1.8175, acc-0.5216\n",
      "Iter-93650, train loss-1.8958, acc-0.5200, valid loss-1.8578, acc-0.5008, test loss-1.8175, acc-0.5215\n",
      "Iter-93660, train loss-1.7247, acc-0.5600, valid loss-1.8578, acc-0.5008, test loss-1.8175, acc-0.5215\n",
      "Iter-93670, train loss-1.8810, acc-0.4400, valid loss-1.8578, acc-0.5010, test loss-1.8174, acc-0.5213\n",
      "Iter-93680, train loss-1.7806, acc-0.5000, valid loss-1.8578, acc-0.5010, test loss-1.8174, acc-0.5213\n",
      "Iter-93690, train loss-1.8323, acc-0.5000, valid loss-1.8577, acc-0.5010, test loss-1.8174, acc-0.5215\n",
      "Iter-93700, train loss-1.9331, acc-0.4200, valid loss-1.8577, acc-0.5010, test loss-1.8173, acc-0.5216\n",
      "Iter-93710, train loss-1.8175, acc-0.5800, valid loss-1.8577, acc-0.5010, test loss-1.8173, acc-0.5217\n",
      "Iter-93720, train loss-1.7864, acc-0.6200, valid loss-1.8576, acc-0.5012, test loss-1.8173, acc-0.5216\n",
      "Iter-93730, train loss-1.7522, acc-0.5600, valid loss-1.8576, acc-0.5010, test loss-1.8173, acc-0.5216\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-93740, train loss-1.8316, acc-0.5400, valid loss-1.8576, acc-0.5012, test loss-1.8172, acc-0.5216\n",
      "Iter-93750, train loss-1.8299, acc-0.5200, valid loss-1.8576, acc-0.5010, test loss-1.8172, acc-0.5214\n",
      "Iter-93760, train loss-1.9050, acc-0.5000, valid loss-1.8575, acc-0.5012, test loss-1.8172, acc-0.5216\n",
      "Iter-93770, train loss-1.8304, acc-0.5000, valid loss-1.8575, acc-0.5010, test loss-1.8171, acc-0.5214\n",
      "Iter-93780, train loss-1.8185, acc-0.4600, valid loss-1.8575, acc-0.5012, test loss-1.8171, acc-0.5215\n",
      "Iter-93790, train loss-1.8439, acc-0.4600, valid loss-1.8575, acc-0.5010, test loss-1.8171, acc-0.5214\n",
      "Iter-93800, train loss-1.9574, acc-0.3800, valid loss-1.8574, acc-0.5008, test loss-1.8171, acc-0.5212\n",
      "Iter-93810, train loss-1.7610, acc-0.5800, valid loss-1.8574, acc-0.5012, test loss-1.8170, acc-0.5213\n",
      "Iter-93820, train loss-1.8584, acc-0.4400, valid loss-1.8574, acc-0.5010, test loss-1.8170, acc-0.5213\n",
      "Iter-93830, train loss-1.7344, acc-0.6200, valid loss-1.8574, acc-0.5012, test loss-1.8170, acc-0.5214\n",
      "Iter-93840, train loss-1.6954, acc-0.6200, valid loss-1.8573, acc-0.5014, test loss-1.8169, acc-0.5212\n",
      "Iter-93850, train loss-1.7933, acc-0.6200, valid loss-1.8573, acc-0.5012, test loss-1.8169, acc-0.5213\n",
      "Iter-93860, train loss-1.8360, acc-0.5000, valid loss-1.8573, acc-0.5012, test loss-1.8169, acc-0.5212\n",
      "Iter-93870, train loss-1.8668, acc-0.5600, valid loss-1.8573, acc-0.5012, test loss-1.8169, acc-0.5212\n",
      "Iter-93880, train loss-1.7079, acc-0.6200, valid loss-1.8572, acc-0.5012, test loss-1.8168, acc-0.5211\n",
      "Iter-93890, train loss-1.8679, acc-0.4800, valid loss-1.8572, acc-0.5014, test loss-1.8168, acc-0.5212\n",
      "Iter-93900, train loss-1.7961, acc-0.5400, valid loss-1.8572, acc-0.5014, test loss-1.8168, acc-0.5213\n",
      "Iter-93910, train loss-1.9128, acc-0.4600, valid loss-1.8572, acc-0.5014, test loss-1.8167, acc-0.5215\n",
      "Iter-93920, train loss-1.8554, acc-0.4600, valid loss-1.8571, acc-0.5014, test loss-1.8167, acc-0.5213\n",
      "Iter-93930, train loss-1.8898, acc-0.4000, valid loss-1.8571, acc-0.5014, test loss-1.8167, acc-0.5213\n",
      "Iter-93940, train loss-1.6604, acc-0.7000, valid loss-1.8571, acc-0.5014, test loss-1.8167, acc-0.5214\n",
      "Iter-93950, train loss-1.8526, acc-0.5000, valid loss-1.8571, acc-0.5014, test loss-1.8166, acc-0.5212\n",
      "Iter-93960, train loss-1.8420, acc-0.5800, valid loss-1.8570, acc-0.5014, test loss-1.8166, acc-0.5213\n",
      "Iter-93970, train loss-1.9737, acc-0.3400, valid loss-1.8570, acc-0.5014, test loss-1.8166, acc-0.5213\n",
      "Iter-93980, train loss-1.8681, acc-0.4000, valid loss-1.8570, acc-0.5014, test loss-1.8165, acc-0.5212\n",
      "Iter-93990, train loss-1.9310, acc-0.4200, valid loss-1.8570, acc-0.5016, test loss-1.8165, acc-0.5211\n",
      "Iter-94000, train loss-1.9040, acc-0.4000, valid loss-1.8569, acc-0.5014, test loss-1.8165, acc-0.5212\n",
      "Iter-94010, train loss-1.7574, acc-0.6400, valid loss-1.8569, acc-0.5016, test loss-1.8165, acc-0.5211\n",
      "Iter-94020, train loss-1.8044, acc-0.5000, valid loss-1.8569, acc-0.5016, test loss-1.8164, acc-0.5211\n",
      "Iter-94030, train loss-1.7604, acc-0.5400, valid loss-1.8569, acc-0.5016, test loss-1.8164, acc-0.5210\n",
      "Iter-94040, train loss-1.8658, acc-0.5600, valid loss-1.8568, acc-0.5016, test loss-1.8164, acc-0.5211\n",
      "Iter-94050, train loss-1.8883, acc-0.4600, valid loss-1.8568, acc-0.5016, test loss-1.8163, acc-0.5211\n",
      "Iter-94060, train loss-1.8198, acc-0.5400, valid loss-1.8568, acc-0.5014, test loss-1.8163, acc-0.5210\n",
      "Iter-94070, train loss-1.8908, acc-0.4200, valid loss-1.8568, acc-0.5014, test loss-1.8163, acc-0.5211\n",
      "Iter-94080, train loss-1.8704, acc-0.4200, valid loss-1.8567, acc-0.5014, test loss-1.8163, acc-0.5210\n",
      "Iter-94090, train loss-1.8723, acc-0.5200, valid loss-1.8567, acc-0.5014, test loss-1.8162, acc-0.5211\n",
      "Iter-94100, train loss-1.8135, acc-0.6200, valid loss-1.8567, acc-0.5014, test loss-1.8162, acc-0.5210\n",
      "Iter-94110, train loss-1.8706, acc-0.4800, valid loss-1.8566, acc-0.5014, test loss-1.8162, acc-0.5210\n",
      "Iter-94120, train loss-1.8741, acc-0.4200, valid loss-1.8566, acc-0.5014, test loss-1.8162, acc-0.5209\n",
      "Iter-94130, train loss-1.8152, acc-0.5200, valid loss-1.8566, acc-0.5014, test loss-1.8161, acc-0.5210\n",
      "Iter-94140, train loss-1.8064, acc-0.6200, valid loss-1.8566, acc-0.5014, test loss-1.8161, acc-0.5209\n",
      "Iter-94150, train loss-1.8344, acc-0.5600, valid loss-1.8565, acc-0.5014, test loss-1.8161, acc-0.5211\n",
      "Iter-94160, train loss-1.8342, acc-0.5400, valid loss-1.8565, acc-0.5016, test loss-1.8160, acc-0.5212\n",
      "Iter-94170, train loss-1.8715, acc-0.4600, valid loss-1.8565, acc-0.5016, test loss-1.8160, acc-0.5213\n",
      "Iter-94180, train loss-1.8745, acc-0.4200, valid loss-1.8565, acc-0.5014, test loss-1.8160, acc-0.5211\n",
      "Iter-94190, train loss-1.8356, acc-0.6000, valid loss-1.8564, acc-0.5016, test loss-1.8159, acc-0.5213\n",
      "Iter-94200, train loss-1.7784, acc-0.5000, valid loss-1.8564, acc-0.5016, test loss-1.8159, acc-0.5213\n",
      "Iter-94210, train loss-1.8068, acc-0.6000, valid loss-1.8564, acc-0.5016, test loss-1.8159, acc-0.5214\n",
      "Iter-94220, train loss-1.9097, acc-0.4600, valid loss-1.8564, acc-0.5014, test loss-1.8159, acc-0.5211\n",
      "Iter-94230, train loss-1.9188, acc-0.4000, valid loss-1.8563, acc-0.5012, test loss-1.8158, acc-0.5211\n",
      "Iter-94240, train loss-1.7532, acc-0.6000, valid loss-1.8563, acc-0.5012, test loss-1.8158, acc-0.5211\n",
      "Iter-94250, train loss-1.8198, acc-0.4800, valid loss-1.8563, acc-0.5014, test loss-1.8158, acc-0.5212\n",
      "Iter-94260, train loss-1.7705, acc-0.5800, valid loss-1.8562, acc-0.5014, test loss-1.8157, acc-0.5209\n",
      "Iter-94270, train loss-1.9072, acc-0.4400, valid loss-1.8562, acc-0.5014, test loss-1.8157, acc-0.5211\n",
      "Iter-94280, train loss-1.7537, acc-0.4800, valid loss-1.8562, acc-0.5014, test loss-1.8157, acc-0.5211\n",
      "Iter-94290, train loss-1.7925, acc-0.5400, valid loss-1.8562, acc-0.5012, test loss-1.8157, acc-0.5211\n",
      "Iter-94300, train loss-1.8785, acc-0.4600, valid loss-1.8561, acc-0.5012, test loss-1.8156, acc-0.5210\n",
      "Iter-94310, train loss-1.9037, acc-0.4000, valid loss-1.8561, acc-0.5014, test loss-1.8156, acc-0.5210\n",
      "Iter-94320, train loss-1.7800, acc-0.5800, valid loss-1.8561, acc-0.5014, test loss-1.8156, acc-0.5210\n",
      "Iter-94330, train loss-1.7803, acc-0.5200, valid loss-1.8561, acc-0.5016, test loss-1.8155, acc-0.5211\n",
      "Iter-94340, train loss-1.8242, acc-0.5600, valid loss-1.8560, acc-0.5016, test loss-1.8155, acc-0.5212\n",
      "Iter-94350, train loss-1.7613, acc-0.5200, valid loss-1.8560, acc-0.5016, test loss-1.8155, acc-0.5212\n",
      "Iter-94360, train loss-1.8707, acc-0.4200, valid loss-1.8560, acc-0.5016, test loss-1.8155, acc-0.5210\n",
      "Iter-94370, train loss-1.8266, acc-0.4800, valid loss-1.8560, acc-0.5016, test loss-1.8154, acc-0.5211\n",
      "Iter-94380, train loss-1.8841, acc-0.4800, valid loss-1.8559, acc-0.5016, test loss-1.8154, acc-0.5212\n",
      "Iter-94390, train loss-1.9228, acc-0.4800, valid loss-1.8559, acc-0.5016, test loss-1.8154, acc-0.5211\n",
      "Iter-94400, train loss-1.9370, acc-0.4800, valid loss-1.8559, acc-0.5016, test loss-1.8153, acc-0.5212\n",
      "Iter-94410, train loss-1.8502, acc-0.5000, valid loss-1.8559, acc-0.5016, test loss-1.8153, acc-0.5211\n",
      "Iter-94420, train loss-1.7888, acc-0.5600, valid loss-1.8558, acc-0.5016, test loss-1.8153, acc-0.5213\n",
      "Iter-94430, train loss-1.8244, acc-0.4800, valid loss-1.8558, acc-0.5016, test loss-1.8152, acc-0.5213\n",
      "Iter-94440, train loss-1.8478, acc-0.5000, valid loss-1.8558, acc-0.5016, test loss-1.8152, acc-0.5213\n",
      "Iter-94450, train loss-1.8714, acc-0.4800, valid loss-1.8558, acc-0.5016, test loss-1.8152, acc-0.5214\n",
      "Iter-94460, train loss-1.8482, acc-0.5000, valid loss-1.8557, acc-0.5016, test loss-1.8152, acc-0.5213\n",
      "Iter-94470, train loss-1.8186, acc-0.5000, valid loss-1.8557, acc-0.5016, test loss-1.8151, acc-0.5212\n",
      "Iter-94480, train loss-1.8823, acc-0.5000, valid loss-1.8557, acc-0.5016, test loss-1.8151, acc-0.5212\n",
      "Iter-94490, train loss-1.8666, acc-0.5600, valid loss-1.8557, acc-0.5016, test loss-1.8151, acc-0.5211\n",
      "Iter-94500, train loss-1.8989, acc-0.5600, valid loss-1.8556, acc-0.5014, test loss-1.8150, acc-0.5212\n",
      "Iter-94510, train loss-1.8538, acc-0.5400, valid loss-1.8556, acc-0.5014, test loss-1.8150, acc-0.5211\n",
      "Iter-94520, train loss-1.8511, acc-0.4400, valid loss-1.8556, acc-0.5014, test loss-1.8150, acc-0.5211\n",
      "Iter-94530, train loss-1.6931, acc-0.5400, valid loss-1.8556, acc-0.5014, test loss-1.8150, acc-0.5212\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-94540, train loss-1.7169, acc-0.6000, valid loss-1.8555, acc-0.5014, test loss-1.8149, acc-0.5211\n",
      "Iter-94550, train loss-1.8836, acc-0.5800, valid loss-1.8555, acc-0.5012, test loss-1.8149, acc-0.5211\n",
      "Iter-94560, train loss-1.9041, acc-0.4600, valid loss-1.8555, acc-0.5014, test loss-1.8149, acc-0.5212\n",
      "Iter-94570, train loss-1.8805, acc-0.4600, valid loss-1.8554, acc-0.5014, test loss-1.8148, acc-0.5212\n",
      "Iter-94580, train loss-1.9652, acc-0.4000, valid loss-1.8554, acc-0.5014, test loss-1.8148, acc-0.5211\n",
      "Iter-94590, train loss-1.7563, acc-0.5600, valid loss-1.8554, acc-0.5014, test loss-1.8148, acc-0.5211\n",
      "Iter-94600, train loss-1.8158, acc-0.5200, valid loss-1.8554, acc-0.5014, test loss-1.8148, acc-0.5212\n",
      "Iter-94610, train loss-1.8725, acc-0.3800, valid loss-1.8553, acc-0.5014, test loss-1.8147, acc-0.5213\n",
      "Iter-94620, train loss-1.8287, acc-0.5400, valid loss-1.8553, acc-0.5014, test loss-1.8147, acc-0.5210\n",
      "Iter-94630, train loss-1.8157, acc-0.5000, valid loss-1.8553, acc-0.5016, test loss-1.8147, acc-0.5211\n",
      "Iter-94640, train loss-1.7990, acc-0.5000, valid loss-1.8553, acc-0.5016, test loss-1.8146, acc-0.5210\n",
      "Iter-94650, train loss-1.7810, acc-0.5400, valid loss-1.8552, acc-0.5016, test loss-1.8146, acc-0.5211\n",
      "Iter-94660, train loss-1.7729, acc-0.6200, valid loss-1.8552, acc-0.5018, test loss-1.8146, acc-0.5211\n",
      "Iter-94670, train loss-1.8917, acc-0.4400, valid loss-1.8552, acc-0.5018, test loss-1.8146, acc-0.5210\n",
      "Iter-94680, train loss-1.7354, acc-0.5400, valid loss-1.8552, acc-0.5018, test loss-1.8145, acc-0.5209\n",
      "Iter-94690, train loss-1.9338, acc-0.3600, valid loss-1.8551, acc-0.5018, test loss-1.8145, acc-0.5211\n",
      "Iter-94700, train loss-1.8214, acc-0.4600, valid loss-1.8551, acc-0.5016, test loss-1.8145, acc-0.5211\n",
      "Iter-94710, train loss-1.7368, acc-0.6200, valid loss-1.8551, acc-0.5016, test loss-1.8144, acc-0.5208\n",
      "Iter-94720, train loss-1.8809, acc-0.4000, valid loss-1.8551, acc-0.5014, test loss-1.8144, acc-0.5209\n",
      "Iter-94730, train loss-1.8991, acc-0.4600, valid loss-1.8550, acc-0.5016, test loss-1.8144, acc-0.5212\n",
      "Iter-94740, train loss-1.7518, acc-0.5600, valid loss-1.8550, acc-0.5014, test loss-1.8144, acc-0.5212\n",
      "Iter-94750, train loss-1.8445, acc-0.5000, valid loss-1.8550, acc-0.5016, test loss-1.8143, acc-0.5212\n",
      "Iter-94760, train loss-1.7310, acc-0.5800, valid loss-1.8550, acc-0.5014, test loss-1.8143, acc-0.5212\n",
      "Iter-94770, train loss-1.8237, acc-0.5200, valid loss-1.8549, acc-0.5014, test loss-1.8143, acc-0.5211\n",
      "Iter-94780, train loss-1.8200, acc-0.5400, valid loss-1.8549, acc-0.5014, test loss-1.8143, acc-0.5211\n",
      "Iter-94790, train loss-1.8355, acc-0.5600, valid loss-1.8549, acc-0.5012, test loss-1.8142, acc-0.5213\n",
      "Iter-94800, train loss-1.9233, acc-0.4200, valid loss-1.8549, acc-0.5012, test loss-1.8142, acc-0.5211\n",
      "Iter-94810, train loss-1.7991, acc-0.5800, valid loss-1.8548, acc-0.5012, test loss-1.8142, acc-0.5210\n",
      "Iter-94820, train loss-1.7623, acc-0.5000, valid loss-1.8548, acc-0.5014, test loss-1.8141, acc-0.5212\n",
      "Iter-94830, train loss-1.8966, acc-0.4600, valid loss-1.8548, acc-0.5012, test loss-1.8141, acc-0.5211\n",
      "Iter-94840, train loss-1.8799, acc-0.4200, valid loss-1.8547, acc-0.5012, test loss-1.8141, acc-0.5210\n",
      "Iter-94850, train loss-1.8056, acc-0.5600, valid loss-1.8547, acc-0.5016, test loss-1.8140, acc-0.5210\n",
      "Iter-94860, train loss-1.9105, acc-0.4000, valid loss-1.8547, acc-0.5014, test loss-1.8140, acc-0.5210\n",
      "Iter-94870, train loss-1.8238, acc-0.5800, valid loss-1.8547, acc-0.5016, test loss-1.8140, acc-0.5211\n",
      "Iter-94880, train loss-1.7620, acc-0.5200, valid loss-1.8546, acc-0.5018, test loss-1.8140, acc-0.5211\n",
      "Iter-94890, train loss-1.7775, acc-0.5000, valid loss-1.8546, acc-0.5014, test loss-1.8139, acc-0.5210\n",
      "Iter-94900, train loss-1.8978, acc-0.5400, valid loss-1.8546, acc-0.5014, test loss-1.8139, acc-0.5210\n",
      "Iter-94910, train loss-1.9184, acc-0.4600, valid loss-1.8546, acc-0.5012, test loss-1.8139, acc-0.5209\n",
      "Iter-94920, train loss-1.8249, acc-0.6200, valid loss-1.8545, acc-0.5012, test loss-1.8139, acc-0.5209\n",
      "Iter-94930, train loss-1.8584, acc-0.5200, valid loss-1.8545, acc-0.5012, test loss-1.8138, acc-0.5211\n",
      "Iter-94940, train loss-1.9027, acc-0.4400, valid loss-1.8545, acc-0.5014, test loss-1.8138, acc-0.5211\n",
      "Iter-94950, train loss-1.7082, acc-0.6600, valid loss-1.8545, acc-0.5012, test loss-1.8138, acc-0.5210\n",
      "Iter-94960, train loss-1.8003, acc-0.5600, valid loss-1.8544, acc-0.5014, test loss-1.8137, acc-0.5211\n",
      "Iter-94970, train loss-1.8868, acc-0.4200, valid loss-1.8544, acc-0.5014, test loss-1.8137, acc-0.5212\n",
      "Iter-94980, train loss-1.8460, acc-0.5000, valid loss-1.8544, acc-0.5014, test loss-1.8137, acc-0.5212\n",
      "Iter-94990, train loss-1.8425, acc-0.4800, valid loss-1.8544, acc-0.5014, test loss-1.8137, acc-0.5212\n",
      "Iter-95000, train loss-1.8646, acc-0.6200, valid loss-1.8543, acc-0.5014, test loss-1.8136, acc-0.5211\n",
      "Iter-95010, train loss-1.7202, acc-0.6400, valid loss-1.8543, acc-0.5012, test loss-1.8136, acc-0.5212\n",
      "Iter-95020, train loss-1.8780, acc-0.5800, valid loss-1.8543, acc-0.5012, test loss-1.8136, acc-0.5212\n",
      "Iter-95030, train loss-1.7000, acc-0.6400, valid loss-1.8542, acc-0.5012, test loss-1.8135, acc-0.5212\n",
      "Iter-95040, train loss-1.9093, acc-0.5000, valid loss-1.8542, acc-0.5014, test loss-1.8135, acc-0.5212\n",
      "Iter-95050, train loss-1.8686, acc-0.5200, valid loss-1.8542, acc-0.5012, test loss-1.8135, acc-0.5213\n",
      "Iter-95060, train loss-1.9536, acc-0.3600, valid loss-1.8542, acc-0.5014, test loss-1.8135, acc-0.5213\n",
      "Iter-95070, train loss-1.7082, acc-0.6400, valid loss-1.8541, acc-0.5010, test loss-1.8134, acc-0.5212\n",
      "Iter-95080, train loss-1.7843, acc-0.5000, valid loss-1.8541, acc-0.5010, test loss-1.8134, acc-0.5212\n",
      "Iter-95090, train loss-1.8617, acc-0.5200, valid loss-1.8541, acc-0.5010, test loss-1.8134, acc-0.5211\n",
      "Iter-95100, train loss-1.8172, acc-0.5000, valid loss-1.8541, acc-0.5010, test loss-1.8133, acc-0.5211\n",
      "Iter-95110, train loss-1.7689, acc-0.5800, valid loss-1.8540, acc-0.5008, test loss-1.8133, acc-0.5211\n",
      "Iter-95120, train loss-1.7975, acc-0.5200, valid loss-1.8540, acc-0.5008, test loss-1.8133, acc-0.5211\n",
      "Iter-95130, train loss-1.8883, acc-0.4400, valid loss-1.8540, acc-0.5008, test loss-1.8133, acc-0.5211\n",
      "Iter-95140, train loss-1.8818, acc-0.5400, valid loss-1.8540, acc-0.5010, test loss-1.8132, acc-0.5211\n",
      "Iter-95150, train loss-1.7850, acc-0.5600, valid loss-1.8539, acc-0.5010, test loss-1.8132, acc-0.5210\n",
      "Iter-95160, train loss-1.7426, acc-0.5400, valid loss-1.8539, acc-0.5008, test loss-1.8132, acc-0.5211\n",
      "Iter-95170, train loss-1.7984, acc-0.5600, valid loss-1.8539, acc-0.5008, test loss-1.8131, acc-0.5211\n",
      "Iter-95180, train loss-1.7601, acc-0.5800, valid loss-1.8539, acc-0.5008, test loss-1.8131, acc-0.5211\n",
      "Iter-95190, train loss-1.7776, acc-0.5200, valid loss-1.8538, acc-0.5010, test loss-1.8131, acc-0.5212\n",
      "Iter-95200, train loss-1.8910, acc-0.5000, valid loss-1.8538, acc-0.5010, test loss-1.8131, acc-0.5211\n",
      "Iter-95210, train loss-1.8740, acc-0.5200, valid loss-1.8538, acc-0.5010, test loss-1.8130, acc-0.5211\n",
      "Iter-95220, train loss-1.8234, acc-0.4600, valid loss-1.8538, acc-0.5010, test loss-1.8130, acc-0.5208\n",
      "Iter-95230, train loss-1.7821, acc-0.5600, valid loss-1.8537, acc-0.5010, test loss-1.8130, acc-0.5209\n",
      "Iter-95240, train loss-1.8486, acc-0.5600, valid loss-1.8537, acc-0.5010, test loss-1.8130, acc-0.5209\n",
      "Iter-95250, train loss-1.8937, acc-0.4600, valid loss-1.8537, acc-0.5008, test loss-1.8129, acc-0.5211\n",
      "Iter-95260, train loss-1.8232, acc-0.5600, valid loss-1.8537, acc-0.5008, test loss-1.8129, acc-0.5211\n",
      "Iter-95270, train loss-1.9411, acc-0.4000, valid loss-1.8536, acc-0.5008, test loss-1.8129, acc-0.5211\n",
      "Iter-95280, train loss-1.8398, acc-0.4600, valid loss-1.8536, acc-0.5010, test loss-1.8128, acc-0.5212\n",
      "Iter-95290, train loss-1.8306, acc-0.4600, valid loss-1.8536, acc-0.5012, test loss-1.8128, acc-0.5211\n",
      "Iter-95300, train loss-1.8423, acc-0.4600, valid loss-1.8536, acc-0.5010, test loss-1.8128, acc-0.5211\n",
      "Iter-95310, train loss-1.9206, acc-0.4200, valid loss-1.8535, acc-0.5010, test loss-1.8128, acc-0.5211\n",
      "Iter-95320, train loss-1.8214, acc-0.5600, valid loss-1.8535, acc-0.5010, test loss-1.8127, acc-0.5212\n",
      "Iter-95330, train loss-1.8647, acc-0.4800, valid loss-1.8535, acc-0.5008, test loss-1.8127, acc-0.5211\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-95340, train loss-1.8620, acc-0.5600, valid loss-1.8535, acc-0.5008, test loss-1.8127, acc-0.5211\n",
      "Iter-95350, train loss-1.8768, acc-0.4800, valid loss-1.8534, acc-0.5008, test loss-1.8127, acc-0.5211\n",
      "Iter-95360, train loss-1.8986, acc-0.5200, valid loss-1.8534, acc-0.5006, test loss-1.8126, acc-0.5211\n",
      "Iter-95370, train loss-1.8528, acc-0.5000, valid loss-1.8534, acc-0.5008, test loss-1.8126, acc-0.5211\n",
      "Iter-95380, train loss-1.7878, acc-0.5000, valid loss-1.8534, acc-0.5008, test loss-1.8126, acc-0.5212\n",
      "Iter-95390, train loss-1.7654, acc-0.5600, valid loss-1.8533, acc-0.5008, test loss-1.8125, acc-0.5213\n",
      "Iter-95400, train loss-1.8621, acc-0.4800, valid loss-1.8533, acc-0.5008, test loss-1.8125, acc-0.5213\n",
      "Iter-95410, train loss-1.8782, acc-0.4600, valid loss-1.8533, acc-0.5008, test loss-1.8125, acc-0.5212\n",
      "Iter-95420, train loss-1.9492, acc-0.4600, valid loss-1.8532, acc-0.5008, test loss-1.8125, acc-0.5213\n",
      "Iter-95430, train loss-1.7172, acc-0.6600, valid loss-1.8532, acc-0.5008, test loss-1.8124, acc-0.5213\n",
      "Iter-95440, train loss-1.8309, acc-0.6200, valid loss-1.8532, acc-0.5006, test loss-1.8124, acc-0.5212\n",
      "Iter-95450, train loss-1.9199, acc-0.4400, valid loss-1.8532, acc-0.5008, test loss-1.8124, acc-0.5213\n",
      "Iter-95460, train loss-1.7651, acc-0.6000, valid loss-1.8531, acc-0.5010, test loss-1.8123, acc-0.5212\n",
      "Iter-95470, train loss-1.7760, acc-0.5600, valid loss-1.8531, acc-0.5008, test loss-1.8123, acc-0.5212\n",
      "Iter-95480, train loss-1.8402, acc-0.6000, valid loss-1.8531, acc-0.5008, test loss-1.8123, acc-0.5212\n",
      "Iter-95490, train loss-1.9239, acc-0.5000, valid loss-1.8531, acc-0.5006, test loss-1.8123, acc-0.5215\n",
      "Iter-95500, train loss-1.9254, acc-0.4200, valid loss-1.8530, acc-0.5010, test loss-1.8122, acc-0.5214\n",
      "Iter-95510, train loss-1.8077, acc-0.5400, valid loss-1.8530, acc-0.5008, test loss-1.8122, acc-0.5214\n",
      "Iter-95520, train loss-1.7997, acc-0.5400, valid loss-1.8530, acc-0.5008, test loss-1.8122, acc-0.5213\n",
      "Iter-95530, train loss-1.8921, acc-0.4200, valid loss-1.8530, acc-0.5008, test loss-1.8122, acc-0.5211\n",
      "Iter-95540, train loss-1.8542, acc-0.4800, valid loss-1.8529, acc-0.5008, test loss-1.8121, acc-0.5212\n",
      "Iter-95550, train loss-1.8941, acc-0.4600, valid loss-1.8529, acc-0.5010, test loss-1.8121, acc-0.5212\n",
      "Iter-95560, train loss-1.7853, acc-0.5600, valid loss-1.8529, acc-0.5006, test loss-1.8121, acc-0.5214\n",
      "Iter-95570, train loss-1.8159, acc-0.6200, valid loss-1.8529, acc-0.5010, test loss-1.8120, acc-0.5211\n",
      "Iter-95580, train loss-1.9777, acc-0.4600, valid loss-1.8528, acc-0.5006, test loss-1.8120, acc-0.5210\n",
      "Iter-95590, train loss-1.8230, acc-0.4200, valid loss-1.8528, acc-0.5008, test loss-1.8120, acc-0.5211\n",
      "Iter-95600, train loss-1.8724, acc-0.5000, valid loss-1.8528, acc-0.5008, test loss-1.8120, acc-0.5211\n",
      "Iter-95610, train loss-1.7771, acc-0.4600, valid loss-1.8528, acc-0.5008, test loss-1.8119, acc-0.5211\n",
      "Iter-95620, train loss-1.8830, acc-0.4200, valid loss-1.8527, acc-0.5008, test loss-1.8119, acc-0.5209\n",
      "Iter-95630, train loss-1.8658, acc-0.3600, valid loss-1.8527, acc-0.5008, test loss-1.8119, acc-0.5210\n",
      "Iter-95640, train loss-1.8270, acc-0.5200, valid loss-1.8527, acc-0.5006, test loss-1.8118, acc-0.5210\n",
      "Iter-95650, train loss-1.7816, acc-0.5800, valid loss-1.8527, acc-0.5008, test loss-1.8118, acc-0.5209\n",
      "Iter-95660, train loss-1.8394, acc-0.4000, valid loss-1.8526, acc-0.5008, test loss-1.8118, acc-0.5211\n",
      "Iter-95670, train loss-1.7603, acc-0.6400, valid loss-1.8526, acc-0.5008, test loss-1.8118, acc-0.5210\n",
      "Iter-95680, train loss-1.7893, acc-0.5400, valid loss-1.8526, acc-0.5008, test loss-1.8117, acc-0.5209\n",
      "Iter-95690, train loss-1.8760, acc-0.4200, valid loss-1.8526, acc-0.5006, test loss-1.8117, acc-0.5209\n",
      "Iter-95700, train loss-1.9172, acc-0.4200, valid loss-1.8525, acc-0.5006, test loss-1.8117, acc-0.5210\n",
      "Iter-95710, train loss-1.8582, acc-0.4400, valid loss-1.8525, acc-0.5008, test loss-1.8116, acc-0.5209\n",
      "Iter-95720, train loss-1.8998, acc-0.4200, valid loss-1.8525, acc-0.5010, test loss-1.8116, acc-0.5210\n",
      "Iter-95730, train loss-1.8507, acc-0.4200, valid loss-1.8525, acc-0.5008, test loss-1.8116, acc-0.5211\n",
      "Iter-95740, train loss-1.8487, acc-0.5200, valid loss-1.8524, acc-0.5008, test loss-1.8116, acc-0.5211\n",
      "Iter-95750, train loss-1.7826, acc-0.6000, valid loss-1.8524, acc-0.5006, test loss-1.8115, acc-0.5212\n",
      "Iter-95760, train loss-1.8321, acc-0.4000, valid loss-1.8524, acc-0.5006, test loss-1.8115, acc-0.5211\n",
      "Iter-95770, train loss-1.7721, acc-0.5600, valid loss-1.8524, acc-0.5010, test loss-1.8115, acc-0.5210\n",
      "Iter-95780, train loss-1.9323, acc-0.3800, valid loss-1.8523, acc-0.5006, test loss-1.8114, acc-0.5211\n",
      "Iter-95790, train loss-1.7788, acc-0.4800, valid loss-1.8523, acc-0.5010, test loss-1.8114, acc-0.5210\n",
      "Iter-95800, train loss-1.8356, acc-0.4400, valid loss-1.8523, acc-0.5010, test loss-1.8114, acc-0.5212\n",
      "Iter-95810, train loss-1.8509, acc-0.4200, valid loss-1.8522, acc-0.5010, test loss-1.8114, acc-0.5213\n",
      "Iter-95820, train loss-1.7954, acc-0.5000, valid loss-1.8522, acc-0.5010, test loss-1.8113, acc-0.5213\n",
      "Iter-95830, train loss-1.9203, acc-0.4600, valid loss-1.8522, acc-0.5008, test loss-1.8113, acc-0.5212\n",
      "Iter-95840, train loss-1.7545, acc-0.5400, valid loss-1.8522, acc-0.5008, test loss-1.8113, acc-0.5213\n",
      "Iter-95850, train loss-1.8297, acc-0.5200, valid loss-1.8521, acc-0.5010, test loss-1.8112, acc-0.5212\n",
      "Iter-95860, train loss-1.8684, acc-0.4200, valid loss-1.8521, acc-0.5008, test loss-1.8112, acc-0.5212\n",
      "Iter-95870, train loss-1.9092, acc-0.4200, valid loss-1.8521, acc-0.5010, test loss-1.8112, acc-0.5211\n",
      "Iter-95880, train loss-1.8353, acc-0.4600, valid loss-1.8521, acc-0.5010, test loss-1.8112, acc-0.5213\n",
      "Iter-95890, train loss-1.8326, acc-0.5400, valid loss-1.8520, acc-0.5010, test loss-1.8111, acc-0.5212\n",
      "Iter-95900, train loss-1.7281, acc-0.5400, valid loss-1.8520, acc-0.5010, test loss-1.8111, acc-0.5212\n",
      "Iter-95910, train loss-1.8462, acc-0.5200, valid loss-1.8520, acc-0.5012, test loss-1.8111, acc-0.5212\n",
      "Iter-95920, train loss-1.8237, acc-0.5600, valid loss-1.8520, acc-0.5010, test loss-1.8110, acc-0.5212\n",
      "Iter-95930, train loss-1.7337, acc-0.6600, valid loss-1.8519, acc-0.5012, test loss-1.8110, acc-0.5212\n",
      "Iter-95940, train loss-1.7657, acc-0.5600, valid loss-1.8519, acc-0.5010, test loss-1.8110, acc-0.5211\n",
      "Iter-95950, train loss-1.9616, acc-0.4000, valid loss-1.8519, acc-0.5012, test loss-1.8110, acc-0.5211\n",
      "Iter-95960, train loss-1.8026, acc-0.5000, valid loss-1.8519, acc-0.5014, test loss-1.8109, acc-0.5211\n",
      "Iter-95970, train loss-1.9196, acc-0.4600, valid loss-1.8518, acc-0.5012, test loss-1.8109, acc-0.5211\n",
      "Iter-95980, train loss-1.8504, acc-0.5200, valid loss-1.8518, acc-0.5014, test loss-1.8109, acc-0.5211\n",
      "Iter-95990, train loss-1.8268, acc-0.3600, valid loss-1.8518, acc-0.5012, test loss-1.8108, acc-0.5211\n",
      "Iter-96000, train loss-1.7679, acc-0.6200, valid loss-1.8518, acc-0.5012, test loss-1.8108, acc-0.5211\n",
      "Iter-96010, train loss-1.7841, acc-0.6200, valid loss-1.8517, acc-0.5014, test loss-1.8108, acc-0.5211\n",
      "Iter-96020, train loss-1.8173, acc-0.6200, valid loss-1.8517, acc-0.5012, test loss-1.8108, acc-0.5212\n",
      "Iter-96030, train loss-1.8131, acc-0.5200, valid loss-1.8517, acc-0.5016, test loss-1.8107, acc-0.5213\n",
      "Iter-96040, train loss-1.8318, acc-0.5200, valid loss-1.8517, acc-0.5016, test loss-1.8107, acc-0.5213\n",
      "Iter-96050, train loss-1.9016, acc-0.4800, valid loss-1.8516, acc-0.5014, test loss-1.8107, acc-0.5214\n",
      "Iter-96060, train loss-1.8155, acc-0.5000, valid loss-1.8516, acc-0.5014, test loss-1.8106, acc-0.5213\n",
      "Iter-96070, train loss-1.9347, acc-0.4200, valid loss-1.8516, acc-0.5014, test loss-1.8106, acc-0.5214\n",
      "Iter-96080, train loss-1.8801, acc-0.4800, valid loss-1.8516, acc-0.5016, test loss-1.8106, acc-0.5213\n",
      "Iter-96090, train loss-1.8099, acc-0.5400, valid loss-1.8515, acc-0.5014, test loss-1.8106, acc-0.5213\n",
      "Iter-96100, train loss-1.8130, acc-0.5600, valid loss-1.8515, acc-0.5016, test loss-1.8105, acc-0.5215\n",
      "Iter-96110, train loss-1.8935, acc-0.4600, valid loss-1.8515, acc-0.5016, test loss-1.8105, acc-0.5214\n",
      "Iter-96120, train loss-1.8155, acc-0.4800, valid loss-1.8514, acc-0.5016, test loss-1.8105, acc-0.5216\n",
      "Iter-96130, train loss-1.8107, acc-0.5600, valid loss-1.8514, acc-0.5016, test loss-1.8104, acc-0.5215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-96140, train loss-1.7475, acc-0.4400, valid loss-1.8514, acc-0.5014, test loss-1.8104, acc-0.5217\n",
      "Iter-96150, train loss-1.7397, acc-0.6000, valid loss-1.8514, acc-0.5014, test loss-1.8104, acc-0.5217\n",
      "Iter-96160, train loss-1.8423, acc-0.4800, valid loss-1.8513, acc-0.5014, test loss-1.8104, acc-0.5218\n",
      "Iter-96170, train loss-2.0162, acc-0.3600, valid loss-1.8513, acc-0.5014, test loss-1.8103, acc-0.5220\n",
      "Iter-96180, train loss-1.6720, acc-0.5600, valid loss-1.8513, acc-0.5014, test loss-1.8103, acc-0.5219\n",
      "Iter-96190, train loss-1.7850, acc-0.6000, valid loss-1.8513, acc-0.5014, test loss-1.8103, acc-0.5220\n",
      "Iter-96200, train loss-1.7340, acc-0.6400, valid loss-1.8512, acc-0.5014, test loss-1.8103, acc-0.5220\n",
      "Iter-96210, train loss-1.9569, acc-0.4600, valid loss-1.8512, acc-0.5016, test loss-1.8102, acc-0.5218\n",
      "Iter-96220, train loss-1.8180, acc-0.6000, valid loss-1.8512, acc-0.5012, test loss-1.8102, acc-0.5220\n",
      "Iter-96230, train loss-1.8276, acc-0.5600, valid loss-1.8512, acc-0.5014, test loss-1.8102, acc-0.5220\n",
      "Iter-96240, train loss-1.8296, acc-0.5000, valid loss-1.8511, acc-0.5014, test loss-1.8101, acc-0.5219\n",
      "Iter-96250, train loss-1.9128, acc-0.4000, valid loss-1.8511, acc-0.5014, test loss-1.8101, acc-0.5219\n",
      "Iter-96260, train loss-1.7215, acc-0.5800, valid loss-1.8511, acc-0.5014, test loss-1.8101, acc-0.5221\n",
      "Iter-96270, train loss-1.8206, acc-0.5400, valid loss-1.8511, acc-0.5014, test loss-1.8101, acc-0.5220\n",
      "Iter-96280, train loss-1.8751, acc-0.4200, valid loss-1.8510, acc-0.5012, test loss-1.8100, acc-0.5220\n",
      "Iter-96290, train loss-1.8373, acc-0.5000, valid loss-1.8510, acc-0.5010, test loss-1.8100, acc-0.5219\n",
      "Iter-96300, train loss-1.8146, acc-0.5000, valid loss-1.8510, acc-0.5012, test loss-1.8100, acc-0.5221\n",
      "Iter-96310, train loss-1.9386, acc-0.4800, valid loss-1.8510, acc-0.5012, test loss-1.8099, acc-0.5222\n",
      "Iter-96320, train loss-1.8211, acc-0.5200, valid loss-1.8509, acc-0.5012, test loss-1.8099, acc-0.5222\n",
      "Iter-96330, train loss-1.8710, acc-0.4800, valid loss-1.8509, acc-0.5014, test loss-1.8099, acc-0.5221\n",
      "Iter-96340, train loss-1.8294, acc-0.5800, valid loss-1.8509, acc-0.5014, test loss-1.8099, acc-0.5220\n",
      "Iter-96350, train loss-1.8043, acc-0.4800, valid loss-1.8509, acc-0.5014, test loss-1.8098, acc-0.5222\n",
      "Iter-96360, train loss-1.9265, acc-0.3600, valid loss-1.8508, acc-0.5014, test loss-1.8098, acc-0.5221\n",
      "Iter-96370, train loss-1.8961, acc-0.4800, valid loss-1.8508, acc-0.5014, test loss-1.8098, acc-0.5221\n",
      "Iter-96380, train loss-1.7803, acc-0.5800, valid loss-1.8508, acc-0.5012, test loss-1.8098, acc-0.5222\n",
      "Iter-96390, train loss-1.8393, acc-0.4600, valid loss-1.8508, acc-0.5012, test loss-1.8097, acc-0.5222\n",
      "Iter-96400, train loss-1.9122, acc-0.4600, valid loss-1.8507, acc-0.5012, test loss-1.8097, acc-0.5222\n",
      "Iter-96410, train loss-1.9015, acc-0.5400, valid loss-1.8507, acc-0.5014, test loss-1.8097, acc-0.5222\n",
      "Iter-96420, train loss-1.8133, acc-0.6200, valid loss-1.8507, acc-0.5010, test loss-1.8096, acc-0.5221\n",
      "Iter-96430, train loss-1.8068, acc-0.5400, valid loss-1.8507, acc-0.5008, test loss-1.8096, acc-0.5222\n",
      "Iter-96440, train loss-1.9375, acc-0.4000, valid loss-1.8506, acc-0.5008, test loss-1.8096, acc-0.5221\n",
      "Iter-96450, train loss-1.8214, acc-0.4400, valid loss-1.8506, acc-0.5010, test loss-1.8096, acc-0.5219\n",
      "Iter-96460, train loss-1.8618, acc-0.4600, valid loss-1.8506, acc-0.5008, test loss-1.8095, acc-0.5219\n",
      "Iter-96470, train loss-1.8026, acc-0.4800, valid loss-1.8505, acc-0.5008, test loss-1.8095, acc-0.5220\n",
      "Iter-96480, train loss-1.8811, acc-0.4400, valid loss-1.8505, acc-0.5008, test loss-1.8095, acc-0.5220\n",
      "Iter-96490, train loss-1.8849, acc-0.4800, valid loss-1.8505, acc-0.5008, test loss-1.8094, acc-0.5219\n",
      "Iter-96500, train loss-1.8542, acc-0.4200, valid loss-1.8505, acc-0.5012, test loss-1.8094, acc-0.5221\n",
      "Iter-96510, train loss-1.8207, acc-0.5400, valid loss-1.8504, acc-0.5012, test loss-1.8094, acc-0.5221\n",
      "Iter-96520, train loss-1.7442, acc-0.5600, valid loss-1.8504, acc-0.5012, test loss-1.8094, acc-0.5222\n",
      "Iter-96530, train loss-1.8797, acc-0.4800, valid loss-1.8504, acc-0.5014, test loss-1.8093, acc-0.5223\n",
      "Iter-96540, train loss-1.7697, acc-0.5400, valid loss-1.8504, acc-0.5014, test loss-1.8093, acc-0.5222\n",
      "Iter-96550, train loss-1.9375, acc-0.5000, valid loss-1.8503, acc-0.5014, test loss-1.8093, acc-0.5222\n",
      "Iter-96560, train loss-1.8428, acc-0.5600, valid loss-1.8503, acc-0.5014, test loss-1.8092, acc-0.5222\n",
      "Iter-96570, train loss-1.8280, acc-0.5200, valid loss-1.8503, acc-0.5018, test loss-1.8092, acc-0.5223\n",
      "Iter-96580, train loss-1.9436, acc-0.4600, valid loss-1.8503, acc-0.5018, test loss-1.8092, acc-0.5222\n",
      "Iter-96590, train loss-1.9064, acc-0.4400, valid loss-1.8502, acc-0.5018, test loss-1.8092, acc-0.5223\n",
      "Iter-96600, train loss-1.7851, acc-0.5200, valid loss-1.8502, acc-0.5018, test loss-1.8091, acc-0.5223\n",
      "Iter-96610, train loss-1.7664, acc-0.5000, valid loss-1.8502, acc-0.5018, test loss-1.8091, acc-0.5223\n",
      "Iter-96620, train loss-1.8268, acc-0.4800, valid loss-1.8502, acc-0.5018, test loss-1.8091, acc-0.5223\n",
      "Iter-96630, train loss-1.8217, acc-0.4600, valid loss-1.8501, acc-0.5018, test loss-1.8090, acc-0.5222\n",
      "Iter-96640, train loss-1.8267, acc-0.5200, valid loss-1.8501, acc-0.5018, test loss-1.8090, acc-0.5223\n",
      "Iter-96650, train loss-1.7293, acc-0.5600, valid loss-1.8501, acc-0.5018, test loss-1.8090, acc-0.5223\n",
      "Iter-96660, train loss-1.7505, acc-0.5600, valid loss-1.8501, acc-0.5018, test loss-1.8090, acc-0.5222\n",
      "Iter-96670, train loss-1.8359, acc-0.5200, valid loss-1.8500, acc-0.5018, test loss-1.8089, acc-0.5221\n",
      "Iter-96680, train loss-1.9019, acc-0.5200, valid loss-1.8500, acc-0.5020, test loss-1.8089, acc-0.5220\n",
      "Iter-96690, train loss-1.8198, acc-0.5800, valid loss-1.8500, acc-0.5018, test loss-1.8089, acc-0.5223\n",
      "Iter-96700, train loss-1.7511, acc-0.5600, valid loss-1.8500, acc-0.5020, test loss-1.8089, acc-0.5221\n",
      "Iter-96710, train loss-1.8524, acc-0.5000, valid loss-1.8499, acc-0.5018, test loss-1.8088, acc-0.5220\n",
      "Iter-96720, train loss-1.8344, acc-0.4400, valid loss-1.8499, acc-0.5018, test loss-1.8088, acc-0.5219\n",
      "Iter-96730, train loss-1.7903, acc-0.6000, valid loss-1.8499, acc-0.5018, test loss-1.8088, acc-0.5221\n",
      "Iter-96740, train loss-1.6816, acc-0.7200, valid loss-1.8499, acc-0.5018, test loss-1.8087, acc-0.5220\n",
      "Iter-96750, train loss-1.7891, acc-0.6200, valid loss-1.8498, acc-0.5018, test loss-1.8087, acc-0.5220\n",
      "Iter-96760, train loss-1.8247, acc-0.5800, valid loss-1.8498, acc-0.5018, test loss-1.8087, acc-0.5220\n",
      "Iter-96770, train loss-1.8385, acc-0.4600, valid loss-1.8498, acc-0.5018, test loss-1.8087, acc-0.5220\n",
      "Iter-96780, train loss-1.8469, acc-0.4800, valid loss-1.8497, acc-0.5018, test loss-1.8086, acc-0.5222\n",
      "Iter-96790, train loss-1.9233, acc-0.5200, valid loss-1.8497, acc-0.5018, test loss-1.8086, acc-0.5221\n",
      "Iter-96800, train loss-1.8913, acc-0.4200, valid loss-1.8497, acc-0.5018, test loss-1.8086, acc-0.5222\n",
      "Iter-96810, train loss-1.8008, acc-0.4400, valid loss-1.8497, acc-0.5018, test loss-1.8085, acc-0.5222\n",
      "Iter-96820, train loss-1.8705, acc-0.4800, valid loss-1.8496, acc-0.5018, test loss-1.8085, acc-0.5220\n",
      "Iter-96830, train loss-1.7749, acc-0.5600, valid loss-1.8496, acc-0.5018, test loss-1.8085, acc-0.5221\n",
      "Iter-96840, train loss-1.9169, acc-0.4800, valid loss-1.8496, acc-0.5018, test loss-1.8085, acc-0.5222\n",
      "Iter-96850, train loss-1.8975, acc-0.5200, valid loss-1.8496, acc-0.5018, test loss-1.8084, acc-0.5220\n",
      "Iter-96860, train loss-1.7783, acc-0.5400, valid loss-1.8495, acc-0.5018, test loss-1.8084, acc-0.5219\n",
      "Iter-96870, train loss-1.7452, acc-0.6400, valid loss-1.8495, acc-0.5018, test loss-1.8084, acc-0.5220\n",
      "Iter-96880, train loss-1.7945, acc-0.5000, valid loss-1.8495, acc-0.5016, test loss-1.8083, acc-0.5220\n",
      "Iter-96890, train loss-1.7671, acc-0.5600, valid loss-1.8495, acc-0.5016, test loss-1.8083, acc-0.5220\n",
      "Iter-96900, train loss-1.7644, acc-0.5000, valid loss-1.8494, acc-0.5014, test loss-1.8083, acc-0.5220\n",
      "Iter-96910, train loss-1.8449, acc-0.4800, valid loss-1.8494, acc-0.5016, test loss-1.8083, acc-0.5222\n",
      "Iter-96920, train loss-1.7948, acc-0.4200, valid loss-1.8494, acc-0.5016, test loss-1.8082, acc-0.5221\n",
      "Iter-96930, train loss-1.8572, acc-0.4600, valid loss-1.8494, acc-0.5014, test loss-1.8082, acc-0.5222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-96940, train loss-1.8981, acc-0.4200, valid loss-1.8493, acc-0.5014, test loss-1.8082, acc-0.5223\n",
      "Iter-96950, train loss-1.7963, acc-0.5600, valid loss-1.8493, acc-0.5016, test loss-1.8081, acc-0.5221\n",
      "Iter-96960, train loss-1.8149, acc-0.4800, valid loss-1.8493, acc-0.5014, test loss-1.8081, acc-0.5223\n",
      "Iter-96970, train loss-1.8939, acc-0.5000, valid loss-1.8493, acc-0.5014, test loss-1.8081, acc-0.5219\n",
      "Iter-96980, train loss-1.7458, acc-0.6000, valid loss-1.8492, acc-0.5016, test loss-1.8081, acc-0.5217\n",
      "Iter-96990, train loss-1.9063, acc-0.4800, valid loss-1.8492, acc-0.5014, test loss-1.8080, acc-0.5218\n",
      "Iter-97000, train loss-1.7939, acc-0.6600, valid loss-1.8492, acc-0.5016, test loss-1.8080, acc-0.5217\n",
      "Iter-97010, train loss-1.7746, acc-0.5400, valid loss-1.8492, acc-0.5016, test loss-1.8080, acc-0.5217\n",
      "Iter-97020, train loss-1.7733, acc-0.5400, valid loss-1.8491, acc-0.5016, test loss-1.8079, acc-0.5219\n",
      "Iter-97030, train loss-1.6547, acc-0.6400, valid loss-1.8491, acc-0.5016, test loss-1.8079, acc-0.5219\n",
      "Iter-97040, train loss-1.8319, acc-0.5400, valid loss-1.8491, acc-0.5016, test loss-1.8079, acc-0.5219\n",
      "Iter-97050, train loss-1.8769, acc-0.4000, valid loss-1.8491, acc-0.5016, test loss-1.8079, acc-0.5218\n",
      "Iter-97060, train loss-1.8084, acc-0.5600, valid loss-1.8490, acc-0.5016, test loss-1.8078, acc-0.5218\n",
      "Iter-97070, train loss-1.8249, acc-0.4800, valid loss-1.8490, acc-0.5014, test loss-1.8078, acc-0.5218\n",
      "Iter-97080, train loss-1.8092, acc-0.5200, valid loss-1.8490, acc-0.5014, test loss-1.8078, acc-0.5218\n",
      "Iter-97090, train loss-1.7910, acc-0.5400, valid loss-1.8490, acc-0.5014, test loss-1.8077, acc-0.5217\n",
      "Iter-97100, train loss-1.8112, acc-0.5400, valid loss-1.8489, acc-0.5014, test loss-1.8077, acc-0.5218\n",
      "Iter-97110, train loss-1.7907, acc-0.5600, valid loss-1.8489, acc-0.5014, test loss-1.8077, acc-0.5218\n",
      "Iter-97120, train loss-1.7457, acc-0.5200, valid loss-1.8489, acc-0.5014, test loss-1.8077, acc-0.5219\n",
      "Iter-97130, train loss-1.8607, acc-0.4400, valid loss-1.8489, acc-0.5016, test loss-1.8076, acc-0.5219\n",
      "Iter-97140, train loss-1.8485, acc-0.4000, valid loss-1.8488, acc-0.5016, test loss-1.8076, acc-0.5220\n",
      "Iter-97150, train loss-1.9528, acc-0.3800, valid loss-1.8488, acc-0.5016, test loss-1.8076, acc-0.5219\n",
      "Iter-97160, train loss-1.8305, acc-0.5400, valid loss-1.8488, acc-0.5018, test loss-1.8076, acc-0.5220\n",
      "Iter-97170, train loss-1.8552, acc-0.4400, valid loss-1.8488, acc-0.5016, test loss-1.8075, acc-0.5219\n",
      "Iter-97180, train loss-1.8845, acc-0.5000, valid loss-1.8487, acc-0.5014, test loss-1.8075, acc-0.5219\n",
      "Iter-97190, train loss-1.7993, acc-0.5000, valid loss-1.8487, acc-0.5016, test loss-1.8075, acc-0.5220\n",
      "Iter-97200, train loss-1.8954, acc-0.4400, valid loss-1.8487, acc-0.5016, test loss-1.8074, acc-0.5220\n",
      "Iter-97210, train loss-1.7905, acc-0.5200, valid loss-1.8486, acc-0.5018, test loss-1.8074, acc-0.5219\n",
      "Iter-97220, train loss-1.9164, acc-0.4800, valid loss-1.8486, acc-0.5018, test loss-1.8074, acc-0.5220\n",
      "Iter-97230, train loss-1.8202, acc-0.5400, valid loss-1.8486, acc-0.5018, test loss-1.8074, acc-0.5219\n",
      "Iter-97240, train loss-1.8578, acc-0.5400, valid loss-1.8486, acc-0.5018, test loss-1.8073, acc-0.5219\n",
      "Iter-97250, train loss-1.8583, acc-0.4400, valid loss-1.8485, acc-0.5018, test loss-1.8073, acc-0.5218\n",
      "Iter-97260, train loss-1.7891, acc-0.5800, valid loss-1.8485, acc-0.5018, test loss-1.8073, acc-0.5218\n",
      "Iter-97270, train loss-1.7982, acc-0.5000, valid loss-1.8485, acc-0.5016, test loss-1.8072, acc-0.5220\n",
      "Iter-97280, train loss-1.8483, acc-0.5000, valid loss-1.8485, acc-0.5016, test loss-1.8072, acc-0.5218\n",
      "Iter-97290, train loss-1.8072, acc-0.5800, valid loss-1.8484, acc-0.5016, test loss-1.8072, acc-0.5220\n",
      "Iter-97300, train loss-1.8435, acc-0.4800, valid loss-1.8484, acc-0.5014, test loss-1.8072, acc-0.5221\n",
      "Iter-97310, train loss-1.8073, acc-0.5200, valid loss-1.8484, acc-0.5016, test loss-1.8071, acc-0.5220\n",
      "Iter-97320, train loss-1.8965, acc-0.4400, valid loss-1.8484, acc-0.5014, test loss-1.8071, acc-0.5221\n",
      "Iter-97330, train loss-1.8823, acc-0.4400, valid loss-1.8483, acc-0.5016, test loss-1.8071, acc-0.5221\n",
      "Iter-97340, train loss-1.8989, acc-0.4800, valid loss-1.8483, acc-0.5016, test loss-1.8071, acc-0.5219\n",
      "Iter-97350, train loss-1.8189, acc-0.5600, valid loss-1.8483, acc-0.5016, test loss-1.8070, acc-0.5220\n",
      "Iter-97360, train loss-1.8945, acc-0.4600, valid loss-1.8482, acc-0.5016, test loss-1.8070, acc-0.5219\n",
      "Iter-97370, train loss-1.9609, acc-0.4000, valid loss-1.8482, acc-0.5016, test loss-1.8070, acc-0.5219\n",
      "Iter-97380, train loss-1.8359, acc-0.5000, valid loss-1.8482, acc-0.5018, test loss-1.8069, acc-0.5221\n",
      "Iter-97390, train loss-1.7958, acc-0.5800, valid loss-1.8482, acc-0.5018, test loss-1.8069, acc-0.5222\n",
      "Iter-97400, train loss-1.8023, acc-0.5600, valid loss-1.8481, acc-0.5020, test loss-1.8069, acc-0.5224\n",
      "Iter-97410, train loss-1.9895, acc-0.3000, valid loss-1.8481, acc-0.5018, test loss-1.8069, acc-0.5223\n",
      "Iter-97420, train loss-1.8474, acc-0.5200, valid loss-1.8481, acc-0.5018, test loss-1.8068, acc-0.5220\n",
      "Iter-97430, train loss-1.9128, acc-0.4000, valid loss-1.8481, acc-0.5018, test loss-1.8068, acc-0.5221\n",
      "Iter-97440, train loss-1.8547, acc-0.4200, valid loss-1.8480, acc-0.5018, test loss-1.8068, acc-0.5221\n",
      "Iter-97450, train loss-1.9341, acc-0.4200, valid loss-1.8480, acc-0.5018, test loss-1.8068, acc-0.5220\n",
      "Iter-97460, train loss-1.7418, acc-0.6400, valid loss-1.8480, acc-0.5016, test loss-1.8067, acc-0.5219\n",
      "Iter-97470, train loss-1.8514, acc-0.4600, valid loss-1.8480, acc-0.5016, test loss-1.8067, acc-0.5220\n",
      "Iter-97480, train loss-1.8218, acc-0.5200, valid loss-1.8480, acc-0.5018, test loss-1.8067, acc-0.5223\n",
      "Iter-97490, train loss-1.8093, acc-0.5600, valid loss-1.8479, acc-0.5018, test loss-1.8067, acc-0.5223\n",
      "Iter-97500, train loss-1.8369, acc-0.5800, valid loss-1.8479, acc-0.5018, test loss-1.8066, acc-0.5222\n",
      "Iter-97510, train loss-1.7976, acc-0.5400, valid loss-1.8479, acc-0.5018, test loss-1.8066, acc-0.5223\n",
      "Iter-97520, train loss-1.9585, acc-0.4000, valid loss-1.8478, acc-0.5018, test loss-1.8066, acc-0.5224\n",
      "Iter-97530, train loss-1.8115, acc-0.5000, valid loss-1.8478, acc-0.5020, test loss-1.8065, acc-0.5225\n",
      "Iter-97540, train loss-1.9043, acc-0.4600, valid loss-1.8478, acc-0.5018, test loss-1.8065, acc-0.5223\n",
      "Iter-97550, train loss-1.7844, acc-0.5600, valid loss-1.8478, acc-0.5018, test loss-1.8065, acc-0.5223\n",
      "Iter-97560, train loss-1.8460, acc-0.5400, valid loss-1.8477, acc-0.5018, test loss-1.8065, acc-0.5223\n",
      "Iter-97570, train loss-1.7971, acc-0.4600, valid loss-1.8477, acc-0.5018, test loss-1.8064, acc-0.5224\n",
      "Iter-97580, train loss-1.7485, acc-0.5800, valid loss-1.8477, acc-0.5018, test loss-1.8064, acc-0.5224\n",
      "Iter-97590, train loss-1.8229, acc-0.4800, valid loss-1.8477, acc-0.5018, test loss-1.8064, acc-0.5224\n",
      "Iter-97600, train loss-1.8465, acc-0.4400, valid loss-1.8476, acc-0.5020, test loss-1.8063, acc-0.5224\n",
      "Iter-97610, train loss-1.8810, acc-0.4600, valid loss-1.8476, acc-0.5018, test loss-1.8063, acc-0.5224\n",
      "Iter-97620, train loss-1.8018, acc-0.4400, valid loss-1.8476, acc-0.5020, test loss-1.8063, acc-0.5225\n",
      "Iter-97630, train loss-1.7448, acc-0.6400, valid loss-1.8476, acc-0.5018, test loss-1.8063, acc-0.5222\n",
      "Iter-97640, train loss-1.8638, acc-0.4600, valid loss-1.8475, acc-0.5020, test loss-1.8062, acc-0.5223\n",
      "Iter-97650, train loss-1.8494, acc-0.4800, valid loss-1.8475, acc-0.5020, test loss-1.8062, acc-0.5223\n",
      "Iter-97660, train loss-1.7379, acc-0.5000, valid loss-1.8475, acc-0.5018, test loss-1.8062, acc-0.5223\n",
      "Iter-97670, train loss-1.8075, acc-0.5000, valid loss-1.8475, acc-0.5016, test loss-1.8061, acc-0.5224\n",
      "Iter-97680, train loss-1.8385, acc-0.4800, valid loss-1.8474, acc-0.5018, test loss-1.8061, acc-0.5222\n",
      "Iter-97690, train loss-1.8333, acc-0.5400, valid loss-1.8474, acc-0.5018, test loss-1.8061, acc-0.5221\n",
      "Iter-97700, train loss-1.7809, acc-0.5400, valid loss-1.8474, acc-0.5020, test loss-1.8061, acc-0.5221\n",
      "Iter-97710, train loss-1.8471, acc-0.4800, valid loss-1.8474, acc-0.5018, test loss-1.8060, acc-0.5221\n",
      "Iter-97720, train loss-1.8350, acc-0.4200, valid loss-1.8473, acc-0.5018, test loss-1.8060, acc-0.5220\n",
      "Iter-97730, train loss-1.9133, acc-0.4400, valid loss-1.8473, acc-0.5018, test loss-1.8060, acc-0.5221\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-97740, train loss-1.7770, acc-0.6000, valid loss-1.8473, acc-0.5018, test loss-1.8060, acc-0.5221\n",
      "Iter-97750, train loss-1.8074, acc-0.4600, valid loss-1.8473, acc-0.5020, test loss-1.8059, acc-0.5223\n",
      "Iter-97760, train loss-1.7782, acc-0.5600, valid loss-1.8472, acc-0.5020, test loss-1.8059, acc-0.5223\n",
      "Iter-97770, train loss-1.8484, acc-0.4800, valid loss-1.8472, acc-0.5016, test loss-1.8059, acc-0.5225\n",
      "Iter-97780, train loss-1.9480, acc-0.4600, valid loss-1.8472, acc-0.5016, test loss-1.8058, acc-0.5222\n",
      "Iter-97790, train loss-1.7906, acc-0.6200, valid loss-1.8472, acc-0.5016, test loss-1.8058, acc-0.5221\n",
      "Iter-97800, train loss-1.8139, acc-0.5800, valid loss-1.8471, acc-0.5016, test loss-1.8058, acc-0.5220\n",
      "Iter-97810, train loss-1.8314, acc-0.5200, valid loss-1.8471, acc-0.5016, test loss-1.8058, acc-0.5222\n",
      "Iter-97820, train loss-1.8233, acc-0.5400, valid loss-1.8471, acc-0.5016, test loss-1.8057, acc-0.5221\n",
      "Iter-97830, train loss-1.9121, acc-0.4000, valid loss-1.8471, acc-0.5016, test loss-1.8057, acc-0.5218\n",
      "Iter-97840, train loss-1.8038, acc-0.4800, valid loss-1.8470, acc-0.5016, test loss-1.8057, acc-0.5221\n",
      "Iter-97850, train loss-1.8508, acc-0.5000, valid loss-1.8470, acc-0.5016, test loss-1.8056, acc-0.5219\n",
      "Iter-97860, train loss-1.8268, acc-0.5200, valid loss-1.8470, acc-0.5014, test loss-1.8056, acc-0.5221\n",
      "Iter-97870, train loss-1.8677, acc-0.5000, valid loss-1.8470, acc-0.5016, test loss-1.8056, acc-0.5220\n",
      "Iter-97880, train loss-1.7909, acc-0.5400, valid loss-1.8469, acc-0.5016, test loss-1.8056, acc-0.5220\n",
      "Iter-97890, train loss-1.7874, acc-0.5800, valid loss-1.8469, acc-0.5014, test loss-1.8055, acc-0.5222\n",
      "Iter-97900, train loss-1.8133, acc-0.4000, valid loss-1.8469, acc-0.5014, test loss-1.8055, acc-0.5221\n",
      "Iter-97910, train loss-1.9009, acc-0.5400, valid loss-1.8469, acc-0.5014, test loss-1.8055, acc-0.5221\n",
      "Iter-97920, train loss-1.8023, acc-0.5400, valid loss-1.8468, acc-0.5016, test loss-1.8054, acc-0.5220\n",
      "Iter-97930, train loss-1.7792, acc-0.6600, valid loss-1.8468, acc-0.5016, test loss-1.8054, acc-0.5222\n",
      "Iter-97940, train loss-1.7163, acc-0.6400, valid loss-1.8468, acc-0.5014, test loss-1.8054, acc-0.5223\n",
      "Iter-97950, train loss-1.8224, acc-0.5000, valid loss-1.8468, acc-0.5014, test loss-1.8054, acc-0.5221\n",
      "Iter-97960, train loss-1.7765, acc-0.5800, valid loss-1.8467, acc-0.5014, test loss-1.8053, acc-0.5219\n",
      "Iter-97970, train loss-1.8294, acc-0.5200, valid loss-1.8467, acc-0.5014, test loss-1.8053, acc-0.5220\n",
      "Iter-97980, train loss-1.7468, acc-0.5200, valid loss-1.8467, acc-0.5014, test loss-1.8053, acc-0.5221\n",
      "Iter-97990, train loss-1.6876, acc-0.6200, valid loss-1.8467, acc-0.5014, test loss-1.8052, acc-0.5221\n",
      "Iter-98000, train loss-1.8184, acc-0.5200, valid loss-1.8466, acc-0.5014, test loss-1.8052, acc-0.5221\n",
      "Iter-98010, train loss-1.7502, acc-0.5800, valid loss-1.8466, acc-0.5014, test loss-1.8052, acc-0.5221\n",
      "Iter-98020, train loss-1.8279, acc-0.6000, valid loss-1.8466, acc-0.5014, test loss-1.8052, acc-0.5221\n",
      "Iter-98030, train loss-1.8123, acc-0.5400, valid loss-1.8465, acc-0.5012, test loss-1.8051, acc-0.5223\n",
      "Iter-98040, train loss-1.8134, acc-0.6200, valid loss-1.8465, acc-0.5014, test loss-1.8051, acc-0.5222\n",
      "Iter-98050, train loss-1.7639, acc-0.7000, valid loss-1.8465, acc-0.5014, test loss-1.8051, acc-0.5222\n",
      "Iter-98060, train loss-1.8440, acc-0.4400, valid loss-1.8465, acc-0.5014, test loss-1.8051, acc-0.5222\n",
      "Iter-98070, train loss-1.7053, acc-0.6000, valid loss-1.8464, acc-0.5014, test loss-1.8050, acc-0.5223\n",
      "Iter-98080, train loss-1.7819, acc-0.4600, valid loss-1.8464, acc-0.5012, test loss-1.8050, acc-0.5225\n",
      "Iter-98090, train loss-1.7270, acc-0.5400, valid loss-1.8464, acc-0.5016, test loss-1.8050, acc-0.5225\n",
      "Iter-98100, train loss-1.7429, acc-0.5800, valid loss-1.8464, acc-0.5014, test loss-1.8049, acc-0.5224\n",
      "Iter-98110, train loss-1.8288, acc-0.5200, valid loss-1.8463, acc-0.5016, test loss-1.8049, acc-0.5223\n",
      "Iter-98120, train loss-1.7810, acc-0.6000, valid loss-1.8463, acc-0.5018, test loss-1.8049, acc-0.5225\n",
      "Iter-98130, train loss-1.9132, acc-0.3800, valid loss-1.8463, acc-0.5018, test loss-1.8049, acc-0.5224\n",
      "Iter-98140, train loss-1.8817, acc-0.4000, valid loss-1.8463, acc-0.5014, test loss-1.8048, acc-0.5224\n",
      "Iter-98150, train loss-1.7829, acc-0.5200, valid loss-1.8463, acc-0.5014, test loss-1.8048, acc-0.5223\n",
      "Iter-98160, train loss-1.8240, acc-0.5200, valid loss-1.8462, acc-0.5016, test loss-1.8048, acc-0.5225\n",
      "Iter-98170, train loss-1.6812, acc-0.6200, valid loss-1.8462, acc-0.5016, test loss-1.8047, acc-0.5224\n",
      "Iter-98180, train loss-1.7333, acc-0.5800, valid loss-1.8462, acc-0.5016, test loss-1.8047, acc-0.5225\n",
      "Iter-98190, train loss-1.8424, acc-0.4600, valid loss-1.8462, acc-0.5014, test loss-1.8047, acc-0.5225\n",
      "Iter-98200, train loss-1.6792, acc-0.7200, valid loss-1.8461, acc-0.5014, test loss-1.8047, acc-0.5225\n",
      "Iter-98210, train loss-1.7738, acc-0.4600, valid loss-1.8461, acc-0.5016, test loss-1.8046, acc-0.5224\n",
      "Iter-98220, train loss-1.8000, acc-0.6000, valid loss-1.8461, acc-0.5016, test loss-1.8046, acc-0.5223\n",
      "Iter-98230, train loss-1.8497, acc-0.4200, valid loss-1.8461, acc-0.5014, test loss-1.8046, acc-0.5223\n",
      "Iter-98240, train loss-1.7108, acc-0.5800, valid loss-1.8460, acc-0.5016, test loss-1.8046, acc-0.5223\n",
      "Iter-98250, train loss-1.8088, acc-0.5800, valid loss-1.8460, acc-0.5016, test loss-1.8045, acc-0.5224\n",
      "Iter-98260, train loss-1.7504, acc-0.5400, valid loss-1.8460, acc-0.5016, test loss-1.8045, acc-0.5223\n",
      "Iter-98270, train loss-1.8239, acc-0.4800, valid loss-1.8460, acc-0.5014, test loss-1.8045, acc-0.5224\n",
      "Iter-98280, train loss-1.7447, acc-0.5600, valid loss-1.8459, acc-0.5014, test loss-1.8044, acc-0.5224\n",
      "Iter-98290, train loss-1.8059, acc-0.6400, valid loss-1.8459, acc-0.5014, test loss-1.8044, acc-0.5224\n",
      "Iter-98300, train loss-1.8356, acc-0.5400, valid loss-1.8459, acc-0.5014, test loss-1.8044, acc-0.5223\n",
      "Iter-98310, train loss-1.9324, acc-0.4800, valid loss-1.8459, acc-0.5016, test loss-1.8044, acc-0.5224\n",
      "Iter-98320, train loss-1.7278, acc-0.5400, valid loss-1.8458, acc-0.5016, test loss-1.8043, acc-0.5225\n",
      "Iter-98330, train loss-1.8181, acc-0.4200, valid loss-1.8458, acc-0.5016, test loss-1.8043, acc-0.5224\n",
      "Iter-98340, train loss-1.7891, acc-0.4000, valid loss-1.8458, acc-0.5016, test loss-1.8043, acc-0.5225\n",
      "Iter-98350, train loss-1.8777, acc-0.5400, valid loss-1.8457, acc-0.5016, test loss-1.8043, acc-0.5226\n",
      "Iter-98360, train loss-1.8527, acc-0.5000, valid loss-1.8457, acc-0.5014, test loss-1.8042, acc-0.5224\n",
      "Iter-98370, train loss-1.8106, acc-0.5000, valid loss-1.8457, acc-0.5014, test loss-1.8042, acc-0.5226\n",
      "Iter-98380, train loss-1.8885, acc-0.4400, valid loss-1.8457, acc-0.5014, test loss-1.8042, acc-0.5226\n",
      "Iter-98390, train loss-1.8263, acc-0.5200, valid loss-1.8456, acc-0.5014, test loss-1.8041, acc-0.5227\n",
      "Iter-98400, train loss-1.8522, acc-0.4200, valid loss-1.8456, acc-0.5014, test loss-1.8041, acc-0.5226\n",
      "Iter-98410, train loss-1.8212, acc-0.4400, valid loss-1.8456, acc-0.5014, test loss-1.8041, acc-0.5226\n",
      "Iter-98420, train loss-1.7940, acc-0.5400, valid loss-1.8456, acc-0.5014, test loss-1.8041, acc-0.5225\n",
      "Iter-98430, train loss-1.6837, acc-0.7000, valid loss-1.8456, acc-0.5014, test loss-1.8040, acc-0.5225\n",
      "Iter-98440, train loss-1.9198, acc-0.4800, valid loss-1.8455, acc-0.5014, test loss-1.8040, acc-0.5225\n",
      "Iter-98450, train loss-1.7929, acc-0.5000, valid loss-1.8455, acc-0.5014, test loss-1.8040, acc-0.5226\n",
      "Iter-98460, train loss-1.7888, acc-0.5600, valid loss-1.8455, acc-0.5016, test loss-1.8040, acc-0.5225\n",
      "Iter-98470, train loss-1.8361, acc-0.5200, valid loss-1.8454, acc-0.5016, test loss-1.8039, acc-0.5226\n",
      "Iter-98480, train loss-1.6680, acc-0.7400, valid loss-1.8454, acc-0.5016, test loss-1.8039, acc-0.5225\n",
      "Iter-98490, train loss-1.7999, acc-0.5600, valid loss-1.8454, acc-0.5016, test loss-1.8039, acc-0.5225\n",
      "Iter-98500, train loss-1.8541, acc-0.5600, valid loss-1.8454, acc-0.5018, test loss-1.8038, acc-0.5229\n",
      "Iter-98510, train loss-1.8985, acc-0.3800, valid loss-1.8453, acc-0.5018, test loss-1.8038, acc-0.5229\n",
      "Iter-98520, train loss-1.8999, acc-0.4400, valid loss-1.8453, acc-0.5018, test loss-1.8038, acc-0.5230\n",
      "Iter-98530, train loss-1.8132, acc-0.6000, valid loss-1.8453, acc-0.5018, test loss-1.8038, acc-0.5231\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-98540, train loss-1.7225, acc-0.6600, valid loss-1.8453, acc-0.5018, test loss-1.8037, acc-0.5231\n",
      "Iter-98550, train loss-1.7865, acc-0.6000, valid loss-1.8452, acc-0.5016, test loss-1.8037, acc-0.5229\n",
      "Iter-98560, train loss-1.7622, acc-0.5000, valid loss-1.8452, acc-0.5018, test loss-1.8037, acc-0.5227\n",
      "Iter-98570, train loss-1.8276, acc-0.4600, valid loss-1.8452, acc-0.5018, test loss-1.8036, acc-0.5227\n",
      "Iter-98580, train loss-1.8094, acc-0.5600, valid loss-1.8452, acc-0.5016, test loss-1.8036, acc-0.5227\n",
      "Iter-98590, train loss-1.8603, acc-0.5200, valid loss-1.8451, acc-0.5016, test loss-1.8036, acc-0.5231\n",
      "Iter-98600, train loss-1.8298, acc-0.5000, valid loss-1.8451, acc-0.5018, test loss-1.8036, acc-0.5231\n",
      "Iter-98610, train loss-1.7023, acc-0.6200, valid loss-1.8451, acc-0.5016, test loss-1.8035, acc-0.5229\n",
      "Iter-98620, train loss-1.7985, acc-0.5000, valid loss-1.8451, acc-0.5016, test loss-1.8035, acc-0.5229\n",
      "Iter-98630, train loss-1.8886, acc-0.3800, valid loss-1.8450, acc-0.5016, test loss-1.8035, acc-0.5230\n",
      "Iter-98640, train loss-1.8451, acc-0.5200, valid loss-1.8450, acc-0.5016, test loss-1.8035, acc-0.5230\n",
      "Iter-98650, train loss-1.7733, acc-0.6000, valid loss-1.8450, acc-0.5016, test loss-1.8034, acc-0.5229\n",
      "Iter-98660, train loss-1.9014, acc-0.4400, valid loss-1.8450, acc-0.5016, test loss-1.8034, acc-0.5230\n",
      "Iter-98670, train loss-1.7830, acc-0.5600, valid loss-1.8449, acc-0.5016, test loss-1.8034, acc-0.5231\n",
      "Iter-98680, train loss-1.8517, acc-0.4600, valid loss-1.8449, acc-0.5016, test loss-1.8033, acc-0.5231\n",
      "Iter-98690, train loss-1.7490, acc-0.6000, valid loss-1.8449, acc-0.5016, test loss-1.8033, acc-0.5230\n",
      "Iter-98700, train loss-1.7222, acc-0.6400, valid loss-1.8449, acc-0.5016, test loss-1.8033, acc-0.5229\n",
      "Iter-98710, train loss-1.8887, acc-0.5000, valid loss-1.8448, acc-0.5016, test loss-1.8033, acc-0.5230\n",
      "Iter-98720, train loss-1.7021, acc-0.6200, valid loss-1.8448, acc-0.5016, test loss-1.8032, acc-0.5229\n",
      "Iter-98730, train loss-1.8214, acc-0.5000, valid loss-1.8448, acc-0.5016, test loss-1.8032, acc-0.5226\n",
      "Iter-98740, train loss-1.7940, acc-0.5200, valid loss-1.8448, acc-0.5012, test loss-1.8032, acc-0.5228\n",
      "Iter-98750, train loss-1.8098, acc-0.5400, valid loss-1.8447, acc-0.5014, test loss-1.8032, acc-0.5228\n",
      "Iter-98760, train loss-1.8121, acc-0.4800, valid loss-1.8447, acc-0.5016, test loss-1.8031, acc-0.5226\n",
      "Iter-98770, train loss-1.7220, acc-0.5200, valid loss-1.8447, acc-0.5014, test loss-1.8031, acc-0.5228\n",
      "Iter-98780, train loss-1.9252, acc-0.4400, valid loss-1.8447, acc-0.5014, test loss-1.8031, acc-0.5230\n",
      "Iter-98790, train loss-1.7839, acc-0.5000, valid loss-1.8446, acc-0.5014, test loss-1.8030, acc-0.5232\n",
      "Iter-98800, train loss-1.8594, acc-0.3800, valid loss-1.8446, acc-0.5014, test loss-1.8030, acc-0.5230\n",
      "Iter-98810, train loss-1.8804, acc-0.4000, valid loss-1.8446, acc-0.5016, test loss-1.8030, acc-0.5230\n",
      "Iter-98820, train loss-1.6972, acc-0.6800, valid loss-1.8446, acc-0.5018, test loss-1.8030, acc-0.5229\n",
      "Iter-98830, train loss-1.7667, acc-0.5800, valid loss-1.8445, acc-0.5016, test loss-1.8029, acc-0.5230\n",
      "Iter-98840, train loss-1.8432, acc-0.4000, valid loss-1.8445, acc-0.5016, test loss-1.8029, acc-0.5232\n",
      "Iter-98850, train loss-1.8881, acc-0.4600, valid loss-1.8445, acc-0.5016, test loss-1.8029, acc-0.5231\n",
      "Iter-98860, train loss-1.9783, acc-0.3600, valid loss-1.8445, acc-0.5016, test loss-1.8029, acc-0.5231\n",
      "Iter-98870, train loss-1.8462, acc-0.4400, valid loss-1.8444, acc-0.5018, test loss-1.8028, acc-0.5230\n",
      "Iter-98880, train loss-1.8073, acc-0.4200, valid loss-1.8444, acc-0.5018, test loss-1.8028, acc-0.5231\n",
      "Iter-98890, train loss-1.7173, acc-0.5800, valid loss-1.8444, acc-0.5016, test loss-1.8028, acc-0.5231\n",
      "Iter-98900, train loss-1.6918, acc-0.6000, valid loss-1.8444, acc-0.5018, test loss-1.8027, acc-0.5231\n",
      "Iter-98910, train loss-1.8061, acc-0.4600, valid loss-1.8443, acc-0.5018, test loss-1.8027, acc-0.5231\n",
      "Iter-98920, train loss-1.7791, acc-0.4600, valid loss-1.8443, acc-0.5018, test loss-1.8027, acc-0.5230\n",
      "Iter-98930, train loss-1.7946, acc-0.5000, valid loss-1.8443, acc-0.5018, test loss-1.8027, acc-0.5230\n",
      "Iter-98940, train loss-1.8667, acc-0.4400, valid loss-1.8443, acc-0.5016, test loss-1.8026, acc-0.5230\n",
      "Iter-98950, train loss-1.8060, acc-0.5000, valid loss-1.8442, acc-0.5016, test loss-1.8026, acc-0.5231\n",
      "Iter-98960, train loss-1.8337, acc-0.4800, valid loss-1.8442, acc-0.5018, test loss-1.8026, acc-0.5230\n",
      "Iter-98970, train loss-1.7916, acc-0.5400, valid loss-1.8442, acc-0.5018, test loss-1.8026, acc-0.5230\n",
      "Iter-98980, train loss-1.7959, acc-0.5000, valid loss-1.8441, acc-0.5018, test loss-1.8025, acc-0.5230\n",
      "Iter-98990, train loss-1.8723, acc-0.5600, valid loss-1.8441, acc-0.5018, test loss-1.8025, acc-0.5230\n",
      "Iter-99000, train loss-1.8484, acc-0.4600, valid loss-1.8441, acc-0.5018, test loss-1.8025, acc-0.5230\n",
      "Iter-99010, train loss-1.8190, acc-0.4800, valid loss-1.8441, acc-0.5018, test loss-1.8024, acc-0.5229\n",
      "Iter-99020, train loss-1.8649, acc-0.3800, valid loss-1.8440, acc-0.5018, test loss-1.8024, acc-0.5228\n",
      "Iter-99030, train loss-1.8151, acc-0.4800, valid loss-1.8440, acc-0.5018, test loss-1.8024, acc-0.5230\n",
      "Iter-99040, train loss-1.8406, acc-0.5200, valid loss-1.8440, acc-0.5018, test loss-1.8024, acc-0.5229\n",
      "Iter-99050, train loss-1.9175, acc-0.4400, valid loss-1.8440, acc-0.5018, test loss-1.8023, acc-0.5229\n",
      "Iter-99060, train loss-1.8081, acc-0.4400, valid loss-1.8439, acc-0.5018, test loss-1.8023, acc-0.5229\n",
      "Iter-99070, train loss-1.8345, acc-0.4200, valid loss-1.8439, acc-0.5018, test loss-1.8023, acc-0.5230\n",
      "Iter-99080, train loss-1.7772, acc-0.5600, valid loss-1.8439, acc-0.5018, test loss-1.8023, acc-0.5230\n",
      "Iter-99090, train loss-1.8618, acc-0.3600, valid loss-1.8439, acc-0.5018, test loss-1.8022, acc-0.5231\n",
      "Iter-99100, train loss-1.7593, acc-0.5800, valid loss-1.8438, acc-0.5018, test loss-1.8022, acc-0.5232\n",
      "Iter-99110, train loss-1.9053, acc-0.4600, valid loss-1.8438, acc-0.5018, test loss-1.8022, acc-0.5231\n",
      "Iter-99120, train loss-1.8685, acc-0.4600, valid loss-1.8438, acc-0.5018, test loss-1.8021, acc-0.5229\n",
      "Iter-99130, train loss-1.8007, acc-0.5600, valid loss-1.8438, acc-0.5018, test loss-1.8021, acc-0.5229\n",
      "Iter-99140, train loss-1.7935, acc-0.5800, valid loss-1.8437, acc-0.5018, test loss-1.8021, acc-0.5229\n",
      "Iter-99150, train loss-1.7113, acc-0.5800, valid loss-1.8437, acc-0.5018, test loss-1.8021, acc-0.5232\n",
      "Iter-99160, train loss-1.8462, acc-0.5400, valid loss-1.8437, acc-0.5018, test loss-1.8020, acc-0.5231\n",
      "Iter-99170, train loss-1.8401, acc-0.4400, valid loss-1.8437, acc-0.5018, test loss-1.8020, acc-0.5232\n",
      "Iter-99180, train loss-1.7170, acc-0.5400, valid loss-1.8436, acc-0.5018, test loss-1.8020, acc-0.5233\n",
      "Iter-99190, train loss-1.8308, acc-0.4200, valid loss-1.8436, acc-0.5018, test loss-1.8019, acc-0.5236\n",
      "Iter-99200, train loss-1.8672, acc-0.4600, valid loss-1.8436, acc-0.5018, test loss-1.8019, acc-0.5235\n",
      "Iter-99210, train loss-1.7855, acc-0.5000, valid loss-1.8436, acc-0.5018, test loss-1.8019, acc-0.5236\n",
      "Iter-99220, train loss-1.6490, acc-0.6600, valid loss-1.8435, acc-0.5018, test loss-1.8019, acc-0.5238\n",
      "Iter-99230, train loss-1.8068, acc-0.4800, valid loss-1.8435, acc-0.5018, test loss-1.8018, acc-0.5236\n",
      "Iter-99240, train loss-1.7711, acc-0.6000, valid loss-1.8435, acc-0.5018, test loss-1.8018, acc-0.5236\n",
      "Iter-99250, train loss-1.7253, acc-0.7200, valid loss-1.8435, acc-0.5018, test loss-1.8018, acc-0.5236\n",
      "Iter-99260, train loss-1.7763, acc-0.5800, valid loss-1.8434, acc-0.5018, test loss-1.8017, acc-0.5237\n",
      "Iter-99270, train loss-1.8741, acc-0.5000, valid loss-1.8434, acc-0.5018, test loss-1.8017, acc-0.5234\n",
      "Iter-99280, train loss-1.9059, acc-0.4000, valid loss-1.8434, acc-0.5018, test loss-1.8017, acc-0.5235\n",
      "Iter-99290, train loss-1.7674, acc-0.5200, valid loss-1.8434, acc-0.5018, test loss-1.8017, acc-0.5233\n",
      "Iter-99300, train loss-1.8077, acc-0.5400, valid loss-1.8433, acc-0.5016, test loss-1.8016, acc-0.5233\n",
      "Iter-99310, train loss-1.7951, acc-0.5000, valid loss-1.8433, acc-0.5018, test loss-1.8016, acc-0.5233\n",
      "Iter-99320, train loss-1.8724, acc-0.5800, valid loss-1.8433, acc-0.5018, test loss-1.8016, acc-0.5235\n",
      "Iter-99330, train loss-1.9089, acc-0.4000, valid loss-1.8433, acc-0.5018, test loss-1.8016, acc-0.5233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-99340, train loss-1.8533, acc-0.3800, valid loss-1.8432, acc-0.5016, test loss-1.8015, acc-0.5234\n",
      "Iter-99350, train loss-1.7319, acc-0.5600, valid loss-1.8432, acc-0.5016, test loss-1.8015, acc-0.5235\n",
      "Iter-99360, train loss-1.8960, acc-0.4600, valid loss-1.8432, acc-0.5018, test loss-1.8015, acc-0.5234\n",
      "Iter-99370, train loss-1.8475, acc-0.5400, valid loss-1.8431, acc-0.5018, test loss-1.8014, acc-0.5234\n",
      "Iter-99380, train loss-1.9101, acc-0.4800, valid loss-1.8431, acc-0.5016, test loss-1.8014, acc-0.5233\n",
      "Iter-99390, train loss-1.8698, acc-0.5000, valid loss-1.8431, acc-0.5018, test loss-1.8014, acc-0.5233\n",
      "Iter-99400, train loss-1.8766, acc-0.5000, valid loss-1.8431, acc-0.5018, test loss-1.8014, acc-0.5233\n",
      "Iter-99410, train loss-1.8007, acc-0.5400, valid loss-1.8430, acc-0.5018, test loss-1.8013, acc-0.5232\n",
      "Iter-99420, train loss-1.8383, acc-0.4400, valid loss-1.8430, acc-0.5018, test loss-1.8013, acc-0.5230\n",
      "Iter-99430, train loss-1.8274, acc-0.4800, valid loss-1.8430, acc-0.5018, test loss-1.8013, acc-0.5230\n",
      "Iter-99440, train loss-1.9065, acc-0.4400, valid loss-1.8430, acc-0.5016, test loss-1.8013, acc-0.5230\n",
      "Iter-99450, train loss-1.8178, acc-0.4600, valid loss-1.8429, acc-0.5016, test loss-1.8012, acc-0.5230\n",
      "Iter-99460, train loss-1.7345, acc-0.6000, valid loss-1.8429, acc-0.5016, test loss-1.8012, acc-0.5231\n",
      "Iter-99470, train loss-1.8880, acc-0.3800, valid loss-1.8429, acc-0.5016, test loss-1.8012, acc-0.5234\n",
      "Iter-99480, train loss-1.8212, acc-0.4400, valid loss-1.8429, acc-0.5016, test loss-1.8011, acc-0.5232\n",
      "Iter-99490, train loss-1.8067, acc-0.5000, valid loss-1.8428, acc-0.5016, test loss-1.8011, acc-0.5233\n",
      "Iter-99500, train loss-1.7536, acc-0.6400, valid loss-1.8428, acc-0.5016, test loss-1.8011, acc-0.5232\n",
      "Iter-99510, train loss-1.8347, acc-0.5000, valid loss-1.8428, acc-0.5018, test loss-1.8011, acc-0.5233\n",
      "Iter-99520, train loss-1.8452, acc-0.4600, valid loss-1.8428, acc-0.5018, test loss-1.8010, acc-0.5232\n",
      "Iter-99530, train loss-1.8553, acc-0.4400, valid loss-1.8427, acc-0.5016, test loss-1.8010, acc-0.5233\n",
      "Iter-99540, train loss-1.8365, acc-0.5800, valid loss-1.8427, acc-0.5018, test loss-1.8010, acc-0.5234\n",
      "Iter-99550, train loss-1.8802, acc-0.4400, valid loss-1.8427, acc-0.5018, test loss-1.8009, acc-0.5235\n",
      "Iter-99560, train loss-1.7652, acc-0.4600, valid loss-1.8427, acc-0.5018, test loss-1.8009, acc-0.5234\n",
      "Iter-99570, train loss-1.8208, acc-0.5200, valid loss-1.8427, acc-0.5018, test loss-1.8009, acc-0.5235\n",
      "Iter-99580, train loss-1.9557, acc-0.4000, valid loss-1.8426, acc-0.5016, test loss-1.8009, acc-0.5236\n",
      "Iter-99590, train loss-1.8301, acc-0.5000, valid loss-1.8426, acc-0.5016, test loss-1.8008, acc-0.5235\n",
      "Iter-99600, train loss-1.7682, acc-0.5600, valid loss-1.8426, acc-0.5016, test loss-1.8008, acc-0.5235\n",
      "Iter-99610, train loss-1.8481, acc-0.4600, valid loss-1.8426, acc-0.5018, test loss-1.8008, acc-0.5235\n",
      "Iter-99620, train loss-1.8517, acc-0.5200, valid loss-1.8425, acc-0.5016, test loss-1.8008, acc-0.5234\n",
      "Iter-99630, train loss-1.9357, acc-0.5000, valid loss-1.8425, acc-0.5014, test loss-1.8007, acc-0.5235\n",
      "Iter-99640, train loss-1.6775, acc-0.6600, valid loss-1.8425, acc-0.5016, test loss-1.8007, acc-0.5236\n",
      "Iter-99650, train loss-1.8611, acc-0.4400, valid loss-1.8424, acc-0.5016, test loss-1.8007, acc-0.5237\n",
      "Iter-99660, train loss-1.8434, acc-0.4000, valid loss-1.8424, acc-0.5016, test loss-1.8006, acc-0.5237\n",
      "Iter-99670, train loss-1.8372, acc-0.4200, valid loss-1.8424, acc-0.5016, test loss-1.8006, acc-0.5238\n",
      "Iter-99680, train loss-1.8693, acc-0.4800, valid loss-1.8424, acc-0.5016, test loss-1.8006, acc-0.5237\n",
      "Iter-99690, train loss-1.6764, acc-0.6600, valid loss-1.8423, acc-0.5014, test loss-1.8006, acc-0.5236\n",
      "Iter-99700, train loss-1.8266, acc-0.5200, valid loss-1.8423, acc-0.5014, test loss-1.8005, acc-0.5236\n",
      "Iter-99710, train loss-1.7371, acc-0.5400, valid loss-1.8423, acc-0.5014, test loss-1.8005, acc-0.5234\n",
      "Iter-99720, train loss-1.8830, acc-0.4400, valid loss-1.8423, acc-0.5014, test loss-1.8005, acc-0.5234\n",
      "Iter-99730, train loss-1.9141, acc-0.4800, valid loss-1.8422, acc-0.5014, test loss-1.8005, acc-0.5234\n",
      "Iter-99740, train loss-1.7870, acc-0.4800, valid loss-1.8422, acc-0.5014, test loss-1.8004, acc-0.5234\n",
      "Iter-99750, train loss-1.7746, acc-0.5800, valid loss-1.8422, acc-0.5014, test loss-1.8004, acc-0.5236\n",
      "Iter-99760, train loss-1.9375, acc-0.4000, valid loss-1.8422, acc-0.5016, test loss-1.8004, acc-0.5236\n",
      "Iter-99770, train loss-1.8925, acc-0.4800, valid loss-1.8421, acc-0.5014, test loss-1.8003, acc-0.5237\n",
      "Iter-99780, train loss-1.7568, acc-0.5800, valid loss-1.8421, acc-0.5016, test loss-1.8003, acc-0.5239\n",
      "Iter-99790, train loss-1.8562, acc-0.4000, valid loss-1.8421, acc-0.5014, test loss-1.8003, acc-0.5238\n",
      "Iter-99800, train loss-1.7681, acc-0.5600, valid loss-1.8421, acc-0.5014, test loss-1.8003, acc-0.5237\n",
      "Iter-99810, train loss-1.8348, acc-0.5600, valid loss-1.8420, acc-0.5014, test loss-1.8002, acc-0.5237\n",
      "Iter-99820, train loss-1.8593, acc-0.5000, valid loss-1.8420, acc-0.5010, test loss-1.8002, acc-0.5237\n",
      "Iter-99830, train loss-1.8122, acc-0.4400, valid loss-1.8420, acc-0.5010, test loss-1.8002, acc-0.5237\n",
      "Iter-99840, train loss-1.6876, acc-0.7000, valid loss-1.8420, acc-0.5010, test loss-1.8002, acc-0.5239\n",
      "Iter-99850, train loss-1.7286, acc-0.7200, valid loss-1.8419, acc-0.5010, test loss-1.8001, acc-0.5239\n",
      "Iter-99860, train loss-1.8555, acc-0.4200, valid loss-1.8419, acc-0.5008, test loss-1.8001, acc-0.5239\n",
      "Iter-99870, train loss-1.7579, acc-0.6000, valid loss-1.8419, acc-0.5008, test loss-1.8001, acc-0.5239\n",
      "Iter-99880, train loss-1.8278, acc-0.5400, valid loss-1.8419, acc-0.5008, test loss-1.8000, acc-0.5239\n",
      "Iter-99890, train loss-1.7619, acc-0.5200, valid loss-1.8418, acc-0.5010, test loss-1.8000, acc-0.5239\n",
      "Iter-99900, train loss-1.7648, acc-0.6400, valid loss-1.8418, acc-0.5008, test loss-1.8000, acc-0.5239\n",
      "Iter-99910, train loss-1.8505, acc-0.5000, valid loss-1.8418, acc-0.5008, test loss-1.8000, acc-0.5239\n",
      "Iter-99920, train loss-1.7623, acc-0.5000, valid loss-1.8418, acc-0.5008, test loss-1.7999, acc-0.5239\n",
      "Iter-99930, train loss-1.7695, acc-0.6000, valid loss-1.8417, acc-0.5008, test loss-1.7999, acc-0.5241\n",
      "Iter-99940, train loss-1.7851, acc-0.5400, valid loss-1.8417, acc-0.5010, test loss-1.7999, acc-0.5239\n",
      "Iter-99950, train loss-1.8145, acc-0.5400, valid loss-1.8417, acc-0.5010, test loss-1.7999, acc-0.5240\n",
      "Iter-99960, train loss-1.8119, acc-0.5200, valid loss-1.8417, acc-0.5014, test loss-1.7998, acc-0.5241\n",
      "Iter-99970, train loss-1.8832, acc-0.5000, valid loss-1.8417, acc-0.5012, test loss-1.7998, acc-0.5240\n",
      "Iter-99980, train loss-1.7720, acc-0.5200, valid loss-1.8416, acc-0.5014, test loss-1.7998, acc-0.5240\n",
      "Iter-99990, train loss-1.8890, acc-0.3800, valid loss-1.8416, acc-0.5016, test loss-1.7997, acc-0.5240\n",
      "Iter-100000, train loss-1.7161, acc-0.5600, valid loss-1.8416, acc-0.5010, test loss-1.7997, acc-0.5240\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nEU0CISIikECIiIgmgRAREeALe0z73rnrLeUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc52c10f9b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.plot(nn.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fc52c10fda0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['train_acc'], label='Train accuracy')\n",
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.plot(nn.losses['test_acc'], label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
