{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # MNIST Data\n",
    "# import numpy as np\n",
    "# from tensorflow.examples.tutorials.mnist import input_data\n",
    "# import impl.layer as l\n",
    "\n",
    "# # Dataset preparation and pre-processing\n",
    "# mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "# X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "# X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "# X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "# y_test.shape, y_val.shape, y_train.shape\n",
    "# X_train.shape, X_train.dtype, X_val.shape, X_val.dtype, X_test.shape, X_test.dtype, y_train.shape, y_val.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>...</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "      <th>att25</th>\n",
       "      <th>att26</th>\n",
       "      <th>msd_track_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>41.08</td>\n",
       "      <td>6.579</td>\n",
       "      <td>4.307</td>\n",
       "      <td>3.421</td>\n",
       "      <td>3.192</td>\n",
       "      <td>2.076</td>\n",
       "      <td>2.179</td>\n",
       "      <td>2.052</td>\n",
       "      <td>1.794</td>\n",
       "      <td>...</td>\n",
       "      <td>1.3470</td>\n",
       "      <td>-0.2463</td>\n",
       "      <td>-1.5470</td>\n",
       "      <td>0.17920</td>\n",
       "      <td>-1.1530</td>\n",
       "      <td>-0.7370</td>\n",
       "      <td>0.40750</td>\n",
       "      <td>-0.67190</td>\n",
       "      <td>-0.05147</td>\n",
       "      <td>TRPLTEM128F92E1389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>60.80</td>\n",
       "      <td>5.973</td>\n",
       "      <td>4.344</td>\n",
       "      <td>3.261</td>\n",
       "      <td>2.835</td>\n",
       "      <td>2.725</td>\n",
       "      <td>2.446</td>\n",
       "      <td>1.884</td>\n",
       "      <td>1.962</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.3316</td>\n",
       "      <td>0.3519</td>\n",
       "      <td>-1.4760</td>\n",
       "      <td>0.52700</td>\n",
       "      <td>-2.1960</td>\n",
       "      <td>1.5990</td>\n",
       "      <td>-1.39000</td>\n",
       "      <td>0.22560</td>\n",
       "      <td>-0.72080</td>\n",
       "      <td>TRJWMBQ128F424155E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>51.47</td>\n",
       "      <td>4.971</td>\n",
       "      <td>4.316</td>\n",
       "      <td>2.916</td>\n",
       "      <td>3.112</td>\n",
       "      <td>2.290</td>\n",
       "      <td>2.053</td>\n",
       "      <td>1.934</td>\n",
       "      <td>1.878</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.2803</td>\n",
       "      <td>-0.1603</td>\n",
       "      <td>-0.1355</td>\n",
       "      <td>1.03500</td>\n",
       "      <td>0.2370</td>\n",
       "      <td>1.4890</td>\n",
       "      <td>0.02959</td>\n",
       "      <td>-0.13670</td>\n",
       "      <td>0.10820</td>\n",
       "      <td>TRRZWMO12903CCFCC2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>41.28</td>\n",
       "      <td>6.610</td>\n",
       "      <td>4.411</td>\n",
       "      <td>2.602</td>\n",
       "      <td>2.822</td>\n",
       "      <td>2.126</td>\n",
       "      <td>1.984</td>\n",
       "      <td>1.973</td>\n",
       "      <td>1.945</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.6930</td>\n",
       "      <td>1.0040</td>\n",
       "      <td>-0.3953</td>\n",
       "      <td>0.26710</td>\n",
       "      <td>-1.0450</td>\n",
       "      <td>0.4974</td>\n",
       "      <td>0.03724</td>\n",
       "      <td>1.04500</td>\n",
       "      <td>-0.20000</td>\n",
       "      <td>TRBZRUT12903CE6C04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>54.17</td>\n",
       "      <td>8.945</td>\n",
       "      <td>4.685</td>\n",
       "      <td>4.208</td>\n",
       "      <td>3.154</td>\n",
       "      <td>3.527</td>\n",
       "      <td>2.733</td>\n",
       "      <td>2.202</td>\n",
       "      <td>2.686</td>\n",
       "      <td>...</td>\n",
       "      <td>2.4690</td>\n",
       "      <td>-0.5449</td>\n",
       "      <td>-0.5622</td>\n",
       "      <td>-0.08968</td>\n",
       "      <td>-0.9823</td>\n",
       "      <td>-0.2445</td>\n",
       "      <td>-1.65800</td>\n",
       "      <td>-0.04825</td>\n",
       "      <td>-0.70950</td>\n",
       "      <td>TRLUJQF128F42AF5BF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   att1   att2   att3   att4   att5   att6   att7   att8   att9  \\\n",
       "0   1  41.08  6.579  4.307  3.421  3.192  2.076  2.179  2.052  1.794   \n",
       "1   2  60.80  5.973  4.344  3.261  2.835  2.725  2.446  1.884  1.962   \n",
       "2   3  51.47  4.971  4.316  2.916  3.112  2.290  2.053  1.934  1.878   \n",
       "3   4  41.28  6.610  4.411  2.602  2.822  2.126  1.984  1.973  1.945   \n",
       "4   5  54.17  8.945  4.685  4.208  3.154  3.527  2.733  2.202  2.686   \n",
       "\n",
       "          ...           att18   att19   att20    att21   att22   att23  \\\n",
       "0         ...          1.3470 -0.2463 -1.5470  0.17920 -1.1530 -0.7370   \n",
       "1         ...         -0.3316  0.3519 -1.4760  0.52700 -2.1960  1.5990   \n",
       "2         ...         -0.2803 -0.1603 -0.1355  1.03500  0.2370  1.4890   \n",
       "3         ...         -1.6930  1.0040 -0.3953  0.26710 -1.0450  0.4974   \n",
       "4         ...          2.4690 -0.5449 -0.5622 -0.08968 -0.9823 -0.2445   \n",
       "\n",
       "     att24    att25    att26        msd_track_id  \n",
       "0  0.40750 -0.67190 -0.05147  TRPLTEM128F92E1389  \n",
       "1 -1.39000  0.22560 -0.72080  TRJWMBQ128F424155E  \n",
       "2  0.02959 -0.13670  0.10820  TRRZWMO12903CCFCC2  \n",
       "3  0.03724  1.04500 -0.20000  TRBZRUT12903CE6C04  \n",
       "4 -1.65800 -0.04825 -0.70950  TRLUJQF128F42AF5BF  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd # to read CSV files (Comma Separated Values)\n",
    "\n",
    "train_x = pd.read_csv(filepath_or_buffer='data/kaggle-music-genre/train.x.csv')\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    class_label\n",
       "0   1  International\n",
       "1   2          Vocal\n",
       "2   3          Latin\n",
       "3   4          Blues\n",
       "4   5          Vocal"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y = pd.read_csv(filepath_or_buffer='data/kaggle-music-genre/train.y.csv')\n",
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>att1</th>\n",
       "      <th>att2</th>\n",
       "      <th>att3</th>\n",
       "      <th>att4</th>\n",
       "      <th>att5</th>\n",
       "      <th>att6</th>\n",
       "      <th>att7</th>\n",
       "      <th>att8</th>\n",
       "      <th>att9</th>\n",
       "      <th>...</th>\n",
       "      <th>att17</th>\n",
       "      <th>att18</th>\n",
       "      <th>att19</th>\n",
       "      <th>att20</th>\n",
       "      <th>att21</th>\n",
       "      <th>att22</th>\n",
       "      <th>att23</th>\n",
       "      <th>att24</th>\n",
       "      <th>att25</th>\n",
       "      <th>att26</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>38.22</td>\n",
       "      <td>8.076</td>\n",
       "      <td>6.935</td>\n",
       "      <td>4.696</td>\n",
       "      <td>3.856</td>\n",
       "      <td>3.465</td>\n",
       "      <td>2.922</td>\n",
       "      <td>2.568</td>\n",
       "      <td>2.070</td>\n",
       "      <td>...</td>\n",
       "      <td>3.988</td>\n",
       "      <td>0.4957</td>\n",
       "      <td>0.1836</td>\n",
       "      <td>-2.2210</td>\n",
       "      <td>0.6453</td>\n",
       "      <td>-0.2923</td>\n",
       "      <td>1.2000</td>\n",
       "      <td>-0.09179</td>\n",
       "      <td>0.4674</td>\n",
       "      <td>0.2158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>36.42</td>\n",
       "      <td>6.131</td>\n",
       "      <td>5.364</td>\n",
       "      <td>4.292</td>\n",
       "      <td>3.968</td>\n",
       "      <td>2.937</td>\n",
       "      <td>2.872</td>\n",
       "      <td>2.142</td>\n",
       "      <td>2.050</td>\n",
       "      <td>...</td>\n",
       "      <td>7.098</td>\n",
       "      <td>1.2290</td>\n",
       "      <td>0.5971</td>\n",
       "      <td>-1.0670</td>\n",
       "      <td>0.9569</td>\n",
       "      <td>-1.8240</td>\n",
       "      <td>2.3130</td>\n",
       "      <td>-0.80890</td>\n",
       "      <td>0.5612</td>\n",
       "      <td>-0.6225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>70.01</td>\n",
       "      <td>5.496</td>\n",
       "      <td>4.698</td>\n",
       "      <td>3.699</td>\n",
       "      <td>3.258</td>\n",
       "      <td>2.293</td>\n",
       "      <td>2.680</td>\n",
       "      <td>2.226</td>\n",
       "      <td>2.034</td>\n",
       "      <td>...</td>\n",
       "      <td>4.449</td>\n",
       "      <td>0.4773</td>\n",
       "      <td>1.6370</td>\n",
       "      <td>-1.0690</td>\n",
       "      <td>2.4160</td>\n",
       "      <td>-0.6299</td>\n",
       "      <td>1.4190</td>\n",
       "      <td>-0.81960</td>\n",
       "      <td>0.9151</td>\n",
       "      <td>-0.5948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>40.64</td>\n",
       "      <td>7.281</td>\n",
       "      <td>6.702</td>\n",
       "      <td>4.043</td>\n",
       "      <td>3.729</td>\n",
       "      <td>3.043</td>\n",
       "      <td>2.644</td>\n",
       "      <td>2.366</td>\n",
       "      <td>1.940</td>\n",
       "      <td>...</td>\n",
       "      <td>2.785</td>\n",
       "      <td>1.9000</td>\n",
       "      <td>-1.1370</td>\n",
       "      <td>1.2750</td>\n",
       "      <td>1.7920</td>\n",
       "      <td>-2.1250</td>\n",
       "      <td>1.6090</td>\n",
       "      <td>-0.83230</td>\n",
       "      <td>-0.1998</td>\n",
       "      <td>-0.1218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>38.85</td>\n",
       "      <td>7.118</td>\n",
       "      <td>5.703</td>\n",
       "      <td>4.825</td>\n",
       "      <td>4.088</td>\n",
       "      <td>3.823</td>\n",
       "      <td>3.254</td>\n",
       "      <td>2.551</td>\n",
       "      <td>2.193</td>\n",
       "      <td>...</td>\n",
       "      <td>4.536</td>\n",
       "      <td>2.1470</td>\n",
       "      <td>1.0200</td>\n",
       "      <td>-0.2656</td>\n",
       "      <td>2.8050</td>\n",
       "      <td>0.2762</td>\n",
       "      <td>0.2504</td>\n",
       "      <td>1.04900</td>\n",
       "      <td>0.3447</td>\n",
       "      <td>-0.7689</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   att1   att2   att3   att4   att5   att6   att7   att8   att9   ...    \\\n",
       "0   1  38.22  8.076  6.935  4.696  3.856  3.465  2.922  2.568  2.070   ...     \n",
       "1   2  36.42  6.131  5.364  4.292  3.968  2.937  2.872  2.142  2.050   ...     \n",
       "2   3  70.01  5.496  4.698  3.699  3.258  2.293  2.680  2.226  2.034   ...     \n",
       "3   4  40.64  7.281  6.702  4.043  3.729  3.043  2.644  2.366  1.940   ...     \n",
       "4   5  38.85  7.118  5.703  4.825  4.088  3.823  3.254  2.551  2.193   ...     \n",
       "\n",
       "   att17   att18   att19   att20   att21   att22   att23    att24   att25  \\\n",
       "0  3.988  0.4957  0.1836 -2.2210  0.6453 -0.2923  1.2000 -0.09179  0.4674   \n",
       "1  7.098  1.2290  0.5971 -1.0670  0.9569 -1.8240  2.3130 -0.80890  0.5612   \n",
       "2  4.449  0.4773  1.6370 -1.0690  2.4160 -0.6299  1.4190 -0.81960  0.9151   \n",
       "3  2.785  1.9000 -1.1370  1.2750  1.7920 -2.1250  1.6090 -0.83230 -0.1998   \n",
       "4  4.536  2.1470  1.0200 -0.2656  2.8050  0.2762  0.2504  1.04900  0.3447   \n",
       "\n",
       "    att26  \n",
       "0  0.2158  \n",
       "1 -0.6225  \n",
       "2 -0.5948  \n",
       "3 -0.1218  \n",
       "4 -0.7689  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_x = pd.read_csv(filepath_or_buffer='data/kaggle-music-genre/test.x.csv')\n",
    "test_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blues</th>\n",
       "      <th>Country</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Folk</th>\n",
       "      <th>International</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Latin</th>\n",
       "      <th>New_Age</th>\n",
       "      <th>Pop_Rock</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Reggae</th>\n",
       "      <th>RnB</th>\n",
       "      <th>Vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.1214</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.0930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   Blues  Country  Electronic    Folk  International    Jazz   Latin  \\\n",
       "0   1  0.0964   0.0884      0.0121  0.1004         0.0137  0.1214  0.0883   \n",
       "1   2  0.0121   0.0804      0.0376  0.0289         0.1310  0.0684  0.1044   \n",
       "2   3  0.1291   0.0985      0.0691  0.0356         0.0788  0.0529  0.1185   \n",
       "3   4  0.0453   0.1234      0.0931  0.0126         0.1224  0.0627  0.0269   \n",
       "4   5  0.0600   0.0915      0.0667  0.0947         0.0509  0.0335  0.1251   \n",
       "\n",
       "   New_Age  Pop_Rock     Rap  Reggae     RnB   Vocal  \n",
       "0   0.0765    0.0332  0.0445  0.1193  0.1019  0.1038  \n",
       "1   0.0118    0.1562  0.0585  0.1633  0.1400  0.0073  \n",
       "2   0.1057    0.1041  0.0075  0.0481  0.1283  0.0238  \n",
       "3   0.0764    0.0812  0.1337  0.0357  0.0937  0.0930  \n",
       "4   0.0202    0.1012  0.0365  0.1310  0.0898  0.0991  "
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_sample = pd.read_csv(filepath_or_buffer='data/kaggle-music-genre/submission-random.csv')\n",
    "test_y_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blues</th>\n",
       "      <th>Country</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Folk</th>\n",
       "      <th>International</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Latin</th>\n",
       "      <th>New_Age</th>\n",
       "      <th>Pop_Rock</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Reggae</th>\n",
       "      <th>RnB</th>\n",
       "      <th>Vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Blues, Country, Electronic, Folk, International, Jazz, Latin, New_Age, Pop_Rock, Rap, Reggae, RnB, Vocal]\n",
       "Index: []"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_sample[:0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000,)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_X = np.array(train_x)\n",
    "train_Y = np.array(train_y[:]['class_label'])\n",
    "test_X = np.array(test_x)\n",
    "\n",
    "# Getting rid of the first and the last column: Id and msd_track_id\n",
    "X_train_val = np.array(train_X[:, 1:-1], dtype=float)\n",
    "X_test = np.array(test_X[:, 1:], dtype=float)\n",
    "\n",
    "train_Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "# # Count the freq of words in the text/collection of words\n",
    "# word_counts = Counter(text)\n",
    "# # Having counted the frequency of the words in collection, sort them from most to least/top to bottom/descendng\n",
    "# sorted_vocab = sorted(word_counts, key=word_counts.get, reverse=True)\n",
    "# # first enumerating for vocab to int\n",
    "# vocab_to_int = {words: ii for ii, words in enumerate(sorted_vocab)}\n",
    "# # into_to_vocab after enumerating through the sorted vocab\n",
    "# int_to_vocab = {ii: words for words, ii in vocab_to_int.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['Jazz', 'New_Age', 'Country', 'Latin', 'Reggae', 'Electronic', 'International', 'Blues', 'Rap', 'Folk', 'Pop_Rock', 'RnB', 'Vocal'])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Count the freq of the keys in the training labels\n",
    "counted_labels = Counter(train_Y)\n",
    "labels_keys = counted_labels.keys()\n",
    "labels_keys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Blues',\n",
       " 'Country',\n",
       " 'Electronic',\n",
       " 'Folk',\n",
       " 'International',\n",
       " 'Jazz',\n",
       " 'Latin',\n",
       " 'New_Age',\n",
       " 'Pop_Rock',\n",
       " 'Rap',\n",
       " 'Reggae',\n",
       " 'RnB',\n",
       " 'Vocal']"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels_keys_sorted = sorted(labels_keys)\n",
    "labels_keys_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Blues': 0,\n",
       " 'Country': 1,\n",
       " 'Electronic': 2,\n",
       " 'Folk': 3,\n",
       " 'International': 4,\n",
       " 'Jazz': 5,\n",
       " 'Latin': 6,\n",
       " 'New_Age': 7,\n",
       " 'Pop_Rock': 8,\n",
       " 'Rap': 9,\n",
       " 'Reggae': 10,\n",
       " 'RnB': 11,\n",
       " 'Vocal': 12}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# This for loop for creating a dictionary/ vocab\n",
    "key_to_val = {key: val for val, key in enumerate(labels_keys_sorted)}\n",
    "key_to_val['Country']\n",
    "key_to_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This for loop for creating a dictionary/ vocab\n",
    "# key_to_val = {key: val for val, key in enumerate(counted_labels)}\n",
    "# key_to_val['Country']\n",
    "# key_to_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: 'Blues',\n",
       " 1: 'Country',\n",
       " 2: 'Electronic',\n",
       " 3: 'Folk',\n",
       " 4: 'International',\n",
       " 5: 'Jazz',\n",
       " 6: 'Latin',\n",
       " 7: 'New_Age',\n",
       " 8: 'Pop_Rock',\n",
       " 9: 'Rap',\n",
       " 10: 'Reggae',\n",
       " 11: 'RnB',\n",
       " 12: 'Vocal'}"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_to_key = {val: key for val, key in enumerate(labels_keys_sorted)}\n",
    "val_to_key[1]\n",
    "val_to_key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # This for loop for creating a list/ vector\n",
    "# # # labels = []\n",
    "# # # for val, key in enumerate(counted_labels):\n",
    "# # #     print(val, key)\n",
    "# # #     labels.append(val)\n",
    "  \n",
    "# # # labels = np.array(labels, dtype=int)\n",
    "# # # labels.size, np.max(labels), labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from impl.layer import onehot\n",
    "\n",
    "# labels_onehot = onehot(labels)\n",
    "\n",
    "# labels, labels_onehot, counted_labels.keys()\n",
    "# key_to_vec = {key: vec for key, vec in zip(counted_labels.keys(), labels_onehot)}\n",
    "# key_to_vec, key_to_vec['Vocal']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13000,)"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train_vec = []\n",
    "for each in train_y[:]['class_label']:\n",
    "#     print(each, key_to_val[each])\n",
    "    Y_train_vec.append(key_to_val[each])\n",
    "\n",
    "Y_train_val = np.array(Y_train_vec)\n",
    "Y_train_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((13000, 26), (10400, 26), dtype('float64'), dtype('float64'))"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Pre-processing: normalizing\n",
    "# def normalize(X):\n",
    "#     # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "#     return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "# X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)\n",
    "\n",
    "# Preprocessing: normalizing the data based on the training set\n",
    "mean = X_train_val.mean(axis=0)\n",
    "std = X_train_val.std(axis=0)\n",
    "\n",
    "X_train_val, X_test = (X_train_val - mean)/ std, (X_test - mean)/ std\n",
    "X_train_val.shape, X_test.shape, X_train_val.dtype, X_test.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11700, 26), (1300, 26), (10400, 26), (1300,), (11700,))"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating validation set: 10% or 1/10 of the training set or whatever dataset with labels/ annotation\n",
    "valid_size = X_train_val.shape[0]//10\n",
    "valid_size\n",
    "X_val = X_train_val[-valid_size:]\n",
    "Y_val = Y_train_val[-valid_size:]\n",
    "X_train = X_train_val[: -valid_size]\n",
    "Y_train = Y_train_val[: -valid_size]\n",
    "X_train_val.shape, \n",
    "X_train.shape, X_val.shape, X_test.shape, Y_val.shape, Y_train.shape \n",
    "# X_train.dtype, X_val.dtype\n",
    "# Y_train.dtype, Y_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # number of layers or depth\n",
    "        self.losses = {'train':[], 'valid':[], 'valid_acc':[]}\n",
    "        \n",
    "        # The adaptive/learnable/updatable random feedforward\n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.ys_prev = []\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        # Previous output layer\n",
    "        ys_prev_L = []\n",
    "        for _ in range(L):\n",
    "            ys_prev_L.append(0.0)\n",
    "        self.ys_prev.append(ys_prev_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Outout layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        # Previous output layer\n",
    "        self.ys_prev.append(0.0)\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "        dX = dout @ W.T # Backprop\n",
    "#         dX = dout @ W_fixed.T # fb alignment\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = l.tanh_forward(X=y)\n",
    "        if train:\n",
    "            caches.append((fc_cache, nl_cache))\n",
    "        ys.append(y) # ys[0]\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches, ys_L = [], [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = l.tanh_forward(X=y)\n",
    "            ys_L.append(y) # ys[1][layer]\n",
    "            X = y.copy() # pass to next layer\n",
    "            if train:\n",
    "                fc_caches.append(fc_cache)\n",
    "                nl_caches.append(nl_cache)\n",
    "        if train:\n",
    "            caches.append((fc_caches, nl_caches)) # caches[1]            \n",
    "        ys.append(ys_L) # ys[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "        ys.append(y) # ys[2]\n",
    "\n",
    "        return ys, caches # for backpropating the error\n",
    "\n",
    "    def loss_function(self, y, y_train):\n",
    "        \n",
    "        loss = cross_entropy(y, y_train) # softmax is included\n",
    "        dy = dcross_entropy(y, y_train) # dsoftmax is included\n",
    "        \n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, ys):\n",
    "        grads, ys_prev = self.grads, self.ys_prev # initialized by Zero in every iteration/epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "#             dy *= ys[1][layer] - ys_prev[1][layer] # temporal diff instead of differentiable function\n",
    "            dy = l.tanh_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "#         dy *= ys[0] - ys_prev[0] # temporal diff instead of differentiable function\n",
    "        dy = l.tanh_backward(cache=nl_cache, dout=dy) # diffable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        ys_logit, _ = self.train_forward(X, train=False)\n",
    "        y_logit = ys_logit[2] # last layer\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_prob = l.softmax(y_logit) # for accuracy == acc\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_logit\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            ys, caches = self.train_forward(X_mini, train=True)\n",
    "            loss, dy = self.loss_function(ys[2], y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, ys) # ys[0], ys[1] and ys_prev are used for backprop\n",
    "            self.ys_prev = ys # for next iteration or epoch learning dW and db\n",
    "            self.losses['train'].append(loss)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "                \n",
    "            # Validate the updated model\n",
    "            y_pred, y_logit = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_logit, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{} train loss: {:.4f} valid loss: {:.4f}, valid accuracy: {:.4f}'.format(\n",
    "                    iter, loss, valid_loss, valid_acc))\n",
    "\n",
    "#         # Test the final model\n",
    "#         y_pred, y_logit = nn.test(X_test)\n",
    "#         loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "#         acc = np.mean(y_pred == y_test)\n",
    "#         print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "#             acc.mean(), acc.std(), loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11700,), (11700, 26), (1300, 26), (1300,))"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.shape, X_train.shape, X_val.shape, Y_val.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-100 train loss: 2.5779 valid loss: 2.5703, valid accuracy: 0.0746\n",
      "Iter-200 train loss: 2.5345 valid loss: 2.5654, valid accuracy: 0.0838\n",
      "Iter-300 train loss: 2.5417 valid loss: 2.5605, valid accuracy: 0.0885\n",
      "Iter-400 train loss: 2.5505 valid loss: 2.5558, valid accuracy: 0.0969\n",
      "Iter-500 train loss: 2.5048 valid loss: 2.5513, valid accuracy: 0.1062\n",
      "Iter-600 train loss: 2.5206 valid loss: 2.5469, valid accuracy: 0.1100\n",
      "Iter-700 train loss: 2.5158 valid loss: 2.5428, valid accuracy: 0.1154\n",
      "Iter-800 train loss: 2.5062 valid loss: 2.5387, valid accuracy: 0.1177\n",
      "Iter-900 train loss: 2.5561 valid loss: 2.5345, valid accuracy: 0.1246\n",
      "Iter-1000 train loss: 2.5086 valid loss: 2.5304, valid accuracy: 0.1292\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 1000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 100 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = Y_train.max() + 1 # number of classes in this classification problem\n",
    "# num_output_units = Y_train.shape[1] # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, Y_train), val_set=(X_val, Y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD7CAYAAABqvuNzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhieqoOIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27a19e58d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAEACAYAAACznAEdAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\niEQoIIiICKCAICIiEQoIIiICwP8D+v7w5k9NWPIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27a2cb61d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Test the final model\n",
    "# y_pred, y_logit = nn.test(X_test)\n",
    "# loss, _ = self.loss_function(y_logit, y_test) # softmax is included in entropy loss function\n",
    "# acc = np.mean(y_pred == y_test)\n",
    "# print('Last iteration - Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.format(\n",
    "#     acc.mean(), acc.std(), loss))\n",
    "# y_pred, y_logits = nn.test(X_test)\n",
    "# mplot.imsave(y_pred)\n",
    "# pd.DataFrame.to_csv(y_pred)\n",
    "# y_pred.shape\n",
    "# import numpy\n",
    "# a = numpy.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "# numpy.savetxt(\"foo.csv\", a, delimiter=\",\")\n",
    "# np.savetxt(X=y_pred, delimiter=\",\", fname='y_predddddddddddddddddd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mBCI-HW1\u001b[0m/                                 foo.csv\r\n",
      "\u001b[01;34mBCI-HW2\u001b[0m/                                 gradient_descent.py\r\n",
      "\u001b[01;34mbio-bp-dl\u001b[0m/                               \u001b[01;34mimpl\u001b[0m/\r\n",
      "confusion_mat_cov.ipynb                  \u001b[01;34mimpl_imagernn_karpathy\u001b[0m/\r\n",
      "\u001b[01;34mdata\u001b[0m/                                    LICENSE\r\n",
      "DCNN.ipynb                               minimal_net.ipynb\r\n",
      "Deep-FFNN-Tanh-FBA.ipynb                 \u001b[01;34mmisc\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD.ipynb             \u001b[01;34mmisc2\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD-Kaggle.ipynb      NOTES\r\n",
      "Deep-FFNN-Tanh-FBA-Kaggle.ipynb          numba-cuda-gpu-example.ipynb\r\n",
      "Deep-FFNN-Tanh-Vanilla.ipynb             output.csv\r\n",
      "Deep-FFNN-Tanh-Vanilla-Kaggle.ipynb      README.md\r\n",
      "DFFNN-FBA-STDP-Tanh-diff.ipynb           \u001b[01;34mrnn-testing-platform\u001b[0m/\r\n",
      "DFFNN-FBA-STDP-Tanh-diff-no_FBA.ipynb    submission.csv\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff2.ipynb  \u001b[01;34mtf-based\u001b[0m/\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff.ipynb   y_predddddddddddddddddd2.csv\r\n",
      "\u001b[01;34mDFFNNs\u001b[0m/                                  y_predddddddddddddddddd3.csv\r\n",
      "\u001b[01;34mDGRUs\u001b[0m/                                   y_predddddddddddddddddd.csv\r\n",
      "\u001b[01;34mDGRUs_old\u001b[0m/                               y_prob.csv\r\n",
      "environment.yml\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>International</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Vocal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Latin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Blues</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Vocal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id    class_label\n",
       "0   1  International\n",
       "1   2          Vocal\n",
       "2   3          Latin\n",
       "3   4          Blues\n",
       "4   5          Vocal"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# for idx in range(y_pred.shape[0]): # y_txn\n",
    "# # for idx in range(10): # y_txn\n",
    "# # for each in y_pred[1000:1100]:\n",
    "# #     print(val_to_key[y_pred[idx]])\n",
    "#     labels.append((idx+1, val_to_key[y_pred[idx]]))\n",
    "# #     labels.append([idx+1, val_to_key[y_pred[idx]]])\n",
    "# #     labels.append(val_to_key[y_pred[idx]])\n",
    "\n",
    "# len(labels), X_test.shape, labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pred_labels = np.array(labels)\n",
    "# pred_labels.shape, pred_labels.dtype, pred_labels[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # import numpy as np\n",
    "# # a = np.asarray([ [1,2,3], [4,5,6], [7,8,9] ])\n",
    "# pred_labels.tofile('foo.csv',sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# # # Writing down the the prediction into the 'csv' file\n",
    "# # np.savetxt(delimiter=',', fname='submission.csv', X=pred_labels) \n",
    "# # import csv\n",
    "\n",
    "# # Finding the corresponding point to the time equivalent\n",
    "# import csv\n",
    "# RESULT = ['apple','cherry','orange','pineapple','strawberry']\n",
    "# with open(\"output.csv\",'wb') as resultFile:\n",
    "#     wr = csv.writer(resultFile, dialect='excel')\n",
    "#     wr.writerow(RESULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data\n",
    "RESULTS = ['apple','cherry','orange','pineapple','strawberry']\n",
    "# RESULTS  = []\n",
    "# RESULTS.append(sample)\n",
    "# Open File\n",
    "resultFyle = open(\"output.csv\",'w')\n",
    "\n",
    "# Write data to file\n",
    "for r in RESULTS:\n",
    "#     resultFyle.write(r + \"\\n\")\n",
    "    resultFyle.write(r + \",\")\n",
    "resultFyle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apple</th>\n",
       "      <th>cherry</th>\n",
       "      <th>orange</th>\n",
       "      <th>pineapple</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [apple, cherry, orange, pineapple, strawberry, Unnamed: 5]\n",
       "Index: []"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filepath_or_buffer='output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Data\n",
    "sample = ['apple','cherry','orange','pineapple','strawberry']\n",
    "RESULTS  = []\n",
    "for _ in range(5):\n",
    "    RESULTS.append(sample)\n",
    "\n",
    "# Open File\n",
    "resultFyle = open(\"output.csv\",'w')\n",
    "\n",
    "# Write data to file\n",
    "for sample in RESULTS:\n",
    "    for r in sample:\n",
    "# #     resultFyle.write(r + \"\\n\")\n",
    "        # Writing dow every row\n",
    "#         resultFyle.write(r + \",\")\n",
    "        resultFyle.write(r)\n",
    "        resultFyle.write(',')\n",
    "#         resultFyle.write(r + \"\\n\")\n",
    "    # Move to the next line\n",
    "#     resultFyle.\n",
    "    resultFyle.write(\"\\n\")\n",
    "resultFyle.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>apple</th>\n",
       "      <th>cherry</th>\n",
       "      <th>orange</th>\n",
       "      <th>pineapple</th>\n",
       "      <th>strawberry</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>apple</td>\n",
       "      <td>cherry</td>\n",
       "      <td>orange</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>strawberry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>apple</td>\n",
       "      <td>cherry</td>\n",
       "      <td>orange</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>strawberry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>apple</td>\n",
       "      <td>cherry</td>\n",
       "      <td>orange</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>strawberry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>apple</td>\n",
       "      <td>cherry</td>\n",
       "      <td>orange</td>\n",
       "      <td>pineapple</td>\n",
       "      <td>strawberry</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   apple  cherry  orange  pineapple  strawberry  Unnamed: 5\n",
       "0  apple  cherry  orange  pineapple  strawberry         NaN\n",
       "1  apple  cherry  orange  pineapple  strawberry         NaN\n",
       "2  apple  cherry  orange  pineapple  strawberry         NaN\n",
       "3  apple  cherry  orange  pineapple  strawberry         NaN"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filepath_or_buffer='output.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mBCI-HW1\u001b[0m/                                 foo.csv\r\n",
      "\u001b[01;34mBCI-HW2\u001b[0m/                                 gradient_descent.py\r\n",
      "\u001b[01;34mbio-bp-dl\u001b[0m/                               \u001b[01;34mimpl\u001b[0m/\r\n",
      "confusion_mat_cov.ipynb                  \u001b[01;34mimpl_imagernn_karpathy\u001b[0m/\r\n",
      "\u001b[01;34mdata\u001b[0m/                                    LICENSE\r\n",
      "DCNN.ipynb                               minimal_net.ipynb\r\n",
      "Deep-FFNN-Tanh-FBA.ipynb                 \u001b[01;34mmisc\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD.ipynb             \u001b[01;34mmisc2\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD-Kaggle.ipynb      NOTES\r\n",
      "Deep-FFNN-Tanh-FBA-Kaggle.ipynb          numba-cuda-gpu-example.ipynb\r\n",
      "Deep-FFNN-Tanh-Vanilla.ipynb             output.csv\r\n",
      "Deep-FFNN-Tanh-Vanilla-Kaggle.ipynb      README.md\r\n",
      "DFFNN-FBA-STDP-Tanh-diff.ipynb           \u001b[01;34mrnn-testing-platform\u001b[0m/\r\n",
      "DFFNN-FBA-STDP-Tanh-diff-no_FBA.ipynb    submission2.csv\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff2.ipynb  submission.csv\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff.ipynb   \u001b[01;34mtf-based\u001b[0m/\r\n",
      "\u001b[01;34mDFFNNs\u001b[0m/                                  y_predddddddddddddddddd2.csv\r\n",
      "\u001b[01;34mDGRUs\u001b[0m/                                   y_predddddddddddddddddd3.csv\r\n",
      "\u001b[01;34mDGRUs_old\u001b[0m/                               y_predddddddddddddddddd.csv\r\n",
      "environment.yml                          y_prob.csv\r\n"
     ]
    }
   ],
   "source": [
    "% ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Id'],\n",
       " ['Blues',\n",
       "  'Country',\n",
       "  'Electronic',\n",
       "  'Folk',\n",
       "  'International',\n",
       "  'Jazz',\n",
       "  'Latin',\n",
       "  'New_Age',\n",
       "  'Pop_Rock',\n",
       "  'Rap',\n",
       "  'Reggae',\n",
       "  'RnB',\n",
       "  'Vocal'])"
      ]
     },
     "execution_count": 340,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = []\n",
    "# labels.append(('Id', 'class_label')) # Id starts with 1\n",
    "labels.append('Id')\n",
    "labels, labels_keys_sorted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id Blues Country Electronic Folk International Jazz Latin New_Age Pop_Rock Rap Reggae RnB Vocal\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(14,)"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = labels_keys_sorted.copy()\n",
    "# test.pop(), test.pop(), test.pop()\n",
    "labels.append(labels_keys_sorted)\n",
    "labels, test.insert(0, 'Id')\n",
    "# title = np.array(test)\n",
    "# print(*title), title, \n",
    "print(*test),\n",
    "title = np.array(test)\n",
    "title.shape\n",
    "# sample_list = []\n",
    "# sample_list.append([*test])\n",
    "# # test.append('Id')\n",
    "# print(*sample_list)\n",
    "# sample_list2 = * sample_list\n",
    "# np.array([*test]), np.array(test) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10400, 13),\n",
       " (10400, 26),\n",
       " (10400, 13),\n",
       " (10400, 14),\n",
       "    Id   Blues  Country  Electronic    Folk  International    Jazz   Latin  \\\n",
       " 0   1  0.0964   0.0884      0.0121  0.1004         0.0137  0.1214  0.0883   \n",
       " \n",
       "    New_Age  Pop_Rock     Rap  Reggae     RnB   Vocal  \n",
       " 0   0.0765    0.0332  0.0445  0.1193  0.1019  0.1038  )"
      ]
     },
     "execution_count": 342,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred, y_logits = nn.test(X_test)\n",
    "y_prob = l.softmax(y_logits)\n",
    "y_prob.shape, X_test.shape, y_logits.shape, test_y_sample.shape, test_y_sample[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_list = []\n",
    "# pred_list.append(test)\n",
    "# pred_list\n",
    "for Id, pred in enumerate(y_prob):\n",
    "#     print(Id+1, *pred)\n",
    "#     test.append(Id+1)\n",
    "#     test.append(*pred)\n",
    "    pred_list.append([Id+1, *pred])\n",
    "\n",
    "    \n",
    "# pred_arr = np.array(pred_list)\n",
    "# # pred_arr.insert(*test, axis=0)\n",
    "# submission = np.row_stack((title, pred_arr))\n",
    "# submission.shape\n",
    "# submission[:2]\n",
    "# # pred_arr.shape\n",
    "# print(pred_list[1])\n",
    "# np.array(pred_list)\n",
    "# new_list = []\n",
    "# new_list.append(*pred_list[0])\n",
    "# np.array(*pred_list[0])\n",
    "# np.array(*pred_list)\n",
    "# np.array(pred_list)\n",
    "# np.array(pred_list)[0]\n",
    "# y_prob[:10, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = open(file='prediction.csv', mode='w')\n",
    "\n",
    "len(test), test[0]\n",
    "# for key in test:\n",
    "for idx in range(len(test)):\n",
    "    if idx < len(test) - 1:\n",
    "        pred_file.write(test[idx] + ',')\n",
    "    else:\n",
    "        pred_file.write(test[idx])        \n",
    "\n",
    "# pred_file.write(-',')\n",
    "pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blues</th>\n",
       "      <th>Country</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Folk</th>\n",
       "      <th>International</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Latin</th>\n",
       "      <th>New_Age</th>\n",
       "      <th>Pop_Rock</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Reggae</th>\n",
       "      <th>RnB</th>\n",
       "      <th>Vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [Id, Blues, Country, Electronic, Folk, International, Jazz, Latin, New_Age, Pop_Rock, Rap, Reggae, RnB, Vocal]\n",
       "Index: []"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filepath_or_buffer='prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_list[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_file = open(file='prediction2.csv', mode='w')\n",
    "pred_file.write('\\n') # because of the previous line        \n",
    "\n",
    "for idx in range(len(test)):\n",
    "    if idx < len(test) - 1:\n",
    "        pred_file.write(test[idx] + ',')\n",
    "    else:\n",
    "        pred_file.write(test[idx] + '\\n')        \n",
    "\n",
    "# len(test), test[0]\n",
    "# for key in test:\n",
    "for i in range(len(pred_list)): # rows\n",
    "    for j in range(len(pred_list[i])): # cols\n",
    "        if j < (len(pred_list[i]) - 1):\n",
    "            pred_file.write(str(pred_list[i][j]))\n",
    "            pred_file.write(',')\n",
    "        else: # last item before starting a new line\n",
    "            pred_file.write(str(pred_list[i][j]) + '\\n')        \n",
    "\n",
    "# pred_file.write(-',')\n",
    "pred_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blues</th>\n",
       "      <th>Country</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Folk</th>\n",
       "      <th>International</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Latin</th>\n",
       "      <th>New_Age</th>\n",
       "      <th>Pop_Rock</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Reggae</th>\n",
       "      <th>RnB</th>\n",
       "      <th>Vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.063315</td>\n",
       "      <td>0.075692</td>\n",
       "      <td>0.090542</td>\n",
       "      <td>0.072905</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>0.058305</td>\n",
       "      <td>0.072097</td>\n",
       "      <td>0.071053</td>\n",
       "      <td>0.052059</td>\n",
       "      <td>0.096331</td>\n",
       "      <td>0.074679</td>\n",
       "      <td>0.084148</td>\n",
       "      <td>0.112782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.077229</td>\n",
       "      <td>0.072573</td>\n",
       "      <td>0.076020</td>\n",
       "      <td>0.070785</td>\n",
       "      <td>0.071869</td>\n",
       "      <td>0.067309</td>\n",
       "      <td>0.075531</td>\n",
       "      <td>0.071660</td>\n",
       "      <td>0.066383</td>\n",
       "      <td>0.090268</td>\n",
       "      <td>0.086847</td>\n",
       "      <td>0.079983</td>\n",
       "      <td>0.093543</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.086678</td>\n",
       "      <td>0.093590</td>\n",
       "      <td>0.083764</td>\n",
       "      <td>0.068918</td>\n",
       "      <td>0.085976</td>\n",
       "      <td>0.063847</td>\n",
       "      <td>0.068652</td>\n",
       "      <td>0.063477</td>\n",
       "      <td>0.075029</td>\n",
       "      <td>0.082691</td>\n",
       "      <td>0.072139</td>\n",
       "      <td>0.072459</td>\n",
       "      <td>0.082780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.091982</td>\n",
       "      <td>0.071371</td>\n",
       "      <td>0.087378</td>\n",
       "      <td>0.063063</td>\n",
       "      <td>0.071639</td>\n",
       "      <td>0.072388</td>\n",
       "      <td>0.063234</td>\n",
       "      <td>0.060040</td>\n",
       "      <td>0.057063</td>\n",
       "      <td>0.094825</td>\n",
       "      <td>0.100601</td>\n",
       "      <td>0.085286</td>\n",
       "      <td>0.081129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.065365</td>\n",
       "      <td>0.065053</td>\n",
       "      <td>0.102780</td>\n",
       "      <td>0.073557</td>\n",
       "      <td>0.069579</td>\n",
       "      <td>0.053834</td>\n",
       "      <td>0.062173</td>\n",
       "      <td>0.074761</td>\n",
       "      <td>0.049168</td>\n",
       "      <td>0.117644</td>\n",
       "      <td>0.073616</td>\n",
       "      <td>0.087466</td>\n",
       "      <td>0.105002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.083222</td>\n",
       "      <td>0.054714</td>\n",
       "      <td>0.068426</td>\n",
       "      <td>0.102083</td>\n",
       "      <td>0.067446</td>\n",
       "      <td>0.076184</td>\n",
       "      <td>0.078843</td>\n",
       "      <td>0.076289</td>\n",
       "      <td>0.101379</td>\n",
       "      <td>0.072598</td>\n",
       "      <td>0.090601</td>\n",
       "      <td>0.056872</td>\n",
       "      <td>0.071342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.078029</td>\n",
       "      <td>0.077064</td>\n",
       "      <td>0.090475</td>\n",
       "      <td>0.072782</td>\n",
       "      <td>0.068836</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>0.071947</td>\n",
       "      <td>0.072302</td>\n",
       "      <td>0.066916</td>\n",
       "      <td>0.097056</td>\n",
       "      <td>0.087280</td>\n",
       "      <td>0.077138</td>\n",
       "      <td>0.079590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.065526</td>\n",
       "      <td>0.089678</td>\n",
       "      <td>0.091900</td>\n",
       "      <td>0.080178</td>\n",
       "      <td>0.080373</td>\n",
       "      <td>0.058853</td>\n",
       "      <td>0.063003</td>\n",
       "      <td>0.074479</td>\n",
       "      <td>0.070979</td>\n",
       "      <td>0.109010</td>\n",
       "      <td>0.076619</td>\n",
       "      <td>0.070192</td>\n",
       "      <td>0.069210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.061524</td>\n",
       "      <td>0.095653</td>\n",
       "      <td>0.083372</td>\n",
       "      <td>0.076891</td>\n",
       "      <td>0.060385</td>\n",
       "      <td>0.065853</td>\n",
       "      <td>0.061284</td>\n",
       "      <td>0.084767</td>\n",
       "      <td>0.069689</td>\n",
       "      <td>0.112807</td>\n",
       "      <td>0.093570</td>\n",
       "      <td>0.064286</td>\n",
       "      <td>0.069919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.072775</td>\n",
       "      <td>0.090906</td>\n",
       "      <td>0.085638</td>\n",
       "      <td>0.058355</td>\n",
       "      <td>0.084724</td>\n",
       "      <td>0.064780</td>\n",
       "      <td>0.069944</td>\n",
       "      <td>0.071284</td>\n",
       "      <td>0.069426</td>\n",
       "      <td>0.108414</td>\n",
       "      <td>0.080399</td>\n",
       "      <td>0.068026</td>\n",
       "      <td>0.075328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.062013</td>\n",
       "      <td>0.066908</td>\n",
       "      <td>0.087756</td>\n",
       "      <td>0.081195</td>\n",
       "      <td>0.070258</td>\n",
       "      <td>0.059591</td>\n",
       "      <td>0.071867</td>\n",
       "      <td>0.078433</td>\n",
       "      <td>0.071667</td>\n",
       "      <td>0.101611</td>\n",
       "      <td>0.094100</td>\n",
       "      <td>0.075352</td>\n",
       "      <td>0.079250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.057166</td>\n",
       "      <td>0.082418</td>\n",
       "      <td>0.083838</td>\n",
       "      <td>0.072011</td>\n",
       "      <td>0.064622</td>\n",
       "      <td>0.055448</td>\n",
       "      <td>0.057169</td>\n",
       "      <td>0.102362</td>\n",
       "      <td>0.066406</td>\n",
       "      <td>0.125425</td>\n",
       "      <td>0.069404</td>\n",
       "      <td>0.072034</td>\n",
       "      <td>0.091696</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.060288</td>\n",
       "      <td>0.082419</td>\n",
       "      <td>0.073954</td>\n",
       "      <td>0.079141</td>\n",
       "      <td>0.075049</td>\n",
       "      <td>0.063762</td>\n",
       "      <td>0.071992</td>\n",
       "      <td>0.081489</td>\n",
       "      <td>0.102075</td>\n",
       "      <td>0.095135</td>\n",
       "      <td>0.074117</td>\n",
       "      <td>0.062444</td>\n",
       "      <td>0.078134</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.077218</td>\n",
       "      <td>0.071312</td>\n",
       "      <td>0.085374</td>\n",
       "      <td>0.076091</td>\n",
       "      <td>0.076240</td>\n",
       "      <td>0.067936</td>\n",
       "      <td>0.070170</td>\n",
       "      <td>0.064333</td>\n",
       "      <td>0.048881</td>\n",
       "      <td>0.092964</td>\n",
       "      <td>0.069333</td>\n",
       "      <td>0.087933</td>\n",
       "      <td>0.112215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.082869</td>\n",
       "      <td>0.065331</td>\n",
       "      <td>0.085600</td>\n",
       "      <td>0.090809</td>\n",
       "      <td>0.072834</td>\n",
       "      <td>0.075293</td>\n",
       "      <td>0.078815</td>\n",
       "      <td>0.069379</td>\n",
       "      <td>0.059064</td>\n",
       "      <td>0.076434</td>\n",
       "      <td>0.072960</td>\n",
       "      <td>0.074654</td>\n",
       "      <td>0.095959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.081125</td>\n",
       "      <td>0.059731</td>\n",
       "      <td>0.078956</td>\n",
       "      <td>0.070791</td>\n",
       "      <td>0.062627</td>\n",
       "      <td>0.081920</td>\n",
       "      <td>0.075243</td>\n",
       "      <td>0.072894</td>\n",
       "      <td>0.065789</td>\n",
       "      <td>0.064003</td>\n",
       "      <td>0.100862</td>\n",
       "      <td>0.078679</td>\n",
       "      <td>0.107380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.067402</td>\n",
       "      <td>0.062600</td>\n",
       "      <td>0.075298</td>\n",
       "      <td>0.087968</td>\n",
       "      <td>0.063009</td>\n",
       "      <td>0.072892</td>\n",
       "      <td>0.069583</td>\n",
       "      <td>0.094699</td>\n",
       "      <td>0.098961</td>\n",
       "      <td>0.084056</td>\n",
       "      <td>0.120014</td>\n",
       "      <td>0.056272</td>\n",
       "      <td>0.047247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.070382</td>\n",
       "      <td>0.069817</td>\n",
       "      <td>0.098745</td>\n",
       "      <td>0.081301</td>\n",
       "      <td>0.076376</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.065029</td>\n",
       "      <td>0.067343</td>\n",
       "      <td>0.054231</td>\n",
       "      <td>0.127732</td>\n",
       "      <td>0.077355</td>\n",
       "      <td>0.074239</td>\n",
       "      <td>0.080784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.106549</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.075847</td>\n",
       "      <td>0.078921</td>\n",
       "      <td>0.071021</td>\n",
       "      <td>0.095883</td>\n",
       "      <td>0.075269</td>\n",
       "      <td>0.070840</td>\n",
       "      <td>0.059786</td>\n",
       "      <td>0.062163</td>\n",
       "      <td>0.099669</td>\n",
       "      <td>0.081815</td>\n",
       "      <td>0.067297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.078994</td>\n",
       "      <td>0.061958</td>\n",
       "      <td>0.084672</td>\n",
       "      <td>0.075654</td>\n",
       "      <td>0.096350</td>\n",
       "      <td>0.074523</td>\n",
       "      <td>0.074882</td>\n",
       "      <td>0.079053</td>\n",
       "      <td>0.049834</td>\n",
       "      <td>0.084343</td>\n",
       "      <td>0.081490</td>\n",
       "      <td>0.070728</td>\n",
       "      <td>0.087520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.067917</td>\n",
       "      <td>0.068907</td>\n",
       "      <td>0.083933</td>\n",
       "      <td>0.079165</td>\n",
       "      <td>0.074337</td>\n",
       "      <td>0.067735</td>\n",
       "      <td>0.078367</td>\n",
       "      <td>0.077923</td>\n",
       "      <td>0.064185</td>\n",
       "      <td>0.068023</td>\n",
       "      <td>0.077703</td>\n",
       "      <td>0.083942</td>\n",
       "      <td>0.107864</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.079539</td>\n",
       "      <td>0.074574</td>\n",
       "      <td>0.081311</td>\n",
       "      <td>0.065907</td>\n",
       "      <td>0.084252</td>\n",
       "      <td>0.059790</td>\n",
       "      <td>0.078967</td>\n",
       "      <td>0.061356</td>\n",
       "      <td>0.059635</td>\n",
       "      <td>0.078660</td>\n",
       "      <td>0.067054</td>\n",
       "      <td>0.090632</td>\n",
       "      <td>0.118324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.075798</td>\n",
       "      <td>0.078323</td>\n",
       "      <td>0.084271</td>\n",
       "      <td>0.062432</td>\n",
       "      <td>0.086183</td>\n",
       "      <td>0.069211</td>\n",
       "      <td>0.065605</td>\n",
       "      <td>0.079864</td>\n",
       "      <td>0.057539</td>\n",
       "      <td>0.093212</td>\n",
       "      <td>0.098743</td>\n",
       "      <td>0.078306</td>\n",
       "      <td>0.070513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.074730</td>\n",
       "      <td>0.068299</td>\n",
       "      <td>0.092346</td>\n",
       "      <td>0.057084</td>\n",
       "      <td>0.085940</td>\n",
       "      <td>0.068831</td>\n",
       "      <td>0.070859</td>\n",
       "      <td>0.068344</td>\n",
       "      <td>0.047245</td>\n",
       "      <td>0.083141</td>\n",
       "      <td>0.072742</td>\n",
       "      <td>0.095858</td>\n",
       "      <td>0.114581</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.068634</td>\n",
       "      <td>0.081433</td>\n",
       "      <td>0.068019</td>\n",
       "      <td>0.078735</td>\n",
       "      <td>0.071830</td>\n",
       "      <td>0.062209</td>\n",
       "      <td>0.074855</td>\n",
       "      <td>0.080081</td>\n",
       "      <td>0.105566</td>\n",
       "      <td>0.086716</td>\n",
       "      <td>0.089674</td>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.072800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.080510</td>\n",
       "      <td>0.062207</td>\n",
       "      <td>0.073753</td>\n",
       "      <td>0.078495</td>\n",
       "      <td>0.074625</td>\n",
       "      <td>0.078448</td>\n",
       "      <td>0.076327</td>\n",
       "      <td>0.072869</td>\n",
       "      <td>0.073565</td>\n",
       "      <td>0.076505</td>\n",
       "      <td>0.100786</td>\n",
       "      <td>0.079194</td>\n",
       "      <td>0.072716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.065420</td>\n",
       "      <td>0.076456</td>\n",
       "      <td>0.086391</td>\n",
       "      <td>0.068839</td>\n",
       "      <td>0.075020</td>\n",
       "      <td>0.062765</td>\n",
       "      <td>0.067025</td>\n",
       "      <td>0.081501</td>\n",
       "      <td>0.054307</td>\n",
       "      <td>0.108953</td>\n",
       "      <td>0.074135</td>\n",
       "      <td>0.078081</td>\n",
       "      <td>0.101106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.081667</td>\n",
       "      <td>0.080299</td>\n",
       "      <td>0.088056</td>\n",
       "      <td>0.066508</td>\n",
       "      <td>0.080673</td>\n",
       "      <td>0.065967</td>\n",
       "      <td>0.066349</td>\n",
       "      <td>0.065586</td>\n",
       "      <td>0.059175</td>\n",
       "      <td>0.105811</td>\n",
       "      <td>0.076263</td>\n",
       "      <td>0.080206</td>\n",
       "      <td>0.083439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.068759</td>\n",
       "      <td>0.076838</td>\n",
       "      <td>0.066037</td>\n",
       "      <td>0.090094</td>\n",
       "      <td>0.075520</td>\n",
       "      <td>0.073241</td>\n",
       "      <td>0.077347</td>\n",
       "      <td>0.082169</td>\n",
       "      <td>0.126539</td>\n",
       "      <td>0.077431</td>\n",
       "      <td>0.081539</td>\n",
       "      <td>0.052050</td>\n",
       "      <td>0.052436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.088023</td>\n",
       "      <td>0.061714</td>\n",
       "      <td>0.079093</td>\n",
       "      <td>0.070218</td>\n",
       "      <td>0.081618</td>\n",
       "      <td>0.085140</td>\n",
       "      <td>0.084659</td>\n",
       "      <td>0.062246</td>\n",
       "      <td>0.060733</td>\n",
       "      <td>0.059945</td>\n",
       "      <td>0.114490</td>\n",
       "      <td>0.081215</td>\n",
       "      <td>0.070905</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>10371</td>\n",
       "      <td>0.071436</td>\n",
       "      <td>0.054941</td>\n",
       "      <td>0.081052</td>\n",
       "      <td>0.073092</td>\n",
       "      <td>0.078257</td>\n",
       "      <td>0.079794</td>\n",
       "      <td>0.079706</td>\n",
       "      <td>0.070574</td>\n",
       "      <td>0.045558</td>\n",
       "      <td>0.085298</td>\n",
       "      <td>0.076828</td>\n",
       "      <td>0.098325</td>\n",
       "      <td>0.105140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>10372</td>\n",
       "      <td>0.065969</td>\n",
       "      <td>0.070944</td>\n",
       "      <td>0.081986</td>\n",
       "      <td>0.097059</td>\n",
       "      <td>0.060460</td>\n",
       "      <td>0.074575</td>\n",
       "      <td>0.075898</td>\n",
       "      <td>0.082430</td>\n",
       "      <td>0.067523</td>\n",
       "      <td>0.075627</td>\n",
       "      <td>0.072690</td>\n",
       "      <td>0.080653</td>\n",
       "      <td>0.094186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>10373</td>\n",
       "      <td>0.064076</td>\n",
       "      <td>0.059617</td>\n",
       "      <td>0.068402</td>\n",
       "      <td>0.065508</td>\n",
       "      <td>0.071631</td>\n",
       "      <td>0.073304</td>\n",
       "      <td>0.082295</td>\n",
       "      <td>0.099071</td>\n",
       "      <td>0.070661</td>\n",
       "      <td>0.077711</td>\n",
       "      <td>0.079130</td>\n",
       "      <td>0.085792</td>\n",
       "      <td>0.102804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>10374</td>\n",
       "      <td>0.096757</td>\n",
       "      <td>0.070155</td>\n",
       "      <td>0.075344</td>\n",
       "      <td>0.078161</td>\n",
       "      <td>0.083898</td>\n",
       "      <td>0.095841</td>\n",
       "      <td>0.082971</td>\n",
       "      <td>0.064405</td>\n",
       "      <td>0.062140</td>\n",
       "      <td>0.062560</td>\n",
       "      <td>0.065599</td>\n",
       "      <td>0.083483</td>\n",
       "      <td>0.078688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>10375</td>\n",
       "      <td>0.075515</td>\n",
       "      <td>0.068950</td>\n",
       "      <td>0.084826</td>\n",
       "      <td>0.082841</td>\n",
       "      <td>0.084274</td>\n",
       "      <td>0.083518</td>\n",
       "      <td>0.076025</td>\n",
       "      <td>0.080561</td>\n",
       "      <td>0.064524</td>\n",
       "      <td>0.085793</td>\n",
       "      <td>0.076493</td>\n",
       "      <td>0.069454</td>\n",
       "      <td>0.067224</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10375</th>\n",
       "      <td>10376</td>\n",
       "      <td>0.104943</td>\n",
       "      <td>0.087569</td>\n",
       "      <td>0.078062</td>\n",
       "      <td>0.064920</td>\n",
       "      <td>0.074846</td>\n",
       "      <td>0.071555</td>\n",
       "      <td>0.072005</td>\n",
       "      <td>0.054131</td>\n",
       "      <td>0.074243</td>\n",
       "      <td>0.070926</td>\n",
       "      <td>0.061757</td>\n",
       "      <td>0.089649</td>\n",
       "      <td>0.095394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10376</th>\n",
       "      <td>10377</td>\n",
       "      <td>0.085147</td>\n",
       "      <td>0.051365</td>\n",
       "      <td>0.070908</td>\n",
       "      <td>0.092854</td>\n",
       "      <td>0.067706</td>\n",
       "      <td>0.087282</td>\n",
       "      <td>0.088153</td>\n",
       "      <td>0.078411</td>\n",
       "      <td>0.091625</td>\n",
       "      <td>0.054568</td>\n",
       "      <td>0.091942</td>\n",
       "      <td>0.081097</td>\n",
       "      <td>0.058943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>10378</td>\n",
       "      <td>0.064191</td>\n",
       "      <td>0.089136</td>\n",
       "      <td>0.076302</td>\n",
       "      <td>0.058125</td>\n",
       "      <td>0.066813</td>\n",
       "      <td>0.055587</td>\n",
       "      <td>0.063345</td>\n",
       "      <td>0.090807</td>\n",
       "      <td>0.049263</td>\n",
       "      <td>0.120544</td>\n",
       "      <td>0.056998</td>\n",
       "      <td>0.092370</td>\n",
       "      <td>0.116518</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10378</th>\n",
       "      <td>10379</td>\n",
       "      <td>0.066030</td>\n",
       "      <td>0.066913</td>\n",
       "      <td>0.083268</td>\n",
       "      <td>0.087876</td>\n",
       "      <td>0.050072</td>\n",
       "      <td>0.081656</td>\n",
       "      <td>0.066006</td>\n",
       "      <td>0.096995</td>\n",
       "      <td>0.071613</td>\n",
       "      <td>0.093203</td>\n",
       "      <td>0.090239</td>\n",
       "      <td>0.075004</td>\n",
       "      <td>0.071124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10379</th>\n",
       "      <td>10380</td>\n",
       "      <td>0.073215</td>\n",
       "      <td>0.110733</td>\n",
       "      <td>0.077872</td>\n",
       "      <td>0.052068</td>\n",
       "      <td>0.085323</td>\n",
       "      <td>0.073216</td>\n",
       "      <td>0.067543</td>\n",
       "      <td>0.073484</td>\n",
       "      <td>0.066835</td>\n",
       "      <td>0.071361</td>\n",
       "      <td>0.082308</td>\n",
       "      <td>0.074528</td>\n",
       "      <td>0.091514</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>10381</td>\n",
       "      <td>0.066482</td>\n",
       "      <td>0.090634</td>\n",
       "      <td>0.074906</td>\n",
       "      <td>0.102707</td>\n",
       "      <td>0.071527</td>\n",
       "      <td>0.085694</td>\n",
       "      <td>0.074822</td>\n",
       "      <td>0.077174</td>\n",
       "      <td>0.072291</td>\n",
       "      <td>0.064037</td>\n",
       "      <td>0.070661</td>\n",
       "      <td>0.067004</td>\n",
       "      <td>0.082061</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>10382</td>\n",
       "      <td>0.074892</td>\n",
       "      <td>0.077363</td>\n",
       "      <td>0.072185</td>\n",
       "      <td>0.079004</td>\n",
       "      <td>0.098369</td>\n",
       "      <td>0.079989</td>\n",
       "      <td>0.078140</td>\n",
       "      <td>0.076804</td>\n",
       "      <td>0.087106</td>\n",
       "      <td>0.078522</td>\n",
       "      <td>0.073950</td>\n",
       "      <td>0.068743</td>\n",
       "      <td>0.054935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>10383</td>\n",
       "      <td>0.078168</td>\n",
       "      <td>0.073526</td>\n",
       "      <td>0.103417</td>\n",
       "      <td>0.063639</td>\n",
       "      <td>0.069290</td>\n",
       "      <td>0.067998</td>\n",
       "      <td>0.055815</td>\n",
       "      <td>0.069927</td>\n",
       "      <td>0.036222</td>\n",
       "      <td>0.113505</td>\n",
       "      <td>0.076193</td>\n",
       "      <td>0.087518</td>\n",
       "      <td>0.104784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>10384</td>\n",
       "      <td>0.077374</td>\n",
       "      <td>0.066866</td>\n",
       "      <td>0.077731</td>\n",
       "      <td>0.053734</td>\n",
       "      <td>0.072661</td>\n",
       "      <td>0.088706</td>\n",
       "      <td>0.077733</td>\n",
       "      <td>0.075562</td>\n",
       "      <td>0.072881</td>\n",
       "      <td>0.061298</td>\n",
       "      <td>0.103407</td>\n",
       "      <td>0.090302</td>\n",
       "      <td>0.081745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>10385</td>\n",
       "      <td>0.074972</td>\n",
       "      <td>0.101698</td>\n",
       "      <td>0.085343</td>\n",
       "      <td>0.069115</td>\n",
       "      <td>0.075315</td>\n",
       "      <td>0.078644</td>\n",
       "      <td>0.065965</td>\n",
       "      <td>0.072053</td>\n",
       "      <td>0.076399</td>\n",
       "      <td>0.090397</td>\n",
       "      <td>0.073383</td>\n",
       "      <td>0.075317</td>\n",
       "      <td>0.061400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>10386</td>\n",
       "      <td>0.084259</td>\n",
       "      <td>0.087039</td>\n",
       "      <td>0.060530</td>\n",
       "      <td>0.071594</td>\n",
       "      <td>0.085236</td>\n",
       "      <td>0.098511</td>\n",
       "      <td>0.086443</td>\n",
       "      <td>0.076173</td>\n",
       "      <td>0.096608</td>\n",
       "      <td>0.051190</td>\n",
       "      <td>0.066854</td>\n",
       "      <td>0.076989</td>\n",
       "      <td>0.058574</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>10387</td>\n",
       "      <td>0.089201</td>\n",
       "      <td>0.090124</td>\n",
       "      <td>0.079828</td>\n",
       "      <td>0.062266</td>\n",
       "      <td>0.078568</td>\n",
       "      <td>0.093179</td>\n",
       "      <td>0.068783</td>\n",
       "      <td>0.064360</td>\n",
       "      <td>0.060843</td>\n",
       "      <td>0.064583</td>\n",
       "      <td>0.100711</td>\n",
       "      <td>0.082114</td>\n",
       "      <td>0.065440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>10388</td>\n",
       "      <td>0.083297</td>\n",
       "      <td>0.063474</td>\n",
       "      <td>0.087431</td>\n",
       "      <td>0.063755</td>\n",
       "      <td>0.089624</td>\n",
       "      <td>0.076942</td>\n",
       "      <td>0.080899</td>\n",
       "      <td>0.063309</td>\n",
       "      <td>0.054278</td>\n",
       "      <td>0.067587</td>\n",
       "      <td>0.083576</td>\n",
       "      <td>0.100456</td>\n",
       "      <td>0.085371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>10389</td>\n",
       "      <td>0.070578</td>\n",
       "      <td>0.055655</td>\n",
       "      <td>0.095830</td>\n",
       "      <td>0.067718</td>\n",
       "      <td>0.075799</td>\n",
       "      <td>0.090398</td>\n",
       "      <td>0.081589</td>\n",
       "      <td>0.078081</td>\n",
       "      <td>0.052391</td>\n",
       "      <td>0.067246</td>\n",
       "      <td>0.112199</td>\n",
       "      <td>0.084900</td>\n",
       "      <td>0.067615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>10390</td>\n",
       "      <td>0.056661</td>\n",
       "      <td>0.060959</td>\n",
       "      <td>0.077281</td>\n",
       "      <td>0.076618</td>\n",
       "      <td>0.080368</td>\n",
       "      <td>0.069752</td>\n",
       "      <td>0.077950</td>\n",
       "      <td>0.102039</td>\n",
       "      <td>0.078214</td>\n",
       "      <td>0.081805</td>\n",
       "      <td>0.102258</td>\n",
       "      <td>0.069290</td>\n",
       "      <td>0.066805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>10391</td>\n",
       "      <td>0.084741</td>\n",
       "      <td>0.080903</td>\n",
       "      <td>0.078916</td>\n",
       "      <td>0.072247</td>\n",
       "      <td>0.089292</td>\n",
       "      <td>0.087799</td>\n",
       "      <td>0.087136</td>\n",
       "      <td>0.064981</td>\n",
       "      <td>0.055058</td>\n",
       "      <td>0.057144</td>\n",
       "      <td>0.051926</td>\n",
       "      <td>0.088242</td>\n",
       "      <td>0.101613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>10392</td>\n",
       "      <td>0.079542</td>\n",
       "      <td>0.080306</td>\n",
       "      <td>0.084435</td>\n",
       "      <td>0.067158</td>\n",
       "      <td>0.076786</td>\n",
       "      <td>0.068375</td>\n",
       "      <td>0.073047</td>\n",
       "      <td>0.061735</td>\n",
       "      <td>0.066151</td>\n",
       "      <td>0.067301</td>\n",
       "      <td>0.060264</td>\n",
       "      <td>0.123400</td>\n",
       "      <td>0.091498</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10393</td>\n",
       "      <td>0.093571</td>\n",
       "      <td>0.067082</td>\n",
       "      <td>0.076361</td>\n",
       "      <td>0.068817</td>\n",
       "      <td>0.084789</td>\n",
       "      <td>0.082485</td>\n",
       "      <td>0.076883</td>\n",
       "      <td>0.073485</td>\n",
       "      <td>0.070202</td>\n",
       "      <td>0.062599</td>\n",
       "      <td>0.105917</td>\n",
       "      <td>0.076687</td>\n",
       "      <td>0.061121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>10394</td>\n",
       "      <td>0.070986</td>\n",
       "      <td>0.073889</td>\n",
       "      <td>0.073786</td>\n",
       "      <td>0.093294</td>\n",
       "      <td>0.070265</td>\n",
       "      <td>0.079904</td>\n",
       "      <td>0.080684</td>\n",
       "      <td>0.078670</td>\n",
       "      <td>0.102302</td>\n",
       "      <td>0.058675</td>\n",
       "      <td>0.083269</td>\n",
       "      <td>0.073634</td>\n",
       "      <td>0.060641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>10395</td>\n",
       "      <td>0.065397</td>\n",
       "      <td>0.076982</td>\n",
       "      <td>0.105544</td>\n",
       "      <td>0.067937</td>\n",
       "      <td>0.060012</td>\n",
       "      <td>0.061207</td>\n",
       "      <td>0.058377</td>\n",
       "      <td>0.081579</td>\n",
       "      <td>0.041423</td>\n",
       "      <td>0.097226</td>\n",
       "      <td>0.091953</td>\n",
       "      <td>0.081605</td>\n",
       "      <td>0.110757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>10396</td>\n",
       "      <td>0.057103</td>\n",
       "      <td>0.088663</td>\n",
       "      <td>0.082675</td>\n",
       "      <td>0.064066</td>\n",
       "      <td>0.080646</td>\n",
       "      <td>0.051503</td>\n",
       "      <td>0.070439</td>\n",
       "      <td>0.088032</td>\n",
       "      <td>0.065381</td>\n",
       "      <td>0.093280</td>\n",
       "      <td>0.055697</td>\n",
       "      <td>0.098527</td>\n",
       "      <td>0.103987</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>10397</td>\n",
       "      <td>0.079732</td>\n",
       "      <td>0.075836</td>\n",
       "      <td>0.071045</td>\n",
       "      <td>0.068480</td>\n",
       "      <td>0.082737</td>\n",
       "      <td>0.088471</td>\n",
       "      <td>0.079463</td>\n",
       "      <td>0.083699</td>\n",
       "      <td>0.060356</td>\n",
       "      <td>0.078033</td>\n",
       "      <td>0.073000</td>\n",
       "      <td>0.068721</td>\n",
       "      <td>0.090430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>10398</td>\n",
       "      <td>0.087942</td>\n",
       "      <td>0.102519</td>\n",
       "      <td>0.081797</td>\n",
       "      <td>0.062577</td>\n",
       "      <td>0.089142</td>\n",
       "      <td>0.078962</td>\n",
       "      <td>0.074124</td>\n",
       "      <td>0.065244</td>\n",
       "      <td>0.060585</td>\n",
       "      <td>0.067460</td>\n",
       "      <td>0.059593</td>\n",
       "      <td>0.088377</td>\n",
       "      <td>0.081679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>10399</td>\n",
       "      <td>0.060962</td>\n",
       "      <td>0.062153</td>\n",
       "      <td>0.089645</td>\n",
       "      <td>0.065252</td>\n",
       "      <td>0.056507</td>\n",
       "      <td>0.063133</td>\n",
       "      <td>0.057602</td>\n",
       "      <td>0.101701</td>\n",
       "      <td>0.042089</td>\n",
       "      <td>0.112100</td>\n",
       "      <td>0.085740</td>\n",
       "      <td>0.080884</td>\n",
       "      <td>0.122232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>10400</td>\n",
       "      <td>0.100341</td>\n",
       "      <td>0.053888</td>\n",
       "      <td>0.071951</td>\n",
       "      <td>0.084929</td>\n",
       "      <td>0.087797</td>\n",
       "      <td>0.079625</td>\n",
       "      <td>0.088838</td>\n",
       "      <td>0.063183</td>\n",
       "      <td>0.065412</td>\n",
       "      <td>0.058388</td>\n",
       "      <td>0.070499</td>\n",
       "      <td>0.087281</td>\n",
       "      <td>0.087867</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10400 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id     Blues   Country  Electronic      Folk  International  \\\n",
       "0          1  0.063315  0.075692    0.090542  0.072905       0.076091   \n",
       "1          2  0.077229  0.072573    0.076020  0.070785       0.071869   \n",
       "2          3  0.086678  0.093590    0.083764  0.068918       0.085976   \n",
       "3          4  0.091982  0.071371    0.087378  0.063063       0.071639   \n",
       "4          5  0.065365  0.065053    0.102780  0.073557       0.069579   \n",
       "5          6  0.083222  0.054714    0.068426  0.102083       0.067446   \n",
       "6          7  0.078029  0.077064    0.090475  0.072782       0.068836   \n",
       "7          8  0.065526  0.089678    0.091900  0.080178       0.080373   \n",
       "8          9  0.061524  0.095653    0.083372  0.076891       0.060385   \n",
       "9         10  0.072775  0.090906    0.085638  0.058355       0.084724   \n",
       "10        11  0.062013  0.066908    0.087756  0.081195       0.070258   \n",
       "11        12  0.057166  0.082418    0.083838  0.072011       0.064622   \n",
       "12        13  0.060288  0.082419    0.073954  0.079141       0.075049   \n",
       "13        14  0.077218  0.071312    0.085374  0.076091       0.076240   \n",
       "14        15  0.082869  0.065331    0.085600  0.090809       0.072834   \n",
       "15        16  0.081125  0.059731    0.078956  0.070791       0.062627   \n",
       "16        17  0.067402  0.062600    0.075298  0.087968       0.063009   \n",
       "17        18  0.070382  0.069817    0.098745  0.081301       0.076376   \n",
       "18        19  0.106549  0.054941    0.075847  0.078921       0.071021   \n",
       "19        20  0.078994  0.061958    0.084672  0.075654       0.096350   \n",
       "20        21  0.067917  0.068907    0.083933  0.079165       0.074337   \n",
       "21        22  0.079539  0.074574    0.081311  0.065907       0.084252   \n",
       "22        23  0.075798  0.078323    0.084271  0.062432       0.086183   \n",
       "23        24  0.074730  0.068299    0.092346  0.057084       0.085940   \n",
       "24        25  0.068634  0.081433    0.068019  0.078735       0.071830   \n",
       "25        26  0.080510  0.062207    0.073753  0.078495       0.074625   \n",
       "26        27  0.065420  0.076456    0.086391  0.068839       0.075020   \n",
       "27        28  0.081667  0.080299    0.088056  0.066508       0.080673   \n",
       "28        29  0.068759  0.076838    0.066037  0.090094       0.075520   \n",
       "29        30  0.088023  0.061714    0.079093  0.070218       0.081618   \n",
       "...      ...       ...       ...         ...       ...            ...   \n",
       "10370  10371  0.071436  0.054941    0.081052  0.073092       0.078257   \n",
       "10371  10372  0.065969  0.070944    0.081986  0.097059       0.060460   \n",
       "10372  10373  0.064076  0.059617    0.068402  0.065508       0.071631   \n",
       "10373  10374  0.096757  0.070155    0.075344  0.078161       0.083898   \n",
       "10374  10375  0.075515  0.068950    0.084826  0.082841       0.084274   \n",
       "10375  10376  0.104943  0.087569    0.078062  0.064920       0.074846   \n",
       "10376  10377  0.085147  0.051365    0.070908  0.092854       0.067706   \n",
       "10377  10378  0.064191  0.089136    0.076302  0.058125       0.066813   \n",
       "10378  10379  0.066030  0.066913    0.083268  0.087876       0.050072   \n",
       "10379  10380  0.073215  0.110733    0.077872  0.052068       0.085323   \n",
       "10380  10381  0.066482  0.090634    0.074906  0.102707       0.071527   \n",
       "10381  10382  0.074892  0.077363    0.072185  0.079004       0.098369   \n",
       "10382  10383  0.078168  0.073526    0.103417  0.063639       0.069290   \n",
       "10383  10384  0.077374  0.066866    0.077731  0.053734       0.072661   \n",
       "10384  10385  0.074972  0.101698    0.085343  0.069115       0.075315   \n",
       "10385  10386  0.084259  0.087039    0.060530  0.071594       0.085236   \n",
       "10386  10387  0.089201  0.090124    0.079828  0.062266       0.078568   \n",
       "10387  10388  0.083297  0.063474    0.087431  0.063755       0.089624   \n",
       "10388  10389  0.070578  0.055655    0.095830  0.067718       0.075799   \n",
       "10389  10390  0.056661  0.060959    0.077281  0.076618       0.080368   \n",
       "10390  10391  0.084741  0.080903    0.078916  0.072247       0.089292   \n",
       "10391  10392  0.079542  0.080306    0.084435  0.067158       0.076786   \n",
       "10392  10393  0.093571  0.067082    0.076361  0.068817       0.084789   \n",
       "10393  10394  0.070986  0.073889    0.073786  0.093294       0.070265   \n",
       "10394  10395  0.065397  0.076982    0.105544  0.067937       0.060012   \n",
       "10395  10396  0.057103  0.088663    0.082675  0.064066       0.080646   \n",
       "10396  10397  0.079732  0.075836    0.071045  0.068480       0.082737   \n",
       "10397  10398  0.087942  0.102519    0.081797  0.062577       0.089142   \n",
       "10398  10399  0.060962  0.062153    0.089645  0.065252       0.056507   \n",
       "10399  10400  0.100341  0.053888    0.071951  0.084929       0.087797   \n",
       "\n",
       "           Jazz     Latin   New_Age  Pop_Rock       Rap    Reggae       RnB  \\\n",
       "0      0.058305  0.072097  0.071053  0.052059  0.096331  0.074679  0.084148   \n",
       "1      0.067309  0.075531  0.071660  0.066383  0.090268  0.086847  0.079983   \n",
       "2      0.063847  0.068652  0.063477  0.075029  0.082691  0.072139  0.072459   \n",
       "3      0.072388  0.063234  0.060040  0.057063  0.094825  0.100601  0.085286   \n",
       "4      0.053834  0.062173  0.074761  0.049168  0.117644  0.073616  0.087466   \n",
       "5      0.076184  0.078843  0.076289  0.101379  0.072598  0.090601  0.056872   \n",
       "6      0.060585  0.071947  0.072302  0.066916  0.097056  0.087280  0.077138   \n",
       "7      0.058853  0.063003  0.074479  0.070979  0.109010  0.076619  0.070192   \n",
       "8      0.065853  0.061284  0.084767  0.069689  0.112807  0.093570  0.064286   \n",
       "9      0.064780  0.069944  0.071284  0.069426  0.108414  0.080399  0.068026   \n",
       "10     0.059591  0.071867  0.078433  0.071667  0.101611  0.094100  0.075352   \n",
       "11     0.055448  0.057169  0.102362  0.066406  0.125425  0.069404  0.072034   \n",
       "12     0.063762  0.071992  0.081489  0.102075  0.095135  0.074117  0.062444   \n",
       "13     0.067936  0.070170  0.064333  0.048881  0.092964  0.069333  0.087933   \n",
       "14     0.075293  0.078815  0.069379  0.059064  0.076434  0.072960  0.074654   \n",
       "15     0.081920  0.075243  0.072894  0.065789  0.064003  0.100862  0.078679   \n",
       "16     0.072892  0.069583  0.094699  0.098961  0.084056  0.120014  0.056272   \n",
       "17     0.056667  0.065029  0.067343  0.054231  0.127732  0.077355  0.074239   \n",
       "18     0.095883  0.075269  0.070840  0.059786  0.062163  0.099669  0.081815   \n",
       "19     0.074523  0.074882  0.079053  0.049834  0.084343  0.081490  0.070728   \n",
       "20     0.067735  0.078367  0.077923  0.064185  0.068023  0.077703  0.083942   \n",
       "21     0.059790  0.078967  0.061356  0.059635  0.078660  0.067054  0.090632   \n",
       "22     0.069211  0.065605  0.079864  0.057539  0.093212  0.098743  0.078306   \n",
       "23     0.068831  0.070859  0.068344  0.047245  0.083141  0.072742  0.095858   \n",
       "24     0.062209  0.074855  0.080081  0.105566  0.086716  0.089674  0.059448   \n",
       "25     0.078448  0.076327  0.072869  0.073565  0.076505  0.100786  0.079194   \n",
       "26     0.062765  0.067025  0.081501  0.054307  0.108953  0.074135  0.078081   \n",
       "27     0.065967  0.066349  0.065586  0.059175  0.105811  0.076263  0.080206   \n",
       "28     0.073241  0.077347  0.082169  0.126539  0.077431  0.081539  0.052050   \n",
       "29     0.085140  0.084659  0.062246  0.060733  0.059945  0.114490  0.081215   \n",
       "...         ...       ...       ...       ...       ...       ...       ...   \n",
       "10370  0.079794  0.079706  0.070574  0.045558  0.085298  0.076828  0.098325   \n",
       "10371  0.074575  0.075898  0.082430  0.067523  0.075627  0.072690  0.080653   \n",
       "10372  0.073304  0.082295  0.099071  0.070661  0.077711  0.079130  0.085792   \n",
       "10373  0.095841  0.082971  0.064405  0.062140  0.062560  0.065599  0.083483   \n",
       "10374  0.083518  0.076025  0.080561  0.064524  0.085793  0.076493  0.069454   \n",
       "10375  0.071555  0.072005  0.054131  0.074243  0.070926  0.061757  0.089649   \n",
       "10376  0.087282  0.088153  0.078411  0.091625  0.054568  0.091942  0.081097   \n",
       "10377  0.055587  0.063345  0.090807  0.049263  0.120544  0.056998  0.092370   \n",
       "10378  0.081656  0.066006  0.096995  0.071613  0.093203  0.090239  0.075004   \n",
       "10379  0.073216  0.067543  0.073484  0.066835  0.071361  0.082308  0.074528   \n",
       "10380  0.085694  0.074822  0.077174  0.072291  0.064037  0.070661  0.067004   \n",
       "10381  0.079989  0.078140  0.076804  0.087106  0.078522  0.073950  0.068743   \n",
       "10382  0.067998  0.055815  0.069927  0.036222  0.113505  0.076193  0.087518   \n",
       "10383  0.088706  0.077733  0.075562  0.072881  0.061298  0.103407  0.090302   \n",
       "10384  0.078644  0.065965  0.072053  0.076399  0.090397  0.073383  0.075317   \n",
       "10385  0.098511  0.086443  0.076173  0.096608  0.051190  0.066854  0.076989   \n",
       "10386  0.093179  0.068783  0.064360  0.060843  0.064583  0.100711  0.082114   \n",
       "10387  0.076942  0.080899  0.063309  0.054278  0.067587  0.083576  0.100456   \n",
       "10388  0.090398  0.081589  0.078081  0.052391  0.067246  0.112199  0.084900   \n",
       "10389  0.069752  0.077950  0.102039  0.078214  0.081805  0.102258  0.069290   \n",
       "10390  0.087799  0.087136  0.064981  0.055058  0.057144  0.051926  0.088242   \n",
       "10391  0.068375  0.073047  0.061735  0.066151  0.067301  0.060264  0.123400   \n",
       "10392  0.082485  0.076883  0.073485  0.070202  0.062599  0.105917  0.076687   \n",
       "10393  0.079904  0.080684  0.078670  0.102302  0.058675  0.083269  0.073634   \n",
       "10394  0.061207  0.058377  0.081579  0.041423  0.097226  0.091953  0.081605   \n",
       "10395  0.051503  0.070439  0.088032  0.065381  0.093280  0.055697  0.098527   \n",
       "10396  0.088471  0.079463  0.083699  0.060356  0.078033  0.073000  0.068721   \n",
       "10397  0.078962  0.074124  0.065244  0.060585  0.067460  0.059593  0.088377   \n",
       "10398  0.063133  0.057602  0.101701  0.042089  0.112100  0.085740  0.080884   \n",
       "10399  0.079625  0.088838  0.063183  0.065412  0.058388  0.070499  0.087281   \n",
       "\n",
       "          Vocal  \n",
       "0      0.112782  \n",
       "1      0.093543  \n",
       "2      0.082780  \n",
       "3      0.081129  \n",
       "4      0.105002  \n",
       "5      0.071342  \n",
       "6      0.079590  \n",
       "7      0.069210  \n",
       "8      0.069919  \n",
       "9      0.075328  \n",
       "10     0.079250  \n",
       "11     0.091696  \n",
       "12     0.078134  \n",
       "13     0.112215  \n",
       "14     0.095959  \n",
       "15     0.107380  \n",
       "16     0.047247  \n",
       "17     0.080784  \n",
       "18     0.067297  \n",
       "19     0.087520  \n",
       "20     0.107864  \n",
       "21     0.118324  \n",
       "22     0.070513  \n",
       "23     0.114581  \n",
       "24     0.072800  \n",
       "25     0.072716  \n",
       "26     0.101106  \n",
       "27     0.083439  \n",
       "28     0.052436  \n",
       "29     0.070905  \n",
       "...         ...  \n",
       "10370  0.105140  \n",
       "10371  0.094186  \n",
       "10372  0.102804  \n",
       "10373  0.078688  \n",
       "10374  0.067224  \n",
       "10375  0.095394  \n",
       "10376  0.058943  \n",
       "10377  0.116518  \n",
       "10378  0.071124  \n",
       "10379  0.091514  \n",
       "10380  0.082061  \n",
       "10381  0.054935  \n",
       "10382  0.104784  \n",
       "10383  0.081745  \n",
       "10384  0.061400  \n",
       "10385  0.058574  \n",
       "10386  0.065440  \n",
       "10387  0.085371  \n",
       "10388  0.067615  \n",
       "10389  0.066805  \n",
       "10390  0.101613  \n",
       "10391  0.091498  \n",
       "10392  0.061121  \n",
       "10393  0.060641  \n",
       "10394  0.110757  \n",
       "10395  0.103987  \n",
       "10396  0.090430  \n",
       "10397  0.081679  \n",
       "10398  0.122232  \n",
       "10399  0.087867  \n",
       "\n",
       "[10400 rows x 14 columns]"
      ]
     },
     "execution_count": 387,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.read_csv(filepath_or_buffer='prediction2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Blues</th>\n",
       "      <th>Country</th>\n",
       "      <th>Electronic</th>\n",
       "      <th>Folk</th>\n",
       "      <th>International</th>\n",
       "      <th>Jazz</th>\n",
       "      <th>Latin</th>\n",
       "      <th>New_Age</th>\n",
       "      <th>Pop_Rock</th>\n",
       "      <th>Rap</th>\n",
       "      <th>Reggae</th>\n",
       "      <th>RnB</th>\n",
       "      <th>Vocal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.0964</td>\n",
       "      <td>0.0884</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0137</td>\n",
       "      <td>0.1214</td>\n",
       "      <td>0.0883</td>\n",
       "      <td>0.0765</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0445</td>\n",
       "      <td>0.1193</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.0804</td>\n",
       "      <td>0.0376</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1044</td>\n",
       "      <td>0.0118</td>\n",
       "      <td>0.1562</td>\n",
       "      <td>0.0585</td>\n",
       "      <td>0.1633</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0356</td>\n",
       "      <td>0.0788</td>\n",
       "      <td>0.0529</td>\n",
       "      <td>0.1185</td>\n",
       "      <td>0.1057</td>\n",
       "      <td>0.1041</td>\n",
       "      <td>0.0075</td>\n",
       "      <td>0.0481</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.0238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.1234</td>\n",
       "      <td>0.0931</td>\n",
       "      <td>0.0126</td>\n",
       "      <td>0.1224</td>\n",
       "      <td>0.0627</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0764</td>\n",
       "      <td>0.0812</td>\n",
       "      <td>0.1337</td>\n",
       "      <td>0.0357</td>\n",
       "      <td>0.0937</td>\n",
       "      <td>0.0930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0915</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.0947</td>\n",
       "      <td>0.0509</td>\n",
       "      <td>0.0335</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.0202</td>\n",
       "      <td>0.1012</td>\n",
       "      <td>0.0365</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.0269</td>\n",
       "      <td>0.0928</td>\n",
       "      <td>0.1235</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.1310</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.0676</td>\n",
       "      <td>0.0737</td>\n",
       "      <td>0.0690</td>\n",
       "      <td>0.0962</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.0019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0336</td>\n",
       "      <td>0.1151</td>\n",
       "      <td>0.0501</td>\n",
       "      <td>0.0919</td>\n",
       "      <td>0.1283</td>\n",
       "      <td>0.1361</td>\n",
       "      <td>0.0458</td>\n",
       "      <td>0.1260</td>\n",
       "      <td>0.0176</td>\n",
       "      <td>0.0305</td>\n",
       "      <td>0.0774</td>\n",
       "      <td>0.0585</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.1595</td>\n",
       "      <td>0.1299</td>\n",
       "      <td>0.0129</td>\n",
       "      <td>0.0179</td>\n",
       "      <td>0.0571</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.0279</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.1641</td>\n",
       "      <td>0.0026</td>\n",
       "      <td>0.1366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.1182</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0795</td>\n",
       "      <td>0.1007</td>\n",
       "      <td>0.0196</td>\n",
       "      <td>0.1387</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.1452</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0756</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.0061</td>\n",
       "      <td>0.1402</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.1327</td>\n",
       "      <td>0.1366</td>\n",
       "      <td>0.1036</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.1167</td>\n",
       "      <td>0.0140</td>\n",
       "      <td>0.1400</td>\n",
       "      <td>0.0552</td>\n",
       "      <td>0.0399</td>\n",
       "      <td>0.0328</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11</td>\n",
       "      <td>0.0370</td>\n",
       "      <td>0.0948</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.1195</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0041</td>\n",
       "      <td>0.1166</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.1101</td>\n",
       "      <td>0.0846</td>\n",
       "      <td>0.0667</td>\n",
       "      <td>0.1230</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12</td>\n",
       "      <td>0.0027</td>\n",
       "      <td>0.0425</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.1303</td>\n",
       "      <td>0.1457</td>\n",
       "      <td>0.0958</td>\n",
       "      <td>0.0175</td>\n",
       "      <td>0.1712</td>\n",
       "      <td>0.1443</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1047</td>\n",
       "      <td>0.0109</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13</td>\n",
       "      <td>0.0640</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.0151</td>\n",
       "      <td>0.0731</td>\n",
       "      <td>0.0649</td>\n",
       "      <td>0.1837</td>\n",
       "      <td>0.0154</td>\n",
       "      <td>0.0461</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.1571</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14</td>\n",
       "      <td>0.0609</td>\n",
       "      <td>0.1177</td>\n",
       "      <td>0.1241</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.0316</td>\n",
       "      <td>0.0545</td>\n",
       "      <td>0.0212</td>\n",
       "      <td>0.0940</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.0093</td>\n",
       "      <td>0.1316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15</td>\n",
       "      <td>0.1308</td>\n",
       "      <td>0.0136</td>\n",
       "      <td>0.0813</td>\n",
       "      <td>0.1107</td>\n",
       "      <td>0.0980</td>\n",
       "      <td>0.0299</td>\n",
       "      <td>0.0597</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.0220</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.1251</td>\n",
       "      <td>0.0833</td>\n",
       "      <td>0.0933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0761</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.1124</td>\n",
       "      <td>0.0645</td>\n",
       "      <td>0.0574</td>\n",
       "      <td>0.0598</td>\n",
       "      <td>0.0881</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.1072</td>\n",
       "      <td>0.0758</td>\n",
       "      <td>0.1410</td>\n",
       "      <td>0.0612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17</td>\n",
       "      <td>0.0306</td>\n",
       "      <td>0.1355</td>\n",
       "      <td>0.1430</td>\n",
       "      <td>0.0412</td>\n",
       "      <td>0.0265</td>\n",
       "      <td>0.1197</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1359</td>\n",
       "      <td>0.1261</td>\n",
       "      <td>0.0117</td>\n",
       "      <td>0.1420</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.0070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>0.0986</td>\n",
       "      <td>0.0364</td>\n",
       "      <td>0.0910</td>\n",
       "      <td>0.1408</td>\n",
       "      <td>0.0454</td>\n",
       "      <td>0.1110</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.1168</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.0781</td>\n",
       "      <td>0.0722</td>\n",
       "      <td>0.0550</td>\n",
       "      <td>0.0414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19</td>\n",
       "      <td>0.1257</td>\n",
       "      <td>0.1139</td>\n",
       "      <td>0.0612</td>\n",
       "      <td>0.1244</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.0172</td>\n",
       "      <td>0.0541</td>\n",
       "      <td>0.1340</td>\n",
       "      <td>0.0716</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0002</td>\n",
       "      <td>0.0971</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20</td>\n",
       "      <td>0.0169</td>\n",
       "      <td>0.1433</td>\n",
       "      <td>0.0285</td>\n",
       "      <td>0.1060</td>\n",
       "      <td>0.0671</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.1482</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.1700</td>\n",
       "      <td>0.0062</td>\n",
       "      <td>0.0355</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.0439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1415</td>\n",
       "      <td>0.0978</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.0103</td>\n",
       "      <td>0.0858</td>\n",
       "      <td>0.1270</td>\n",
       "      <td>0.2315</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0032</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.0294</td>\n",
       "      <td>0.1593</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0793</td>\n",
       "      <td>0.1495</td>\n",
       "      <td>0.0059</td>\n",
       "      <td>0.1207</td>\n",
       "      <td>0.0657</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.0023</td>\n",
       "      <td>0.0662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23</td>\n",
       "      <td>0.0561</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.0838</td>\n",
       "      <td>0.0060</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.1133</td>\n",
       "      <td>0.1158</td>\n",
       "      <td>0.0743</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24</td>\n",
       "      <td>0.1109</td>\n",
       "      <td>0.0392</td>\n",
       "      <td>0.0324</td>\n",
       "      <td>0.0245</td>\n",
       "      <td>0.1291</td>\n",
       "      <td>0.1132</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.1262</td>\n",
       "      <td>0.0434</td>\n",
       "      <td>0.0500</td>\n",
       "      <td>0.0684</td>\n",
       "      <td>0.1281</td>\n",
       "      <td>0.0487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>25</td>\n",
       "      <td>0.0256</td>\n",
       "      <td>0.0875</td>\n",
       "      <td>0.0426</td>\n",
       "      <td>0.1033</td>\n",
       "      <td>0.0895</td>\n",
       "      <td>0.1792</td>\n",
       "      <td>0.0389</td>\n",
       "      <td>0.0723</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.0083</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>26</td>\n",
       "      <td>0.1492</td>\n",
       "      <td>0.0575</td>\n",
       "      <td>0.0492</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0927</td>\n",
       "      <td>0.1396</td>\n",
       "      <td>0.0354</td>\n",
       "      <td>0.0953</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.1329</td>\n",
       "      <td>0.0221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>27</td>\n",
       "      <td>0.0132</td>\n",
       "      <td>0.0252</td>\n",
       "      <td>0.0815</td>\n",
       "      <td>0.1499</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0790</td>\n",
       "      <td>0.1300</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.0644</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.0074</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>28</td>\n",
       "      <td>0.1474</td>\n",
       "      <td>0.0251</td>\n",
       "      <td>0.0110</td>\n",
       "      <td>0.0475</td>\n",
       "      <td>0.0859</td>\n",
       "      <td>0.1204</td>\n",
       "      <td>0.1246</td>\n",
       "      <td>0.0309</td>\n",
       "      <td>0.1215</td>\n",
       "      <td>0.0672</td>\n",
       "      <td>0.0776</td>\n",
       "      <td>0.0525</td>\n",
       "      <td>0.0883</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>29</td>\n",
       "      <td>0.0485</td>\n",
       "      <td>0.0941</td>\n",
       "      <td>0.0439</td>\n",
       "      <td>0.1277</td>\n",
       "      <td>0.0030</td>\n",
       "      <td>0.0745</td>\n",
       "      <td>0.0249</td>\n",
       "      <td>0.0965</td>\n",
       "      <td>0.0971</td>\n",
       "      <td>0.0586</td>\n",
       "      <td>0.1091</td>\n",
       "      <td>0.1005</td>\n",
       "      <td>0.1215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>30</td>\n",
       "      <td>0.1078</td>\n",
       "      <td>0.0042</td>\n",
       "      <td>0.1286</td>\n",
       "      <td>0.1068</td>\n",
       "      <td>0.0223</td>\n",
       "      <td>0.0857</td>\n",
       "      <td>0.1143</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.1278</td>\n",
       "      <td>0.0264</td>\n",
       "      <td>0.1223</td>\n",
       "      <td>0.0616</td>\n",
       "      <td>0.0069</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10370</th>\n",
       "      <td>10371</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.1285</td>\n",
       "      <td>0.0473</td>\n",
       "      <td>0.1097</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.1533</td>\n",
       "      <td>0.0127</td>\n",
       "      <td>0.0890</td>\n",
       "      <td>0.0326</td>\n",
       "      <td>0.0272</td>\n",
       "      <td>0.1118</td>\n",
       "      <td>0.0043</td>\n",
       "      <td>0.1171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10371</th>\n",
       "      <td>10372</td>\n",
       "      <td>0.1832</td>\n",
       "      <td>0.1448</td>\n",
       "      <td>0.0544</td>\n",
       "      <td>0.1176</td>\n",
       "      <td>0.0850</td>\n",
       "      <td>0.0053</td>\n",
       "      <td>0.0452</td>\n",
       "      <td>0.0203</td>\n",
       "      <td>0.1791</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0556</td>\n",
       "      <td>0.0407</td>\n",
       "      <td>0.0470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10372</th>\n",
       "      <td>10373</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0990</td>\n",
       "      <td>0.0486</td>\n",
       "      <td>0.0298</td>\n",
       "      <td>0.1113</td>\n",
       "      <td>0.0998</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0418</td>\n",
       "      <td>0.1082</td>\n",
       "      <td>0.0979</td>\n",
       "      <td>0.0817</td>\n",
       "      <td>0.0520</td>\n",
       "      <td>0.1111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10373</th>\n",
       "      <td>10374</td>\n",
       "      <td>0.1128</td>\n",
       "      <td>0.0009</td>\n",
       "      <td>0.1026</td>\n",
       "      <td>0.0789</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.0911</td>\n",
       "      <td>0.0508</td>\n",
       "      <td>0.1799</td>\n",
       "      <td>0.1491</td>\n",
       "      <td>0.0730</td>\n",
       "      <td>0.0606</td>\n",
       "      <td>0.0029</td>\n",
       "      <td>0.0534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10374</th>\n",
       "      <td>10375</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.0946</td>\n",
       "      <td>0.0985</td>\n",
       "      <td>0.0740</td>\n",
       "      <td>0.1171</td>\n",
       "      <td>0.0914</td>\n",
       "      <td>0.1127</td>\n",
       "      <td>0.1309</td>\n",
       "      <td>0.0565</td>\n",
       "      <td>0.1004</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.0361</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10375</th>\n",
       "      <td>10376</td>\n",
       "      <td>0.1142</td>\n",
       "      <td>0.0688</td>\n",
       "      <td>0.1304</td>\n",
       "      <td>0.0056</td>\n",
       "      <td>0.0450</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0820</td>\n",
       "      <td>0.0932</td>\n",
       "      <td>0.0315</td>\n",
       "      <td>0.0629</td>\n",
       "      <td>0.1317</td>\n",
       "      <td>0.1240</td>\n",
       "      <td>0.1090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10376</th>\n",
       "      <td>10377</td>\n",
       "      <td>0.0417</td>\n",
       "      <td>0.1617</td>\n",
       "      <td>0.0063</td>\n",
       "      <td>0.0519</td>\n",
       "      <td>0.0291</td>\n",
       "      <td>0.0139</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1484</td>\n",
       "      <td>0.0429</td>\n",
       "      <td>0.1108</td>\n",
       "      <td>0.1654</td>\n",
       "      <td>0.0993</td>\n",
       "      <td>0.0267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10377</th>\n",
       "      <td>10378</td>\n",
       "      <td>0.0512</td>\n",
       "      <td>0.0219</td>\n",
       "      <td>0.0395</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0770</td>\n",
       "      <td>0.0447</td>\n",
       "      <td>0.1472</td>\n",
       "      <td>0.0493</td>\n",
       "      <td>0.1517</td>\n",
       "      <td>0.0744</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.1254</td>\n",
       "      <td>0.0844</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10378</th>\n",
       "      <td>10379</td>\n",
       "      <td>0.0968</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0807</td>\n",
       "      <td>0.0762</td>\n",
       "      <td>0.2096</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0332</td>\n",
       "      <td>0.0207</td>\n",
       "      <td>0.0380</td>\n",
       "      <td>0.1967</td>\n",
       "      <td>0.0584</td>\n",
       "      <td>0.0497</td>\n",
       "      <td>0.0412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10379</th>\n",
       "      <td>10380</td>\n",
       "      <td>0.0048</td>\n",
       "      <td>0.0899</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0576</td>\n",
       "      <td>0.0901</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0546</td>\n",
       "      <td>0.1274</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.1055</td>\n",
       "      <td>0.0383</td>\n",
       "      <td>0.1051</td>\n",
       "      <td>0.0908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10380</th>\n",
       "      <td>10381</td>\n",
       "      <td>0.0768</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.0477</td>\n",
       "      <td>0.1535</td>\n",
       "      <td>0.1326</td>\n",
       "      <td>0.0007</td>\n",
       "      <td>0.0636</td>\n",
       "      <td>0.0085</td>\n",
       "      <td>0.1610</td>\n",
       "      <td>0.1093</td>\n",
       "      <td>0.0611</td>\n",
       "      <td>0.0411</td>\n",
       "      <td>0.0345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10381</th>\n",
       "      <td>10382</td>\n",
       "      <td>0.0799</td>\n",
       "      <td>0.1181</td>\n",
       "      <td>0.0631</td>\n",
       "      <td>0.0860</td>\n",
       "      <td>0.0704</td>\n",
       "      <td>0.0798</td>\n",
       "      <td>0.0786</td>\n",
       "      <td>0.0590</td>\n",
       "      <td>0.0757</td>\n",
       "      <td>0.1196</td>\n",
       "      <td>0.0613</td>\n",
       "      <td>0.0853</td>\n",
       "      <td>0.0232</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10382</th>\n",
       "      <td>10383</td>\n",
       "      <td>0.0739</td>\n",
       "      <td>0.0329</td>\n",
       "      <td>0.1019</td>\n",
       "      <td>0.1070</td>\n",
       "      <td>0.0463</td>\n",
       "      <td>0.1145</td>\n",
       "      <td>0.1374</td>\n",
       "      <td>0.1130</td>\n",
       "      <td>0.0811</td>\n",
       "      <td>0.0067</td>\n",
       "      <td>0.0499</td>\n",
       "      <td>0.1279</td>\n",
       "      <td>0.0076</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10383</th>\n",
       "      <td>10384</td>\n",
       "      <td>0.0495</td>\n",
       "      <td>0.0422</td>\n",
       "      <td>0.1503</td>\n",
       "      <td>0.0464</td>\n",
       "      <td>0.0898</td>\n",
       "      <td>0.0725</td>\n",
       "      <td>0.0769</td>\n",
       "      <td>0.1273</td>\n",
       "      <td>0.1073</td>\n",
       "      <td>0.0920</td>\n",
       "      <td>0.0206</td>\n",
       "      <td>0.1090</td>\n",
       "      <td>0.0162</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10384</th>\n",
       "      <td>10385</td>\n",
       "      <td>0.0073</td>\n",
       "      <td>0.0601</td>\n",
       "      <td>0.0236</td>\n",
       "      <td>0.1382</td>\n",
       "      <td>0.0954</td>\n",
       "      <td>0.0033</td>\n",
       "      <td>0.1824</td>\n",
       "      <td>0.0904</td>\n",
       "      <td>0.0436</td>\n",
       "      <td>0.1052</td>\n",
       "      <td>0.0087</td>\n",
       "      <td>0.1580</td>\n",
       "      <td>0.0839</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10385</th>\n",
       "      <td>10386</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.0065</td>\n",
       "      <td>0.1397</td>\n",
       "      <td>0.0604</td>\n",
       "      <td>0.0618</td>\n",
       "      <td>0.0155</td>\n",
       "      <td>0.0387</td>\n",
       "      <td>0.0699</td>\n",
       "      <td>0.1516</td>\n",
       "      <td>0.0208</td>\n",
       "      <td>0.1934</td>\n",
       "      <td>0.1180</td>\n",
       "      <td>0.0605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10386</th>\n",
       "      <td>10387</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>0.1122</td>\n",
       "      <td>0.0134</td>\n",
       "      <td>0.0801</td>\n",
       "      <td>0.1173</td>\n",
       "      <td>0.0149</td>\n",
       "      <td>0.0888</td>\n",
       "      <td>0.0455</td>\n",
       "      <td>0.1190</td>\n",
       "      <td>0.1225</td>\n",
       "      <td>0.0600</td>\n",
       "      <td>0.0903</td>\n",
       "      <td>0.0154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10387</th>\n",
       "      <td>10388</td>\n",
       "      <td>0.0423</td>\n",
       "      <td>0.0974</td>\n",
       "      <td>0.0759</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.1067</td>\n",
       "      <td>0.1463</td>\n",
       "      <td>0.1034</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.0187</td>\n",
       "      <td>0.0698</td>\n",
       "      <td>0.0591</td>\n",
       "      <td>0.1152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10388</th>\n",
       "      <td>10389</td>\n",
       "      <td>0.2089</td>\n",
       "      <td>0.0101</td>\n",
       "      <td>0.0462</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.1183</td>\n",
       "      <td>0.0268</td>\n",
       "      <td>0.1071</td>\n",
       "      <td>0.1976</td>\n",
       "      <td>0.0854</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.0386</td>\n",
       "      <td>0.0258</td>\n",
       "      <td>0.0190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10389</th>\n",
       "      <td>10390</td>\n",
       "      <td>0.1547</td>\n",
       "      <td>0.0289</td>\n",
       "      <td>0.0019</td>\n",
       "      <td>0.1106</td>\n",
       "      <td>0.1048</td>\n",
       "      <td>0.0025</td>\n",
       "      <td>0.0638</td>\n",
       "      <td>0.0582</td>\n",
       "      <td>0.0771</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0453</td>\n",
       "      <td>0.1413</td>\n",
       "      <td>0.0727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10390</th>\n",
       "      <td>10391</td>\n",
       "      <td>0.1252</td>\n",
       "      <td>0.0632</td>\n",
       "      <td>0.0866</td>\n",
       "      <td>0.0894</td>\n",
       "      <td>0.0275</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.1138</td>\n",
       "      <td>0.0542</td>\n",
       "      <td>0.1381</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0503</td>\n",
       "      <td>0.0666</td>\n",
       "      <td>0.0395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10391</th>\n",
       "      <td>10392</td>\n",
       "      <td>0.1164</td>\n",
       "      <td>0.0099</td>\n",
       "      <td>0.0082</td>\n",
       "      <td>0.0648</td>\n",
       "      <td>0.0226</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.0358</td>\n",
       "      <td>0.0446</td>\n",
       "      <td>0.1760</td>\n",
       "      <td>0.1603</td>\n",
       "      <td>0.0702</td>\n",
       "      <td>0.1269</td>\n",
       "      <td>0.0375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10392</th>\n",
       "      <td>10393</td>\n",
       "      <td>0.0224</td>\n",
       "      <td>0.0945</td>\n",
       "      <td>0.1098</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.0162</td>\n",
       "      <td>0.0982</td>\n",
       "      <td>0.0397</td>\n",
       "      <td>0.1264</td>\n",
       "      <td>0.0092</td>\n",
       "      <td>0.0655</td>\n",
       "      <td>0.0424</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.1550</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10393</th>\n",
       "      <td>10394</td>\n",
       "      <td>0.0720</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.1438</td>\n",
       "      <td>0.1017</td>\n",
       "      <td>0.0361</td>\n",
       "      <td>0.1172</td>\n",
       "      <td>0.0539</td>\n",
       "      <td>0.0829</td>\n",
       "      <td>0.0382</td>\n",
       "      <td>0.0913</td>\n",
       "      <td>0.0646</td>\n",
       "      <td>0.0010</td>\n",
       "      <td>0.1156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10394</th>\n",
       "      <td>10395</td>\n",
       "      <td>0.1076</td>\n",
       "      <td>0.0340</td>\n",
       "      <td>0.0952</td>\n",
       "      <td>0.0691</td>\n",
       "      <td>0.0842</td>\n",
       "      <td>0.0628</td>\n",
       "      <td>0.0112</td>\n",
       "      <td>0.1383</td>\n",
       "      <td>0.1369</td>\n",
       "      <td>0.0120</td>\n",
       "      <td>0.1362</td>\n",
       "      <td>0.0194</td>\n",
       "      <td>0.0932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10395</th>\n",
       "      <td>10396</td>\n",
       "      <td>0.0440</td>\n",
       "      <td>0.0441</td>\n",
       "      <td>0.1056</td>\n",
       "      <td>0.0639</td>\n",
       "      <td>0.0210</td>\n",
       "      <td>0.0938</td>\n",
       "      <td>0.0738</td>\n",
       "      <td>0.0874</td>\n",
       "      <td>0.1423</td>\n",
       "      <td>0.1149</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.1243</td>\n",
       "      <td>0.0546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10396</th>\n",
       "      <td>10397</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0733</td>\n",
       "      <td>0.0637</td>\n",
       "      <td>0.1395</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.1222</td>\n",
       "      <td>0.0192</td>\n",
       "      <td>0.0307</td>\n",
       "      <td>0.0869</td>\n",
       "      <td>0.0303</td>\n",
       "      <td>0.1393</td>\n",
       "      <td>0.1212</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10397</th>\n",
       "      <td>10398</td>\n",
       "      <td>0.0726</td>\n",
       "      <td>0.1146</td>\n",
       "      <td>0.0490</td>\n",
       "      <td>0.0287</td>\n",
       "      <td>0.0634</td>\n",
       "      <td>0.1135</td>\n",
       "      <td>0.0703</td>\n",
       "      <td>0.1205</td>\n",
       "      <td>0.0922</td>\n",
       "      <td>0.1079</td>\n",
       "      <td>0.0569</td>\n",
       "      <td>0.0839</td>\n",
       "      <td>0.0265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10398</th>\n",
       "      <td>10399</td>\n",
       "      <td>0.0274</td>\n",
       "      <td>0.0865</td>\n",
       "      <td>0.0825</td>\n",
       "      <td>0.0559</td>\n",
       "      <td>0.0121</td>\n",
       "      <td>0.1230</td>\n",
       "      <td>0.0047</td>\n",
       "      <td>0.0870</td>\n",
       "      <td>0.0489</td>\n",
       "      <td>0.1086</td>\n",
       "      <td>0.1150</td>\n",
       "      <td>0.1648</td>\n",
       "      <td>0.0837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10399</th>\n",
       "      <td>10400</td>\n",
       "      <td>0.1178</td>\n",
       "      <td>0.0021</td>\n",
       "      <td>0.1376</td>\n",
       "      <td>0.0292</td>\n",
       "      <td>0.1612</td>\n",
       "      <td>0.0036</td>\n",
       "      <td>0.1958</td>\n",
       "      <td>0.0232</td>\n",
       "      <td>0.1594</td>\n",
       "      <td>0.0018</td>\n",
       "      <td>0.0816</td>\n",
       "      <td>0.0255</td>\n",
       "      <td>0.0613</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10400 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          Id   Blues  Country  Electronic    Folk  International    Jazz  \\\n",
       "0          1  0.0964   0.0884      0.0121  0.1004         0.0137  0.1214   \n",
       "1          2  0.0121   0.0804      0.0376  0.0289         0.1310  0.0684   \n",
       "2          3  0.1291   0.0985      0.0691  0.0356         0.0788  0.0529   \n",
       "3          4  0.0453   0.1234      0.0931  0.0126         0.1224  0.0627   \n",
       "4          5  0.0600   0.0915      0.0667  0.0947         0.0509  0.0335   \n",
       "5          6  0.0269   0.0928      0.1235  0.0598         0.1310  0.1400   \n",
       "6          7  0.0890   0.0336      0.1151  0.0501         0.0919  0.1283   \n",
       "7          8  0.1595   0.1299      0.0129  0.0179         0.0571  0.1243   \n",
       "8          9  0.0490   0.1182      0.0968  0.0795         0.1007  0.0196   \n",
       "9         10  0.0061   0.1402      0.0120  0.1327         0.1366  0.1036   \n",
       "10        11  0.0370   0.0948      0.0429  0.0870         0.1195  0.0224   \n",
       "11        12  0.0027   0.0425      0.0422  0.1303         0.1457  0.0958   \n",
       "12        13  0.0640   0.0117      0.0151  0.0731         0.0649  0.1837   \n",
       "13        14  0.0609   0.1177      0.1241  0.0971         0.0316  0.0545   \n",
       "14        15  0.1308   0.0136      0.0813  0.1107         0.0980  0.0299   \n",
       "15        16  0.0326   0.0761      0.0063  0.1124         0.0645  0.0574   \n",
       "16        17  0.0306   0.1355      0.1430  0.0412         0.0265  0.1197   \n",
       "17        18  0.0986   0.0364      0.0910  0.1408         0.0454  0.1110   \n",
       "18        19  0.1257   0.1139      0.0612  0.1244         0.0726  0.0172   \n",
       "19        20  0.0169   0.1433      0.0285  0.1060         0.0671  0.0720   \n",
       "20        21  0.0361   0.1415      0.0978  0.0110         0.0029  0.1142   \n",
       "21        22  0.0208   0.0762      0.0294  0.1593         0.1180  0.0793   \n",
       "22        23  0.0561   0.0586      0.0838  0.0060         0.0790  0.0932   \n",
       "23        24  0.1109   0.0392      0.0324  0.0245         0.1291  0.1132   \n",
       "24        25  0.0256   0.0875      0.0426  0.1033         0.0895  0.1792   \n",
       "25        26  0.1492   0.0575      0.0492  0.0110         0.0927  0.1396   \n",
       "26        27  0.0132   0.0252      0.0815  0.1499         0.1413  0.0790   \n",
       "27        28  0.1474   0.0251      0.0110  0.0475         0.0859  0.1204   \n",
       "28        29  0.0485   0.0941      0.0439  0.1277         0.0030  0.0745   \n",
       "29        30  0.1078   0.0042      0.1286  0.1068         0.0223  0.0857   \n",
       "...      ...     ...      ...         ...     ...            ...     ...   \n",
       "10370  10371  0.1106   0.1285      0.0473  0.1097         0.0559  0.1533   \n",
       "10371  10372  0.1832   0.1448      0.0544  0.1176         0.0850  0.0053   \n",
       "10372  10373  0.1055   0.0990      0.0486  0.0298         0.1113  0.0998   \n",
       "10373  10374  0.1128   0.0009      0.1026  0.0789         0.0441  0.0911   \n",
       "10374  10375  0.0291   0.0226      0.0946  0.0985         0.0740  0.1171   \n",
       "10375  10376  0.1142   0.0688      0.1304  0.0056         0.0450  0.0018   \n",
       "10376  10377  0.0417   0.1617      0.0063  0.0519         0.0291  0.0139   \n",
       "10377  10378  0.0512   0.0219      0.0395  0.0613         0.0770  0.0447   \n",
       "10378  10379  0.0968   0.0982      0.0807  0.0762         0.2096  0.0007   \n",
       "10379  10380  0.0048   0.0899      0.1052  0.0576         0.0901  0.0255   \n",
       "10380  10381  0.0768   0.1098      0.0477  0.1535         0.1326  0.0007   \n",
       "10381  10382  0.0799   0.1181      0.0631  0.0860         0.0704  0.0798   \n",
       "10382  10383  0.0739   0.0329      0.1019  0.1070         0.0463  0.1145   \n",
       "10383  10384  0.0495   0.0422      0.1503  0.0464         0.0898  0.0725   \n",
       "10384  10385  0.0073   0.0601      0.0236  0.1382         0.0954  0.0033   \n",
       "10385  10386  0.0634   0.0065      0.1397  0.0604         0.0618  0.0155   \n",
       "10386  10387  0.1205   0.1122      0.0134  0.0801         0.1173  0.0149   \n",
       "10387  10388  0.0423   0.0974      0.0759  0.0019         0.1067  0.1463   \n",
       "10388  10389  0.2089   0.0101      0.0462  0.0289         0.1183  0.0268   \n",
       "10389  10390  0.1547   0.0289      0.0019  0.1106         0.1048  0.0025   \n",
       "10390  10391  0.1252   0.0632      0.0866  0.0894         0.0275  0.1264   \n",
       "10391  10392  0.1164   0.0099      0.0082  0.0648         0.0226  0.1269   \n",
       "10392  10393  0.0224   0.0945      0.1098  0.1383         0.0162  0.0982   \n",
       "10393  10394  0.0720   0.0816      0.1438  0.1017         0.0361  0.1172   \n",
       "10394  10395  0.1076   0.0340      0.0952  0.0691         0.0842  0.0628   \n",
       "10395  10396  0.0440   0.0441      0.1056  0.0639         0.0210  0.0938   \n",
       "10396  10397  0.0869   0.0733      0.0637  0.1395         0.0869  0.1222   \n",
       "10397  10398  0.0726   0.1146      0.0490  0.0287         0.0634  0.1135   \n",
       "10398  10399  0.0274   0.0865      0.0825  0.0559         0.0121  0.1230   \n",
       "10399  10400  0.1178   0.0021      0.1376  0.0292         0.1612  0.0036   \n",
       "\n",
       "        Latin  New_Age  Pop_Rock     Rap  Reggae     RnB   Vocal  \n",
       "0      0.0883   0.0765    0.0332  0.0445  0.1193  0.1019  0.1038  \n",
       "1      0.1044   0.0118    0.1562  0.0585  0.1633  0.1400  0.0073  \n",
       "2      0.1185   0.1057    0.1041  0.0075  0.0481  0.1283  0.0238  \n",
       "3      0.0269   0.0764    0.0812  0.1337  0.0357  0.0937  0.0930  \n",
       "4      0.1251   0.0202    0.1012  0.0365  0.1310  0.0898  0.0991  \n",
       "5      0.1082   0.0676    0.0737  0.0690  0.0962  0.0093  0.0019  \n",
       "6      0.1361   0.0458    0.1260  0.0176  0.0305  0.0774  0.0585  \n",
       "7      0.0139   0.0447    0.0279  0.1086  0.1641  0.0026  0.1366  \n",
       "8      0.1387   0.0462    0.1452  0.0544  0.0756  0.0722  0.0040  \n",
       "9      0.0702   0.1167    0.0140  0.1400  0.0552  0.0399  0.0328  \n",
       "10     0.0041   0.1166    0.0913  0.1101  0.0846  0.0667  0.1230  \n",
       "11     0.0175   0.1712    0.1443  0.0285  0.0637  0.1047  0.0109  \n",
       "12     0.0154   0.0461    0.0544  0.0550  0.1571  0.0545  0.2048  \n",
       "13     0.0212   0.0940    0.0986  0.0397  0.1196  0.0093  0.1316  \n",
       "14     0.0597   0.0473    0.0220  0.1051  0.1251  0.0833  0.0933  \n",
       "15     0.0598   0.0881    0.1176  0.1072  0.0758  0.1410  0.0612  \n",
       "16     0.0285   0.1359    0.1261  0.0117  0.1420  0.0520  0.0070  \n",
       "17     0.0993   0.1168    0.0139  0.0781  0.0722  0.0550  0.0414  \n",
       "18     0.0541   0.1340    0.0716  0.0264  0.1017  0.0002  0.0971  \n",
       "19     0.1482   0.0255    0.1700  0.0062  0.0355  0.1369  0.0439  \n",
       "20     0.0103   0.0858    0.1270  0.2315  0.0829  0.0556  0.0032  \n",
       "21     0.1495   0.0059    0.1207  0.0657  0.1067  0.0023  0.0662  \n",
       "22     0.1133   0.1158    0.0743  0.0954  0.1205  0.1026  0.0014  \n",
       "23     0.0859   0.1262    0.0434  0.0500  0.0684  0.1281  0.0487  \n",
       "24     0.0389   0.0723    0.1625  0.0083  0.0870  0.0249  0.0784  \n",
       "25     0.0354   0.0953    0.0275  0.0590  0.1285  0.1329  0.0221  \n",
       "26     0.1300   0.0628    0.0644  0.0768  0.0074  0.0382  0.1303  \n",
       "27     0.1246   0.0309    0.1215  0.0672  0.0776  0.0525  0.0883  \n",
       "28     0.0249   0.0965    0.0971  0.0586  0.1091  0.1005  0.1215  \n",
       "29     0.1143   0.0853    0.1278  0.0264  0.1223  0.0616  0.0069  \n",
       "...       ...      ...       ...     ...     ...     ...     ...  \n",
       "10370  0.0127   0.0890    0.0326  0.0272  0.1118  0.0043  0.1171  \n",
       "10371  0.0452   0.0203    0.1791  0.0219  0.0556  0.0407  0.0470  \n",
       "10372  0.0134   0.0418    0.1082  0.0979  0.0817  0.0520  0.1111  \n",
       "10373  0.0508   0.1799    0.1491  0.0730  0.0606  0.0029  0.0534  \n",
       "10374  0.0914   0.1127    0.1309  0.0565  0.1004  0.0361  0.0361  \n",
       "10375  0.0820   0.0932    0.0315  0.0629  0.1317  0.1240  0.1090  \n",
       "10376  0.1019   0.1484    0.0429  0.1108  0.1654  0.0993  0.0267  \n",
       "10377  0.1472   0.0493    0.1517  0.0744  0.0720  0.1254  0.0844  \n",
       "10378  0.0332   0.0207    0.0380  0.1967  0.0584  0.0497  0.0412  \n",
       "10379  0.0546   0.1274    0.1052  0.1055  0.0383  0.1051  0.0908  \n",
       "10380  0.0636   0.0085    0.1610  0.1093  0.0611  0.0411  0.0345  \n",
       "10381  0.0786   0.0590    0.0757  0.1196  0.0613  0.0853  0.0232  \n",
       "10382  0.1374   0.1130    0.0811  0.0067  0.0499  0.1279  0.0076  \n",
       "10383  0.0769   0.1273    0.1073  0.0920  0.0206  0.1090  0.0162  \n",
       "10384  0.1824   0.0904    0.0436  0.1052  0.0087  0.1580  0.0839  \n",
       "10385  0.0387   0.0699    0.1516  0.0208  0.1934  0.1180  0.0605  \n",
       "10386  0.0888   0.0455    0.1190  0.1225  0.0600  0.0903  0.0154  \n",
       "10387  0.1034   0.0382    0.1252  0.0187  0.0698  0.0591  0.1152  \n",
       "10388  0.1071   0.1976    0.0854  0.0874  0.0386  0.0258  0.0190  \n",
       "10389  0.0638   0.0582    0.0771  0.1381  0.0453  0.1413  0.0727  \n",
       "10390  0.1138   0.0542    0.1381  0.0192  0.0503  0.0666  0.0395  \n",
       "10391  0.0358   0.0446    0.1760  0.1603  0.0702  0.1269  0.0375  \n",
       "10392  0.0397   0.1264    0.0092  0.0655  0.0424  0.0825  0.1550  \n",
       "10393  0.0539   0.0829    0.0382  0.0913  0.0646  0.0010  0.1156  \n",
       "10394  0.0112   0.1383    0.1369  0.0120  0.1362  0.0194  0.0932  \n",
       "10395  0.0738   0.0874    0.1423  0.1149  0.0303  0.1243  0.0546  \n",
       "10396  0.0192   0.0307    0.0869  0.0303  0.1393  0.1212  0.0000  \n",
       "10397  0.0703   0.1205    0.0922  0.1079  0.0569  0.0839  0.0265  \n",
       "10398  0.0047   0.0870    0.0489  0.1086  0.1150  0.1648  0.0837  \n",
       "10399  0.1958   0.0232    0.1594  0.0018  0.0816  0.0255  0.0613  \n",
       "\n",
       "[10400 rows x 14 columns]"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_y_sample\n",
    "# test_y_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_prob.shape, y_prob.dtype, y_prob[:2]\n",
    "# y_prob.tofile(file='submission.csv', sep=',', format='%5.5f')\n",
    "submission.tofile(file='submission.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "submission.tofile(file='submission2.csv', sep=',') #, format=\"%s\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mBCI-HW1\u001b[0m/                                 foo.csv\r\n",
      "\u001b[01;34mBCI-HW2\u001b[0m/                                 gradient_descent.py\r\n",
      "\u001b[01;34mbio-bp-dl\u001b[0m/                               \u001b[01;34mimpl\u001b[0m/\r\n",
      "confusion_mat_cov.ipynb                  \u001b[01;34mimpl_imagernn_karpathy\u001b[0m/\r\n",
      "\u001b[01;34mdata\u001b[0m/                                    LICENSE\r\n",
      "DCNN.ipynb                               minimal_net.ipynb\r\n",
      "Deep-FFNN-Tanh-FBA.ipynb                 \u001b[01;34mmisc\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD.ipynb             \u001b[01;34mmisc2\u001b[0m/\r\n",
      "Deep-FFNN-Tanh-FBA-ITD-Kaggle.ipynb      NOTES\r\n",
      "Deep-FFNN-Tanh-FBA-Kaggle.ipynb          numba-cuda-gpu-example.ipynb\r\n",
      "Deep-FFNN-Tanh-Vanilla.ipynb             output.csv\r\n",
      "Deep-FFNN-Tanh-Vanilla-Kaggle.ipynb      README.md\r\n",
      "DFFNN-FBA-STDP-Tanh-diff.ipynb           \u001b[01;34mrnn-testing-platform\u001b[0m/\r\n",
      "DFFNN-FBA-STDP-Tanh-diff-no_FBA.ipynb    submission.csv\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff2.ipynb  \u001b[01;34mtf-based\u001b[0m/\r\n",
      "DFFNN-FBA-STDP-Tanh-TemporalDiff.ipynb   y_predddddddddddddddddd2.csv\r\n",
      "\u001b[01;34mDFFNNs\u001b[0m/                                  y_predddddddddddddddddd3.csv\r\n",
      "\u001b[01;34mDGRUs\u001b[0m/                                   y_predddddddddddddddddd.csv\r\n",
      "\u001b[01;34mDGRUs_old\u001b[0m/                               y_prob.csv\r\n",
      "environment.yml\r\n"
     ]
    }
   ],
   "source": [
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sample =  np.fromfile('../Downloads/submission-random.csv', sep=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample = pd.read_csv(filepath_or_buffer='submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>'Id'</th>\n",
       "      <th>'Blues'</th>\n",
       "      <th>'Country'</th>\n",
       "      <th>'Electronic'</th>\n",
       "      <th>'Folk'</th>\n",
       "      <th>'International'</th>\n",
       "      <th>'Jazz'</th>\n",
       "      <th>'Latin'</th>\n",
       "      <th>'New_Age'</th>\n",
       "      <th>'Pop_Rock'</th>\n",
       "      <th>...</th>\n",
       "      <th>'0.08492850423581863'</th>\n",
       "      <th>'0.08779660473153712'</th>\n",
       "      <th>'0.07962545437721189'</th>\n",
       "      <th>'0.08883812199891572'</th>\n",
       "      <th>'0.0631830150841213'</th>\n",
       "      <th>'0.06541243928632023'</th>\n",
       "      <th>'0.05838763749287561'</th>\n",
       "      <th>'0.070499351542608'</th>\n",
       "      <th>'0.08728107203218675'</th>\n",
       "      <th>'0.08786739375204171'</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 145614 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: ['Id', 'Blues', 'Country', 'Electronic', 'Folk', 'International', 'Jazz', 'Latin', 'New_Age', 'Pop_Rock', 'Rap', 'Reggae', 'RnB', 'Vocal', '1.0', '0.06331482529484075', '0.07569215679323768', '0.09054200920301506', '0.07290541973981052', '0.0760906619309567', '0.05830534477238557', '0.07209673959050499', '0.07105282104764829', '0.05205947416859241', '0.09633113354063781', '0.07467920032384553', '0.0841484948480899', '0.11278171874643482', '2.0', '0.07722904020508518', '0.07257296605505895', '0.07601967674090099', '0.07078531008965669', '0.07186877950136351', '0.06730895970352616', '0.07553141131199578', '0.0716596705146177', '0.06638338923727079', '0.09026754354308586', '0.08684676932192416', '0.07998332069159975', '0.09354316308391457', '3.0', '0.08667811210260425', '0.09358991083572687', '0.08376374714539556', '0.06891799392476193', '0.08597569276538357', '0.06384723902118757', '0.06865226861176564', '0.06347663689903361', '0.07502901700545539', '0.08269135436150411', '0.0721385180322287', '0.07245948044748494', '0.08278002884746756', '4.0', '0.09198232500730268', '0.07137144988532364', '0.08737806184909384', '0.06306342014327988', '0.07163913452650035', '0.07238776687155571', '0.06323387873557151', '0.06004000032580088', '0.05706284022414767', '0.0948252336253342', '0.1006010430780791', '0.08528606817393443', '0.08112877755407598', '5.0', '0.06536505330491331', '0.0650532843504294', '0.10277998196423667', '0.07355734435408974', '0.06957941053974234', '0.05383421161769948', '0.06217282367425284', '0.07476099265685747', '0.049167965243803576', '0.11764406204557275', '0.07361606385303995', '0.08746642401289578', '0.10500238238246672', '6.0', '0.0832222498890728', '0.054713756414083096', '0.0684260145312235', '0.10208326951430886', '0.06744632602418327', '0.0761840352999159', '0.07884304079478523', '0.07628900994900753', '0.10137852921718568', '0.07259781746368629', '0.09060133594397375', '0.05687245168879557', '0.0713421632697786', '7.0', '0.07802892400060485', ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 145614 columns]"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Pop_Rock', 5)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_to_key[0], key_to_val['Blues']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_prob = pd.read_csv(filepath_or_buffer='y_prob.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0.00317</th>\n",
       "      <th>0.01518</th>\n",
       "      <th>0.46551</th>\n",
       "      <th>0.01597</th>\n",
       "      <th>0.00730</th>\n",
       "      <th>0.01441</th>\n",
       "      <th>0.07149</th>\n",
       "      <th>0.01446</th>\n",
       "      <th>0.32313</th>\n",
       "      <th>0.00510</th>\n",
       "      <th>...</th>\n",
       "      <th>0.01342.18</th>\n",
       "      <th>0.22801.1</th>\n",
       "      <th>0.14515.2</th>\n",
       "      <th>0.02259.11</th>\n",
       "      <th>0.05781.9</th>\n",
       "      <th>0.01140.21</th>\n",
       "      <th>0.16361.1</th>\n",
       "      <th>0.02778.14</th>\n",
       "      <th>0.02164.8</th>\n",
       "      <th>0.01738.18</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>0 rows × 135200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [0.00317, 0.01518, 0.46551, 0.01597, 0.00730, 0.01441, 0.07149, 0.01446, 0.32313, 0.00510, 0.00107, 0.04692, 0.01629, 0.00823, 0.06148, 0.14456, 0.01124, 0.02515, 0.02763, 0.05439, 0.05128, 0.48560, 0.02344, 0.00241, 0.09850, 0.00607, 0.03383, 0.00601, 0.25815, 0.06245, 0.01236, 0.01418, 0.08862, 0.03961, 0.41734, 0.00725, 0.00141, 0.05672, 0.00207, 0.01632, 0.10631, 0.05016, 0.13406, 0.02545, 0.04688, 0.09564, 0.04325, 0.37643, 0.06109, 0.00697, 0.02396, 0.01349, 0.00958, 0.00387, 0.47537, 0.02084, 0.00701, 0.01177, 0.02561, 0.01122, 0.39854, 0.00310, 0.00040, 0.03130, 0.00139, 0.03053, 0.00324, 0.39947, 0.14309, 0.00804, 0.01427, 0.05040, 0.01927, 0.28808, 0.00475, 0.00060, 0.03590, 0.00236, 0.02770, 0.04806, 0.14266, 0.02327, 0.04844, 0.02872, 0.18310, 0.07437, 0.26269, 0.02435, 0.00271, 0.12976, 0.00418, 0.00522, 0.02864, 0.09106, 0.04066, 0.01372, 0.05629, 0.03943, 0.01530, 0.65218, ...]\n",
       "Index: []\n",
       "\n",
       "[0 rows x 135200 columns]"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_prob.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
