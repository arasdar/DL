{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "((55000, 784), (5000, 784), (10000, 784))"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data\n",
    "import numpy as np\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "import impl.layer as l\n",
    "\n",
    "# Dataset preparation and pre-processing\n",
    "mnist = input_data.read_data_sets('data/MNIST_data/', one_hot=False)\n",
    "\n",
    "X_train, y_train = mnist.train.images, mnist.train.labels\n",
    "X_val, y_val = mnist.validation.images, mnist.validation.labels\n",
    "X_test, y_test = mnist.test.images, mnist.test.labels\n",
    "X_train.shape, X_val.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Pre-processing: normalizing\n",
    "def normalize(X):\n",
    "    # max scale for images 255= 2**8= 8 bit grayscale for each channel\n",
    "    return (X - X.mean(axis=0)) #/ X.std(axis=0)\n",
    "\n",
    "X_train, X_val, X_test = normalize(X=X_train), normalize(X=X_val), normalize(X=X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "import impl.layer as l # or from impl.layer import *\n",
    "from impl.loss import * # import all functions from impl.loss file # import impl.loss as loss_func\n",
    "from sklearn.utils import shuffle as skshuffle\n",
    "\n",
    "class FFNN:\n",
    "\n",
    "    def __init__(self, D, C, H, L):\n",
    "        self.L = L # layers\n",
    "        self.C = C # classes\n",
    "        self.losses = {'train':[], 'train_acc':[], \n",
    "                       'valid':[], 'valid_acc':[], \n",
    "                       'test':[], 'test_acc':[]}\n",
    "        \n",
    "        self.model = []\n",
    "        self.W_fixed = []\n",
    "        self.grads = []\n",
    "        self.dy_prev = np.zeros((1, C))\n",
    "        self.y_prev = np.zeros((1, C))\n",
    "        low, high = -1, 1\n",
    "        \n",
    "        # Input layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.), b=np.zeros((1, H)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(D, H), low=low, high=high) / np.sqrt(D / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Input layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[0].items()})\n",
    "\n",
    "        # Hidden layers: weights/ biases\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = dict(W=np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, H)))\n",
    "            m_L.append(m)\n",
    "        self.model.append(m_L)\n",
    "        # Fixed feedback weight\n",
    "        m_L = []\n",
    "        for _ in range(L):\n",
    "            m = np.random.uniform(size=(H, H), low=low, high=high) / np.sqrt(H / 2.)\n",
    "            m_L.append(m)\n",
    "        self.W_fixed.append(m_L)\n",
    "        # Hidden layer: gradients\n",
    "        grad_L = []\n",
    "        for _ in range(L):\n",
    "            grad_L.append({key: np.zeros_like(val) for key, val in self.model[1][0].items()})\n",
    "        self.grads.append(grad_L)\n",
    "        \n",
    "        # Output layer: weights/ biases\n",
    "        m = dict(W=np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.), b=np.zeros((1, C)))\n",
    "        self.model.append(m)\n",
    "        # Fixed feedback weight\n",
    "        m = np.random.uniform(size=(H, C), low=low, high=high) / np.sqrt(H / 2.)\n",
    "        self.W_fixed.append(m)\n",
    "        # Output layer: gradients\n",
    "        self.grads.append({key: np.zeros_like(val) for key, val in self.model[2].items()})\n",
    "        \n",
    "    def fc_forward(self, X, W, b):\n",
    "        out = (X @ W) + b\n",
    "        cache = (W, X)\n",
    "        return out, cache\n",
    "\n",
    "    def fc_backward(self, dout, cache, W_fixed):\n",
    "        W, X = cache\n",
    "\n",
    "        dW = X.T @ dout\n",
    "        db = np.sum(dout, axis=0).reshape(1, -1) # db_1xn\n",
    "        \n",
    "#         dX = dout @ W.T # vanilla Backprop\n",
    "        dX = dout @ W_fixed.T # fba backprop\n",
    "\n",
    "        return dX, dW, db\n",
    "\n",
    "    def train_forward(self, X, train):\n",
    "        caches, ys = [], []\n",
    "        \n",
    "        # Input layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[0]['W'], b=self.model[0]['b']) # X_1xD, y_1xc\n",
    "        y, nl_cache = l.tanh_forward(X=y)\n",
    "#         y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#         y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#         y *= 2.0 # uni-var/ std\n",
    "        if train:\n",
    "            caches.append((fc_cache, nl_cache))\n",
    "        X = y.copy() # pass to the next layer\n",
    "        \n",
    "        # Hidden layers\n",
    "        fc_caches, nl_caches = [], []\n",
    "        for layer in range(self.L):\n",
    "            y, fc_cache = self.fc_forward(X=X, W=self.model[1][layer]['W'], b=self.model[1][layer]['b'])\n",
    "            y, nl_cache = l.tanh_forward(X=y)\n",
    "#             y, nl_cache = l.sigmoid_forward(X=y) # non-linearity/ activation\n",
    "#             y -= l.sigmoid(0.0) # zero-centered/ mean\n",
    "#             y *= 2.0 # uni-var/ std\n",
    "            X = y.copy() # pass to next layer\n",
    "            if train:\n",
    "                fc_caches.append(fc_cache)\n",
    "                nl_caches.append(nl_cache)\n",
    "        if train:\n",
    "            caches.append((fc_caches, nl_caches)) # caches[1]            \n",
    "        \n",
    "        # Output layer\n",
    "        y, fc_cache = self.fc_forward(X=X, W=self.model[2]['W'], b=self.model[2]['b'])\n",
    "        y_prob = l.softmax(X=y)\n",
    "        if train:\n",
    "            caches.append(fc_cache)\n",
    "\n",
    "        return y_prob, caches # for backpropating the error\n",
    "\n",
    "    def cross_entropy(self, y_prob, y_train):\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         prob = l.softmax(y_pred)\n",
    "        log_like = -np.log(y_prob[range(m), y_train] + l.eps) # to avoid the devision by zero\n",
    "        data_loss = np.sum(log_like) / m\n",
    "\n",
    "        return data_loss\n",
    "\n",
    "    def dcross_entropy(self, y_prob, y_train): # this is equal for both since the reg_loss (noise) derivative is ZERO.\n",
    "        m = y_prob.shape[0]\n",
    "\n",
    "        #         grad_y = l.softmax(y_pred)\n",
    "        grad_y = y_prob\n",
    "        grad_y[range(m), y_train] -= 1.\n",
    "        grad_y /= m\n",
    "\n",
    "        return grad_y\n",
    "\n",
    "    def loss_function(self, y_prob, y_train):\n",
    "        \n",
    "        loss = self.cross_entropy(y_prob, y_train) # softmax is included\n",
    "        dy = self.dcross_entropy(y_prob, y_train) # dsoftmax is included\n",
    "\n",
    "        return loss, dy\n",
    "        \n",
    "    def train_backward(self, dy, caches, y):\n",
    "        grads = self.grads.copy() # initialized by Zero in every iteration/epoch\n",
    "        dy_prev = self.dy_prev.copy() # for temporal differencing\n",
    "        self.dy_prev = dy.copy() # next iteration/ epoch\n",
    "#         y_prev = self.y_prev.copy() # for temporal differencing\n",
    "#         self.y_prev = y.copy() # next iteration/ epoch\n",
    "        \n",
    "        # Output layer\n",
    "        fc_cache = caches[2]\n",
    "        # softmax_backward is included in dcross_entropy.\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[2])\n",
    "        dy = dX.copy()\n",
    "#         dy =  dy @ self.W_fixed[2].T # done\n",
    "        dy_prev =  dy_prev @ self.W_fixed[2].T\n",
    "#         y =  y @ self.W_fixed[2].T # done\n",
    "#         y_prev =  y_prev @ self.W_fixed[2].T\n",
    "        grads[2]['W'] = dW\n",
    "        grads[2]['b'] = db\n",
    "\n",
    "        # Hidden layer\n",
    "        fc_caches, nl_caches = caches[1]\n",
    "        for layer in reversed(range(self.L)):\n",
    "#             dy = l.tanh_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "#             dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "            dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "#             dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "            dX, dW, db = self.fc_backward(dout=dy, cache=fc_caches[layer], W_fixed=self.W_fixed[1][layer])\n",
    "            dy = dX.copy()\n",
    "#             dy =  dy @ self.W_fixed[2].T # done\n",
    "            dy_prev =  dy_prev @ self.W_fixed[1][layer].T\n",
    "#             y =  y @ self.W_fixed[1][layer].T # done\n",
    "#             y_prev =  y_prev @ self.W_fixed[1][layer].T\n",
    "            grads[1][layer]['W'] = dW\n",
    "            grads[1][layer]['b'] = db\n",
    "        \n",
    "        # Input layer\n",
    "        fc_cache, nl_cache = caches[0]\n",
    "#         dy = l.tanh_backward(cache=nl_cache, dout=dy) # diffable function\n",
    "#         dy = l.sigmoid_backward(cache=nl_caches[layer], dout=dy) # diffable function\n",
    "        dy *= dy - dy_prev # temporal diff instead of differentiable function\n",
    "#         dy *= y - y_prev # temporal diff instead of differentiable function\n",
    "        dX, dW, db = self.fc_backward(dout=dy, cache=fc_cache, W_fixed=self.W_fixed[0])\n",
    "        grads[0]['W'] = dW\n",
    "        grads[0]['b'] = db\n",
    "\n",
    "        return dX, grads\n",
    "    \n",
    "    def test(self, X):\n",
    "        y_prob, _ = self.train_forward(X, train=False)\n",
    "        \n",
    "        # if self.mode == 'classification':\n",
    "        y_pred = np.argmax(y_prob, axis=1) # for loss ==err\n",
    "        \n",
    "        return y_pred, y_prob\n",
    "        \n",
    "    def get_minibatch(self, X, y, minibatch_size, shuffle):\n",
    "        minibatches = []\n",
    "\n",
    "        if shuffle:\n",
    "            X, y = skshuffle(X, y)\n",
    "\n",
    "        for i in range(0, X.shape[0], minibatch_size):\n",
    "            X_mini = X[i:i + minibatch_size]\n",
    "            y_mini = y[i:i + minibatch_size]\n",
    "            minibatches.append((X_mini, y_mini))\n",
    "\n",
    "        return minibatches\n",
    "\n",
    "    def sgd(self, train_set, val_set, alpha, mb_size, n_iter, print_after):\n",
    "        X_train, y_train = train_set\n",
    "        X_val, y_val = val_set\n",
    "\n",
    "        # Epochs\n",
    "        for iter in range(1, n_iter + 1):\n",
    "\n",
    "            # Minibatches\n",
    "            minibatches = self.get_minibatch(X_train, y_train, mb_size, shuffle=True)\n",
    "            idx = np.random.randint(0, len(minibatches))\n",
    "            X_mini, y_mini = minibatches[idx]\n",
    "            \n",
    "            # Train the model\n",
    "            y_prob, caches = self.train_forward(X_mini, train=True)\n",
    "            _, dy = self.loss_function(y_prob, y_mini)\n",
    "            _, grads = self.train_backward(dy, caches, y_prob)\n",
    "            \n",
    "            # Update the model for input layer\n",
    "            for key in grads[0].keys():\n",
    "                self.model[0][key] -= alpha * grads[0][key]\n",
    "\n",
    "            # Update the model for the hidden layers\n",
    "            for layer in range(self.L):\n",
    "                for key in grads[1][layer].keys():\n",
    "                    self.model[1][layer][key] -= alpha * grads[1][layer][key]\n",
    "\n",
    "            # Update the model for output layer\n",
    "            for key in grads[2].keys():\n",
    "                self.model[2][key] -= alpha * grads[2][key]\n",
    "            \n",
    "            # Training accuracy\n",
    "            y_pred, y_prob = self.test(X_mini)\n",
    "            loss, _ = self.loss_function(y_prob, y_mini) # softmax is included in entropy loss function\n",
    "            self.losses['train'].append(loss)\n",
    "            acc = np.mean(y_pred == y_mini) # confusion matrix\n",
    "            self.losses['train_acc'].append(acc)\n",
    "\n",
    "            # Validate the updated model\n",
    "            y_pred, y_prob = self.test(X_val)\n",
    "            valid_loss, _ = self.loss_function(y_prob, y_val) # softmax is included in entropy loss function\n",
    "            self.losses['valid'].append(valid_loss)\n",
    "            valid_acc = np.mean(y_pred == y_val) # confusion matrix\n",
    "            self.losses['valid_acc'].append(valid_acc)\n",
    "            \n",
    "            # Test the final model\n",
    "            y_pred, y_prob = nn.test(X_test)\n",
    "            test_loss, _ = self.loss_function(y_prob, y_test) # softmax is included in entropy loss function\n",
    "            self.losses['test'].append(test_loss)\n",
    "            test_acc = np.mean(y_pred == y_test)\n",
    "            self.losses['test_acc'].append(test_acc)\n",
    "#             print('Test accuracy mean: {:.4f}, std: {:.4f}, loss: {:.4f}'.\n",
    "#             format(acc.mean(), acc.std(), loss))\n",
    "            \n",
    "            # Print the model info: loss & accuracy or err & acc\n",
    "            if iter % print_after == 0:\n",
    "                print('Iter-{}, train loss-{:.4f}, acc-{:.4f}, valid loss-{:.4f}, acc-{:.4f}, test loss-{:.4f}, acc-{:.4f}'.format(\n",
    "                   iter, loss, acc, valid_loss, valid_acc, test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10, train loss-2.3219, acc-0.1200, valid loss-2.3191, acc-0.1034, test loss-2.3200, acc-0.0937\n",
      "Iter-20, train loss-2.3418, acc-0.1000, valid loss-2.3190, acc-0.1040, test loss-2.3199, acc-0.0940\n",
      "Iter-30, train loss-2.3174, acc-0.0600, valid loss-2.3188, acc-0.1044, test loss-2.3198, acc-0.0942\n",
      "Iter-40, train loss-2.3151, acc-0.1800, valid loss-2.3187, acc-0.1046, test loss-2.3196, acc-0.0946\n",
      "Iter-50, train loss-2.3148, acc-0.0800, valid loss-2.3185, acc-0.1046, test loss-2.3195, acc-0.0950\n",
      "Iter-60, train loss-2.3034, acc-0.1400, valid loss-2.3184, acc-0.1052, test loss-2.3193, acc-0.0953\n",
      "Iter-70, train loss-2.3074, acc-0.1200, valid loss-2.3183, acc-0.1052, test loss-2.3192, acc-0.0954\n",
      "Iter-80, train loss-2.3214, acc-0.0800, valid loss-2.3181, acc-0.1056, test loss-2.3190, acc-0.0955\n",
      "Iter-90, train loss-2.3169, acc-0.1200, valid loss-2.3180, acc-0.1058, test loss-2.3189, acc-0.0957\n",
      "Iter-100, train loss-2.3270, acc-0.1200, valid loss-2.3178, acc-0.1058, test loss-2.3188, acc-0.0957\n",
      "Iter-110, train loss-2.3057, acc-0.1400, valid loss-2.3177, acc-0.1056, test loss-2.3186, acc-0.0961\n",
      "Iter-120, train loss-2.3192, acc-0.0600, valid loss-2.3176, acc-0.1060, test loss-2.3185, acc-0.0962\n",
      "Iter-130, train loss-2.3221, acc-0.0800, valid loss-2.3174, acc-0.1058, test loss-2.3183, acc-0.0962\n",
      "Iter-140, train loss-2.3185, acc-0.1000, valid loss-2.3173, acc-0.1060, test loss-2.3182, acc-0.0965\n",
      "Iter-150, train loss-2.3348, acc-0.0600, valid loss-2.3171, acc-0.1060, test loss-2.3181, acc-0.0969\n",
      "Iter-160, train loss-2.3342, acc-0.0400, valid loss-2.3170, acc-0.1062, test loss-2.3179, acc-0.0971\n",
      "Iter-170, train loss-2.3173, acc-0.0800, valid loss-2.3168, acc-0.1066, test loss-2.3178, acc-0.0972\n",
      "Iter-180, train loss-2.3258, acc-0.0800, valid loss-2.3167, acc-0.1070, test loss-2.3176, acc-0.0975\n",
      "Iter-190, train loss-2.3474, acc-0.1000, valid loss-2.3166, acc-0.1070, test loss-2.3175, acc-0.0977\n",
      "Iter-200, train loss-2.3291, acc-0.1000, valid loss-2.3164, acc-0.1072, test loss-2.3174, acc-0.0980\n",
      "Iter-210, train loss-2.2914, acc-0.1200, valid loss-2.3163, acc-0.1072, test loss-2.3172, acc-0.0979\n",
      "Iter-220, train loss-2.3322, acc-0.0600, valid loss-2.3162, acc-0.1074, test loss-2.3171, acc-0.0982\n",
      "Iter-230, train loss-2.3330, acc-0.0800, valid loss-2.3160, acc-0.1072, test loss-2.3169, acc-0.0980\n",
      "Iter-240, train loss-2.3173, acc-0.0400, valid loss-2.3159, acc-0.1074, test loss-2.3168, acc-0.0986\n",
      "Iter-250, train loss-2.2968, acc-0.1600, valid loss-2.3157, acc-0.1076, test loss-2.3166, acc-0.0987\n",
      "Iter-260, train loss-2.2801, acc-0.1600, valid loss-2.3156, acc-0.1076, test loss-2.3165, acc-0.0992\n",
      "Iter-270, train loss-2.3240, acc-0.1000, valid loss-2.3155, acc-0.1076, test loss-2.3164, acc-0.0995\n",
      "Iter-280, train loss-2.3100, acc-0.0800, valid loss-2.3153, acc-0.1078, test loss-2.3162, acc-0.0998\n",
      "Iter-290, train loss-2.3204, acc-0.1000, valid loss-2.3152, acc-0.1080, test loss-2.3161, acc-0.1000\n",
      "Iter-300, train loss-2.2978, acc-0.1200, valid loss-2.3150, acc-0.1082, test loss-2.3160, acc-0.1002\n",
      "Iter-310, train loss-2.3246, acc-0.0800, valid loss-2.3149, acc-0.1082, test loss-2.3158, acc-0.1006\n",
      "Iter-320, train loss-2.3086, acc-0.1000, valid loss-2.3148, acc-0.1084, test loss-2.3157, acc-0.1007\n",
      "Iter-330, train loss-2.3302, acc-0.0800, valid loss-2.3146, acc-0.1082, test loss-2.3155, acc-0.1008\n",
      "Iter-340, train loss-2.3000, acc-0.1400, valid loss-2.3145, acc-0.1084, test loss-2.3154, acc-0.1012\n",
      "Iter-350, train loss-2.3133, acc-0.0600, valid loss-2.3143, acc-0.1084, test loss-2.3153, acc-0.1014\n",
      "Iter-360, train loss-2.3136, acc-0.1000, valid loss-2.3142, acc-0.1080, test loss-2.3151, acc-0.1013\n",
      "Iter-370, train loss-2.3010, acc-0.0600, valid loss-2.3141, acc-0.1084, test loss-2.3150, acc-0.1014\n",
      "Iter-380, train loss-2.3056, acc-0.1000, valid loss-2.3139, acc-0.1082, test loss-2.3148, acc-0.1015\n",
      "Iter-390, train loss-2.3180, acc-0.0800, valid loss-2.3138, acc-0.1082, test loss-2.3147, acc-0.1017\n",
      "Iter-400, train loss-2.3154, acc-0.0800, valid loss-2.3136, acc-0.1086, test loss-2.3146, acc-0.1017\n",
      "Iter-410, train loss-2.3165, acc-0.1200, valid loss-2.3135, acc-0.1092, test loss-2.3144, acc-0.1018\n",
      "Iter-420, train loss-2.3303, acc-0.0200, valid loss-2.3134, acc-0.1096, test loss-2.3143, acc-0.1021\n",
      "Iter-430, train loss-2.3424, acc-0.0600, valid loss-2.3132, acc-0.1098, test loss-2.3141, acc-0.1022\n",
      "Iter-440, train loss-2.3156, acc-0.1200, valid loss-2.3131, acc-0.1102, test loss-2.3140, acc-0.1025\n",
      "Iter-450, train loss-2.3035, acc-0.0800, valid loss-2.3129, acc-0.1106, test loss-2.3139, acc-0.1027\n",
      "Iter-460, train loss-2.2933, acc-0.1400, valid loss-2.3128, acc-0.1106, test loss-2.3137, acc-0.1029\n",
      "Iter-470, train loss-2.3088, acc-0.0800, valid loss-2.3127, acc-0.1106, test loss-2.3136, acc-0.1032\n",
      "Iter-480, train loss-2.3002, acc-0.1800, valid loss-2.3125, acc-0.1106, test loss-2.3134, acc-0.1033\n",
      "Iter-490, train loss-2.2852, acc-0.1400, valid loss-2.3124, acc-0.1110, test loss-2.3133, acc-0.1036\n",
      "Iter-500, train loss-2.3130, acc-0.1000, valid loss-2.3122, acc-0.1114, test loss-2.3132, acc-0.1038\n",
      "Iter-510, train loss-2.3124, acc-0.0600, valid loss-2.3121, acc-0.1118, test loss-2.3130, acc-0.1042\n",
      "Iter-520, train loss-2.3264, acc-0.0200, valid loss-2.3119, acc-0.1118, test loss-2.3129, acc-0.1047\n",
      "Iter-530, train loss-2.3308, acc-0.0400, valid loss-2.3118, acc-0.1118, test loss-2.3127, acc-0.1048\n",
      "Iter-540, train loss-2.2752, acc-0.2000, valid loss-2.3117, acc-0.1118, test loss-2.3126, acc-0.1050\n",
      "Iter-550, train loss-2.3098, acc-0.1000, valid loss-2.3115, acc-0.1120, test loss-2.3124, acc-0.1055\n",
      "Iter-560, train loss-2.3098, acc-0.0800, valid loss-2.3114, acc-0.1120, test loss-2.3123, acc-0.1057\n",
      "Iter-570, train loss-2.3088, acc-0.1000, valid loss-2.3112, acc-0.1120, test loss-2.3122, acc-0.1059\n",
      "Iter-580, train loss-2.2872, acc-0.2200, valid loss-2.3111, acc-0.1124, test loss-2.3120, acc-0.1064\n",
      "Iter-590, train loss-2.3083, acc-0.0800, valid loss-2.3110, acc-0.1126, test loss-2.3119, acc-0.1064\n",
      "Iter-600, train loss-2.3175, acc-0.1000, valid loss-2.3109, acc-0.1126, test loss-2.3118, acc-0.1063\n",
      "Iter-610, train loss-2.3211, acc-0.0600, valid loss-2.3107, acc-0.1126, test loss-2.3116, acc-0.1064\n",
      "Iter-620, train loss-2.3166, acc-0.0800, valid loss-2.3106, acc-0.1128, test loss-2.3115, acc-0.1067\n",
      "Iter-630, train loss-2.3104, acc-0.1200, valid loss-2.3104, acc-0.1136, test loss-2.3114, acc-0.1072\n",
      "Iter-640, train loss-2.2848, acc-0.1800, valid loss-2.3103, acc-0.1138, test loss-2.3112, acc-0.1075\n",
      "Iter-650, train loss-2.3043, acc-0.1600, valid loss-2.3101, acc-0.1138, test loss-2.3111, acc-0.1077\n",
      "Iter-660, train loss-2.2987, acc-0.1600, valid loss-2.3100, acc-0.1142, test loss-2.3109, acc-0.1079\n",
      "Iter-670, train loss-2.3234, acc-0.0600, valid loss-2.3099, acc-0.1144, test loss-2.3108, acc-0.1085\n",
      "Iter-680, train loss-2.3257, acc-0.0600, valid loss-2.3097, acc-0.1148, test loss-2.3106, acc-0.1089\n",
      "Iter-690, train loss-2.3154, acc-0.0400, valid loss-2.3096, acc-0.1152, test loss-2.3105, acc-0.1088\n",
      "Iter-700, train loss-2.2867, acc-0.1800, valid loss-2.3094, acc-0.1148, test loss-2.3104, acc-0.1091\n",
      "Iter-710, train loss-2.3062, acc-0.1200, valid loss-2.3093, acc-0.1150, test loss-2.3102, acc-0.1096\n",
      "Iter-720, train loss-2.3376, acc-0.0800, valid loss-2.3092, acc-0.1152, test loss-2.3101, acc-0.1095\n",
      "Iter-730, train loss-2.3078, acc-0.0600, valid loss-2.3090, acc-0.1156, test loss-2.3099, acc-0.1099\n",
      "Iter-740, train loss-2.2891, acc-0.2600, valid loss-2.3089, acc-0.1160, test loss-2.3098, acc-0.1100\n",
      "Iter-750, train loss-2.3344, acc-0.0800, valid loss-2.3087, acc-0.1160, test loss-2.3096, acc-0.1100\n",
      "Iter-760, train loss-2.3107, acc-0.1200, valid loss-2.3086, acc-0.1160, test loss-2.3095, acc-0.1101\n",
      "Iter-770, train loss-2.3279, acc-0.1000, valid loss-2.3085, acc-0.1164, test loss-2.3094, acc-0.1102\n",
      "Iter-780, train loss-2.3214, acc-0.0600, valid loss-2.3083, acc-0.1166, test loss-2.3092, acc-0.1103\n",
      "Iter-790, train loss-2.3312, acc-0.0800, valid loss-2.3082, acc-0.1168, test loss-2.3091, acc-0.1109\n",
      "Iter-800, train loss-2.3271, acc-0.0800, valid loss-2.3081, acc-0.1172, test loss-2.3090, acc-0.1111\n",
      "Iter-810, train loss-2.3079, acc-0.1200, valid loss-2.3079, acc-0.1176, test loss-2.3088, acc-0.1112\n",
      "Iter-820, train loss-2.3179, acc-0.0600, valid loss-2.3078, acc-0.1178, test loss-2.3087, acc-0.1113\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-830, train loss-2.3097, acc-0.1000, valid loss-2.3076, acc-0.1178, test loss-2.3085, acc-0.1113\n",
      "Iter-840, train loss-2.3053, acc-0.1400, valid loss-2.3075, acc-0.1184, test loss-2.3084, acc-0.1118\n",
      "Iter-850, train loss-2.3083, acc-0.0600, valid loss-2.3073, acc-0.1184, test loss-2.3083, acc-0.1117\n",
      "Iter-860, train loss-2.3190, acc-0.1000, valid loss-2.3072, acc-0.1188, test loss-2.3081, acc-0.1119\n",
      "Iter-870, train loss-2.3070, acc-0.0800, valid loss-2.3071, acc-0.1190, test loss-2.3080, acc-0.1121\n",
      "Iter-880, train loss-2.3010, acc-0.0800, valid loss-2.3069, acc-0.1188, test loss-2.3078, acc-0.1122\n",
      "Iter-890, train loss-2.2944, acc-0.1000, valid loss-2.3068, acc-0.1192, test loss-2.3077, acc-0.1122\n",
      "Iter-900, train loss-2.3009, acc-0.1600, valid loss-2.3066, acc-0.1196, test loss-2.3075, acc-0.1124\n",
      "Iter-910, train loss-2.3344, acc-0.1000, valid loss-2.3065, acc-0.1202, test loss-2.3074, acc-0.1124\n",
      "Iter-920, train loss-2.2926, acc-0.1200, valid loss-2.3063, acc-0.1200, test loss-2.3073, acc-0.1124\n",
      "Iter-930, train loss-2.2958, acc-0.1600, valid loss-2.3062, acc-0.1200, test loss-2.3071, acc-0.1127\n",
      "Iter-940, train loss-2.3034, acc-0.1600, valid loss-2.3061, acc-0.1210, test loss-2.3070, acc-0.1130\n",
      "Iter-950, train loss-2.2937, acc-0.1000, valid loss-2.3059, acc-0.1212, test loss-2.3068, acc-0.1135\n",
      "Iter-960, train loss-2.2912, acc-0.2000, valid loss-2.3058, acc-0.1216, test loss-2.3067, acc-0.1137\n",
      "Iter-970, train loss-2.2894, acc-0.1600, valid loss-2.3056, acc-0.1214, test loss-2.3065, acc-0.1141\n",
      "Iter-980, train loss-2.3025, acc-0.1000, valid loss-2.3055, acc-0.1216, test loss-2.3064, acc-0.1146\n",
      "Iter-990, train loss-2.2935, acc-0.1000, valid loss-2.3053, acc-0.1216, test loss-2.3063, acc-0.1145\n",
      "Iter-1000, train loss-2.3347, acc-0.0400, valid loss-2.3052, acc-0.1222, test loss-2.3061, acc-0.1147\n",
      "Iter-1010, train loss-2.2848, acc-0.1600, valid loss-2.3051, acc-0.1224, test loss-2.3060, acc-0.1151\n",
      "Iter-1020, train loss-2.2927, acc-0.1600, valid loss-2.3049, acc-0.1228, test loss-2.3058, acc-0.1151\n",
      "Iter-1030, train loss-2.3042, acc-0.1000, valid loss-2.3048, acc-0.1228, test loss-2.3057, acc-0.1155\n",
      "Iter-1040, train loss-2.3136, acc-0.0800, valid loss-2.3046, acc-0.1228, test loss-2.3055, acc-0.1158\n",
      "Iter-1050, train loss-2.2857, acc-0.1800, valid loss-2.3045, acc-0.1228, test loss-2.3054, acc-0.1162\n",
      "Iter-1060, train loss-2.3042, acc-0.1200, valid loss-2.3044, acc-0.1230, test loss-2.3053, acc-0.1164\n",
      "Iter-1070, train loss-2.2942, acc-0.0800, valid loss-2.3042, acc-0.1234, test loss-2.3051, acc-0.1165\n",
      "Iter-1080, train loss-2.2734, acc-0.2400, valid loss-2.3040, acc-0.1236, test loss-2.3050, acc-0.1166\n",
      "Iter-1090, train loss-2.2992, acc-0.1400, valid loss-2.3039, acc-0.1242, test loss-2.3048, acc-0.1168\n",
      "Iter-1100, train loss-2.2998, acc-0.1400, valid loss-2.3038, acc-0.1242, test loss-2.3047, acc-0.1170\n",
      "Iter-1110, train loss-2.3121, acc-0.0800, valid loss-2.3036, acc-0.1244, test loss-2.3045, acc-0.1174\n",
      "Iter-1120, train loss-2.3125, acc-0.0800, valid loss-2.3035, acc-0.1248, test loss-2.3044, acc-0.1176\n",
      "Iter-1130, train loss-2.2955, acc-0.2200, valid loss-2.3033, acc-0.1252, test loss-2.3042, acc-0.1179\n",
      "Iter-1140, train loss-2.3062, acc-0.1000, valid loss-2.3032, acc-0.1250, test loss-2.3041, acc-0.1177\n",
      "Iter-1150, train loss-2.3099, acc-0.1200, valid loss-2.3031, acc-0.1254, test loss-2.3040, acc-0.1183\n",
      "Iter-1160, train loss-2.3109, acc-0.0600, valid loss-2.3029, acc-0.1256, test loss-2.3038, acc-0.1186\n",
      "Iter-1170, train loss-2.2797, acc-0.1200, valid loss-2.3028, acc-0.1262, test loss-2.3037, acc-0.1189\n",
      "Iter-1180, train loss-2.3078, acc-0.1600, valid loss-2.3026, acc-0.1264, test loss-2.3036, acc-0.1195\n",
      "Iter-1190, train loss-2.2849, acc-0.1000, valid loss-2.3025, acc-0.1264, test loss-2.3034, acc-0.1200\n",
      "Iter-1200, train loss-2.3184, acc-0.0400, valid loss-2.3024, acc-0.1272, test loss-2.3033, acc-0.1202\n",
      "Iter-1210, train loss-2.3158, acc-0.0800, valid loss-2.3022, acc-0.1276, test loss-2.3031, acc-0.1206\n",
      "Iter-1220, train loss-2.2928, acc-0.1400, valid loss-2.3021, acc-0.1282, test loss-2.3030, acc-0.1211\n",
      "Iter-1230, train loss-2.2991, acc-0.1400, valid loss-2.3019, acc-0.1282, test loss-2.3029, acc-0.1215\n",
      "Iter-1240, train loss-2.2908, acc-0.1800, valid loss-2.3018, acc-0.1286, test loss-2.3027, acc-0.1217\n",
      "Iter-1250, train loss-2.2726, acc-0.1200, valid loss-2.3017, acc-0.1292, test loss-2.3026, acc-0.1222\n",
      "Iter-1260, train loss-2.3067, acc-0.1000, valid loss-2.3015, acc-0.1290, test loss-2.3024, acc-0.1226\n",
      "Iter-1270, train loss-2.2918, acc-0.2400, valid loss-2.3014, acc-0.1294, test loss-2.3023, acc-0.1228\n",
      "Iter-1280, train loss-2.2986, acc-0.0400, valid loss-2.3013, acc-0.1300, test loss-2.3022, acc-0.1229\n",
      "Iter-1290, train loss-2.2934, acc-0.1600, valid loss-2.3011, acc-0.1300, test loss-2.3020, acc-0.1235\n",
      "Iter-1300, train loss-2.2987, acc-0.1200, valid loss-2.3010, acc-0.1304, test loss-2.3019, acc-0.1239\n",
      "Iter-1310, train loss-2.3227, acc-0.0800, valid loss-2.3009, acc-0.1306, test loss-2.3018, acc-0.1240\n",
      "Iter-1320, train loss-2.3221, acc-0.0800, valid loss-2.3007, acc-0.1308, test loss-2.3016, acc-0.1242\n",
      "Iter-1330, train loss-2.2955, acc-0.0600, valid loss-2.3006, acc-0.1308, test loss-2.3015, acc-0.1244\n",
      "Iter-1340, train loss-2.2929, acc-0.0800, valid loss-2.3004, acc-0.1312, test loss-2.3013, acc-0.1245\n",
      "Iter-1350, train loss-2.2827, acc-0.1600, valid loss-2.3003, acc-0.1314, test loss-2.3012, acc-0.1250\n",
      "Iter-1360, train loss-2.2873, acc-0.1600, valid loss-2.3002, acc-0.1318, test loss-2.3011, acc-0.1252\n",
      "Iter-1370, train loss-2.2927, acc-0.1200, valid loss-2.3000, acc-0.1320, test loss-2.3009, acc-0.1254\n",
      "Iter-1380, train loss-2.2807, acc-0.1600, valid loss-2.2999, acc-0.1324, test loss-2.3008, acc-0.1258\n",
      "Iter-1390, train loss-2.2848, acc-0.1200, valid loss-2.2997, acc-0.1324, test loss-2.3007, acc-0.1263\n",
      "Iter-1400, train loss-2.3125, acc-0.1000, valid loss-2.2996, acc-0.1326, test loss-2.3005, acc-0.1268\n",
      "Iter-1410, train loss-2.3072, acc-0.1000, valid loss-2.2995, acc-0.1330, test loss-2.3004, acc-0.1272\n",
      "Iter-1420, train loss-2.2969, acc-0.1600, valid loss-2.2993, acc-0.1334, test loss-2.3002, acc-0.1274\n",
      "Iter-1430, train loss-2.3173, acc-0.0600, valid loss-2.2992, acc-0.1334, test loss-2.3001, acc-0.1277\n",
      "Iter-1440, train loss-2.2847, acc-0.1400, valid loss-2.2990, acc-0.1340, test loss-2.2999, acc-0.1283\n",
      "Iter-1450, train loss-2.3038, acc-0.1200, valid loss-2.2989, acc-0.1340, test loss-2.2998, acc-0.1286\n",
      "Iter-1460, train loss-2.2820, acc-0.1200, valid loss-2.2988, acc-0.1340, test loss-2.2997, acc-0.1291\n",
      "Iter-1470, train loss-2.2902, acc-0.1600, valid loss-2.2986, acc-0.1348, test loss-2.2995, acc-0.1292\n",
      "Iter-1480, train loss-2.3004, acc-0.1800, valid loss-2.2985, acc-0.1350, test loss-2.2994, acc-0.1287\n",
      "Iter-1490, train loss-2.3359, acc-0.0200, valid loss-2.2983, acc-0.1350, test loss-2.2993, acc-0.1291\n",
      "Iter-1500, train loss-2.3001, acc-0.1200, valid loss-2.2982, acc-0.1352, test loss-2.2991, acc-0.1290\n",
      "Iter-1510, train loss-2.2922, acc-0.1400, valid loss-2.2981, acc-0.1358, test loss-2.2990, acc-0.1297\n",
      "Iter-1520, train loss-2.2962, acc-0.1400, valid loss-2.2979, acc-0.1362, test loss-2.2988, acc-0.1300\n",
      "Iter-1530, train loss-2.2841, acc-0.1400, valid loss-2.2978, acc-0.1362, test loss-2.2987, acc-0.1303\n",
      "Iter-1540, train loss-2.3130, acc-0.0800, valid loss-2.2976, acc-0.1366, test loss-2.2986, acc-0.1305\n",
      "Iter-1550, train loss-2.2723, acc-0.2200, valid loss-2.2975, acc-0.1372, test loss-2.2984, acc-0.1306\n",
      "Iter-1560, train loss-2.3107, acc-0.1200, valid loss-2.2974, acc-0.1376, test loss-2.2983, acc-0.1305\n",
      "Iter-1570, train loss-2.2871, acc-0.1400, valid loss-2.2972, acc-0.1384, test loss-2.2981, acc-0.1311\n",
      "Iter-1580, train loss-2.3007, acc-0.2000, valid loss-2.2971, acc-0.1384, test loss-2.2980, acc-0.1313\n",
      "Iter-1590, train loss-2.3288, acc-0.0800, valid loss-2.2969, acc-0.1382, test loss-2.2979, acc-0.1318\n",
      "Iter-1600, train loss-2.2965, acc-0.0800, valid loss-2.2968, acc-0.1384, test loss-2.2977, acc-0.1322\n",
      "Iter-1610, train loss-2.3034, acc-0.1600, valid loss-2.2967, acc-0.1388, test loss-2.2976, acc-0.1324\n",
      "Iter-1620, train loss-2.3064, acc-0.1000, valid loss-2.2965, acc-0.1398, test loss-2.2975, acc-0.1323\n",
      "Iter-1630, train loss-2.2986, acc-0.1200, valid loss-2.2964, acc-0.1398, test loss-2.2973, acc-0.1323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-1640, train loss-2.3018, acc-0.1200, valid loss-2.2962, acc-0.1404, test loss-2.2972, acc-0.1326\n",
      "Iter-1650, train loss-2.3215, acc-0.0400, valid loss-2.2961, acc-0.1406, test loss-2.2970, acc-0.1332\n",
      "Iter-1660, train loss-2.2978, acc-0.1200, valid loss-2.2960, acc-0.1406, test loss-2.2969, acc-0.1330\n",
      "Iter-1670, train loss-2.2979, acc-0.1400, valid loss-2.2958, acc-0.1408, test loss-2.2967, acc-0.1333\n",
      "Iter-1680, train loss-2.2788, acc-0.1200, valid loss-2.2957, acc-0.1410, test loss-2.2966, acc-0.1334\n",
      "Iter-1690, train loss-2.3103, acc-0.0800, valid loss-2.2955, acc-0.1412, test loss-2.2965, acc-0.1335\n",
      "Iter-1700, train loss-2.2888, acc-0.1000, valid loss-2.2954, acc-0.1416, test loss-2.2963, acc-0.1338\n",
      "Iter-1710, train loss-2.3112, acc-0.1000, valid loss-2.2953, acc-0.1414, test loss-2.2962, acc-0.1339\n",
      "Iter-1720, train loss-2.2933, acc-0.1400, valid loss-2.2951, acc-0.1416, test loss-2.2960, acc-0.1346\n",
      "Iter-1730, train loss-2.3068, acc-0.1000, valid loss-2.2950, acc-0.1422, test loss-2.2959, acc-0.1349\n",
      "Iter-1740, train loss-2.2976, acc-0.1200, valid loss-2.2948, acc-0.1426, test loss-2.2957, acc-0.1353\n",
      "Iter-1750, train loss-2.2804, acc-0.1600, valid loss-2.2947, acc-0.1428, test loss-2.2956, acc-0.1355\n",
      "Iter-1760, train loss-2.3089, acc-0.0600, valid loss-2.2946, acc-0.1434, test loss-2.2955, acc-0.1359\n",
      "Iter-1770, train loss-2.2834, acc-0.1800, valid loss-2.2944, acc-0.1436, test loss-2.2953, acc-0.1361\n",
      "Iter-1780, train loss-2.2974, acc-0.0800, valid loss-2.2943, acc-0.1442, test loss-2.2952, acc-0.1362\n",
      "Iter-1790, train loss-2.2827, acc-0.2000, valid loss-2.2941, acc-0.1448, test loss-2.2951, acc-0.1367\n",
      "Iter-1800, train loss-2.2855, acc-0.1000, valid loss-2.2940, acc-0.1448, test loss-2.2949, acc-0.1372\n",
      "Iter-1810, train loss-2.3002, acc-0.1000, valid loss-2.2938, acc-0.1448, test loss-2.2948, acc-0.1374\n",
      "Iter-1820, train loss-2.2842, acc-0.1000, valid loss-2.2937, acc-0.1452, test loss-2.2946, acc-0.1380\n",
      "Iter-1830, train loss-2.2843, acc-0.1600, valid loss-2.2936, acc-0.1454, test loss-2.2945, acc-0.1380\n",
      "Iter-1840, train loss-2.2822, acc-0.1400, valid loss-2.2934, acc-0.1452, test loss-2.2944, acc-0.1384\n",
      "Iter-1850, train loss-2.3122, acc-0.1400, valid loss-2.2933, acc-0.1460, test loss-2.2942, acc-0.1389\n",
      "Iter-1860, train loss-2.2842, acc-0.1600, valid loss-2.2932, acc-0.1468, test loss-2.2941, acc-0.1388\n",
      "Iter-1870, train loss-2.2824, acc-0.1400, valid loss-2.2930, acc-0.1472, test loss-2.2940, acc-0.1397\n",
      "Iter-1880, train loss-2.2951, acc-0.1000, valid loss-2.2929, acc-0.1474, test loss-2.2938, acc-0.1401\n",
      "Iter-1890, train loss-2.3060, acc-0.1600, valid loss-2.2927, acc-0.1474, test loss-2.2937, acc-0.1405\n",
      "Iter-1900, train loss-2.3121, acc-0.0600, valid loss-2.2926, acc-0.1480, test loss-2.2935, acc-0.1411\n",
      "Iter-1910, train loss-2.2912, acc-0.0800, valid loss-2.2925, acc-0.1480, test loss-2.2934, acc-0.1414\n",
      "Iter-1920, train loss-2.2864, acc-0.2200, valid loss-2.2923, acc-0.1482, test loss-2.2933, acc-0.1413\n",
      "Iter-1930, train loss-2.3043, acc-0.1600, valid loss-2.2922, acc-0.1484, test loss-2.2932, acc-0.1420\n",
      "Iter-1940, train loss-2.2897, acc-0.1600, valid loss-2.2921, acc-0.1488, test loss-2.2930, acc-0.1424\n",
      "Iter-1950, train loss-2.2842, acc-0.1400, valid loss-2.2919, acc-0.1492, test loss-2.2929, acc-0.1423\n",
      "Iter-1960, train loss-2.2750, acc-0.2400, valid loss-2.2918, acc-0.1494, test loss-2.2927, acc-0.1427\n",
      "Iter-1970, train loss-2.3068, acc-0.0800, valid loss-2.2917, acc-0.1494, test loss-2.2926, acc-0.1432\n",
      "Iter-1980, train loss-2.3044, acc-0.1200, valid loss-2.2916, acc-0.1496, test loss-2.2925, acc-0.1438\n",
      "Iter-1990, train loss-2.3048, acc-0.1200, valid loss-2.2914, acc-0.1496, test loss-2.2924, acc-0.1439\n",
      "Iter-2000, train loss-2.3010, acc-0.1600, valid loss-2.2913, acc-0.1498, test loss-2.2922, acc-0.1441\n",
      "Iter-2010, train loss-2.3038, acc-0.0800, valid loss-2.2911, acc-0.1496, test loss-2.2921, acc-0.1445\n",
      "Iter-2020, train loss-2.3003, acc-0.0600, valid loss-2.2910, acc-0.1496, test loss-2.2920, acc-0.1448\n",
      "Iter-2030, train loss-2.2723, acc-0.1400, valid loss-2.2909, acc-0.1496, test loss-2.2918, acc-0.1449\n",
      "Iter-2040, train loss-2.3039, acc-0.1600, valid loss-2.2908, acc-0.1496, test loss-2.2917, acc-0.1448\n",
      "Iter-2050, train loss-2.2747, acc-0.2200, valid loss-2.2906, acc-0.1494, test loss-2.2915, acc-0.1449\n",
      "Iter-2060, train loss-2.3135, acc-0.0600, valid loss-2.2905, acc-0.1498, test loss-2.2914, acc-0.1456\n",
      "Iter-2070, train loss-2.2960, acc-0.1200, valid loss-2.2903, acc-0.1496, test loss-2.2913, acc-0.1456\n",
      "Iter-2080, train loss-2.2848, acc-0.2400, valid loss-2.2902, acc-0.1500, test loss-2.2911, acc-0.1463\n",
      "Iter-2090, train loss-2.3201, acc-0.1200, valid loss-2.2901, acc-0.1504, test loss-2.2910, acc-0.1464\n",
      "Iter-2100, train loss-2.2843, acc-0.2200, valid loss-2.2899, acc-0.1504, test loss-2.2909, acc-0.1465\n",
      "Iter-2110, train loss-2.2818, acc-0.1600, valid loss-2.2898, acc-0.1504, test loss-2.2907, acc-0.1468\n",
      "Iter-2120, train loss-2.2893, acc-0.1000, valid loss-2.2897, acc-0.1504, test loss-2.2906, acc-0.1468\n",
      "Iter-2130, train loss-2.2696, acc-0.1400, valid loss-2.2895, acc-0.1504, test loss-2.2905, acc-0.1469\n",
      "Iter-2140, train loss-2.2938, acc-0.1200, valid loss-2.2894, acc-0.1504, test loss-2.2903, acc-0.1468\n",
      "Iter-2150, train loss-2.2858, acc-0.1600, valid loss-2.2893, acc-0.1504, test loss-2.2902, acc-0.1468\n",
      "Iter-2160, train loss-2.2881, acc-0.2200, valid loss-2.2891, acc-0.1504, test loss-2.2900, acc-0.1471\n",
      "Iter-2170, train loss-2.2865, acc-0.0800, valid loss-2.2890, acc-0.1508, test loss-2.2899, acc-0.1473\n",
      "Iter-2180, train loss-2.2912, acc-0.0800, valid loss-2.2888, acc-0.1506, test loss-2.2898, acc-0.1475\n",
      "Iter-2190, train loss-2.2793, acc-0.2000, valid loss-2.2887, acc-0.1508, test loss-2.2896, acc-0.1478\n",
      "Iter-2200, train loss-2.2797, acc-0.1800, valid loss-2.2886, acc-0.1514, test loss-2.2895, acc-0.1480\n",
      "Iter-2210, train loss-2.3021, acc-0.1600, valid loss-2.2884, acc-0.1510, test loss-2.2893, acc-0.1483\n",
      "Iter-2220, train loss-2.3207, acc-0.0200, valid loss-2.2883, acc-0.1514, test loss-2.2892, acc-0.1491\n",
      "Iter-2230, train loss-2.2709, acc-0.2400, valid loss-2.2882, acc-0.1516, test loss-2.2891, acc-0.1494\n",
      "Iter-2240, train loss-2.2850, acc-0.1400, valid loss-2.2880, acc-0.1522, test loss-2.2889, acc-0.1493\n",
      "Iter-2250, train loss-2.3011, acc-0.1000, valid loss-2.2879, acc-0.1522, test loss-2.2888, acc-0.1494\n",
      "Iter-2260, train loss-2.2909, acc-0.1200, valid loss-2.2878, acc-0.1524, test loss-2.2887, acc-0.1500\n",
      "Iter-2270, train loss-2.2872, acc-0.2000, valid loss-2.2876, acc-0.1524, test loss-2.2885, acc-0.1501\n",
      "Iter-2280, train loss-2.2702, acc-0.1800, valid loss-2.2875, acc-0.1530, test loss-2.2884, acc-0.1506\n",
      "Iter-2290, train loss-2.2782, acc-0.1800, valid loss-2.2874, acc-0.1532, test loss-2.2883, acc-0.1510\n",
      "Iter-2300, train loss-2.2849, acc-0.2000, valid loss-2.2872, acc-0.1536, test loss-2.2881, acc-0.1513\n",
      "Iter-2310, train loss-2.2940, acc-0.1400, valid loss-2.2871, acc-0.1542, test loss-2.2880, acc-0.1515\n",
      "Iter-2320, train loss-2.2768, acc-0.1600, valid loss-2.2869, acc-0.1544, test loss-2.2879, acc-0.1519\n",
      "Iter-2330, train loss-2.2821, acc-0.1600, valid loss-2.2868, acc-0.1550, test loss-2.2877, acc-0.1528\n",
      "Iter-2340, train loss-2.2735, acc-0.0800, valid loss-2.2867, acc-0.1550, test loss-2.2876, acc-0.1526\n",
      "Iter-2350, train loss-2.2748, acc-0.1600, valid loss-2.2865, acc-0.1552, test loss-2.2874, acc-0.1527\n",
      "Iter-2360, train loss-2.3001, acc-0.1000, valid loss-2.2864, acc-0.1550, test loss-2.2873, acc-0.1534\n",
      "Iter-2370, train loss-2.2949, acc-0.1600, valid loss-2.2863, acc-0.1560, test loss-2.2872, acc-0.1534\n",
      "Iter-2380, train loss-2.2891, acc-0.1400, valid loss-2.2861, acc-0.1564, test loss-2.2870, acc-0.1539\n",
      "Iter-2390, train loss-2.2902, acc-0.2000, valid loss-2.2860, acc-0.1564, test loss-2.2869, acc-0.1538\n",
      "Iter-2400, train loss-2.2602, acc-0.2000, valid loss-2.2859, acc-0.1564, test loss-2.2868, acc-0.1542\n",
      "Iter-2410, train loss-2.2838, acc-0.1800, valid loss-2.2857, acc-0.1570, test loss-2.2866, acc-0.1545\n",
      "Iter-2420, train loss-2.2870, acc-0.1400, valid loss-2.2856, acc-0.1574, test loss-2.2865, acc-0.1547\n",
      "Iter-2430, train loss-2.2852, acc-0.1600, valid loss-2.2854, acc-0.1578, test loss-2.2864, acc-0.1549\n",
      "Iter-2440, train loss-2.2876, acc-0.1800, valid loss-2.2853, acc-0.1582, test loss-2.2862, acc-0.1551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-2450, train loss-2.3015, acc-0.1000, valid loss-2.2852, acc-0.1582, test loss-2.2861, acc-0.1556\n",
      "Iter-2460, train loss-2.2904, acc-0.1600, valid loss-2.2850, acc-0.1586, test loss-2.2860, acc-0.1559\n",
      "Iter-2470, train loss-2.3017, acc-0.0600, valid loss-2.2849, acc-0.1590, test loss-2.2858, acc-0.1560\n",
      "Iter-2480, train loss-2.3011, acc-0.1200, valid loss-2.2848, acc-0.1590, test loss-2.2857, acc-0.1565\n",
      "Iter-2490, train loss-2.2801, acc-0.1600, valid loss-2.2846, acc-0.1594, test loss-2.2856, acc-0.1563\n",
      "Iter-2500, train loss-2.2655, acc-0.1600, valid loss-2.2845, acc-0.1592, test loss-2.2854, acc-0.1568\n",
      "Iter-2510, train loss-2.2815, acc-0.1800, valid loss-2.2844, acc-0.1600, test loss-2.2853, acc-0.1574\n",
      "Iter-2520, train loss-2.2906, acc-0.1400, valid loss-2.2842, acc-0.1602, test loss-2.2852, acc-0.1573\n",
      "Iter-2530, train loss-2.3126, acc-0.1000, valid loss-2.2841, acc-0.1612, test loss-2.2850, acc-0.1576\n",
      "Iter-2540, train loss-2.2872, acc-0.2000, valid loss-2.2840, acc-0.1616, test loss-2.2849, acc-0.1581\n",
      "Iter-2550, train loss-2.2954, acc-0.0800, valid loss-2.2838, acc-0.1616, test loss-2.2848, acc-0.1585\n",
      "Iter-2560, train loss-2.2884, acc-0.1400, valid loss-2.2837, acc-0.1622, test loss-2.2846, acc-0.1588\n",
      "Iter-2570, train loss-2.2600, acc-0.2400, valid loss-2.2835, acc-0.1622, test loss-2.2845, acc-0.1589\n",
      "Iter-2580, train loss-2.2774, acc-0.1800, valid loss-2.2834, acc-0.1626, test loss-2.2843, acc-0.1591\n",
      "Iter-2590, train loss-2.2860, acc-0.1600, valid loss-2.2833, acc-0.1636, test loss-2.2842, acc-0.1591\n",
      "Iter-2600, train loss-2.2735, acc-0.1600, valid loss-2.2831, acc-0.1638, test loss-2.2841, acc-0.1595\n",
      "Iter-2610, train loss-2.2766, acc-0.2000, valid loss-2.2830, acc-0.1636, test loss-2.2839, acc-0.1596\n",
      "Iter-2620, train loss-2.2865, acc-0.1600, valid loss-2.2829, acc-0.1642, test loss-2.2838, acc-0.1599\n",
      "Iter-2630, train loss-2.2907, acc-0.1400, valid loss-2.2827, acc-0.1644, test loss-2.2837, acc-0.1601\n",
      "Iter-2640, train loss-2.2778, acc-0.1600, valid loss-2.2826, acc-0.1650, test loss-2.2835, acc-0.1602\n",
      "Iter-2650, train loss-2.3027, acc-0.1400, valid loss-2.2825, acc-0.1652, test loss-2.2834, acc-0.1601\n",
      "Iter-2660, train loss-2.2954, acc-0.1400, valid loss-2.2824, acc-0.1658, test loss-2.2833, acc-0.1611\n",
      "Iter-2670, train loss-2.2647, acc-0.1800, valid loss-2.2822, acc-0.1664, test loss-2.2831, acc-0.1612\n",
      "Iter-2680, train loss-2.3021, acc-0.0600, valid loss-2.2821, acc-0.1668, test loss-2.2830, acc-0.1619\n",
      "Iter-2690, train loss-2.2905, acc-0.1600, valid loss-2.2820, acc-0.1668, test loss-2.2829, acc-0.1619\n",
      "Iter-2700, train loss-2.2639, acc-0.2000, valid loss-2.2818, acc-0.1668, test loss-2.2827, acc-0.1625\n",
      "Iter-2710, train loss-2.2714, acc-0.2000, valid loss-2.2817, acc-0.1668, test loss-2.2826, acc-0.1622\n",
      "Iter-2720, train loss-2.2798, acc-0.1000, valid loss-2.2816, acc-0.1672, test loss-2.2825, acc-0.1630\n",
      "Iter-2730, train loss-2.2843, acc-0.1600, valid loss-2.2814, acc-0.1688, test loss-2.2823, acc-0.1639\n",
      "Iter-2740, train loss-2.2787, acc-0.1200, valid loss-2.2813, acc-0.1688, test loss-2.2822, acc-0.1641\n",
      "Iter-2750, train loss-2.2634, acc-0.1200, valid loss-2.2812, acc-0.1694, test loss-2.2821, acc-0.1652\n",
      "Iter-2760, train loss-2.2771, acc-0.1200, valid loss-2.2810, acc-0.1696, test loss-2.2819, acc-0.1653\n",
      "Iter-2770, train loss-2.2987, acc-0.1400, valid loss-2.2809, acc-0.1702, test loss-2.2818, acc-0.1656\n",
      "Iter-2780, train loss-2.2893, acc-0.1800, valid loss-2.2808, acc-0.1704, test loss-2.2817, acc-0.1662\n",
      "Iter-2790, train loss-2.2827, acc-0.2000, valid loss-2.2806, acc-0.1700, test loss-2.2816, acc-0.1663\n",
      "Iter-2800, train loss-2.2841, acc-0.1600, valid loss-2.2805, acc-0.1704, test loss-2.2814, acc-0.1664\n",
      "Iter-2810, train loss-2.2896, acc-0.1400, valid loss-2.2804, acc-0.1708, test loss-2.2813, acc-0.1670\n",
      "Iter-2820, train loss-2.2869, acc-0.1000, valid loss-2.2803, acc-0.1712, test loss-2.2812, acc-0.1677\n",
      "Iter-2830, train loss-2.2966, acc-0.1600, valid loss-2.2801, acc-0.1718, test loss-2.2810, acc-0.1679\n",
      "Iter-2840, train loss-2.2741, acc-0.2200, valid loss-2.2800, acc-0.1720, test loss-2.2809, acc-0.1687\n",
      "Iter-2850, train loss-2.2788, acc-0.1800, valid loss-2.2799, acc-0.1722, test loss-2.2808, acc-0.1689\n",
      "Iter-2860, train loss-2.3054, acc-0.1000, valid loss-2.2797, acc-0.1724, test loss-2.2806, acc-0.1691\n",
      "Iter-2870, train loss-2.2658, acc-0.2000, valid loss-2.2796, acc-0.1724, test loss-2.2805, acc-0.1696\n",
      "Iter-2880, train loss-2.2917, acc-0.1800, valid loss-2.2795, acc-0.1728, test loss-2.2804, acc-0.1700\n",
      "Iter-2890, train loss-2.2715, acc-0.2400, valid loss-2.2793, acc-0.1730, test loss-2.2802, acc-0.1699\n",
      "Iter-2900, train loss-2.2762, acc-0.1200, valid loss-2.2792, acc-0.1732, test loss-2.2801, acc-0.1702\n",
      "Iter-2910, train loss-2.2874, acc-0.1200, valid loss-2.2791, acc-0.1732, test loss-2.2799, acc-0.1704\n",
      "Iter-2920, train loss-2.2600, acc-0.1800, valid loss-2.2789, acc-0.1736, test loss-2.2798, acc-0.1708\n",
      "Iter-2930, train loss-2.2722, acc-0.1600, valid loss-2.2788, acc-0.1742, test loss-2.2797, acc-0.1712\n",
      "Iter-2940, train loss-2.2742, acc-0.1200, valid loss-2.2787, acc-0.1744, test loss-2.2795, acc-0.1719\n",
      "Iter-2950, train loss-2.2709, acc-0.2400, valid loss-2.2785, acc-0.1746, test loss-2.2794, acc-0.1722\n",
      "Iter-2960, train loss-2.2821, acc-0.1800, valid loss-2.2784, acc-0.1750, test loss-2.2793, acc-0.1724\n",
      "Iter-2970, train loss-2.2954, acc-0.0800, valid loss-2.2783, acc-0.1758, test loss-2.2792, acc-0.1727\n",
      "Iter-2980, train loss-2.2907, acc-0.1600, valid loss-2.2781, acc-0.1762, test loss-2.2790, acc-0.1732\n",
      "Iter-2990, train loss-2.2722, acc-0.2200, valid loss-2.2780, acc-0.1764, test loss-2.2789, acc-0.1735\n",
      "Iter-3000, train loss-2.3042, acc-0.1600, valid loss-2.2779, acc-0.1764, test loss-2.2788, acc-0.1737\n",
      "Iter-3010, train loss-2.2569, acc-0.2200, valid loss-2.2777, acc-0.1764, test loss-2.2786, acc-0.1739\n",
      "Iter-3020, train loss-2.2619, acc-0.1600, valid loss-2.2776, acc-0.1768, test loss-2.2785, acc-0.1745\n",
      "Iter-3030, train loss-2.2771, acc-0.2200, valid loss-2.2775, acc-0.1770, test loss-2.2784, acc-0.1749\n",
      "Iter-3040, train loss-2.2909, acc-0.1800, valid loss-2.2773, acc-0.1776, test loss-2.2782, acc-0.1755\n",
      "Iter-3050, train loss-2.2647, acc-0.3000, valid loss-2.2772, acc-0.1778, test loss-2.2781, acc-0.1758\n",
      "Iter-3060, train loss-2.2805, acc-0.1200, valid loss-2.2771, acc-0.1784, test loss-2.2780, acc-0.1763\n",
      "Iter-3070, train loss-2.2621, acc-0.1400, valid loss-2.2769, acc-0.1786, test loss-2.2778, acc-0.1763\n",
      "Iter-3080, train loss-2.2821, acc-0.1000, valid loss-2.2768, acc-0.1796, test loss-2.2777, acc-0.1769\n",
      "Iter-3090, train loss-2.2605, acc-0.2000, valid loss-2.2767, acc-0.1800, test loss-2.2776, acc-0.1771\n",
      "Iter-3100, train loss-2.2565, acc-0.2200, valid loss-2.2765, acc-0.1802, test loss-2.2774, acc-0.1774\n",
      "Iter-3110, train loss-2.2793, acc-0.1600, valid loss-2.2764, acc-0.1806, test loss-2.2773, acc-0.1775\n",
      "Iter-3120, train loss-2.2575, acc-0.1400, valid loss-2.2763, acc-0.1808, test loss-2.2772, acc-0.1778\n",
      "Iter-3130, train loss-2.2640, acc-0.1800, valid loss-2.2762, acc-0.1810, test loss-2.2771, acc-0.1780\n",
      "Iter-3140, train loss-2.2895, acc-0.1200, valid loss-2.2760, acc-0.1812, test loss-2.2769, acc-0.1788\n",
      "Iter-3150, train loss-2.2956, acc-0.0400, valid loss-2.2759, acc-0.1812, test loss-2.2768, acc-0.1790\n",
      "Iter-3160, train loss-2.2599, acc-0.2000, valid loss-2.2758, acc-0.1812, test loss-2.2767, acc-0.1795\n",
      "Iter-3170, train loss-2.2902, acc-0.1400, valid loss-2.2756, acc-0.1818, test loss-2.2765, acc-0.1798\n",
      "Iter-3180, train loss-2.2357, acc-0.1600, valid loss-2.2755, acc-0.1822, test loss-2.2764, acc-0.1801\n",
      "Iter-3190, train loss-2.2924, acc-0.2000, valid loss-2.2754, acc-0.1820, test loss-2.2762, acc-0.1801\n",
      "Iter-3200, train loss-2.2794, acc-0.0800, valid loss-2.2752, acc-0.1820, test loss-2.2761, acc-0.1802\n",
      "Iter-3210, train loss-2.2577, acc-0.2400, valid loss-2.2751, acc-0.1822, test loss-2.2760, acc-0.1803\n",
      "Iter-3220, train loss-2.2986, acc-0.1400, valid loss-2.2750, acc-0.1822, test loss-2.2759, acc-0.1805\n",
      "Iter-3230, train loss-2.2695, acc-0.1200, valid loss-2.2748, acc-0.1820, test loss-2.2757, acc-0.1812\n",
      "Iter-3240, train loss-2.2779, acc-0.2200, valid loss-2.2747, acc-0.1834, test loss-2.2756, acc-0.1818\n",
      "Iter-3250, train loss-2.2828, acc-0.1000, valid loss-2.2746, acc-0.1846, test loss-2.2754, acc-0.1820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-3260, train loss-2.2675, acc-0.1800, valid loss-2.2744, acc-0.1844, test loss-2.2753, acc-0.1822\n",
      "Iter-3270, train loss-2.2804, acc-0.1800, valid loss-2.2743, acc-0.1846, test loss-2.2752, acc-0.1823\n",
      "Iter-3280, train loss-2.2719, acc-0.1600, valid loss-2.2742, acc-0.1846, test loss-2.2750, acc-0.1827\n",
      "Iter-3290, train loss-2.2569, acc-0.1800, valid loss-2.2740, acc-0.1850, test loss-2.2749, acc-0.1832\n",
      "Iter-3300, train loss-2.2748, acc-0.1800, valid loss-2.2739, acc-0.1854, test loss-2.2748, acc-0.1836\n",
      "Iter-3310, train loss-2.2696, acc-0.1600, valid loss-2.2738, acc-0.1852, test loss-2.2747, acc-0.1840\n",
      "Iter-3320, train loss-2.2671, acc-0.1600, valid loss-2.2737, acc-0.1858, test loss-2.2745, acc-0.1839\n",
      "Iter-3330, train loss-2.2549, acc-0.2000, valid loss-2.2735, acc-0.1860, test loss-2.2744, acc-0.1844\n",
      "Iter-3340, train loss-2.2644, acc-0.2200, valid loss-2.2734, acc-0.1862, test loss-2.2742, acc-0.1848\n",
      "Iter-3350, train loss-2.2793, acc-0.1800, valid loss-2.2733, acc-0.1864, test loss-2.2741, acc-0.1848\n",
      "Iter-3360, train loss-2.2673, acc-0.2400, valid loss-2.2731, acc-0.1870, test loss-2.2740, acc-0.1850\n",
      "Iter-3370, train loss-2.2715, acc-0.2400, valid loss-2.2730, acc-0.1874, test loss-2.2739, acc-0.1852\n",
      "Iter-3380, train loss-2.2644, acc-0.2800, valid loss-2.2729, acc-0.1880, test loss-2.2737, acc-0.1855\n",
      "Iter-3390, train loss-2.2733, acc-0.1800, valid loss-2.2727, acc-0.1888, test loss-2.2736, acc-0.1855\n",
      "Iter-3400, train loss-2.2882, acc-0.1400, valid loss-2.2726, acc-0.1892, test loss-2.2735, acc-0.1858\n",
      "Iter-3410, train loss-2.2748, acc-0.1600, valid loss-2.2725, acc-0.1896, test loss-2.2733, acc-0.1865\n",
      "Iter-3420, train loss-2.2926, acc-0.1800, valid loss-2.2723, acc-0.1898, test loss-2.2732, acc-0.1871\n",
      "Iter-3430, train loss-2.2607, acc-0.1800, valid loss-2.2722, acc-0.1902, test loss-2.2731, acc-0.1875\n",
      "Iter-3440, train loss-2.2780, acc-0.2200, valid loss-2.2721, acc-0.1910, test loss-2.2729, acc-0.1878\n",
      "Iter-3450, train loss-2.2532, acc-0.2400, valid loss-2.2719, acc-0.1914, test loss-2.2728, acc-0.1883\n",
      "Iter-3460, train loss-2.2581, acc-0.1800, valid loss-2.2718, acc-0.1914, test loss-2.2727, acc-0.1884\n",
      "Iter-3470, train loss-2.2644, acc-0.2800, valid loss-2.2717, acc-0.1920, test loss-2.2725, acc-0.1886\n",
      "Iter-3480, train loss-2.2826, acc-0.1600, valid loss-2.2715, acc-0.1922, test loss-2.2724, acc-0.1884\n",
      "Iter-3490, train loss-2.2663, acc-0.1800, valid loss-2.2714, acc-0.1924, test loss-2.2723, acc-0.1886\n",
      "Iter-3500, train loss-2.3020, acc-0.0400, valid loss-2.2713, acc-0.1928, test loss-2.2722, acc-0.1886\n",
      "Iter-3510, train loss-2.2781, acc-0.1800, valid loss-2.2712, acc-0.1930, test loss-2.2720, acc-0.1888\n",
      "Iter-3520, train loss-2.2675, acc-0.2400, valid loss-2.2710, acc-0.1934, test loss-2.2719, acc-0.1894\n",
      "Iter-3530, train loss-2.2638, acc-0.2200, valid loss-2.2709, acc-0.1936, test loss-2.2718, acc-0.1897\n",
      "Iter-3540, train loss-2.2658, acc-0.2400, valid loss-2.2708, acc-0.1938, test loss-2.2716, acc-0.1896\n",
      "Iter-3550, train loss-2.2818, acc-0.1600, valid loss-2.2706, acc-0.1940, test loss-2.2715, acc-0.1900\n",
      "Iter-3560, train loss-2.2651, acc-0.2400, valid loss-2.2705, acc-0.1942, test loss-2.2714, acc-0.1899\n",
      "Iter-3570, train loss-2.2897, acc-0.1000, valid loss-2.2704, acc-0.1948, test loss-2.2712, acc-0.1904\n",
      "Iter-3580, train loss-2.2636, acc-0.2000, valid loss-2.2702, acc-0.1946, test loss-2.2711, acc-0.1905\n",
      "Iter-3590, train loss-2.2653, acc-0.2400, valid loss-2.2701, acc-0.1950, test loss-2.2710, acc-0.1908\n",
      "Iter-3600, train loss-2.2757, acc-0.1400, valid loss-2.2700, acc-0.1954, test loss-2.2709, acc-0.1913\n",
      "Iter-3610, train loss-2.2447, acc-0.2400, valid loss-2.2699, acc-0.1954, test loss-2.2707, acc-0.1917\n",
      "Iter-3620, train loss-2.3053, acc-0.1400, valid loss-2.2697, acc-0.1960, test loss-2.2706, acc-0.1921\n",
      "Iter-3630, train loss-2.2610, acc-0.1200, valid loss-2.2696, acc-0.1964, test loss-2.2705, acc-0.1926\n",
      "Iter-3640, train loss-2.2708, acc-0.2600, valid loss-2.2695, acc-0.1970, test loss-2.2703, acc-0.1931\n",
      "Iter-3650, train loss-2.2589, acc-0.2200, valid loss-2.2693, acc-0.1970, test loss-2.2702, acc-0.1939\n",
      "Iter-3660, train loss-2.2757, acc-0.1200, valid loss-2.2692, acc-0.1976, test loss-2.2701, acc-0.1940\n",
      "Iter-3670, train loss-2.2680, acc-0.0800, valid loss-2.2691, acc-0.1978, test loss-2.2700, acc-0.1940\n",
      "Iter-3680, train loss-2.2749, acc-0.1800, valid loss-2.2689, acc-0.1982, test loss-2.2698, acc-0.1943\n",
      "Iter-3690, train loss-2.2775, acc-0.1600, valid loss-2.2688, acc-0.1980, test loss-2.2697, acc-0.1945\n",
      "Iter-3700, train loss-2.2736, acc-0.0800, valid loss-2.2687, acc-0.1982, test loss-2.2695, acc-0.1945\n",
      "Iter-3710, train loss-2.2686, acc-0.2200, valid loss-2.2685, acc-0.1988, test loss-2.2694, acc-0.1952\n",
      "Iter-3720, train loss-2.2756, acc-0.1800, valid loss-2.2684, acc-0.1988, test loss-2.2693, acc-0.1956\n",
      "Iter-3730, train loss-2.2902, acc-0.1400, valid loss-2.2683, acc-0.1990, test loss-2.2691, acc-0.1965\n",
      "Iter-3740, train loss-2.2640, acc-0.2200, valid loss-2.2681, acc-0.1994, test loss-2.2690, acc-0.1966\n",
      "Iter-3750, train loss-2.2620, acc-0.2400, valid loss-2.2680, acc-0.1998, test loss-2.2689, acc-0.1965\n",
      "Iter-3760, train loss-2.2546, acc-0.2200, valid loss-2.2679, acc-0.2008, test loss-2.2687, acc-0.1976\n",
      "Iter-3770, train loss-2.2756, acc-0.1200, valid loss-2.2677, acc-0.2010, test loss-2.2686, acc-0.1979\n",
      "Iter-3780, train loss-2.3081, acc-0.1200, valid loss-2.2676, acc-0.2018, test loss-2.2685, acc-0.1981\n",
      "Iter-3790, train loss-2.2956, acc-0.1400, valid loss-2.2675, acc-0.2020, test loss-2.2683, acc-0.1984\n",
      "Iter-3800, train loss-2.2828, acc-0.1600, valid loss-2.2673, acc-0.2022, test loss-2.2682, acc-0.1986\n",
      "Iter-3810, train loss-2.2683, acc-0.1800, valid loss-2.2672, acc-0.2022, test loss-2.2681, acc-0.1992\n",
      "Iter-3820, train loss-2.2627, acc-0.1600, valid loss-2.2671, acc-0.2032, test loss-2.2679, acc-0.1995\n",
      "Iter-3830, train loss-2.2764, acc-0.2400, valid loss-2.2669, acc-0.2030, test loss-2.2678, acc-0.1996\n",
      "Iter-3840, train loss-2.2683, acc-0.2400, valid loss-2.2668, acc-0.2032, test loss-2.2677, acc-0.2004\n",
      "Iter-3850, train loss-2.2693, acc-0.2400, valid loss-2.2667, acc-0.2030, test loss-2.2675, acc-0.2009\n",
      "Iter-3860, train loss-2.2445, acc-0.3200, valid loss-2.2665, acc-0.2028, test loss-2.2674, acc-0.2013\n",
      "Iter-3870, train loss-2.2560, acc-0.2600, valid loss-2.2664, acc-0.2030, test loss-2.2673, acc-0.2018\n",
      "Iter-3880, train loss-2.2519, acc-0.3000, valid loss-2.2663, acc-0.2036, test loss-2.2671, acc-0.2022\n",
      "Iter-3890, train loss-2.2763, acc-0.1600, valid loss-2.2661, acc-0.2038, test loss-2.2670, acc-0.2025\n",
      "Iter-3900, train loss-2.2826, acc-0.1400, valid loss-2.2660, acc-0.2042, test loss-2.2669, acc-0.2032\n",
      "Iter-3910, train loss-2.2790, acc-0.2000, valid loss-2.2659, acc-0.2046, test loss-2.2668, acc-0.2038\n",
      "Iter-3920, train loss-2.2322, acc-0.3000, valid loss-2.2657, acc-0.2046, test loss-2.2666, acc-0.2037\n",
      "Iter-3930, train loss-2.2480, acc-0.2400, valid loss-2.2656, acc-0.2046, test loss-2.2665, acc-0.2041\n",
      "Iter-3940, train loss-2.2594, acc-0.3000, valid loss-2.2655, acc-0.2058, test loss-2.2663, acc-0.2043\n",
      "Iter-3950, train loss-2.2915, acc-0.1200, valid loss-2.2653, acc-0.2060, test loss-2.2662, acc-0.2050\n",
      "Iter-3960, train loss-2.2649, acc-0.2200, valid loss-2.2652, acc-0.2062, test loss-2.2661, acc-0.2054\n",
      "Iter-3970, train loss-2.2490, acc-0.2200, valid loss-2.2651, acc-0.2062, test loss-2.2660, acc-0.2058\n",
      "Iter-3980, train loss-2.2719, acc-0.1800, valid loss-2.2649, acc-0.2068, test loss-2.2658, acc-0.2061\n",
      "Iter-3990, train loss-2.2944, acc-0.1000, valid loss-2.2648, acc-0.2066, test loss-2.2657, acc-0.2066\n",
      "Iter-4000, train loss-2.2665, acc-0.2800, valid loss-2.2646, acc-0.2076, test loss-2.2655, acc-0.2071\n",
      "Iter-4010, train loss-2.2797, acc-0.2200, valid loss-2.2645, acc-0.2080, test loss-2.2654, acc-0.2069\n",
      "Iter-4020, train loss-2.2647, acc-0.2000, valid loss-2.2644, acc-0.2084, test loss-2.2653, acc-0.2072\n",
      "Iter-4030, train loss-2.2651, acc-0.2600, valid loss-2.2643, acc-0.2084, test loss-2.2652, acc-0.2076\n",
      "Iter-4040, train loss-2.2657, acc-0.1200, valid loss-2.2641, acc-0.2084, test loss-2.2650, acc-0.2076\n",
      "Iter-4050, train loss-2.2612, acc-0.1800, valid loss-2.2640, acc-0.2088, test loss-2.2649, acc-0.2079\n",
      "Iter-4060, train loss-2.2569, acc-0.1400, valid loss-2.2639, acc-0.2092, test loss-2.2648, acc-0.2083\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4070, train loss-2.2342, acc-0.3400, valid loss-2.2637, acc-0.2106, test loss-2.2646, acc-0.2085\n",
      "Iter-4080, train loss-2.2435, acc-0.3600, valid loss-2.2636, acc-0.2112, test loss-2.2645, acc-0.2087\n",
      "Iter-4090, train loss-2.2806, acc-0.1800, valid loss-2.2635, acc-0.2114, test loss-2.2644, acc-0.2089\n",
      "Iter-4100, train loss-2.2670, acc-0.2000, valid loss-2.2634, acc-0.2118, test loss-2.2643, acc-0.2092\n",
      "Iter-4110, train loss-2.2644, acc-0.2200, valid loss-2.2632, acc-0.2118, test loss-2.2641, acc-0.2099\n",
      "Iter-4120, train loss-2.2813, acc-0.1800, valid loss-2.2631, acc-0.2124, test loss-2.2640, acc-0.2099\n",
      "Iter-4130, train loss-2.2534, acc-0.2800, valid loss-2.2629, acc-0.2126, test loss-2.2639, acc-0.2104\n",
      "Iter-4140, train loss-2.2799, acc-0.2000, valid loss-2.2628, acc-0.2132, test loss-2.2637, acc-0.2107\n",
      "Iter-4150, train loss-2.2640, acc-0.2000, valid loss-2.2627, acc-0.2136, test loss-2.2636, acc-0.2107\n",
      "Iter-4160, train loss-2.2603, acc-0.2400, valid loss-2.2626, acc-0.2134, test loss-2.2635, acc-0.2111\n",
      "Iter-4170, train loss-2.2713, acc-0.2200, valid loss-2.2624, acc-0.2134, test loss-2.2633, acc-0.2115\n",
      "Iter-4180, train loss-2.2541, acc-0.2600, valid loss-2.2623, acc-0.2144, test loss-2.2632, acc-0.2117\n",
      "Iter-4190, train loss-2.2675, acc-0.2200, valid loss-2.2622, acc-0.2144, test loss-2.2631, acc-0.2123\n",
      "Iter-4200, train loss-2.2628, acc-0.2200, valid loss-2.2620, acc-0.2158, test loss-2.2629, acc-0.2127\n",
      "Iter-4210, train loss-2.2630, acc-0.1800, valid loss-2.2619, acc-0.2160, test loss-2.2628, acc-0.2128\n",
      "Iter-4220, train loss-2.2703, acc-0.0800, valid loss-2.2618, acc-0.2166, test loss-2.2627, acc-0.2133\n",
      "Iter-4230, train loss-2.2863, acc-0.1400, valid loss-2.2616, acc-0.2174, test loss-2.2626, acc-0.2135\n",
      "Iter-4240, train loss-2.2634, acc-0.2600, valid loss-2.2615, acc-0.2172, test loss-2.2624, acc-0.2143\n",
      "Iter-4250, train loss-2.2481, acc-0.2800, valid loss-2.2614, acc-0.2174, test loss-2.2623, acc-0.2146\n",
      "Iter-4260, train loss-2.2760, acc-0.2000, valid loss-2.2613, acc-0.2182, test loss-2.2622, acc-0.2148\n",
      "Iter-4270, train loss-2.2688, acc-0.1600, valid loss-2.2611, acc-0.2188, test loss-2.2620, acc-0.2153\n",
      "Iter-4280, train loss-2.2570, acc-0.2000, valid loss-2.2610, acc-0.2190, test loss-2.2619, acc-0.2155\n",
      "Iter-4290, train loss-2.2623, acc-0.2000, valid loss-2.2609, acc-0.2198, test loss-2.2618, acc-0.2158\n",
      "Iter-4300, train loss-2.2590, acc-0.2000, valid loss-2.2608, acc-0.2200, test loss-2.2617, acc-0.2159\n",
      "Iter-4310, train loss-2.2672, acc-0.2200, valid loss-2.2606, acc-0.2200, test loss-2.2615, acc-0.2164\n",
      "Iter-4320, train loss-2.2549, acc-0.2000, valid loss-2.2605, acc-0.2202, test loss-2.2614, acc-0.2169\n",
      "Iter-4330, train loss-2.2600, acc-0.3200, valid loss-2.2604, acc-0.2208, test loss-2.2613, acc-0.2174\n",
      "Iter-4340, train loss-2.2876, acc-0.1000, valid loss-2.2602, acc-0.2208, test loss-2.2611, acc-0.2173\n",
      "Iter-4350, train loss-2.2625, acc-0.2000, valid loss-2.2601, acc-0.2210, test loss-2.2610, acc-0.2181\n",
      "Iter-4360, train loss-2.2383, acc-0.2800, valid loss-2.2600, acc-0.2208, test loss-2.2609, acc-0.2181\n",
      "Iter-4370, train loss-2.2542, acc-0.2200, valid loss-2.2599, acc-0.2206, test loss-2.2608, acc-0.2187\n",
      "Iter-4380, train loss-2.2521, acc-0.2000, valid loss-2.2597, acc-0.2216, test loss-2.2606, acc-0.2189\n",
      "Iter-4390, train loss-2.2609, acc-0.2600, valid loss-2.2596, acc-0.2214, test loss-2.2605, acc-0.2188\n",
      "Iter-4400, train loss-2.2517, acc-0.1800, valid loss-2.2595, acc-0.2224, test loss-2.2604, acc-0.2196\n",
      "Iter-4410, train loss-2.2617, acc-0.2400, valid loss-2.2593, acc-0.2232, test loss-2.2602, acc-0.2202\n",
      "Iter-4420, train loss-2.2560, acc-0.1800, valid loss-2.2592, acc-0.2234, test loss-2.2601, acc-0.2208\n",
      "Iter-4430, train loss-2.2485, acc-0.3400, valid loss-2.2590, acc-0.2238, test loss-2.2600, acc-0.2215\n",
      "Iter-4440, train loss-2.2275, acc-0.2200, valid loss-2.2589, acc-0.2236, test loss-2.2598, acc-0.2217\n",
      "Iter-4450, train loss-2.3021, acc-0.2200, valid loss-2.2588, acc-0.2246, test loss-2.2597, acc-0.2222\n",
      "Iter-4460, train loss-2.2835, acc-0.1600, valid loss-2.2586, acc-0.2248, test loss-2.2596, acc-0.2223\n",
      "Iter-4470, train loss-2.2558, acc-0.2200, valid loss-2.2585, acc-0.2254, test loss-2.2594, acc-0.2227\n",
      "Iter-4480, train loss-2.2454, acc-0.2400, valid loss-2.2584, acc-0.2254, test loss-2.2593, acc-0.2228\n",
      "Iter-4490, train loss-2.2538, acc-0.2000, valid loss-2.2582, acc-0.2260, test loss-2.2592, acc-0.2230\n",
      "Iter-4500, train loss-2.2585, acc-0.2200, valid loss-2.2581, acc-0.2260, test loss-2.2590, acc-0.2234\n",
      "Iter-4510, train loss-2.2942, acc-0.1000, valid loss-2.2580, acc-0.2266, test loss-2.2589, acc-0.2233\n",
      "Iter-4520, train loss-2.2624, acc-0.2600, valid loss-2.2579, acc-0.2266, test loss-2.2588, acc-0.2238\n",
      "Iter-4530, train loss-2.2355, acc-0.3200, valid loss-2.2577, acc-0.2266, test loss-2.2587, acc-0.2241\n",
      "Iter-4540, train loss-2.2569, acc-0.2800, valid loss-2.2576, acc-0.2272, test loss-2.2585, acc-0.2243\n",
      "Iter-4550, train loss-2.2731, acc-0.2000, valid loss-2.2575, acc-0.2274, test loss-2.2584, acc-0.2252\n",
      "Iter-4560, train loss-2.2603, acc-0.1600, valid loss-2.2573, acc-0.2278, test loss-2.2583, acc-0.2252\n",
      "Iter-4570, train loss-2.2804, acc-0.1600, valid loss-2.2572, acc-0.2282, test loss-2.2581, acc-0.2255\n",
      "Iter-4580, train loss-2.2764, acc-0.2600, valid loss-2.2571, acc-0.2286, test loss-2.2580, acc-0.2262\n",
      "Iter-4590, train loss-2.2537, acc-0.2000, valid loss-2.2569, acc-0.2290, test loss-2.2579, acc-0.2264\n",
      "Iter-4600, train loss-2.2354, acc-0.2400, valid loss-2.2568, acc-0.2294, test loss-2.2578, acc-0.2269\n",
      "Iter-4610, train loss-2.2397, acc-0.4000, valid loss-2.2567, acc-0.2294, test loss-2.2576, acc-0.2269\n",
      "Iter-4620, train loss-2.2638, acc-0.2600, valid loss-2.2566, acc-0.2300, test loss-2.2575, acc-0.2270\n",
      "Iter-4630, train loss-2.2486, acc-0.2400, valid loss-2.2564, acc-0.2304, test loss-2.2574, acc-0.2275\n",
      "Iter-4640, train loss-2.2554, acc-0.2200, valid loss-2.2563, acc-0.2306, test loss-2.2572, acc-0.2282\n",
      "Iter-4650, train loss-2.2370, acc-0.2600, valid loss-2.2562, acc-0.2308, test loss-2.2571, acc-0.2284\n",
      "Iter-4660, train loss-2.2754, acc-0.2000, valid loss-2.2561, acc-0.2316, test loss-2.2570, acc-0.2288\n",
      "Iter-4670, train loss-2.2571, acc-0.1400, valid loss-2.2559, acc-0.2318, test loss-2.2569, acc-0.2289\n",
      "Iter-4680, train loss-2.2492, acc-0.2400, valid loss-2.2558, acc-0.2324, test loss-2.2567, acc-0.2292\n",
      "Iter-4690, train loss-2.2780, acc-0.1400, valid loss-2.2557, acc-0.2322, test loss-2.2566, acc-0.2292\n",
      "Iter-4700, train loss-2.2345, acc-0.2600, valid loss-2.2555, acc-0.2326, test loss-2.2565, acc-0.2294\n",
      "Iter-4710, train loss-2.2655, acc-0.1600, valid loss-2.2554, acc-0.2334, test loss-2.2563, acc-0.2294\n",
      "Iter-4720, train loss-2.2329, acc-0.3000, valid loss-2.2553, acc-0.2346, test loss-2.2562, acc-0.2303\n",
      "Iter-4730, train loss-2.2655, acc-0.1600, valid loss-2.2551, acc-0.2350, test loss-2.2561, acc-0.2309\n",
      "Iter-4740, train loss-2.2435, acc-0.2400, valid loss-2.2550, acc-0.2350, test loss-2.2559, acc-0.2310\n",
      "Iter-4750, train loss-2.2532, acc-0.2800, valid loss-2.2549, acc-0.2352, test loss-2.2558, acc-0.2314\n",
      "Iter-4760, train loss-2.2295, acc-0.3600, valid loss-2.2547, acc-0.2358, test loss-2.2557, acc-0.2319\n",
      "Iter-4770, train loss-2.2261, acc-0.2800, valid loss-2.2546, acc-0.2362, test loss-2.2555, acc-0.2322\n",
      "Iter-4780, train loss-2.2784, acc-0.1600, valid loss-2.2545, acc-0.2372, test loss-2.2554, acc-0.2324\n",
      "Iter-4790, train loss-2.2607, acc-0.1800, valid loss-2.2544, acc-0.2374, test loss-2.2553, acc-0.2328\n",
      "Iter-4800, train loss-2.2552, acc-0.2400, valid loss-2.2542, acc-0.2374, test loss-2.2552, acc-0.2333\n",
      "Iter-4810, train loss-2.2658, acc-0.2400, valid loss-2.2541, acc-0.2378, test loss-2.2550, acc-0.2335\n",
      "Iter-4820, train loss-2.2778, acc-0.2600, valid loss-2.2540, acc-0.2376, test loss-2.2549, acc-0.2339\n",
      "Iter-4830, train loss-2.2882, acc-0.1800, valid loss-2.2538, acc-0.2378, test loss-2.2548, acc-0.2340\n",
      "Iter-4840, train loss-2.2505, acc-0.3000, valid loss-2.2537, acc-0.2388, test loss-2.2546, acc-0.2344\n",
      "Iter-4850, train loss-2.2296, acc-0.2400, valid loss-2.2536, acc-0.2390, test loss-2.2545, acc-0.2346\n",
      "Iter-4860, train loss-2.2236, acc-0.3200, valid loss-2.2534, acc-0.2390, test loss-2.2544, acc-0.2348\n",
      "Iter-4870, train loss-2.2719, acc-0.1800, valid loss-2.2533, acc-0.2394, test loss-2.2542, acc-0.2349\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-4880, train loss-2.2636, acc-0.2400, valid loss-2.2532, acc-0.2402, test loss-2.2541, acc-0.2357\n",
      "Iter-4890, train loss-2.2576, acc-0.2400, valid loss-2.2531, acc-0.2408, test loss-2.2540, acc-0.2360\n",
      "Iter-4900, train loss-2.2548, acc-0.2800, valid loss-2.2529, acc-0.2412, test loss-2.2538, acc-0.2363\n",
      "Iter-4910, train loss-2.2583, acc-0.2400, valid loss-2.2528, acc-0.2416, test loss-2.2537, acc-0.2367\n",
      "Iter-4920, train loss-2.2528, acc-0.2000, valid loss-2.2527, acc-0.2422, test loss-2.2536, acc-0.2369\n",
      "Iter-4930, train loss-2.2629, acc-0.2400, valid loss-2.2525, acc-0.2426, test loss-2.2535, acc-0.2375\n",
      "Iter-4940, train loss-2.2525, acc-0.2200, valid loss-2.2524, acc-0.2428, test loss-2.2533, acc-0.2377\n",
      "Iter-4950, train loss-2.2339, acc-0.3400, valid loss-2.2523, acc-0.2428, test loss-2.2532, acc-0.2381\n",
      "Iter-4960, train loss-2.2802, acc-0.1400, valid loss-2.2522, acc-0.2426, test loss-2.2531, acc-0.2388\n",
      "Iter-4970, train loss-2.2607, acc-0.2800, valid loss-2.2520, acc-0.2432, test loss-2.2530, acc-0.2390\n",
      "Iter-4980, train loss-2.2464, acc-0.3000, valid loss-2.2519, acc-0.2432, test loss-2.2528, acc-0.2395\n",
      "Iter-4990, train loss-2.2611, acc-0.1800, valid loss-2.2518, acc-0.2434, test loss-2.2527, acc-0.2397\n",
      "Iter-5000, train loss-2.2693, acc-0.2000, valid loss-2.2517, acc-0.2438, test loss-2.2526, acc-0.2400\n",
      "Iter-5010, train loss-2.2209, acc-0.3400, valid loss-2.2515, acc-0.2446, test loss-2.2524, acc-0.2403\n",
      "Iter-5020, train loss-2.2399, acc-0.2600, valid loss-2.2514, acc-0.2452, test loss-2.2523, acc-0.2405\n",
      "Iter-5030, train loss-2.2542, acc-0.1800, valid loss-2.2513, acc-0.2458, test loss-2.2522, acc-0.2411\n",
      "Iter-5040, train loss-2.2534, acc-0.2200, valid loss-2.2511, acc-0.2460, test loss-2.2521, acc-0.2415\n",
      "Iter-5050, train loss-2.2336, acc-0.3400, valid loss-2.2510, acc-0.2462, test loss-2.2519, acc-0.2421\n",
      "Iter-5060, train loss-2.2478, acc-0.2000, valid loss-2.2509, acc-0.2464, test loss-2.2518, acc-0.2433\n",
      "Iter-5070, train loss-2.2339, acc-0.3000, valid loss-2.2508, acc-0.2470, test loss-2.2517, acc-0.2435\n",
      "Iter-5080, train loss-2.2630, acc-0.2800, valid loss-2.2506, acc-0.2474, test loss-2.2516, acc-0.2441\n",
      "Iter-5090, train loss-2.2611, acc-0.1800, valid loss-2.2505, acc-0.2480, test loss-2.2514, acc-0.2445\n",
      "Iter-5100, train loss-2.2340, acc-0.2400, valid loss-2.2504, acc-0.2484, test loss-2.2513, acc-0.2448\n",
      "Iter-5110, train loss-2.2714, acc-0.2400, valid loss-2.2503, acc-0.2486, test loss-2.2512, acc-0.2455\n",
      "Iter-5120, train loss-2.2514, acc-0.1800, valid loss-2.2502, acc-0.2490, test loss-2.2511, acc-0.2459\n",
      "Iter-5130, train loss-2.2583, acc-0.2400, valid loss-2.2500, acc-0.2494, test loss-2.2509, acc-0.2463\n",
      "Iter-5140, train loss-2.2604, acc-0.1800, valid loss-2.2499, acc-0.2496, test loss-2.2508, acc-0.2467\n",
      "Iter-5150, train loss-2.2382, acc-0.3800, valid loss-2.2498, acc-0.2500, test loss-2.2507, acc-0.2470\n",
      "Iter-5160, train loss-2.2471, acc-0.2400, valid loss-2.2496, acc-0.2504, test loss-2.2506, acc-0.2482\n",
      "Iter-5170, train loss-2.2650, acc-0.2200, valid loss-2.2495, acc-0.2506, test loss-2.2504, acc-0.2489\n",
      "Iter-5180, train loss-2.2384, acc-0.2400, valid loss-2.2494, acc-0.2508, test loss-2.2503, acc-0.2488\n",
      "Iter-5190, train loss-2.2510, acc-0.2800, valid loss-2.2492, acc-0.2506, test loss-2.2502, acc-0.2489\n",
      "Iter-5200, train loss-2.2442, acc-0.3600, valid loss-2.2491, acc-0.2508, test loss-2.2500, acc-0.2492\n",
      "Iter-5210, train loss-2.2502, acc-0.2400, valid loss-2.2490, acc-0.2512, test loss-2.2499, acc-0.2495\n",
      "Iter-5220, train loss-2.2649, acc-0.1400, valid loss-2.2489, acc-0.2520, test loss-2.2498, acc-0.2500\n",
      "Iter-5230, train loss-2.2435, acc-0.1600, valid loss-2.2487, acc-0.2530, test loss-2.2497, acc-0.2502\n",
      "Iter-5240, train loss-2.2312, acc-0.2200, valid loss-2.2486, acc-0.2532, test loss-2.2495, acc-0.2507\n",
      "Iter-5250, train loss-2.2668, acc-0.2000, valid loss-2.2485, acc-0.2532, test loss-2.2494, acc-0.2510\n",
      "Iter-5260, train loss-2.2483, acc-0.2000, valid loss-2.2483, acc-0.2536, test loss-2.2493, acc-0.2513\n",
      "Iter-5270, train loss-2.2616, acc-0.2000, valid loss-2.2482, acc-0.2544, test loss-2.2492, acc-0.2515\n",
      "Iter-5280, train loss-2.2414, acc-0.2800, valid loss-2.2481, acc-0.2542, test loss-2.2490, acc-0.2523\n",
      "Iter-5290, train loss-2.2404, acc-0.2200, valid loss-2.2480, acc-0.2550, test loss-2.2489, acc-0.2527\n",
      "Iter-5300, train loss-2.2202, acc-0.3200, valid loss-2.2478, acc-0.2552, test loss-2.2488, acc-0.2531\n",
      "Iter-5310, train loss-2.2623, acc-0.2200, valid loss-2.2477, acc-0.2554, test loss-2.2486, acc-0.2529\n",
      "Iter-5320, train loss-2.2631, acc-0.2400, valid loss-2.2476, acc-0.2556, test loss-2.2485, acc-0.2539\n",
      "Iter-5330, train loss-2.2163, acc-0.3600, valid loss-2.2475, acc-0.2566, test loss-2.2484, acc-0.2541\n",
      "Iter-5340, train loss-2.2449, acc-0.3000, valid loss-2.2473, acc-0.2568, test loss-2.2483, acc-0.2541\n",
      "Iter-5350, train loss-2.2235, acc-0.1800, valid loss-2.2472, acc-0.2574, test loss-2.2481, acc-0.2544\n",
      "Iter-5360, train loss-2.2613, acc-0.2000, valid loss-2.2471, acc-0.2578, test loss-2.2480, acc-0.2546\n",
      "Iter-5370, train loss-2.2269, acc-0.3200, valid loss-2.2470, acc-0.2578, test loss-2.2479, acc-0.2554\n",
      "Iter-5380, train loss-2.2423, acc-0.2400, valid loss-2.2468, acc-0.2578, test loss-2.2478, acc-0.2559\n",
      "Iter-5390, train loss-2.2372, acc-0.2800, valid loss-2.2467, acc-0.2578, test loss-2.2476, acc-0.2566\n",
      "Iter-5400, train loss-2.2472, acc-0.2000, valid loss-2.2466, acc-0.2578, test loss-2.2475, acc-0.2569\n",
      "Iter-5410, train loss-2.2285, acc-0.2800, valid loss-2.2465, acc-0.2586, test loss-2.2474, acc-0.2573\n",
      "Iter-5420, train loss-2.2429, acc-0.2400, valid loss-2.2463, acc-0.2588, test loss-2.2473, acc-0.2578\n",
      "Iter-5430, train loss-2.2316, acc-0.3400, valid loss-2.2462, acc-0.2590, test loss-2.2471, acc-0.2585\n",
      "Iter-5440, train loss-2.2274, acc-0.2800, valid loss-2.2461, acc-0.2594, test loss-2.2470, acc-0.2589\n",
      "Iter-5450, train loss-2.2586, acc-0.2600, valid loss-2.2460, acc-0.2600, test loss-2.2469, acc-0.2593\n",
      "Iter-5460, train loss-2.2545, acc-0.2400, valid loss-2.2458, acc-0.2610, test loss-2.2468, acc-0.2596\n",
      "Iter-5470, train loss-2.2330, acc-0.2000, valid loss-2.2457, acc-0.2608, test loss-2.2466, acc-0.2599\n",
      "Iter-5480, train loss-2.2744, acc-0.2000, valid loss-2.2456, acc-0.2614, test loss-2.2465, acc-0.2605\n",
      "Iter-5490, train loss-2.2508, acc-0.3000, valid loss-2.2454, acc-0.2620, test loss-2.2464, acc-0.2611\n",
      "Iter-5500, train loss-2.2255, acc-0.2600, valid loss-2.2453, acc-0.2630, test loss-2.2462, acc-0.2615\n",
      "Iter-5510, train loss-2.2608, acc-0.3400, valid loss-2.2452, acc-0.2626, test loss-2.2461, acc-0.2620\n",
      "Iter-5520, train loss-2.2839, acc-0.1200, valid loss-2.2451, acc-0.2626, test loss-2.2460, acc-0.2623\n",
      "Iter-5530, train loss-2.2501, acc-0.2200, valid loss-2.2449, acc-0.2634, test loss-2.2459, acc-0.2625\n",
      "Iter-5540, train loss-2.2527, acc-0.2200, valid loss-2.2448, acc-0.2642, test loss-2.2457, acc-0.2627\n",
      "Iter-5550, train loss-2.2192, acc-0.4200, valid loss-2.2447, acc-0.2644, test loss-2.2456, acc-0.2634\n",
      "Iter-5560, train loss-2.2320, acc-0.3200, valid loss-2.2445, acc-0.2650, test loss-2.2455, acc-0.2635\n",
      "Iter-5570, train loss-2.2432, acc-0.3200, valid loss-2.2444, acc-0.2652, test loss-2.2453, acc-0.2640\n",
      "Iter-5580, train loss-2.2486, acc-0.2400, valid loss-2.2443, acc-0.2656, test loss-2.2452, acc-0.2642\n",
      "Iter-5590, train loss-2.2579, acc-0.2600, valid loss-2.2442, acc-0.2660, test loss-2.2451, acc-0.2649\n",
      "Iter-5600, train loss-2.2325, acc-0.3000, valid loss-2.2440, acc-0.2658, test loss-2.2450, acc-0.2651\n",
      "Iter-5610, train loss-2.2115, acc-0.4200, valid loss-2.2439, acc-0.2660, test loss-2.2448, acc-0.2652\n",
      "Iter-5620, train loss-2.2653, acc-0.2800, valid loss-2.2438, acc-0.2662, test loss-2.2447, acc-0.2657\n",
      "Iter-5630, train loss-2.2440, acc-0.2400, valid loss-2.2437, acc-0.2666, test loss-2.2446, acc-0.2659\n",
      "Iter-5640, train loss-2.2473, acc-0.1400, valid loss-2.2436, acc-0.2676, test loss-2.2445, acc-0.2664\n",
      "Iter-5650, train loss-2.2595, acc-0.2400, valid loss-2.2434, acc-0.2670, test loss-2.2444, acc-0.2665\n",
      "Iter-5660, train loss-2.2761, acc-0.2400, valid loss-2.2433, acc-0.2674, test loss-2.2442, acc-0.2673\n",
      "Iter-5670, train loss-2.2522, acc-0.2400, valid loss-2.2432, acc-0.2678, test loss-2.2441, acc-0.2676\n",
      "Iter-5680, train loss-2.2589, acc-0.2400, valid loss-2.2430, acc-0.2680, test loss-2.2440, acc-0.2678\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-5690, train loss-2.2338, acc-0.2400, valid loss-2.2429, acc-0.2684, test loss-2.2438, acc-0.2678\n",
      "Iter-5700, train loss-2.2148, acc-0.3600, valid loss-2.2428, acc-0.2680, test loss-2.2437, acc-0.2682\n",
      "Iter-5710, train loss-2.2642, acc-0.2200, valid loss-2.2427, acc-0.2682, test loss-2.2436, acc-0.2688\n",
      "Iter-5720, train loss-2.2555, acc-0.2800, valid loss-2.2425, acc-0.2684, test loss-2.2435, acc-0.2690\n",
      "Iter-5730, train loss-2.2203, acc-0.2800, valid loss-2.2424, acc-0.2686, test loss-2.2433, acc-0.2691\n",
      "Iter-5740, train loss-2.2257, acc-0.2400, valid loss-2.2423, acc-0.2694, test loss-2.2432, acc-0.2694\n",
      "Iter-5750, train loss-2.2258, acc-0.2800, valid loss-2.2421, acc-0.2696, test loss-2.2431, acc-0.2697\n",
      "Iter-5760, train loss-2.2047, acc-0.3200, valid loss-2.2420, acc-0.2698, test loss-2.2430, acc-0.2699\n",
      "Iter-5770, train loss-2.2494, acc-0.2000, valid loss-2.2419, acc-0.2704, test loss-2.2428, acc-0.2702\n",
      "Iter-5780, train loss-2.2185, acc-0.3400, valid loss-2.2417, acc-0.2708, test loss-2.2427, acc-0.2704\n",
      "Iter-5790, train loss-2.2403, acc-0.2400, valid loss-2.2416, acc-0.2712, test loss-2.2426, acc-0.2708\n",
      "Iter-5800, train loss-2.2623, acc-0.1800, valid loss-2.2415, acc-0.2714, test loss-2.2424, acc-0.2711\n",
      "Iter-5810, train loss-2.2289, acc-0.3800, valid loss-2.2413, acc-0.2720, test loss-2.2423, acc-0.2712\n",
      "Iter-5820, train loss-2.2377, acc-0.2600, valid loss-2.2412, acc-0.2728, test loss-2.2422, acc-0.2716\n",
      "Iter-5830, train loss-2.2415, acc-0.2000, valid loss-2.2411, acc-0.2734, test loss-2.2420, acc-0.2720\n",
      "Iter-5840, train loss-2.2773, acc-0.1800, valid loss-2.2410, acc-0.2738, test loss-2.2419, acc-0.2724\n",
      "Iter-5850, train loss-2.2275, acc-0.3000, valid loss-2.2408, acc-0.2738, test loss-2.2418, acc-0.2725\n",
      "Iter-5860, train loss-2.2177, acc-0.3800, valid loss-2.2407, acc-0.2748, test loss-2.2417, acc-0.2727\n",
      "Iter-5870, train loss-2.2539, acc-0.3000, valid loss-2.2406, acc-0.2748, test loss-2.2415, acc-0.2727\n",
      "Iter-5880, train loss-2.2415, acc-0.2000, valid loss-2.2404, acc-0.2756, test loss-2.2414, acc-0.2731\n",
      "Iter-5890, train loss-2.2457, acc-0.2400, valid loss-2.2403, acc-0.2758, test loss-2.2413, acc-0.2738\n",
      "Iter-5900, train loss-2.2436, acc-0.2600, valid loss-2.2402, acc-0.2758, test loss-2.2412, acc-0.2739\n",
      "Iter-5910, train loss-2.2407, acc-0.2800, valid loss-2.2401, acc-0.2766, test loss-2.2410, acc-0.2741\n",
      "Iter-5920, train loss-2.2233, acc-0.3000, valid loss-2.2399, acc-0.2770, test loss-2.2409, acc-0.2743\n",
      "Iter-5930, train loss-2.2472, acc-0.3200, valid loss-2.2398, acc-0.2776, test loss-2.2408, acc-0.2743\n",
      "Iter-5940, train loss-2.2290, acc-0.2800, valid loss-2.2397, acc-0.2774, test loss-2.2406, acc-0.2751\n",
      "Iter-5950, train loss-2.2311, acc-0.3600, valid loss-2.2396, acc-0.2776, test loss-2.2405, acc-0.2749\n",
      "Iter-5960, train loss-2.2307, acc-0.2800, valid loss-2.2394, acc-0.2778, test loss-2.2404, acc-0.2756\n",
      "Iter-5970, train loss-2.2685, acc-0.1800, valid loss-2.2393, acc-0.2782, test loss-2.2403, acc-0.2757\n",
      "Iter-5980, train loss-2.2618, acc-0.2400, valid loss-2.2392, acc-0.2786, test loss-2.2401, acc-0.2762\n",
      "Iter-5990, train loss-2.2537, acc-0.3200, valid loss-2.2391, acc-0.2788, test loss-2.2400, acc-0.2764\n",
      "Iter-6000, train loss-2.2333, acc-0.4000, valid loss-2.2389, acc-0.2790, test loss-2.2399, acc-0.2767\n",
      "Iter-6010, train loss-2.2485, acc-0.3200, valid loss-2.2388, acc-0.2790, test loss-2.2398, acc-0.2772\n",
      "Iter-6020, train loss-2.2354, acc-0.2000, valid loss-2.2387, acc-0.2796, test loss-2.2396, acc-0.2775\n",
      "Iter-6030, train loss-2.2668, acc-0.1400, valid loss-2.2386, acc-0.2806, test loss-2.2395, acc-0.2776\n",
      "Iter-6040, train loss-2.2492, acc-0.2000, valid loss-2.2384, acc-0.2806, test loss-2.2394, acc-0.2777\n",
      "Iter-6050, train loss-2.2286, acc-0.3000, valid loss-2.2383, acc-0.2810, test loss-2.2393, acc-0.2783\n",
      "Iter-6060, train loss-2.2575, acc-0.2000, valid loss-2.2382, acc-0.2814, test loss-2.2391, acc-0.2789\n",
      "Iter-6070, train loss-2.2460, acc-0.2600, valid loss-2.2381, acc-0.2814, test loss-2.2390, acc-0.2794\n",
      "Iter-6080, train loss-2.2423, acc-0.2000, valid loss-2.2379, acc-0.2816, test loss-2.2389, acc-0.2796\n",
      "Iter-6090, train loss-2.2258, acc-0.3400, valid loss-2.2378, acc-0.2820, test loss-2.2387, acc-0.2796\n",
      "Iter-6100, train loss-2.2151, acc-0.3000, valid loss-2.2377, acc-0.2820, test loss-2.2386, acc-0.2800\n",
      "Iter-6110, train loss-2.2470, acc-0.2200, valid loss-2.2375, acc-0.2818, test loss-2.2385, acc-0.2805\n",
      "Iter-6120, train loss-2.2272, acc-0.3800, valid loss-2.2374, acc-0.2820, test loss-2.2384, acc-0.2808\n",
      "Iter-6130, train loss-2.2422, acc-0.2400, valid loss-2.2373, acc-0.2820, test loss-2.2382, acc-0.2814\n",
      "Iter-6140, train loss-2.2261, acc-0.3000, valid loss-2.2372, acc-0.2822, test loss-2.2381, acc-0.2817\n",
      "Iter-6150, train loss-2.2224, acc-0.3400, valid loss-2.2370, acc-0.2826, test loss-2.2380, acc-0.2822\n",
      "Iter-6160, train loss-2.2546, acc-0.2000, valid loss-2.2369, acc-0.2830, test loss-2.2379, acc-0.2825\n",
      "Iter-6170, train loss-2.2559, acc-0.1400, valid loss-2.2368, acc-0.2838, test loss-2.2377, acc-0.2826\n",
      "Iter-6180, train loss-2.2073, acc-0.4000, valid loss-2.2366, acc-0.2840, test loss-2.2376, acc-0.2832\n",
      "Iter-6190, train loss-2.2434, acc-0.3200, valid loss-2.2365, acc-0.2838, test loss-2.2375, acc-0.2836\n",
      "Iter-6200, train loss-2.2207, acc-0.2600, valid loss-2.2364, acc-0.2842, test loss-2.2373, acc-0.2842\n",
      "Iter-6210, train loss-2.2306, acc-0.3400, valid loss-2.2363, acc-0.2840, test loss-2.2372, acc-0.2843\n",
      "Iter-6220, train loss-2.2593, acc-0.1800, valid loss-2.2362, acc-0.2840, test loss-2.2371, acc-0.2845\n",
      "Iter-6230, train loss-2.2429, acc-0.2000, valid loss-2.2360, acc-0.2844, test loss-2.2370, acc-0.2849\n",
      "Iter-6240, train loss-2.2391, acc-0.3400, valid loss-2.2359, acc-0.2844, test loss-2.2369, acc-0.2853\n",
      "Iter-6250, train loss-2.2306, acc-0.3400, valid loss-2.2358, acc-0.2854, test loss-2.2367, acc-0.2855\n",
      "Iter-6260, train loss-2.2386, acc-0.2200, valid loss-2.2357, acc-0.2858, test loss-2.2366, acc-0.2858\n",
      "Iter-6270, train loss-2.2390, acc-0.3600, valid loss-2.2355, acc-0.2858, test loss-2.2365, acc-0.2869\n",
      "Iter-6280, train loss-2.2436, acc-0.2600, valid loss-2.2354, acc-0.2860, test loss-2.2364, acc-0.2872\n",
      "Iter-6290, train loss-2.2480, acc-0.2000, valid loss-2.2353, acc-0.2862, test loss-2.2362, acc-0.2876\n",
      "Iter-6300, train loss-2.2382, acc-0.3200, valid loss-2.2352, acc-0.2864, test loss-2.2361, acc-0.2877\n",
      "Iter-6310, train loss-2.2598, acc-0.2600, valid loss-2.2350, acc-0.2868, test loss-2.2360, acc-0.2879\n",
      "Iter-6320, train loss-2.2356, acc-0.2400, valid loss-2.2349, acc-0.2872, test loss-2.2359, acc-0.2881\n",
      "Iter-6330, train loss-2.2355, acc-0.2600, valid loss-2.2348, acc-0.2878, test loss-2.2357, acc-0.2885\n",
      "Iter-6340, train loss-2.2327, acc-0.3600, valid loss-2.2347, acc-0.2880, test loss-2.2356, acc-0.2887\n",
      "Iter-6350, train loss-2.2440, acc-0.2400, valid loss-2.2346, acc-0.2882, test loss-2.2355, acc-0.2891\n",
      "Iter-6360, train loss-2.2264, acc-0.3200, valid loss-2.2344, acc-0.2880, test loss-2.2353, acc-0.2891\n",
      "Iter-6370, train loss-2.2355, acc-0.2800, valid loss-2.2343, acc-0.2886, test loss-2.2352, acc-0.2894\n",
      "Iter-6380, train loss-2.2665, acc-0.1400, valid loss-2.2342, acc-0.2886, test loss-2.2351, acc-0.2898\n",
      "Iter-6390, train loss-2.2091, acc-0.4400, valid loss-2.2340, acc-0.2888, test loss-2.2350, acc-0.2902\n",
      "Iter-6400, train loss-2.2360, acc-0.1800, valid loss-2.2339, acc-0.2892, test loss-2.2348, acc-0.2905\n",
      "Iter-6410, train loss-2.2324, acc-0.2800, valid loss-2.2338, acc-0.2892, test loss-2.2347, acc-0.2904\n",
      "Iter-6420, train loss-2.2125, acc-0.3200, valid loss-2.2337, acc-0.2902, test loss-2.2346, acc-0.2911\n",
      "Iter-6430, train loss-2.2210, acc-0.2800, valid loss-2.2336, acc-0.2906, test loss-2.2345, acc-0.2906\n",
      "Iter-6440, train loss-2.2141, acc-0.3600, valid loss-2.2334, acc-0.2906, test loss-2.2344, acc-0.2913\n",
      "Iter-6450, train loss-2.2313, acc-0.2600, valid loss-2.2333, acc-0.2914, test loss-2.2342, acc-0.2912\n",
      "Iter-6460, train loss-2.2065, acc-0.4000, valid loss-2.2332, acc-0.2912, test loss-2.2341, acc-0.2917\n",
      "Iter-6470, train loss-2.2530, acc-0.2000, valid loss-2.2331, acc-0.2914, test loss-2.2340, acc-0.2921\n",
      "Iter-6480, train loss-2.2199, acc-0.2600, valid loss-2.2329, acc-0.2920, test loss-2.2339, acc-0.2928\n",
      "Iter-6490, train loss-2.2140, acc-0.4000, valid loss-2.2328, acc-0.2930, test loss-2.2337, acc-0.2930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-6500, train loss-2.2002, acc-0.3000, valid loss-2.2327, acc-0.2930, test loss-2.2336, acc-0.2934\n",
      "Iter-6510, train loss-2.2405, acc-0.2400, valid loss-2.2326, acc-0.2928, test loss-2.2335, acc-0.2932\n",
      "Iter-6520, train loss-2.2507, acc-0.2600, valid loss-2.2324, acc-0.2934, test loss-2.2334, acc-0.2936\n",
      "Iter-6530, train loss-2.2163, acc-0.4200, valid loss-2.2323, acc-0.2942, test loss-2.2332, acc-0.2941\n",
      "Iter-6540, train loss-2.2208, acc-0.3000, valid loss-2.2322, acc-0.2942, test loss-2.2331, acc-0.2941\n",
      "Iter-6550, train loss-2.2425, acc-0.2800, valid loss-2.2321, acc-0.2944, test loss-2.2330, acc-0.2945\n",
      "Iter-6560, train loss-2.2458, acc-0.2600, valid loss-2.2319, acc-0.2952, test loss-2.2329, acc-0.2948\n",
      "Iter-6570, train loss-2.2425, acc-0.2200, valid loss-2.2318, acc-0.2954, test loss-2.2327, acc-0.2951\n",
      "Iter-6580, train loss-2.2550, acc-0.2400, valid loss-2.2317, acc-0.2956, test loss-2.2326, acc-0.2956\n",
      "Iter-6590, train loss-2.2406, acc-0.2600, valid loss-2.2316, acc-0.2964, test loss-2.2325, acc-0.2956\n",
      "Iter-6600, train loss-2.2367, acc-0.3000, valid loss-2.2314, acc-0.2968, test loss-2.2324, acc-0.2960\n",
      "Iter-6610, train loss-2.2493, acc-0.2600, valid loss-2.2313, acc-0.2970, test loss-2.2323, acc-0.2961\n",
      "Iter-6620, train loss-2.2080, acc-0.4000, valid loss-2.2312, acc-0.2974, test loss-2.2321, acc-0.2963\n",
      "Iter-6630, train loss-2.2539, acc-0.2800, valid loss-2.2311, acc-0.2978, test loss-2.2320, acc-0.2964\n",
      "Iter-6640, train loss-2.2174, acc-0.3600, valid loss-2.2310, acc-0.2978, test loss-2.2319, acc-0.2964\n",
      "Iter-6650, train loss-2.2408, acc-0.2600, valid loss-2.2308, acc-0.2978, test loss-2.2318, acc-0.2968\n",
      "Iter-6660, train loss-2.2238, acc-0.3000, valid loss-2.2307, acc-0.2980, test loss-2.2316, acc-0.2970\n",
      "Iter-6670, train loss-2.2507, acc-0.2600, valid loss-2.2306, acc-0.2982, test loss-2.2315, acc-0.2970\n",
      "Iter-6680, train loss-2.2157, acc-0.3200, valid loss-2.2305, acc-0.2986, test loss-2.2314, acc-0.2974\n",
      "Iter-6690, train loss-2.2493, acc-0.2400, valid loss-2.2303, acc-0.2986, test loss-2.2313, acc-0.2977\n",
      "Iter-6700, train loss-2.2293, acc-0.2800, valid loss-2.2302, acc-0.2990, test loss-2.2311, acc-0.2980\n",
      "Iter-6710, train loss-2.2348, acc-0.3600, valid loss-2.2301, acc-0.2992, test loss-2.2310, acc-0.2982\n",
      "Iter-6720, train loss-2.2329, acc-0.3000, valid loss-2.2300, acc-0.3004, test loss-2.2309, acc-0.2978\n",
      "Iter-6730, train loss-2.2435, acc-0.2200, valid loss-2.2298, acc-0.3008, test loss-2.2308, acc-0.2981\n",
      "Iter-6740, train loss-2.2251, acc-0.3000, valid loss-2.2297, acc-0.3008, test loss-2.2306, acc-0.2987\n",
      "Iter-6750, train loss-2.2247, acc-0.3600, valid loss-2.2296, acc-0.3014, test loss-2.2305, acc-0.2986\n",
      "Iter-6760, train loss-2.2159, acc-0.3000, valid loss-2.2294, acc-0.3014, test loss-2.2304, acc-0.2987\n",
      "Iter-6770, train loss-2.2268, acc-0.2800, valid loss-2.2293, acc-0.3018, test loss-2.2303, acc-0.2988\n",
      "Iter-6780, train loss-2.2244, acc-0.3800, valid loss-2.2292, acc-0.3018, test loss-2.2301, acc-0.2994\n",
      "Iter-6790, train loss-2.2330, acc-0.2400, valid loss-2.2291, acc-0.3030, test loss-2.2300, acc-0.2995\n",
      "Iter-6800, train loss-2.2479, acc-0.2600, valid loss-2.2290, acc-0.3024, test loss-2.2299, acc-0.2998\n",
      "Iter-6810, train loss-2.2528, acc-0.2400, valid loss-2.2288, acc-0.3032, test loss-2.2298, acc-0.3004\n",
      "Iter-6820, train loss-2.2288, acc-0.3400, valid loss-2.2287, acc-0.3036, test loss-2.2297, acc-0.3007\n",
      "Iter-6830, train loss-2.2321, acc-0.1800, valid loss-2.2286, acc-0.3034, test loss-2.2295, acc-0.3007\n",
      "Iter-6840, train loss-2.2229, acc-0.3600, valid loss-2.2285, acc-0.3040, test loss-2.2294, acc-0.3010\n",
      "Iter-6850, train loss-2.2204, acc-0.3200, valid loss-2.2283, acc-0.3050, test loss-2.2293, acc-0.3015\n",
      "Iter-6860, train loss-2.2262, acc-0.2600, valid loss-2.2282, acc-0.3046, test loss-2.2291, acc-0.3018\n",
      "Iter-6870, train loss-2.2393, acc-0.2400, valid loss-2.2281, acc-0.3046, test loss-2.2290, acc-0.3022\n",
      "Iter-6880, train loss-2.2451, acc-0.2200, valid loss-2.2279, acc-0.3046, test loss-2.2289, acc-0.3025\n",
      "Iter-6890, train loss-2.2208, acc-0.3400, valid loss-2.2278, acc-0.3046, test loss-2.2288, acc-0.3028\n",
      "Iter-6900, train loss-2.2371, acc-0.2800, valid loss-2.2277, acc-0.3048, test loss-2.2287, acc-0.3030\n",
      "Iter-6910, train loss-2.2287, acc-0.3400, valid loss-2.2276, acc-0.3050, test loss-2.2285, acc-0.3033\n",
      "Iter-6920, train loss-2.2218, acc-0.3400, valid loss-2.2275, acc-0.3052, test loss-2.2284, acc-0.3032\n",
      "Iter-6930, train loss-2.2298, acc-0.2600, valid loss-2.2273, acc-0.3056, test loss-2.2283, acc-0.3036\n",
      "Iter-6940, train loss-2.2126, acc-0.4200, valid loss-2.2272, acc-0.3056, test loss-2.2281, acc-0.3035\n",
      "Iter-6950, train loss-2.2299, acc-0.2800, valid loss-2.2271, acc-0.3060, test loss-2.2280, acc-0.3039\n",
      "Iter-6960, train loss-2.2171, acc-0.3800, valid loss-2.2270, acc-0.3062, test loss-2.2279, acc-0.3041\n",
      "Iter-6970, train loss-2.2295, acc-0.2600, valid loss-2.2268, acc-0.3064, test loss-2.2278, acc-0.3042\n",
      "Iter-6980, train loss-2.2383, acc-0.3400, valid loss-2.2267, acc-0.3066, test loss-2.2276, acc-0.3045\n",
      "Iter-6990, train loss-2.2385, acc-0.2600, valid loss-2.2266, acc-0.3068, test loss-2.2275, acc-0.3048\n",
      "Iter-7000, train loss-2.2316, acc-0.3600, valid loss-2.2265, acc-0.3072, test loss-2.2274, acc-0.3055\n",
      "Iter-7010, train loss-2.2366, acc-0.2800, valid loss-2.2263, acc-0.3070, test loss-2.2273, acc-0.3059\n",
      "Iter-7020, train loss-2.2060, acc-0.3400, valid loss-2.2262, acc-0.3078, test loss-2.2271, acc-0.3068\n",
      "Iter-7030, train loss-2.2189, acc-0.4000, valid loss-2.2261, acc-0.3082, test loss-2.2270, acc-0.3069\n",
      "Iter-7040, train loss-2.2275, acc-0.3000, valid loss-2.2259, acc-0.3082, test loss-2.2269, acc-0.3073\n",
      "Iter-7050, train loss-2.2577, acc-0.2600, valid loss-2.2258, acc-0.3080, test loss-2.2268, acc-0.3076\n",
      "Iter-7060, train loss-2.2329, acc-0.2400, valid loss-2.2257, acc-0.3084, test loss-2.2266, acc-0.3081\n",
      "Iter-7070, train loss-2.2261, acc-0.2600, valid loss-2.2256, acc-0.3086, test loss-2.2265, acc-0.3081\n",
      "Iter-7080, train loss-2.2027, acc-0.4000, valid loss-2.2255, acc-0.3090, test loss-2.2264, acc-0.3082\n",
      "Iter-7090, train loss-2.2384, acc-0.2800, valid loss-2.2253, acc-0.3094, test loss-2.2263, acc-0.3086\n",
      "Iter-7100, train loss-2.2637, acc-0.1400, valid loss-2.2252, acc-0.3096, test loss-2.2261, acc-0.3088\n",
      "Iter-7110, train loss-2.2099, acc-0.3200, valid loss-2.2251, acc-0.3096, test loss-2.2260, acc-0.3089\n",
      "Iter-7120, train loss-2.2321, acc-0.2800, valid loss-2.2250, acc-0.3098, test loss-2.2259, acc-0.3094\n",
      "Iter-7130, train loss-2.2282, acc-0.3000, valid loss-2.2249, acc-0.3096, test loss-2.2258, acc-0.3092\n",
      "Iter-7140, train loss-2.2353, acc-0.2800, valid loss-2.2247, acc-0.3104, test loss-2.2257, acc-0.3094\n",
      "Iter-7150, train loss-2.2284, acc-0.3600, valid loss-2.2246, acc-0.3106, test loss-2.2255, acc-0.3096\n",
      "Iter-7160, train loss-2.2174, acc-0.4200, valid loss-2.2245, acc-0.3110, test loss-2.2254, acc-0.3098\n",
      "Iter-7170, train loss-2.2153, acc-0.3800, valid loss-2.2244, acc-0.3112, test loss-2.2253, acc-0.3104\n",
      "Iter-7180, train loss-2.2430, acc-0.1600, valid loss-2.2242, acc-0.3112, test loss-2.2252, acc-0.3107\n",
      "Iter-7190, train loss-2.2435, acc-0.2600, valid loss-2.2241, acc-0.3114, test loss-2.2250, acc-0.3111\n",
      "Iter-7200, train loss-2.2096, acc-0.3600, valid loss-2.2240, acc-0.3116, test loss-2.2249, acc-0.3117\n",
      "Iter-7210, train loss-2.2488, acc-0.3000, valid loss-2.2239, acc-0.3118, test loss-2.2248, acc-0.3118\n",
      "Iter-7220, train loss-2.2657, acc-0.2200, valid loss-2.2238, acc-0.3120, test loss-2.2247, acc-0.3120\n",
      "Iter-7230, train loss-2.2061, acc-0.2400, valid loss-2.2236, acc-0.3122, test loss-2.2246, acc-0.3126\n",
      "Iter-7240, train loss-2.2566, acc-0.2200, valid loss-2.2235, acc-0.3122, test loss-2.2244, acc-0.3123\n",
      "Iter-7250, train loss-2.2226, acc-0.2800, valid loss-2.2234, acc-0.3122, test loss-2.2243, acc-0.3123\n",
      "Iter-7260, train loss-2.2236, acc-0.2800, valid loss-2.2233, acc-0.3126, test loss-2.2242, acc-0.3128\n",
      "Iter-7270, train loss-2.2155, acc-0.3400, valid loss-2.2231, acc-0.3134, test loss-2.2241, acc-0.3134\n",
      "Iter-7280, train loss-2.1995, acc-0.3600, valid loss-2.2230, acc-0.3140, test loss-2.2239, acc-0.3137\n",
      "Iter-7290, train loss-2.2205, acc-0.3000, valid loss-2.2229, acc-0.3140, test loss-2.2238, acc-0.3135\n",
      "Iter-7300, train loss-2.2002, acc-0.3400, valid loss-2.2228, acc-0.3144, test loss-2.2237, acc-0.3143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-7310, train loss-2.2216, acc-0.4000, valid loss-2.2227, acc-0.3146, test loss-2.2236, acc-0.3144\n",
      "Iter-7320, train loss-2.2427, acc-0.2600, valid loss-2.2225, acc-0.3154, test loss-2.2235, acc-0.3148\n",
      "Iter-7330, train loss-2.1985, acc-0.4000, valid loss-2.2224, acc-0.3158, test loss-2.2233, acc-0.3145\n",
      "Iter-7340, train loss-2.2038, acc-0.3200, valid loss-2.2223, acc-0.3162, test loss-2.2232, acc-0.3146\n",
      "Iter-7350, train loss-2.2346, acc-0.3200, valid loss-2.2222, acc-0.3166, test loss-2.2231, acc-0.3149\n",
      "Iter-7360, train loss-2.2160, acc-0.3000, valid loss-2.2220, acc-0.3168, test loss-2.2230, acc-0.3153\n",
      "Iter-7370, train loss-2.1969, acc-0.4000, valid loss-2.2219, acc-0.3168, test loss-2.2228, acc-0.3153\n",
      "Iter-7380, train loss-2.1931, acc-0.3200, valid loss-2.2218, acc-0.3176, test loss-2.2227, acc-0.3157\n",
      "Iter-7390, train loss-2.2455, acc-0.2800, valid loss-2.2217, acc-0.3178, test loss-2.2226, acc-0.3158\n",
      "Iter-7400, train loss-2.1994, acc-0.5000, valid loss-2.2215, acc-0.3178, test loss-2.2225, acc-0.3158\n",
      "Iter-7410, train loss-2.2223, acc-0.3000, valid loss-2.2214, acc-0.3178, test loss-2.2224, acc-0.3162\n",
      "Iter-7420, train loss-2.2238, acc-0.3400, valid loss-2.2213, acc-0.3180, test loss-2.2222, acc-0.3165\n",
      "Iter-7430, train loss-2.2116, acc-0.3800, valid loss-2.2212, acc-0.3186, test loss-2.2221, acc-0.3164\n",
      "Iter-7440, train loss-2.2182, acc-0.3200, valid loss-2.2211, acc-0.3188, test loss-2.2220, acc-0.3165\n",
      "Iter-7450, train loss-2.2252, acc-0.3200, valid loss-2.2209, acc-0.3192, test loss-2.2219, acc-0.3170\n",
      "Iter-7460, train loss-2.2279, acc-0.3000, valid loss-2.2208, acc-0.3192, test loss-2.2218, acc-0.3168\n",
      "Iter-7470, train loss-2.2087, acc-0.2800, valid loss-2.2207, acc-0.3198, test loss-2.2216, acc-0.3175\n",
      "Iter-7480, train loss-2.2528, acc-0.3000, valid loss-2.2206, acc-0.3196, test loss-2.2215, acc-0.3174\n",
      "Iter-7490, train loss-2.2317, acc-0.2800, valid loss-2.2205, acc-0.3198, test loss-2.2214, acc-0.3172\n",
      "Iter-7500, train loss-2.2292, acc-0.3000, valid loss-2.2204, acc-0.3196, test loss-2.2213, acc-0.3178\n",
      "Iter-7510, train loss-2.2435, acc-0.2400, valid loss-2.2202, acc-0.3198, test loss-2.2212, acc-0.3178\n",
      "Iter-7520, train loss-2.2067, acc-0.4200, valid loss-2.2201, acc-0.3198, test loss-2.2211, acc-0.3179\n",
      "Iter-7530, train loss-2.1953, acc-0.3600, valid loss-2.2200, acc-0.3200, test loss-2.2209, acc-0.3181\n",
      "Iter-7540, train loss-2.2253, acc-0.3200, valid loss-2.2199, acc-0.3206, test loss-2.2208, acc-0.3184\n",
      "Iter-7550, train loss-2.2076, acc-0.4400, valid loss-2.2198, acc-0.3210, test loss-2.2207, acc-0.3187\n",
      "Iter-7560, train loss-2.2139, acc-0.3200, valid loss-2.2196, acc-0.3210, test loss-2.2206, acc-0.3187\n",
      "Iter-7570, train loss-2.2264, acc-0.3000, valid loss-2.2195, acc-0.3208, test loss-2.2205, acc-0.3189\n",
      "Iter-7580, train loss-2.2256, acc-0.3200, valid loss-2.2194, acc-0.3208, test loss-2.2203, acc-0.3193\n",
      "Iter-7590, train loss-2.2457, acc-0.3000, valid loss-2.2193, acc-0.3208, test loss-2.2202, acc-0.3193\n",
      "Iter-7600, train loss-2.1889, acc-0.3800, valid loss-2.2191, acc-0.3214, test loss-2.2201, acc-0.3197\n",
      "Iter-7610, train loss-2.2294, acc-0.2400, valid loss-2.2190, acc-0.3220, test loss-2.2200, acc-0.3199\n",
      "Iter-7620, train loss-2.2059, acc-0.4200, valid loss-2.2189, acc-0.3230, test loss-2.2198, acc-0.3200\n",
      "Iter-7630, train loss-2.2254, acc-0.3000, valid loss-2.2188, acc-0.3228, test loss-2.2197, acc-0.3203\n",
      "Iter-7640, train loss-2.2469, acc-0.2800, valid loss-2.2187, acc-0.3232, test loss-2.2196, acc-0.3205\n",
      "Iter-7650, train loss-2.2345, acc-0.2200, valid loss-2.2185, acc-0.3234, test loss-2.2195, acc-0.3204\n",
      "Iter-7660, train loss-2.1801, acc-0.4400, valid loss-2.2184, acc-0.3234, test loss-2.2194, acc-0.3210\n",
      "Iter-7670, train loss-2.2399, acc-0.3200, valid loss-2.2183, acc-0.3238, test loss-2.2192, acc-0.3208\n",
      "Iter-7680, train loss-2.2308, acc-0.2600, valid loss-2.2182, acc-0.3232, test loss-2.2191, acc-0.3211\n",
      "Iter-7690, train loss-2.1783, acc-0.4200, valid loss-2.2181, acc-0.3244, test loss-2.2190, acc-0.3212\n",
      "Iter-7700, train loss-2.2761, acc-0.1200, valid loss-2.2179, acc-0.3244, test loss-2.2189, acc-0.3213\n",
      "Iter-7710, train loss-2.2092, acc-0.3600, valid loss-2.2178, acc-0.3244, test loss-2.2188, acc-0.3219\n",
      "Iter-7720, train loss-2.2211, acc-0.3200, valid loss-2.2177, acc-0.3248, test loss-2.2187, acc-0.3220\n",
      "Iter-7730, train loss-2.2231, acc-0.3000, valid loss-2.2176, acc-0.3248, test loss-2.2185, acc-0.3224\n",
      "Iter-7740, train loss-2.2288, acc-0.2400, valid loss-2.2175, acc-0.3250, test loss-2.2184, acc-0.3226\n",
      "Iter-7750, train loss-2.2224, acc-0.3000, valid loss-2.2173, acc-0.3250, test loss-2.2183, acc-0.3227\n",
      "Iter-7760, train loss-2.2113, acc-0.2600, valid loss-2.2172, acc-0.3250, test loss-2.2182, acc-0.3230\n",
      "Iter-7770, train loss-2.2202, acc-0.3600, valid loss-2.2171, acc-0.3250, test loss-2.2180, acc-0.3233\n",
      "Iter-7780, train loss-2.2290, acc-0.2400, valid loss-2.2170, acc-0.3252, test loss-2.2179, acc-0.3238\n",
      "Iter-7790, train loss-2.2162, acc-0.3600, valid loss-2.2168, acc-0.3254, test loss-2.2178, acc-0.3243\n",
      "Iter-7800, train loss-2.2088, acc-0.3000, valid loss-2.2167, acc-0.3260, test loss-2.2177, acc-0.3247\n",
      "Iter-7810, train loss-2.2335, acc-0.2600, valid loss-2.2166, acc-0.3262, test loss-2.2175, acc-0.3248\n",
      "Iter-7820, train loss-2.2240, acc-0.2400, valid loss-2.2165, acc-0.3264, test loss-2.2174, acc-0.3245\n",
      "Iter-7830, train loss-2.2174, acc-0.2800, valid loss-2.2163, acc-0.3266, test loss-2.2173, acc-0.3246\n",
      "Iter-7840, train loss-2.2079, acc-0.3800, valid loss-2.2162, acc-0.3266, test loss-2.2172, acc-0.3252\n",
      "Iter-7850, train loss-2.2172, acc-0.3200, valid loss-2.2161, acc-0.3270, test loss-2.2170, acc-0.3253\n",
      "Iter-7860, train loss-2.2046, acc-0.3600, valid loss-2.2160, acc-0.3268, test loss-2.2169, acc-0.3254\n",
      "Iter-7870, train loss-2.2363, acc-0.3200, valid loss-2.2159, acc-0.3272, test loss-2.2168, acc-0.3258\n",
      "Iter-7880, train loss-2.2104, acc-0.4200, valid loss-2.2157, acc-0.3276, test loss-2.2167, acc-0.3261\n",
      "Iter-7890, train loss-2.2215, acc-0.3200, valid loss-2.2156, acc-0.3280, test loss-2.2166, acc-0.3264\n",
      "Iter-7900, train loss-2.1800, acc-0.4800, valid loss-2.2155, acc-0.3278, test loss-2.2164, acc-0.3262\n",
      "Iter-7910, train loss-2.2061, acc-0.3800, valid loss-2.2154, acc-0.3282, test loss-2.2163, acc-0.3266\n",
      "Iter-7920, train loss-2.2288, acc-0.2400, valid loss-2.2153, acc-0.3282, test loss-2.2162, acc-0.3266\n",
      "Iter-7930, train loss-2.2240, acc-0.3000, valid loss-2.2151, acc-0.3288, test loss-2.2161, acc-0.3268\n",
      "Iter-7940, train loss-2.2381, acc-0.3000, valid loss-2.2150, acc-0.3290, test loss-2.2160, acc-0.3270\n",
      "Iter-7950, train loss-2.2128, acc-0.3800, valid loss-2.2149, acc-0.3296, test loss-2.2158, acc-0.3270\n",
      "Iter-7960, train loss-2.1901, acc-0.3200, valid loss-2.2148, acc-0.3296, test loss-2.2157, acc-0.3272\n",
      "Iter-7970, train loss-2.2462, acc-0.2800, valid loss-2.2147, acc-0.3300, test loss-2.2156, acc-0.3273\n",
      "Iter-7980, train loss-2.1828, acc-0.4200, valid loss-2.2146, acc-0.3304, test loss-2.2155, acc-0.3279\n",
      "Iter-7990, train loss-2.1808, acc-0.4600, valid loss-2.2144, acc-0.3308, test loss-2.2154, acc-0.3283\n",
      "Iter-8000, train loss-2.2045, acc-0.3400, valid loss-2.2143, acc-0.3312, test loss-2.2153, acc-0.3286\n",
      "Iter-8010, train loss-2.1984, acc-0.3400, valid loss-2.2142, acc-0.3320, test loss-2.2151, acc-0.3286\n",
      "Iter-8020, train loss-2.1933, acc-0.4000, valid loss-2.2141, acc-0.3322, test loss-2.2150, acc-0.3286\n",
      "Iter-8030, train loss-2.2242, acc-0.2400, valid loss-2.2140, acc-0.3330, test loss-2.2149, acc-0.3286\n",
      "Iter-8040, train loss-2.2330, acc-0.2600, valid loss-2.2138, acc-0.3330, test loss-2.2148, acc-0.3292\n",
      "Iter-8050, train loss-2.2057, acc-0.3200, valid loss-2.2137, acc-0.3326, test loss-2.2147, acc-0.3291\n",
      "Iter-8060, train loss-2.2013, acc-0.3400, valid loss-2.2136, acc-0.3328, test loss-2.2145, acc-0.3295\n",
      "Iter-8070, train loss-2.2317, acc-0.2600, valid loss-2.2135, acc-0.3326, test loss-2.2144, acc-0.3297\n",
      "Iter-8080, train loss-2.2303, acc-0.3400, valid loss-2.2134, acc-0.3330, test loss-2.2143, acc-0.3297\n",
      "Iter-8090, train loss-2.2031, acc-0.3800, valid loss-2.2133, acc-0.3334, test loss-2.2142, acc-0.3303\n",
      "Iter-8100, train loss-2.2264, acc-0.3400, valid loss-2.2131, acc-0.3338, test loss-2.2141, acc-0.3303\n",
      "Iter-8110, train loss-2.2024, acc-0.3800, valid loss-2.2130, acc-0.3340, test loss-2.2139, acc-0.3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8120, train loss-2.2278, acc-0.2800, valid loss-2.2129, acc-0.3340, test loss-2.2138, acc-0.3308\n",
      "Iter-8130, train loss-2.2391, acc-0.2600, valid loss-2.2128, acc-0.3342, test loss-2.2137, acc-0.3308\n",
      "Iter-8140, train loss-2.2135, acc-0.3200, valid loss-2.2126, acc-0.3352, test loss-2.2136, acc-0.3311\n",
      "Iter-8150, train loss-2.1765, acc-0.5200, valid loss-2.2125, acc-0.3352, test loss-2.2135, acc-0.3310\n",
      "Iter-8160, train loss-2.2272, acc-0.2000, valid loss-2.2124, acc-0.3354, test loss-2.2134, acc-0.3313\n",
      "Iter-8170, train loss-2.2061, acc-0.3000, valid loss-2.2123, acc-0.3356, test loss-2.2132, acc-0.3317\n",
      "Iter-8180, train loss-2.2157, acc-0.3000, valid loss-2.2122, acc-0.3356, test loss-2.2131, acc-0.3320\n",
      "Iter-8190, train loss-2.2364, acc-0.2800, valid loss-2.2121, acc-0.3358, test loss-2.2130, acc-0.3321\n",
      "Iter-8200, train loss-2.1748, acc-0.4600, valid loss-2.2119, acc-0.3362, test loss-2.2129, acc-0.3323\n",
      "Iter-8210, train loss-2.2327, acc-0.2800, valid loss-2.2118, acc-0.3364, test loss-2.2128, acc-0.3324\n",
      "Iter-8220, train loss-2.2374, acc-0.2600, valid loss-2.2117, acc-0.3364, test loss-2.2126, acc-0.3326\n",
      "Iter-8230, train loss-2.2092, acc-0.3000, valid loss-2.2116, acc-0.3364, test loss-2.2125, acc-0.3328\n",
      "Iter-8240, train loss-2.2048, acc-0.3800, valid loss-2.2115, acc-0.3366, test loss-2.2124, acc-0.3331\n",
      "Iter-8250, train loss-2.2171, acc-0.3000, valid loss-2.2113, acc-0.3372, test loss-2.2123, acc-0.3332\n",
      "Iter-8260, train loss-2.1962, acc-0.3400, valid loss-2.2112, acc-0.3372, test loss-2.2122, acc-0.3335\n",
      "Iter-8270, train loss-2.2151, acc-0.3000, valid loss-2.2111, acc-0.3372, test loss-2.2120, acc-0.3336\n",
      "Iter-8280, train loss-2.2350, acc-0.2400, valid loss-2.2110, acc-0.3376, test loss-2.2119, acc-0.3337\n",
      "Iter-8290, train loss-2.1861, acc-0.3800, valid loss-2.2108, acc-0.3378, test loss-2.2118, acc-0.3337\n",
      "Iter-8300, train loss-2.1976, acc-0.3400, valid loss-2.2107, acc-0.3378, test loss-2.2117, acc-0.3339\n",
      "Iter-8310, train loss-2.2344, acc-0.3000, valid loss-2.2106, acc-0.3386, test loss-2.2115, acc-0.3343\n",
      "Iter-8320, train loss-2.2409, acc-0.2000, valid loss-2.2105, acc-0.3390, test loss-2.2114, acc-0.3343\n",
      "Iter-8330, train loss-2.2062, acc-0.3200, valid loss-2.2104, acc-0.3392, test loss-2.2113, acc-0.3344\n",
      "Iter-8340, train loss-2.2008, acc-0.4200, valid loss-2.2102, acc-0.3390, test loss-2.2112, acc-0.3344\n",
      "Iter-8350, train loss-2.2259, acc-0.2800, valid loss-2.2101, acc-0.3396, test loss-2.2111, acc-0.3345\n",
      "Iter-8360, train loss-2.1852, acc-0.3200, valid loss-2.2100, acc-0.3396, test loss-2.2110, acc-0.3344\n",
      "Iter-8370, train loss-2.2062, acc-0.2600, valid loss-2.2099, acc-0.3400, test loss-2.2108, acc-0.3345\n",
      "Iter-8380, train loss-2.1934, acc-0.4200, valid loss-2.2098, acc-0.3402, test loss-2.2107, acc-0.3349\n",
      "Iter-8390, train loss-2.2284, acc-0.2800, valid loss-2.2097, acc-0.3404, test loss-2.2106, acc-0.3349\n",
      "Iter-8400, train loss-2.2234, acc-0.2800, valid loss-2.2095, acc-0.3408, test loss-2.2105, acc-0.3352\n",
      "Iter-8410, train loss-2.2433, acc-0.2200, valid loss-2.2094, acc-0.3406, test loss-2.2104, acc-0.3354\n",
      "Iter-8420, train loss-2.1997, acc-0.3200, valid loss-2.2093, acc-0.3412, test loss-2.2102, acc-0.3357\n",
      "Iter-8430, train loss-2.2228, acc-0.3000, valid loss-2.2092, acc-0.3412, test loss-2.2101, acc-0.3362\n",
      "Iter-8440, train loss-2.2333, acc-0.2800, valid loss-2.2091, acc-0.3410, test loss-2.2100, acc-0.3364\n",
      "Iter-8450, train loss-2.1711, acc-0.5000, valid loss-2.2090, acc-0.3412, test loss-2.2099, acc-0.3366\n",
      "Iter-8460, train loss-2.2190, acc-0.3600, valid loss-2.2088, acc-0.3412, test loss-2.2098, acc-0.3368\n",
      "Iter-8470, train loss-2.2151, acc-0.2600, valid loss-2.2087, acc-0.3414, test loss-2.2097, acc-0.3369\n",
      "Iter-8480, train loss-2.1899, acc-0.3600, valid loss-2.2086, acc-0.3420, test loss-2.2095, acc-0.3373\n",
      "Iter-8490, train loss-2.1895, acc-0.5600, valid loss-2.2085, acc-0.3422, test loss-2.2094, acc-0.3376\n",
      "Iter-8500, train loss-2.2237, acc-0.3400, valid loss-2.2084, acc-0.3422, test loss-2.2093, acc-0.3378\n",
      "Iter-8510, train loss-2.2219, acc-0.3800, valid loss-2.2082, acc-0.3426, test loss-2.2092, acc-0.3382\n",
      "Iter-8520, train loss-2.2239, acc-0.3000, valid loss-2.2081, acc-0.3422, test loss-2.2091, acc-0.3382\n",
      "Iter-8530, train loss-2.2001, acc-0.3200, valid loss-2.2080, acc-0.3426, test loss-2.2089, acc-0.3384\n",
      "Iter-8540, train loss-2.2074, acc-0.3600, valid loss-2.2079, acc-0.3430, test loss-2.2088, acc-0.3384\n",
      "Iter-8550, train loss-2.2094, acc-0.4000, valid loss-2.2078, acc-0.3430, test loss-2.2087, acc-0.3389\n",
      "Iter-8560, train loss-2.1669, acc-0.5000, valid loss-2.2077, acc-0.3438, test loss-2.2086, acc-0.3392\n",
      "Iter-8570, train loss-2.2136, acc-0.2400, valid loss-2.2075, acc-0.3442, test loss-2.2085, acc-0.3393\n",
      "Iter-8580, train loss-2.2428, acc-0.2800, valid loss-2.2074, acc-0.3442, test loss-2.2083, acc-0.3396\n",
      "Iter-8590, train loss-2.2117, acc-0.3000, valid loss-2.2073, acc-0.3438, test loss-2.2082, acc-0.3393\n",
      "Iter-8600, train loss-2.1677, acc-0.4800, valid loss-2.2072, acc-0.3442, test loss-2.2081, acc-0.3393\n",
      "Iter-8610, train loss-2.2087, acc-0.3600, valid loss-2.2071, acc-0.3442, test loss-2.2080, acc-0.3395\n",
      "Iter-8620, train loss-2.2003, acc-0.4200, valid loss-2.2069, acc-0.3442, test loss-2.2079, acc-0.3398\n",
      "Iter-8630, train loss-2.2231, acc-0.3000, valid loss-2.2068, acc-0.3444, test loss-2.2077, acc-0.3399\n",
      "Iter-8640, train loss-2.2200, acc-0.2600, valid loss-2.2067, acc-0.3450, test loss-2.2076, acc-0.3402\n",
      "Iter-8650, train loss-2.2087, acc-0.3800, valid loss-2.2066, acc-0.3448, test loss-2.2075, acc-0.3401\n",
      "Iter-8660, train loss-2.2157, acc-0.3400, valid loss-2.2065, acc-0.3452, test loss-2.2074, acc-0.3403\n",
      "Iter-8670, train loss-2.2117, acc-0.3000, valid loss-2.2063, acc-0.3454, test loss-2.2073, acc-0.3405\n",
      "Iter-8680, train loss-2.1975, acc-0.3200, valid loss-2.2062, acc-0.3456, test loss-2.2072, acc-0.3406\n",
      "Iter-8690, train loss-2.2236, acc-0.3600, valid loss-2.2061, acc-0.3458, test loss-2.2070, acc-0.3406\n",
      "Iter-8700, train loss-2.1851, acc-0.4200, valid loss-2.2060, acc-0.3460, test loss-2.2069, acc-0.3409\n",
      "Iter-8710, train loss-2.2354, acc-0.2800, valid loss-2.2059, acc-0.3460, test loss-2.2068, acc-0.3408\n",
      "Iter-8720, train loss-2.2416, acc-0.2200, valid loss-2.2058, acc-0.3458, test loss-2.2067, acc-0.3413\n",
      "Iter-8730, train loss-2.2232, acc-0.3400, valid loss-2.2056, acc-0.3460, test loss-2.2066, acc-0.3412\n",
      "Iter-8740, train loss-2.2268, acc-0.3000, valid loss-2.2055, acc-0.3460, test loss-2.2064, acc-0.3412\n",
      "Iter-8750, train loss-2.2022, acc-0.3200, valid loss-2.2054, acc-0.3466, test loss-2.2063, acc-0.3413\n",
      "Iter-8760, train loss-2.2045, acc-0.2800, valid loss-2.2053, acc-0.3464, test loss-2.2062, acc-0.3415\n",
      "Iter-8770, train loss-2.2189, acc-0.2200, valid loss-2.2052, acc-0.3464, test loss-2.2061, acc-0.3417\n",
      "Iter-8780, train loss-2.1945, acc-0.4000, valid loss-2.2051, acc-0.3462, test loss-2.2060, acc-0.3418\n",
      "Iter-8790, train loss-2.1994, acc-0.4200, valid loss-2.2049, acc-0.3464, test loss-2.2059, acc-0.3423\n",
      "Iter-8800, train loss-2.1918, acc-0.3800, valid loss-2.2048, acc-0.3464, test loss-2.2057, acc-0.3425\n",
      "Iter-8810, train loss-2.1562, acc-0.5000, valid loss-2.2047, acc-0.3462, test loss-2.2056, acc-0.3422\n",
      "Iter-8820, train loss-2.2116, acc-0.3600, valid loss-2.2046, acc-0.3460, test loss-2.2055, acc-0.3425\n",
      "Iter-8830, train loss-2.2167, acc-0.3200, valid loss-2.2045, acc-0.3462, test loss-2.2054, acc-0.3426\n",
      "Iter-8840, train loss-2.2041, acc-0.2800, valid loss-2.2044, acc-0.3462, test loss-2.2053, acc-0.3429\n",
      "Iter-8850, train loss-2.2010, acc-0.3600, valid loss-2.2042, acc-0.3462, test loss-2.2051, acc-0.3433\n",
      "Iter-8860, train loss-2.2174, acc-0.3800, valid loss-2.2041, acc-0.3466, test loss-2.2050, acc-0.3432\n",
      "Iter-8870, train loss-2.2197, acc-0.3400, valid loss-2.2040, acc-0.3470, test loss-2.2049, acc-0.3433\n",
      "Iter-8880, train loss-2.2194, acc-0.3000, valid loss-2.2039, acc-0.3472, test loss-2.2048, acc-0.3437\n",
      "Iter-8890, train loss-2.2157, acc-0.2800, valid loss-2.2038, acc-0.3470, test loss-2.2047, acc-0.3440\n",
      "Iter-8900, train loss-2.2168, acc-0.3400, valid loss-2.2036, acc-0.3470, test loss-2.2046, acc-0.3441\n",
      "Iter-8910, train loss-2.1869, acc-0.5200, valid loss-2.2035, acc-0.3474, test loss-2.2044, acc-0.3448\n",
      "Iter-8920, train loss-2.2143, acc-0.3800, valid loss-2.2034, acc-0.3478, test loss-2.2043, acc-0.3448\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-8930, train loss-2.1932, acc-0.3200, valid loss-2.2033, acc-0.3480, test loss-2.2042, acc-0.3446\n",
      "Iter-8940, train loss-2.2222, acc-0.3000, valid loss-2.2032, acc-0.3478, test loss-2.2041, acc-0.3446\n",
      "Iter-8950, train loss-2.2084, acc-0.3000, valid loss-2.2030, acc-0.3482, test loss-2.2040, acc-0.3449\n",
      "Iter-8960, train loss-2.2306, acc-0.3000, valid loss-2.2029, acc-0.3486, test loss-2.2038, acc-0.3448\n",
      "Iter-8970, train loss-2.1982, acc-0.3200, valid loss-2.2028, acc-0.3494, test loss-2.2037, acc-0.3448\n",
      "Iter-8980, train loss-2.2020, acc-0.3800, valid loss-2.2027, acc-0.3494, test loss-2.2036, acc-0.3449\n",
      "Iter-8990, train loss-2.2260, acc-0.3000, valid loss-2.2025, acc-0.3486, test loss-2.2035, acc-0.3452\n",
      "Iter-9000, train loss-2.2172, acc-0.3600, valid loss-2.2024, acc-0.3492, test loss-2.2033, acc-0.3451\n",
      "Iter-9010, train loss-2.2239, acc-0.3000, valid loss-2.2023, acc-0.3496, test loss-2.2032, acc-0.3452\n",
      "Iter-9020, train loss-2.2264, acc-0.3400, valid loss-2.2022, acc-0.3498, test loss-2.2031, acc-0.3454\n",
      "Iter-9030, train loss-2.1702, acc-0.4200, valid loss-2.2021, acc-0.3498, test loss-2.2030, acc-0.3457\n",
      "Iter-9040, train loss-2.2282, acc-0.2600, valid loss-2.2019, acc-0.3500, test loss-2.2029, acc-0.3460\n",
      "Iter-9050, train loss-2.2223, acc-0.2600, valid loss-2.2018, acc-0.3502, test loss-2.2027, acc-0.3461\n",
      "Iter-9060, train loss-2.1746, acc-0.4400, valid loss-2.2017, acc-0.3508, test loss-2.2026, acc-0.3463\n",
      "Iter-9070, train loss-2.2016, acc-0.3400, valid loss-2.2016, acc-0.3508, test loss-2.2025, acc-0.3463\n",
      "Iter-9080, train loss-2.2327, acc-0.2800, valid loss-2.2015, acc-0.3506, test loss-2.2024, acc-0.3466\n",
      "Iter-9090, train loss-2.1630, acc-0.4200, valid loss-2.2014, acc-0.3506, test loss-2.2023, acc-0.3467\n",
      "Iter-9100, train loss-2.1907, acc-0.3400, valid loss-2.2012, acc-0.3508, test loss-2.2022, acc-0.3469\n",
      "Iter-9110, train loss-2.1901, acc-0.3800, valid loss-2.2011, acc-0.3516, test loss-2.2020, acc-0.3477\n",
      "Iter-9120, train loss-2.1819, acc-0.4200, valid loss-2.2010, acc-0.3512, test loss-2.2019, acc-0.3477\n",
      "Iter-9130, train loss-2.1900, acc-0.4200, valid loss-2.2009, acc-0.3516, test loss-2.2018, acc-0.3477\n",
      "Iter-9140, train loss-2.2039, acc-0.2800, valid loss-2.2008, acc-0.3510, test loss-2.2017, acc-0.3476\n",
      "Iter-9150, train loss-2.1947, acc-0.3400, valid loss-2.2007, acc-0.3518, test loss-2.2016, acc-0.3477\n",
      "Iter-9160, train loss-2.2087, acc-0.3800, valid loss-2.2005, acc-0.3516, test loss-2.2015, acc-0.3478\n",
      "Iter-9170, train loss-2.2045, acc-0.3200, valid loss-2.2004, acc-0.3516, test loss-2.2013, acc-0.3477\n",
      "Iter-9180, train loss-2.1819, acc-0.4800, valid loss-2.2003, acc-0.3518, test loss-2.2012, acc-0.3475\n",
      "Iter-9190, train loss-2.1937, acc-0.3600, valid loss-2.2002, acc-0.3520, test loss-2.2011, acc-0.3473\n",
      "Iter-9200, train loss-2.1948, acc-0.3200, valid loss-2.2001, acc-0.3522, test loss-2.2010, acc-0.3478\n",
      "Iter-9210, train loss-2.2181, acc-0.3800, valid loss-2.1999, acc-0.3522, test loss-2.2009, acc-0.3482\n",
      "Iter-9220, train loss-2.2300, acc-0.2200, valid loss-2.1998, acc-0.3520, test loss-2.2007, acc-0.3481\n",
      "Iter-9230, train loss-2.2035, acc-0.3000, valid loss-2.1997, acc-0.3520, test loss-2.2006, acc-0.3487\n",
      "Iter-9240, train loss-2.1949, acc-0.2800, valid loss-2.1996, acc-0.3522, test loss-2.2005, acc-0.3488\n",
      "Iter-9250, train loss-2.2167, acc-0.3000, valid loss-2.1995, acc-0.3520, test loss-2.2004, acc-0.3487\n",
      "Iter-9260, train loss-2.2107, acc-0.3400, valid loss-2.1993, acc-0.3522, test loss-2.2003, acc-0.3488\n",
      "Iter-9270, train loss-2.1863, acc-0.4200, valid loss-2.1992, acc-0.3524, test loss-2.2001, acc-0.3491\n",
      "Iter-9280, train loss-2.1862, acc-0.4000, valid loss-2.1991, acc-0.3526, test loss-2.2000, acc-0.3492\n",
      "Iter-9290, train loss-2.1840, acc-0.3600, valid loss-2.1990, acc-0.3526, test loss-2.1999, acc-0.3492\n",
      "Iter-9300, train loss-2.2225, acc-0.4000, valid loss-2.1989, acc-0.3528, test loss-2.1998, acc-0.3493\n",
      "Iter-9310, train loss-2.1886, acc-0.4000, valid loss-2.1987, acc-0.3530, test loss-2.1997, acc-0.3492\n",
      "Iter-9320, train loss-2.2293, acc-0.2800, valid loss-2.1986, acc-0.3530, test loss-2.1995, acc-0.3494\n",
      "Iter-9330, train loss-2.1797, acc-0.4600, valid loss-2.1985, acc-0.3536, test loss-2.1994, acc-0.3496\n",
      "Iter-9340, train loss-2.1683, acc-0.4600, valid loss-2.1984, acc-0.3536, test loss-2.1993, acc-0.3498\n",
      "Iter-9350, train loss-2.1904, acc-0.4600, valid loss-2.1983, acc-0.3542, test loss-2.1992, acc-0.3500\n",
      "Iter-9360, train loss-2.1649, acc-0.5000, valid loss-2.1982, acc-0.3540, test loss-2.1991, acc-0.3503\n",
      "Iter-9370, train loss-2.1968, acc-0.3200, valid loss-2.1980, acc-0.3544, test loss-2.1989, acc-0.3503\n",
      "Iter-9380, train loss-2.2075, acc-0.3600, valid loss-2.1979, acc-0.3548, test loss-2.1988, acc-0.3505\n",
      "Iter-9390, train loss-2.1851, acc-0.3400, valid loss-2.1978, acc-0.3548, test loss-2.1987, acc-0.3507\n",
      "Iter-9400, train loss-2.1955, acc-0.3600, valid loss-2.1977, acc-0.3550, test loss-2.1986, acc-0.3505\n",
      "Iter-9410, train loss-2.2340, acc-0.2000, valid loss-2.1975, acc-0.3548, test loss-2.1985, acc-0.3506\n",
      "Iter-9420, train loss-2.1998, acc-0.4000, valid loss-2.1974, acc-0.3548, test loss-2.1983, acc-0.3508\n",
      "Iter-9430, train loss-2.1639, acc-0.4400, valid loss-2.1973, acc-0.3550, test loss-2.1982, acc-0.3510\n",
      "Iter-9440, train loss-2.1878, acc-0.4000, valid loss-2.1972, acc-0.3546, test loss-2.1981, acc-0.3510\n",
      "Iter-9450, train loss-2.2026, acc-0.2400, valid loss-2.1971, acc-0.3546, test loss-2.1980, acc-0.3510\n",
      "Iter-9460, train loss-2.2106, acc-0.3000, valid loss-2.1970, acc-0.3546, test loss-2.1979, acc-0.3508\n",
      "Iter-9470, train loss-2.1773, acc-0.3800, valid loss-2.1968, acc-0.3546, test loss-2.1977, acc-0.3510\n",
      "Iter-9480, train loss-2.2470, acc-0.2000, valid loss-2.1967, acc-0.3548, test loss-2.1976, acc-0.3512\n",
      "Iter-9490, train loss-2.1971, acc-0.3000, valid loss-2.1966, acc-0.3544, test loss-2.1975, acc-0.3512\n",
      "Iter-9500, train loss-2.2065, acc-0.3200, valid loss-2.1965, acc-0.3546, test loss-2.1974, acc-0.3515\n",
      "Iter-9510, train loss-2.1940, acc-0.3800, valid loss-2.1964, acc-0.3552, test loss-2.1973, acc-0.3519\n",
      "Iter-9520, train loss-2.1643, acc-0.4400, valid loss-2.1962, acc-0.3554, test loss-2.1971, acc-0.3521\n",
      "Iter-9530, train loss-2.1724, acc-0.3600, valid loss-2.1961, acc-0.3556, test loss-2.1970, acc-0.3520\n",
      "Iter-9540, train loss-2.1902, acc-0.3000, valid loss-2.1960, acc-0.3552, test loss-2.1969, acc-0.3527\n",
      "Iter-9550, train loss-2.2096, acc-0.3200, valid loss-2.1959, acc-0.3552, test loss-2.1968, acc-0.3524\n",
      "Iter-9560, train loss-2.2020, acc-0.2600, valid loss-2.1958, acc-0.3558, test loss-2.1967, acc-0.3530\n",
      "Iter-9570, train loss-2.1950, acc-0.4000, valid loss-2.1957, acc-0.3560, test loss-2.1965, acc-0.3529\n",
      "Iter-9580, train loss-2.1993, acc-0.3200, valid loss-2.1955, acc-0.3562, test loss-2.1964, acc-0.3529\n",
      "Iter-9590, train loss-2.2052, acc-0.3000, valid loss-2.1954, acc-0.3560, test loss-2.1963, acc-0.3533\n",
      "Iter-9600, train loss-2.2202, acc-0.2800, valid loss-2.1953, acc-0.3560, test loss-2.1962, acc-0.3529\n",
      "Iter-9610, train loss-2.1949, acc-0.4200, valid loss-2.1952, acc-0.3566, test loss-2.1961, acc-0.3533\n",
      "Iter-9620, train loss-2.1788, acc-0.4000, valid loss-2.1951, acc-0.3560, test loss-2.1959, acc-0.3535\n",
      "Iter-9630, train loss-2.2463, acc-0.1800, valid loss-2.1949, acc-0.3564, test loss-2.1958, acc-0.3531\n",
      "Iter-9640, train loss-2.2127, acc-0.2400, valid loss-2.1948, acc-0.3564, test loss-2.1957, acc-0.3534\n",
      "Iter-9650, train loss-2.2270, acc-0.2600, valid loss-2.1947, acc-0.3564, test loss-2.1956, acc-0.3537\n",
      "Iter-9660, train loss-2.1885, acc-0.4000, valid loss-2.1946, acc-0.3562, test loss-2.1955, acc-0.3536\n",
      "Iter-9670, train loss-2.1956, acc-0.3600, valid loss-2.1945, acc-0.3564, test loss-2.1954, acc-0.3540\n",
      "Iter-9680, train loss-2.2012, acc-0.3400, valid loss-2.1944, acc-0.3566, test loss-2.1953, acc-0.3541\n",
      "Iter-9690, train loss-2.2071, acc-0.3600, valid loss-2.1943, acc-0.3566, test loss-2.1951, acc-0.3538\n",
      "Iter-9700, train loss-2.1825, acc-0.3600, valid loss-2.1941, acc-0.3566, test loss-2.1950, acc-0.3537\n",
      "Iter-9710, train loss-2.2086, acc-0.2200, valid loss-2.1940, acc-0.3568, test loss-2.1949, acc-0.3540\n",
      "Iter-9720, train loss-2.1930, acc-0.3400, valid loss-2.1939, acc-0.3572, test loss-2.1948, acc-0.3543\n",
      "Iter-9730, train loss-2.1869, acc-0.3800, valid loss-2.1938, acc-0.3572, test loss-2.1947, acc-0.3545\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-9740, train loss-2.2040, acc-0.3800, valid loss-2.1937, acc-0.3578, test loss-2.1945, acc-0.3544\n",
      "Iter-9750, train loss-2.2096, acc-0.3000, valid loss-2.1935, acc-0.3576, test loss-2.1944, acc-0.3546\n",
      "Iter-9760, train loss-2.2235, acc-0.2400, valid loss-2.1934, acc-0.3580, test loss-2.1943, acc-0.3549\n",
      "Iter-9770, train loss-2.1967, acc-0.3000, valid loss-2.1933, acc-0.3586, test loss-2.1942, acc-0.3551\n",
      "Iter-9780, train loss-2.1863, acc-0.3800, valid loss-2.1932, acc-0.3582, test loss-2.1941, acc-0.3552\n",
      "Iter-9790, train loss-2.1417, acc-0.4600, valid loss-2.1931, acc-0.3582, test loss-2.1940, acc-0.3553\n",
      "Iter-9800, train loss-2.1942, acc-0.3200, valid loss-2.1930, acc-0.3584, test loss-2.1938, acc-0.3554\n",
      "Iter-9810, train loss-2.2157, acc-0.3000, valid loss-2.1928, acc-0.3582, test loss-2.1937, acc-0.3557\n",
      "Iter-9820, train loss-2.1677, acc-0.4200, valid loss-2.1927, acc-0.3578, test loss-2.1936, acc-0.3560\n",
      "Iter-9830, train loss-2.1983, acc-0.3400, valid loss-2.1926, acc-0.3568, test loss-2.1935, acc-0.3558\n",
      "Iter-9840, train loss-2.1971, acc-0.3400, valid loss-2.1925, acc-0.3580, test loss-2.1934, acc-0.3561\n",
      "Iter-9850, train loss-2.2237, acc-0.2200, valid loss-2.1923, acc-0.3582, test loss-2.1932, acc-0.3560\n",
      "Iter-9860, train loss-2.1718, acc-0.3600, valid loss-2.1922, acc-0.3580, test loss-2.1931, acc-0.3562\n",
      "Iter-9870, train loss-2.2057, acc-0.3000, valid loss-2.1921, acc-0.3582, test loss-2.1930, acc-0.3559\n",
      "Iter-9880, train loss-2.1950, acc-0.3600, valid loss-2.1920, acc-0.3584, test loss-2.1929, acc-0.3558\n",
      "Iter-9890, train loss-2.1992, acc-0.4000, valid loss-2.1919, acc-0.3586, test loss-2.1928, acc-0.3560\n",
      "Iter-9900, train loss-2.1839, acc-0.3600, valid loss-2.1918, acc-0.3586, test loss-2.1927, acc-0.3560\n",
      "Iter-9910, train loss-2.1946, acc-0.3800, valid loss-2.1916, acc-0.3590, test loss-2.1925, acc-0.3558\n",
      "Iter-9920, train loss-2.2021, acc-0.3400, valid loss-2.1915, acc-0.3590, test loss-2.1924, acc-0.3563\n",
      "Iter-9930, train loss-2.2099, acc-0.3200, valid loss-2.1914, acc-0.3590, test loss-2.1923, acc-0.3563\n",
      "Iter-9940, train loss-2.2125, acc-0.3000, valid loss-2.1913, acc-0.3596, test loss-2.1922, acc-0.3565\n",
      "Iter-9950, train loss-2.1968, acc-0.3000, valid loss-2.1912, acc-0.3598, test loss-2.1921, acc-0.3565\n",
      "Iter-9960, train loss-2.1744, acc-0.4000, valid loss-2.1911, acc-0.3598, test loss-2.1920, acc-0.3566\n",
      "Iter-9970, train loss-2.2108, acc-0.2800, valid loss-2.1910, acc-0.3602, test loss-2.1919, acc-0.3567\n",
      "Iter-9980, train loss-2.2140, acc-0.2200, valid loss-2.1908, acc-0.3606, test loss-2.1917, acc-0.3569\n",
      "Iter-9990, train loss-2.2012, acc-0.3200, valid loss-2.1907, acc-0.3608, test loss-2.1916, acc-0.3569\n",
      "Iter-10000, train loss-2.2054, acc-0.3600, valid loss-2.1906, acc-0.3606, test loss-2.1915, acc-0.3570\n",
      "Iter-10010, train loss-2.2006, acc-0.2800, valid loss-2.1905, acc-0.3608, test loss-2.1914, acc-0.3569\n",
      "Iter-10020, train loss-2.2229, acc-0.2400, valid loss-2.1904, acc-0.3606, test loss-2.1913, acc-0.3573\n",
      "Iter-10030, train loss-2.2034, acc-0.3800, valid loss-2.1902, acc-0.3604, test loss-2.1911, acc-0.3576\n",
      "Iter-10040, train loss-2.1966, acc-0.3000, valid loss-2.1901, acc-0.3608, test loss-2.1910, acc-0.3576\n",
      "Iter-10050, train loss-2.1669, acc-0.4800, valid loss-2.1900, acc-0.3602, test loss-2.1909, acc-0.3578\n",
      "Iter-10060, train loss-2.1594, acc-0.3600, valid loss-2.1899, acc-0.3608, test loss-2.1908, acc-0.3576\n",
      "Iter-10070, train loss-2.1654, acc-0.4200, valid loss-2.1898, acc-0.3614, test loss-2.1907, acc-0.3577\n",
      "Iter-10080, train loss-2.2133, acc-0.3400, valid loss-2.1897, acc-0.3606, test loss-2.1905, acc-0.3577\n",
      "Iter-10090, train loss-2.1765, acc-0.4000, valid loss-2.1895, acc-0.3610, test loss-2.1904, acc-0.3577\n",
      "Iter-10100, train loss-2.1718, acc-0.4000, valid loss-2.1894, acc-0.3608, test loss-2.1903, acc-0.3584\n",
      "Iter-10110, train loss-2.1930, acc-0.3200, valid loss-2.1893, acc-0.3610, test loss-2.1902, acc-0.3584\n",
      "Iter-10120, train loss-2.2053, acc-0.3800, valid loss-2.1892, acc-0.3606, test loss-2.1901, acc-0.3585\n",
      "Iter-10130, train loss-2.2121, acc-0.3000, valid loss-2.1891, acc-0.3604, test loss-2.1900, acc-0.3588\n",
      "Iter-10140, train loss-2.2150, acc-0.2600, valid loss-2.1890, acc-0.3608, test loss-2.1898, acc-0.3593\n",
      "Iter-10150, train loss-2.1754, acc-0.4000, valid loss-2.1888, acc-0.3614, test loss-2.1897, acc-0.3595\n",
      "Iter-10160, train loss-2.1902, acc-0.3000, valid loss-2.1887, acc-0.3610, test loss-2.1896, acc-0.3595\n",
      "Iter-10170, train loss-2.2135, acc-0.3200, valid loss-2.1886, acc-0.3610, test loss-2.1895, acc-0.3594\n",
      "Iter-10180, train loss-2.2077, acc-0.4000, valid loss-2.1885, acc-0.3614, test loss-2.1894, acc-0.3596\n",
      "Iter-10190, train loss-2.1889, acc-0.3600, valid loss-2.1884, acc-0.3612, test loss-2.1893, acc-0.3594\n",
      "Iter-10200, train loss-2.1895, acc-0.3600, valid loss-2.1883, acc-0.3614, test loss-2.1892, acc-0.3594\n",
      "Iter-10210, train loss-2.1717, acc-0.3800, valid loss-2.1881, acc-0.3612, test loss-2.1890, acc-0.3595\n",
      "Iter-10220, train loss-2.1745, acc-0.3400, valid loss-2.1880, acc-0.3610, test loss-2.1889, acc-0.3592\n",
      "Iter-10230, train loss-2.2041, acc-0.2400, valid loss-2.1879, acc-0.3614, test loss-2.1888, acc-0.3598\n",
      "Iter-10240, train loss-2.1759, acc-0.3400, valid loss-2.1878, acc-0.3616, test loss-2.1887, acc-0.3597\n",
      "Iter-10250, train loss-2.1553, acc-0.4200, valid loss-2.1877, acc-0.3614, test loss-2.1886, acc-0.3603\n",
      "Iter-10260, train loss-2.1906, acc-0.3600, valid loss-2.1876, acc-0.3616, test loss-2.1885, acc-0.3600\n",
      "Iter-10270, train loss-2.2084, acc-0.3000, valid loss-2.1875, acc-0.3616, test loss-2.1884, acc-0.3603\n",
      "Iter-10280, train loss-2.1994, acc-0.4000, valid loss-2.1873, acc-0.3620, test loss-2.1882, acc-0.3601\n",
      "Iter-10290, train loss-2.1955, acc-0.3400, valid loss-2.1872, acc-0.3618, test loss-2.1881, acc-0.3601\n",
      "Iter-10300, train loss-2.1774, acc-0.3600, valid loss-2.1871, acc-0.3622, test loss-2.1880, acc-0.3603\n",
      "Iter-10310, train loss-2.2021, acc-0.3000, valid loss-2.1870, acc-0.3620, test loss-2.1879, acc-0.3601\n",
      "Iter-10320, train loss-2.1637, acc-0.4400, valid loss-2.1869, acc-0.3616, test loss-2.1878, acc-0.3600\n",
      "Iter-10330, train loss-2.2186, acc-0.3000, valid loss-2.1868, acc-0.3620, test loss-2.1877, acc-0.3601\n",
      "Iter-10340, train loss-2.2049, acc-0.3400, valid loss-2.1866, acc-0.3616, test loss-2.1875, acc-0.3602\n",
      "Iter-10350, train loss-2.1975, acc-0.3000, valid loss-2.1865, acc-0.3620, test loss-2.1874, acc-0.3602\n",
      "Iter-10360, train loss-2.1775, acc-0.4400, valid loss-2.1864, acc-0.3622, test loss-2.1873, acc-0.3604\n",
      "Iter-10370, train loss-2.1840, acc-0.3800, valid loss-2.1863, acc-0.3626, test loss-2.1872, acc-0.3605\n",
      "Iter-10380, train loss-2.2086, acc-0.3000, valid loss-2.1862, acc-0.3630, test loss-2.1871, acc-0.3607\n",
      "Iter-10390, train loss-2.2247, acc-0.2600, valid loss-2.1860, acc-0.3630, test loss-2.1870, acc-0.3609\n",
      "Iter-10400, train loss-2.1801, acc-0.3200, valid loss-2.1859, acc-0.3634, test loss-2.1869, acc-0.3609\n",
      "Iter-10410, train loss-2.1932, acc-0.4200, valid loss-2.1858, acc-0.3634, test loss-2.1867, acc-0.3610\n",
      "Iter-10420, train loss-2.2039, acc-0.3400, valid loss-2.1857, acc-0.3638, test loss-2.1866, acc-0.3610\n",
      "Iter-10430, train loss-2.1748, acc-0.4400, valid loss-2.1856, acc-0.3636, test loss-2.1865, acc-0.3610\n",
      "Iter-10440, train loss-2.1983, acc-0.3600, valid loss-2.1855, acc-0.3638, test loss-2.1864, acc-0.3611\n",
      "Iter-10450, train loss-2.1957, acc-0.3000, valid loss-2.1854, acc-0.3636, test loss-2.1863, acc-0.3611\n",
      "Iter-10460, train loss-2.1703, acc-0.4800, valid loss-2.1852, acc-0.3638, test loss-2.1862, acc-0.3613\n",
      "Iter-10470, train loss-2.1668, acc-0.4400, valid loss-2.1851, acc-0.3646, test loss-2.1860, acc-0.3611\n",
      "Iter-10480, train loss-2.1777, acc-0.2800, valid loss-2.1850, acc-0.3648, test loss-2.1859, acc-0.3608\n",
      "Iter-10490, train loss-2.1923, acc-0.2600, valid loss-2.1849, acc-0.3648, test loss-2.1858, acc-0.3614\n",
      "Iter-10500, train loss-2.1955, acc-0.3400, valid loss-2.1848, acc-0.3650, test loss-2.1857, acc-0.3614\n",
      "Iter-10510, train loss-2.2097, acc-0.3000, valid loss-2.1847, acc-0.3648, test loss-2.1856, acc-0.3616\n",
      "Iter-10520, train loss-2.1842, acc-0.3800, valid loss-2.1845, acc-0.3650, test loss-2.1855, acc-0.3614\n",
      "Iter-10530, train loss-2.1686, acc-0.4200, valid loss-2.1844, acc-0.3650, test loss-2.1853, acc-0.3616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-10540, train loss-2.1539, acc-0.4400, valid loss-2.1843, acc-0.3652, test loss-2.1852, acc-0.3618\n",
      "Iter-10550, train loss-2.1786, acc-0.3400, valid loss-2.1842, acc-0.3650, test loss-2.1851, acc-0.3617\n",
      "Iter-10560, train loss-2.2167, acc-0.2600, valid loss-2.1841, acc-0.3646, test loss-2.1850, acc-0.3616\n",
      "Iter-10570, train loss-2.1847, acc-0.3400, valid loss-2.1839, acc-0.3650, test loss-2.1849, acc-0.3621\n",
      "Iter-10580, train loss-2.1894, acc-0.3400, valid loss-2.1838, acc-0.3646, test loss-2.1847, acc-0.3620\n",
      "Iter-10590, train loss-2.2092, acc-0.3000, valid loss-2.1837, acc-0.3650, test loss-2.1846, acc-0.3623\n",
      "Iter-10600, train loss-2.1453, acc-0.4000, valid loss-2.1836, acc-0.3648, test loss-2.1845, acc-0.3622\n",
      "Iter-10610, train loss-2.1708, acc-0.4400, valid loss-2.1835, acc-0.3650, test loss-2.1844, acc-0.3625\n",
      "Iter-10620, train loss-2.1884, acc-0.3400, valid loss-2.1834, acc-0.3656, test loss-2.1843, acc-0.3625\n",
      "Iter-10630, train loss-2.1809, acc-0.4000, valid loss-2.1832, acc-0.3658, test loss-2.1842, acc-0.3624\n",
      "Iter-10640, train loss-2.1637, acc-0.4600, valid loss-2.1831, acc-0.3656, test loss-2.1840, acc-0.3622\n",
      "Iter-10650, train loss-2.1796, acc-0.3800, valid loss-2.1830, acc-0.3660, test loss-2.1839, acc-0.3625\n",
      "Iter-10660, train loss-2.1937, acc-0.3600, valid loss-2.1829, acc-0.3660, test loss-2.1838, acc-0.3627\n",
      "Iter-10670, train loss-2.1713, acc-0.3600, valid loss-2.1828, acc-0.3662, test loss-2.1837, acc-0.3628\n",
      "Iter-10680, train loss-2.1921, acc-0.3000, valid loss-2.1827, acc-0.3662, test loss-2.1836, acc-0.3627\n",
      "Iter-10690, train loss-2.1886, acc-0.3800, valid loss-2.1825, acc-0.3662, test loss-2.1835, acc-0.3629\n",
      "Iter-10700, train loss-2.1616, acc-0.5000, valid loss-2.1824, acc-0.3668, test loss-2.1834, acc-0.3632\n",
      "Iter-10710, train loss-2.2314, acc-0.2400, valid loss-2.1823, acc-0.3668, test loss-2.1832, acc-0.3635\n",
      "Iter-10720, train loss-2.1406, acc-0.4800, valid loss-2.1822, acc-0.3664, test loss-2.1831, acc-0.3635\n",
      "Iter-10730, train loss-2.1844, acc-0.3400, valid loss-2.1821, acc-0.3660, test loss-2.1830, acc-0.3635\n",
      "Iter-10740, train loss-2.1732, acc-0.4200, valid loss-2.1820, acc-0.3658, test loss-2.1829, acc-0.3633\n",
      "Iter-10750, train loss-2.1606, acc-0.4400, valid loss-2.1819, acc-0.3654, test loss-2.1828, acc-0.3631\n",
      "Iter-10760, train loss-2.1837, acc-0.3400, valid loss-2.1817, acc-0.3656, test loss-2.1827, acc-0.3629\n",
      "Iter-10770, train loss-2.1483, acc-0.5000, valid loss-2.1816, acc-0.3660, test loss-2.1825, acc-0.3630\n",
      "Iter-10780, train loss-2.1886, acc-0.3600, valid loss-2.1815, acc-0.3658, test loss-2.1824, acc-0.3629\n",
      "Iter-10790, train loss-2.1849, acc-0.4200, valid loss-2.1814, acc-0.3664, test loss-2.1823, acc-0.3633\n",
      "Iter-10800, train loss-2.1831, acc-0.3400, valid loss-2.1813, acc-0.3670, test loss-2.1822, acc-0.3636\n",
      "Iter-10810, train loss-2.2025, acc-0.3400, valid loss-2.1812, acc-0.3670, test loss-2.1821, acc-0.3635\n",
      "Iter-10820, train loss-2.1653, acc-0.4000, valid loss-2.1811, acc-0.3666, test loss-2.1820, acc-0.3636\n",
      "Iter-10830, train loss-2.2003, acc-0.3000, valid loss-2.1810, acc-0.3662, test loss-2.1819, acc-0.3637\n",
      "Iter-10840, train loss-2.2038, acc-0.3200, valid loss-2.1809, acc-0.3666, test loss-2.1818, acc-0.3639\n",
      "Iter-10850, train loss-2.2104, acc-0.3000, valid loss-2.1808, acc-0.3668, test loss-2.1817, acc-0.3641\n",
      "Iter-10860, train loss-2.1816, acc-0.3400, valid loss-2.1806, acc-0.3668, test loss-2.1815, acc-0.3641\n",
      "Iter-10870, train loss-2.1637, acc-0.3200, valid loss-2.1805, acc-0.3668, test loss-2.1814, acc-0.3642\n",
      "Iter-10880, train loss-2.1840, acc-0.3800, valid loss-2.1804, acc-0.3664, test loss-2.1813, acc-0.3640\n",
      "Iter-10890, train loss-2.2007, acc-0.3400, valid loss-2.1803, acc-0.3670, test loss-2.1812, acc-0.3643\n",
      "Iter-10900, train loss-2.1855, acc-0.3400, valid loss-2.1802, acc-0.3668, test loss-2.1811, acc-0.3647\n",
      "Iter-10910, train loss-2.1680, acc-0.3800, valid loss-2.1801, acc-0.3664, test loss-2.1810, acc-0.3647\n",
      "Iter-10920, train loss-2.2052, acc-0.3600, valid loss-2.1800, acc-0.3668, test loss-2.1809, acc-0.3648\n",
      "Iter-10930, train loss-2.1612, acc-0.3800, valid loss-2.1798, acc-0.3674, test loss-2.1807, acc-0.3648\n",
      "Iter-10940, train loss-2.1644, acc-0.4000, valid loss-2.1797, acc-0.3672, test loss-2.1806, acc-0.3651\n",
      "Iter-10950, train loss-2.1698, acc-0.4600, valid loss-2.1796, acc-0.3674, test loss-2.1805, acc-0.3651\n",
      "Iter-10960, train loss-2.2246, acc-0.2400, valid loss-2.1795, acc-0.3672, test loss-2.1804, acc-0.3652\n",
      "Iter-10970, train loss-2.1761, acc-0.4200, valid loss-2.1794, acc-0.3678, test loss-2.1803, acc-0.3652\n",
      "Iter-10980, train loss-2.1930, acc-0.2600, valid loss-2.1793, acc-0.3676, test loss-2.1802, acc-0.3652\n",
      "Iter-10990, train loss-2.1953, acc-0.3400, valid loss-2.1792, acc-0.3678, test loss-2.1800, acc-0.3651\n",
      "Iter-11000, train loss-2.1741, acc-0.3400, valid loss-2.1790, acc-0.3678, test loss-2.1799, acc-0.3654\n",
      "Iter-11010, train loss-2.2081, acc-0.3400, valid loss-2.1789, acc-0.3680, test loss-2.1798, acc-0.3651\n",
      "Iter-11020, train loss-2.1774, acc-0.4200, valid loss-2.1788, acc-0.3680, test loss-2.1797, acc-0.3653\n",
      "Iter-11030, train loss-2.1656, acc-0.3800, valid loss-2.1787, acc-0.3672, test loss-2.1796, acc-0.3650\n",
      "Iter-11040, train loss-2.1716, acc-0.3600, valid loss-2.1786, acc-0.3674, test loss-2.1795, acc-0.3650\n",
      "Iter-11050, train loss-2.1596, acc-0.4200, valid loss-2.1785, acc-0.3672, test loss-2.1794, acc-0.3648\n",
      "Iter-11060, train loss-2.1304, acc-0.5200, valid loss-2.1784, acc-0.3674, test loss-2.1792, acc-0.3649\n",
      "Iter-11070, train loss-2.1951, acc-0.4200, valid loss-2.1782, acc-0.3674, test loss-2.1791, acc-0.3651\n",
      "Iter-11080, train loss-2.1793, acc-0.4200, valid loss-2.1781, acc-0.3674, test loss-2.1790, acc-0.3653\n",
      "Iter-11090, train loss-2.1459, acc-0.3800, valid loss-2.1780, acc-0.3674, test loss-2.1789, acc-0.3653\n",
      "Iter-11100, train loss-2.1928, acc-0.3200, valid loss-2.1779, acc-0.3674, test loss-2.1788, acc-0.3655\n",
      "Iter-11110, train loss-2.1759, acc-0.3800, valid loss-2.1778, acc-0.3676, test loss-2.1787, acc-0.3657\n",
      "Iter-11120, train loss-2.1807, acc-0.3400, valid loss-2.1777, acc-0.3676, test loss-2.1786, acc-0.3657\n",
      "Iter-11130, train loss-2.1854, acc-0.3200, valid loss-2.1776, acc-0.3678, test loss-2.1784, acc-0.3662\n",
      "Iter-11140, train loss-2.1822, acc-0.3400, valid loss-2.1774, acc-0.3678, test loss-2.1783, acc-0.3663\n",
      "Iter-11150, train loss-2.1825, acc-0.4000, valid loss-2.1773, acc-0.3678, test loss-2.1782, acc-0.3665\n",
      "Iter-11160, train loss-2.1632, acc-0.3800, valid loss-2.1772, acc-0.3676, test loss-2.1781, acc-0.3664\n",
      "Iter-11170, train loss-2.2076, acc-0.2600, valid loss-2.1771, acc-0.3676, test loss-2.1780, acc-0.3665\n",
      "Iter-11180, train loss-2.1887, acc-0.3400, valid loss-2.1770, acc-0.3678, test loss-2.1779, acc-0.3665\n",
      "Iter-11190, train loss-2.1838, acc-0.3600, valid loss-2.1769, acc-0.3676, test loss-2.1778, acc-0.3668\n",
      "Iter-11200, train loss-2.2106, acc-0.3000, valid loss-2.1768, acc-0.3678, test loss-2.1776, acc-0.3669\n",
      "Iter-11210, train loss-2.1700, acc-0.3400, valid loss-2.1767, acc-0.3678, test loss-2.1775, acc-0.3670\n",
      "Iter-11220, train loss-2.1663, acc-0.3600, valid loss-2.1765, acc-0.3678, test loss-2.1774, acc-0.3670\n",
      "Iter-11230, train loss-2.1896, acc-0.3000, valid loss-2.1764, acc-0.3678, test loss-2.1773, acc-0.3671\n",
      "Iter-11240, train loss-2.1557, acc-0.5000, valid loss-2.1763, acc-0.3678, test loss-2.1772, acc-0.3670\n",
      "Iter-11250, train loss-2.1735, acc-0.4000, valid loss-2.1762, acc-0.3678, test loss-2.1771, acc-0.3673\n",
      "Iter-11260, train loss-2.1790, acc-0.4000, valid loss-2.1761, acc-0.3676, test loss-2.1770, acc-0.3672\n",
      "Iter-11270, train loss-2.2086, acc-0.2400, valid loss-2.1760, acc-0.3682, test loss-2.1768, acc-0.3669\n",
      "Iter-11280, train loss-2.1855, acc-0.3800, valid loss-2.1759, acc-0.3680, test loss-2.1767, acc-0.3670\n",
      "Iter-11290, train loss-2.1792, acc-0.3200, valid loss-2.1757, acc-0.3682, test loss-2.1766, acc-0.3671\n",
      "Iter-11300, train loss-2.1806, acc-0.3600, valid loss-2.1756, acc-0.3682, test loss-2.1765, acc-0.3673\n",
      "Iter-11310, train loss-2.1764, acc-0.3400, valid loss-2.1755, acc-0.3688, test loss-2.1764, acc-0.3673\n",
      "Iter-11320, train loss-2.1864, acc-0.3400, valid loss-2.1754, acc-0.3686, test loss-2.1763, acc-0.3676\n",
      "Iter-11330, train loss-2.1698, acc-0.4000, valid loss-2.1753, acc-0.3686, test loss-2.1762, acc-0.3679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-11340, train loss-2.2087, acc-0.3000, valid loss-2.1752, acc-0.3688, test loss-2.1761, acc-0.3679\n",
      "Iter-11350, train loss-2.1872, acc-0.3200, valid loss-2.1751, acc-0.3688, test loss-2.1760, acc-0.3676\n",
      "Iter-11360, train loss-2.1654, acc-0.3200, valid loss-2.1750, acc-0.3692, test loss-2.1758, acc-0.3678\n",
      "Iter-11370, train loss-2.1674, acc-0.3600, valid loss-2.1748, acc-0.3686, test loss-2.1757, acc-0.3677\n",
      "Iter-11380, train loss-2.1914, acc-0.3200, valid loss-2.1747, acc-0.3688, test loss-2.1756, acc-0.3677\n",
      "Iter-11390, train loss-2.1718, acc-0.4000, valid loss-2.1746, acc-0.3688, test loss-2.1755, acc-0.3673\n",
      "Iter-11400, train loss-2.2104, acc-0.3400, valid loss-2.1745, acc-0.3690, test loss-2.1754, acc-0.3674\n",
      "Iter-11410, train loss-2.1724, acc-0.3800, valid loss-2.1744, acc-0.3692, test loss-2.1753, acc-0.3673\n",
      "Iter-11420, train loss-2.1604, acc-0.4000, valid loss-2.1743, acc-0.3692, test loss-2.1751, acc-0.3672\n",
      "Iter-11430, train loss-2.1446, acc-0.4000, valid loss-2.1742, acc-0.3694, test loss-2.1750, acc-0.3676\n",
      "Iter-11440, train loss-2.1784, acc-0.3400, valid loss-2.1741, acc-0.3696, test loss-2.1749, acc-0.3675\n",
      "Iter-11450, train loss-2.1639, acc-0.4600, valid loss-2.1739, acc-0.3694, test loss-2.1748, acc-0.3673\n",
      "Iter-11460, train loss-2.1766, acc-0.3800, valid loss-2.1738, acc-0.3692, test loss-2.1747, acc-0.3672\n",
      "Iter-11470, train loss-2.1434, acc-0.4200, valid loss-2.1737, acc-0.3692, test loss-2.1746, acc-0.3675\n",
      "Iter-11480, train loss-2.1946, acc-0.2800, valid loss-2.1736, acc-0.3692, test loss-2.1745, acc-0.3672\n",
      "Iter-11490, train loss-2.2016, acc-0.2600, valid loss-2.1735, acc-0.3696, test loss-2.1744, acc-0.3674\n",
      "Iter-11500, train loss-2.1340, acc-0.4800, valid loss-2.1734, acc-0.3702, test loss-2.1742, acc-0.3678\n",
      "Iter-11510, train loss-2.1735, acc-0.3800, valid loss-2.1733, acc-0.3702, test loss-2.1741, acc-0.3679\n",
      "Iter-11520, train loss-2.1686, acc-0.4200, valid loss-2.1731, acc-0.3702, test loss-2.1740, acc-0.3681\n",
      "Iter-11530, train loss-2.1918, acc-0.3400, valid loss-2.1730, acc-0.3704, test loss-2.1739, acc-0.3684\n",
      "Iter-11540, train loss-2.2087, acc-0.2600, valid loss-2.1729, acc-0.3706, test loss-2.1738, acc-0.3682\n",
      "Iter-11550, train loss-2.1682, acc-0.3400, valid loss-2.1728, acc-0.3708, test loss-2.1737, acc-0.3681\n",
      "Iter-11560, train loss-2.1919, acc-0.3600, valid loss-2.1727, acc-0.3706, test loss-2.1735, acc-0.3681\n",
      "Iter-11570, train loss-2.1921, acc-0.3400, valid loss-2.1726, acc-0.3706, test loss-2.1734, acc-0.3682\n",
      "Iter-11580, train loss-2.1687, acc-0.4200, valid loss-2.1724, acc-0.3708, test loss-2.1733, acc-0.3683\n",
      "Iter-11590, train loss-2.1866, acc-0.3800, valid loss-2.1723, acc-0.3708, test loss-2.1732, acc-0.3682\n",
      "Iter-11600, train loss-2.2062, acc-0.3000, valid loss-2.1722, acc-0.3712, test loss-2.1731, acc-0.3685\n",
      "Iter-11610, train loss-2.1824, acc-0.3800, valid loss-2.1721, acc-0.3710, test loss-2.1730, acc-0.3686\n",
      "Iter-11620, train loss-2.1901, acc-0.2800, valid loss-2.1720, acc-0.3712, test loss-2.1729, acc-0.3688\n",
      "Iter-11630, train loss-2.1889, acc-0.3400, valid loss-2.1719, acc-0.3712, test loss-2.1728, acc-0.3691\n",
      "Iter-11640, train loss-2.1968, acc-0.3000, valid loss-2.1718, acc-0.3718, test loss-2.1726, acc-0.3692\n",
      "Iter-11650, train loss-2.1666, acc-0.4000, valid loss-2.1717, acc-0.3716, test loss-2.1725, acc-0.3694\n",
      "Iter-11660, train loss-2.1571, acc-0.4600, valid loss-2.1715, acc-0.3716, test loss-2.1724, acc-0.3695\n",
      "Iter-11670, train loss-2.1902, acc-0.3400, valid loss-2.1714, acc-0.3716, test loss-2.1723, acc-0.3695\n",
      "Iter-11680, train loss-2.1793, acc-0.3600, valid loss-2.1713, acc-0.3718, test loss-2.1722, acc-0.3695\n",
      "Iter-11690, train loss-2.1555, acc-0.3400, valid loss-2.1712, acc-0.3720, test loss-2.1721, acc-0.3695\n",
      "Iter-11700, train loss-2.1719, acc-0.4200, valid loss-2.1711, acc-0.3724, test loss-2.1720, acc-0.3693\n",
      "Iter-11710, train loss-2.2185, acc-0.3400, valid loss-2.1710, acc-0.3724, test loss-2.1719, acc-0.3696\n",
      "Iter-11720, train loss-2.2156, acc-0.2800, valid loss-2.1709, acc-0.3726, test loss-2.1718, acc-0.3697\n",
      "Iter-11730, train loss-2.2050, acc-0.2800, valid loss-2.1708, acc-0.3722, test loss-2.1717, acc-0.3697\n",
      "Iter-11740, train loss-2.1833, acc-0.4200, valid loss-2.1707, acc-0.3726, test loss-2.1715, acc-0.3698\n",
      "Iter-11750, train loss-2.1601, acc-0.3200, valid loss-2.1706, acc-0.3724, test loss-2.1714, acc-0.3699\n",
      "Iter-11760, train loss-2.1730, acc-0.2800, valid loss-2.1705, acc-0.3724, test loss-2.1713, acc-0.3698\n",
      "Iter-11770, train loss-2.1738, acc-0.3600, valid loss-2.1703, acc-0.3726, test loss-2.1712, acc-0.3700\n",
      "Iter-11780, train loss-2.1789, acc-0.3000, valid loss-2.1702, acc-0.3730, test loss-2.1711, acc-0.3698\n",
      "Iter-11790, train loss-2.1624, acc-0.4200, valid loss-2.1701, acc-0.3728, test loss-2.1710, acc-0.3699\n",
      "Iter-11800, train loss-2.1750, acc-0.3200, valid loss-2.1700, acc-0.3726, test loss-2.1709, acc-0.3697\n",
      "Iter-11810, train loss-2.1663, acc-0.4400, valid loss-2.1699, acc-0.3728, test loss-2.1707, acc-0.3698\n",
      "Iter-11820, train loss-2.2191, acc-0.2800, valid loss-2.1698, acc-0.3732, test loss-2.1706, acc-0.3700\n",
      "Iter-11830, train loss-2.2051, acc-0.2600, valid loss-2.1697, acc-0.3736, test loss-2.1705, acc-0.3705\n",
      "Iter-11840, train loss-2.1587, acc-0.3200, valid loss-2.1695, acc-0.3736, test loss-2.1704, acc-0.3703\n",
      "Iter-11850, train loss-2.2185, acc-0.2800, valid loss-2.1694, acc-0.3744, test loss-2.1703, acc-0.3704\n",
      "Iter-11860, train loss-2.1840, acc-0.3800, valid loss-2.1693, acc-0.3742, test loss-2.1702, acc-0.3705\n",
      "Iter-11870, train loss-2.1586, acc-0.3600, valid loss-2.1692, acc-0.3742, test loss-2.1701, acc-0.3708\n",
      "Iter-11880, train loss-2.1983, acc-0.2800, valid loss-2.1691, acc-0.3742, test loss-2.1699, acc-0.3707\n",
      "Iter-11890, train loss-2.2243, acc-0.2800, valid loss-2.1690, acc-0.3742, test loss-2.1698, acc-0.3709\n",
      "Iter-11900, train loss-2.1501, acc-0.3800, valid loss-2.1689, acc-0.3744, test loss-2.1697, acc-0.3708\n",
      "Iter-11910, train loss-2.1578, acc-0.3600, valid loss-2.1688, acc-0.3750, test loss-2.1696, acc-0.3708\n",
      "Iter-11920, train loss-2.1860, acc-0.3400, valid loss-2.1687, acc-0.3754, test loss-2.1695, acc-0.3709\n",
      "Iter-11930, train loss-2.1740, acc-0.3200, valid loss-2.1686, acc-0.3754, test loss-2.1694, acc-0.3710\n",
      "Iter-11940, train loss-2.1499, acc-0.5200, valid loss-2.1684, acc-0.3752, test loss-2.1693, acc-0.3711\n",
      "Iter-11950, train loss-2.1425, acc-0.4200, valid loss-2.1683, acc-0.3752, test loss-2.1692, acc-0.3712\n",
      "Iter-11960, train loss-2.1825, acc-0.4200, valid loss-2.1682, acc-0.3752, test loss-2.1690, acc-0.3711\n",
      "Iter-11970, train loss-2.2028, acc-0.3800, valid loss-2.1681, acc-0.3752, test loss-2.1689, acc-0.3715\n",
      "Iter-11980, train loss-2.1761, acc-0.3800, valid loss-2.1680, acc-0.3752, test loss-2.1688, acc-0.3716\n",
      "Iter-11990, train loss-2.1765, acc-0.3000, valid loss-2.1679, acc-0.3754, test loss-2.1687, acc-0.3716\n",
      "Iter-12000, train loss-2.1852, acc-0.3200, valid loss-2.1678, acc-0.3754, test loss-2.1686, acc-0.3716\n",
      "Iter-12010, train loss-2.1869, acc-0.3600, valid loss-2.1677, acc-0.3754, test loss-2.1685, acc-0.3715\n",
      "Iter-12020, train loss-2.1875, acc-0.2800, valid loss-2.1675, acc-0.3756, test loss-2.1684, acc-0.3718\n",
      "Iter-12030, train loss-2.1502, acc-0.4400, valid loss-2.1674, acc-0.3756, test loss-2.1683, acc-0.3720\n",
      "Iter-12040, train loss-2.1607, acc-0.3400, valid loss-2.1673, acc-0.3758, test loss-2.1682, acc-0.3720\n",
      "Iter-12050, train loss-2.1730, acc-0.3600, valid loss-2.1672, acc-0.3758, test loss-2.1681, acc-0.3721\n",
      "Iter-12060, train loss-2.1655, acc-0.4000, valid loss-2.1671, acc-0.3760, test loss-2.1679, acc-0.3719\n",
      "Iter-12070, train loss-2.0989, acc-0.4200, valid loss-2.1670, acc-0.3760, test loss-2.1678, acc-0.3721\n",
      "Iter-12080, train loss-2.1820, acc-0.3600, valid loss-2.1669, acc-0.3758, test loss-2.1677, acc-0.3721\n",
      "Iter-12090, train loss-2.1435, acc-0.4000, valid loss-2.1668, acc-0.3756, test loss-2.1676, acc-0.3721\n",
      "Iter-12100, train loss-2.1962, acc-0.2800, valid loss-2.1667, acc-0.3756, test loss-2.1675, acc-0.3724\n",
      "Iter-12110, train loss-2.1746, acc-0.3400, valid loss-2.1666, acc-0.3760, test loss-2.1674, acc-0.3725\n",
      "Iter-12120, train loss-2.2129, acc-0.2600, valid loss-2.1665, acc-0.3760, test loss-2.1673, acc-0.3730\n",
      "Iter-12130, train loss-2.2010, acc-0.2000, valid loss-2.1664, acc-0.3758, test loss-2.1672, acc-0.3728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12140, train loss-2.1517, acc-0.4400, valid loss-2.1662, acc-0.3754, test loss-2.1671, acc-0.3729\n",
      "Iter-12150, train loss-2.1487, acc-0.4000, valid loss-2.1661, acc-0.3758, test loss-2.1670, acc-0.3732\n",
      "Iter-12160, train loss-2.1589, acc-0.4000, valid loss-2.1660, acc-0.3760, test loss-2.1668, acc-0.3729\n",
      "Iter-12170, train loss-2.1802, acc-0.3800, valid loss-2.1659, acc-0.3760, test loss-2.1667, acc-0.3728\n",
      "Iter-12180, train loss-2.2041, acc-0.2800, valid loss-2.1658, acc-0.3760, test loss-2.1666, acc-0.3729\n",
      "Iter-12190, train loss-2.1759, acc-0.4200, valid loss-2.1657, acc-0.3758, test loss-2.1665, acc-0.3733\n",
      "Iter-12200, train loss-2.1792, acc-0.4200, valid loss-2.1656, acc-0.3760, test loss-2.1664, acc-0.3732\n",
      "Iter-12210, train loss-2.1193, acc-0.4400, valid loss-2.1654, acc-0.3760, test loss-2.1663, acc-0.3732\n",
      "Iter-12220, train loss-2.1619, acc-0.3600, valid loss-2.1653, acc-0.3760, test loss-2.1662, acc-0.3732\n",
      "Iter-12230, train loss-2.1671, acc-0.3800, valid loss-2.1652, acc-0.3766, test loss-2.1661, acc-0.3732\n",
      "Iter-12240, train loss-2.2043, acc-0.2800, valid loss-2.1651, acc-0.3764, test loss-2.1660, acc-0.3735\n",
      "Iter-12250, train loss-2.1841, acc-0.3800, valid loss-2.1650, acc-0.3764, test loss-2.1658, acc-0.3738\n",
      "Iter-12260, train loss-2.1923, acc-0.3000, valid loss-2.1649, acc-0.3764, test loss-2.1657, acc-0.3738\n",
      "Iter-12270, train loss-2.1498, acc-0.4400, valid loss-2.1648, acc-0.3762, test loss-2.1656, acc-0.3737\n",
      "Iter-12280, train loss-2.1482, acc-0.5200, valid loss-2.1647, acc-0.3762, test loss-2.1655, acc-0.3736\n",
      "Iter-12290, train loss-2.1633, acc-0.4000, valid loss-2.1645, acc-0.3758, test loss-2.1654, acc-0.3738\n",
      "Iter-12300, train loss-2.1707, acc-0.3400, valid loss-2.1644, acc-0.3758, test loss-2.1653, acc-0.3738\n",
      "Iter-12310, train loss-2.1612, acc-0.4600, valid loss-2.1643, acc-0.3766, test loss-2.1651, acc-0.3734\n",
      "Iter-12320, train loss-2.1741, acc-0.3600, valid loss-2.1642, acc-0.3762, test loss-2.1650, acc-0.3735\n",
      "Iter-12330, train loss-2.1765, acc-0.4600, valid loss-2.1641, acc-0.3764, test loss-2.1649, acc-0.3734\n",
      "Iter-12340, train loss-2.1709, acc-0.3600, valid loss-2.1640, acc-0.3762, test loss-2.1648, acc-0.3734\n",
      "Iter-12350, train loss-2.1476, acc-0.3800, valid loss-2.1639, acc-0.3760, test loss-2.1647, acc-0.3736\n",
      "Iter-12360, train loss-2.1613, acc-0.4400, valid loss-2.1637, acc-0.3758, test loss-2.1646, acc-0.3736\n",
      "Iter-12370, train loss-2.1577, acc-0.3400, valid loss-2.1636, acc-0.3762, test loss-2.1645, acc-0.3737\n",
      "Iter-12380, train loss-2.1868, acc-0.3000, valid loss-2.1635, acc-0.3760, test loss-2.1644, acc-0.3738\n",
      "Iter-12390, train loss-2.2199, acc-0.2200, valid loss-2.1634, acc-0.3760, test loss-2.1643, acc-0.3737\n",
      "Iter-12400, train loss-2.1547, acc-0.3000, valid loss-2.1633, acc-0.3760, test loss-2.1642, acc-0.3739\n",
      "Iter-12410, train loss-2.1715, acc-0.4600, valid loss-2.1632, acc-0.3762, test loss-2.1640, acc-0.3742\n",
      "Iter-12420, train loss-2.1339, acc-0.4000, valid loss-2.1631, acc-0.3764, test loss-2.1639, acc-0.3746\n",
      "Iter-12430, train loss-2.2222, acc-0.2200, valid loss-2.1630, acc-0.3764, test loss-2.1638, acc-0.3746\n",
      "Iter-12440, train loss-2.1843, acc-0.3200, valid loss-2.1628, acc-0.3764, test loss-2.1637, acc-0.3749\n",
      "Iter-12450, train loss-2.1849, acc-0.3400, valid loss-2.1627, acc-0.3766, test loss-2.1636, acc-0.3749\n",
      "Iter-12460, train loss-2.1724, acc-0.3600, valid loss-2.1626, acc-0.3766, test loss-2.1635, acc-0.3749\n",
      "Iter-12470, train loss-2.1637, acc-0.4600, valid loss-2.1625, acc-0.3762, test loss-2.1634, acc-0.3747\n",
      "Iter-12480, train loss-2.1645, acc-0.4000, valid loss-2.1624, acc-0.3764, test loss-2.1632, acc-0.3748\n",
      "Iter-12490, train loss-2.1871, acc-0.3200, valid loss-2.1623, acc-0.3760, test loss-2.1631, acc-0.3749\n",
      "Iter-12500, train loss-2.1431, acc-0.4200, valid loss-2.1622, acc-0.3760, test loss-2.1630, acc-0.3747\n",
      "Iter-12510, train loss-2.1933, acc-0.3000, valid loss-2.1621, acc-0.3762, test loss-2.1629, acc-0.3747\n",
      "Iter-12520, train loss-2.1696, acc-0.3400, valid loss-2.1619, acc-0.3760, test loss-2.1628, acc-0.3751\n",
      "Iter-12530, train loss-2.1423, acc-0.4600, valid loss-2.1618, acc-0.3758, test loss-2.1627, acc-0.3749\n",
      "Iter-12540, train loss-2.1481, acc-0.4400, valid loss-2.1617, acc-0.3760, test loss-2.1626, acc-0.3751\n",
      "Iter-12550, train loss-2.1763, acc-0.3200, valid loss-2.1616, acc-0.3764, test loss-2.1625, acc-0.3751\n",
      "Iter-12560, train loss-2.2016, acc-0.2600, valid loss-2.1615, acc-0.3764, test loss-2.1623, acc-0.3752\n",
      "Iter-12570, train loss-2.1725, acc-0.3400, valid loss-2.1614, acc-0.3766, test loss-2.1622, acc-0.3751\n",
      "Iter-12580, train loss-2.1895, acc-0.3000, valid loss-2.1613, acc-0.3766, test loss-2.1621, acc-0.3751\n",
      "Iter-12590, train loss-2.2089, acc-0.3200, valid loss-2.1612, acc-0.3762, test loss-2.1620, acc-0.3755\n",
      "Iter-12600, train loss-2.1464, acc-0.4000, valid loss-2.1610, acc-0.3760, test loss-2.1619, acc-0.3756\n",
      "Iter-12610, train loss-2.1455, acc-0.3600, valid loss-2.1609, acc-0.3766, test loss-2.1618, acc-0.3758\n",
      "Iter-12620, train loss-2.2295, acc-0.3000, valid loss-2.1608, acc-0.3766, test loss-2.1617, acc-0.3758\n",
      "Iter-12630, train loss-2.1719, acc-0.4400, valid loss-2.1607, acc-0.3766, test loss-2.1616, acc-0.3756\n",
      "Iter-12640, train loss-2.1781, acc-0.3800, valid loss-2.1606, acc-0.3770, test loss-2.1615, acc-0.3760\n",
      "Iter-12650, train loss-2.1642, acc-0.3200, valid loss-2.1605, acc-0.3766, test loss-2.1614, acc-0.3760\n",
      "Iter-12660, train loss-2.1627, acc-0.3800, valid loss-2.1604, acc-0.3766, test loss-2.1613, acc-0.3760\n",
      "Iter-12670, train loss-2.1767, acc-0.3600, valid loss-2.1603, acc-0.3762, test loss-2.1611, acc-0.3760\n",
      "Iter-12680, train loss-2.1625, acc-0.3600, valid loss-2.1602, acc-0.3768, test loss-2.1610, acc-0.3762\n",
      "Iter-12690, train loss-2.1730, acc-0.2600, valid loss-2.1601, acc-0.3768, test loss-2.1609, acc-0.3760\n",
      "Iter-12700, train loss-2.1666, acc-0.3600, valid loss-2.1600, acc-0.3770, test loss-2.1608, acc-0.3760\n",
      "Iter-12710, train loss-2.1651, acc-0.3000, valid loss-2.1598, acc-0.3768, test loss-2.1607, acc-0.3762\n",
      "Iter-12720, train loss-2.1504, acc-0.4000, valid loss-2.1597, acc-0.3772, test loss-2.1606, acc-0.3762\n",
      "Iter-12730, train loss-2.1781, acc-0.3600, valid loss-2.1596, acc-0.3770, test loss-2.1605, acc-0.3761\n",
      "Iter-12740, train loss-2.1937, acc-0.2600, valid loss-2.1595, acc-0.3770, test loss-2.1604, acc-0.3759\n",
      "Iter-12750, train loss-2.1760, acc-0.3600, valid loss-2.1594, acc-0.3774, test loss-2.1603, acc-0.3760\n",
      "Iter-12760, train loss-2.0980, acc-0.5000, valid loss-2.1593, acc-0.3778, test loss-2.1601, acc-0.3761\n",
      "Iter-12770, train loss-2.1460, acc-0.4800, valid loss-2.1592, acc-0.3774, test loss-2.1600, acc-0.3761\n",
      "Iter-12780, train loss-2.1748, acc-0.4000, valid loss-2.1591, acc-0.3776, test loss-2.1599, acc-0.3762\n",
      "Iter-12790, train loss-2.2234, acc-0.3200, valid loss-2.1590, acc-0.3782, test loss-2.1598, acc-0.3760\n",
      "Iter-12800, train loss-2.1166, acc-0.5400, valid loss-2.1588, acc-0.3784, test loss-2.1597, acc-0.3761\n",
      "Iter-12810, train loss-2.1443, acc-0.4000, valid loss-2.1587, acc-0.3782, test loss-2.1596, acc-0.3761\n",
      "Iter-12820, train loss-2.1486, acc-0.4000, valid loss-2.1586, acc-0.3788, test loss-2.1595, acc-0.3760\n",
      "Iter-12830, train loss-2.1418, acc-0.4200, valid loss-2.1585, acc-0.3784, test loss-2.1594, acc-0.3762\n",
      "Iter-12840, train loss-2.1432, acc-0.4200, valid loss-2.1584, acc-0.3790, test loss-2.1592, acc-0.3762\n",
      "Iter-12850, train loss-2.1870, acc-0.3200, valid loss-2.1583, acc-0.3786, test loss-2.1591, acc-0.3759\n",
      "Iter-12860, train loss-2.1637, acc-0.3400, valid loss-2.1582, acc-0.3788, test loss-2.1590, acc-0.3762\n",
      "Iter-12870, train loss-2.1854, acc-0.3200, valid loss-2.1581, acc-0.3792, test loss-2.1589, acc-0.3764\n",
      "Iter-12880, train loss-2.1396, acc-0.3600, valid loss-2.1579, acc-0.3794, test loss-2.1588, acc-0.3767\n",
      "Iter-12890, train loss-2.1488, acc-0.3800, valid loss-2.1578, acc-0.3794, test loss-2.1587, acc-0.3768\n",
      "Iter-12900, train loss-2.1599, acc-0.3400, valid loss-2.1577, acc-0.3798, test loss-2.1586, acc-0.3765\n",
      "Iter-12910, train loss-2.1819, acc-0.3200, valid loss-2.1576, acc-0.3802, test loss-2.1585, acc-0.3767\n",
      "Iter-12920, train loss-2.1985, acc-0.2800, valid loss-2.1575, acc-0.3804, test loss-2.1583, acc-0.3772\n",
      "Iter-12930, train loss-2.1315, acc-0.4800, valid loss-2.1574, acc-0.3808, test loss-2.1582, acc-0.3775\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-12940, train loss-2.1657, acc-0.4400, valid loss-2.1573, acc-0.3812, test loss-2.1581, acc-0.3776\n",
      "Iter-12950, train loss-2.1514, acc-0.3400, valid loss-2.1572, acc-0.3812, test loss-2.1580, acc-0.3778\n",
      "Iter-12960, train loss-2.1384, acc-0.4000, valid loss-2.1570, acc-0.3806, test loss-2.1579, acc-0.3779\n",
      "Iter-12970, train loss-2.1668, acc-0.3600, valid loss-2.1569, acc-0.3806, test loss-2.1578, acc-0.3780\n",
      "Iter-12980, train loss-2.1416, acc-0.3800, valid loss-2.1568, acc-0.3812, test loss-2.1577, acc-0.3778\n",
      "Iter-12990, train loss-2.1515, acc-0.3400, valid loss-2.1567, acc-0.3808, test loss-2.1576, acc-0.3779\n",
      "Iter-13000, train loss-2.1502, acc-0.4600, valid loss-2.1566, acc-0.3812, test loss-2.1575, acc-0.3779\n",
      "Iter-13010, train loss-2.1722, acc-0.2800, valid loss-2.1565, acc-0.3814, test loss-2.1574, acc-0.3778\n",
      "Iter-13020, train loss-2.1496, acc-0.3600, valid loss-2.1564, acc-0.3814, test loss-2.1572, acc-0.3780\n",
      "Iter-13030, train loss-2.1560, acc-0.3400, valid loss-2.1563, acc-0.3814, test loss-2.1571, acc-0.3782\n",
      "Iter-13040, train loss-2.1329, acc-0.3600, valid loss-2.1562, acc-0.3814, test loss-2.1570, acc-0.3784\n",
      "Iter-13050, train loss-2.1597, acc-0.4000, valid loss-2.1560, acc-0.3816, test loss-2.1569, acc-0.3786\n",
      "Iter-13060, train loss-2.1516, acc-0.4400, valid loss-2.1559, acc-0.3822, test loss-2.1568, acc-0.3786\n",
      "Iter-13070, train loss-2.1389, acc-0.4200, valid loss-2.1558, acc-0.3820, test loss-2.1567, acc-0.3786\n",
      "Iter-13080, train loss-2.1696, acc-0.3400, valid loss-2.1557, acc-0.3822, test loss-2.1566, acc-0.3786\n",
      "Iter-13090, train loss-2.1696, acc-0.3800, valid loss-2.1556, acc-0.3820, test loss-2.1565, acc-0.3789\n",
      "Iter-13100, train loss-2.0909, acc-0.4800, valid loss-2.1555, acc-0.3818, test loss-2.1564, acc-0.3793\n",
      "Iter-13110, train loss-2.1916, acc-0.4800, valid loss-2.1554, acc-0.3818, test loss-2.1563, acc-0.3794\n",
      "Iter-13120, train loss-2.1347, acc-0.3800, valid loss-2.1553, acc-0.3820, test loss-2.1562, acc-0.3795\n",
      "Iter-13130, train loss-2.1952, acc-0.2800, valid loss-2.1552, acc-0.3820, test loss-2.1560, acc-0.3795\n",
      "Iter-13140, train loss-2.1717, acc-0.3600, valid loss-2.1551, acc-0.3822, test loss-2.1559, acc-0.3794\n",
      "Iter-13150, train loss-2.1421, acc-0.3800, valid loss-2.1550, acc-0.3828, test loss-2.1558, acc-0.3794\n",
      "Iter-13160, train loss-2.1428, acc-0.3800, valid loss-2.1549, acc-0.3830, test loss-2.1557, acc-0.3793\n",
      "Iter-13170, train loss-2.1740, acc-0.3600, valid loss-2.1548, acc-0.3832, test loss-2.1556, acc-0.3796\n",
      "Iter-13180, train loss-2.1307, acc-0.4400, valid loss-2.1547, acc-0.3832, test loss-2.1555, acc-0.3796\n",
      "Iter-13190, train loss-2.1724, acc-0.4000, valid loss-2.1545, acc-0.3832, test loss-2.1554, acc-0.3795\n",
      "Iter-13200, train loss-2.1144, acc-0.4800, valid loss-2.1544, acc-0.3832, test loss-2.1553, acc-0.3794\n",
      "Iter-13210, train loss-2.1853, acc-0.3000, valid loss-2.1543, acc-0.3836, test loss-2.1552, acc-0.3795\n",
      "Iter-13220, train loss-2.1468, acc-0.3800, valid loss-2.1542, acc-0.3838, test loss-2.1551, acc-0.3800\n",
      "Iter-13230, train loss-2.1213, acc-0.4600, valid loss-2.1541, acc-0.3836, test loss-2.1549, acc-0.3797\n",
      "Iter-13240, train loss-2.1616, acc-0.4400, valid loss-2.1540, acc-0.3836, test loss-2.1548, acc-0.3795\n",
      "Iter-13250, train loss-2.1891, acc-0.2800, valid loss-2.1539, acc-0.3842, test loss-2.1547, acc-0.3801\n",
      "Iter-13260, train loss-2.1971, acc-0.2200, valid loss-2.1538, acc-0.3838, test loss-2.1546, acc-0.3802\n",
      "Iter-13270, train loss-2.1410, acc-0.3600, valid loss-2.1537, acc-0.3838, test loss-2.1545, acc-0.3798\n",
      "Iter-13280, train loss-2.1762, acc-0.3400, valid loss-2.1536, acc-0.3840, test loss-2.1544, acc-0.3797\n",
      "Iter-13290, train loss-2.1310, acc-0.4600, valid loss-2.1535, acc-0.3840, test loss-2.1543, acc-0.3798\n",
      "Iter-13300, train loss-2.1820, acc-0.3200, valid loss-2.1533, acc-0.3842, test loss-2.1542, acc-0.3802\n",
      "Iter-13310, train loss-2.1587, acc-0.2600, valid loss-2.1532, acc-0.3844, test loss-2.1541, acc-0.3802\n",
      "Iter-13320, train loss-2.1863, acc-0.3400, valid loss-2.1531, acc-0.3844, test loss-2.1540, acc-0.3801\n",
      "Iter-13330, train loss-2.1216, acc-0.4600, valid loss-2.1530, acc-0.3846, test loss-2.1539, acc-0.3800\n",
      "Iter-13340, train loss-2.1489, acc-0.3600, valid loss-2.1529, acc-0.3844, test loss-2.1537, acc-0.3798\n",
      "Iter-13350, train loss-2.1523, acc-0.3400, valid loss-2.1528, acc-0.3842, test loss-2.1536, acc-0.3798\n",
      "Iter-13360, train loss-2.1406, acc-0.4000, valid loss-2.1527, acc-0.3838, test loss-2.1535, acc-0.3797\n",
      "Iter-13370, train loss-2.1400, acc-0.3800, valid loss-2.1526, acc-0.3838, test loss-2.1534, acc-0.3795\n",
      "Iter-13380, train loss-2.1756, acc-0.2600, valid loss-2.1525, acc-0.3838, test loss-2.1533, acc-0.3796\n",
      "Iter-13390, train loss-2.1845, acc-0.3400, valid loss-2.1524, acc-0.3840, test loss-2.1532, acc-0.3795\n",
      "Iter-13400, train loss-2.1487, acc-0.3600, valid loss-2.1523, acc-0.3840, test loss-2.1531, acc-0.3796\n",
      "Iter-13410, train loss-2.1496, acc-0.3600, valid loss-2.1522, acc-0.3840, test loss-2.1530, acc-0.3797\n",
      "Iter-13420, train loss-2.1145, acc-0.4400, valid loss-2.1521, acc-0.3844, test loss-2.1529, acc-0.3797\n",
      "Iter-13430, train loss-2.1991, acc-0.2600, valid loss-2.1520, acc-0.3850, test loss-2.1528, acc-0.3799\n",
      "Iter-13440, train loss-2.1690, acc-0.3400, valid loss-2.1518, acc-0.3846, test loss-2.1527, acc-0.3797\n",
      "Iter-13450, train loss-2.1406, acc-0.4600, valid loss-2.1517, acc-0.3850, test loss-2.1526, acc-0.3799\n",
      "Iter-13460, train loss-2.1610, acc-0.3800, valid loss-2.1516, acc-0.3852, test loss-2.1525, acc-0.3800\n",
      "Iter-13470, train loss-2.1430, acc-0.3600, valid loss-2.1515, acc-0.3848, test loss-2.1524, acc-0.3801\n",
      "Iter-13480, train loss-2.1535, acc-0.3400, valid loss-2.1514, acc-0.3848, test loss-2.1523, acc-0.3801\n",
      "Iter-13490, train loss-2.1554, acc-0.3600, valid loss-2.1513, acc-0.3846, test loss-2.1521, acc-0.3802\n",
      "Iter-13500, train loss-2.2154, acc-0.3000, valid loss-2.1512, acc-0.3852, test loss-2.1520, acc-0.3805\n",
      "Iter-13510, train loss-2.1366, acc-0.4200, valid loss-2.1511, acc-0.3850, test loss-2.1519, acc-0.3806\n",
      "Iter-13520, train loss-2.1843, acc-0.3000, valid loss-2.1510, acc-0.3850, test loss-2.1518, acc-0.3806\n",
      "Iter-13530, train loss-2.1530, acc-0.4000, valid loss-2.1508, acc-0.3852, test loss-2.1517, acc-0.3807\n",
      "Iter-13540, train loss-2.1514, acc-0.3400, valid loss-2.1507, acc-0.3854, test loss-2.1516, acc-0.3808\n",
      "Iter-13550, train loss-2.1590, acc-0.3200, valid loss-2.1506, acc-0.3858, test loss-2.1515, acc-0.3806\n",
      "Iter-13560, train loss-2.1360, acc-0.4000, valid loss-2.1505, acc-0.3858, test loss-2.1514, acc-0.3810\n",
      "Iter-13570, train loss-2.1847, acc-0.3600, valid loss-2.1504, acc-0.3864, test loss-2.1513, acc-0.3808\n",
      "Iter-13580, train loss-2.1539, acc-0.3600, valid loss-2.1503, acc-0.3862, test loss-2.1511, acc-0.3809\n",
      "Iter-13590, train loss-2.1280, acc-0.4400, valid loss-2.1502, acc-0.3862, test loss-2.1510, acc-0.3809\n",
      "Iter-13600, train loss-2.1456, acc-0.3800, valid loss-2.1501, acc-0.3866, test loss-2.1509, acc-0.3809\n",
      "Iter-13610, train loss-2.1953, acc-0.2200, valid loss-2.1500, acc-0.3868, test loss-2.1508, acc-0.3812\n",
      "Iter-13620, train loss-2.1475, acc-0.4200, valid loss-2.1499, acc-0.3870, test loss-2.1507, acc-0.3814\n",
      "Iter-13630, train loss-2.1626, acc-0.3400, valid loss-2.1498, acc-0.3870, test loss-2.1506, acc-0.3816\n",
      "Iter-13640, train loss-2.0972, acc-0.5200, valid loss-2.1497, acc-0.3870, test loss-2.1505, acc-0.3814\n",
      "Iter-13650, train loss-2.1360, acc-0.2800, valid loss-2.1496, acc-0.3872, test loss-2.1504, acc-0.3817\n",
      "Iter-13660, train loss-2.1808, acc-0.2800, valid loss-2.1495, acc-0.3870, test loss-2.1503, acc-0.3818\n",
      "Iter-13670, train loss-2.1240, acc-0.4600, valid loss-2.1493, acc-0.3872, test loss-2.1502, acc-0.3818\n",
      "Iter-13680, train loss-2.1777, acc-0.3400, valid loss-2.1492, acc-0.3874, test loss-2.1501, acc-0.3819\n",
      "Iter-13690, train loss-2.2009, acc-0.3600, valid loss-2.1491, acc-0.3876, test loss-2.1500, acc-0.3819\n",
      "Iter-13700, train loss-2.1605, acc-0.3800, valid loss-2.1490, acc-0.3880, test loss-2.1499, acc-0.3817\n",
      "Iter-13710, train loss-2.1678, acc-0.3400, valid loss-2.1489, acc-0.3880, test loss-2.1498, acc-0.3819\n",
      "Iter-13720, train loss-2.1871, acc-0.3600, valid loss-2.1488, acc-0.3882, test loss-2.1497, acc-0.3820\n",
      "Iter-13730, train loss-2.1554, acc-0.3800, valid loss-2.1487, acc-0.3882, test loss-2.1496, acc-0.3821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-13740, train loss-2.1368, acc-0.4600, valid loss-2.1486, acc-0.3884, test loss-2.1494, acc-0.3820\n",
      "Iter-13750, train loss-2.1518, acc-0.4200, valid loss-2.1485, acc-0.3884, test loss-2.1493, acc-0.3820\n",
      "Iter-13760, train loss-2.1894, acc-0.2400, valid loss-2.1484, acc-0.3882, test loss-2.1492, acc-0.3822\n",
      "Iter-13770, train loss-2.1396, acc-0.3600, valid loss-2.1483, acc-0.3882, test loss-2.1491, acc-0.3823\n",
      "Iter-13780, train loss-2.1454, acc-0.3800, valid loss-2.1482, acc-0.3880, test loss-2.1490, acc-0.3825\n",
      "Iter-13790, train loss-2.1180, acc-0.4600, valid loss-2.1481, acc-0.3880, test loss-2.1489, acc-0.3823\n",
      "Iter-13800, train loss-2.1487, acc-0.4000, valid loss-2.1480, acc-0.3876, test loss-2.1488, acc-0.3822\n",
      "Iter-13810, train loss-2.1477, acc-0.4600, valid loss-2.1479, acc-0.3876, test loss-2.1487, acc-0.3823\n",
      "Iter-13820, train loss-2.2242, acc-0.2600, valid loss-2.1478, acc-0.3876, test loss-2.1486, acc-0.3823\n",
      "Iter-13830, train loss-2.1875, acc-0.2600, valid loss-2.1476, acc-0.3878, test loss-2.1485, acc-0.3825\n",
      "Iter-13840, train loss-2.1236, acc-0.4600, valid loss-2.1475, acc-0.3878, test loss-2.1484, acc-0.3826\n",
      "Iter-13850, train loss-2.1366, acc-0.5200, valid loss-2.1474, acc-0.3880, test loss-2.1483, acc-0.3826\n",
      "Iter-13860, train loss-2.1534, acc-0.3200, valid loss-2.1473, acc-0.3882, test loss-2.1482, acc-0.3826\n",
      "Iter-13870, train loss-2.1229, acc-0.5000, valid loss-2.1472, acc-0.3886, test loss-2.1481, acc-0.3830\n",
      "Iter-13880, train loss-2.1332, acc-0.5000, valid loss-2.1471, acc-0.3888, test loss-2.1479, acc-0.3830\n",
      "Iter-13890, train loss-2.0910, acc-0.5400, valid loss-2.1470, acc-0.3888, test loss-2.1478, acc-0.3830\n",
      "Iter-13900, train loss-2.1502, acc-0.3400, valid loss-2.1469, acc-0.3890, test loss-2.1477, acc-0.3832\n",
      "Iter-13910, train loss-2.1467, acc-0.4200, valid loss-2.1468, acc-0.3890, test loss-2.1476, acc-0.3831\n",
      "Iter-13920, train loss-2.0881, acc-0.4800, valid loss-2.1467, acc-0.3888, test loss-2.1475, acc-0.3830\n",
      "Iter-13930, train loss-2.1704, acc-0.4000, valid loss-2.1466, acc-0.3886, test loss-2.1474, acc-0.3832\n",
      "Iter-13940, train loss-2.0887, acc-0.5200, valid loss-2.1465, acc-0.3888, test loss-2.1473, acc-0.3832\n",
      "Iter-13950, train loss-2.1552, acc-0.4400, valid loss-2.1463, acc-0.3890, test loss-2.1472, acc-0.3830\n",
      "Iter-13960, train loss-2.1595, acc-0.3800, valid loss-2.1462, acc-0.3890, test loss-2.1471, acc-0.3831\n",
      "Iter-13970, train loss-2.1526, acc-0.3400, valid loss-2.1461, acc-0.3890, test loss-2.1470, acc-0.3833\n",
      "Iter-13980, train loss-2.1473, acc-0.3800, valid loss-2.1460, acc-0.3890, test loss-2.1469, acc-0.3831\n",
      "Iter-13990, train loss-2.1233, acc-0.4600, valid loss-2.1459, acc-0.3890, test loss-2.1467, acc-0.3831\n",
      "Iter-14000, train loss-2.1604, acc-0.3000, valid loss-2.1458, acc-0.3890, test loss-2.1466, acc-0.3832\n",
      "Iter-14010, train loss-2.1298, acc-0.4400, valid loss-2.1457, acc-0.3890, test loss-2.1465, acc-0.3832\n",
      "Iter-14020, train loss-2.1667, acc-0.3200, valid loss-2.1456, acc-0.3890, test loss-2.1464, acc-0.3835\n",
      "Iter-14030, train loss-2.1237, acc-0.3400, valid loss-2.1455, acc-0.3892, test loss-2.1463, acc-0.3835\n",
      "Iter-14040, train loss-2.1518, acc-0.3400, valid loss-2.1454, acc-0.3896, test loss-2.1462, acc-0.3834\n",
      "Iter-14050, train loss-2.1544, acc-0.3800, valid loss-2.1453, acc-0.3898, test loss-2.1461, acc-0.3836\n",
      "Iter-14060, train loss-2.1376, acc-0.4000, valid loss-2.1452, acc-0.3898, test loss-2.1460, acc-0.3835\n",
      "Iter-14070, train loss-2.1501, acc-0.3800, valid loss-2.1450, acc-0.3898, test loss-2.1459, acc-0.3833\n",
      "Iter-14080, train loss-2.1473, acc-0.4200, valid loss-2.1449, acc-0.3900, test loss-2.1458, acc-0.3837\n",
      "Iter-14090, train loss-2.1409, acc-0.3800, valid loss-2.1448, acc-0.3900, test loss-2.1457, acc-0.3837\n",
      "Iter-14100, train loss-2.1666, acc-0.4000, valid loss-2.1447, acc-0.3896, test loss-2.1455, acc-0.3837\n",
      "Iter-14110, train loss-2.1566, acc-0.3800, valid loss-2.1446, acc-0.3896, test loss-2.1454, acc-0.3839\n",
      "Iter-14120, train loss-2.1186, acc-0.3600, valid loss-2.1445, acc-0.3898, test loss-2.1453, acc-0.3838\n",
      "Iter-14130, train loss-2.1148, acc-0.4400, valid loss-2.1444, acc-0.3900, test loss-2.1452, acc-0.3837\n",
      "Iter-14140, train loss-2.1829, acc-0.2000, valid loss-2.1443, acc-0.3900, test loss-2.1451, acc-0.3837\n",
      "Iter-14150, train loss-2.1431, acc-0.4400, valid loss-2.1442, acc-0.3898, test loss-2.1450, acc-0.3837\n",
      "Iter-14160, train loss-2.1251, acc-0.4400, valid loss-2.1441, acc-0.3904, test loss-2.1449, acc-0.3837\n",
      "Iter-14170, train loss-2.1196, acc-0.4800, valid loss-2.1440, acc-0.3902, test loss-2.1448, acc-0.3836\n",
      "Iter-14180, train loss-2.1656, acc-0.3400, valid loss-2.1439, acc-0.3904, test loss-2.1447, acc-0.3837\n",
      "Iter-14190, train loss-2.1732, acc-0.3200, valid loss-2.1438, acc-0.3902, test loss-2.1446, acc-0.3838\n",
      "Iter-14200, train loss-2.1079, acc-0.4400, valid loss-2.1436, acc-0.3904, test loss-2.1445, acc-0.3837\n",
      "Iter-14210, train loss-2.1753, acc-0.2800, valid loss-2.1435, acc-0.3906, test loss-2.1444, acc-0.3837\n",
      "Iter-14220, train loss-2.1826, acc-0.3000, valid loss-2.1434, acc-0.3906, test loss-2.1443, acc-0.3838\n",
      "Iter-14230, train loss-2.1344, acc-0.4000, valid loss-2.1433, acc-0.3910, test loss-2.1442, acc-0.3840\n",
      "Iter-14240, train loss-2.1103, acc-0.4400, valid loss-2.1432, acc-0.3906, test loss-2.1440, acc-0.3848\n",
      "Iter-14250, train loss-2.1211, acc-0.4000, valid loss-2.1431, acc-0.3908, test loss-2.1439, acc-0.3847\n",
      "Iter-14260, train loss-2.1466, acc-0.3800, valid loss-2.1430, acc-0.3908, test loss-2.1438, acc-0.3848\n",
      "Iter-14270, train loss-2.1337, acc-0.3400, valid loss-2.1429, acc-0.3906, test loss-2.1437, acc-0.3847\n",
      "Iter-14280, train loss-2.1584, acc-0.3800, valid loss-2.1428, acc-0.3910, test loss-2.1436, acc-0.3850\n",
      "Iter-14290, train loss-2.1628, acc-0.4000, valid loss-2.1427, acc-0.3908, test loss-2.1435, acc-0.3849\n",
      "Iter-14300, train loss-2.1480, acc-0.4400, valid loss-2.1426, acc-0.3908, test loss-2.1434, acc-0.3848\n",
      "Iter-14310, train loss-2.1186, acc-0.4000, valid loss-2.1425, acc-0.3908, test loss-2.1433, acc-0.3848\n",
      "Iter-14320, train loss-2.1575, acc-0.3000, valid loss-2.1424, acc-0.3906, test loss-2.1432, acc-0.3848\n",
      "Iter-14330, train loss-2.0983, acc-0.4800, valid loss-2.1423, acc-0.3906, test loss-2.1431, acc-0.3850\n",
      "Iter-14340, train loss-2.1560, acc-0.3800, valid loss-2.1422, acc-0.3906, test loss-2.1430, acc-0.3848\n",
      "Iter-14350, train loss-2.1478, acc-0.4400, valid loss-2.1421, acc-0.3906, test loss-2.1429, acc-0.3846\n",
      "Iter-14360, train loss-2.1210, acc-0.4000, valid loss-2.1420, acc-0.3910, test loss-2.1427, acc-0.3848\n",
      "Iter-14370, train loss-2.1703, acc-0.3200, valid loss-2.1419, acc-0.3912, test loss-2.1426, acc-0.3851\n",
      "Iter-14380, train loss-2.1241, acc-0.4400, valid loss-2.1417, acc-0.3910, test loss-2.1425, acc-0.3852\n",
      "Iter-14390, train loss-2.1582, acc-0.3600, valid loss-2.1416, acc-0.3912, test loss-2.1424, acc-0.3851\n",
      "Iter-14400, train loss-2.1745, acc-0.2800, valid loss-2.1415, acc-0.3910, test loss-2.1423, acc-0.3854\n",
      "Iter-14410, train loss-2.1395, acc-0.3200, valid loss-2.1414, acc-0.3914, test loss-2.1422, acc-0.3856\n",
      "Iter-14420, train loss-2.1347, acc-0.4400, valid loss-2.1413, acc-0.3914, test loss-2.1421, acc-0.3856\n",
      "Iter-14430, train loss-2.1682, acc-0.2800, valid loss-2.1412, acc-0.3918, test loss-2.1420, acc-0.3853\n",
      "Iter-14440, train loss-2.1503, acc-0.3600, valid loss-2.1411, acc-0.3918, test loss-2.1419, acc-0.3855\n",
      "Iter-14450, train loss-2.1471, acc-0.4000, valid loss-2.1410, acc-0.3920, test loss-2.1418, acc-0.3854\n",
      "Iter-14460, train loss-2.1459, acc-0.3200, valid loss-2.1409, acc-0.3922, test loss-2.1417, acc-0.3856\n",
      "Iter-14470, train loss-2.2094, acc-0.2000, valid loss-2.1408, acc-0.3924, test loss-2.1416, acc-0.3859\n",
      "Iter-14480, train loss-2.1478, acc-0.4200, valid loss-2.1407, acc-0.3924, test loss-2.1415, acc-0.3858\n",
      "Iter-14490, train loss-2.1853, acc-0.2200, valid loss-2.1405, acc-0.3920, test loss-2.1414, acc-0.3858\n",
      "Iter-14500, train loss-2.1335, acc-0.4600, valid loss-2.1404, acc-0.3922, test loss-2.1412, acc-0.3863\n",
      "Iter-14510, train loss-2.1485, acc-0.3600, valid loss-2.1403, acc-0.3922, test loss-2.1411, acc-0.3861\n",
      "Iter-14520, train loss-2.1672, acc-0.3400, valid loss-2.1402, acc-0.3922, test loss-2.1410, acc-0.3862\n",
      "Iter-14530, train loss-2.1101, acc-0.4800, valid loss-2.1401, acc-0.3922, test loss-2.1409, acc-0.3865\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-14540, train loss-2.1480, acc-0.3600, valid loss-2.1400, acc-0.3926, test loss-2.1408, acc-0.3864\n",
      "Iter-14550, train loss-2.1524, acc-0.3000, valid loss-2.1399, acc-0.3926, test loss-2.1407, acc-0.3866\n",
      "Iter-14560, train loss-2.1601, acc-0.3400, valid loss-2.1398, acc-0.3924, test loss-2.1406, acc-0.3868\n",
      "Iter-14570, train loss-2.1542, acc-0.3800, valid loss-2.1397, acc-0.3922, test loss-2.1405, acc-0.3869\n",
      "Iter-14580, train loss-2.1284, acc-0.4400, valid loss-2.1396, acc-0.3926, test loss-2.1404, acc-0.3868\n",
      "Iter-14590, train loss-2.1505, acc-0.4200, valid loss-2.1395, acc-0.3924, test loss-2.1403, acc-0.3870\n",
      "Iter-14600, train loss-2.1381, acc-0.3000, valid loss-2.1394, acc-0.3924, test loss-2.1402, acc-0.3869\n",
      "Iter-14610, train loss-2.1621, acc-0.4000, valid loss-2.1393, acc-0.3924, test loss-2.1401, acc-0.3873\n",
      "Iter-14620, train loss-2.1633, acc-0.4000, valid loss-2.1392, acc-0.3926, test loss-2.1400, acc-0.3873\n",
      "Iter-14630, train loss-2.1718, acc-0.3200, valid loss-2.1391, acc-0.3926, test loss-2.1399, acc-0.3872\n",
      "Iter-14640, train loss-2.1481, acc-0.3800, valid loss-2.1390, acc-0.3928, test loss-2.1398, acc-0.3872\n",
      "Iter-14650, train loss-2.1506, acc-0.3200, valid loss-2.1389, acc-0.3926, test loss-2.1397, acc-0.3871\n",
      "Iter-14660, train loss-2.1317, acc-0.3400, valid loss-2.1388, acc-0.3926, test loss-2.1396, acc-0.3876\n",
      "Iter-14670, train loss-2.1018, acc-0.4800, valid loss-2.1387, acc-0.3924, test loss-2.1395, acc-0.3876\n",
      "Iter-14680, train loss-2.1159, acc-0.4600, valid loss-2.1385, acc-0.3926, test loss-2.1393, acc-0.3877\n",
      "Iter-14690, train loss-2.1481, acc-0.3200, valid loss-2.1384, acc-0.3928, test loss-2.1392, acc-0.3878\n",
      "Iter-14700, train loss-2.1741, acc-0.3600, valid loss-2.1383, acc-0.3932, test loss-2.1391, acc-0.3880\n",
      "Iter-14710, train loss-2.1287, acc-0.4600, valid loss-2.1382, acc-0.3932, test loss-2.1390, acc-0.3880\n",
      "Iter-14720, train loss-2.1136, acc-0.4800, valid loss-2.1381, acc-0.3936, test loss-2.1389, acc-0.3882\n",
      "Iter-14730, train loss-2.1680, acc-0.3800, valid loss-2.1380, acc-0.3930, test loss-2.1388, acc-0.3883\n",
      "Iter-14740, train loss-2.1497, acc-0.3000, valid loss-2.1379, acc-0.3932, test loss-2.1387, acc-0.3883\n",
      "Iter-14750, train loss-2.1198, acc-0.4400, valid loss-2.1378, acc-0.3932, test loss-2.1386, acc-0.3884\n",
      "Iter-14760, train loss-2.1686, acc-0.2600, valid loss-2.1377, acc-0.3934, test loss-2.1385, acc-0.3887\n",
      "Iter-14770, train loss-2.1440, acc-0.4200, valid loss-2.1376, acc-0.3932, test loss-2.1384, acc-0.3887\n",
      "Iter-14780, train loss-2.1070, acc-0.4200, valid loss-2.1375, acc-0.3934, test loss-2.1383, acc-0.3886\n",
      "Iter-14790, train loss-2.1414, acc-0.4400, valid loss-2.1374, acc-0.3934, test loss-2.1382, acc-0.3888\n",
      "Iter-14800, train loss-2.1488, acc-0.3600, valid loss-2.1373, acc-0.3930, test loss-2.1381, acc-0.3885\n",
      "Iter-14810, train loss-2.1027, acc-0.4000, valid loss-2.1372, acc-0.3932, test loss-2.1380, acc-0.3885\n",
      "Iter-14820, train loss-2.1543, acc-0.3800, valid loss-2.1371, acc-0.3932, test loss-2.1379, acc-0.3890\n",
      "Iter-14830, train loss-2.1971, acc-0.2000, valid loss-2.1369, acc-0.3934, test loss-2.1377, acc-0.3887\n",
      "Iter-14840, train loss-2.1229, acc-0.3400, valid loss-2.1368, acc-0.3936, test loss-2.1376, acc-0.3887\n",
      "Iter-14850, train loss-2.1320, acc-0.4600, valid loss-2.1367, acc-0.3932, test loss-2.1375, acc-0.3887\n",
      "Iter-14860, train loss-2.1081, acc-0.4400, valid loss-2.1366, acc-0.3932, test loss-2.1374, acc-0.3890\n",
      "Iter-14870, train loss-2.1688, acc-0.3400, valid loss-2.1365, acc-0.3932, test loss-2.1373, acc-0.3891\n",
      "Iter-14880, train loss-2.1520, acc-0.3600, valid loss-2.1364, acc-0.3934, test loss-2.1372, acc-0.3890\n",
      "Iter-14890, train loss-2.1376, acc-0.4400, valid loss-2.1363, acc-0.3934, test loss-2.1371, acc-0.3890\n",
      "Iter-14900, train loss-2.1738, acc-0.2400, valid loss-2.1362, acc-0.3932, test loss-2.1370, acc-0.3891\n",
      "Iter-14910, train loss-2.1670, acc-0.3200, valid loss-2.1361, acc-0.3934, test loss-2.1369, acc-0.3893\n",
      "Iter-14920, train loss-2.1378, acc-0.4000, valid loss-2.1360, acc-0.3934, test loss-2.1368, acc-0.3892\n",
      "Iter-14930, train loss-2.1139, acc-0.3800, valid loss-2.1359, acc-0.3936, test loss-2.1367, acc-0.3895\n",
      "Iter-14940, train loss-2.1427, acc-0.4000, valid loss-2.1358, acc-0.3936, test loss-2.1366, acc-0.3899\n",
      "Iter-14950, train loss-2.2034, acc-0.2400, valid loss-2.1357, acc-0.3936, test loss-2.1365, acc-0.3900\n",
      "Iter-14960, train loss-2.1606, acc-0.3600, valid loss-2.1356, acc-0.3938, test loss-2.1364, acc-0.3901\n",
      "Iter-14970, train loss-2.1908, acc-0.3200, valid loss-2.1355, acc-0.3938, test loss-2.1363, acc-0.3902\n",
      "Iter-14980, train loss-2.0908, acc-0.4400, valid loss-2.1354, acc-0.3938, test loss-2.1362, acc-0.3902\n",
      "Iter-14990, train loss-2.1166, acc-0.4000, valid loss-2.1353, acc-0.3940, test loss-2.1361, acc-0.3903\n",
      "Iter-15000, train loss-2.1524, acc-0.3200, valid loss-2.1352, acc-0.3938, test loss-2.1360, acc-0.3901\n",
      "Iter-15010, train loss-2.1601, acc-0.3200, valid loss-2.1351, acc-0.3940, test loss-2.1359, acc-0.3901\n",
      "Iter-15020, train loss-2.1220, acc-0.4000, valid loss-2.1350, acc-0.3940, test loss-2.1358, acc-0.3901\n",
      "Iter-15030, train loss-2.1211, acc-0.4200, valid loss-2.1349, acc-0.3942, test loss-2.1357, acc-0.3901\n",
      "Iter-15040, train loss-2.1563, acc-0.2800, valid loss-2.1348, acc-0.3942, test loss-2.1356, acc-0.3900\n",
      "Iter-15050, train loss-2.1233, acc-0.4200, valid loss-2.1347, acc-0.3942, test loss-2.1355, acc-0.3903\n",
      "Iter-15060, train loss-2.1362, acc-0.3800, valid loss-2.1346, acc-0.3944, test loss-2.1353, acc-0.3904\n",
      "Iter-15070, train loss-2.1438, acc-0.3000, valid loss-2.1345, acc-0.3948, test loss-2.1352, acc-0.3902\n",
      "Iter-15080, train loss-2.1105, acc-0.4400, valid loss-2.1343, acc-0.3944, test loss-2.1351, acc-0.3903\n",
      "Iter-15090, train loss-2.1185, acc-0.4800, valid loss-2.1342, acc-0.3948, test loss-2.1350, acc-0.3905\n",
      "Iter-15100, train loss-2.1748, acc-0.3200, valid loss-2.1341, acc-0.3950, test loss-2.1349, acc-0.3907\n",
      "Iter-15110, train loss-2.1462, acc-0.3400, valid loss-2.1340, acc-0.3946, test loss-2.1348, acc-0.3908\n",
      "Iter-15120, train loss-2.1300, acc-0.4600, valid loss-2.1339, acc-0.3948, test loss-2.1347, acc-0.3906\n",
      "Iter-15130, train loss-2.1463, acc-0.4000, valid loss-2.1338, acc-0.3946, test loss-2.1346, acc-0.3907\n",
      "Iter-15140, train loss-2.1193, acc-0.4800, valid loss-2.1337, acc-0.3946, test loss-2.1345, acc-0.3908\n",
      "Iter-15150, train loss-2.1660, acc-0.3800, valid loss-2.1336, acc-0.3946, test loss-2.1344, acc-0.3908\n",
      "Iter-15160, train loss-2.1255, acc-0.4600, valid loss-2.1335, acc-0.3948, test loss-2.1343, acc-0.3910\n",
      "Iter-15170, train loss-2.1730, acc-0.3200, valid loss-2.1334, acc-0.3950, test loss-2.1342, acc-0.3912\n",
      "Iter-15180, train loss-2.1551, acc-0.3400, valid loss-2.1333, acc-0.3950, test loss-2.1341, acc-0.3909\n",
      "Iter-15190, train loss-2.1758, acc-0.3000, valid loss-2.1332, acc-0.3948, test loss-2.1340, acc-0.3905\n",
      "Iter-15200, train loss-2.1528, acc-0.3800, valid loss-2.1331, acc-0.3948, test loss-2.1339, acc-0.3910\n",
      "Iter-15210, train loss-2.1384, acc-0.4200, valid loss-2.1330, acc-0.3950, test loss-2.1338, acc-0.3908\n",
      "Iter-15220, train loss-2.1504, acc-0.4000, valid loss-2.1329, acc-0.3948, test loss-2.1337, acc-0.3906\n",
      "Iter-15230, train loss-2.1180, acc-0.4400, valid loss-2.1328, acc-0.3952, test loss-2.1336, acc-0.3908\n",
      "Iter-15240, train loss-2.1029, acc-0.4600, valid loss-2.1327, acc-0.3952, test loss-2.1335, acc-0.3907\n",
      "Iter-15250, train loss-2.1707, acc-0.4200, valid loss-2.1326, acc-0.3954, test loss-2.1334, acc-0.3909\n",
      "Iter-15260, train loss-2.1150, acc-0.3800, valid loss-2.1324, acc-0.3952, test loss-2.1332, acc-0.3909\n",
      "Iter-15270, train loss-2.1242, acc-0.4400, valid loss-2.1323, acc-0.3952, test loss-2.1331, acc-0.3910\n",
      "Iter-15280, train loss-2.1477, acc-0.3800, valid loss-2.1322, acc-0.3952, test loss-2.1330, acc-0.3909\n",
      "Iter-15290, train loss-2.1459, acc-0.4200, valid loss-2.1321, acc-0.3954, test loss-2.1329, acc-0.3910\n",
      "Iter-15300, train loss-2.1473, acc-0.3400, valid loss-2.1320, acc-0.3958, test loss-2.1328, acc-0.3911\n",
      "Iter-15310, train loss-2.1530, acc-0.4000, valid loss-2.1319, acc-0.3958, test loss-2.1327, acc-0.3913\n",
      "Iter-15320, train loss-2.1522, acc-0.3200, valid loss-2.1318, acc-0.3956, test loss-2.1326, acc-0.3911\n",
      "Iter-15330, train loss-2.1422, acc-0.3200, valid loss-2.1317, acc-0.3956, test loss-2.1325, acc-0.3912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-15340, train loss-2.1397, acc-0.3000, valid loss-2.1316, acc-0.3958, test loss-2.1324, acc-0.3914\n",
      "Iter-15350, train loss-2.1478, acc-0.3200, valid loss-2.1315, acc-0.3956, test loss-2.1323, acc-0.3914\n",
      "Iter-15360, train loss-2.1191, acc-0.4600, valid loss-2.1314, acc-0.3954, test loss-2.1322, acc-0.3911\n",
      "Iter-15370, train loss-2.1665, acc-0.3600, valid loss-2.1313, acc-0.3956, test loss-2.1321, acc-0.3913\n",
      "Iter-15380, train loss-2.1823, acc-0.2800, valid loss-2.1312, acc-0.3958, test loss-2.1320, acc-0.3913\n",
      "Iter-15390, train loss-2.1667, acc-0.4000, valid loss-2.1311, acc-0.3960, test loss-2.1319, acc-0.3914\n",
      "Iter-15400, train loss-2.1781, acc-0.3000, valid loss-2.1310, acc-0.3962, test loss-2.1318, acc-0.3916\n",
      "Iter-15410, train loss-2.1849, acc-0.2600, valid loss-2.1309, acc-0.3962, test loss-2.1317, acc-0.3917\n",
      "Iter-15420, train loss-2.1466, acc-0.3400, valid loss-2.1308, acc-0.3964, test loss-2.1316, acc-0.3914\n",
      "Iter-15430, train loss-2.1335, acc-0.4200, valid loss-2.1307, acc-0.3966, test loss-2.1315, acc-0.3914\n",
      "Iter-15440, train loss-2.1153, acc-0.4000, valid loss-2.1306, acc-0.3964, test loss-2.1314, acc-0.3913\n",
      "Iter-15450, train loss-2.1500, acc-0.3600, valid loss-2.1305, acc-0.3968, test loss-2.1313, acc-0.3914\n",
      "Iter-15460, train loss-2.0887, acc-0.4800, valid loss-2.1304, acc-0.3972, test loss-2.1312, acc-0.3914\n",
      "Iter-15470, train loss-2.1074, acc-0.4800, valid loss-2.1303, acc-0.3964, test loss-2.1311, acc-0.3913\n",
      "Iter-15480, train loss-2.0856, acc-0.5800, valid loss-2.1302, acc-0.3966, test loss-2.1310, acc-0.3915\n",
      "Iter-15490, train loss-2.1264, acc-0.3600, valid loss-2.1301, acc-0.3968, test loss-2.1309, acc-0.3913\n",
      "Iter-15500, train loss-2.1272, acc-0.3600, valid loss-2.1299, acc-0.3972, test loss-2.1308, acc-0.3911\n",
      "Iter-15510, train loss-2.1480, acc-0.4400, valid loss-2.1298, acc-0.3974, test loss-2.1307, acc-0.3914\n",
      "Iter-15520, train loss-2.1202, acc-0.4600, valid loss-2.1297, acc-0.3972, test loss-2.1305, acc-0.3914\n",
      "Iter-15530, train loss-2.1112, acc-0.5200, valid loss-2.1296, acc-0.3972, test loss-2.1304, acc-0.3917\n",
      "Iter-15540, train loss-2.1619, acc-0.4000, valid loss-2.1295, acc-0.3972, test loss-2.1303, acc-0.3919\n",
      "Iter-15550, train loss-2.1301, acc-0.3600, valid loss-2.1294, acc-0.3976, test loss-2.1302, acc-0.3924\n",
      "Iter-15560, train loss-2.1237, acc-0.4200, valid loss-2.1293, acc-0.3972, test loss-2.1301, acc-0.3923\n",
      "Iter-15570, train loss-2.0760, acc-0.4600, valid loss-2.1292, acc-0.3972, test loss-2.1300, acc-0.3924\n",
      "Iter-15580, train loss-2.1568, acc-0.3200, valid loss-2.1291, acc-0.3972, test loss-2.1299, acc-0.3925\n",
      "Iter-15590, train loss-2.1235, acc-0.4000, valid loss-2.1290, acc-0.3970, test loss-2.1298, acc-0.3921\n",
      "Iter-15600, train loss-2.1261, acc-0.4200, valid loss-2.1289, acc-0.3970, test loss-2.1297, acc-0.3920\n",
      "Iter-15610, train loss-2.1166, acc-0.4400, valid loss-2.1288, acc-0.3970, test loss-2.1296, acc-0.3925\n",
      "Iter-15620, train loss-2.1089, acc-0.4200, valid loss-2.1287, acc-0.3966, test loss-2.1295, acc-0.3925\n",
      "Iter-15630, train loss-2.1705, acc-0.2800, valid loss-2.1286, acc-0.3968, test loss-2.1294, acc-0.3924\n",
      "Iter-15640, train loss-2.1400, acc-0.2800, valid loss-2.1285, acc-0.3970, test loss-2.1293, acc-0.3925\n",
      "Iter-15650, train loss-2.1603, acc-0.2800, valid loss-2.1284, acc-0.3966, test loss-2.1292, acc-0.3926\n",
      "Iter-15660, train loss-2.1000, acc-0.4400, valid loss-2.1283, acc-0.3968, test loss-2.1291, acc-0.3925\n",
      "Iter-15670, train loss-2.1753, acc-0.3800, valid loss-2.1282, acc-0.3972, test loss-2.1290, acc-0.3925\n",
      "Iter-15680, train loss-2.1495, acc-0.3800, valid loss-2.1281, acc-0.3972, test loss-2.1289, acc-0.3926\n",
      "Iter-15690, train loss-2.1468, acc-0.3800, valid loss-2.1280, acc-0.3974, test loss-2.1288, acc-0.3928\n",
      "Iter-15700, train loss-2.1551, acc-0.3000, valid loss-2.1279, acc-0.3976, test loss-2.1287, acc-0.3929\n",
      "Iter-15710, train loss-2.1229, acc-0.4000, valid loss-2.1277, acc-0.3976, test loss-2.1286, acc-0.3929\n",
      "Iter-15720, train loss-2.1199, acc-0.4200, valid loss-2.1276, acc-0.3976, test loss-2.1285, acc-0.3929\n",
      "Iter-15730, train loss-2.1295, acc-0.4400, valid loss-2.1275, acc-0.3978, test loss-2.1283, acc-0.3926\n",
      "Iter-15740, train loss-2.1408, acc-0.3600, valid loss-2.1274, acc-0.3976, test loss-2.1282, acc-0.3925\n",
      "Iter-15750, train loss-2.1334, acc-0.3600, valid loss-2.1273, acc-0.3978, test loss-2.1281, acc-0.3926\n",
      "Iter-15760, train loss-2.1318, acc-0.3600, valid loss-2.1272, acc-0.3986, test loss-2.1280, acc-0.3928\n",
      "Iter-15770, train loss-2.1257, acc-0.4400, valid loss-2.1271, acc-0.3986, test loss-2.1279, acc-0.3929\n",
      "Iter-15780, train loss-2.1000, acc-0.4600, valid loss-2.1270, acc-0.3986, test loss-2.1278, acc-0.3929\n",
      "Iter-15790, train loss-2.1373, acc-0.3600, valid loss-2.1269, acc-0.3986, test loss-2.1277, acc-0.3929\n",
      "Iter-15800, train loss-2.1155, acc-0.4000, valid loss-2.1268, acc-0.3984, test loss-2.1276, acc-0.3931\n",
      "Iter-15810, train loss-2.1648, acc-0.3600, valid loss-2.1267, acc-0.3986, test loss-2.1275, acc-0.3929\n",
      "Iter-15820, train loss-2.1214, acc-0.3600, valid loss-2.1266, acc-0.3990, test loss-2.1274, acc-0.3927\n",
      "Iter-15830, train loss-2.1284, acc-0.4600, valid loss-2.1265, acc-0.3990, test loss-2.1273, acc-0.3929\n",
      "Iter-15840, train loss-2.1700, acc-0.3000, valid loss-2.1264, acc-0.3992, test loss-2.1272, acc-0.3930\n",
      "Iter-15850, train loss-2.1642, acc-0.3200, valid loss-2.1263, acc-0.3988, test loss-2.1271, acc-0.3930\n",
      "Iter-15860, train loss-2.1356, acc-0.4000, valid loss-2.1262, acc-0.3990, test loss-2.1270, acc-0.3932\n",
      "Iter-15870, train loss-2.1561, acc-0.3200, valid loss-2.1261, acc-0.3992, test loss-2.1269, acc-0.3933\n",
      "Iter-15880, train loss-2.1483, acc-0.3600, valid loss-2.1260, acc-0.3994, test loss-2.1268, acc-0.3933\n",
      "Iter-15890, train loss-2.1233, acc-0.4000, valid loss-2.1259, acc-0.3992, test loss-2.1267, acc-0.3933\n",
      "Iter-15900, train loss-2.1295, acc-0.4600, valid loss-2.1258, acc-0.3994, test loss-2.1266, acc-0.3931\n",
      "Iter-15910, train loss-2.1481, acc-0.4200, valid loss-2.1257, acc-0.3994, test loss-2.1265, acc-0.3930\n",
      "Iter-15920, train loss-2.0958, acc-0.4600, valid loss-2.1256, acc-0.3994, test loss-2.1264, acc-0.3933\n",
      "Iter-15930, train loss-2.1462, acc-0.3400, valid loss-2.1255, acc-0.3996, test loss-2.1263, acc-0.3935\n",
      "Iter-15940, train loss-2.1055, acc-0.3800, valid loss-2.1253, acc-0.3996, test loss-2.1262, acc-0.3936\n",
      "Iter-15950, train loss-2.0695, acc-0.5000, valid loss-2.1252, acc-0.3994, test loss-2.1261, acc-0.3934\n",
      "Iter-15960, train loss-2.1225, acc-0.3600, valid loss-2.1251, acc-0.3992, test loss-2.1259, acc-0.3935\n",
      "Iter-15970, train loss-2.1557, acc-0.2800, valid loss-2.1250, acc-0.3992, test loss-2.1258, acc-0.3936\n",
      "Iter-15980, train loss-2.1549, acc-0.3200, valid loss-2.1249, acc-0.3994, test loss-2.1257, acc-0.3934\n",
      "Iter-15990, train loss-2.1415, acc-0.4200, valid loss-2.1248, acc-0.3994, test loss-2.1256, acc-0.3935\n",
      "Iter-16000, train loss-2.1205, acc-0.4200, valid loss-2.1247, acc-0.3998, test loss-2.1255, acc-0.3930\n",
      "Iter-16010, train loss-2.1280, acc-0.4200, valid loss-2.1246, acc-0.3998, test loss-2.1254, acc-0.3930\n",
      "Iter-16020, train loss-2.1012, acc-0.5000, valid loss-2.1245, acc-0.3998, test loss-2.1253, acc-0.3932\n",
      "Iter-16030, train loss-2.1360, acc-0.4000, valid loss-2.1244, acc-0.4000, test loss-2.1252, acc-0.3935\n",
      "Iter-16040, train loss-2.1430, acc-0.3600, valid loss-2.1243, acc-0.4000, test loss-2.1251, acc-0.3936\n",
      "Iter-16050, train loss-2.0868, acc-0.4200, valid loss-2.1242, acc-0.4000, test loss-2.1250, acc-0.3936\n",
      "Iter-16060, train loss-2.1527, acc-0.3600, valid loss-2.1241, acc-0.4000, test loss-2.1249, acc-0.3937\n",
      "Iter-16070, train loss-2.1557, acc-0.3600, valid loss-2.1240, acc-0.3996, test loss-2.1248, acc-0.3939\n",
      "Iter-16080, train loss-2.1364, acc-0.4200, valid loss-2.1239, acc-0.3996, test loss-2.1247, acc-0.3937\n",
      "Iter-16090, train loss-2.1549, acc-0.3200, valid loss-2.1238, acc-0.3998, test loss-2.1246, acc-0.3939\n",
      "Iter-16100, train loss-2.1649, acc-0.3200, valid loss-2.1237, acc-0.3996, test loss-2.1245, acc-0.3940\n",
      "Iter-16110, train loss-2.1255, acc-0.3200, valid loss-2.1236, acc-0.3996, test loss-2.1244, acc-0.3939\n",
      "Iter-16120, train loss-2.1075, acc-0.4200, valid loss-2.1235, acc-0.4000, test loss-2.1243, acc-0.3940\n",
      "Iter-16130, train loss-2.0824, acc-0.5000, valid loss-2.1234, acc-0.4000, test loss-2.1242, acc-0.3944\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16140, train loss-2.1096, acc-0.3600, valid loss-2.1233, acc-0.4002, test loss-2.1241, acc-0.3943\n",
      "Iter-16150, train loss-2.1351, acc-0.3800, valid loss-2.1232, acc-0.3996, test loss-2.1240, acc-0.3942\n",
      "Iter-16160, train loss-2.1184, acc-0.4200, valid loss-2.1231, acc-0.3998, test loss-2.1239, acc-0.3945\n",
      "Iter-16170, train loss-2.1576, acc-0.3000, valid loss-2.1230, acc-0.4002, test loss-2.1238, acc-0.3944\n",
      "Iter-16180, train loss-2.1221, acc-0.3600, valid loss-2.1229, acc-0.4004, test loss-2.1237, acc-0.3942\n",
      "Iter-16190, train loss-2.1076, acc-0.4200, valid loss-2.1228, acc-0.4006, test loss-2.1236, acc-0.3945\n",
      "Iter-16200, train loss-2.1162, acc-0.3400, valid loss-2.1227, acc-0.4006, test loss-2.1235, acc-0.3945\n",
      "Iter-16210, train loss-2.1466, acc-0.4000, valid loss-2.1226, acc-0.4006, test loss-2.1234, acc-0.3944\n",
      "Iter-16220, train loss-2.1653, acc-0.3000, valid loss-2.1225, acc-0.4006, test loss-2.1233, acc-0.3943\n",
      "Iter-16230, train loss-2.1454, acc-0.3600, valid loss-2.1224, acc-0.4010, test loss-2.1232, acc-0.3944\n",
      "Iter-16240, train loss-2.1293, acc-0.3600, valid loss-2.1223, acc-0.4010, test loss-2.1231, acc-0.3945\n",
      "Iter-16250, train loss-2.1428, acc-0.4200, valid loss-2.1221, acc-0.4010, test loss-2.1229, acc-0.3944\n",
      "Iter-16260, train loss-2.1023, acc-0.4400, valid loss-2.1220, acc-0.4014, test loss-2.1228, acc-0.3946\n",
      "Iter-16270, train loss-2.1058, acc-0.4400, valid loss-2.1220, acc-0.4014, test loss-2.1227, acc-0.3947\n",
      "Iter-16280, train loss-2.1003, acc-0.4600, valid loss-2.1219, acc-0.4018, test loss-2.1227, acc-0.3946\n",
      "Iter-16290, train loss-2.1218, acc-0.4000, valid loss-2.1218, acc-0.4016, test loss-2.1226, acc-0.3948\n",
      "Iter-16300, train loss-2.0947, acc-0.3800, valid loss-2.1217, acc-0.4014, test loss-2.1225, acc-0.3947\n",
      "Iter-16310, train loss-2.0925, acc-0.4000, valid loss-2.1215, acc-0.4014, test loss-2.1223, acc-0.3947\n",
      "Iter-16320, train loss-2.1332, acc-0.3200, valid loss-2.1214, acc-0.4016, test loss-2.1222, acc-0.3948\n",
      "Iter-16330, train loss-2.1084, acc-0.4600, valid loss-2.1213, acc-0.4018, test loss-2.1221, acc-0.3947\n",
      "Iter-16340, train loss-2.1443, acc-0.3000, valid loss-2.1212, acc-0.4014, test loss-2.1220, acc-0.3951\n",
      "Iter-16350, train loss-2.1154, acc-0.4000, valid loss-2.1211, acc-0.4016, test loss-2.1219, acc-0.3951\n",
      "Iter-16360, train loss-2.0747, acc-0.5600, valid loss-2.1210, acc-0.4016, test loss-2.1218, acc-0.3951\n",
      "Iter-16370, train loss-2.1343, acc-0.4200, valid loss-2.1209, acc-0.4018, test loss-2.1217, acc-0.3953\n",
      "Iter-16380, train loss-2.1630, acc-0.3800, valid loss-2.1208, acc-0.4018, test loss-2.1216, acc-0.3954\n",
      "Iter-16390, train loss-2.1120, acc-0.4000, valid loss-2.1207, acc-0.4016, test loss-2.1215, acc-0.3954\n",
      "Iter-16400, train loss-2.0838, acc-0.5000, valid loss-2.1206, acc-0.4016, test loss-2.1214, acc-0.3953\n",
      "Iter-16410, train loss-2.1008, acc-0.4600, valid loss-2.1205, acc-0.4016, test loss-2.1213, acc-0.3953\n",
      "Iter-16420, train loss-2.0785, acc-0.5000, valid loss-2.1204, acc-0.4016, test loss-2.1212, acc-0.3954\n",
      "Iter-16430, train loss-2.1157, acc-0.4600, valid loss-2.1203, acc-0.4016, test loss-2.1211, acc-0.3954\n",
      "Iter-16440, train loss-2.0883, acc-0.4800, valid loss-2.1202, acc-0.4020, test loss-2.1210, acc-0.3954\n",
      "Iter-16450, train loss-2.0988, acc-0.4000, valid loss-2.1201, acc-0.4022, test loss-2.1209, acc-0.3957\n",
      "Iter-16460, train loss-2.0901, acc-0.4200, valid loss-2.1200, acc-0.4022, test loss-2.1208, acc-0.3957\n",
      "Iter-16470, train loss-2.1701, acc-0.3600, valid loss-2.1199, acc-0.4026, test loss-2.1207, acc-0.3959\n",
      "Iter-16480, train loss-2.1151, acc-0.4200, valid loss-2.1198, acc-0.4024, test loss-2.1206, acc-0.3958\n",
      "Iter-16490, train loss-2.1312, acc-0.3400, valid loss-2.1197, acc-0.4026, test loss-2.1205, acc-0.3959\n",
      "Iter-16500, train loss-2.1408, acc-0.3800, valid loss-2.1196, acc-0.4022, test loss-2.1204, acc-0.3961\n",
      "Iter-16510, train loss-2.1573, acc-0.3000, valid loss-2.1195, acc-0.4028, test loss-2.1203, acc-0.3959\n",
      "Iter-16520, train loss-2.1102, acc-0.4200, valid loss-2.1194, acc-0.4026, test loss-2.1202, acc-0.3959\n",
      "Iter-16530, train loss-2.1262, acc-0.4400, valid loss-2.1193, acc-0.4026, test loss-2.1201, acc-0.3962\n",
      "Iter-16540, train loss-2.1186, acc-0.4000, valid loss-2.1192, acc-0.4026, test loss-2.1200, acc-0.3962\n",
      "Iter-16550, train loss-2.1126, acc-0.4000, valid loss-2.1191, acc-0.4026, test loss-2.1199, acc-0.3965\n",
      "Iter-16560, train loss-2.1072, acc-0.3800, valid loss-2.1190, acc-0.4026, test loss-2.1198, acc-0.3966\n",
      "Iter-16570, train loss-2.0993, acc-0.4400, valid loss-2.1189, acc-0.4026, test loss-2.1197, acc-0.3965\n",
      "Iter-16580, train loss-2.0948, acc-0.3800, valid loss-2.1188, acc-0.4026, test loss-2.1196, acc-0.3964\n",
      "Iter-16590, train loss-2.1281, acc-0.3800, valid loss-2.1187, acc-0.4028, test loss-2.1195, acc-0.3970\n",
      "Iter-16600, train loss-2.0973, acc-0.4200, valid loss-2.1186, acc-0.4028, test loss-2.1194, acc-0.3968\n",
      "Iter-16610, train loss-2.1118, acc-0.4800, valid loss-2.1185, acc-0.4028, test loss-2.1193, acc-0.3968\n",
      "Iter-16620, train loss-2.1889, acc-0.2600, valid loss-2.1184, acc-0.4028, test loss-2.1192, acc-0.3969\n",
      "Iter-16630, train loss-2.1280, acc-0.3200, valid loss-2.1183, acc-0.4026, test loss-2.1191, acc-0.3972\n",
      "Iter-16640, train loss-2.1443, acc-0.3400, valid loss-2.1182, acc-0.4026, test loss-2.1190, acc-0.3974\n",
      "Iter-16650, train loss-2.1274, acc-0.3800, valid loss-2.1181, acc-0.4026, test loss-2.1189, acc-0.3974\n",
      "Iter-16660, train loss-2.1415, acc-0.3600, valid loss-2.1180, acc-0.4028, test loss-2.1188, acc-0.3974\n",
      "Iter-16670, train loss-2.0907, acc-0.4400, valid loss-2.1179, acc-0.4028, test loss-2.1187, acc-0.3970\n",
      "Iter-16680, train loss-2.1138, acc-0.4400, valid loss-2.1178, acc-0.4032, test loss-2.1186, acc-0.3970\n",
      "Iter-16690, train loss-2.1043, acc-0.4600, valid loss-2.1177, acc-0.4032, test loss-2.1185, acc-0.3971\n",
      "Iter-16700, train loss-2.1290, acc-0.4600, valid loss-2.1176, acc-0.4032, test loss-2.1184, acc-0.3972\n",
      "Iter-16710, train loss-2.1152, acc-0.4000, valid loss-2.1175, acc-0.4032, test loss-2.1183, acc-0.3974\n",
      "Iter-16720, train loss-2.0958, acc-0.4200, valid loss-2.1174, acc-0.4030, test loss-2.1182, acc-0.3976\n",
      "Iter-16730, train loss-2.1780, acc-0.2600, valid loss-2.1173, acc-0.4030, test loss-2.1181, acc-0.3975\n",
      "Iter-16740, train loss-2.0924, acc-0.4600, valid loss-2.1172, acc-0.4032, test loss-2.1180, acc-0.3977\n",
      "Iter-16750, train loss-2.1341, acc-0.3600, valid loss-2.1171, acc-0.4034, test loss-2.1179, acc-0.3978\n",
      "Iter-16760, train loss-2.0956, acc-0.5000, valid loss-2.1170, acc-0.4036, test loss-2.1178, acc-0.3978\n",
      "Iter-16770, train loss-2.1163, acc-0.4200, valid loss-2.1169, acc-0.4038, test loss-2.1177, acc-0.3978\n",
      "Iter-16780, train loss-2.1276, acc-0.3800, valid loss-2.1168, acc-0.4036, test loss-2.1176, acc-0.3981\n",
      "Iter-16790, train loss-2.1205, acc-0.3400, valid loss-2.1167, acc-0.4042, test loss-2.1175, acc-0.3978\n",
      "Iter-16800, train loss-2.1141, acc-0.4400, valid loss-2.1166, acc-0.4040, test loss-2.1174, acc-0.3980\n",
      "Iter-16810, train loss-2.1001, acc-0.4800, valid loss-2.1165, acc-0.4040, test loss-2.1173, acc-0.3980\n",
      "Iter-16820, train loss-2.1236, acc-0.2600, valid loss-2.1164, acc-0.4042, test loss-2.1172, acc-0.3979\n",
      "Iter-16830, train loss-2.1074, acc-0.3800, valid loss-2.1163, acc-0.4042, test loss-2.1171, acc-0.3979\n",
      "Iter-16840, train loss-2.1486, acc-0.4000, valid loss-2.1162, acc-0.4042, test loss-2.1170, acc-0.3979\n",
      "Iter-16850, train loss-2.1206, acc-0.3800, valid loss-2.1161, acc-0.4044, test loss-2.1169, acc-0.3980\n",
      "Iter-16860, train loss-2.1170, acc-0.4200, valid loss-2.1160, acc-0.4046, test loss-2.1168, acc-0.3982\n",
      "Iter-16870, train loss-2.0788, acc-0.5600, valid loss-2.1159, acc-0.4046, test loss-2.1167, acc-0.3984\n",
      "Iter-16880, train loss-2.0829, acc-0.4400, valid loss-2.1158, acc-0.4046, test loss-2.1166, acc-0.3982\n",
      "Iter-16890, train loss-2.1424, acc-0.2600, valid loss-2.1157, acc-0.4046, test loss-2.1165, acc-0.3983\n",
      "Iter-16900, train loss-2.1064, acc-0.4200, valid loss-2.1156, acc-0.4048, test loss-2.1164, acc-0.3984\n",
      "Iter-16910, train loss-2.1554, acc-0.2200, valid loss-2.1155, acc-0.4050, test loss-2.1163, acc-0.3982\n",
      "Iter-16920, train loss-2.1330, acc-0.4000, valid loss-2.1154, acc-0.4048, test loss-2.1162, acc-0.3985\n",
      "Iter-16930, train loss-2.0725, acc-0.4400, valid loss-2.1153, acc-0.4050, test loss-2.1161, acc-0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-16940, train loss-2.1480, acc-0.3200, valid loss-2.1152, acc-0.4048, test loss-2.1160, acc-0.3985\n",
      "Iter-16950, train loss-2.1337, acc-0.3200, valid loss-2.1151, acc-0.4046, test loss-2.1159, acc-0.3985\n",
      "Iter-16960, train loss-2.1242, acc-0.3600, valid loss-2.1149, acc-0.4048, test loss-2.1158, acc-0.3986\n",
      "Iter-16970, train loss-2.1557, acc-0.3200, valid loss-2.1148, acc-0.4052, test loss-2.1157, acc-0.3984\n",
      "Iter-16980, train loss-2.0972, acc-0.4200, valid loss-2.1147, acc-0.4054, test loss-2.1156, acc-0.3987\n",
      "Iter-16990, train loss-2.1461, acc-0.4000, valid loss-2.1146, acc-0.4054, test loss-2.1155, acc-0.3988\n",
      "Iter-17000, train loss-2.0747, acc-0.4400, valid loss-2.1145, acc-0.4052, test loss-2.1154, acc-0.3988\n",
      "Iter-17010, train loss-2.1851, acc-0.3400, valid loss-2.1144, acc-0.4052, test loss-2.1152, acc-0.3989\n",
      "Iter-17020, train loss-2.1423, acc-0.3800, valid loss-2.1143, acc-0.4052, test loss-2.1151, acc-0.3988\n",
      "Iter-17030, train loss-2.0883, acc-0.4600, valid loss-2.1142, acc-0.4052, test loss-2.1150, acc-0.3988\n",
      "Iter-17040, train loss-2.1919, acc-0.3000, valid loss-2.1141, acc-0.4054, test loss-2.1149, acc-0.3992\n",
      "Iter-17050, train loss-2.0968, acc-0.4800, valid loss-2.1140, acc-0.4054, test loss-2.1148, acc-0.3991\n",
      "Iter-17060, train loss-2.1033, acc-0.4600, valid loss-2.1139, acc-0.4052, test loss-2.1147, acc-0.3990\n",
      "Iter-17070, train loss-2.1143, acc-0.3600, valid loss-2.1138, acc-0.4052, test loss-2.1146, acc-0.3994\n",
      "Iter-17080, train loss-2.1121, acc-0.4200, valid loss-2.1137, acc-0.4052, test loss-2.1145, acc-0.3992\n",
      "Iter-17090, train loss-2.1569, acc-0.3400, valid loss-2.1136, acc-0.4054, test loss-2.1144, acc-0.3997\n",
      "Iter-17100, train loss-2.1276, acc-0.3200, valid loss-2.1135, acc-0.4054, test loss-2.1143, acc-0.3998\n",
      "Iter-17110, train loss-2.1039, acc-0.5000, valid loss-2.1134, acc-0.4054, test loss-2.1142, acc-0.4001\n",
      "Iter-17120, train loss-2.1362, acc-0.4000, valid loss-2.1133, acc-0.4054, test loss-2.1141, acc-0.3999\n",
      "Iter-17130, train loss-2.1161, acc-0.4200, valid loss-2.1132, acc-0.4054, test loss-2.1140, acc-0.4005\n",
      "Iter-17140, train loss-2.1323, acc-0.3600, valid loss-2.1131, acc-0.4054, test loss-2.1139, acc-0.4002\n",
      "Iter-17150, train loss-2.1264, acc-0.3800, valid loss-2.1130, acc-0.4056, test loss-2.1138, acc-0.4000\n",
      "Iter-17160, train loss-2.1127, acc-0.5000, valid loss-2.1129, acc-0.4060, test loss-2.1137, acc-0.3999\n",
      "Iter-17170, train loss-2.0883, acc-0.4600, valid loss-2.1128, acc-0.4056, test loss-2.1136, acc-0.3999\n",
      "Iter-17180, train loss-2.1228, acc-0.3800, valid loss-2.1127, acc-0.4058, test loss-2.1135, acc-0.4000\n",
      "Iter-17190, train loss-2.0957, acc-0.4400, valid loss-2.1126, acc-0.4056, test loss-2.1134, acc-0.3998\n",
      "Iter-17200, train loss-2.0945, acc-0.4000, valid loss-2.1125, acc-0.4058, test loss-2.1133, acc-0.4000\n",
      "Iter-17210, train loss-2.0790, acc-0.4600, valid loss-2.1124, acc-0.4058, test loss-2.1132, acc-0.3997\n",
      "Iter-17220, train loss-2.1557, acc-0.3600, valid loss-2.1123, acc-0.4058, test loss-2.1131, acc-0.4000\n",
      "Iter-17230, train loss-2.1361, acc-0.3800, valid loss-2.1122, acc-0.4058, test loss-2.1130, acc-0.4002\n",
      "Iter-17240, train loss-2.1468, acc-0.3200, valid loss-2.1121, acc-0.4064, test loss-2.1129, acc-0.3999\n",
      "Iter-17250, train loss-2.1213, acc-0.3400, valid loss-2.1120, acc-0.4062, test loss-2.1128, acc-0.4001\n",
      "Iter-17260, train loss-2.0486, acc-0.5000, valid loss-2.1119, acc-0.4062, test loss-2.1127, acc-0.4003\n",
      "Iter-17270, train loss-2.1114, acc-0.3800, valid loss-2.1118, acc-0.4062, test loss-2.1127, acc-0.4003\n",
      "Iter-17280, train loss-2.0871, acc-0.4400, valid loss-2.1117, acc-0.4060, test loss-2.1125, acc-0.4004\n",
      "Iter-17290, train loss-2.1114, acc-0.4200, valid loss-2.1116, acc-0.4064, test loss-2.1124, acc-0.4004\n",
      "Iter-17300, train loss-2.0977, acc-0.4000, valid loss-2.1115, acc-0.4066, test loss-2.1123, acc-0.4006\n",
      "Iter-17310, train loss-2.1353, acc-0.3200, valid loss-2.1114, acc-0.4068, test loss-2.1122, acc-0.4006\n",
      "Iter-17320, train loss-2.1616, acc-0.3400, valid loss-2.1113, acc-0.4068, test loss-2.1121, acc-0.4007\n",
      "Iter-17330, train loss-2.1286, acc-0.3800, valid loss-2.1112, acc-0.4068, test loss-2.1120, acc-0.4007\n",
      "Iter-17340, train loss-2.1369, acc-0.3800, valid loss-2.1111, acc-0.4064, test loss-2.1119, acc-0.4008\n",
      "Iter-17350, train loss-2.0743, acc-0.4600, valid loss-2.1110, acc-0.4062, test loss-2.1118, acc-0.4006\n",
      "Iter-17360, train loss-2.1303, acc-0.3600, valid loss-2.1109, acc-0.4060, test loss-2.1117, acc-0.4003\n",
      "Iter-17370, train loss-2.1085, acc-0.4000, valid loss-2.1108, acc-0.4064, test loss-2.1116, acc-0.4005\n",
      "Iter-17380, train loss-2.1207, acc-0.4400, valid loss-2.1107, acc-0.4062, test loss-2.1115, acc-0.4007\n",
      "Iter-17390, train loss-2.1417, acc-0.3600, valid loss-2.1106, acc-0.4068, test loss-2.1114, acc-0.4010\n",
      "Iter-17400, train loss-2.0875, acc-0.4400, valid loss-2.1105, acc-0.4070, test loss-2.1113, acc-0.4012\n",
      "Iter-17410, train loss-2.1094, acc-0.4000, valid loss-2.1104, acc-0.4068, test loss-2.1112, acc-0.4013\n",
      "Iter-17420, train loss-2.1160, acc-0.3600, valid loss-2.1103, acc-0.4068, test loss-2.1111, acc-0.4012\n",
      "Iter-17430, train loss-2.0810, acc-0.5000, valid loss-2.1102, acc-0.4068, test loss-2.1110, acc-0.4012\n",
      "Iter-17440, train loss-2.1633, acc-0.2800, valid loss-2.1101, acc-0.4066, test loss-2.1109, acc-0.4012\n",
      "Iter-17450, train loss-2.1667, acc-0.3400, valid loss-2.1100, acc-0.4070, test loss-2.1108, acc-0.4014\n",
      "Iter-17460, train loss-2.1255, acc-0.3400, valid loss-2.1099, acc-0.4066, test loss-2.1107, acc-0.4014\n",
      "Iter-17470, train loss-2.1462, acc-0.2600, valid loss-2.1098, acc-0.4064, test loss-2.1106, acc-0.4015\n",
      "Iter-17480, train loss-2.1714, acc-0.2400, valid loss-2.1097, acc-0.4064, test loss-2.1105, acc-0.4016\n",
      "Iter-17490, train loss-2.0916, acc-0.5000, valid loss-2.1096, acc-0.4068, test loss-2.1104, acc-0.4018\n",
      "Iter-17500, train loss-2.1687, acc-0.3000, valid loss-2.1095, acc-0.4066, test loss-2.1103, acc-0.4019\n",
      "Iter-17510, train loss-2.1058, acc-0.4200, valid loss-2.1094, acc-0.4066, test loss-2.1102, acc-0.4015\n",
      "Iter-17520, train loss-2.1284, acc-0.3800, valid loss-2.1093, acc-0.4064, test loss-2.1102, acc-0.4017\n",
      "Iter-17530, train loss-2.1195, acc-0.4000, valid loss-2.1092, acc-0.4068, test loss-2.1101, acc-0.4016\n",
      "Iter-17540, train loss-2.0794, acc-0.4400, valid loss-2.1091, acc-0.4068, test loss-2.1099, acc-0.4018\n",
      "Iter-17550, train loss-2.1342, acc-0.3000, valid loss-2.1090, acc-0.4068, test loss-2.1099, acc-0.4018\n",
      "Iter-17560, train loss-2.1582, acc-0.3400, valid loss-2.1089, acc-0.4070, test loss-2.1098, acc-0.4019\n",
      "Iter-17570, train loss-2.0912, acc-0.4400, valid loss-2.1088, acc-0.4072, test loss-2.1097, acc-0.4020\n",
      "Iter-17580, train loss-2.1409, acc-0.4200, valid loss-2.1088, acc-0.4074, test loss-2.1096, acc-0.4021\n",
      "Iter-17590, train loss-2.1057, acc-0.4000, valid loss-2.1087, acc-0.4078, test loss-2.1095, acc-0.4020\n",
      "Iter-17600, train loss-2.1102, acc-0.3400, valid loss-2.1086, acc-0.4074, test loss-2.1094, acc-0.4021\n",
      "Iter-17610, train loss-2.1018, acc-0.5200, valid loss-2.1085, acc-0.4080, test loss-2.1093, acc-0.4022\n",
      "Iter-17620, train loss-2.1318, acc-0.4000, valid loss-2.1084, acc-0.4080, test loss-2.1092, acc-0.4023\n",
      "Iter-17630, train loss-2.0822, acc-0.5000, valid loss-2.1083, acc-0.4080, test loss-2.1091, acc-0.4023\n",
      "Iter-17640, train loss-2.1597, acc-0.4000, valid loss-2.1082, acc-0.4080, test loss-2.1090, acc-0.4023\n",
      "Iter-17650, train loss-2.0816, acc-0.5000, valid loss-2.1081, acc-0.4078, test loss-2.1089, acc-0.4025\n",
      "Iter-17660, train loss-2.1201, acc-0.4000, valid loss-2.1079, acc-0.4078, test loss-2.1088, acc-0.4026\n",
      "Iter-17670, train loss-2.1040, acc-0.4200, valid loss-2.1079, acc-0.4084, test loss-2.1087, acc-0.4024\n",
      "Iter-17680, train loss-2.1326, acc-0.3600, valid loss-2.1078, acc-0.4084, test loss-2.1086, acc-0.4024\n",
      "Iter-17690, train loss-2.1125, acc-0.4000, valid loss-2.1077, acc-0.4082, test loss-2.1085, acc-0.4025\n",
      "Iter-17700, train loss-2.0931, acc-0.5400, valid loss-2.1076, acc-0.4078, test loss-2.1084, acc-0.4028\n",
      "Iter-17710, train loss-2.1261, acc-0.4200, valid loss-2.1074, acc-0.4082, test loss-2.1083, acc-0.4029\n",
      "Iter-17720, train loss-2.0357, acc-0.5600, valid loss-2.1073, acc-0.4080, test loss-2.1082, acc-0.4031\n",
      "Iter-17730, train loss-2.1058, acc-0.4200, valid loss-2.1072, acc-0.4078, test loss-2.1081, acc-0.4027\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-17740, train loss-2.1376, acc-0.3200, valid loss-2.1071, acc-0.4084, test loss-2.1080, acc-0.4031\n",
      "Iter-17750, train loss-2.1330, acc-0.4000, valid loss-2.1070, acc-0.4082, test loss-2.1079, acc-0.4030\n",
      "Iter-17760, train loss-2.0772, acc-0.4000, valid loss-2.1069, acc-0.4082, test loss-2.1078, acc-0.4030\n",
      "Iter-17770, train loss-2.0343, acc-0.5000, valid loss-2.1068, acc-0.4082, test loss-2.1077, acc-0.4031\n",
      "Iter-17780, train loss-2.0879, acc-0.4200, valid loss-2.1067, acc-0.4082, test loss-2.1076, acc-0.4033\n",
      "Iter-17790, train loss-2.1442, acc-0.3600, valid loss-2.1066, acc-0.4080, test loss-2.1075, acc-0.4034\n",
      "Iter-17800, train loss-2.1258, acc-0.3400, valid loss-2.1065, acc-0.4082, test loss-2.1074, acc-0.4033\n",
      "Iter-17810, train loss-2.1283, acc-0.3800, valid loss-2.1064, acc-0.4082, test loss-2.1073, acc-0.4034\n",
      "Iter-17820, train loss-2.1710, acc-0.3600, valid loss-2.1063, acc-0.4082, test loss-2.1072, acc-0.4033\n",
      "Iter-17830, train loss-2.1199, acc-0.3800, valid loss-2.1062, acc-0.4082, test loss-2.1070, acc-0.4034\n",
      "Iter-17840, train loss-2.1336, acc-0.3400, valid loss-2.1061, acc-0.4080, test loss-2.1069, acc-0.4034\n",
      "Iter-17850, train loss-2.0874, acc-0.5000, valid loss-2.1060, acc-0.4082, test loss-2.1069, acc-0.4035\n",
      "Iter-17860, train loss-2.1276, acc-0.3200, valid loss-2.1059, acc-0.4082, test loss-2.1067, acc-0.4035\n",
      "Iter-17870, train loss-2.1025, acc-0.3800, valid loss-2.1058, acc-0.4084, test loss-2.1067, acc-0.4036\n",
      "Iter-17880, train loss-2.1281, acc-0.3200, valid loss-2.1057, acc-0.4084, test loss-2.1066, acc-0.4036\n",
      "Iter-17890, train loss-2.1040, acc-0.4400, valid loss-2.1056, acc-0.4084, test loss-2.1065, acc-0.4034\n",
      "Iter-17900, train loss-2.0944, acc-0.4400, valid loss-2.1055, acc-0.4084, test loss-2.1064, acc-0.4034\n",
      "Iter-17910, train loss-2.1276, acc-0.3600, valid loss-2.1054, acc-0.4084, test loss-2.1063, acc-0.4034\n",
      "Iter-17920, train loss-2.0951, acc-0.4200, valid loss-2.1053, acc-0.4082, test loss-2.1062, acc-0.4039\n",
      "Iter-17930, train loss-2.0464, acc-0.4600, valid loss-2.1052, acc-0.4082, test loss-2.1061, acc-0.4036\n",
      "Iter-17940, train loss-2.1148, acc-0.3400, valid loss-2.1051, acc-0.4084, test loss-2.1060, acc-0.4039\n",
      "Iter-17950, train loss-2.1629, acc-0.2800, valid loss-2.1050, acc-0.4084, test loss-2.1059, acc-0.4039\n",
      "Iter-17960, train loss-2.0750, acc-0.4600, valid loss-2.1049, acc-0.4082, test loss-2.1057, acc-0.4039\n",
      "Iter-17970, train loss-2.1164, acc-0.3800, valid loss-2.1048, acc-0.4080, test loss-2.1057, acc-0.4039\n",
      "Iter-17980, train loss-2.1406, acc-0.3600, valid loss-2.1047, acc-0.4082, test loss-2.1055, acc-0.4039\n",
      "Iter-17990, train loss-2.0857, acc-0.4400, valid loss-2.1046, acc-0.4084, test loss-2.1054, acc-0.4039\n",
      "Iter-18000, train loss-2.0901, acc-0.4400, valid loss-2.1045, acc-0.4082, test loss-2.1054, acc-0.4037\n",
      "Iter-18010, train loss-2.1549, acc-0.3400, valid loss-2.1044, acc-0.4084, test loss-2.1052, acc-0.4038\n",
      "Iter-18020, train loss-2.0848, acc-0.4600, valid loss-2.1043, acc-0.4082, test loss-2.1051, acc-0.4038\n",
      "Iter-18030, train loss-2.1221, acc-0.3600, valid loss-2.1042, acc-0.4082, test loss-2.1051, acc-0.4042\n",
      "Iter-18040, train loss-2.1212, acc-0.3600, valid loss-2.1041, acc-0.4082, test loss-2.1049, acc-0.4042\n",
      "Iter-18050, train loss-2.1074, acc-0.3200, valid loss-2.1040, acc-0.4084, test loss-2.1048, acc-0.4041\n",
      "Iter-18060, train loss-2.0480, acc-0.4000, valid loss-2.1039, acc-0.4084, test loss-2.1047, acc-0.4038\n",
      "Iter-18070, train loss-2.1368, acc-0.3000, valid loss-2.1038, acc-0.4082, test loss-2.1046, acc-0.4040\n",
      "Iter-18080, train loss-2.0986, acc-0.4000, valid loss-2.1037, acc-0.4084, test loss-2.1045, acc-0.4038\n",
      "Iter-18090, train loss-2.1100, acc-0.4600, valid loss-2.1036, acc-0.4084, test loss-2.1044, acc-0.4038\n",
      "Iter-18100, train loss-2.1173, acc-0.3800, valid loss-2.1035, acc-0.4084, test loss-2.1043, acc-0.4037\n",
      "Iter-18110, train loss-2.1316, acc-0.3800, valid loss-2.1034, acc-0.4084, test loss-2.1042, acc-0.4037\n",
      "Iter-18120, train loss-2.1339, acc-0.3200, valid loss-2.1033, acc-0.4084, test loss-2.1041, acc-0.4039\n",
      "Iter-18130, train loss-2.0790, acc-0.4400, valid loss-2.1032, acc-0.4084, test loss-2.1040, acc-0.4041\n",
      "Iter-18140, train loss-2.0620, acc-0.5000, valid loss-2.1031, acc-0.4084, test loss-2.1039, acc-0.4041\n",
      "Iter-18150, train loss-2.1158, acc-0.4800, valid loss-2.1030, acc-0.4084, test loss-2.1038, acc-0.4039\n",
      "Iter-18160, train loss-2.0897, acc-0.4600, valid loss-2.1029, acc-0.4084, test loss-2.1037, acc-0.4041\n",
      "Iter-18170, train loss-2.1057, acc-0.4600, valid loss-2.1028, acc-0.4082, test loss-2.1036, acc-0.4041\n",
      "Iter-18180, train loss-2.1380, acc-0.3800, valid loss-2.1027, acc-0.4082, test loss-2.1035, acc-0.4041\n",
      "Iter-18190, train loss-2.1769, acc-0.3600, valid loss-2.1026, acc-0.4084, test loss-2.1034, acc-0.4042\n",
      "Iter-18200, train loss-2.0486, acc-0.4800, valid loss-2.1025, acc-0.4082, test loss-2.1033, acc-0.4041\n",
      "Iter-18210, train loss-2.1401, acc-0.3800, valid loss-2.1024, acc-0.4084, test loss-2.1032, acc-0.4041\n",
      "Iter-18220, train loss-2.0817, acc-0.3800, valid loss-2.1023, acc-0.4086, test loss-2.1031, acc-0.4042\n",
      "Iter-18230, train loss-2.0635, acc-0.4800, valid loss-2.1022, acc-0.4084, test loss-2.1030, acc-0.4043\n",
      "Iter-18240, train loss-2.0728, acc-0.4000, valid loss-2.1021, acc-0.4086, test loss-2.1029, acc-0.4044\n",
      "Iter-18250, train loss-2.1570, acc-0.2800, valid loss-2.1020, acc-0.4086, test loss-2.1028, acc-0.4042\n",
      "Iter-18260, train loss-2.1176, acc-0.3800, valid loss-2.1019, acc-0.4086, test loss-2.1027, acc-0.4046\n",
      "Iter-18270, train loss-2.0957, acc-0.4400, valid loss-2.1018, acc-0.4086, test loss-2.1026, acc-0.4043\n",
      "Iter-18280, train loss-2.1083, acc-0.3400, valid loss-2.1017, acc-0.4086, test loss-2.1025, acc-0.4046\n",
      "Iter-18290, train loss-2.1400, acc-0.3600, valid loss-2.1016, acc-0.4086, test loss-2.1024, acc-0.4045\n",
      "Iter-18300, train loss-2.0726, acc-0.3800, valid loss-2.1015, acc-0.4086, test loss-2.1023, acc-0.4043\n",
      "Iter-18310, train loss-2.1469, acc-0.3000, valid loss-2.1014, acc-0.4086, test loss-2.1022, acc-0.4049\n",
      "Iter-18320, train loss-2.1043, acc-0.4000, valid loss-2.1013, acc-0.4086, test loss-2.1021, acc-0.4047\n",
      "Iter-18330, train loss-2.0698, acc-0.4800, valid loss-2.1012, acc-0.4086, test loss-2.1020, acc-0.4050\n",
      "Iter-18340, train loss-2.0782, acc-0.5000, valid loss-2.1011, acc-0.4086, test loss-2.1019, acc-0.4055\n",
      "Iter-18350, train loss-2.1290, acc-0.3800, valid loss-2.1010, acc-0.4086, test loss-2.1018, acc-0.4056\n",
      "Iter-18360, train loss-2.1305, acc-0.4200, valid loss-2.1009, acc-0.4090, test loss-2.1017, acc-0.4057\n",
      "Iter-18370, train loss-2.0825, acc-0.5400, valid loss-2.1008, acc-0.4090, test loss-2.1016, acc-0.4057\n",
      "Iter-18380, train loss-2.1109, acc-0.3800, valid loss-2.1007, acc-0.4090, test loss-2.1015, acc-0.4059\n",
      "Iter-18390, train loss-2.0881, acc-0.3600, valid loss-2.1006, acc-0.4088, test loss-2.1014, acc-0.4061\n",
      "Iter-18400, train loss-2.1119, acc-0.3800, valid loss-2.1005, acc-0.4086, test loss-2.1013, acc-0.4058\n",
      "Iter-18410, train loss-2.0618, acc-0.4200, valid loss-2.1004, acc-0.4086, test loss-2.1012, acc-0.4058\n",
      "Iter-18420, train loss-2.1261, acc-0.3800, valid loss-2.1003, acc-0.4088, test loss-2.1011, acc-0.4058\n",
      "Iter-18430, train loss-2.0758, acc-0.4000, valid loss-2.1002, acc-0.4088, test loss-2.1010, acc-0.4056\n",
      "Iter-18440, train loss-2.1553, acc-0.2800, valid loss-2.1001, acc-0.4090, test loss-2.1009, acc-0.4060\n",
      "Iter-18450, train loss-2.1010, acc-0.4000, valid loss-2.1000, acc-0.4094, test loss-2.1008, acc-0.4059\n",
      "Iter-18460, train loss-2.0823, acc-0.4600, valid loss-2.0999, acc-0.4092, test loss-2.1007, acc-0.4061\n",
      "Iter-18470, train loss-2.1189, acc-0.4400, valid loss-2.0998, acc-0.4090, test loss-2.1006, acc-0.4060\n",
      "Iter-18480, train loss-2.0809, acc-0.4400, valid loss-2.0997, acc-0.4092, test loss-2.1005, acc-0.4059\n",
      "Iter-18490, train loss-2.0737, acc-0.3800, valid loss-2.0996, acc-0.4096, test loss-2.1004, acc-0.4060\n",
      "Iter-18500, train loss-2.0698, acc-0.5400, valid loss-2.0995, acc-0.4094, test loss-2.1003, acc-0.4060\n",
      "Iter-18510, train loss-2.1071, acc-0.4400, valid loss-2.0994, acc-0.4094, test loss-2.1002, acc-0.4058\n",
      "Iter-18520, train loss-2.1109, acc-0.4200, valid loss-2.0993, acc-0.4094, test loss-2.1001, acc-0.4060\n",
      "Iter-18530, train loss-2.1029, acc-0.4000, valid loss-2.0992, acc-0.4096, test loss-2.1000, acc-0.4060\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-18540, train loss-2.1044, acc-0.3200, valid loss-2.0991, acc-0.4096, test loss-2.0999, acc-0.4062\n",
      "Iter-18550, train loss-2.1265, acc-0.4000, valid loss-2.0990, acc-0.4098, test loss-2.0998, acc-0.4060\n",
      "Iter-18560, train loss-2.0866, acc-0.3200, valid loss-2.0989, acc-0.4098, test loss-2.0998, acc-0.4060\n",
      "Iter-18570, train loss-2.0487, acc-0.4000, valid loss-2.0988, acc-0.4096, test loss-2.0997, acc-0.4060\n",
      "Iter-18580, train loss-2.0664, acc-0.4400, valid loss-2.0987, acc-0.4102, test loss-2.0996, acc-0.4061\n",
      "Iter-18590, train loss-2.0620, acc-0.4400, valid loss-2.0986, acc-0.4098, test loss-2.0995, acc-0.4058\n",
      "Iter-18600, train loss-2.0557, acc-0.5400, valid loss-2.0985, acc-0.4100, test loss-2.0993, acc-0.4060\n",
      "Iter-18610, train loss-2.1166, acc-0.3400, valid loss-2.0984, acc-0.4102, test loss-2.0992, acc-0.4059\n",
      "Iter-18620, train loss-2.1150, acc-0.3400, valid loss-2.0983, acc-0.4102, test loss-2.0991, acc-0.4060\n",
      "Iter-18630, train loss-2.0713, acc-0.4400, valid loss-2.0982, acc-0.4100, test loss-2.0990, acc-0.4060\n",
      "Iter-18640, train loss-2.1226, acc-0.3000, valid loss-2.0981, acc-0.4102, test loss-2.0989, acc-0.4062\n",
      "Iter-18650, train loss-2.1064, acc-0.4200, valid loss-2.0980, acc-0.4100, test loss-2.0989, acc-0.4061\n",
      "Iter-18660, train loss-2.0907, acc-0.4200, valid loss-2.0979, acc-0.4100, test loss-2.0987, acc-0.4063\n",
      "Iter-18670, train loss-2.0586, acc-0.4600, valid loss-2.0978, acc-0.4098, test loss-2.0987, acc-0.4063\n",
      "Iter-18680, train loss-2.1298, acc-0.4200, valid loss-2.0977, acc-0.4098, test loss-2.0986, acc-0.4064\n",
      "Iter-18690, train loss-2.0775, acc-0.4400, valid loss-2.0976, acc-0.4100, test loss-2.0985, acc-0.4063\n",
      "Iter-18700, train loss-2.0953, acc-0.4400, valid loss-2.0975, acc-0.4102, test loss-2.0984, acc-0.4063\n",
      "Iter-18710, train loss-2.1139, acc-0.4000, valid loss-2.0974, acc-0.4102, test loss-2.0983, acc-0.4062\n",
      "Iter-18720, train loss-2.1596, acc-0.3000, valid loss-2.0973, acc-0.4106, test loss-2.0982, acc-0.4064\n",
      "Iter-18730, train loss-2.1489, acc-0.3200, valid loss-2.0972, acc-0.4108, test loss-2.0981, acc-0.4062\n",
      "Iter-18740, train loss-2.0951, acc-0.4600, valid loss-2.0971, acc-0.4110, test loss-2.0980, acc-0.4064\n",
      "Iter-18750, train loss-2.1412, acc-0.3200, valid loss-2.0970, acc-0.4112, test loss-2.0979, acc-0.4066\n",
      "Iter-18760, train loss-2.1067, acc-0.4200, valid loss-2.0969, acc-0.4112, test loss-2.0978, acc-0.4067\n",
      "Iter-18770, train loss-2.0921, acc-0.3400, valid loss-2.0968, acc-0.4112, test loss-2.0977, acc-0.4070\n",
      "Iter-18780, train loss-2.0889, acc-0.4800, valid loss-2.0967, acc-0.4114, test loss-2.0976, acc-0.4071\n",
      "Iter-18790, train loss-2.0842, acc-0.4000, valid loss-2.0966, acc-0.4114, test loss-2.0975, acc-0.4071\n",
      "Iter-18800, train loss-2.1379, acc-0.2800, valid loss-2.0965, acc-0.4114, test loss-2.0974, acc-0.4071\n",
      "Iter-18810, train loss-2.0923, acc-0.3600, valid loss-2.0964, acc-0.4112, test loss-2.0973, acc-0.4074\n",
      "Iter-18820, train loss-2.0839, acc-0.4400, valid loss-2.0963, acc-0.4114, test loss-2.0972, acc-0.4076\n",
      "Iter-18830, train loss-2.1337, acc-0.3600, valid loss-2.0962, acc-0.4112, test loss-2.0971, acc-0.4076\n",
      "Iter-18840, train loss-2.0908, acc-0.4600, valid loss-2.0961, acc-0.4112, test loss-2.0970, acc-0.4076\n",
      "Iter-18850, train loss-2.0543, acc-0.5400, valid loss-2.0960, acc-0.4112, test loss-2.0969, acc-0.4076\n",
      "Iter-18860, train loss-2.1125, acc-0.4000, valid loss-2.0959, acc-0.4118, test loss-2.0968, acc-0.4077\n",
      "Iter-18870, train loss-2.1874, acc-0.2400, valid loss-2.0958, acc-0.4126, test loss-2.0967, acc-0.4075\n",
      "Iter-18880, train loss-2.1052, acc-0.4600, valid loss-2.0957, acc-0.4122, test loss-2.0966, acc-0.4077\n",
      "Iter-18890, train loss-2.0972, acc-0.4600, valid loss-2.0956, acc-0.4122, test loss-2.0965, acc-0.4077\n",
      "Iter-18900, train loss-2.1365, acc-0.3200, valid loss-2.0955, acc-0.4126, test loss-2.0964, acc-0.4076\n",
      "Iter-18910, train loss-2.1752, acc-0.2400, valid loss-2.0954, acc-0.4128, test loss-2.0963, acc-0.4077\n",
      "Iter-18920, train loss-2.0955, acc-0.3400, valid loss-2.0953, acc-0.4128, test loss-2.0962, acc-0.4079\n",
      "Iter-18930, train loss-2.1331, acc-0.4200, valid loss-2.0953, acc-0.4126, test loss-2.0961, acc-0.4080\n",
      "Iter-18940, train loss-2.0892, acc-0.4200, valid loss-2.0952, acc-0.4128, test loss-2.0960, acc-0.4079\n",
      "Iter-18950, train loss-2.0996, acc-0.4000, valid loss-2.0951, acc-0.4130, test loss-2.0959, acc-0.4079\n",
      "Iter-18960, train loss-2.0988, acc-0.4400, valid loss-2.0950, acc-0.4130, test loss-2.0958, acc-0.4079\n",
      "Iter-18970, train loss-2.1152, acc-0.4400, valid loss-2.0949, acc-0.4128, test loss-2.0957, acc-0.4081\n",
      "Iter-18980, train loss-2.0944, acc-0.4400, valid loss-2.0948, acc-0.4132, test loss-2.0956, acc-0.4080\n",
      "Iter-18990, train loss-2.0649, acc-0.4800, valid loss-2.0946, acc-0.4134, test loss-2.0955, acc-0.4081\n",
      "Iter-19000, train loss-2.1228, acc-0.4200, valid loss-2.0946, acc-0.4138, test loss-2.0954, acc-0.4082\n",
      "Iter-19010, train loss-2.1326, acc-0.3400, valid loss-2.0945, acc-0.4138, test loss-2.0953, acc-0.4081\n",
      "Iter-19020, train loss-2.1144, acc-0.4600, valid loss-2.0944, acc-0.4134, test loss-2.0952, acc-0.4081\n",
      "Iter-19030, train loss-2.0836, acc-0.3800, valid loss-2.0943, acc-0.4136, test loss-2.0951, acc-0.4081\n",
      "Iter-19040, train loss-2.1003, acc-0.3600, valid loss-2.0942, acc-0.4134, test loss-2.0950, acc-0.4084\n",
      "Iter-19050, train loss-2.0868, acc-0.4200, valid loss-2.0941, acc-0.4134, test loss-2.0949, acc-0.4083\n",
      "Iter-19060, train loss-2.0973, acc-0.4200, valid loss-2.0940, acc-0.4138, test loss-2.0948, acc-0.4083\n",
      "Iter-19070, train loss-2.1746, acc-0.3000, valid loss-2.0939, acc-0.4138, test loss-2.0947, acc-0.4083\n",
      "Iter-19080, train loss-2.0948, acc-0.3800, valid loss-2.0938, acc-0.4136, test loss-2.0946, acc-0.4084\n",
      "Iter-19090, train loss-2.0756, acc-0.3800, valid loss-2.0937, acc-0.4136, test loss-2.0945, acc-0.4084\n",
      "Iter-19100, train loss-2.1345, acc-0.3000, valid loss-2.0936, acc-0.4136, test loss-2.0944, acc-0.4083\n",
      "Iter-19110, train loss-2.0831, acc-0.3600, valid loss-2.0935, acc-0.4136, test loss-2.0943, acc-0.4086\n",
      "Iter-19120, train loss-2.1257, acc-0.4200, valid loss-2.0934, acc-0.4142, test loss-2.0942, acc-0.4082\n",
      "Iter-19130, train loss-2.0699, acc-0.5200, valid loss-2.0933, acc-0.4140, test loss-2.0941, acc-0.4085\n",
      "Iter-19140, train loss-2.0770, acc-0.4200, valid loss-2.0932, acc-0.4138, test loss-2.0941, acc-0.4086\n",
      "Iter-19150, train loss-2.1212, acc-0.3400, valid loss-2.0931, acc-0.4142, test loss-2.0940, acc-0.4084\n",
      "Iter-19160, train loss-2.1143, acc-0.4600, valid loss-2.0930, acc-0.4144, test loss-2.0939, acc-0.4087\n",
      "Iter-19170, train loss-2.0966, acc-0.3600, valid loss-2.0929, acc-0.4144, test loss-2.0938, acc-0.4088\n",
      "Iter-19180, train loss-2.1036, acc-0.3400, valid loss-2.0928, acc-0.4144, test loss-2.0937, acc-0.4087\n",
      "Iter-19190, train loss-2.1261, acc-0.3600, valid loss-2.0927, acc-0.4144, test loss-2.0936, acc-0.4089\n",
      "Iter-19200, train loss-2.0935, acc-0.4400, valid loss-2.0926, acc-0.4144, test loss-2.0935, acc-0.4093\n",
      "Iter-19210, train loss-2.1048, acc-0.3800, valid loss-2.0925, acc-0.4144, test loss-2.0934, acc-0.4092\n",
      "Iter-19220, train loss-2.1586, acc-0.2800, valid loss-2.0924, acc-0.4144, test loss-2.0933, acc-0.4095\n",
      "Iter-19230, train loss-2.0911, acc-0.3000, valid loss-2.0923, acc-0.4150, test loss-2.0932, acc-0.4095\n",
      "Iter-19240, train loss-2.1245, acc-0.4000, valid loss-2.0922, acc-0.4150, test loss-2.0931, acc-0.4094\n",
      "Iter-19250, train loss-2.0750, acc-0.5000, valid loss-2.0921, acc-0.4150, test loss-2.0930, acc-0.4096\n",
      "Iter-19260, train loss-2.0992, acc-0.3600, valid loss-2.0920, acc-0.4148, test loss-2.0929, acc-0.4096\n",
      "Iter-19270, train loss-2.1006, acc-0.3600, valid loss-2.0919, acc-0.4148, test loss-2.0928, acc-0.4098\n",
      "Iter-19280, train loss-2.0062, acc-0.6400, valid loss-2.0918, acc-0.4150, test loss-2.0927, acc-0.4097\n",
      "Iter-19290, train loss-2.0709, acc-0.5200, valid loss-2.0917, acc-0.4148, test loss-2.0926, acc-0.4097\n",
      "Iter-19300, train loss-2.0992, acc-0.4400, valid loss-2.0917, acc-0.4154, test loss-2.0925, acc-0.4096\n",
      "Iter-19310, train loss-2.0902, acc-0.5200, valid loss-2.0915, acc-0.4154, test loss-2.0924, acc-0.4096\n",
      "Iter-19320, train loss-2.0968, acc-0.4000, valid loss-2.0914, acc-0.4156, test loss-2.0923, acc-0.4094\n",
      "Iter-19330, train loss-2.0510, acc-0.4400, valid loss-2.0913, acc-0.4156, test loss-2.0922, acc-0.4094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-19340, train loss-2.0811, acc-0.4600, valid loss-2.0913, acc-0.4154, test loss-2.0921, acc-0.4094\n",
      "Iter-19350, train loss-2.0783, acc-0.4200, valid loss-2.0911, acc-0.4154, test loss-2.0920, acc-0.4097\n",
      "Iter-19360, train loss-2.0622, acc-0.4600, valid loss-2.0911, acc-0.4154, test loss-2.0919, acc-0.4096\n",
      "Iter-19370, train loss-2.0956, acc-0.5000, valid loss-2.0909, acc-0.4154, test loss-2.0918, acc-0.4094\n",
      "Iter-19380, train loss-2.0703, acc-0.4200, valid loss-2.0908, acc-0.4152, test loss-2.0917, acc-0.4094\n",
      "Iter-19390, train loss-2.1022, acc-0.3600, valid loss-2.0907, acc-0.4152, test loss-2.0916, acc-0.4096\n",
      "Iter-19400, train loss-2.0826, acc-0.4000, valid loss-2.0906, acc-0.4154, test loss-2.0915, acc-0.4097\n",
      "Iter-19410, train loss-2.0834, acc-0.4800, valid loss-2.0905, acc-0.4152, test loss-2.0914, acc-0.4097\n",
      "Iter-19420, train loss-2.0496, acc-0.4800, valid loss-2.0905, acc-0.4154, test loss-2.0913, acc-0.4093\n",
      "Iter-19430, train loss-2.1035, acc-0.4400, valid loss-2.0904, acc-0.4152, test loss-2.0912, acc-0.4095\n",
      "Iter-19440, train loss-2.1412, acc-0.3800, valid loss-2.0903, acc-0.4154, test loss-2.0911, acc-0.4095\n",
      "Iter-19450, train loss-2.0815, acc-0.4400, valid loss-2.0902, acc-0.4154, test loss-2.0910, acc-0.4096\n",
      "Iter-19460, train loss-2.0741, acc-0.3600, valid loss-2.0900, acc-0.4152, test loss-2.0909, acc-0.4095\n",
      "Iter-19470, train loss-2.1343, acc-0.3200, valid loss-2.0899, acc-0.4150, test loss-2.0908, acc-0.4096\n",
      "Iter-19480, train loss-2.1259, acc-0.3400, valid loss-2.0898, acc-0.4148, test loss-2.0907, acc-0.4094\n",
      "Iter-19490, train loss-2.0856, acc-0.3600, valid loss-2.0898, acc-0.4150, test loss-2.0906, acc-0.4094\n",
      "Iter-19500, train loss-2.1102, acc-0.4200, valid loss-2.0896, acc-0.4152, test loss-2.0905, acc-0.4096\n",
      "Iter-19510, train loss-2.1433, acc-0.2800, valid loss-2.0895, acc-0.4150, test loss-2.0904, acc-0.4097\n",
      "Iter-19520, train loss-2.1205, acc-0.4600, valid loss-2.0894, acc-0.4148, test loss-2.0903, acc-0.4096\n",
      "Iter-19530, train loss-2.0744, acc-0.4200, valid loss-2.0893, acc-0.4152, test loss-2.0902, acc-0.4099\n",
      "Iter-19540, train loss-2.0493, acc-0.4600, valid loss-2.0892, acc-0.4152, test loss-2.0901, acc-0.4099\n",
      "Iter-19550, train loss-2.1099, acc-0.4000, valid loss-2.0892, acc-0.4150, test loss-2.0900, acc-0.4099\n",
      "Iter-19560, train loss-2.0633, acc-0.4400, valid loss-2.0891, acc-0.4148, test loss-2.0899, acc-0.4097\n",
      "Iter-19570, train loss-2.1045, acc-0.3200, valid loss-2.0890, acc-0.4152, test loss-2.0898, acc-0.4099\n",
      "Iter-19580, train loss-2.0657, acc-0.4200, valid loss-2.0889, acc-0.4150, test loss-2.0897, acc-0.4099\n",
      "Iter-19590, train loss-2.0880, acc-0.4400, valid loss-2.0888, acc-0.4152, test loss-2.0896, acc-0.4099\n",
      "Iter-19600, train loss-2.1003, acc-0.3600, valid loss-2.0887, acc-0.4152, test loss-2.0895, acc-0.4101\n",
      "Iter-19610, train loss-2.0909, acc-0.3800, valid loss-2.0886, acc-0.4154, test loss-2.0894, acc-0.4102\n",
      "Iter-19620, train loss-2.1093, acc-0.4200, valid loss-2.0885, acc-0.4152, test loss-2.0893, acc-0.4101\n",
      "Iter-19630, train loss-2.0588, acc-0.4600, valid loss-2.0884, acc-0.4152, test loss-2.0892, acc-0.4101\n",
      "Iter-19640, train loss-2.1074, acc-0.2800, valid loss-2.0883, acc-0.4156, test loss-2.0891, acc-0.4104\n",
      "Iter-19650, train loss-2.1258, acc-0.3800, valid loss-2.0882, acc-0.4158, test loss-2.0890, acc-0.4103\n",
      "Iter-19660, train loss-2.0998, acc-0.4000, valid loss-2.0881, acc-0.4156, test loss-2.0890, acc-0.4101\n",
      "Iter-19670, train loss-2.0871, acc-0.3800, valid loss-2.0880, acc-0.4156, test loss-2.0889, acc-0.4104\n",
      "Iter-19680, train loss-2.0492, acc-0.4400, valid loss-2.0879, acc-0.4154, test loss-2.0888, acc-0.4105\n",
      "Iter-19690, train loss-2.1233, acc-0.3000, valid loss-2.0878, acc-0.4154, test loss-2.0887, acc-0.4105\n",
      "Iter-19700, train loss-2.0353, acc-0.4800, valid loss-2.0877, acc-0.4154, test loss-2.0886, acc-0.4103\n",
      "Iter-19710, train loss-2.0881, acc-0.4400, valid loss-2.0876, acc-0.4154, test loss-2.0884, acc-0.4104\n",
      "Iter-19720, train loss-2.0975, acc-0.3400, valid loss-2.0875, acc-0.4156, test loss-2.0883, acc-0.4105\n",
      "Iter-19730, train loss-2.0410, acc-0.5000, valid loss-2.0874, acc-0.4154, test loss-2.0883, acc-0.4104\n",
      "Iter-19740, train loss-2.0909, acc-0.4200, valid loss-2.0873, acc-0.4156, test loss-2.0882, acc-0.4109\n",
      "Iter-19750, train loss-2.1200, acc-0.3200, valid loss-2.0872, acc-0.4156, test loss-2.0881, acc-0.4107\n",
      "Iter-19760, train loss-2.1170, acc-0.3400, valid loss-2.0871, acc-0.4158, test loss-2.0880, acc-0.4107\n",
      "Iter-19770, train loss-2.0910, acc-0.3000, valid loss-2.0870, acc-0.4158, test loss-2.0879, acc-0.4108\n",
      "Iter-19780, train loss-2.1048, acc-0.3600, valid loss-2.0869, acc-0.4158, test loss-2.0878, acc-0.4109\n",
      "Iter-19790, train loss-2.0932, acc-0.4000, valid loss-2.0869, acc-0.4158, test loss-2.0877, acc-0.4110\n",
      "Iter-19800, train loss-2.1064, acc-0.3200, valid loss-2.0868, acc-0.4160, test loss-2.0876, acc-0.4111\n",
      "Iter-19810, train loss-2.1127, acc-0.4200, valid loss-2.0867, acc-0.4158, test loss-2.0875, acc-0.4112\n",
      "Iter-19820, train loss-2.0879, acc-0.3600, valid loss-2.0866, acc-0.4158, test loss-2.0874, acc-0.4113\n",
      "Iter-19830, train loss-2.1156, acc-0.3600, valid loss-2.0865, acc-0.4158, test loss-2.0873, acc-0.4112\n",
      "Iter-19840, train loss-2.0650, acc-0.3800, valid loss-2.0864, acc-0.4158, test loss-2.0872, acc-0.4112\n",
      "Iter-19850, train loss-2.1017, acc-0.4800, valid loss-2.0863, acc-0.4160, test loss-2.0871, acc-0.4114\n",
      "Iter-19860, train loss-2.1103, acc-0.3800, valid loss-2.0862, acc-0.4162, test loss-2.0870, acc-0.4118\n",
      "Iter-19870, train loss-2.0052, acc-0.5800, valid loss-2.0861, acc-0.4160, test loss-2.0869, acc-0.4118\n",
      "Iter-19880, train loss-2.0693, acc-0.4600, valid loss-2.0860, acc-0.4160, test loss-2.0868, acc-0.4120\n",
      "Iter-19890, train loss-2.0817, acc-0.4000, valid loss-2.0859, acc-0.4160, test loss-2.0868, acc-0.4119\n",
      "Iter-19900, train loss-2.0407, acc-0.5600, valid loss-2.0858, acc-0.4160, test loss-2.0867, acc-0.4117\n",
      "Iter-19910, train loss-2.0830, acc-0.4400, valid loss-2.0857, acc-0.4162, test loss-2.0865, acc-0.4117\n",
      "Iter-19920, train loss-2.0964, acc-0.4400, valid loss-2.0856, acc-0.4162, test loss-2.0864, acc-0.4118\n",
      "Iter-19930, train loss-2.0619, acc-0.5400, valid loss-2.0855, acc-0.4164, test loss-2.0863, acc-0.4120\n",
      "Iter-19940, train loss-2.1157, acc-0.3800, valid loss-2.0854, acc-0.4164, test loss-2.0863, acc-0.4119\n",
      "Iter-19950, train loss-2.0852, acc-0.4000, valid loss-2.0853, acc-0.4162, test loss-2.0862, acc-0.4120\n",
      "Iter-19960, train loss-2.0649, acc-0.4400, valid loss-2.0852, acc-0.4168, test loss-2.0861, acc-0.4120\n",
      "Iter-19970, train loss-2.1159, acc-0.4400, valid loss-2.0851, acc-0.4172, test loss-2.0860, acc-0.4125\n",
      "Iter-19980, train loss-2.1195, acc-0.3800, valid loss-2.0850, acc-0.4174, test loss-2.0859, acc-0.4126\n",
      "Iter-19990, train loss-2.1146, acc-0.3600, valid loss-2.0849, acc-0.4176, test loss-2.0858, acc-0.4120\n",
      "Iter-20000, train loss-2.0831, acc-0.3800, valid loss-2.0848, acc-0.4174, test loss-2.0857, acc-0.4122\n",
      "Iter-20010, train loss-2.1121, acc-0.4000, valid loss-2.0847, acc-0.4178, test loss-2.0856, acc-0.4124\n",
      "Iter-20020, train loss-2.0778, acc-0.4400, valid loss-2.0847, acc-0.4176, test loss-2.0855, acc-0.4126\n",
      "Iter-20030, train loss-2.1173, acc-0.3200, valid loss-2.0846, acc-0.4176, test loss-2.0854, acc-0.4125\n",
      "Iter-20040, train loss-2.1408, acc-0.2800, valid loss-2.0845, acc-0.4178, test loss-2.0853, acc-0.4123\n",
      "Iter-20050, train loss-2.1200, acc-0.3200, valid loss-2.0844, acc-0.4178, test loss-2.0852, acc-0.4121\n",
      "Iter-20060, train loss-2.0186, acc-0.4800, valid loss-2.0843, acc-0.4180, test loss-2.0851, acc-0.4125\n",
      "Iter-20070, train loss-2.1140, acc-0.3000, valid loss-2.0842, acc-0.4182, test loss-2.0850, acc-0.4126\n",
      "Iter-20080, train loss-2.0624, acc-0.4400, valid loss-2.0841, acc-0.4184, test loss-2.0849, acc-0.4126\n",
      "Iter-20090, train loss-2.0414, acc-0.4400, valid loss-2.0840, acc-0.4184, test loss-2.0848, acc-0.4125\n",
      "Iter-20100, train loss-2.1127, acc-0.3800, valid loss-2.0839, acc-0.4186, test loss-2.0847, acc-0.4126\n",
      "Iter-20110, train loss-2.1630, acc-0.3000, valid loss-2.0838, acc-0.4186, test loss-2.0847, acc-0.4127\n",
      "Iter-20120, train loss-2.0959, acc-0.3800, valid loss-2.0837, acc-0.4186, test loss-2.0846, acc-0.4130\n",
      "Iter-20130, train loss-2.1206, acc-0.3400, valid loss-2.0836, acc-0.4186, test loss-2.0845, acc-0.4129\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20140, train loss-2.1081, acc-0.4000, valid loss-2.0835, acc-0.4184, test loss-2.0844, acc-0.4128\n",
      "Iter-20150, train loss-2.1241, acc-0.3600, valid loss-2.0834, acc-0.4186, test loss-2.0843, acc-0.4129\n",
      "Iter-20160, train loss-2.0845, acc-0.4400, valid loss-2.0833, acc-0.4188, test loss-2.0842, acc-0.4129\n",
      "Iter-20170, train loss-2.1101, acc-0.3000, valid loss-2.0832, acc-0.4188, test loss-2.0841, acc-0.4129\n",
      "Iter-20180, train loss-2.0572, acc-0.4000, valid loss-2.0831, acc-0.4190, test loss-2.0840, acc-0.4128\n",
      "Iter-20190, train loss-2.0634, acc-0.4600, valid loss-2.0831, acc-0.4190, test loss-2.0839, acc-0.4128\n",
      "Iter-20200, train loss-2.1059, acc-0.4000, valid loss-2.0830, acc-0.4190, test loss-2.0838, acc-0.4127\n",
      "Iter-20210, train loss-2.0742, acc-0.4200, valid loss-2.0829, acc-0.4184, test loss-2.0837, acc-0.4127\n",
      "Iter-20220, train loss-2.0041, acc-0.6600, valid loss-2.0828, acc-0.4184, test loss-2.0836, acc-0.4126\n",
      "Iter-20230, train loss-2.0774, acc-0.4000, valid loss-2.0827, acc-0.4186, test loss-2.0835, acc-0.4126\n",
      "Iter-20240, train loss-2.0923, acc-0.3800, valid loss-2.0826, acc-0.4184, test loss-2.0834, acc-0.4126\n",
      "Iter-20250, train loss-2.0389, acc-0.3800, valid loss-2.0825, acc-0.4184, test loss-2.0833, acc-0.4127\n",
      "Iter-20260, train loss-2.1058, acc-0.4400, valid loss-2.0824, acc-0.4184, test loss-2.0832, acc-0.4128\n",
      "Iter-20270, train loss-2.0735, acc-0.4800, valid loss-2.0823, acc-0.4184, test loss-2.0831, acc-0.4129\n",
      "Iter-20280, train loss-2.0860, acc-0.3200, valid loss-2.0822, acc-0.4186, test loss-2.0830, acc-0.4128\n",
      "Iter-20290, train loss-2.1004, acc-0.3800, valid loss-2.0821, acc-0.4184, test loss-2.0829, acc-0.4128\n",
      "Iter-20300, train loss-2.1396, acc-0.3600, valid loss-2.0820, acc-0.4186, test loss-2.0828, acc-0.4129\n",
      "Iter-20310, train loss-2.0692, acc-0.4400, valid loss-2.0819, acc-0.4184, test loss-2.0828, acc-0.4130\n",
      "Iter-20320, train loss-2.1080, acc-0.3600, valid loss-2.0818, acc-0.4184, test loss-2.0827, acc-0.4130\n",
      "Iter-20330, train loss-2.0909, acc-0.5400, valid loss-2.0817, acc-0.4188, test loss-2.0826, acc-0.4129\n",
      "Iter-20340, train loss-2.0451, acc-0.5000, valid loss-2.0816, acc-0.4184, test loss-2.0825, acc-0.4131\n",
      "Iter-20350, train loss-2.0745, acc-0.4400, valid loss-2.0815, acc-0.4188, test loss-2.0824, acc-0.4129\n",
      "Iter-20360, train loss-2.0818, acc-0.3800, valid loss-2.0814, acc-0.4188, test loss-2.0823, acc-0.4132\n",
      "Iter-20370, train loss-2.1209, acc-0.2800, valid loss-2.0813, acc-0.4194, test loss-2.0822, acc-0.4133\n",
      "Iter-20380, train loss-2.0607, acc-0.5400, valid loss-2.0812, acc-0.4194, test loss-2.0821, acc-0.4137\n",
      "Iter-20390, train loss-2.0648, acc-0.4200, valid loss-2.0811, acc-0.4194, test loss-2.0820, acc-0.4135\n",
      "Iter-20400, train loss-2.1186, acc-0.3600, valid loss-2.0811, acc-0.4192, test loss-2.0819, acc-0.4136\n",
      "Iter-20410, train loss-2.0656, acc-0.3400, valid loss-2.0810, acc-0.4192, test loss-2.0818, acc-0.4135\n",
      "Iter-20420, train loss-2.0993, acc-0.4200, valid loss-2.0809, acc-0.4192, test loss-2.0817, acc-0.4135\n",
      "Iter-20430, train loss-2.0772, acc-0.3600, valid loss-2.0808, acc-0.4194, test loss-2.0816, acc-0.4137\n",
      "Iter-20440, train loss-2.0584, acc-0.5200, valid loss-2.0807, acc-0.4196, test loss-2.0815, acc-0.4139\n",
      "Iter-20450, train loss-2.0725, acc-0.4200, valid loss-2.0806, acc-0.4194, test loss-2.0814, acc-0.4140\n",
      "Iter-20460, train loss-2.0648, acc-0.3800, valid loss-2.0805, acc-0.4198, test loss-2.0813, acc-0.4140\n",
      "Iter-20470, train loss-2.1173, acc-0.3600, valid loss-2.0804, acc-0.4198, test loss-2.0812, acc-0.4141\n",
      "Iter-20480, train loss-2.0661, acc-0.3800, valid loss-2.0803, acc-0.4198, test loss-2.0811, acc-0.4144\n",
      "Iter-20490, train loss-2.0806, acc-0.4200, valid loss-2.0802, acc-0.4198, test loss-2.0810, acc-0.4144\n",
      "Iter-20500, train loss-2.0873, acc-0.4400, valid loss-2.0801, acc-0.4198, test loss-2.0809, acc-0.4142\n",
      "Iter-20510, train loss-2.0529, acc-0.5400, valid loss-2.0800, acc-0.4198, test loss-2.0809, acc-0.4142\n",
      "Iter-20520, train loss-2.1606, acc-0.2800, valid loss-2.0799, acc-0.4198, test loss-2.0808, acc-0.4144\n",
      "Iter-20530, train loss-2.1038, acc-0.3600, valid loss-2.0798, acc-0.4200, test loss-2.0807, acc-0.4144\n",
      "Iter-20540, train loss-2.0901, acc-0.4600, valid loss-2.0797, acc-0.4198, test loss-2.0806, acc-0.4147\n",
      "Iter-20550, train loss-2.0870, acc-0.3600, valid loss-2.0796, acc-0.4198, test loss-2.0805, acc-0.4149\n",
      "Iter-20560, train loss-2.0277, acc-0.4800, valid loss-2.0795, acc-0.4198, test loss-2.0804, acc-0.4147\n",
      "Iter-20570, train loss-2.1213, acc-0.3400, valid loss-2.0794, acc-0.4198, test loss-2.0803, acc-0.4149\n",
      "Iter-20580, train loss-2.1158, acc-0.3400, valid loss-2.0793, acc-0.4200, test loss-2.0802, acc-0.4148\n",
      "Iter-20590, train loss-2.0479, acc-0.4600, valid loss-2.0792, acc-0.4198, test loss-2.0801, acc-0.4144\n",
      "Iter-20600, train loss-2.0540, acc-0.4200, valid loss-2.0791, acc-0.4198, test loss-2.0800, acc-0.4147\n",
      "Iter-20610, train loss-2.0492, acc-0.5000, valid loss-2.0790, acc-0.4198, test loss-2.0799, acc-0.4145\n",
      "Iter-20620, train loss-2.0926, acc-0.3600, valid loss-2.0789, acc-0.4200, test loss-2.0798, acc-0.4146\n",
      "Iter-20630, train loss-2.1335, acc-0.4000, valid loss-2.0788, acc-0.4198, test loss-2.0797, acc-0.4147\n",
      "Iter-20640, train loss-2.1371, acc-0.2800, valid loss-2.0787, acc-0.4198, test loss-2.0796, acc-0.4147\n",
      "Iter-20650, train loss-2.0458, acc-0.5000, valid loss-2.0786, acc-0.4198, test loss-2.0795, acc-0.4147\n",
      "Iter-20660, train loss-2.1422, acc-0.3200, valid loss-2.0785, acc-0.4198, test loss-2.0794, acc-0.4146\n",
      "Iter-20670, train loss-2.1058, acc-0.4600, valid loss-2.0784, acc-0.4198, test loss-2.0793, acc-0.4149\n",
      "Iter-20680, train loss-2.0129, acc-0.5800, valid loss-2.0784, acc-0.4198, test loss-2.0792, acc-0.4148\n",
      "Iter-20690, train loss-2.1014, acc-0.4000, valid loss-2.0783, acc-0.4198, test loss-2.0791, acc-0.4151\n",
      "Iter-20700, train loss-2.1014, acc-0.4000, valid loss-2.0782, acc-0.4198, test loss-2.0790, acc-0.4149\n",
      "Iter-20710, train loss-2.1233, acc-0.3200, valid loss-2.0781, acc-0.4198, test loss-2.0789, acc-0.4146\n",
      "Iter-20720, train loss-2.0794, acc-0.5400, valid loss-2.0780, acc-0.4200, test loss-2.0788, acc-0.4148\n",
      "Iter-20730, train loss-2.0918, acc-0.4400, valid loss-2.0779, acc-0.4200, test loss-2.0787, acc-0.4145\n",
      "Iter-20740, train loss-2.0989, acc-0.3800, valid loss-2.0778, acc-0.4200, test loss-2.0786, acc-0.4142\n",
      "Iter-20750, train loss-2.0610, acc-0.4600, valid loss-2.0777, acc-0.4196, test loss-2.0785, acc-0.4144\n",
      "Iter-20760, train loss-2.0800, acc-0.3400, valid loss-2.0776, acc-0.4200, test loss-2.0784, acc-0.4143\n",
      "Iter-20770, train loss-2.0424, acc-0.4800, valid loss-2.0775, acc-0.4200, test loss-2.0783, acc-0.4146\n",
      "Iter-20780, train loss-2.0617, acc-0.4400, valid loss-2.0774, acc-0.4198, test loss-2.0783, acc-0.4145\n",
      "Iter-20790, train loss-2.0814, acc-0.4200, valid loss-2.0773, acc-0.4198, test loss-2.0782, acc-0.4145\n",
      "Iter-20800, train loss-1.9866, acc-0.5000, valid loss-2.0772, acc-0.4198, test loss-2.0781, acc-0.4149\n",
      "Iter-20810, train loss-2.1030, acc-0.3800, valid loss-2.0771, acc-0.4198, test loss-2.0780, acc-0.4151\n",
      "Iter-20820, train loss-2.0680, acc-0.4400, valid loss-2.0771, acc-0.4196, test loss-2.0779, acc-0.4151\n",
      "Iter-20830, train loss-2.0290, acc-0.4800, valid loss-2.0770, acc-0.4198, test loss-2.0778, acc-0.4151\n",
      "Iter-20840, train loss-2.0312, acc-0.4600, valid loss-2.0769, acc-0.4200, test loss-2.0777, acc-0.4152\n",
      "Iter-20850, train loss-2.0397, acc-0.4400, valid loss-2.0768, acc-0.4200, test loss-2.0776, acc-0.4151\n",
      "Iter-20860, train loss-2.0656, acc-0.3800, valid loss-2.0767, acc-0.4200, test loss-2.0775, acc-0.4152\n",
      "Iter-20870, train loss-2.1313, acc-0.2800, valid loss-2.0766, acc-0.4200, test loss-2.0774, acc-0.4153\n",
      "Iter-20880, train loss-2.1280, acc-0.3600, valid loss-2.0765, acc-0.4200, test loss-2.0773, acc-0.4154\n",
      "Iter-20890, train loss-2.1090, acc-0.3600, valid loss-2.0764, acc-0.4200, test loss-2.0772, acc-0.4154\n",
      "Iter-20900, train loss-2.0977, acc-0.3400, valid loss-2.0763, acc-0.4200, test loss-2.0771, acc-0.4154\n",
      "Iter-20910, train loss-2.0751, acc-0.4400, valid loss-2.0762, acc-0.4200, test loss-2.0770, acc-0.4153\n",
      "Iter-20920, train loss-2.0685, acc-0.4200, valid loss-2.0761, acc-0.4202, test loss-2.0769, acc-0.4154\n",
      "Iter-20930, train loss-2.0553, acc-0.4600, valid loss-2.0760, acc-0.4202, test loss-2.0768, acc-0.4154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-20940, train loss-2.0849, acc-0.4800, valid loss-2.0759, acc-0.4204, test loss-2.0767, acc-0.4154\n",
      "Iter-20950, train loss-2.0775, acc-0.3800, valid loss-2.0758, acc-0.4204, test loss-2.0766, acc-0.4154\n",
      "Iter-20960, train loss-2.1003, acc-0.3800, valid loss-2.0757, acc-0.4202, test loss-2.0765, acc-0.4154\n",
      "Iter-20970, train loss-2.1061, acc-0.3600, valid loss-2.0756, acc-0.4204, test loss-2.0764, acc-0.4155\n",
      "Iter-20980, train loss-2.0372, acc-0.4600, valid loss-2.0755, acc-0.4202, test loss-2.0764, acc-0.4155\n",
      "Iter-20990, train loss-2.1054, acc-0.3600, valid loss-2.0754, acc-0.4200, test loss-2.0763, acc-0.4155\n",
      "Iter-21000, train loss-2.0576, acc-0.3400, valid loss-2.0753, acc-0.4200, test loss-2.0762, acc-0.4154\n",
      "Iter-21010, train loss-2.0770, acc-0.4000, valid loss-2.0752, acc-0.4200, test loss-2.0761, acc-0.4153\n",
      "Iter-21020, train loss-2.0597, acc-0.4800, valid loss-2.0751, acc-0.4200, test loss-2.0760, acc-0.4154\n",
      "Iter-21030, train loss-2.0877, acc-0.4000, valid loss-2.0750, acc-0.4200, test loss-2.0759, acc-0.4154\n",
      "Iter-21040, train loss-2.0560, acc-0.4600, valid loss-2.0750, acc-0.4200, test loss-2.0758, acc-0.4154\n",
      "Iter-21050, train loss-2.0929, acc-0.3200, valid loss-2.0749, acc-0.4200, test loss-2.0757, acc-0.4156\n",
      "Iter-21060, train loss-2.0124, acc-0.6000, valid loss-2.0748, acc-0.4202, test loss-2.0756, acc-0.4156\n",
      "Iter-21070, train loss-2.1167, acc-0.2800, valid loss-2.0747, acc-0.4200, test loss-2.0755, acc-0.4156\n",
      "Iter-21080, train loss-2.1104, acc-0.3400, valid loss-2.0746, acc-0.4198, test loss-2.0754, acc-0.4156\n",
      "Iter-21090, train loss-2.0646, acc-0.4200, valid loss-2.0745, acc-0.4198, test loss-2.0753, acc-0.4156\n",
      "Iter-21100, train loss-2.1168, acc-0.3600, valid loss-2.0744, acc-0.4200, test loss-2.0752, acc-0.4156\n",
      "Iter-21110, train loss-2.0163, acc-0.6000, valid loss-2.0743, acc-0.4200, test loss-2.0751, acc-0.4157\n",
      "Iter-21120, train loss-2.0837, acc-0.3600, valid loss-2.0742, acc-0.4204, test loss-2.0750, acc-0.4158\n",
      "Iter-21130, train loss-2.0932, acc-0.4600, valid loss-2.0741, acc-0.4204, test loss-2.0749, acc-0.4158\n",
      "Iter-21140, train loss-2.0801, acc-0.4200, valid loss-2.0740, acc-0.4202, test loss-2.0748, acc-0.4159\n",
      "Iter-21150, train loss-2.0645, acc-0.4000, valid loss-2.0739, acc-0.4202, test loss-2.0747, acc-0.4162\n",
      "Iter-21160, train loss-2.0389, acc-0.4600, valid loss-2.0738, acc-0.4202, test loss-2.0746, acc-0.4161\n",
      "Iter-21170, train loss-2.0533, acc-0.4400, valid loss-2.0737, acc-0.4204, test loss-2.0746, acc-0.4161\n",
      "Iter-21180, train loss-2.0826, acc-0.3800, valid loss-2.0736, acc-0.4206, test loss-2.0745, acc-0.4160\n",
      "Iter-21190, train loss-2.0413, acc-0.4400, valid loss-2.0735, acc-0.4206, test loss-2.0744, acc-0.4158\n",
      "Iter-21200, train loss-2.0877, acc-0.3800, valid loss-2.0735, acc-0.4202, test loss-2.0743, acc-0.4158\n",
      "Iter-21210, train loss-2.1040, acc-0.4400, valid loss-2.0734, acc-0.4202, test loss-2.0742, acc-0.4159\n",
      "Iter-21220, train loss-2.0973, acc-0.3800, valid loss-2.0733, acc-0.4202, test loss-2.0741, acc-0.4160\n",
      "Iter-21230, train loss-2.1154, acc-0.3000, valid loss-2.0732, acc-0.4206, test loss-2.0740, acc-0.4160\n",
      "Iter-21240, train loss-2.0872, acc-0.3000, valid loss-2.0731, acc-0.4206, test loss-2.0739, acc-0.4164\n",
      "Iter-21250, train loss-2.0464, acc-0.4600, valid loss-2.0730, acc-0.4208, test loss-2.0738, acc-0.4165\n",
      "Iter-21260, train loss-2.0747, acc-0.3800, valid loss-2.0729, acc-0.4206, test loss-2.0737, acc-0.4164\n",
      "Iter-21270, train loss-2.0708, acc-0.4400, valid loss-2.0728, acc-0.4204, test loss-2.0736, acc-0.4163\n",
      "Iter-21280, train loss-2.0911, acc-0.3600, valid loss-2.0727, acc-0.4204, test loss-2.0735, acc-0.4164\n",
      "Iter-21290, train loss-2.0483, acc-0.4000, valid loss-2.0726, acc-0.4204, test loss-2.0734, acc-0.4163\n",
      "Iter-21300, train loss-2.0298, acc-0.4200, valid loss-2.0725, acc-0.4202, test loss-2.0733, acc-0.4163\n",
      "Iter-21310, train loss-2.0485, acc-0.5400, valid loss-2.0724, acc-0.4202, test loss-2.0732, acc-0.4165\n",
      "Iter-21320, train loss-2.0844, acc-0.4600, valid loss-2.0723, acc-0.4204, test loss-2.0731, acc-0.4167\n",
      "Iter-21330, train loss-2.0629, acc-0.4800, valid loss-2.0723, acc-0.4200, test loss-2.0730, acc-0.4164\n",
      "Iter-21340, train loss-2.0779, acc-0.3600, valid loss-2.0722, acc-0.4198, test loss-2.0730, acc-0.4163\n",
      "Iter-21350, train loss-2.1029, acc-0.3000, valid loss-2.0721, acc-0.4196, test loss-2.0729, acc-0.4163\n",
      "Iter-21360, train loss-2.0698, acc-0.5000, valid loss-2.0720, acc-0.4196, test loss-2.0728, acc-0.4162\n",
      "Iter-21370, train loss-2.0936, acc-0.3600, valid loss-2.0719, acc-0.4198, test loss-2.0727, acc-0.4163\n",
      "Iter-21380, train loss-2.1093, acc-0.3600, valid loss-2.0718, acc-0.4196, test loss-2.0726, acc-0.4164\n",
      "Iter-21390, train loss-2.1187, acc-0.3200, valid loss-2.0717, acc-0.4196, test loss-2.0725, acc-0.4163\n",
      "Iter-21400, train loss-2.1020, acc-0.4400, valid loss-2.0716, acc-0.4204, test loss-2.0724, acc-0.4164\n",
      "Iter-21410, train loss-2.0380, acc-0.4200, valid loss-2.0715, acc-0.4200, test loss-2.0723, acc-0.4164\n",
      "Iter-21420, train loss-2.0401, acc-0.4800, valid loss-2.0714, acc-0.4202, test loss-2.0722, acc-0.4162\n",
      "Iter-21430, train loss-2.1092, acc-0.3000, valid loss-2.0713, acc-0.4204, test loss-2.0721, acc-0.4162\n",
      "Iter-21440, train loss-2.0572, acc-0.3800, valid loss-2.0712, acc-0.4202, test loss-2.0720, acc-0.4165\n",
      "Iter-21450, train loss-2.0672, acc-0.3600, valid loss-2.0711, acc-0.4204, test loss-2.0719, acc-0.4165\n",
      "Iter-21460, train loss-2.0690, acc-0.4000, valid loss-2.0710, acc-0.4202, test loss-2.0718, acc-0.4163\n",
      "Iter-21470, train loss-2.0996, acc-0.4000, valid loss-2.0709, acc-0.4204, test loss-2.0717, acc-0.4165\n",
      "Iter-21480, train loss-2.1105, acc-0.3000, valid loss-2.0708, acc-0.4206, test loss-2.0716, acc-0.4167\n",
      "Iter-21490, train loss-2.1059, acc-0.3800, valid loss-2.0707, acc-0.4210, test loss-2.0715, acc-0.4168\n",
      "Iter-21500, train loss-2.0842, acc-0.3800, valid loss-2.0707, acc-0.4210, test loss-2.0715, acc-0.4169\n",
      "Iter-21510, train loss-2.0600, acc-0.3800, valid loss-2.0706, acc-0.4214, test loss-2.0714, acc-0.4168\n",
      "Iter-21520, train loss-2.0410, acc-0.5200, valid loss-2.0705, acc-0.4214, test loss-2.0713, acc-0.4169\n",
      "Iter-21530, train loss-2.0760, acc-0.5000, valid loss-2.0704, acc-0.4214, test loss-2.0712, acc-0.4170\n",
      "Iter-21540, train loss-2.0657, acc-0.4600, valid loss-2.0703, acc-0.4212, test loss-2.0711, acc-0.4170\n",
      "Iter-21550, train loss-2.0639, acc-0.4400, valid loss-2.0702, acc-0.4212, test loss-2.0710, acc-0.4169\n",
      "Iter-21560, train loss-2.0777, acc-0.3800, valid loss-2.0701, acc-0.4212, test loss-2.0709, acc-0.4170\n",
      "Iter-21570, train loss-2.0992, acc-0.3600, valid loss-2.0700, acc-0.4212, test loss-2.0708, acc-0.4169\n",
      "Iter-21580, train loss-2.0319, acc-0.5400, valid loss-2.0699, acc-0.4212, test loss-2.0707, acc-0.4171\n",
      "Iter-21590, train loss-2.0883, acc-0.3600, valid loss-2.0698, acc-0.4218, test loss-2.0706, acc-0.4170\n",
      "Iter-21600, train loss-2.0667, acc-0.4400, valid loss-2.0697, acc-0.4216, test loss-2.0705, acc-0.4172\n",
      "Iter-21610, train loss-2.1033, acc-0.3400, valid loss-2.0696, acc-0.4218, test loss-2.0704, acc-0.4174\n",
      "Iter-21620, train loss-2.0861, acc-0.4200, valid loss-2.0696, acc-0.4220, test loss-2.0703, acc-0.4173\n",
      "Iter-21630, train loss-2.0860, acc-0.3400, valid loss-2.0695, acc-0.4222, test loss-2.0702, acc-0.4173\n",
      "Iter-21640, train loss-2.1492, acc-0.2600, valid loss-2.0694, acc-0.4216, test loss-2.0702, acc-0.4172\n",
      "Iter-21650, train loss-2.0574, acc-0.3600, valid loss-2.0693, acc-0.4212, test loss-2.0701, acc-0.4170\n",
      "Iter-21660, train loss-2.0759, acc-0.4800, valid loss-2.0692, acc-0.4216, test loss-2.0700, acc-0.4171\n",
      "Iter-21670, train loss-2.0216, acc-0.5200, valid loss-2.0691, acc-0.4216, test loss-2.0699, acc-0.4170\n",
      "Iter-21680, train loss-2.1055, acc-0.3200, valid loss-2.0690, acc-0.4220, test loss-2.0698, acc-0.4170\n",
      "Iter-21690, train loss-2.0557, acc-0.4400, valid loss-2.0689, acc-0.4222, test loss-2.0697, acc-0.4171\n",
      "Iter-21700, train loss-2.0889, acc-0.3800, valid loss-2.0688, acc-0.4220, test loss-2.0696, acc-0.4170\n",
      "Iter-21710, train loss-2.0142, acc-0.4600, valid loss-2.0687, acc-0.4220, test loss-2.0695, acc-0.4170\n",
      "Iter-21720, train loss-2.0951, acc-0.4400, valid loss-2.0686, acc-0.4220, test loss-2.0694, acc-0.4171\n",
      "Iter-21730, train loss-2.0206, acc-0.4600, valid loss-2.0685, acc-0.4222, test loss-2.0693, acc-0.4170\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-21740, train loss-2.0668, acc-0.4400, valid loss-2.0684, acc-0.4218, test loss-2.0692, acc-0.4171\n",
      "Iter-21750, train loss-2.0963, acc-0.3600, valid loss-2.0683, acc-0.4222, test loss-2.0691, acc-0.4171\n",
      "Iter-21760, train loss-2.0320, acc-0.4800, valid loss-2.0682, acc-0.4222, test loss-2.0690, acc-0.4167\n",
      "Iter-21770, train loss-2.0904, acc-0.3400, valid loss-2.0682, acc-0.4224, test loss-2.0689, acc-0.4169\n",
      "Iter-21780, train loss-2.1066, acc-0.3400, valid loss-2.0681, acc-0.4226, test loss-2.0688, acc-0.4171\n",
      "Iter-21790, train loss-2.0563, acc-0.4400, valid loss-2.0680, acc-0.4224, test loss-2.0687, acc-0.4176\n",
      "Iter-21800, train loss-2.0804, acc-0.4000, valid loss-2.0679, acc-0.4228, test loss-2.0687, acc-0.4177\n",
      "Iter-21810, train loss-2.0218, acc-0.4600, valid loss-2.0678, acc-0.4228, test loss-2.0686, acc-0.4174\n",
      "Iter-21820, train loss-2.0854, acc-0.4400, valid loss-2.0677, acc-0.4228, test loss-2.0685, acc-0.4173\n",
      "Iter-21830, train loss-2.0613, acc-0.3800, valid loss-2.0676, acc-0.4232, test loss-2.0684, acc-0.4172\n",
      "Iter-21840, train loss-2.0998, acc-0.3400, valid loss-2.0675, acc-0.4230, test loss-2.0683, acc-0.4172\n",
      "Iter-21850, train loss-2.0160, acc-0.4600, valid loss-2.0674, acc-0.4230, test loss-2.0682, acc-0.4172\n",
      "Iter-21860, train loss-2.0668, acc-0.4400, valid loss-2.0673, acc-0.4230, test loss-2.0681, acc-0.4172\n",
      "Iter-21870, train loss-2.0386, acc-0.3800, valid loss-2.0672, acc-0.4230, test loss-2.0680, acc-0.4173\n",
      "Iter-21880, train loss-2.0602, acc-0.4400, valid loss-2.0671, acc-0.4232, test loss-2.0679, acc-0.4178\n",
      "Iter-21890, train loss-2.0678, acc-0.4600, valid loss-2.0670, acc-0.4230, test loss-2.0678, acc-0.4176\n",
      "Iter-21900, train loss-2.0580, acc-0.4200, valid loss-2.0670, acc-0.4232, test loss-2.0677, acc-0.4178\n",
      "Iter-21910, train loss-2.0502, acc-0.5000, valid loss-2.0669, acc-0.4230, test loss-2.0676, acc-0.4176\n",
      "Iter-21920, train loss-2.0508, acc-0.4000, valid loss-2.0668, acc-0.4230, test loss-2.0675, acc-0.4174\n",
      "Iter-21930, train loss-2.0818, acc-0.3600, valid loss-2.0667, acc-0.4234, test loss-2.0674, acc-0.4175\n",
      "Iter-21940, train loss-2.0548, acc-0.4200, valid loss-2.0666, acc-0.4232, test loss-2.0673, acc-0.4175\n",
      "Iter-21950, train loss-2.1513, acc-0.2800, valid loss-2.0665, acc-0.4234, test loss-2.0673, acc-0.4172\n",
      "Iter-21960, train loss-2.0586, acc-0.4800, valid loss-2.0664, acc-0.4232, test loss-2.0672, acc-0.4174\n",
      "Iter-21970, train loss-2.0554, acc-0.4600, valid loss-2.0663, acc-0.4236, test loss-2.0671, acc-0.4174\n",
      "Iter-21980, train loss-2.0666, acc-0.3200, valid loss-2.0662, acc-0.4240, test loss-2.0670, acc-0.4176\n",
      "Iter-21990, train loss-2.1145, acc-0.3000, valid loss-2.0661, acc-0.4240, test loss-2.0669, acc-0.4176\n",
      "Iter-22000, train loss-2.1199, acc-0.4200, valid loss-2.0660, acc-0.4240, test loss-2.0668, acc-0.4177\n",
      "Iter-22010, train loss-2.0805, acc-0.4200, valid loss-2.0659, acc-0.4242, test loss-2.0667, acc-0.4177\n",
      "Iter-22020, train loss-2.1062, acc-0.3000, valid loss-2.0658, acc-0.4242, test loss-2.0666, acc-0.4177\n",
      "Iter-22030, train loss-2.0946, acc-0.3600, valid loss-2.0657, acc-0.4242, test loss-2.0665, acc-0.4178\n",
      "Iter-22040, train loss-2.1041, acc-0.4200, valid loss-2.0656, acc-0.4240, test loss-2.0664, acc-0.4180\n",
      "Iter-22050, train loss-2.1077, acc-0.3200, valid loss-2.0655, acc-0.4244, test loss-2.0663, acc-0.4180\n",
      "Iter-22060, train loss-2.0870, acc-0.4000, valid loss-2.0654, acc-0.4238, test loss-2.0662, acc-0.4176\n",
      "Iter-22070, train loss-2.0457, acc-0.4400, valid loss-2.0653, acc-0.4238, test loss-2.0661, acc-0.4175\n",
      "Iter-22080, train loss-2.0408, acc-0.4200, valid loss-2.0652, acc-0.4236, test loss-2.0660, acc-0.4172\n",
      "Iter-22090, train loss-2.1008, acc-0.3400, valid loss-2.0651, acc-0.4240, test loss-2.0659, acc-0.4174\n",
      "Iter-22100, train loss-2.0751, acc-0.4200, valid loss-2.0651, acc-0.4240, test loss-2.0658, acc-0.4174\n",
      "Iter-22110, train loss-2.0586, acc-0.3800, valid loss-2.0650, acc-0.4236, test loss-2.0658, acc-0.4173\n",
      "Iter-22120, train loss-2.0939, acc-0.4400, valid loss-2.0649, acc-0.4238, test loss-2.0657, acc-0.4174\n",
      "Iter-22130, train loss-2.0695, acc-0.4200, valid loss-2.0648, acc-0.4238, test loss-2.0656, acc-0.4171\n",
      "Iter-22140, train loss-2.0370, acc-0.4200, valid loss-2.0647, acc-0.4234, test loss-2.0655, acc-0.4170\n",
      "Iter-22150, train loss-2.0410, acc-0.4600, valid loss-2.0646, acc-0.4238, test loss-2.0654, acc-0.4172\n",
      "Iter-22160, train loss-2.0505, acc-0.5200, valid loss-2.0645, acc-0.4236, test loss-2.0653, acc-0.4172\n",
      "Iter-22170, train loss-2.0353, acc-0.4400, valid loss-2.0644, acc-0.4236, test loss-2.0652, acc-0.4173\n",
      "Iter-22180, train loss-2.0927, acc-0.4000, valid loss-2.0643, acc-0.4238, test loss-2.0651, acc-0.4175\n",
      "Iter-22190, train loss-2.0921, acc-0.4200, valid loss-2.0642, acc-0.4238, test loss-2.0650, acc-0.4172\n",
      "Iter-22200, train loss-2.0572, acc-0.4400, valid loss-2.0641, acc-0.4238, test loss-2.0649, acc-0.4171\n",
      "Iter-22210, train loss-2.0795, acc-0.4200, valid loss-2.0640, acc-0.4240, test loss-2.0648, acc-0.4171\n",
      "Iter-22220, train loss-2.0551, acc-0.4200, valid loss-2.0639, acc-0.4242, test loss-2.0647, acc-0.4173\n",
      "Iter-22230, train loss-2.0827, acc-0.4000, valid loss-2.0638, acc-0.4242, test loss-2.0646, acc-0.4173\n",
      "Iter-22240, train loss-2.1132, acc-0.4200, valid loss-2.0637, acc-0.4244, test loss-2.0645, acc-0.4173\n",
      "Iter-22250, train loss-2.0586, acc-0.4600, valid loss-2.0636, acc-0.4246, test loss-2.0644, acc-0.4173\n",
      "Iter-22260, train loss-2.0718, acc-0.4600, valid loss-2.0636, acc-0.4244, test loss-2.0644, acc-0.4174\n",
      "Iter-22270, train loss-2.0367, acc-0.4400, valid loss-2.0635, acc-0.4246, test loss-2.0643, acc-0.4174\n",
      "Iter-22280, train loss-2.1129, acc-0.3400, valid loss-2.0634, acc-0.4246, test loss-2.0642, acc-0.4172\n",
      "Iter-22290, train loss-2.0771, acc-0.3600, valid loss-2.0633, acc-0.4244, test loss-2.0641, acc-0.4172\n",
      "Iter-22300, train loss-2.0595, acc-0.4600, valid loss-2.0632, acc-0.4244, test loss-2.0640, acc-0.4171\n",
      "Iter-22310, train loss-2.0803, acc-0.4600, valid loss-2.0631, acc-0.4246, test loss-2.0639, acc-0.4171\n",
      "Iter-22320, train loss-1.9551, acc-0.6400, valid loss-2.0630, acc-0.4246, test loss-2.0638, acc-0.4172\n",
      "Iter-22330, train loss-2.1066, acc-0.3000, valid loss-2.0629, acc-0.4244, test loss-2.0637, acc-0.4173\n",
      "Iter-22340, train loss-2.0763, acc-0.4200, valid loss-2.0628, acc-0.4244, test loss-2.0636, acc-0.4174\n",
      "Iter-22350, train loss-2.0344, acc-0.5200, valid loss-2.0627, acc-0.4244, test loss-2.0635, acc-0.4175\n",
      "Iter-22360, train loss-2.0703, acc-0.4000, valid loss-2.0626, acc-0.4246, test loss-2.0634, acc-0.4177\n",
      "Iter-22370, train loss-2.1109, acc-0.3600, valid loss-2.0625, acc-0.4244, test loss-2.0633, acc-0.4174\n",
      "Iter-22380, train loss-2.0512, acc-0.4800, valid loss-2.0624, acc-0.4244, test loss-2.0632, acc-0.4175\n",
      "Iter-22390, train loss-2.0903, acc-0.3400, valid loss-2.0623, acc-0.4250, test loss-2.0632, acc-0.4178\n",
      "Iter-22400, train loss-2.0663, acc-0.4600, valid loss-2.0623, acc-0.4250, test loss-2.0631, acc-0.4179\n",
      "Iter-22410, train loss-2.1072, acc-0.3200, valid loss-2.0622, acc-0.4250, test loss-2.0630, acc-0.4177\n",
      "Iter-22420, train loss-2.0656, acc-0.4600, valid loss-2.0621, acc-0.4246, test loss-2.0629, acc-0.4176\n",
      "Iter-22430, train loss-2.0555, acc-0.3600, valid loss-2.0620, acc-0.4248, test loss-2.0628, acc-0.4176\n",
      "Iter-22440, train loss-2.0299, acc-0.5000, valid loss-2.0619, acc-0.4250, test loss-2.0627, acc-0.4175\n",
      "Iter-22450, train loss-2.0482, acc-0.5400, valid loss-2.0618, acc-0.4248, test loss-2.0626, acc-0.4177\n",
      "Iter-22460, train loss-2.0328, acc-0.4400, valid loss-2.0617, acc-0.4252, test loss-2.0625, acc-0.4175\n",
      "Iter-22470, train loss-2.0476, acc-0.4000, valid loss-2.0616, acc-0.4254, test loss-2.0624, acc-0.4177\n",
      "Iter-22480, train loss-2.0274, acc-0.3800, valid loss-2.0615, acc-0.4254, test loss-2.0623, acc-0.4179\n",
      "Iter-22490, train loss-2.0412, acc-0.4000, valid loss-2.0614, acc-0.4252, test loss-2.0622, acc-0.4178\n",
      "Iter-22500, train loss-2.0965, acc-0.4400, valid loss-2.0613, acc-0.4252, test loss-2.0621, acc-0.4177\n",
      "Iter-22510, train loss-2.0749, acc-0.3800, valid loss-2.0612, acc-0.4252, test loss-2.0620, acc-0.4177\n",
      "Iter-22520, train loss-2.0869, acc-0.3600, valid loss-2.0611, acc-0.4252, test loss-2.0619, acc-0.4175\n",
      "Iter-22530, train loss-2.0677, acc-0.4000, valid loss-2.0610, acc-0.4254, test loss-2.0618, acc-0.4179\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-22540, train loss-2.0752, acc-0.4200, valid loss-2.0609, acc-0.4256, test loss-2.0618, acc-0.4177\n",
      "Iter-22550, train loss-2.0437, acc-0.3400, valid loss-2.0608, acc-0.4250, test loss-2.0617, acc-0.4179\n",
      "Iter-22560, train loss-2.1083, acc-0.2800, valid loss-2.0607, acc-0.4248, test loss-2.0616, acc-0.4175\n",
      "Iter-22570, train loss-2.0240, acc-0.3400, valid loss-2.0607, acc-0.4246, test loss-2.0615, acc-0.4176\n",
      "Iter-22580, train loss-2.1060, acc-0.3600, valid loss-2.0606, acc-0.4244, test loss-2.0614, acc-0.4179\n",
      "Iter-22590, train loss-2.0257, acc-0.3800, valid loss-2.0605, acc-0.4246, test loss-2.0613, acc-0.4178\n",
      "Iter-22600, train loss-2.0671, acc-0.3400, valid loss-2.0604, acc-0.4252, test loss-2.0612, acc-0.4177\n",
      "Iter-22610, train loss-2.0553, acc-0.4000, valid loss-2.0603, acc-0.4254, test loss-2.0611, acc-0.4179\n",
      "Iter-22620, train loss-2.0633, acc-0.3400, valid loss-2.0602, acc-0.4252, test loss-2.0610, acc-0.4175\n",
      "Iter-22630, train loss-2.0686, acc-0.4400, valid loss-2.0601, acc-0.4254, test loss-2.0609, acc-0.4177\n",
      "Iter-22640, train loss-2.1094, acc-0.3600, valid loss-2.0600, acc-0.4262, test loss-2.0609, acc-0.4180\n",
      "Iter-22650, train loss-2.0928, acc-0.3800, valid loss-2.0599, acc-0.4262, test loss-2.0608, acc-0.4175\n",
      "Iter-22660, train loss-2.1235, acc-0.3400, valid loss-2.0599, acc-0.4258, test loss-2.0607, acc-0.4176\n",
      "Iter-22670, train loss-2.0621, acc-0.5000, valid loss-2.0598, acc-0.4256, test loss-2.0606, acc-0.4176\n",
      "Iter-22680, train loss-2.0898, acc-0.4600, valid loss-2.0597, acc-0.4258, test loss-2.0605, acc-0.4178\n",
      "Iter-22690, train loss-2.0504, acc-0.4000, valid loss-2.0596, acc-0.4260, test loss-2.0604, acc-0.4178\n",
      "Iter-22700, train loss-2.0897, acc-0.4400, valid loss-2.0595, acc-0.4258, test loss-2.0603, acc-0.4180\n",
      "Iter-22710, train loss-2.0009, acc-0.5800, valid loss-2.0594, acc-0.4256, test loss-2.0602, acc-0.4181\n",
      "Iter-22720, train loss-2.0789, acc-0.4000, valid loss-2.0593, acc-0.4256, test loss-2.0601, acc-0.4181\n",
      "Iter-22730, train loss-2.0548, acc-0.4400, valid loss-2.0592, acc-0.4256, test loss-2.0600, acc-0.4180\n",
      "Iter-22740, train loss-2.1278, acc-0.2600, valid loss-2.0591, acc-0.4256, test loss-2.0599, acc-0.4183\n",
      "Iter-22750, train loss-2.1434, acc-0.2200, valid loss-2.0590, acc-0.4258, test loss-2.0598, acc-0.4181\n",
      "Iter-22760, train loss-2.0564, acc-0.4000, valid loss-2.0589, acc-0.4258, test loss-2.0597, acc-0.4180\n",
      "Iter-22770, train loss-2.0849, acc-0.3400, valid loss-2.0588, acc-0.4260, test loss-2.0597, acc-0.4181\n",
      "Iter-22780, train loss-1.9757, acc-0.5600, valid loss-2.0587, acc-0.4262, test loss-2.0596, acc-0.4183\n",
      "Iter-22790, train loss-2.0614, acc-0.4200, valid loss-2.0586, acc-0.4262, test loss-2.0595, acc-0.4183\n",
      "Iter-22800, train loss-2.0686, acc-0.4000, valid loss-2.0586, acc-0.4262, test loss-2.0594, acc-0.4184\n",
      "Iter-22810, train loss-2.0775, acc-0.4400, valid loss-2.0585, acc-0.4264, test loss-2.0593, acc-0.4184\n",
      "Iter-22820, train loss-2.0995, acc-0.4000, valid loss-2.0584, acc-0.4264, test loss-2.0592, acc-0.4184\n",
      "Iter-22830, train loss-2.0785, acc-0.3600, valid loss-2.0583, acc-0.4264, test loss-2.0591, acc-0.4185\n",
      "Iter-22840, train loss-2.1352, acc-0.2600, valid loss-2.0582, acc-0.4262, test loss-2.0590, acc-0.4185\n",
      "Iter-22850, train loss-2.0184, acc-0.5200, valid loss-2.0581, acc-0.4268, test loss-2.0589, acc-0.4186\n",
      "Iter-22860, train loss-2.0498, acc-0.4800, valid loss-2.0580, acc-0.4268, test loss-2.0588, acc-0.4185\n",
      "Iter-22870, train loss-2.0668, acc-0.3800, valid loss-2.0579, acc-0.4270, test loss-2.0587, acc-0.4189\n",
      "Iter-22880, train loss-2.0828, acc-0.4600, valid loss-2.0578, acc-0.4270, test loss-2.0586, acc-0.4191\n",
      "Iter-22890, train loss-2.1076, acc-0.3600, valid loss-2.0577, acc-0.4268, test loss-2.0586, acc-0.4189\n",
      "Iter-22900, train loss-2.0343, acc-0.4400, valid loss-2.0577, acc-0.4270, test loss-2.0585, acc-0.4190\n",
      "Iter-22910, train loss-2.0480, acc-0.5400, valid loss-2.0576, acc-0.4278, test loss-2.0584, acc-0.4191\n",
      "Iter-22920, train loss-2.0525, acc-0.4000, valid loss-2.0575, acc-0.4274, test loss-2.0583, acc-0.4189\n",
      "Iter-22930, train loss-2.1248, acc-0.4600, valid loss-2.0574, acc-0.4276, test loss-2.0582, acc-0.4189\n",
      "Iter-22940, train loss-2.0722, acc-0.4200, valid loss-2.0573, acc-0.4278, test loss-2.0581, acc-0.4191\n",
      "Iter-22950, train loss-2.0335, acc-0.4800, valid loss-2.0572, acc-0.4276, test loss-2.0580, acc-0.4191\n",
      "Iter-22960, train loss-2.0775, acc-0.3600, valid loss-2.0571, acc-0.4272, test loss-2.0579, acc-0.4190\n",
      "Iter-22970, train loss-2.0427, acc-0.4200, valid loss-2.0570, acc-0.4274, test loss-2.0578, acc-0.4191\n",
      "Iter-22980, train loss-2.0929, acc-0.3800, valid loss-2.0569, acc-0.4272, test loss-2.0577, acc-0.4191\n",
      "Iter-22990, train loss-2.0502, acc-0.4000, valid loss-2.0568, acc-0.4272, test loss-2.0576, acc-0.4190\n",
      "Iter-23000, train loss-2.0572, acc-0.4800, valid loss-2.0567, acc-0.4268, test loss-2.0576, acc-0.4191\n",
      "Iter-23010, train loss-2.0155, acc-0.4800, valid loss-2.0567, acc-0.4272, test loss-2.0575, acc-0.4192\n",
      "Iter-23020, train loss-2.0255, acc-0.4600, valid loss-2.0566, acc-0.4272, test loss-2.0574, acc-0.4192\n",
      "Iter-23030, train loss-2.0611, acc-0.4200, valid loss-2.0565, acc-0.4276, test loss-2.0573, acc-0.4189\n",
      "Iter-23040, train loss-2.0504, acc-0.5200, valid loss-2.0564, acc-0.4274, test loss-2.0572, acc-0.4189\n",
      "Iter-23050, train loss-2.0617, acc-0.4600, valid loss-2.0563, acc-0.4274, test loss-2.0571, acc-0.4188\n",
      "Iter-23060, train loss-2.0520, acc-0.3200, valid loss-2.0562, acc-0.4276, test loss-2.0570, acc-0.4188\n",
      "Iter-23070, train loss-2.0941, acc-0.3000, valid loss-2.0561, acc-0.4276, test loss-2.0569, acc-0.4189\n",
      "Iter-23080, train loss-2.0488, acc-0.4000, valid loss-2.0560, acc-0.4274, test loss-2.0568, acc-0.4192\n",
      "Iter-23090, train loss-2.1288, acc-0.3400, valid loss-2.0559, acc-0.4276, test loss-2.0567, acc-0.4191\n",
      "Iter-23100, train loss-2.0988, acc-0.3600, valid loss-2.0558, acc-0.4278, test loss-2.0566, acc-0.4191\n",
      "Iter-23110, train loss-2.0400, acc-0.4400, valid loss-2.0557, acc-0.4276, test loss-2.0565, acc-0.4195\n",
      "Iter-23120, train loss-2.0424, acc-0.4800, valid loss-2.0557, acc-0.4274, test loss-2.0564, acc-0.4194\n",
      "Iter-23130, train loss-2.0164, acc-0.4600, valid loss-2.0556, acc-0.4278, test loss-2.0564, acc-0.4195\n",
      "Iter-23140, train loss-2.0373, acc-0.5000, valid loss-2.0555, acc-0.4280, test loss-2.0563, acc-0.4196\n",
      "Iter-23150, train loss-2.0803, acc-0.3200, valid loss-2.0554, acc-0.4276, test loss-2.0562, acc-0.4193\n",
      "Iter-23160, train loss-2.0996, acc-0.3800, valid loss-2.0553, acc-0.4276, test loss-2.0561, acc-0.4193\n",
      "Iter-23170, train loss-2.0912, acc-0.3600, valid loss-2.0552, acc-0.4278, test loss-2.0560, acc-0.4192\n",
      "Iter-23180, train loss-2.0706, acc-0.5200, valid loss-2.0551, acc-0.4274, test loss-2.0559, acc-0.4195\n",
      "Iter-23190, train loss-2.0401, acc-0.4800, valid loss-2.0550, acc-0.4274, test loss-2.0558, acc-0.4194\n",
      "Iter-23200, train loss-2.0045, acc-0.6000, valid loss-2.0549, acc-0.4280, test loss-2.0557, acc-0.4194\n",
      "Iter-23210, train loss-2.0830, acc-0.4000, valid loss-2.0548, acc-0.4278, test loss-2.0556, acc-0.4197\n",
      "Iter-23220, train loss-2.0541, acc-0.4600, valid loss-2.0547, acc-0.4280, test loss-2.0555, acc-0.4197\n",
      "Iter-23230, train loss-2.0265, acc-0.4000, valid loss-2.0547, acc-0.4276, test loss-2.0554, acc-0.4196\n",
      "Iter-23240, train loss-2.1331, acc-0.2800, valid loss-2.0546, acc-0.4274, test loss-2.0554, acc-0.4199\n",
      "Iter-23250, train loss-2.0691, acc-0.4200, valid loss-2.0545, acc-0.4280, test loss-2.0553, acc-0.4200\n",
      "Iter-23260, train loss-2.0401, acc-0.4400, valid loss-2.0544, acc-0.4278, test loss-2.0552, acc-0.4199\n",
      "Iter-23270, train loss-2.0682, acc-0.3400, valid loss-2.0543, acc-0.4276, test loss-2.0551, acc-0.4200\n",
      "Iter-23280, train loss-2.0632, acc-0.3400, valid loss-2.0542, acc-0.4276, test loss-2.0550, acc-0.4199\n",
      "Iter-23290, train loss-2.0195, acc-0.4400, valid loss-2.0541, acc-0.4276, test loss-2.0549, acc-0.4199\n",
      "Iter-23300, train loss-2.0539, acc-0.4600, valid loss-2.0540, acc-0.4276, test loss-2.0548, acc-0.4202\n",
      "Iter-23310, train loss-2.0548, acc-0.4400, valid loss-2.0540, acc-0.4278, test loss-2.0547, acc-0.4198\n",
      "Iter-23320, train loss-2.0318, acc-0.5000, valid loss-2.0539, acc-0.4278, test loss-2.0546, acc-0.4199\n",
      "Iter-23330, train loss-2.0272, acc-0.3800, valid loss-2.0538, acc-0.4278, test loss-2.0546, acc-0.4202\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-23340, train loss-1.9598, acc-0.5600, valid loss-2.0537, acc-0.4280, test loss-2.0545, acc-0.4203\n",
      "Iter-23350, train loss-2.0660, acc-0.3800, valid loss-2.0536, acc-0.4280, test loss-2.0544, acc-0.4202\n",
      "Iter-23360, train loss-2.1164, acc-0.4200, valid loss-2.0535, acc-0.4278, test loss-2.0543, acc-0.4203\n",
      "Iter-23370, train loss-2.0448, acc-0.3800, valid loss-2.0534, acc-0.4280, test loss-2.0542, acc-0.4202\n",
      "Iter-23380, train loss-1.9900, acc-0.6000, valid loss-2.0533, acc-0.4278, test loss-2.0541, acc-0.4203\n",
      "Iter-23390, train loss-2.1008, acc-0.4000, valid loss-2.0532, acc-0.4280, test loss-2.0540, acc-0.4203\n",
      "Iter-23400, train loss-2.0810, acc-0.3400, valid loss-2.0531, acc-0.4282, test loss-2.0539, acc-0.4205\n",
      "Iter-23410, train loss-2.0632, acc-0.4600, valid loss-2.0530, acc-0.4284, test loss-2.0538, acc-0.4206\n",
      "Iter-23420, train loss-2.0579, acc-0.4200, valid loss-2.0529, acc-0.4288, test loss-2.0537, acc-0.4205\n",
      "Iter-23430, train loss-2.1253, acc-0.3200, valid loss-2.0529, acc-0.4284, test loss-2.0536, acc-0.4208\n",
      "Iter-23440, train loss-2.0527, acc-0.4200, valid loss-2.0528, acc-0.4284, test loss-2.0536, acc-0.4205\n",
      "Iter-23450, train loss-2.0838, acc-0.3800, valid loss-2.0527, acc-0.4282, test loss-2.0535, acc-0.4207\n",
      "Iter-23460, train loss-2.0662, acc-0.4200, valid loss-2.0526, acc-0.4282, test loss-2.0534, acc-0.4206\n",
      "Iter-23470, train loss-2.1125, acc-0.3400, valid loss-2.0525, acc-0.4280, test loss-2.0533, acc-0.4206\n",
      "Iter-23480, train loss-2.0383, acc-0.3600, valid loss-2.0524, acc-0.4278, test loss-2.0532, acc-0.4208\n",
      "Iter-23490, train loss-2.0275, acc-0.4600, valid loss-2.0523, acc-0.4276, test loss-2.0531, acc-0.4211\n",
      "Iter-23500, train loss-2.0666, acc-0.4200, valid loss-2.0522, acc-0.4278, test loss-2.0530, acc-0.4210\n",
      "Iter-23510, train loss-2.0678, acc-0.3600, valid loss-2.0521, acc-0.4274, test loss-2.0529, acc-0.4211\n",
      "Iter-23520, train loss-2.0781, acc-0.3800, valid loss-2.0520, acc-0.4274, test loss-2.0528, acc-0.4211\n",
      "Iter-23530, train loss-2.0942, acc-0.3800, valid loss-2.0519, acc-0.4276, test loss-2.0527, acc-0.4211\n",
      "Iter-23540, train loss-2.0536, acc-0.4600, valid loss-2.0519, acc-0.4276, test loss-2.0526, acc-0.4212\n",
      "Iter-23550, train loss-2.0526, acc-0.4000, valid loss-2.0518, acc-0.4278, test loss-2.0526, acc-0.4213\n",
      "Iter-23560, train loss-2.1000, acc-0.3400, valid loss-2.0517, acc-0.4276, test loss-2.0525, acc-0.4215\n",
      "Iter-23570, train loss-2.0220, acc-0.4200, valid loss-2.0516, acc-0.4278, test loss-2.0524, acc-0.4215\n",
      "Iter-23580, train loss-2.0443, acc-0.4000, valid loss-2.0515, acc-0.4280, test loss-2.0523, acc-0.4218\n",
      "Iter-23590, train loss-2.0527, acc-0.4800, valid loss-2.0514, acc-0.4280, test loss-2.0522, acc-0.4220\n",
      "Iter-23600, train loss-2.0756, acc-0.4200, valid loss-2.0513, acc-0.4284, test loss-2.0521, acc-0.4218\n",
      "Iter-23610, train loss-2.0039, acc-0.4800, valid loss-2.0512, acc-0.4282, test loss-2.0520, acc-0.4218\n",
      "Iter-23620, train loss-2.0230, acc-0.4200, valid loss-2.0511, acc-0.4282, test loss-2.0519, acc-0.4220\n",
      "Iter-23630, train loss-2.0925, acc-0.3200, valid loss-2.0510, acc-0.4286, test loss-2.0518, acc-0.4218\n",
      "Iter-23640, train loss-2.0332, acc-0.3600, valid loss-2.0510, acc-0.4286, test loss-2.0517, acc-0.4221\n",
      "Iter-23650, train loss-2.0575, acc-0.4000, valid loss-2.0509, acc-0.4284, test loss-2.0517, acc-0.4224\n",
      "Iter-23660, train loss-2.0337, acc-0.5800, valid loss-2.0508, acc-0.4286, test loss-2.0516, acc-0.4224\n",
      "Iter-23670, train loss-2.0451, acc-0.4000, valid loss-2.0507, acc-0.4284, test loss-2.0515, acc-0.4225\n",
      "Iter-23680, train loss-2.0184, acc-0.5000, valid loss-2.0506, acc-0.4286, test loss-2.0514, acc-0.4226\n",
      "Iter-23690, train loss-2.1148, acc-0.3200, valid loss-2.0505, acc-0.4290, test loss-2.0513, acc-0.4225\n",
      "Iter-23700, train loss-2.0942, acc-0.3600, valid loss-2.0504, acc-0.4288, test loss-2.0512, acc-0.4226\n",
      "Iter-23710, train loss-2.0213, acc-0.4600, valid loss-2.0503, acc-0.4296, test loss-2.0511, acc-0.4226\n",
      "Iter-23720, train loss-2.0712, acc-0.3800, valid loss-2.0502, acc-0.4294, test loss-2.0510, acc-0.4226\n",
      "Iter-23730, train loss-2.0240, acc-0.4200, valid loss-2.0501, acc-0.4294, test loss-2.0510, acc-0.4226\n",
      "Iter-23740, train loss-2.1016, acc-0.3800, valid loss-2.0501, acc-0.4294, test loss-2.0509, acc-0.4228\n",
      "Iter-23750, train loss-2.0926, acc-0.4200, valid loss-2.0500, acc-0.4292, test loss-2.0508, acc-0.4229\n",
      "Iter-23760, train loss-2.0803, acc-0.4800, valid loss-2.0499, acc-0.4292, test loss-2.0507, acc-0.4230\n",
      "Iter-23770, train loss-2.0422, acc-0.4800, valid loss-2.0498, acc-0.4290, test loss-2.0506, acc-0.4230\n",
      "Iter-23780, train loss-2.0472, acc-0.5200, valid loss-2.0497, acc-0.4290, test loss-2.0505, acc-0.4231\n",
      "Iter-23790, train loss-2.0214, acc-0.5000, valid loss-2.0496, acc-0.4290, test loss-2.0504, acc-0.4229\n",
      "Iter-23800, train loss-2.1076, acc-0.3800, valid loss-2.0495, acc-0.4286, test loss-2.0503, acc-0.4227\n",
      "Iter-23810, train loss-2.0435, acc-0.3800, valid loss-2.0494, acc-0.4286, test loss-2.0502, acc-0.4227\n",
      "Iter-23820, train loss-2.0460, acc-0.4600, valid loss-2.0493, acc-0.4284, test loss-2.0501, acc-0.4230\n",
      "Iter-23830, train loss-2.0087, acc-0.5600, valid loss-2.0493, acc-0.4286, test loss-2.0501, acc-0.4230\n",
      "Iter-23840, train loss-2.0223, acc-0.5000, valid loss-2.0492, acc-0.4292, test loss-2.0500, acc-0.4231\n",
      "Iter-23850, train loss-2.0715, acc-0.4000, valid loss-2.0491, acc-0.4290, test loss-2.0499, acc-0.4230\n",
      "Iter-23860, train loss-2.0309, acc-0.3600, valid loss-2.0490, acc-0.4294, test loss-2.0498, acc-0.4230\n",
      "Iter-23870, train loss-2.0584, acc-0.3800, valid loss-2.0489, acc-0.4292, test loss-2.0497, acc-0.4231\n",
      "Iter-23880, train loss-2.0295, acc-0.5200, valid loss-2.0488, acc-0.4292, test loss-2.0496, acc-0.4230\n",
      "Iter-23890, train loss-2.0674, acc-0.4200, valid loss-2.0487, acc-0.4294, test loss-2.0495, acc-0.4231\n",
      "Iter-23900, train loss-2.0303, acc-0.4800, valid loss-2.0486, acc-0.4294, test loss-2.0494, acc-0.4232\n",
      "Iter-23910, train loss-2.1036, acc-0.4400, valid loss-2.0485, acc-0.4292, test loss-2.0493, acc-0.4233\n",
      "Iter-23920, train loss-2.0488, acc-0.4400, valid loss-2.0484, acc-0.4294, test loss-2.0492, acc-0.4235\n",
      "Iter-23930, train loss-2.0393, acc-0.5000, valid loss-2.0484, acc-0.4290, test loss-2.0491, acc-0.4235\n",
      "Iter-23940, train loss-2.0825, acc-0.3200, valid loss-2.0483, acc-0.4288, test loss-2.0491, acc-0.4234\n",
      "Iter-23950, train loss-2.0793, acc-0.4400, valid loss-2.0482, acc-0.4290, test loss-2.0490, acc-0.4234\n",
      "Iter-23960, train loss-2.0139, acc-0.4600, valid loss-2.0481, acc-0.4288, test loss-2.0489, acc-0.4234\n",
      "Iter-23970, train loss-2.0567, acc-0.4000, valid loss-2.0480, acc-0.4288, test loss-2.0488, acc-0.4234\n",
      "Iter-23980, train loss-2.0528, acc-0.4600, valid loss-2.0479, acc-0.4292, test loss-2.0487, acc-0.4236\n",
      "Iter-23990, train loss-2.0576, acc-0.4200, valid loss-2.0478, acc-0.4290, test loss-2.0486, acc-0.4240\n",
      "Iter-24000, train loss-2.0611, acc-0.4400, valid loss-2.0478, acc-0.4290, test loss-2.0485, acc-0.4237\n",
      "Iter-24010, train loss-2.0062, acc-0.4200, valid loss-2.0477, acc-0.4290, test loss-2.0484, acc-0.4237\n",
      "Iter-24020, train loss-2.0667, acc-0.4600, valid loss-2.0476, acc-0.4290, test loss-2.0484, acc-0.4236\n",
      "Iter-24030, train loss-2.0621, acc-0.3800, valid loss-2.0475, acc-0.4290, test loss-2.0483, acc-0.4238\n",
      "Iter-24040, train loss-2.0430, acc-0.4800, valid loss-2.0474, acc-0.4288, test loss-2.0482, acc-0.4241\n",
      "Iter-24050, train loss-2.0008, acc-0.5000, valid loss-2.0473, acc-0.4288, test loss-2.0481, acc-0.4243\n",
      "Iter-24060, train loss-2.1219, acc-0.2600, valid loss-2.0472, acc-0.4288, test loss-2.0480, acc-0.4239\n",
      "Iter-24070, train loss-1.9445, acc-0.6800, valid loss-2.0471, acc-0.4288, test loss-2.0479, acc-0.4241\n",
      "Iter-24080, train loss-2.1135, acc-0.3400, valid loss-2.0470, acc-0.4290, test loss-2.0478, acc-0.4244\n",
      "Iter-24090, train loss-2.0345, acc-0.4200, valid loss-2.0470, acc-0.4294, test loss-2.0477, acc-0.4243\n",
      "Iter-24100, train loss-2.0437, acc-0.5000, valid loss-2.0469, acc-0.4294, test loss-2.0477, acc-0.4244\n",
      "Iter-24110, train loss-2.0114, acc-0.4400, valid loss-2.0468, acc-0.4290, test loss-2.0476, acc-0.4244\n",
      "Iter-24120, train loss-2.0654, acc-0.3200, valid loss-2.0467, acc-0.4294, test loss-2.0475, acc-0.4245\n",
      "Iter-24130, train loss-2.0450, acc-0.4400, valid loss-2.0466, acc-0.4290, test loss-2.0474, acc-0.4243\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24140, train loss-2.0197, acc-0.4200, valid loss-2.0465, acc-0.4292, test loss-2.0473, acc-0.4241\n",
      "Iter-24150, train loss-2.0121, acc-0.5000, valid loss-2.0464, acc-0.4292, test loss-2.0472, acc-0.4242\n",
      "Iter-24160, train loss-2.0458, acc-0.4200, valid loss-2.0463, acc-0.4296, test loss-2.0471, acc-0.4241\n",
      "Iter-24170, train loss-2.1157, acc-0.3000, valid loss-2.0462, acc-0.4296, test loss-2.0470, acc-0.4242\n",
      "Iter-24180, train loss-2.0820, acc-0.3600, valid loss-2.0461, acc-0.4300, test loss-2.0469, acc-0.4245\n",
      "Iter-24190, train loss-2.1332, acc-0.3400, valid loss-2.0461, acc-0.4300, test loss-2.0469, acc-0.4244\n",
      "Iter-24200, train loss-2.1033, acc-0.4200, valid loss-2.0460, acc-0.4300, test loss-2.0468, acc-0.4244\n",
      "Iter-24210, train loss-2.0741, acc-0.3800, valid loss-2.0459, acc-0.4304, test loss-2.0467, acc-0.4244\n",
      "Iter-24220, train loss-2.0398, acc-0.4600, valid loss-2.0458, acc-0.4302, test loss-2.0466, acc-0.4242\n",
      "Iter-24230, train loss-2.0669, acc-0.4400, valid loss-2.0457, acc-0.4302, test loss-2.0465, acc-0.4242\n",
      "Iter-24240, train loss-2.0238, acc-0.5200, valid loss-2.0456, acc-0.4300, test loss-2.0464, acc-0.4241\n",
      "Iter-24250, train loss-2.1082, acc-0.3400, valid loss-2.0455, acc-0.4304, test loss-2.0463, acc-0.4244\n",
      "Iter-24260, train loss-2.0633, acc-0.4000, valid loss-2.0454, acc-0.4306, test loss-2.0462, acc-0.4243\n",
      "Iter-24270, train loss-2.0853, acc-0.3200, valid loss-2.0454, acc-0.4304, test loss-2.0461, acc-0.4245\n",
      "Iter-24280, train loss-2.0770, acc-0.4000, valid loss-2.0453, acc-0.4308, test loss-2.0460, acc-0.4244\n",
      "Iter-24290, train loss-2.0276, acc-0.4600, valid loss-2.0452, acc-0.4312, test loss-2.0459, acc-0.4245\n",
      "Iter-24300, train loss-2.0336, acc-0.4600, valid loss-2.0451, acc-0.4310, test loss-2.0459, acc-0.4246\n",
      "Iter-24310, train loss-2.0028, acc-0.5600, valid loss-2.0450, acc-0.4310, test loss-2.0458, acc-0.4245\n",
      "Iter-24320, train loss-2.0536, acc-0.4000, valid loss-2.0449, acc-0.4312, test loss-2.0457, acc-0.4244\n",
      "Iter-24330, train loss-2.0331, acc-0.4800, valid loss-2.0448, acc-0.4312, test loss-2.0456, acc-0.4246\n",
      "Iter-24340, train loss-2.0825, acc-0.3800, valid loss-2.0447, acc-0.4312, test loss-2.0455, acc-0.4248\n",
      "Iter-24350, train loss-2.1283, acc-0.2800, valid loss-2.0446, acc-0.4312, test loss-2.0454, acc-0.4247\n",
      "Iter-24360, train loss-2.0544, acc-0.3800, valid loss-2.0446, acc-0.4312, test loss-2.0453, acc-0.4246\n",
      "Iter-24370, train loss-2.1180, acc-0.3200, valid loss-2.0445, acc-0.4310, test loss-2.0452, acc-0.4245\n",
      "Iter-24380, train loss-2.0573, acc-0.3400, valid loss-2.0444, acc-0.4314, test loss-2.0452, acc-0.4247\n",
      "Iter-24390, train loss-2.0662, acc-0.3800, valid loss-2.0443, acc-0.4314, test loss-2.0451, acc-0.4248\n",
      "Iter-24400, train loss-2.1166, acc-0.3000, valid loss-2.0442, acc-0.4314, test loss-2.0450, acc-0.4249\n",
      "Iter-24410, train loss-2.0624, acc-0.4600, valid loss-2.0441, acc-0.4314, test loss-2.0449, acc-0.4249\n",
      "Iter-24420, train loss-2.0514, acc-0.3600, valid loss-2.0441, acc-0.4314, test loss-2.0448, acc-0.4252\n",
      "Iter-24430, train loss-2.0506, acc-0.4400, valid loss-2.0440, acc-0.4312, test loss-2.0447, acc-0.4251\n",
      "Iter-24440, train loss-2.0368, acc-0.4200, valid loss-2.0439, acc-0.4316, test loss-2.0446, acc-0.4252\n",
      "Iter-24450, train loss-2.0639, acc-0.3800, valid loss-2.0438, acc-0.4316, test loss-2.0446, acc-0.4256\n",
      "Iter-24460, train loss-2.1021, acc-0.2800, valid loss-2.0437, acc-0.4320, test loss-2.0445, acc-0.4254\n",
      "Iter-24470, train loss-2.0157, acc-0.5000, valid loss-2.0436, acc-0.4324, test loss-2.0444, acc-0.4252\n",
      "Iter-24480, train loss-2.0802, acc-0.4200, valid loss-2.0435, acc-0.4320, test loss-2.0443, acc-0.4252\n",
      "Iter-24490, train loss-2.0095, acc-0.4600, valid loss-2.0434, acc-0.4318, test loss-2.0442, acc-0.4251\n",
      "Iter-24500, train loss-2.0169, acc-0.5600, valid loss-2.0434, acc-0.4316, test loss-2.0441, acc-0.4251\n",
      "Iter-24510, train loss-2.0517, acc-0.4200, valid loss-2.0433, acc-0.4324, test loss-2.0440, acc-0.4252\n",
      "Iter-24520, train loss-2.0502, acc-0.2800, valid loss-2.0432, acc-0.4322, test loss-2.0439, acc-0.4252\n",
      "Iter-24530, train loss-2.0838, acc-0.3800, valid loss-2.0431, acc-0.4318, test loss-2.0439, acc-0.4252\n",
      "Iter-24540, train loss-2.0377, acc-0.5000, valid loss-2.0430, acc-0.4322, test loss-2.0438, acc-0.4253\n",
      "Iter-24550, train loss-2.0863, acc-0.3600, valid loss-2.0429, acc-0.4322, test loss-2.0437, acc-0.4255\n",
      "Iter-24560, train loss-2.0559, acc-0.4200, valid loss-2.0428, acc-0.4318, test loss-2.0436, acc-0.4252\n",
      "Iter-24570, train loss-2.0096, acc-0.4400, valid loss-2.0427, acc-0.4318, test loss-2.0435, acc-0.4254\n",
      "Iter-24580, train loss-2.0232, acc-0.3800, valid loss-2.0426, acc-0.4320, test loss-2.0434, acc-0.4254\n",
      "Iter-24590, train loss-2.1640, acc-0.2200, valid loss-2.0425, acc-0.4318, test loss-2.0433, acc-0.4254\n",
      "Iter-24600, train loss-2.0373, acc-0.4000, valid loss-2.0424, acc-0.4322, test loss-2.0432, acc-0.4256\n",
      "Iter-24610, train loss-2.0756, acc-0.4200, valid loss-2.0424, acc-0.4320, test loss-2.0431, acc-0.4256\n",
      "Iter-24620, train loss-2.0833, acc-0.4000, valid loss-2.0423, acc-0.4320, test loss-2.0431, acc-0.4256\n",
      "Iter-24630, train loss-1.9944, acc-0.4200, valid loss-2.0422, acc-0.4324, test loss-2.0430, acc-0.4258\n",
      "Iter-24640, train loss-2.0418, acc-0.4000, valid loss-2.0421, acc-0.4320, test loss-2.0429, acc-0.4259\n",
      "Iter-24650, train loss-2.0330, acc-0.4400, valid loss-2.0420, acc-0.4324, test loss-2.0428, acc-0.4258\n",
      "Iter-24660, train loss-1.9991, acc-0.4800, valid loss-2.0419, acc-0.4324, test loss-2.0427, acc-0.4257\n",
      "Iter-24670, train loss-2.0504, acc-0.4200, valid loss-2.0418, acc-0.4324, test loss-2.0426, acc-0.4259\n",
      "Iter-24680, train loss-2.1240, acc-0.3000, valid loss-2.0417, acc-0.4324, test loss-2.0425, acc-0.4256\n",
      "Iter-24690, train loss-2.1139, acc-0.2800, valid loss-2.0417, acc-0.4322, test loss-2.0424, acc-0.4258\n",
      "Iter-24700, train loss-2.0289, acc-0.4200, valid loss-2.0416, acc-0.4320, test loss-2.0423, acc-0.4258\n",
      "Iter-24710, train loss-2.0899, acc-0.2600, valid loss-2.0415, acc-0.4328, test loss-2.0423, acc-0.4258\n",
      "Iter-24720, train loss-2.0244, acc-0.4200, valid loss-2.0414, acc-0.4326, test loss-2.0422, acc-0.4257\n",
      "Iter-24730, train loss-2.0515, acc-0.4200, valid loss-2.0413, acc-0.4322, test loss-2.0421, acc-0.4256\n",
      "Iter-24740, train loss-2.0168, acc-0.4400, valid loss-2.0412, acc-0.4324, test loss-2.0420, acc-0.4258\n",
      "Iter-24750, train loss-1.9762, acc-0.5400, valid loss-2.0411, acc-0.4318, test loss-2.0419, acc-0.4259\n",
      "Iter-24760, train loss-2.0468, acc-0.4000, valid loss-2.0410, acc-0.4318, test loss-2.0418, acc-0.4260\n",
      "Iter-24770, train loss-2.1173, acc-0.3000, valid loss-2.0409, acc-0.4322, test loss-2.0417, acc-0.4259\n",
      "Iter-24780, train loss-2.0685, acc-0.3800, valid loss-2.0409, acc-0.4322, test loss-2.0416, acc-0.4258\n",
      "Iter-24790, train loss-2.0374, acc-0.4600, valid loss-2.0408, acc-0.4324, test loss-2.0416, acc-0.4260\n",
      "Iter-24800, train loss-2.0350, acc-0.4600, valid loss-2.0407, acc-0.4320, test loss-2.0415, acc-0.4260\n",
      "Iter-24810, train loss-2.0545, acc-0.3800, valid loss-2.0406, acc-0.4324, test loss-2.0414, acc-0.4262\n",
      "Iter-24820, train loss-2.0738, acc-0.3600, valid loss-2.0405, acc-0.4326, test loss-2.0413, acc-0.4262\n",
      "Iter-24830, train loss-2.0886, acc-0.3400, valid loss-2.0404, acc-0.4326, test loss-2.0412, acc-0.4265\n",
      "Iter-24840, train loss-2.0552, acc-0.4200, valid loss-2.0403, acc-0.4328, test loss-2.0411, acc-0.4265\n",
      "Iter-24850, train loss-2.0472, acc-0.5200, valid loss-2.0402, acc-0.4332, test loss-2.0410, acc-0.4266\n",
      "Iter-24860, train loss-2.0081, acc-0.5200, valid loss-2.0402, acc-0.4326, test loss-2.0409, acc-0.4265\n",
      "Iter-24870, train loss-2.0616, acc-0.3600, valid loss-2.0401, acc-0.4330, test loss-2.0409, acc-0.4264\n",
      "Iter-24880, train loss-2.0718, acc-0.3800, valid loss-2.0400, acc-0.4330, test loss-2.0408, acc-0.4265\n",
      "Iter-24890, train loss-2.0358, acc-0.4400, valid loss-2.0399, acc-0.4326, test loss-2.0407, acc-0.4263\n",
      "Iter-24900, train loss-1.9991, acc-0.5200, valid loss-2.0398, acc-0.4330, test loss-2.0406, acc-0.4265\n",
      "Iter-24910, train loss-2.0540, acc-0.4400, valid loss-2.0397, acc-0.4328, test loss-2.0405, acc-0.4266\n",
      "Iter-24920, train loss-2.0754, acc-0.4200, valid loss-2.0396, acc-0.4328, test loss-2.0404, acc-0.4266\n",
      "Iter-24930, train loss-2.0383, acc-0.4600, valid loss-2.0395, acc-0.4332, test loss-2.0403, acc-0.4266\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-24940, train loss-2.0276, acc-0.4800, valid loss-2.0395, acc-0.4330, test loss-2.0402, acc-0.4266\n",
      "Iter-24950, train loss-2.0531, acc-0.4200, valid loss-2.0394, acc-0.4334, test loss-2.0402, acc-0.4268\n",
      "Iter-24960, train loss-2.0894, acc-0.3400, valid loss-2.0393, acc-0.4334, test loss-2.0401, acc-0.4267\n",
      "Iter-24970, train loss-2.0744, acc-0.3000, valid loss-2.0392, acc-0.4334, test loss-2.0400, acc-0.4266\n",
      "Iter-24980, train loss-2.0560, acc-0.3800, valid loss-2.0391, acc-0.4338, test loss-2.0399, acc-0.4267\n",
      "Iter-24990, train loss-2.0356, acc-0.4200, valid loss-2.0390, acc-0.4342, test loss-2.0398, acc-0.4268\n",
      "Iter-25000, train loss-2.0505, acc-0.4600, valid loss-2.0389, acc-0.4344, test loss-2.0397, acc-0.4267\n",
      "Iter-25010, train loss-2.0456, acc-0.3800, valid loss-2.0388, acc-0.4344, test loss-2.0396, acc-0.4270\n",
      "Iter-25020, train loss-2.0457, acc-0.4000, valid loss-2.0388, acc-0.4342, test loss-2.0396, acc-0.4269\n",
      "Iter-25030, train loss-2.0119, acc-0.4600, valid loss-2.0387, acc-0.4344, test loss-2.0395, acc-0.4269\n",
      "Iter-25040, train loss-2.0400, acc-0.4600, valid loss-2.0386, acc-0.4348, test loss-2.0394, acc-0.4269\n",
      "Iter-25050, train loss-2.1035, acc-0.4400, valid loss-2.0385, acc-0.4342, test loss-2.0393, acc-0.4269\n",
      "Iter-25060, train loss-2.0214, acc-0.4800, valid loss-2.0384, acc-0.4340, test loss-2.0392, acc-0.4269\n",
      "Iter-25070, train loss-2.0144, acc-0.4400, valid loss-2.0383, acc-0.4342, test loss-2.0391, acc-0.4268\n",
      "Iter-25080, train loss-2.0243, acc-0.4600, valid loss-2.0382, acc-0.4338, test loss-2.0390, acc-0.4268\n",
      "Iter-25090, train loss-1.9955, acc-0.4800, valid loss-2.0381, acc-0.4338, test loss-2.0389, acc-0.4268\n",
      "Iter-25100, train loss-1.9965, acc-0.5400, valid loss-2.0380, acc-0.4342, test loss-2.0388, acc-0.4271\n",
      "Iter-25110, train loss-2.0308, acc-0.5200, valid loss-2.0380, acc-0.4340, test loss-2.0388, acc-0.4269\n",
      "Iter-25120, train loss-2.0036, acc-0.4800, valid loss-2.0379, acc-0.4344, test loss-2.0387, acc-0.4269\n",
      "Iter-25130, train loss-2.0302, acc-0.3600, valid loss-2.0378, acc-0.4342, test loss-2.0386, acc-0.4270\n",
      "Iter-25140, train loss-2.0421, acc-0.4400, valid loss-2.0377, acc-0.4342, test loss-2.0385, acc-0.4270\n",
      "Iter-25150, train loss-2.0768, acc-0.3600, valid loss-2.0376, acc-0.4346, test loss-2.0384, acc-0.4270\n",
      "Iter-25160, train loss-2.0757, acc-0.3000, valid loss-2.0375, acc-0.4352, test loss-2.0383, acc-0.4273\n",
      "Iter-25170, train loss-2.0126, acc-0.5400, valid loss-2.0374, acc-0.4348, test loss-2.0382, acc-0.4273\n",
      "Iter-25180, train loss-2.0924, acc-0.3200, valid loss-2.0374, acc-0.4350, test loss-2.0381, acc-0.4275\n",
      "Iter-25190, train loss-2.0585, acc-0.4000, valid loss-2.0373, acc-0.4350, test loss-2.0381, acc-0.4277\n",
      "Iter-25200, train loss-2.0266, acc-0.5000, valid loss-2.0372, acc-0.4352, test loss-2.0380, acc-0.4279\n",
      "Iter-25210, train loss-2.0450, acc-0.4000, valid loss-2.0371, acc-0.4354, test loss-2.0379, acc-0.4281\n",
      "Iter-25220, train loss-2.0426, acc-0.4600, valid loss-2.0370, acc-0.4352, test loss-2.0378, acc-0.4281\n",
      "Iter-25230, train loss-2.0625, acc-0.3800, valid loss-2.0369, acc-0.4356, test loss-2.0377, acc-0.4281\n",
      "Iter-25240, train loss-2.0626, acc-0.4200, valid loss-2.0368, acc-0.4352, test loss-2.0376, acc-0.4283\n",
      "Iter-25250, train loss-2.0651, acc-0.4000, valid loss-2.0367, acc-0.4358, test loss-2.0375, acc-0.4282\n",
      "Iter-25260, train loss-2.0455, acc-0.4600, valid loss-2.0367, acc-0.4360, test loss-2.0375, acc-0.4285\n",
      "Iter-25270, train loss-2.0519, acc-0.4600, valid loss-2.0366, acc-0.4362, test loss-2.0374, acc-0.4284\n",
      "Iter-25280, train loss-2.0654, acc-0.3600, valid loss-2.0365, acc-0.4362, test loss-2.0373, acc-0.4286\n",
      "Iter-25290, train loss-2.0225, acc-0.4400, valid loss-2.0364, acc-0.4362, test loss-2.0372, acc-0.4285\n",
      "Iter-25300, train loss-2.0357, acc-0.4800, valid loss-2.0363, acc-0.4360, test loss-2.0371, acc-0.4286\n",
      "Iter-25310, train loss-2.0620, acc-0.4000, valid loss-2.0362, acc-0.4360, test loss-2.0370, acc-0.4286\n",
      "Iter-25320, train loss-2.0672, acc-0.3800, valid loss-2.0361, acc-0.4358, test loss-2.0369, acc-0.4286\n",
      "Iter-25330, train loss-2.0419, acc-0.4800, valid loss-2.0361, acc-0.4356, test loss-2.0369, acc-0.4287\n",
      "Iter-25340, train loss-2.0333, acc-0.3400, valid loss-2.0360, acc-0.4360, test loss-2.0368, acc-0.4286\n",
      "Iter-25350, train loss-1.9948, acc-0.4800, valid loss-2.0359, acc-0.4360, test loss-2.0367, acc-0.4288\n",
      "Iter-25360, train loss-2.0790, acc-0.3400, valid loss-2.0358, acc-0.4358, test loss-2.0366, acc-0.4290\n",
      "Iter-25370, train loss-2.0626, acc-0.4000, valid loss-2.0357, acc-0.4360, test loss-2.0365, acc-0.4291\n",
      "Iter-25380, train loss-1.9758, acc-0.6000, valid loss-2.0356, acc-0.4360, test loss-2.0364, acc-0.4291\n",
      "Iter-25390, train loss-2.1006, acc-0.3800, valid loss-2.0356, acc-0.4362, test loss-2.0363, acc-0.4293\n",
      "Iter-25400, train loss-1.9883, acc-0.5000, valid loss-2.0355, acc-0.4366, test loss-2.0362, acc-0.4294\n",
      "Iter-25410, train loss-2.0599, acc-0.4200, valid loss-2.0354, acc-0.4370, test loss-2.0361, acc-0.4294\n",
      "Iter-25420, train loss-2.0478, acc-0.3600, valid loss-2.0353, acc-0.4366, test loss-2.0361, acc-0.4295\n",
      "Iter-25430, train loss-2.0665, acc-0.4400, valid loss-2.0352, acc-0.4366, test loss-2.0360, acc-0.4295\n",
      "Iter-25440, train loss-2.0292, acc-0.5400, valid loss-2.0351, acc-0.4372, test loss-2.0359, acc-0.4296\n",
      "Iter-25450, train loss-2.0364, acc-0.4000, valid loss-2.0350, acc-0.4374, test loss-2.0358, acc-0.4294\n",
      "Iter-25460, train loss-2.0402, acc-0.4600, valid loss-2.0349, acc-0.4370, test loss-2.0357, acc-0.4291\n",
      "Iter-25470, train loss-2.0079, acc-0.4600, valid loss-2.0348, acc-0.4370, test loss-2.0356, acc-0.4292\n",
      "Iter-25480, train loss-2.0514, acc-0.4600, valid loss-2.0348, acc-0.4376, test loss-2.0355, acc-0.4296\n",
      "Iter-25490, train loss-2.0437, acc-0.4600, valid loss-2.0347, acc-0.4372, test loss-2.0355, acc-0.4295\n",
      "Iter-25500, train loss-2.0133, acc-0.5200, valid loss-2.0346, acc-0.4372, test loss-2.0354, acc-0.4298\n",
      "Iter-25510, train loss-2.0476, acc-0.4400, valid loss-2.0345, acc-0.4376, test loss-2.0353, acc-0.4297\n",
      "Iter-25520, train loss-2.0178, acc-0.5200, valid loss-2.0344, acc-0.4376, test loss-2.0352, acc-0.4299\n",
      "Iter-25530, train loss-2.0743, acc-0.4000, valid loss-2.0343, acc-0.4374, test loss-2.0351, acc-0.4299\n",
      "Iter-25540, train loss-1.9971, acc-0.4800, valid loss-2.0342, acc-0.4376, test loss-2.0350, acc-0.4297\n",
      "Iter-25550, train loss-2.0693, acc-0.4000, valid loss-2.0341, acc-0.4376, test loss-2.0349, acc-0.4299\n",
      "Iter-25560, train loss-2.0294, acc-0.4200, valid loss-2.0341, acc-0.4376, test loss-2.0348, acc-0.4300\n",
      "Iter-25570, train loss-2.0054, acc-0.4400, valid loss-2.0340, acc-0.4376, test loss-2.0347, acc-0.4298\n",
      "Iter-25580, train loss-2.0948, acc-0.3200, valid loss-2.0339, acc-0.4376, test loss-2.0347, acc-0.4299\n",
      "Iter-25590, train loss-2.0738, acc-0.2600, valid loss-2.0338, acc-0.4376, test loss-2.0346, acc-0.4298\n",
      "Iter-25600, train loss-1.9909, acc-0.5400, valid loss-2.0337, acc-0.4376, test loss-2.0345, acc-0.4297\n",
      "Iter-25610, train loss-1.9502, acc-0.6400, valid loss-2.0336, acc-0.4378, test loss-2.0344, acc-0.4296\n",
      "Iter-25620, train loss-2.1137, acc-0.3000, valid loss-2.0335, acc-0.4376, test loss-2.0343, acc-0.4297\n",
      "Iter-25630, train loss-2.0753, acc-0.4000, valid loss-2.0334, acc-0.4380, test loss-2.0342, acc-0.4298\n",
      "Iter-25640, train loss-2.0257, acc-0.5200, valid loss-2.0333, acc-0.4378, test loss-2.0341, acc-0.4300\n",
      "Iter-25650, train loss-2.0722, acc-0.4400, valid loss-2.0333, acc-0.4380, test loss-2.0340, acc-0.4300\n",
      "Iter-25660, train loss-2.0641, acc-0.4200, valid loss-2.0332, acc-0.4380, test loss-2.0340, acc-0.4304\n",
      "Iter-25670, train loss-2.0230, acc-0.4600, valid loss-2.0331, acc-0.4376, test loss-2.0339, acc-0.4302\n",
      "Iter-25680, train loss-2.0036, acc-0.4800, valid loss-2.0330, acc-0.4376, test loss-2.0338, acc-0.4303\n",
      "Iter-25690, train loss-2.0798, acc-0.3600, valid loss-2.0329, acc-0.4380, test loss-2.0337, acc-0.4304\n",
      "Iter-25700, train loss-2.0657, acc-0.3800, valid loss-2.0328, acc-0.4380, test loss-2.0336, acc-0.4303\n",
      "Iter-25710, train loss-2.0301, acc-0.4200, valid loss-2.0327, acc-0.4384, test loss-2.0335, acc-0.4304\n",
      "Iter-25720, train loss-2.0431, acc-0.4600, valid loss-2.0326, acc-0.4382, test loss-2.0334, acc-0.4305\n",
      "Iter-25730, train loss-2.0089, acc-0.4400, valid loss-2.0326, acc-0.4386, test loss-2.0333, acc-0.4306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-25740, train loss-2.0718, acc-0.3400, valid loss-2.0325, acc-0.4384, test loss-2.0332, acc-0.4306\n",
      "Iter-25750, train loss-2.0400, acc-0.4600, valid loss-2.0324, acc-0.4388, test loss-2.0332, acc-0.4306\n",
      "Iter-25760, train loss-2.0861, acc-0.3000, valid loss-2.0323, acc-0.4388, test loss-2.0331, acc-0.4307\n",
      "Iter-25770, train loss-2.0201, acc-0.3800, valid loss-2.0322, acc-0.4388, test loss-2.0330, acc-0.4308\n",
      "Iter-25780, train loss-2.0589, acc-0.4000, valid loss-2.0321, acc-0.4386, test loss-2.0329, acc-0.4304\n",
      "Iter-25790, train loss-2.0546, acc-0.3000, valid loss-2.0320, acc-0.4386, test loss-2.0328, acc-0.4307\n",
      "Iter-25800, train loss-2.0394, acc-0.3600, valid loss-2.0319, acc-0.4386, test loss-2.0327, acc-0.4307\n",
      "Iter-25810, train loss-2.0279, acc-0.4600, valid loss-2.0319, acc-0.4388, test loss-2.0326, acc-0.4307\n",
      "Iter-25820, train loss-2.0017, acc-0.4600, valid loss-2.0318, acc-0.4384, test loss-2.0326, acc-0.4308\n",
      "Iter-25830, train loss-2.0179, acc-0.5000, valid loss-2.0317, acc-0.4390, test loss-2.0325, acc-0.4308\n",
      "Iter-25840, train loss-2.0698, acc-0.3800, valid loss-2.0316, acc-0.4388, test loss-2.0324, acc-0.4308\n",
      "Iter-25850, train loss-2.0460, acc-0.4600, valid loss-2.0315, acc-0.4386, test loss-2.0323, acc-0.4309\n",
      "Iter-25860, train loss-1.9555, acc-0.5600, valid loss-2.0314, acc-0.4388, test loss-2.0322, acc-0.4310\n",
      "Iter-25870, train loss-1.9922, acc-0.5200, valid loss-2.0313, acc-0.4390, test loss-2.0321, acc-0.4309\n",
      "Iter-25880, train loss-2.0298, acc-0.4000, valid loss-2.0313, acc-0.4390, test loss-2.0320, acc-0.4307\n",
      "Iter-25890, train loss-2.0385, acc-0.4400, valid loss-2.0312, acc-0.4394, test loss-2.0320, acc-0.4309\n",
      "Iter-25900, train loss-2.0187, acc-0.4600, valid loss-2.0311, acc-0.4394, test loss-2.0319, acc-0.4309\n",
      "Iter-25910, train loss-2.0733, acc-0.4400, valid loss-2.0310, acc-0.4390, test loss-2.0318, acc-0.4311\n",
      "Iter-25920, train loss-2.0240, acc-0.4400, valid loss-2.0309, acc-0.4384, test loss-2.0317, acc-0.4311\n",
      "Iter-25930, train loss-1.9928, acc-0.4800, valid loss-2.0308, acc-0.4390, test loss-2.0316, acc-0.4312\n",
      "Iter-25940, train loss-1.9762, acc-0.4200, valid loss-2.0307, acc-0.4390, test loss-2.0315, acc-0.4312\n",
      "Iter-25950, train loss-2.0433, acc-0.4600, valid loss-2.0306, acc-0.4394, test loss-2.0314, acc-0.4312\n",
      "Iter-25960, train loss-1.9897, acc-0.5200, valid loss-2.0306, acc-0.4392, test loss-2.0313, acc-0.4311\n",
      "Iter-25970, train loss-2.0604, acc-0.4800, valid loss-2.0305, acc-0.4396, test loss-2.0313, acc-0.4313\n",
      "Iter-25980, train loss-2.0544, acc-0.4400, valid loss-2.0304, acc-0.4392, test loss-2.0312, acc-0.4313\n",
      "Iter-25990, train loss-2.0669, acc-0.3800, valid loss-2.0303, acc-0.4396, test loss-2.0311, acc-0.4313\n",
      "Iter-26000, train loss-2.0222, acc-0.3600, valid loss-2.0302, acc-0.4398, test loss-2.0310, acc-0.4310\n",
      "Iter-26010, train loss-2.0308, acc-0.4000, valid loss-2.0301, acc-0.4392, test loss-2.0309, acc-0.4313\n",
      "Iter-26020, train loss-2.0564, acc-0.4000, valid loss-2.0300, acc-0.4396, test loss-2.0308, acc-0.4314\n",
      "Iter-26030, train loss-2.0071, acc-0.5200, valid loss-2.0300, acc-0.4390, test loss-2.0308, acc-0.4315\n",
      "Iter-26040, train loss-2.0034, acc-0.4400, valid loss-2.0299, acc-0.4398, test loss-2.0307, acc-0.4313\n",
      "Iter-26050, train loss-2.0040, acc-0.4400, valid loss-2.0298, acc-0.4398, test loss-2.0306, acc-0.4314\n",
      "Iter-26060, train loss-2.0673, acc-0.3800, valid loss-2.0297, acc-0.4402, test loss-2.0305, acc-0.4314\n",
      "Iter-26070, train loss-2.0746, acc-0.3600, valid loss-2.0296, acc-0.4398, test loss-2.0304, acc-0.4314\n",
      "Iter-26080, train loss-2.0743, acc-0.4000, valid loss-2.0296, acc-0.4402, test loss-2.0303, acc-0.4317\n",
      "Iter-26090, train loss-2.0196, acc-0.4000, valid loss-2.0295, acc-0.4404, test loss-2.0303, acc-0.4314\n",
      "Iter-26100, train loss-2.0699, acc-0.3600, valid loss-2.0294, acc-0.4402, test loss-2.0302, acc-0.4316\n",
      "Iter-26110, train loss-2.0473, acc-0.4200, valid loss-2.0293, acc-0.4404, test loss-2.0301, acc-0.4318\n",
      "Iter-26120, train loss-2.1264, acc-0.3200, valid loss-2.0292, acc-0.4404, test loss-2.0300, acc-0.4323\n",
      "Iter-26130, train loss-2.1009, acc-0.2600, valid loss-2.0291, acc-0.4404, test loss-2.0299, acc-0.4323\n",
      "Iter-26140, train loss-2.0081, acc-0.5400, valid loss-2.0290, acc-0.4404, test loss-2.0298, acc-0.4321\n",
      "Iter-26150, train loss-2.0821, acc-0.3600, valid loss-2.0289, acc-0.4406, test loss-2.0297, acc-0.4320\n",
      "Iter-26160, train loss-2.0463, acc-0.3400, valid loss-2.0289, acc-0.4402, test loss-2.0297, acc-0.4322\n",
      "Iter-26170, train loss-2.0387, acc-0.3400, valid loss-2.0288, acc-0.4400, test loss-2.0296, acc-0.4323\n",
      "Iter-26180, train loss-2.0535, acc-0.3800, valid loss-2.0287, acc-0.4404, test loss-2.0295, acc-0.4325\n",
      "Iter-26190, train loss-2.0400, acc-0.4400, valid loss-2.0286, acc-0.4406, test loss-2.0294, acc-0.4326\n",
      "Iter-26200, train loss-2.0996, acc-0.3600, valid loss-2.0285, acc-0.4408, test loss-2.0293, acc-0.4327\n",
      "Iter-26210, train loss-2.0169, acc-0.5400, valid loss-2.0284, acc-0.4408, test loss-2.0292, acc-0.4325\n",
      "Iter-26220, train loss-2.0621, acc-0.4200, valid loss-2.0283, acc-0.4404, test loss-2.0291, acc-0.4327\n",
      "Iter-26230, train loss-2.0916, acc-0.2800, valid loss-2.0283, acc-0.4404, test loss-2.0290, acc-0.4328\n",
      "Iter-26240, train loss-1.9866, acc-0.5000, valid loss-2.0282, acc-0.4402, test loss-2.0290, acc-0.4324\n",
      "Iter-26250, train loss-2.0540, acc-0.3800, valid loss-2.0281, acc-0.4408, test loss-2.0289, acc-0.4322\n",
      "Iter-26260, train loss-2.0612, acc-0.3200, valid loss-2.0280, acc-0.4410, test loss-2.0288, acc-0.4325\n",
      "Iter-26270, train loss-2.0364, acc-0.4000, valid loss-2.0279, acc-0.4410, test loss-2.0287, acc-0.4327\n",
      "Iter-26280, train loss-2.0222, acc-0.4400, valid loss-2.0278, acc-0.4412, test loss-2.0286, acc-0.4327\n",
      "Iter-26290, train loss-2.0165, acc-0.5000, valid loss-2.0277, acc-0.4404, test loss-2.0285, acc-0.4325\n",
      "Iter-26300, train loss-2.0897, acc-0.2800, valid loss-2.0276, acc-0.4406, test loss-2.0284, acc-0.4325\n",
      "Iter-26310, train loss-2.0845, acc-0.3200, valid loss-2.0276, acc-0.4410, test loss-2.0283, acc-0.4324\n",
      "Iter-26320, train loss-1.9958, acc-0.5000, valid loss-2.0275, acc-0.4404, test loss-2.0283, acc-0.4325\n",
      "Iter-26330, train loss-2.0280, acc-0.4800, valid loss-2.0274, acc-0.4404, test loss-2.0282, acc-0.4324\n",
      "Iter-26340, train loss-2.0061, acc-0.4800, valid loss-2.0273, acc-0.4404, test loss-2.0281, acc-0.4325\n",
      "Iter-26350, train loss-2.0149, acc-0.5600, valid loss-2.0272, acc-0.4402, test loss-2.0280, acc-0.4323\n",
      "Iter-26360, train loss-2.0285, acc-0.5000, valid loss-2.0271, acc-0.4404, test loss-2.0279, acc-0.4326\n",
      "Iter-26370, train loss-2.0863, acc-0.2400, valid loss-2.0270, acc-0.4404, test loss-2.0278, acc-0.4328\n",
      "Iter-26380, train loss-2.0468, acc-0.4000, valid loss-2.0270, acc-0.4406, test loss-2.0277, acc-0.4328\n",
      "Iter-26390, train loss-2.0985, acc-0.3200, valid loss-2.0269, acc-0.4406, test loss-2.0277, acc-0.4328\n",
      "Iter-26400, train loss-2.0094, acc-0.3600, valid loss-2.0268, acc-0.4412, test loss-2.0276, acc-0.4323\n",
      "Iter-26410, train loss-2.0502, acc-0.4800, valid loss-2.0267, acc-0.4412, test loss-2.0275, acc-0.4327\n",
      "Iter-26420, train loss-2.0012, acc-0.5600, valid loss-2.0266, acc-0.4412, test loss-2.0274, acc-0.4327\n",
      "Iter-26430, train loss-2.0035, acc-0.5600, valid loss-2.0265, acc-0.4410, test loss-2.0273, acc-0.4328\n",
      "Iter-26440, train loss-1.9588, acc-0.4800, valid loss-2.0264, acc-0.4408, test loss-2.0272, acc-0.4327\n",
      "Iter-26450, train loss-2.0675, acc-0.3600, valid loss-2.0264, acc-0.4408, test loss-2.0272, acc-0.4328\n",
      "Iter-26460, train loss-2.0657, acc-0.3600, valid loss-2.0263, acc-0.4410, test loss-2.0271, acc-0.4328\n",
      "Iter-26470, train loss-2.0245, acc-0.5800, valid loss-2.0262, acc-0.4410, test loss-2.0270, acc-0.4327\n",
      "Iter-26480, train loss-2.0337, acc-0.4000, valid loss-2.0261, acc-0.4412, test loss-2.0269, acc-0.4328\n",
      "Iter-26490, train loss-2.0241, acc-0.4000, valid loss-2.0260, acc-0.4412, test loss-2.0268, acc-0.4327\n",
      "Iter-26500, train loss-1.9896, acc-0.5000, valid loss-2.0259, acc-0.4412, test loss-2.0267, acc-0.4328\n",
      "Iter-26510, train loss-2.0984, acc-0.3200, valid loss-2.0259, acc-0.4414, test loss-2.0267, acc-0.4330\n",
      "Iter-26520, train loss-2.0337, acc-0.4000, valid loss-2.0258, acc-0.4410, test loss-2.0266, acc-0.4328\n",
      "Iter-26530, train loss-2.0337, acc-0.3200, valid loss-2.0257, acc-0.4408, test loss-2.0265, acc-0.4329\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-26540, train loss-2.0667, acc-0.3400, valid loss-2.0256, acc-0.4410, test loss-2.0264, acc-0.4329\n",
      "Iter-26550, train loss-1.9991, acc-0.5000, valid loss-2.0255, acc-0.4408, test loss-2.0263, acc-0.4330\n",
      "Iter-26560, train loss-2.0598, acc-0.4400, valid loss-2.0254, acc-0.4412, test loss-2.0262, acc-0.4330\n",
      "Iter-26570, train loss-1.9789, acc-0.4800, valid loss-2.0254, acc-0.4410, test loss-2.0261, acc-0.4331\n",
      "Iter-26580, train loss-2.0840, acc-0.4000, valid loss-2.0253, acc-0.4412, test loss-2.0261, acc-0.4331\n",
      "Iter-26590, train loss-2.0754, acc-0.3000, valid loss-2.0252, acc-0.4418, test loss-2.0260, acc-0.4330\n",
      "Iter-26600, train loss-2.0063, acc-0.4000, valid loss-2.0251, acc-0.4410, test loss-2.0259, acc-0.4331\n",
      "Iter-26610, train loss-2.0960, acc-0.3200, valid loss-2.0250, acc-0.4410, test loss-2.0258, acc-0.4328\n",
      "Iter-26620, train loss-2.0493, acc-0.3200, valid loss-2.0249, acc-0.4410, test loss-2.0257, acc-0.4329\n",
      "Iter-26630, train loss-1.9911, acc-0.4800, valid loss-2.0248, acc-0.4410, test loss-2.0256, acc-0.4330\n",
      "Iter-26640, train loss-1.9654, acc-0.5400, valid loss-2.0247, acc-0.4408, test loss-2.0255, acc-0.4332\n",
      "Iter-26650, train loss-2.0297, acc-0.4200, valid loss-2.0247, acc-0.4406, test loss-2.0255, acc-0.4331\n",
      "Iter-26660, train loss-2.0199, acc-0.4600, valid loss-2.0246, acc-0.4406, test loss-2.0254, acc-0.4333\n",
      "Iter-26670, train loss-2.0227, acc-0.4800, valid loss-2.0245, acc-0.4406, test loss-2.0253, acc-0.4333\n",
      "Iter-26680, train loss-2.0014, acc-0.4400, valid loss-2.0244, acc-0.4406, test loss-2.0252, acc-0.4331\n",
      "Iter-26690, train loss-2.0056, acc-0.4200, valid loss-2.0243, acc-0.4406, test loss-2.0251, acc-0.4332\n",
      "Iter-26700, train loss-2.0561, acc-0.4000, valid loss-2.0242, acc-0.4404, test loss-2.0250, acc-0.4332\n",
      "Iter-26710, train loss-1.9924, acc-0.4800, valid loss-2.0242, acc-0.4410, test loss-2.0250, acc-0.4333\n",
      "Iter-26720, train loss-2.0601, acc-0.4400, valid loss-2.0241, acc-0.4412, test loss-2.0249, acc-0.4331\n",
      "Iter-26730, train loss-2.0112, acc-0.4400, valid loss-2.0240, acc-0.4412, test loss-2.0248, acc-0.4332\n",
      "Iter-26740, train loss-2.0860, acc-0.3400, valid loss-2.0239, acc-0.4414, test loss-2.0247, acc-0.4333\n",
      "Iter-26750, train loss-2.0162, acc-0.5200, valid loss-2.0238, acc-0.4422, test loss-2.0246, acc-0.4334\n",
      "Iter-26760, train loss-1.9865, acc-0.4200, valid loss-2.0237, acc-0.4420, test loss-2.0245, acc-0.4335\n",
      "Iter-26770, train loss-2.0720, acc-0.3800, valid loss-2.0237, acc-0.4416, test loss-2.0245, acc-0.4334\n",
      "Iter-26780, train loss-2.0298, acc-0.3800, valid loss-2.0236, acc-0.4422, test loss-2.0244, acc-0.4336\n",
      "Iter-26790, train loss-2.0852, acc-0.2800, valid loss-2.0235, acc-0.4422, test loss-2.0243, acc-0.4336\n",
      "Iter-26800, train loss-2.0194, acc-0.5200, valid loss-2.0234, acc-0.4428, test loss-2.0242, acc-0.4334\n",
      "Iter-26810, train loss-1.9934, acc-0.4000, valid loss-2.0233, acc-0.4422, test loss-2.0241, acc-0.4334\n",
      "Iter-26820, train loss-1.9741, acc-0.5200, valid loss-2.0232, acc-0.4422, test loss-2.0240, acc-0.4332\n",
      "Iter-26830, train loss-2.1024, acc-0.3000, valid loss-2.0231, acc-0.4424, test loss-2.0239, acc-0.4335\n",
      "Iter-26840, train loss-2.0649, acc-0.3600, valid loss-2.0231, acc-0.4424, test loss-2.0239, acc-0.4337\n",
      "Iter-26850, train loss-2.0315, acc-0.3800, valid loss-2.0230, acc-0.4424, test loss-2.0238, acc-0.4336\n",
      "Iter-26860, train loss-1.9369, acc-0.5200, valid loss-2.0229, acc-0.4426, test loss-2.0237, acc-0.4336\n",
      "Iter-26870, train loss-2.0896, acc-0.3000, valid loss-2.0228, acc-0.4428, test loss-2.0236, acc-0.4336\n",
      "Iter-26880, train loss-2.0432, acc-0.4000, valid loss-2.0227, acc-0.4424, test loss-2.0235, acc-0.4337\n",
      "Iter-26890, train loss-1.9837, acc-0.5000, valid loss-2.0226, acc-0.4428, test loss-2.0234, acc-0.4338\n",
      "Iter-26900, train loss-2.0584, acc-0.4000, valid loss-2.0225, acc-0.4428, test loss-2.0233, acc-0.4338\n",
      "Iter-26910, train loss-2.0540, acc-0.4200, valid loss-2.0225, acc-0.4428, test loss-2.0233, acc-0.4341\n",
      "Iter-26920, train loss-2.0849, acc-0.3400, valid loss-2.0224, acc-0.4422, test loss-2.0232, acc-0.4338\n",
      "Iter-26930, train loss-2.0458, acc-0.4000, valid loss-2.0223, acc-0.4428, test loss-2.0231, acc-0.4339\n",
      "Iter-26940, train loss-2.0258, acc-0.3800, valid loss-2.0222, acc-0.4424, test loss-2.0230, acc-0.4338\n",
      "Iter-26950, train loss-2.0335, acc-0.3800, valid loss-2.0221, acc-0.4426, test loss-2.0229, acc-0.4336\n",
      "Iter-26960, train loss-2.0457, acc-0.4200, valid loss-2.0220, acc-0.4428, test loss-2.0228, acc-0.4338\n",
      "Iter-26970, train loss-2.0400, acc-0.4000, valid loss-2.0220, acc-0.4430, test loss-2.0227, acc-0.4340\n",
      "Iter-26980, train loss-2.0182, acc-0.5200, valid loss-2.0219, acc-0.4428, test loss-2.0227, acc-0.4338\n",
      "Iter-26990, train loss-2.0139, acc-0.5200, valid loss-2.0218, acc-0.4428, test loss-2.0226, acc-0.4339\n",
      "Iter-27000, train loss-2.0144, acc-0.5000, valid loss-2.0217, acc-0.4428, test loss-2.0225, acc-0.4338\n",
      "Iter-27010, train loss-2.0305, acc-0.4200, valid loss-2.0216, acc-0.4426, test loss-2.0224, acc-0.4340\n",
      "Iter-27020, train loss-2.0658, acc-0.3600, valid loss-2.0215, acc-0.4426, test loss-2.0223, acc-0.4340\n",
      "Iter-27030, train loss-1.9907, acc-0.4600, valid loss-2.0214, acc-0.4426, test loss-2.0222, acc-0.4340\n",
      "Iter-27040, train loss-2.0138, acc-0.4000, valid loss-2.0213, acc-0.4426, test loss-2.0221, acc-0.4340\n",
      "Iter-27050, train loss-2.0561, acc-0.4000, valid loss-2.0213, acc-0.4426, test loss-2.0221, acc-0.4339\n",
      "Iter-27060, train loss-2.0372, acc-0.4000, valid loss-2.0212, acc-0.4428, test loss-2.0220, acc-0.4341\n",
      "Iter-27070, train loss-2.0230, acc-0.4800, valid loss-2.0211, acc-0.4430, test loss-2.0219, acc-0.4341\n",
      "Iter-27080, train loss-2.0874, acc-0.3400, valid loss-2.0210, acc-0.4430, test loss-2.0218, acc-0.4341\n",
      "Iter-27090, train loss-1.9796, acc-0.4800, valid loss-2.0209, acc-0.4432, test loss-2.0217, acc-0.4341\n",
      "Iter-27100, train loss-2.0127, acc-0.5000, valid loss-2.0208, acc-0.4432, test loss-2.0216, acc-0.4341\n",
      "Iter-27110, train loss-2.0259, acc-0.3600, valid loss-2.0207, acc-0.4428, test loss-2.0215, acc-0.4343\n",
      "Iter-27120, train loss-2.0561, acc-0.4400, valid loss-2.0207, acc-0.4432, test loss-2.0215, acc-0.4344\n",
      "Iter-27130, train loss-1.9637, acc-0.5600, valid loss-2.0206, acc-0.4434, test loss-2.0214, acc-0.4343\n",
      "Iter-27140, train loss-2.0282, acc-0.4000, valid loss-2.0205, acc-0.4430, test loss-2.0213, acc-0.4342\n",
      "Iter-27150, train loss-2.0878, acc-0.2800, valid loss-2.0204, acc-0.4434, test loss-2.0212, acc-0.4344\n",
      "Iter-27160, train loss-2.1302, acc-0.2800, valid loss-2.0203, acc-0.4436, test loss-2.0211, acc-0.4344\n",
      "Iter-27170, train loss-2.0320, acc-0.4400, valid loss-2.0202, acc-0.4438, test loss-2.0210, acc-0.4346\n",
      "Iter-27180, train loss-2.0076, acc-0.4200, valid loss-2.0202, acc-0.4440, test loss-2.0210, acc-0.4345\n",
      "Iter-27190, train loss-2.0753, acc-0.4000, valid loss-2.0201, acc-0.4438, test loss-2.0209, acc-0.4345\n",
      "Iter-27200, train loss-2.0089, acc-0.4800, valid loss-2.0200, acc-0.4438, test loss-2.0208, acc-0.4346\n",
      "Iter-27210, train loss-1.9636, acc-0.5400, valid loss-2.0199, acc-0.4436, test loss-2.0207, acc-0.4343\n",
      "Iter-27220, train loss-2.0818, acc-0.4400, valid loss-2.0198, acc-0.4438, test loss-2.0206, acc-0.4345\n",
      "Iter-27230, train loss-2.1017, acc-0.3400, valid loss-2.0198, acc-0.4436, test loss-2.0206, acc-0.4344\n",
      "Iter-27240, train loss-1.9791, acc-0.4200, valid loss-2.0197, acc-0.4436, test loss-2.0205, acc-0.4345\n",
      "Iter-27250, train loss-1.9649, acc-0.5000, valid loss-2.0196, acc-0.4434, test loss-2.0204, acc-0.4346\n",
      "Iter-27260, train loss-2.0345, acc-0.4400, valid loss-2.0195, acc-0.4434, test loss-2.0203, acc-0.4344\n",
      "Iter-27270, train loss-2.0759, acc-0.2600, valid loss-2.0194, acc-0.4430, test loss-2.0202, acc-0.4344\n",
      "Iter-27280, train loss-2.0637, acc-0.3600, valid loss-2.0193, acc-0.4430, test loss-2.0201, acc-0.4345\n",
      "Iter-27290, train loss-2.0009, acc-0.4800, valid loss-2.0192, acc-0.4434, test loss-2.0201, acc-0.4345\n",
      "Iter-27300, train loss-2.0458, acc-0.4000, valid loss-2.0192, acc-0.4432, test loss-2.0200, acc-0.4346\n",
      "Iter-27310, train loss-2.0075, acc-0.4600, valid loss-2.0191, acc-0.4432, test loss-2.0199, acc-0.4345\n",
      "Iter-27320, train loss-2.0560, acc-0.4400, valid loss-2.0190, acc-0.4432, test loss-2.0198, acc-0.4347\n",
      "Iter-27330, train loss-2.0121, acc-0.4600, valid loss-2.0189, acc-0.4436, test loss-2.0197, acc-0.4346\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-27340, train loss-2.0412, acc-0.4000, valid loss-2.0188, acc-0.4434, test loss-2.0196, acc-0.4349\n",
      "Iter-27350, train loss-2.0019, acc-0.5000, valid loss-2.0187, acc-0.4434, test loss-2.0196, acc-0.4352\n",
      "Iter-27360, train loss-2.0205, acc-0.4200, valid loss-2.0187, acc-0.4436, test loss-2.0195, acc-0.4352\n",
      "Iter-27370, train loss-1.9833, acc-0.4800, valid loss-2.0186, acc-0.4436, test loss-2.0194, acc-0.4352\n",
      "Iter-27380, train loss-2.1363, acc-0.2600, valid loss-2.0185, acc-0.4438, test loss-2.0193, acc-0.4351\n",
      "Iter-27390, train loss-1.9889, acc-0.5200, valid loss-2.0184, acc-0.4438, test loss-2.0192, acc-0.4350\n",
      "Iter-27400, train loss-2.1035, acc-0.3200, valid loss-2.0183, acc-0.4440, test loss-2.0191, acc-0.4350\n",
      "Iter-27410, train loss-2.0441, acc-0.3800, valid loss-2.0182, acc-0.4442, test loss-2.0191, acc-0.4350\n",
      "Iter-27420, train loss-2.0448, acc-0.4000, valid loss-2.0181, acc-0.4442, test loss-2.0190, acc-0.4350\n",
      "Iter-27430, train loss-2.0952, acc-0.3600, valid loss-2.0181, acc-0.4436, test loss-2.0189, acc-0.4352\n",
      "Iter-27440, train loss-1.9728, acc-0.4200, valid loss-2.0180, acc-0.4436, test loss-2.0188, acc-0.4352\n",
      "Iter-27450, train loss-2.0669, acc-0.3000, valid loss-2.0179, acc-0.4436, test loss-2.0187, acc-0.4352\n",
      "Iter-27460, train loss-2.0267, acc-0.4000, valid loss-2.0178, acc-0.4434, test loss-2.0186, acc-0.4352\n",
      "Iter-27470, train loss-1.9911, acc-0.4800, valid loss-2.0177, acc-0.4436, test loss-2.0186, acc-0.4351\n",
      "Iter-27480, train loss-2.0104, acc-0.5200, valid loss-2.0176, acc-0.4434, test loss-2.0185, acc-0.4355\n",
      "Iter-27490, train loss-1.9908, acc-0.4800, valid loss-2.0176, acc-0.4442, test loss-2.0184, acc-0.4353\n",
      "Iter-27500, train loss-2.0076, acc-0.4400, valid loss-2.0175, acc-0.4442, test loss-2.0183, acc-0.4353\n",
      "Iter-27510, train loss-2.0563, acc-0.4000, valid loss-2.0174, acc-0.4440, test loss-2.0182, acc-0.4353\n",
      "Iter-27520, train loss-2.0189, acc-0.5000, valid loss-2.0173, acc-0.4440, test loss-2.0181, acc-0.4350\n",
      "Iter-27530, train loss-1.9829, acc-0.4200, valid loss-2.0172, acc-0.4438, test loss-2.0180, acc-0.4350\n",
      "Iter-27540, train loss-2.0515, acc-0.3400, valid loss-2.0171, acc-0.4438, test loss-2.0180, acc-0.4351\n",
      "Iter-27550, train loss-2.0410, acc-0.3200, valid loss-2.0170, acc-0.4436, test loss-2.0179, acc-0.4349\n",
      "Iter-27560, train loss-1.9781, acc-0.5800, valid loss-2.0170, acc-0.4440, test loss-2.0178, acc-0.4351\n",
      "Iter-27570, train loss-2.0287, acc-0.4400, valid loss-2.0169, acc-0.4436, test loss-2.0177, acc-0.4353\n",
      "Iter-27580, train loss-2.0722, acc-0.3000, valid loss-2.0168, acc-0.4436, test loss-2.0176, acc-0.4353\n",
      "Iter-27590, train loss-2.0471, acc-0.3600, valid loss-2.0167, acc-0.4436, test loss-2.0175, acc-0.4354\n",
      "Iter-27600, train loss-2.0773, acc-0.3400, valid loss-2.0166, acc-0.4436, test loss-2.0175, acc-0.4356\n",
      "Iter-27610, train loss-2.0818, acc-0.3600, valid loss-2.0166, acc-0.4440, test loss-2.0174, acc-0.4355\n",
      "Iter-27620, train loss-2.0454, acc-0.4200, valid loss-2.0165, acc-0.4440, test loss-2.0173, acc-0.4354\n",
      "Iter-27630, train loss-2.0390, acc-0.4600, valid loss-2.0164, acc-0.4440, test loss-2.0172, acc-0.4353\n",
      "Iter-27640, train loss-1.9896, acc-0.4400, valid loss-2.0163, acc-0.4438, test loss-2.0171, acc-0.4353\n",
      "Iter-27650, train loss-2.0392, acc-0.4400, valid loss-2.0162, acc-0.4442, test loss-2.0170, acc-0.4356\n",
      "Iter-27660, train loss-2.0191, acc-0.5000, valid loss-2.0161, acc-0.4440, test loss-2.0170, acc-0.4357\n",
      "Iter-27670, train loss-1.9801, acc-0.4000, valid loss-2.0161, acc-0.4442, test loss-2.0169, acc-0.4357\n",
      "Iter-27680, train loss-1.9890, acc-0.5000, valid loss-2.0160, acc-0.4444, test loss-2.0168, acc-0.4359\n",
      "Iter-27690, train loss-2.0932, acc-0.3800, valid loss-2.0159, acc-0.4444, test loss-2.0167, acc-0.4358\n",
      "Iter-27700, train loss-2.0384, acc-0.3600, valid loss-2.0158, acc-0.4450, test loss-2.0166, acc-0.4358\n",
      "Iter-27710, train loss-2.0031, acc-0.4400, valid loss-2.0157, acc-0.4446, test loss-2.0165, acc-0.4359\n",
      "Iter-27720, train loss-2.0571, acc-0.4200, valid loss-2.0156, acc-0.4444, test loss-2.0165, acc-0.4358\n",
      "Iter-27730, train loss-2.0607, acc-0.4600, valid loss-2.0156, acc-0.4444, test loss-2.0164, acc-0.4358\n",
      "Iter-27740, train loss-1.9938, acc-0.4000, valid loss-2.0155, acc-0.4444, test loss-2.0163, acc-0.4359\n",
      "Iter-27750, train loss-2.0254, acc-0.4000, valid loss-2.0154, acc-0.4444, test loss-2.0162, acc-0.4357\n",
      "Iter-27760, train loss-2.0158, acc-0.5000, valid loss-2.0153, acc-0.4444, test loss-2.0161, acc-0.4357\n",
      "Iter-27770, train loss-2.0126, acc-0.4000, valid loss-2.0152, acc-0.4444, test loss-2.0161, acc-0.4354\n",
      "Iter-27780, train loss-2.0053, acc-0.4400, valid loss-2.0151, acc-0.4446, test loss-2.0160, acc-0.4355\n",
      "Iter-27790, train loss-1.9265, acc-0.6000, valid loss-2.0151, acc-0.4446, test loss-2.0159, acc-0.4355\n",
      "Iter-27800, train loss-1.9849, acc-0.4400, valid loss-2.0150, acc-0.4444, test loss-2.0158, acc-0.4355\n",
      "Iter-27810, train loss-2.0198, acc-0.4400, valid loss-2.0149, acc-0.4446, test loss-2.0157, acc-0.4355\n",
      "Iter-27820, train loss-2.0524, acc-0.4400, valid loss-2.0148, acc-0.4446, test loss-2.0156, acc-0.4354\n",
      "Iter-27830, train loss-2.0161, acc-0.4400, valid loss-2.0147, acc-0.4446, test loss-2.0155, acc-0.4356\n",
      "Iter-27840, train loss-2.0307, acc-0.4000, valid loss-2.0146, acc-0.4446, test loss-2.0155, acc-0.4354\n",
      "Iter-27850, train loss-1.9859, acc-0.4600, valid loss-2.0146, acc-0.4444, test loss-2.0154, acc-0.4354\n",
      "Iter-27860, train loss-1.9933, acc-0.4800, valid loss-2.0145, acc-0.4444, test loss-2.0153, acc-0.4353\n",
      "Iter-27870, train loss-1.9925, acc-0.5400, valid loss-2.0144, acc-0.4446, test loss-2.0152, acc-0.4354\n",
      "Iter-27880, train loss-1.9696, acc-0.5200, valid loss-2.0143, acc-0.4446, test loss-2.0151, acc-0.4353\n",
      "Iter-27890, train loss-1.9646, acc-0.5000, valid loss-2.0142, acc-0.4446, test loss-2.0151, acc-0.4354\n",
      "Iter-27900, train loss-1.9751, acc-0.5000, valid loss-2.0141, acc-0.4446, test loss-2.0150, acc-0.4352\n",
      "Iter-27910, train loss-2.0362, acc-0.3800, valid loss-2.0141, acc-0.4446, test loss-2.0149, acc-0.4353\n",
      "Iter-27920, train loss-2.0427, acc-0.3400, valid loss-2.0140, acc-0.4446, test loss-2.0148, acc-0.4354\n",
      "Iter-27930, train loss-2.0085, acc-0.4600, valid loss-2.0139, acc-0.4442, test loss-2.0147, acc-0.4356\n",
      "Iter-27940, train loss-2.0035, acc-0.5600, valid loss-2.0138, acc-0.4444, test loss-2.0146, acc-0.4356\n",
      "Iter-27950, train loss-1.9805, acc-0.4000, valid loss-2.0137, acc-0.4444, test loss-2.0146, acc-0.4357\n",
      "Iter-27960, train loss-2.0076, acc-0.4600, valid loss-2.0137, acc-0.4446, test loss-2.0145, acc-0.4355\n",
      "Iter-27970, train loss-1.9593, acc-0.5200, valid loss-2.0136, acc-0.4444, test loss-2.0144, acc-0.4356\n",
      "Iter-27980, train loss-1.9018, acc-0.5600, valid loss-2.0135, acc-0.4444, test loss-2.0143, acc-0.4357\n",
      "Iter-27990, train loss-2.0095, acc-0.4000, valid loss-2.0134, acc-0.4448, test loss-2.0142, acc-0.4358\n",
      "Iter-28000, train loss-2.0320, acc-0.4200, valid loss-2.0133, acc-0.4448, test loss-2.0141, acc-0.4358\n",
      "Iter-28010, train loss-2.0500, acc-0.4000, valid loss-2.0132, acc-0.4448, test loss-2.0141, acc-0.4359\n",
      "Iter-28020, train loss-2.0324, acc-0.4400, valid loss-2.0132, acc-0.4446, test loss-2.0140, acc-0.4361\n",
      "Iter-28030, train loss-1.9826, acc-0.5200, valid loss-2.0131, acc-0.4446, test loss-2.0139, acc-0.4359\n",
      "Iter-28040, train loss-1.9977, acc-0.4400, valid loss-2.0130, acc-0.4446, test loss-2.0138, acc-0.4362\n",
      "Iter-28050, train loss-2.0453, acc-0.3800, valid loss-2.0129, acc-0.4448, test loss-2.0137, acc-0.4359\n",
      "Iter-28060, train loss-2.0763, acc-0.3600, valid loss-2.0128, acc-0.4448, test loss-2.0136, acc-0.4360\n",
      "Iter-28070, train loss-1.9929, acc-0.5000, valid loss-2.0127, acc-0.4446, test loss-2.0136, acc-0.4365\n",
      "Iter-28080, train loss-2.0021, acc-0.4800, valid loss-2.0127, acc-0.4448, test loss-2.0135, acc-0.4362\n",
      "Iter-28090, train loss-2.0375, acc-0.4200, valid loss-2.0126, acc-0.4446, test loss-2.0134, acc-0.4363\n",
      "Iter-28100, train loss-2.0568, acc-0.3800, valid loss-2.0125, acc-0.4446, test loss-2.0133, acc-0.4367\n",
      "Iter-28110, train loss-2.0043, acc-0.5000, valid loss-2.0124, acc-0.4444, test loss-2.0132, acc-0.4366\n",
      "Iter-28120, train loss-2.0416, acc-0.3200, valid loss-2.0123, acc-0.4444, test loss-2.0132, acc-0.4365\n",
      "Iter-28130, train loss-2.0540, acc-0.4200, valid loss-2.0123, acc-0.4444, test loss-2.0131, acc-0.4366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28140, train loss-1.9990, acc-0.4800, valid loss-2.0122, acc-0.4444, test loss-2.0130, acc-0.4365\n",
      "Iter-28150, train loss-2.0610, acc-0.4000, valid loss-2.0121, acc-0.4442, test loss-2.0129, acc-0.4365\n",
      "Iter-28160, train loss-2.0001, acc-0.4800, valid loss-2.0120, acc-0.4446, test loss-2.0128, acc-0.4363\n",
      "Iter-28170, train loss-2.0419, acc-0.4400, valid loss-2.0119, acc-0.4448, test loss-2.0127, acc-0.4362\n",
      "Iter-28180, train loss-2.0590, acc-0.3000, valid loss-2.0118, acc-0.4446, test loss-2.0127, acc-0.4364\n",
      "Iter-28190, train loss-1.9973, acc-0.3800, valid loss-2.0118, acc-0.4444, test loss-2.0126, acc-0.4364\n",
      "Iter-28200, train loss-2.0321, acc-0.4200, valid loss-2.0117, acc-0.4444, test loss-2.0125, acc-0.4365\n",
      "Iter-28210, train loss-2.0138, acc-0.5000, valid loss-2.0116, acc-0.4444, test loss-2.0124, acc-0.4361\n",
      "Iter-28220, train loss-2.0094, acc-0.4000, valid loss-2.0115, acc-0.4444, test loss-2.0123, acc-0.4360\n",
      "Iter-28230, train loss-2.0642, acc-0.4000, valid loss-2.0114, acc-0.4444, test loss-2.0122, acc-0.4358\n",
      "Iter-28240, train loss-2.0361, acc-0.3200, valid loss-2.0113, acc-0.4446, test loss-2.0122, acc-0.4358\n",
      "Iter-28250, train loss-2.0374, acc-0.4800, valid loss-2.0113, acc-0.4448, test loss-2.0121, acc-0.4356\n",
      "Iter-28260, train loss-2.0606, acc-0.3800, valid loss-2.0112, acc-0.4448, test loss-2.0120, acc-0.4356\n",
      "Iter-28270, train loss-2.0464, acc-0.4200, valid loss-2.0111, acc-0.4450, test loss-2.0119, acc-0.4356\n",
      "Iter-28280, train loss-1.9891, acc-0.3800, valid loss-2.0110, acc-0.4448, test loss-2.0118, acc-0.4356\n",
      "Iter-28290, train loss-2.0399, acc-0.4000, valid loss-2.0109, acc-0.4448, test loss-2.0118, acc-0.4357\n",
      "Iter-28300, train loss-2.0175, acc-0.4200, valid loss-2.0109, acc-0.4448, test loss-2.0117, acc-0.4354\n",
      "Iter-28310, train loss-2.0200, acc-0.3400, valid loss-2.0108, acc-0.4450, test loss-2.0116, acc-0.4356\n",
      "Iter-28320, train loss-1.9846, acc-0.5800, valid loss-2.0107, acc-0.4448, test loss-2.0115, acc-0.4357\n",
      "Iter-28330, train loss-1.9677, acc-0.5000, valid loss-2.0106, acc-0.4446, test loss-2.0114, acc-0.4361\n",
      "Iter-28340, train loss-1.9897, acc-0.4200, valid loss-2.0105, acc-0.4448, test loss-2.0113, acc-0.4362\n",
      "Iter-28350, train loss-2.0242, acc-0.3400, valid loss-2.0104, acc-0.4446, test loss-2.0113, acc-0.4362\n",
      "Iter-28360, train loss-1.9631, acc-0.5000, valid loss-2.0103, acc-0.4450, test loss-2.0112, acc-0.4361\n",
      "Iter-28370, train loss-2.0215, acc-0.4400, valid loss-2.0103, acc-0.4450, test loss-2.0111, acc-0.4361\n",
      "Iter-28380, train loss-2.0378, acc-0.3800, valid loss-2.0102, acc-0.4450, test loss-2.0110, acc-0.4363\n",
      "Iter-28390, train loss-2.0669, acc-0.3400, valid loss-2.0101, acc-0.4456, test loss-2.0109, acc-0.4364\n",
      "Iter-28400, train loss-2.0933, acc-0.3400, valid loss-2.0100, acc-0.4454, test loss-2.0108, acc-0.4365\n",
      "Iter-28410, train loss-1.9956, acc-0.5400, valid loss-2.0099, acc-0.4450, test loss-2.0108, acc-0.4364\n",
      "Iter-28420, train loss-2.0375, acc-0.4200, valid loss-2.0099, acc-0.4452, test loss-2.0107, acc-0.4363\n",
      "Iter-28430, train loss-1.9805, acc-0.6200, valid loss-2.0098, acc-0.4450, test loss-2.0106, acc-0.4362\n",
      "Iter-28440, train loss-1.9897, acc-0.4000, valid loss-2.0097, acc-0.4450, test loss-2.0105, acc-0.4363\n",
      "Iter-28450, train loss-1.9979, acc-0.4400, valid loss-2.0096, acc-0.4452, test loss-2.0104, acc-0.4365\n",
      "Iter-28460, train loss-1.9911, acc-0.4800, valid loss-2.0095, acc-0.4454, test loss-2.0104, acc-0.4364\n",
      "Iter-28470, train loss-2.0030, acc-0.4000, valid loss-2.0095, acc-0.4454, test loss-2.0103, acc-0.4365\n",
      "Iter-28480, train loss-2.0279, acc-0.4000, valid loss-2.0094, acc-0.4456, test loss-2.0102, acc-0.4366\n",
      "Iter-28490, train loss-2.0550, acc-0.3600, valid loss-2.0093, acc-0.4456, test loss-2.0101, acc-0.4366\n",
      "Iter-28500, train loss-2.0025, acc-0.5400, valid loss-2.0092, acc-0.4454, test loss-2.0100, acc-0.4364\n",
      "Iter-28510, train loss-2.0355, acc-0.3000, valid loss-2.0091, acc-0.4454, test loss-2.0099, acc-0.4366\n",
      "Iter-28520, train loss-2.0668, acc-0.4000, valid loss-2.0090, acc-0.4454, test loss-2.0099, acc-0.4365\n",
      "Iter-28530, train loss-1.9087, acc-0.5200, valid loss-2.0090, acc-0.4454, test loss-2.0098, acc-0.4366\n",
      "Iter-28540, train loss-1.9987, acc-0.4800, valid loss-2.0089, acc-0.4452, test loss-2.0097, acc-0.4367\n",
      "Iter-28550, train loss-2.0123, acc-0.4400, valid loss-2.0088, acc-0.4452, test loss-2.0096, acc-0.4367\n",
      "Iter-28560, train loss-2.0445, acc-0.4400, valid loss-2.0087, acc-0.4454, test loss-2.0095, acc-0.4368\n",
      "Iter-28570, train loss-1.9338, acc-0.5600, valid loss-2.0086, acc-0.4454, test loss-2.0095, acc-0.4365\n",
      "Iter-28580, train loss-2.0076, acc-0.3600, valid loss-2.0086, acc-0.4458, test loss-2.0094, acc-0.4368\n",
      "Iter-28590, train loss-2.0039, acc-0.4600, valid loss-2.0085, acc-0.4456, test loss-2.0093, acc-0.4365\n",
      "Iter-28600, train loss-1.9912, acc-0.4600, valid loss-2.0084, acc-0.4456, test loss-2.0092, acc-0.4364\n",
      "Iter-28610, train loss-2.0240, acc-0.4400, valid loss-2.0083, acc-0.4460, test loss-2.0091, acc-0.4366\n",
      "Iter-28620, train loss-2.0311, acc-0.5000, valid loss-2.0082, acc-0.4462, test loss-2.0091, acc-0.4365\n",
      "Iter-28630, train loss-2.0392, acc-0.3400, valid loss-2.0082, acc-0.4466, test loss-2.0090, acc-0.4366\n",
      "Iter-28640, train loss-1.9749, acc-0.5200, valid loss-2.0081, acc-0.4464, test loss-2.0089, acc-0.4367\n",
      "Iter-28650, train loss-2.0165, acc-0.3600, valid loss-2.0080, acc-0.4460, test loss-2.0088, acc-0.4368\n",
      "Iter-28660, train loss-2.0492, acc-0.3400, valid loss-2.0079, acc-0.4460, test loss-2.0087, acc-0.4369\n",
      "Iter-28670, train loss-1.9878, acc-0.4200, valid loss-2.0078, acc-0.4460, test loss-2.0087, acc-0.4368\n",
      "Iter-28680, train loss-2.0445, acc-0.4000, valid loss-2.0078, acc-0.4462, test loss-2.0086, acc-0.4370\n",
      "Iter-28690, train loss-2.0401, acc-0.4200, valid loss-2.0077, acc-0.4460, test loss-2.0085, acc-0.4370\n",
      "Iter-28700, train loss-2.0091, acc-0.3400, valid loss-2.0076, acc-0.4460, test loss-2.0084, acc-0.4370\n",
      "Iter-28710, train loss-2.0130, acc-0.4600, valid loss-2.0075, acc-0.4462, test loss-2.0083, acc-0.4370\n",
      "Iter-28720, train loss-2.0538, acc-0.3200, valid loss-2.0074, acc-0.4462, test loss-2.0082, acc-0.4371\n",
      "Iter-28730, train loss-2.0180, acc-0.4800, valid loss-2.0074, acc-0.4464, test loss-2.0082, acc-0.4372\n",
      "Iter-28740, train loss-2.0044, acc-0.4200, valid loss-2.0073, acc-0.4464, test loss-2.0081, acc-0.4371\n",
      "Iter-28750, train loss-2.0036, acc-0.4400, valid loss-2.0072, acc-0.4466, test loss-2.0080, acc-0.4371\n",
      "Iter-28760, train loss-1.9613, acc-0.5200, valid loss-2.0071, acc-0.4466, test loss-2.0079, acc-0.4371\n",
      "Iter-28770, train loss-2.0881, acc-0.3000, valid loss-2.0070, acc-0.4464, test loss-2.0078, acc-0.4372\n",
      "Iter-28780, train loss-2.0682, acc-0.5000, valid loss-2.0070, acc-0.4466, test loss-2.0078, acc-0.4371\n",
      "Iter-28790, train loss-1.9565, acc-0.4400, valid loss-2.0069, acc-0.4466, test loss-2.0077, acc-0.4375\n",
      "Iter-28800, train loss-2.0886, acc-0.3400, valid loss-2.0068, acc-0.4466, test loss-2.0076, acc-0.4375\n",
      "Iter-28810, train loss-2.0481, acc-0.3600, valid loss-2.0067, acc-0.4466, test loss-2.0075, acc-0.4374\n",
      "Iter-28820, train loss-2.0417, acc-0.4000, valid loss-2.0066, acc-0.4468, test loss-2.0074, acc-0.4376\n",
      "Iter-28830, train loss-2.0784, acc-0.3800, valid loss-2.0066, acc-0.4468, test loss-2.0074, acc-0.4375\n",
      "Iter-28840, train loss-2.0395, acc-0.3800, valid loss-2.0065, acc-0.4470, test loss-2.0073, acc-0.4378\n",
      "Iter-28850, train loss-2.0558, acc-0.3400, valid loss-2.0064, acc-0.4468, test loss-2.0072, acc-0.4376\n",
      "Iter-28860, train loss-2.0510, acc-0.3600, valid loss-2.0063, acc-0.4472, test loss-2.0071, acc-0.4376\n",
      "Iter-28870, train loss-2.0092, acc-0.5400, valid loss-2.0062, acc-0.4470, test loss-2.0070, acc-0.4379\n",
      "Iter-28880, train loss-2.0544, acc-0.4800, valid loss-2.0062, acc-0.4474, test loss-2.0070, acc-0.4376\n",
      "Iter-28890, train loss-2.0275, acc-0.4600, valid loss-2.0061, acc-0.4472, test loss-2.0069, acc-0.4375\n",
      "Iter-28900, train loss-2.0348, acc-0.4400, valid loss-2.0060, acc-0.4470, test loss-2.0068, acc-0.4376\n",
      "Iter-28910, train loss-2.0876, acc-0.3200, valid loss-2.0059, acc-0.4470, test loss-2.0067, acc-0.4376\n",
      "Iter-28920, train loss-1.9729, acc-0.5200, valid loss-2.0058, acc-0.4470, test loss-2.0066, acc-0.4377\n",
      "Iter-28930, train loss-2.1257, acc-0.2200, valid loss-2.0058, acc-0.4470, test loss-2.0066, acc-0.4376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-28940, train loss-2.0117, acc-0.5000, valid loss-2.0057, acc-0.4470, test loss-2.0065, acc-0.4377\n",
      "Iter-28950, train loss-2.1181, acc-0.2800, valid loss-2.0056, acc-0.4472, test loss-2.0064, acc-0.4376\n",
      "Iter-28960, train loss-2.0071, acc-0.3800, valid loss-2.0055, acc-0.4472, test loss-2.0063, acc-0.4376\n",
      "Iter-28970, train loss-2.0231, acc-0.4800, valid loss-2.0054, acc-0.4472, test loss-2.0062, acc-0.4376\n",
      "Iter-28980, train loss-1.9952, acc-0.4800, valid loss-2.0054, acc-0.4472, test loss-2.0062, acc-0.4377\n",
      "Iter-28990, train loss-2.0063, acc-0.4600, valid loss-2.0053, acc-0.4472, test loss-2.0061, acc-0.4378\n",
      "Iter-29000, train loss-2.0277, acc-0.3800, valid loss-2.0052, acc-0.4472, test loss-2.0060, acc-0.4376\n",
      "Iter-29010, train loss-1.9856, acc-0.5000, valid loss-2.0051, acc-0.4472, test loss-2.0059, acc-0.4376\n",
      "Iter-29020, train loss-2.0213, acc-0.4200, valid loss-2.0050, acc-0.4474, test loss-2.0058, acc-0.4374\n",
      "Iter-29030, train loss-2.0003, acc-0.4200, valid loss-2.0050, acc-0.4474, test loss-2.0058, acc-0.4371\n",
      "Iter-29040, train loss-2.0066, acc-0.4400, valid loss-2.0049, acc-0.4474, test loss-2.0057, acc-0.4375\n",
      "Iter-29050, train loss-2.0583, acc-0.4600, valid loss-2.0048, acc-0.4476, test loss-2.0056, acc-0.4376\n",
      "Iter-29060, train loss-2.0024, acc-0.4200, valid loss-2.0047, acc-0.4474, test loss-2.0055, acc-0.4375\n",
      "Iter-29070, train loss-2.0144, acc-0.3800, valid loss-2.0046, acc-0.4474, test loss-2.0054, acc-0.4374\n",
      "Iter-29080, train loss-2.0445, acc-0.2800, valid loss-2.0046, acc-0.4474, test loss-2.0054, acc-0.4374\n",
      "Iter-29090, train loss-1.9545, acc-0.5200, valid loss-2.0045, acc-0.4474, test loss-2.0053, acc-0.4374\n",
      "Iter-29100, train loss-2.0871, acc-0.3400, valid loss-2.0044, acc-0.4478, test loss-2.0052, acc-0.4375\n",
      "Iter-29110, train loss-1.9362, acc-0.4600, valid loss-2.0043, acc-0.4476, test loss-2.0051, acc-0.4377\n",
      "Iter-29120, train loss-2.0192, acc-0.3600, valid loss-2.0042, acc-0.4476, test loss-2.0050, acc-0.4376\n",
      "Iter-29130, train loss-2.0474, acc-0.4200, valid loss-2.0041, acc-0.4476, test loss-2.0050, acc-0.4377\n",
      "Iter-29140, train loss-2.0144, acc-0.4600, valid loss-2.0041, acc-0.4476, test loss-2.0049, acc-0.4378\n",
      "Iter-29150, train loss-2.0031, acc-0.4400, valid loss-2.0040, acc-0.4478, test loss-2.0048, acc-0.4379\n",
      "Iter-29160, train loss-1.9618, acc-0.5200, valid loss-2.0039, acc-0.4476, test loss-2.0047, acc-0.4378\n",
      "Iter-29170, train loss-2.0471, acc-0.3600, valid loss-2.0038, acc-0.4478, test loss-2.0046, acc-0.4379\n",
      "Iter-29180, train loss-2.0176, acc-0.5000, valid loss-2.0037, acc-0.4474, test loss-2.0045, acc-0.4382\n",
      "Iter-29190, train loss-1.9707, acc-0.4400, valid loss-2.0037, acc-0.4474, test loss-2.0045, acc-0.4380\n",
      "Iter-29200, train loss-2.0344, acc-0.4000, valid loss-2.0036, acc-0.4472, test loss-2.0044, acc-0.4378\n",
      "Iter-29210, train loss-2.0234, acc-0.4800, valid loss-2.0035, acc-0.4472, test loss-2.0043, acc-0.4381\n",
      "Iter-29220, train loss-2.0561, acc-0.4200, valid loss-2.0034, acc-0.4472, test loss-2.0042, acc-0.4378\n",
      "Iter-29230, train loss-1.9761, acc-0.4400, valid loss-2.0033, acc-0.4474, test loss-2.0041, acc-0.4378\n",
      "Iter-29240, train loss-2.0244, acc-0.4000, valid loss-2.0032, acc-0.4476, test loss-2.0041, acc-0.4377\n",
      "Iter-29250, train loss-1.9911, acc-0.4000, valid loss-2.0032, acc-0.4478, test loss-2.0040, acc-0.4378\n",
      "Iter-29260, train loss-1.9668, acc-0.5600, valid loss-2.0031, acc-0.4480, test loss-2.0039, acc-0.4381\n",
      "Iter-29270, train loss-1.9681, acc-0.5200, valid loss-2.0030, acc-0.4480, test loss-2.0038, acc-0.4380\n",
      "Iter-29280, train loss-2.0342, acc-0.4200, valid loss-2.0029, acc-0.4478, test loss-2.0037, acc-0.4379\n",
      "Iter-29290, train loss-2.0029, acc-0.4400, valid loss-2.0028, acc-0.4480, test loss-2.0036, acc-0.4382\n",
      "Iter-29300, train loss-2.0086, acc-0.3200, valid loss-2.0028, acc-0.4484, test loss-2.0036, acc-0.4385\n",
      "Iter-29310, train loss-2.0075, acc-0.4600, valid loss-2.0027, acc-0.4486, test loss-2.0035, acc-0.4386\n",
      "Iter-29320, train loss-2.0605, acc-0.3800, valid loss-2.0026, acc-0.4490, test loss-2.0034, acc-0.4386\n",
      "Iter-29330, train loss-2.0694, acc-0.4000, valid loss-2.0025, acc-0.4484, test loss-2.0033, acc-0.4388\n",
      "Iter-29340, train loss-2.0314, acc-0.4800, valid loss-2.0024, acc-0.4490, test loss-2.0032, acc-0.4389\n",
      "Iter-29350, train loss-2.0402, acc-0.4400, valid loss-2.0024, acc-0.4486, test loss-2.0032, acc-0.4389\n",
      "Iter-29360, train loss-2.0303, acc-0.3800, valid loss-2.0023, acc-0.4488, test loss-2.0031, acc-0.4389\n",
      "Iter-29370, train loss-2.0017, acc-0.4400, valid loss-2.0022, acc-0.4490, test loss-2.0030, acc-0.4388\n",
      "Iter-29380, train loss-2.0261, acc-0.4400, valid loss-2.0021, acc-0.4492, test loss-2.0029, acc-0.4386\n",
      "Iter-29390, train loss-2.0682, acc-0.3400, valid loss-2.0020, acc-0.4492, test loss-2.0028, acc-0.4385\n",
      "Iter-29400, train loss-1.9666, acc-0.5800, valid loss-2.0020, acc-0.4492, test loss-2.0028, acc-0.4385\n",
      "Iter-29410, train loss-1.9862, acc-0.4600, valid loss-2.0019, acc-0.4490, test loss-2.0027, acc-0.4388\n",
      "Iter-29420, train loss-1.9739, acc-0.5200, valid loss-2.0018, acc-0.4494, test loss-2.0026, acc-0.4391\n",
      "Iter-29430, train loss-2.0454, acc-0.4000, valid loss-2.0017, acc-0.4490, test loss-2.0025, acc-0.4393\n",
      "Iter-29440, train loss-1.9515, acc-0.5400, valid loss-2.0016, acc-0.4494, test loss-2.0024, acc-0.4393\n",
      "Iter-29450, train loss-2.0924, acc-0.3200, valid loss-2.0016, acc-0.4496, test loss-2.0024, acc-0.4395\n",
      "Iter-29460, train loss-1.9825, acc-0.4800, valid loss-2.0015, acc-0.4496, test loss-2.0023, acc-0.4393\n",
      "Iter-29470, train loss-2.0248, acc-0.3800, valid loss-2.0014, acc-0.4496, test loss-2.0022, acc-0.4396\n",
      "Iter-29480, train loss-1.9661, acc-0.5000, valid loss-2.0013, acc-0.4490, test loss-2.0021, acc-0.4395\n",
      "Iter-29490, train loss-1.9519, acc-0.5400, valid loss-2.0012, acc-0.4492, test loss-2.0020, acc-0.4393\n",
      "Iter-29500, train loss-1.9556, acc-0.4800, valid loss-2.0012, acc-0.4494, test loss-2.0020, acc-0.4393\n",
      "Iter-29510, train loss-2.0497, acc-0.3800, valid loss-2.0011, acc-0.4498, test loss-2.0019, acc-0.4392\n",
      "Iter-29520, train loss-2.0229, acc-0.4200, valid loss-2.0010, acc-0.4496, test loss-2.0018, acc-0.4392\n",
      "Iter-29530, train loss-2.0213, acc-0.4200, valid loss-2.0009, acc-0.4498, test loss-2.0017, acc-0.4395\n",
      "Iter-29540, train loss-1.9666, acc-0.4400, valid loss-2.0008, acc-0.4498, test loss-2.0017, acc-0.4394\n",
      "Iter-29550, train loss-2.0303, acc-0.4200, valid loss-2.0007, acc-0.4496, test loss-2.0016, acc-0.4393\n",
      "Iter-29560, train loss-2.0702, acc-0.3400, valid loss-2.0007, acc-0.4500, test loss-2.0015, acc-0.4390\n",
      "Iter-29570, train loss-1.9827, acc-0.5200, valid loss-2.0006, acc-0.4502, test loss-2.0014, acc-0.4389\n",
      "Iter-29580, train loss-2.0052, acc-0.4400, valid loss-2.0005, acc-0.4504, test loss-2.0013, acc-0.4388\n",
      "Iter-29590, train loss-1.9890, acc-0.4600, valid loss-2.0004, acc-0.4500, test loss-2.0012, acc-0.4389\n",
      "Iter-29600, train loss-2.0735, acc-0.3800, valid loss-2.0003, acc-0.4504, test loss-2.0012, acc-0.4386\n",
      "Iter-29610, train loss-2.0332, acc-0.4400, valid loss-2.0002, acc-0.4498, test loss-2.0011, acc-0.4390\n",
      "Iter-29620, train loss-1.9921, acc-0.4600, valid loss-2.0002, acc-0.4502, test loss-2.0010, acc-0.4391\n",
      "Iter-29630, train loss-2.0274, acc-0.4400, valid loss-2.0001, acc-0.4502, test loss-2.0009, acc-0.4390\n",
      "Iter-29640, train loss-1.9881, acc-0.5000, valid loss-2.0000, acc-0.4500, test loss-2.0008, acc-0.4392\n",
      "Iter-29650, train loss-2.0782, acc-0.3000, valid loss-1.9999, acc-0.4502, test loss-2.0008, acc-0.4393\n",
      "Iter-29660, train loss-2.0031, acc-0.4600, valid loss-1.9998, acc-0.4504, test loss-2.0007, acc-0.4392\n",
      "Iter-29670, train loss-1.9057, acc-0.6800, valid loss-1.9998, acc-0.4506, test loss-2.0006, acc-0.4393\n",
      "Iter-29680, train loss-1.9567, acc-0.5400, valid loss-1.9997, acc-0.4506, test loss-2.0005, acc-0.4393\n",
      "Iter-29690, train loss-2.0292, acc-0.4800, valid loss-1.9996, acc-0.4506, test loss-2.0004, acc-0.4393\n",
      "Iter-29700, train loss-1.9431, acc-0.6000, valid loss-1.9995, acc-0.4502, test loss-2.0004, acc-0.4395\n",
      "Iter-29710, train loss-2.0958, acc-0.4000, valid loss-1.9995, acc-0.4506, test loss-2.0003, acc-0.4397\n",
      "Iter-29720, train loss-2.0289, acc-0.4600, valid loss-1.9994, acc-0.4508, test loss-2.0002, acc-0.4397\n",
      "Iter-29730, train loss-1.9858, acc-0.4600, valid loss-1.9993, acc-0.4506, test loss-2.0001, acc-0.4399\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-29740, train loss-2.0405, acc-0.4000, valid loss-1.9992, acc-0.4506, test loss-2.0000, acc-0.4400\n",
      "Iter-29750, train loss-1.9966, acc-0.4600, valid loss-1.9991, acc-0.4506, test loss-1.9999, acc-0.4400\n",
      "Iter-29760, train loss-1.9712, acc-0.5400, valid loss-1.9990, acc-0.4506, test loss-1.9999, acc-0.4400\n",
      "Iter-29770, train loss-1.9961, acc-0.5000, valid loss-1.9990, acc-0.4506, test loss-1.9998, acc-0.4398\n",
      "Iter-29780, train loss-2.0175, acc-0.4400, valid loss-1.9989, acc-0.4504, test loss-1.9997, acc-0.4401\n",
      "Iter-29790, train loss-2.0182, acc-0.4200, valid loss-1.9988, acc-0.4510, test loss-1.9996, acc-0.4402\n",
      "Iter-29800, train loss-2.0769, acc-0.3200, valid loss-1.9987, acc-0.4506, test loss-1.9995, acc-0.4401\n",
      "Iter-29810, train loss-2.0621, acc-0.3600, valid loss-1.9986, acc-0.4504, test loss-1.9995, acc-0.4402\n",
      "Iter-29820, train loss-1.9924, acc-0.4000, valid loss-1.9985, acc-0.4504, test loss-1.9994, acc-0.4401\n",
      "Iter-29830, train loss-1.9713, acc-0.4400, valid loss-1.9985, acc-0.4504, test loss-1.9993, acc-0.4402\n",
      "Iter-29840, train loss-1.9729, acc-0.4400, valid loss-1.9984, acc-0.4506, test loss-1.9992, acc-0.4403\n",
      "Iter-29850, train loss-1.9447, acc-0.5000, valid loss-1.9983, acc-0.4508, test loss-1.9991, acc-0.4402\n",
      "Iter-29860, train loss-2.0336, acc-0.3800, valid loss-1.9982, acc-0.4508, test loss-1.9991, acc-0.4402\n",
      "Iter-29870, train loss-2.0173, acc-0.4000, valid loss-1.9982, acc-0.4510, test loss-1.9990, acc-0.4404\n",
      "Iter-29880, train loss-1.9806, acc-0.4800, valid loss-1.9981, acc-0.4508, test loss-1.9989, acc-0.4402\n",
      "Iter-29890, train loss-1.8939, acc-0.5600, valid loss-1.9980, acc-0.4504, test loss-1.9988, acc-0.4402\n",
      "Iter-29900, train loss-2.0433, acc-0.3800, valid loss-1.9979, acc-0.4504, test loss-1.9987, acc-0.4401\n",
      "Iter-29910, train loss-2.0032, acc-0.5000, valid loss-1.9978, acc-0.4504, test loss-1.9987, acc-0.4399\n",
      "Iter-29920, train loss-2.0061, acc-0.4400, valid loss-1.9977, acc-0.4504, test loss-1.9986, acc-0.4397\n",
      "Iter-29930, train loss-2.0445, acc-0.4000, valid loss-1.9977, acc-0.4508, test loss-1.9985, acc-0.4397\n",
      "Iter-29940, train loss-2.0521, acc-0.3200, valid loss-1.9976, acc-0.4508, test loss-1.9984, acc-0.4399\n",
      "Iter-29950, train loss-2.0445, acc-0.4200, valid loss-1.9975, acc-0.4510, test loss-1.9983, acc-0.4396\n",
      "Iter-29960, train loss-1.9867, acc-0.5200, valid loss-1.9974, acc-0.4512, test loss-1.9983, acc-0.4395\n",
      "Iter-29970, train loss-2.0030, acc-0.4600, valid loss-1.9973, acc-0.4512, test loss-1.9982, acc-0.4395\n",
      "Iter-29980, train loss-1.9921, acc-0.3800, valid loss-1.9973, acc-0.4512, test loss-1.9981, acc-0.4399\n",
      "Iter-29990, train loss-2.0468, acc-0.4200, valid loss-1.9972, acc-0.4512, test loss-1.9980, acc-0.4399\n",
      "Iter-30000, train loss-1.9679, acc-0.4800, valid loss-1.9971, acc-0.4512, test loss-1.9979, acc-0.4398\n",
      "Iter-30010, train loss-1.9994, acc-0.4200, valid loss-1.9970, acc-0.4512, test loss-1.9979, acc-0.4399\n",
      "Iter-30020, train loss-2.0568, acc-0.4200, valid loss-1.9969, acc-0.4512, test loss-1.9978, acc-0.4401\n",
      "Iter-30030, train loss-1.9854, acc-0.5000, valid loss-1.9969, acc-0.4514, test loss-1.9977, acc-0.4401\n",
      "Iter-30040, train loss-1.9650, acc-0.5000, valid loss-1.9968, acc-0.4514, test loss-1.9976, acc-0.4400\n",
      "Iter-30050, train loss-2.0803, acc-0.3800, valid loss-1.9967, acc-0.4514, test loss-1.9975, acc-0.4397\n",
      "Iter-30060, train loss-1.9922, acc-0.4600, valid loss-1.9966, acc-0.4514, test loss-1.9975, acc-0.4396\n",
      "Iter-30070, train loss-2.0206, acc-0.5200, valid loss-1.9965, acc-0.4516, test loss-1.9974, acc-0.4396\n",
      "Iter-30080, train loss-1.9989, acc-0.4800, valid loss-1.9965, acc-0.4516, test loss-1.9973, acc-0.4395\n",
      "Iter-30090, train loss-1.9787, acc-0.4800, valid loss-1.9964, acc-0.4512, test loss-1.9972, acc-0.4394\n",
      "Iter-30100, train loss-2.0800, acc-0.2400, valid loss-1.9963, acc-0.4514, test loss-1.9971, acc-0.4395\n",
      "Iter-30110, train loss-1.9782, acc-0.5000, valid loss-1.9962, acc-0.4514, test loss-1.9971, acc-0.4395\n",
      "Iter-30120, train loss-2.0044, acc-0.5200, valid loss-1.9961, acc-0.4514, test loss-1.9970, acc-0.4397\n",
      "Iter-30130, train loss-1.9604, acc-0.5000, valid loss-1.9961, acc-0.4512, test loss-1.9969, acc-0.4397\n",
      "Iter-30140, train loss-1.9592, acc-0.4600, valid loss-1.9960, acc-0.4514, test loss-1.9968, acc-0.4397\n",
      "Iter-30150, train loss-2.0096, acc-0.4000, valid loss-1.9959, acc-0.4514, test loss-1.9967, acc-0.4397\n",
      "Iter-30160, train loss-2.0406, acc-0.4400, valid loss-1.9958, acc-0.4512, test loss-1.9967, acc-0.4396\n",
      "Iter-30170, train loss-2.0171, acc-0.3400, valid loss-1.9957, acc-0.4508, test loss-1.9966, acc-0.4397\n",
      "Iter-30180, train loss-2.0569, acc-0.4000, valid loss-1.9957, acc-0.4512, test loss-1.9965, acc-0.4398\n",
      "Iter-30190, train loss-2.0587, acc-0.4800, valid loss-1.9956, acc-0.4506, test loss-1.9964, acc-0.4394\n",
      "Iter-30200, train loss-1.9936, acc-0.4400, valid loss-1.9955, acc-0.4508, test loss-1.9963, acc-0.4395\n",
      "Iter-30210, train loss-1.9837, acc-0.4600, valid loss-1.9954, acc-0.4510, test loss-1.9963, acc-0.4398\n",
      "Iter-30220, train loss-2.0676, acc-0.3000, valid loss-1.9953, acc-0.4516, test loss-1.9962, acc-0.4400\n",
      "Iter-30230, train loss-2.0152, acc-0.4600, valid loss-1.9953, acc-0.4510, test loss-1.9961, acc-0.4401\n",
      "Iter-30240, train loss-2.0283, acc-0.4000, valid loss-1.9952, acc-0.4512, test loss-1.9960, acc-0.4399\n",
      "Iter-30250, train loss-2.0101, acc-0.4400, valid loss-1.9951, acc-0.4516, test loss-1.9959, acc-0.4402\n",
      "Iter-30260, train loss-1.9376, acc-0.5400, valid loss-1.9950, acc-0.4516, test loss-1.9959, acc-0.4403\n",
      "Iter-30270, train loss-2.0501, acc-0.3600, valid loss-1.9949, acc-0.4516, test loss-1.9958, acc-0.4402\n",
      "Iter-30280, train loss-1.9440, acc-0.5400, valid loss-1.9949, acc-0.4514, test loss-1.9957, acc-0.4403\n",
      "Iter-30290, train loss-2.0069, acc-0.5000, valid loss-1.9948, acc-0.4510, test loss-1.9956, acc-0.4400\n",
      "Iter-30300, train loss-1.9464, acc-0.4200, valid loss-1.9947, acc-0.4510, test loss-1.9955, acc-0.4399\n",
      "Iter-30310, train loss-1.9660, acc-0.4000, valid loss-1.9946, acc-0.4512, test loss-1.9954, acc-0.4400\n",
      "Iter-30320, train loss-2.0700, acc-0.3600, valid loss-1.9945, acc-0.4510, test loss-1.9954, acc-0.4402\n",
      "Iter-30330, train loss-2.0587, acc-0.3400, valid loss-1.9945, acc-0.4514, test loss-1.9953, acc-0.4400\n",
      "Iter-30340, train loss-1.9980, acc-0.5800, valid loss-1.9944, acc-0.4514, test loss-1.9952, acc-0.4400\n",
      "Iter-30350, train loss-2.0555, acc-0.3800, valid loss-1.9943, acc-0.4514, test loss-1.9951, acc-0.4399\n",
      "Iter-30360, train loss-1.9906, acc-0.4200, valid loss-1.9942, acc-0.4512, test loss-1.9950, acc-0.4403\n",
      "Iter-30370, train loss-1.9270, acc-0.5800, valid loss-1.9941, acc-0.4512, test loss-1.9950, acc-0.4403\n",
      "Iter-30380, train loss-2.0230, acc-0.4200, valid loss-1.9940, acc-0.4512, test loss-1.9949, acc-0.4403\n",
      "Iter-30390, train loss-1.9767, acc-0.4600, valid loss-1.9940, acc-0.4512, test loss-1.9948, acc-0.4403\n",
      "Iter-30400, train loss-2.0251, acc-0.5000, valid loss-1.9939, acc-0.4514, test loss-1.9947, acc-0.4404\n",
      "Iter-30410, train loss-2.0792, acc-0.3200, valid loss-1.9938, acc-0.4512, test loss-1.9947, acc-0.4404\n",
      "Iter-30420, train loss-2.0127, acc-0.4800, valid loss-1.9937, acc-0.4512, test loss-1.9946, acc-0.4403\n",
      "Iter-30430, train loss-1.9513, acc-0.5200, valid loss-1.9937, acc-0.4512, test loss-1.9945, acc-0.4403\n",
      "Iter-30440, train loss-2.0570, acc-0.3600, valid loss-1.9936, acc-0.4512, test loss-1.9944, acc-0.4405\n",
      "Iter-30450, train loss-2.0061, acc-0.4600, valid loss-1.9935, acc-0.4516, test loss-1.9943, acc-0.4406\n",
      "Iter-30460, train loss-2.0072, acc-0.4800, valid loss-1.9934, acc-0.4512, test loss-1.9943, acc-0.4404\n",
      "Iter-30470, train loss-2.0045, acc-0.4800, valid loss-1.9933, acc-0.4514, test loss-1.9942, acc-0.4405\n",
      "Iter-30480, train loss-1.9988, acc-0.5800, valid loss-1.9933, acc-0.4514, test loss-1.9941, acc-0.4407\n",
      "Iter-30490, train loss-1.9800, acc-0.5000, valid loss-1.9932, acc-0.4518, test loss-1.9940, acc-0.4407\n",
      "Iter-30500, train loss-1.9496, acc-0.5000, valid loss-1.9931, acc-0.4518, test loss-1.9939, acc-0.4405\n",
      "Iter-30510, train loss-2.0476, acc-0.3400, valid loss-1.9930, acc-0.4516, test loss-1.9939, acc-0.4404\n",
      "Iter-30520, train loss-2.0105, acc-0.5400, valid loss-1.9929, acc-0.4518, test loss-1.9938, acc-0.4404\n",
      "Iter-30530, train loss-2.0106, acc-0.4200, valid loss-1.9929, acc-0.4516, test loss-1.9937, acc-0.4406\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-30540, train loss-2.0017, acc-0.4400, valid loss-1.9928, acc-0.4516, test loss-1.9936, acc-0.4405\n",
      "Iter-30550, train loss-2.0598, acc-0.3600, valid loss-1.9927, acc-0.4518, test loss-1.9936, acc-0.4405\n",
      "Iter-30560, train loss-1.9205, acc-0.4600, valid loss-1.9926, acc-0.4524, test loss-1.9935, acc-0.4405\n",
      "Iter-30570, train loss-2.0068, acc-0.3800, valid loss-1.9926, acc-0.4528, test loss-1.9934, acc-0.4407\n",
      "Iter-30580, train loss-1.9896, acc-0.4400, valid loss-1.9925, acc-0.4528, test loss-1.9933, acc-0.4406\n",
      "Iter-30590, train loss-2.0142, acc-0.4800, valid loss-1.9924, acc-0.4528, test loss-1.9932, acc-0.4408\n",
      "Iter-30600, train loss-2.0716, acc-0.3800, valid loss-1.9923, acc-0.4526, test loss-1.9932, acc-0.4406\n",
      "Iter-30610, train loss-2.0232, acc-0.4800, valid loss-1.9922, acc-0.4526, test loss-1.9931, acc-0.4405\n",
      "Iter-30620, train loss-1.9852, acc-0.4200, valid loss-1.9922, acc-0.4524, test loss-1.9930, acc-0.4409\n",
      "Iter-30630, train loss-2.0826, acc-0.3000, valid loss-1.9921, acc-0.4524, test loss-1.9929, acc-0.4411\n",
      "Iter-30640, train loss-2.0395, acc-0.4000, valid loss-1.9920, acc-0.4524, test loss-1.9928, acc-0.4409\n",
      "Iter-30650, train loss-1.9716, acc-0.4600, valid loss-1.9919, acc-0.4524, test loss-1.9928, acc-0.4409\n",
      "Iter-30660, train loss-2.0214, acc-0.3600, valid loss-1.9919, acc-0.4526, test loss-1.9927, acc-0.4410\n",
      "Iter-30670, train loss-2.0111, acc-0.3600, valid loss-1.9918, acc-0.4526, test loss-1.9926, acc-0.4411\n",
      "Iter-30680, train loss-1.9897, acc-0.4600, valid loss-1.9917, acc-0.4524, test loss-1.9925, acc-0.4411\n",
      "Iter-30690, train loss-2.0322, acc-0.4000, valid loss-1.9916, acc-0.4522, test loss-1.9924, acc-0.4410\n",
      "Iter-30700, train loss-1.9027, acc-0.5600, valid loss-1.9915, acc-0.4522, test loss-1.9924, acc-0.4412\n",
      "Iter-30710, train loss-1.9907, acc-0.4200, valid loss-1.9915, acc-0.4522, test loss-1.9923, acc-0.4415\n",
      "Iter-30720, train loss-2.0140, acc-0.4200, valid loss-1.9914, acc-0.4522, test loss-1.9922, acc-0.4413\n",
      "Iter-30730, train loss-1.9993, acc-0.3800, valid loss-1.9913, acc-0.4524, test loss-1.9921, acc-0.4413\n",
      "Iter-30740, train loss-2.0825, acc-0.3400, valid loss-1.9912, acc-0.4522, test loss-1.9920, acc-0.4413\n",
      "Iter-30750, train loss-2.0217, acc-0.3400, valid loss-1.9911, acc-0.4522, test loss-1.9919, acc-0.4411\n",
      "Iter-30760, train loss-1.9417, acc-0.5000, valid loss-1.9910, acc-0.4522, test loss-1.9919, acc-0.4410\n",
      "Iter-30770, train loss-2.0073, acc-0.4400, valid loss-1.9910, acc-0.4520, test loss-1.9918, acc-0.4413\n",
      "Iter-30780, train loss-1.9786, acc-0.5200, valid loss-1.9909, acc-0.4522, test loss-1.9917, acc-0.4415\n",
      "Iter-30790, train loss-2.0634, acc-0.3600, valid loss-1.9908, acc-0.4522, test loss-1.9916, acc-0.4412\n",
      "Iter-30800, train loss-2.0910, acc-0.3200, valid loss-1.9907, acc-0.4520, test loss-1.9916, acc-0.4415\n",
      "Iter-30810, train loss-1.9889, acc-0.5400, valid loss-1.9906, acc-0.4522, test loss-1.9915, acc-0.4415\n",
      "Iter-30820, train loss-1.9771, acc-0.4600, valid loss-1.9906, acc-0.4522, test loss-1.9914, acc-0.4415\n",
      "Iter-30830, train loss-1.9979, acc-0.4400, valid loss-1.9905, acc-0.4520, test loss-1.9913, acc-0.4416\n",
      "Iter-30840, train loss-1.9460, acc-0.5000, valid loss-1.9904, acc-0.4524, test loss-1.9912, acc-0.4418\n",
      "Iter-30850, train loss-1.9820, acc-0.4400, valid loss-1.9903, acc-0.4524, test loss-1.9912, acc-0.4416\n",
      "Iter-30860, train loss-1.9707, acc-0.5000, valid loss-1.9902, acc-0.4526, test loss-1.9911, acc-0.4416\n",
      "Iter-30870, train loss-2.0285, acc-0.4000, valid loss-1.9902, acc-0.4526, test loss-1.9910, acc-0.4416\n",
      "Iter-30880, train loss-2.0095, acc-0.3600, valid loss-1.9901, acc-0.4526, test loss-1.9909, acc-0.4416\n",
      "Iter-30890, train loss-1.9784, acc-0.4600, valid loss-1.9900, acc-0.4528, test loss-1.9908, acc-0.4418\n",
      "Iter-30900, train loss-2.0322, acc-0.4400, valid loss-1.9899, acc-0.4528, test loss-1.9908, acc-0.4419\n",
      "Iter-30910, train loss-1.9710, acc-0.4600, valid loss-1.9898, acc-0.4528, test loss-1.9907, acc-0.4419\n",
      "Iter-30920, train loss-2.0261, acc-0.5200, valid loss-1.9898, acc-0.4528, test loss-1.9906, acc-0.4420\n",
      "Iter-30930, train loss-2.0125, acc-0.4200, valid loss-1.9897, acc-0.4530, test loss-1.9905, acc-0.4420\n",
      "Iter-30940, train loss-1.9661, acc-0.5400, valid loss-1.9896, acc-0.4528, test loss-1.9905, acc-0.4419\n",
      "Iter-30950, train loss-1.9309, acc-0.4800, valid loss-1.9895, acc-0.4530, test loss-1.9904, acc-0.4421\n",
      "Iter-30960, train loss-1.9564, acc-0.4600, valid loss-1.9894, acc-0.4530, test loss-1.9903, acc-0.4422\n",
      "Iter-30970, train loss-2.0145, acc-0.4400, valid loss-1.9894, acc-0.4530, test loss-1.9902, acc-0.4421\n",
      "Iter-30980, train loss-1.9897, acc-0.4000, valid loss-1.9893, acc-0.4532, test loss-1.9901, acc-0.4421\n",
      "Iter-30990, train loss-2.0190, acc-0.4200, valid loss-1.9892, acc-0.4530, test loss-1.9901, acc-0.4420\n",
      "Iter-31000, train loss-2.0333, acc-0.4600, valid loss-1.9891, acc-0.4528, test loss-1.9900, acc-0.4422\n",
      "Iter-31010, train loss-1.9524, acc-0.5000, valid loss-1.9891, acc-0.4528, test loss-1.9899, acc-0.4423\n",
      "Iter-31020, train loss-1.9892, acc-0.4400, valid loss-1.9890, acc-0.4530, test loss-1.9898, acc-0.4423\n",
      "Iter-31030, train loss-1.9863, acc-0.4600, valid loss-1.9889, acc-0.4532, test loss-1.9897, acc-0.4423\n",
      "Iter-31040, train loss-1.9205, acc-0.5600, valid loss-1.9888, acc-0.4532, test loss-1.9897, acc-0.4422\n",
      "Iter-31050, train loss-1.9812, acc-0.4000, valid loss-1.9887, acc-0.4534, test loss-1.9896, acc-0.4424\n",
      "Iter-31060, train loss-2.0156, acc-0.4200, valid loss-1.9886, acc-0.4536, test loss-1.9895, acc-0.4425\n",
      "Iter-31070, train loss-1.9472, acc-0.4200, valid loss-1.9886, acc-0.4538, test loss-1.9894, acc-0.4424\n",
      "Iter-31080, train loss-1.9521, acc-0.5000, valid loss-1.9885, acc-0.4538, test loss-1.9893, acc-0.4425\n",
      "Iter-31090, train loss-1.9760, acc-0.5200, valid loss-1.9884, acc-0.4536, test loss-1.9893, acc-0.4425\n",
      "Iter-31100, train loss-2.0248, acc-0.4200, valid loss-1.9883, acc-0.4536, test loss-1.9892, acc-0.4424\n",
      "Iter-31110, train loss-1.9863, acc-0.4400, valid loss-1.9883, acc-0.4538, test loss-1.9891, acc-0.4425\n",
      "Iter-31120, train loss-1.9083, acc-0.6000, valid loss-1.9882, acc-0.4536, test loss-1.9890, acc-0.4423\n",
      "Iter-31130, train loss-2.0330, acc-0.4200, valid loss-1.9881, acc-0.4532, test loss-1.9890, acc-0.4425\n",
      "Iter-31140, train loss-1.9780, acc-0.5000, valid loss-1.9880, acc-0.4530, test loss-1.9889, acc-0.4422\n",
      "Iter-31150, train loss-2.0057, acc-0.4600, valid loss-1.9879, acc-0.4536, test loss-1.9888, acc-0.4426\n",
      "Iter-31160, train loss-1.9949, acc-0.4600, valid loss-1.9879, acc-0.4536, test loss-1.9887, acc-0.4427\n",
      "Iter-31170, train loss-2.0484, acc-0.4400, valid loss-1.9878, acc-0.4530, test loss-1.9886, acc-0.4424\n",
      "Iter-31180, train loss-1.9645, acc-0.5200, valid loss-1.9877, acc-0.4530, test loss-1.9886, acc-0.4427\n",
      "Iter-31190, train loss-2.0055, acc-0.4200, valid loss-1.9876, acc-0.4528, test loss-1.9885, acc-0.4428\n",
      "Iter-31200, train loss-1.9396, acc-0.5000, valid loss-1.9875, acc-0.4528, test loss-1.9884, acc-0.4427\n",
      "Iter-31210, train loss-2.0805, acc-0.2600, valid loss-1.9875, acc-0.4534, test loss-1.9883, acc-0.4427\n",
      "Iter-31220, train loss-1.9834, acc-0.5000, valid loss-1.9874, acc-0.4534, test loss-1.9882, acc-0.4426\n",
      "Iter-31230, train loss-1.9971, acc-0.5000, valid loss-1.9873, acc-0.4534, test loss-1.9882, acc-0.4424\n",
      "Iter-31240, train loss-2.0061, acc-0.4200, valid loss-1.9872, acc-0.4534, test loss-1.9881, acc-0.4424\n",
      "Iter-31250, train loss-2.0067, acc-0.4800, valid loss-1.9872, acc-0.4536, test loss-1.9880, acc-0.4426\n",
      "Iter-31260, train loss-2.0610, acc-0.2800, valid loss-1.9871, acc-0.4534, test loss-1.9879, acc-0.4426\n",
      "Iter-31270, train loss-2.0127, acc-0.4200, valid loss-1.9870, acc-0.4534, test loss-1.9879, acc-0.4430\n",
      "Iter-31280, train loss-2.0337, acc-0.3400, valid loss-1.9869, acc-0.4540, test loss-1.9878, acc-0.4430\n",
      "Iter-31290, train loss-2.0029, acc-0.3600, valid loss-1.9868, acc-0.4538, test loss-1.9877, acc-0.4431\n",
      "Iter-31300, train loss-1.9519, acc-0.5200, valid loss-1.9868, acc-0.4540, test loss-1.9876, acc-0.4430\n",
      "Iter-31310, train loss-1.9690, acc-0.5200, valid loss-1.9867, acc-0.4538, test loss-1.9875, acc-0.4429\n",
      "Iter-31320, train loss-2.0691, acc-0.3600, valid loss-1.9866, acc-0.4540, test loss-1.9875, acc-0.4432\n",
      "Iter-31330, train loss-2.0170, acc-0.4000, valid loss-1.9865, acc-0.4540, test loss-1.9874, acc-0.4432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-31340, train loss-2.0213, acc-0.3400, valid loss-1.9864, acc-0.4540, test loss-1.9873, acc-0.4434\n",
      "Iter-31350, train loss-2.0000, acc-0.4200, valid loss-1.9864, acc-0.4540, test loss-1.9872, acc-0.4431\n",
      "Iter-31360, train loss-2.0441, acc-0.4800, valid loss-1.9863, acc-0.4542, test loss-1.9872, acc-0.4434\n",
      "Iter-31370, train loss-1.9665, acc-0.5600, valid loss-1.9862, acc-0.4542, test loss-1.9871, acc-0.4433\n",
      "Iter-31380, train loss-1.9987, acc-0.3400, valid loss-1.9861, acc-0.4544, test loss-1.9870, acc-0.4433\n",
      "Iter-31390, train loss-2.0167, acc-0.3200, valid loss-1.9861, acc-0.4544, test loss-1.9869, acc-0.4434\n",
      "Iter-31400, train loss-1.9928, acc-0.4200, valid loss-1.9860, acc-0.4548, test loss-1.9868, acc-0.4435\n",
      "Iter-31410, train loss-1.9883, acc-0.4200, valid loss-1.9859, acc-0.4548, test loss-1.9868, acc-0.4436\n",
      "Iter-31420, train loss-2.0357, acc-0.4400, valid loss-1.9858, acc-0.4544, test loss-1.9867, acc-0.4436\n",
      "Iter-31430, train loss-2.0256, acc-0.3800, valid loss-1.9857, acc-0.4544, test loss-1.9866, acc-0.4436\n",
      "Iter-31440, train loss-1.9548, acc-0.5400, valid loss-1.9857, acc-0.4542, test loss-1.9865, acc-0.4434\n",
      "Iter-31450, train loss-1.9805, acc-0.4400, valid loss-1.9856, acc-0.4544, test loss-1.9865, acc-0.4434\n",
      "Iter-31460, train loss-1.9226, acc-0.5000, valid loss-1.9855, acc-0.4544, test loss-1.9864, acc-0.4433\n",
      "Iter-31470, train loss-1.9764, acc-0.4600, valid loss-1.9854, acc-0.4542, test loss-1.9863, acc-0.4435\n",
      "Iter-31480, train loss-2.0025, acc-0.4600, valid loss-1.9853, acc-0.4546, test loss-1.9862, acc-0.4435\n",
      "Iter-31490, train loss-1.9334, acc-0.5800, valid loss-1.9853, acc-0.4542, test loss-1.9861, acc-0.4439\n",
      "Iter-31500, train loss-2.0005, acc-0.4000, valid loss-1.9852, acc-0.4542, test loss-1.9861, acc-0.4434\n",
      "Iter-31510, train loss-1.9835, acc-0.4600, valid loss-1.9851, acc-0.4538, test loss-1.9860, acc-0.4436\n",
      "Iter-31520, train loss-1.9650, acc-0.4800, valid loss-1.9850, acc-0.4538, test loss-1.9859, acc-0.4439\n",
      "Iter-31530, train loss-2.0520, acc-0.3200, valid loss-1.9849, acc-0.4536, test loss-1.9858, acc-0.4438\n",
      "Iter-31540, train loss-2.0072, acc-0.4400, valid loss-1.9849, acc-0.4536, test loss-1.9857, acc-0.4438\n",
      "Iter-31550, train loss-1.9571, acc-0.4200, valid loss-1.9848, acc-0.4536, test loss-1.9857, acc-0.4437\n",
      "Iter-31560, train loss-2.0199, acc-0.4600, valid loss-1.9847, acc-0.4534, test loss-1.9856, acc-0.4435\n",
      "Iter-31570, train loss-2.0123, acc-0.4200, valid loss-1.9846, acc-0.4538, test loss-1.9855, acc-0.4438\n",
      "Iter-31580, train loss-2.0557, acc-0.3000, valid loss-1.9846, acc-0.4538, test loss-1.9854, acc-0.4439\n",
      "Iter-31590, train loss-2.0107, acc-0.4200, valid loss-1.9845, acc-0.4540, test loss-1.9854, acc-0.4441\n",
      "Iter-31600, train loss-1.8820, acc-0.6200, valid loss-1.9844, acc-0.4538, test loss-1.9853, acc-0.4440\n",
      "Iter-31610, train loss-1.9471, acc-0.4600, valid loss-1.9843, acc-0.4540, test loss-1.9852, acc-0.4445\n",
      "Iter-31620, train loss-1.9400, acc-0.4400, valid loss-1.9842, acc-0.4538, test loss-1.9851, acc-0.4441\n",
      "Iter-31630, train loss-2.0295, acc-0.4800, valid loss-1.9842, acc-0.4538, test loss-1.9850, acc-0.4442\n",
      "Iter-31640, train loss-2.0523, acc-0.3800, valid loss-1.9841, acc-0.4540, test loss-1.9850, acc-0.4442\n",
      "Iter-31650, train loss-2.0454, acc-0.4800, valid loss-1.9840, acc-0.4540, test loss-1.9849, acc-0.4443\n",
      "Iter-31660, train loss-1.9328, acc-0.4600, valid loss-1.9839, acc-0.4542, test loss-1.9848, acc-0.4446\n",
      "Iter-31670, train loss-1.9460, acc-0.4000, valid loss-1.9839, acc-0.4542, test loss-1.9847, acc-0.4446\n",
      "Iter-31680, train loss-2.0031, acc-0.4400, valid loss-1.9838, acc-0.4542, test loss-1.9847, acc-0.4446\n",
      "Iter-31690, train loss-1.9552, acc-0.4600, valid loss-1.9837, acc-0.4546, test loss-1.9846, acc-0.4446\n",
      "Iter-31700, train loss-2.0075, acc-0.4800, valid loss-1.9836, acc-0.4544, test loss-1.9845, acc-0.4447\n",
      "Iter-31710, train loss-1.9476, acc-0.4800, valid loss-1.9835, acc-0.4546, test loss-1.9844, acc-0.4448\n",
      "Iter-31720, train loss-1.9943, acc-0.4200, valid loss-1.9835, acc-0.4544, test loss-1.9843, acc-0.4450\n",
      "Iter-31730, train loss-1.8922, acc-0.5200, valid loss-1.9834, acc-0.4542, test loss-1.9843, acc-0.4445\n",
      "Iter-31740, train loss-1.9687, acc-0.4600, valid loss-1.9833, acc-0.4542, test loss-1.9842, acc-0.4448\n",
      "Iter-31750, train loss-2.0176, acc-0.4400, valid loss-1.9832, acc-0.4544, test loss-1.9841, acc-0.4448\n",
      "Iter-31760, train loss-2.0192, acc-0.4000, valid loss-1.9831, acc-0.4538, test loss-1.9840, acc-0.4448\n",
      "Iter-31770, train loss-2.0285, acc-0.4000, valid loss-1.9831, acc-0.4540, test loss-1.9840, acc-0.4447\n",
      "Iter-31780, train loss-1.9264, acc-0.5000, valid loss-1.9830, acc-0.4540, test loss-1.9839, acc-0.4446\n",
      "Iter-31790, train loss-1.9924, acc-0.4400, valid loss-1.9829, acc-0.4540, test loss-1.9838, acc-0.4447\n",
      "Iter-31800, train loss-2.0693, acc-0.3000, valid loss-1.9828, acc-0.4542, test loss-1.9837, acc-0.4447\n",
      "Iter-31810, train loss-1.9967, acc-0.4400, valid loss-1.9828, acc-0.4542, test loss-1.9836, acc-0.4446\n",
      "Iter-31820, train loss-1.9838, acc-0.4000, valid loss-1.9827, acc-0.4540, test loss-1.9836, acc-0.4447\n",
      "Iter-31830, train loss-1.9420, acc-0.4400, valid loss-1.9826, acc-0.4542, test loss-1.9835, acc-0.4445\n",
      "Iter-31840, train loss-1.9974, acc-0.5200, valid loss-1.9825, acc-0.4542, test loss-1.9834, acc-0.4447\n",
      "Iter-31850, train loss-1.9510, acc-0.5200, valid loss-1.9824, acc-0.4540, test loss-1.9833, acc-0.4448\n",
      "Iter-31860, train loss-1.8978, acc-0.5600, valid loss-1.9824, acc-0.4540, test loss-1.9833, acc-0.4448\n",
      "Iter-31870, train loss-2.0182, acc-0.4200, valid loss-1.9823, acc-0.4542, test loss-1.9832, acc-0.4447\n",
      "Iter-31880, train loss-1.9178, acc-0.4000, valid loss-1.9822, acc-0.4542, test loss-1.9831, acc-0.4447\n",
      "Iter-31890, train loss-1.9907, acc-0.5400, valid loss-1.9821, acc-0.4538, test loss-1.9830, acc-0.4449\n",
      "Iter-31900, train loss-1.8957, acc-0.5800, valid loss-1.9820, acc-0.4540, test loss-1.9829, acc-0.4448\n",
      "Iter-31910, train loss-1.9970, acc-0.4200, valid loss-1.9820, acc-0.4544, test loss-1.9829, acc-0.4448\n",
      "Iter-31920, train loss-2.0006, acc-0.4400, valid loss-1.9819, acc-0.4544, test loss-1.9828, acc-0.4450\n",
      "Iter-31930, train loss-2.0646, acc-0.3200, valid loss-1.9818, acc-0.4544, test loss-1.9827, acc-0.4450\n",
      "Iter-31940, train loss-2.0140, acc-0.3600, valid loss-1.9817, acc-0.4544, test loss-1.9826, acc-0.4449\n",
      "Iter-31950, train loss-1.9660, acc-0.4200, valid loss-1.9817, acc-0.4542, test loss-1.9826, acc-0.4448\n",
      "Iter-31960, train loss-1.9419, acc-0.5600, valid loss-1.9816, acc-0.4542, test loss-1.9825, acc-0.4448\n",
      "Iter-31970, train loss-1.9790, acc-0.5000, valid loss-1.9815, acc-0.4542, test loss-1.9824, acc-0.4448\n",
      "Iter-31980, train loss-2.0351, acc-0.3800, valid loss-1.9814, acc-0.4540, test loss-1.9823, acc-0.4448\n",
      "Iter-31990, train loss-2.0003, acc-0.4200, valid loss-1.9813, acc-0.4538, test loss-1.9822, acc-0.4446\n",
      "Iter-32000, train loss-1.9287, acc-0.5400, valid loss-1.9813, acc-0.4538, test loss-1.9822, acc-0.4448\n",
      "Iter-32010, train loss-1.9383, acc-0.5200, valid loss-1.9812, acc-0.4538, test loss-1.9821, acc-0.4448\n",
      "Iter-32020, train loss-1.9590, acc-0.4400, valid loss-1.9811, acc-0.4538, test loss-1.9820, acc-0.4448\n",
      "Iter-32030, train loss-2.0215, acc-0.4000, valid loss-1.9810, acc-0.4540, test loss-1.9819, acc-0.4445\n",
      "Iter-32040, train loss-1.9943, acc-0.5200, valid loss-1.9809, acc-0.4538, test loss-1.9819, acc-0.4445\n",
      "Iter-32050, train loss-2.0681, acc-0.3400, valid loss-1.9809, acc-0.4538, test loss-1.9818, acc-0.4448\n",
      "Iter-32060, train loss-1.9616, acc-0.4800, valid loss-1.9808, acc-0.4540, test loss-1.9817, acc-0.4446\n",
      "Iter-32070, train loss-1.9679, acc-0.4600, valid loss-1.9807, acc-0.4540, test loss-1.9816, acc-0.4446\n",
      "Iter-32080, train loss-2.0153, acc-0.3800, valid loss-1.9806, acc-0.4540, test loss-1.9815, acc-0.4446\n",
      "Iter-32090, train loss-1.9508, acc-0.5200, valid loss-1.9806, acc-0.4542, test loss-1.9815, acc-0.4446\n",
      "Iter-32100, train loss-2.0407, acc-0.3600, valid loss-1.9805, acc-0.4540, test loss-1.9814, acc-0.4446\n",
      "Iter-32110, train loss-2.0221, acc-0.3600, valid loss-1.9804, acc-0.4542, test loss-1.9813, acc-0.4448\n",
      "Iter-32120, train loss-1.9284, acc-0.5400, valid loss-1.9803, acc-0.4536, test loss-1.9812, acc-0.4444\n",
      "Iter-32130, train loss-1.9212, acc-0.5400, valid loss-1.9803, acc-0.4536, test loss-1.9812, acc-0.4445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32140, train loss-1.9730, acc-0.4800, valid loss-1.9802, acc-0.4536, test loss-1.9811, acc-0.4446\n",
      "Iter-32150, train loss-1.9794, acc-0.5000, valid loss-1.9801, acc-0.4536, test loss-1.9810, acc-0.4446\n",
      "Iter-32160, train loss-1.9894, acc-0.4200, valid loss-1.9800, acc-0.4538, test loss-1.9809, acc-0.4448\n",
      "Iter-32170, train loss-1.9442, acc-0.5600, valid loss-1.9799, acc-0.4536, test loss-1.9808, acc-0.4449\n",
      "Iter-32180, train loss-1.9931, acc-0.4200, valid loss-1.9799, acc-0.4536, test loss-1.9808, acc-0.4448\n",
      "Iter-32190, train loss-2.0211, acc-0.3600, valid loss-1.9798, acc-0.4538, test loss-1.9807, acc-0.4452\n",
      "Iter-32200, train loss-1.9360, acc-0.5400, valid loss-1.9797, acc-0.4542, test loss-1.9806, acc-0.4450\n",
      "Iter-32210, train loss-1.9515, acc-0.4200, valid loss-1.9796, acc-0.4540, test loss-1.9805, acc-0.4450\n",
      "Iter-32220, train loss-1.9897, acc-0.3800, valid loss-1.9795, acc-0.4544, test loss-1.9804, acc-0.4452\n",
      "Iter-32230, train loss-1.9899, acc-0.5000, valid loss-1.9795, acc-0.4544, test loss-1.9804, acc-0.4452\n",
      "Iter-32240, train loss-2.0490, acc-0.3600, valid loss-1.9794, acc-0.4544, test loss-1.9803, acc-0.4452\n",
      "Iter-32250, train loss-1.9375, acc-0.5000, valid loss-1.9793, acc-0.4544, test loss-1.9802, acc-0.4453\n",
      "Iter-32260, train loss-1.9764, acc-0.4200, valid loss-1.9792, acc-0.4542, test loss-1.9801, acc-0.4453\n",
      "Iter-32270, train loss-2.0477, acc-0.3800, valid loss-1.9792, acc-0.4546, test loss-1.9801, acc-0.4455\n",
      "Iter-32280, train loss-2.0211, acc-0.3800, valid loss-1.9791, acc-0.4548, test loss-1.9800, acc-0.4456\n",
      "Iter-32290, train loss-1.9893, acc-0.4400, valid loss-1.9790, acc-0.4548, test loss-1.9799, acc-0.4454\n",
      "Iter-32300, train loss-2.0443, acc-0.3600, valid loss-1.9789, acc-0.4554, test loss-1.9798, acc-0.4455\n",
      "Iter-32310, train loss-2.0177, acc-0.4400, valid loss-1.9789, acc-0.4556, test loss-1.9798, acc-0.4454\n",
      "Iter-32320, train loss-1.9907, acc-0.4400, valid loss-1.9788, acc-0.4554, test loss-1.9797, acc-0.4457\n",
      "Iter-32330, train loss-1.9678, acc-0.5000, valid loss-1.9787, acc-0.4554, test loss-1.9796, acc-0.4455\n",
      "Iter-32340, train loss-1.9741, acc-0.3400, valid loss-1.9786, acc-0.4552, test loss-1.9795, acc-0.4456\n",
      "Iter-32350, train loss-2.0160, acc-0.4000, valid loss-1.9785, acc-0.4554, test loss-1.9794, acc-0.4456\n",
      "Iter-32360, train loss-1.9762, acc-0.4200, valid loss-1.9785, acc-0.4552, test loss-1.9794, acc-0.4454\n",
      "Iter-32370, train loss-1.9488, acc-0.4400, valid loss-1.9784, acc-0.4554, test loss-1.9793, acc-0.4456\n",
      "Iter-32380, train loss-1.9871, acc-0.4600, valid loss-1.9783, acc-0.4548, test loss-1.9792, acc-0.4457\n",
      "Iter-32390, train loss-2.0271, acc-0.3400, valid loss-1.9782, acc-0.4550, test loss-1.9791, acc-0.4455\n",
      "Iter-32400, train loss-1.9129, acc-0.4800, valid loss-1.9782, acc-0.4550, test loss-1.9791, acc-0.4455\n",
      "Iter-32410, train loss-1.9713, acc-0.5000, valid loss-1.9781, acc-0.4554, test loss-1.9790, acc-0.4457\n",
      "Iter-32420, train loss-1.9775, acc-0.4600, valid loss-1.9780, acc-0.4556, test loss-1.9789, acc-0.4456\n",
      "Iter-32430, train loss-1.9856, acc-0.4600, valid loss-1.9779, acc-0.4556, test loss-1.9788, acc-0.4458\n",
      "Iter-32440, train loss-2.0017, acc-0.4400, valid loss-1.9778, acc-0.4556, test loss-1.9787, acc-0.4461\n",
      "Iter-32450, train loss-1.9077, acc-0.5200, valid loss-1.9778, acc-0.4558, test loss-1.9787, acc-0.4461\n",
      "Iter-32460, train loss-2.0262, acc-0.4600, valid loss-1.9777, acc-0.4562, test loss-1.9786, acc-0.4462\n",
      "Iter-32470, train loss-2.0351, acc-0.3400, valid loss-1.9776, acc-0.4564, test loss-1.9785, acc-0.4461\n",
      "Iter-32480, train loss-1.9805, acc-0.5200, valid loss-1.9775, acc-0.4564, test loss-1.9784, acc-0.4460\n",
      "Iter-32490, train loss-1.9983, acc-0.4600, valid loss-1.9775, acc-0.4560, test loss-1.9784, acc-0.4462\n",
      "Iter-32500, train loss-2.1083, acc-0.3200, valid loss-1.9774, acc-0.4558, test loss-1.9783, acc-0.4462\n",
      "Iter-32510, train loss-2.0389, acc-0.4600, valid loss-1.9773, acc-0.4562, test loss-1.9782, acc-0.4460\n",
      "Iter-32520, train loss-2.0268, acc-0.2400, valid loss-1.9772, acc-0.4562, test loss-1.9781, acc-0.4460\n",
      "Iter-32530, train loss-1.9210, acc-0.4600, valid loss-1.9772, acc-0.4562, test loss-1.9781, acc-0.4459\n",
      "Iter-32540, train loss-2.0703, acc-0.3600, valid loss-1.9771, acc-0.4564, test loss-1.9780, acc-0.4460\n",
      "Iter-32550, train loss-1.9614, acc-0.4200, valid loss-1.9770, acc-0.4562, test loss-1.9779, acc-0.4461\n",
      "Iter-32560, train loss-1.9661, acc-0.4600, valid loss-1.9769, acc-0.4560, test loss-1.9778, acc-0.4464\n",
      "Iter-32570, train loss-2.0110, acc-0.4000, valid loss-1.9768, acc-0.4562, test loss-1.9777, acc-0.4461\n",
      "Iter-32580, train loss-1.9839, acc-0.4200, valid loss-1.9768, acc-0.4562, test loss-1.9777, acc-0.4462\n",
      "Iter-32590, train loss-2.0147, acc-0.4400, valid loss-1.9767, acc-0.4566, test loss-1.9776, acc-0.4462\n",
      "Iter-32600, train loss-1.9709, acc-0.5200, valid loss-1.9766, acc-0.4566, test loss-1.9775, acc-0.4462\n",
      "Iter-32610, train loss-1.9639, acc-0.5200, valid loss-1.9765, acc-0.4566, test loss-1.9774, acc-0.4463\n",
      "Iter-32620, train loss-2.0517, acc-0.3200, valid loss-1.9765, acc-0.4566, test loss-1.9774, acc-0.4464\n",
      "Iter-32630, train loss-2.0353, acc-0.3800, valid loss-1.9764, acc-0.4566, test loss-1.9773, acc-0.4464\n",
      "Iter-32640, train loss-2.0601, acc-0.3200, valid loss-1.9763, acc-0.4566, test loss-1.9772, acc-0.4462\n",
      "Iter-32650, train loss-1.9727, acc-0.4200, valid loss-1.9762, acc-0.4564, test loss-1.9771, acc-0.4463\n",
      "Iter-32660, train loss-1.9618, acc-0.4400, valid loss-1.9762, acc-0.4570, test loss-1.9771, acc-0.4463\n",
      "Iter-32670, train loss-2.0466, acc-0.3000, valid loss-1.9761, acc-0.4572, test loss-1.9770, acc-0.4464\n",
      "Iter-32680, train loss-1.9930, acc-0.4000, valid loss-1.9760, acc-0.4570, test loss-1.9769, acc-0.4465\n",
      "Iter-32690, train loss-2.0156, acc-0.3400, valid loss-1.9759, acc-0.4570, test loss-1.9768, acc-0.4464\n",
      "Iter-32700, train loss-2.0004, acc-0.3600, valid loss-1.9758, acc-0.4572, test loss-1.9767, acc-0.4465\n",
      "Iter-32710, train loss-2.0764, acc-0.3200, valid loss-1.9758, acc-0.4572, test loss-1.9767, acc-0.4464\n",
      "Iter-32720, train loss-2.0448, acc-0.3600, valid loss-1.9757, acc-0.4572, test loss-1.9766, acc-0.4465\n",
      "Iter-32730, train loss-1.9536, acc-0.5800, valid loss-1.9756, acc-0.4570, test loss-1.9765, acc-0.4464\n",
      "Iter-32740, train loss-1.9629, acc-0.3600, valid loss-1.9755, acc-0.4570, test loss-1.9765, acc-0.4466\n",
      "Iter-32750, train loss-1.9599, acc-0.5000, valid loss-1.9755, acc-0.4570, test loss-1.9764, acc-0.4466\n",
      "Iter-32760, train loss-1.9600, acc-0.5400, valid loss-1.9754, acc-0.4570, test loss-1.9763, acc-0.4466\n",
      "Iter-32770, train loss-2.0049, acc-0.3400, valid loss-1.9753, acc-0.4574, test loss-1.9762, acc-0.4470\n",
      "Iter-32780, train loss-1.8499, acc-0.6200, valid loss-1.9752, acc-0.4572, test loss-1.9762, acc-0.4467\n",
      "Iter-32790, train loss-2.0080, acc-0.4000, valid loss-1.9752, acc-0.4574, test loss-1.9761, acc-0.4466\n",
      "Iter-32800, train loss-2.0810, acc-0.3200, valid loss-1.9751, acc-0.4574, test loss-1.9760, acc-0.4467\n",
      "Iter-32810, train loss-1.9721, acc-0.4800, valid loss-1.9750, acc-0.4574, test loss-1.9759, acc-0.4467\n",
      "Iter-32820, train loss-2.0369, acc-0.4000, valid loss-1.9749, acc-0.4574, test loss-1.9758, acc-0.4467\n",
      "Iter-32830, train loss-2.0029, acc-0.3200, valid loss-1.9749, acc-0.4574, test loss-1.9758, acc-0.4467\n",
      "Iter-32840, train loss-1.9208, acc-0.5000, valid loss-1.9748, acc-0.4568, test loss-1.9757, acc-0.4468\n",
      "Iter-32850, train loss-1.9950, acc-0.4000, valid loss-1.9747, acc-0.4568, test loss-1.9756, acc-0.4467\n",
      "Iter-32860, train loss-2.0007, acc-0.4400, valid loss-1.9746, acc-0.4568, test loss-1.9755, acc-0.4467\n",
      "Iter-32870, train loss-2.0143, acc-0.4800, valid loss-1.9746, acc-0.4568, test loss-1.9755, acc-0.4468\n",
      "Iter-32880, train loss-2.0205, acc-0.4200, valid loss-1.9745, acc-0.4574, test loss-1.9754, acc-0.4470\n",
      "Iter-32890, train loss-1.9239, acc-0.5600, valid loss-1.9744, acc-0.4574, test loss-1.9753, acc-0.4470\n",
      "Iter-32900, train loss-1.8826, acc-0.5600, valid loss-1.9743, acc-0.4574, test loss-1.9753, acc-0.4471\n",
      "Iter-32910, train loss-2.0218, acc-0.4000, valid loss-1.9743, acc-0.4574, test loss-1.9752, acc-0.4469\n",
      "Iter-32920, train loss-1.9866, acc-0.4800, valid loss-1.9742, acc-0.4574, test loss-1.9751, acc-0.4469\n",
      "Iter-32930, train loss-2.0120, acc-0.4400, valid loss-1.9741, acc-0.4574, test loss-1.9750, acc-0.4469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-32940, train loss-2.0230, acc-0.4400, valid loss-1.9740, acc-0.4572, test loss-1.9749, acc-0.4468\n",
      "Iter-32950, train loss-1.9740, acc-0.4600, valid loss-1.9739, acc-0.4572, test loss-1.9749, acc-0.4469\n",
      "Iter-32960, train loss-2.0191, acc-0.4600, valid loss-1.9739, acc-0.4572, test loss-1.9748, acc-0.4468\n",
      "Iter-32970, train loss-1.8528, acc-0.6200, valid loss-1.9738, acc-0.4574, test loss-1.9747, acc-0.4468\n",
      "Iter-32980, train loss-2.0536, acc-0.3400, valid loss-1.9737, acc-0.4574, test loss-1.9746, acc-0.4469\n",
      "Iter-32990, train loss-2.0183, acc-0.3400, valid loss-1.9736, acc-0.4578, test loss-1.9746, acc-0.4468\n",
      "Iter-33000, train loss-2.0199, acc-0.3800, valid loss-1.9736, acc-0.4576, test loss-1.9745, acc-0.4468\n",
      "Iter-33010, train loss-1.9729, acc-0.5200, valid loss-1.9735, acc-0.4580, test loss-1.9744, acc-0.4468\n",
      "Iter-33020, train loss-1.9442, acc-0.5200, valid loss-1.9734, acc-0.4578, test loss-1.9743, acc-0.4470\n",
      "Iter-33030, train loss-1.9530, acc-0.5200, valid loss-1.9733, acc-0.4578, test loss-1.9743, acc-0.4470\n",
      "Iter-33040, train loss-1.9938, acc-0.4600, valid loss-1.9733, acc-0.4578, test loss-1.9742, acc-0.4470\n",
      "Iter-33050, train loss-1.9890, acc-0.4200, valid loss-1.9732, acc-0.4578, test loss-1.9741, acc-0.4469\n",
      "Iter-33060, train loss-2.0536, acc-0.3200, valid loss-1.9731, acc-0.4574, test loss-1.9740, acc-0.4470\n",
      "Iter-33070, train loss-2.0217, acc-0.3800, valid loss-1.9730, acc-0.4574, test loss-1.9740, acc-0.4469\n",
      "Iter-33080, train loss-1.9329, acc-0.4800, valid loss-1.9730, acc-0.4578, test loss-1.9739, acc-0.4469\n",
      "Iter-33090, train loss-1.9909, acc-0.4200, valid loss-1.9729, acc-0.4574, test loss-1.9738, acc-0.4469\n",
      "Iter-33100, train loss-1.9810, acc-0.4000, valid loss-1.9728, acc-0.4578, test loss-1.9737, acc-0.4471\n",
      "Iter-33110, train loss-1.9141, acc-0.5200, valid loss-1.9727, acc-0.4574, test loss-1.9736, acc-0.4470\n",
      "Iter-33120, train loss-2.0018, acc-0.3800, valid loss-1.9727, acc-0.4576, test loss-1.9736, acc-0.4471\n",
      "Iter-33130, train loss-1.9353, acc-0.4800, valid loss-1.9726, acc-0.4578, test loss-1.9735, acc-0.4472\n",
      "Iter-33140, train loss-2.0101, acc-0.3200, valid loss-1.9725, acc-0.4576, test loss-1.9734, acc-0.4470\n",
      "Iter-33150, train loss-1.9510, acc-0.4800, valid loss-1.9724, acc-0.4574, test loss-1.9733, acc-0.4471\n",
      "Iter-33160, train loss-2.0359, acc-0.4400, valid loss-1.9724, acc-0.4574, test loss-1.9733, acc-0.4472\n",
      "Iter-33170, train loss-2.0115, acc-0.4400, valid loss-1.9723, acc-0.4572, test loss-1.9732, acc-0.4472\n",
      "Iter-33180, train loss-1.9599, acc-0.5000, valid loss-1.9722, acc-0.4576, test loss-1.9731, acc-0.4473\n",
      "Iter-33190, train loss-1.9932, acc-0.4000, valid loss-1.9721, acc-0.4578, test loss-1.9730, acc-0.4474\n",
      "Iter-33200, train loss-2.0094, acc-0.4200, valid loss-1.9720, acc-0.4574, test loss-1.9730, acc-0.4472\n",
      "Iter-33210, train loss-1.9647, acc-0.5000, valid loss-1.9720, acc-0.4574, test loss-1.9729, acc-0.4471\n",
      "Iter-33220, train loss-2.0360, acc-0.4400, valid loss-1.9719, acc-0.4576, test loss-1.9728, acc-0.4472\n",
      "Iter-33230, train loss-2.0868, acc-0.3200, valid loss-1.9718, acc-0.4576, test loss-1.9727, acc-0.4471\n",
      "Iter-33240, train loss-2.0029, acc-0.4200, valid loss-1.9717, acc-0.4578, test loss-1.9727, acc-0.4472\n",
      "Iter-33250, train loss-2.0953, acc-0.2600, valid loss-1.9717, acc-0.4576, test loss-1.9726, acc-0.4473\n",
      "Iter-33260, train loss-2.0090, acc-0.4000, valid loss-1.9716, acc-0.4576, test loss-1.9725, acc-0.4473\n",
      "Iter-33270, train loss-1.9568, acc-0.4800, valid loss-1.9715, acc-0.4576, test loss-1.9724, acc-0.4473\n",
      "Iter-33280, train loss-2.0655, acc-0.3400, valid loss-1.9714, acc-0.4576, test loss-1.9724, acc-0.4471\n",
      "Iter-33290, train loss-2.0112, acc-0.3400, valid loss-1.9714, acc-0.4576, test loss-1.9723, acc-0.4472\n",
      "Iter-33300, train loss-1.9884, acc-0.4400, valid loss-1.9713, acc-0.4574, test loss-1.9722, acc-0.4473\n",
      "Iter-33310, train loss-1.9462, acc-0.5200, valid loss-1.9712, acc-0.4578, test loss-1.9721, acc-0.4474\n",
      "Iter-33320, train loss-1.8967, acc-0.4800, valid loss-1.9711, acc-0.4572, test loss-1.9720, acc-0.4473\n",
      "Iter-33330, train loss-2.0447, acc-0.3200, valid loss-1.9711, acc-0.4574, test loss-1.9720, acc-0.4472\n",
      "Iter-33340, train loss-2.0204, acc-0.3600, valid loss-1.9710, acc-0.4576, test loss-1.9719, acc-0.4472\n",
      "Iter-33350, train loss-1.9886, acc-0.4800, valid loss-1.9709, acc-0.4576, test loss-1.9718, acc-0.4470\n",
      "Iter-33360, train loss-2.0045, acc-0.4600, valid loss-1.9708, acc-0.4576, test loss-1.9717, acc-0.4471\n",
      "Iter-33370, train loss-1.9555, acc-0.5200, valid loss-1.9708, acc-0.4576, test loss-1.9717, acc-0.4471\n",
      "Iter-33380, train loss-1.9191, acc-0.5800, valid loss-1.9707, acc-0.4580, test loss-1.9716, acc-0.4472\n",
      "Iter-33390, train loss-1.9940, acc-0.4400, valid loss-1.9706, acc-0.4580, test loss-1.9715, acc-0.4472\n",
      "Iter-33400, train loss-2.0064, acc-0.3600, valid loss-1.9705, acc-0.4578, test loss-1.9714, acc-0.4472\n",
      "Iter-33410, train loss-1.9553, acc-0.5200, valid loss-1.9704, acc-0.4576, test loss-1.9714, acc-0.4471\n",
      "Iter-33420, train loss-1.9952, acc-0.3800, valid loss-1.9704, acc-0.4578, test loss-1.9713, acc-0.4473\n",
      "Iter-33430, train loss-2.0291, acc-0.4000, valid loss-1.9703, acc-0.4576, test loss-1.9712, acc-0.4473\n",
      "Iter-33440, train loss-1.9250, acc-0.4000, valid loss-1.9702, acc-0.4578, test loss-1.9711, acc-0.4472\n",
      "Iter-33450, train loss-1.9408, acc-0.4800, valid loss-1.9701, acc-0.4576, test loss-1.9711, acc-0.4474\n",
      "Iter-33460, train loss-2.0568, acc-0.4000, valid loss-1.9701, acc-0.4578, test loss-1.9710, acc-0.4473\n",
      "Iter-33470, train loss-1.9488, acc-0.5200, valid loss-1.9700, acc-0.4578, test loss-1.9709, acc-0.4473\n",
      "Iter-33480, train loss-1.9514, acc-0.4600, valid loss-1.9699, acc-0.4576, test loss-1.9708, acc-0.4471\n",
      "Iter-33490, train loss-2.0509, acc-0.2200, valid loss-1.9699, acc-0.4576, test loss-1.9708, acc-0.4471\n",
      "Iter-33500, train loss-2.0415, acc-0.3800, valid loss-1.9698, acc-0.4576, test loss-1.9707, acc-0.4473\n",
      "Iter-33510, train loss-1.9986, acc-0.4400, valid loss-1.9697, acc-0.4578, test loss-1.9706, acc-0.4473\n",
      "Iter-33520, train loss-2.0361, acc-0.2800, valid loss-1.9696, acc-0.4576, test loss-1.9706, acc-0.4474\n",
      "Iter-33530, train loss-1.9500, acc-0.5400, valid loss-1.9696, acc-0.4574, test loss-1.9705, acc-0.4474\n",
      "Iter-33540, train loss-1.9441, acc-0.4600, valid loss-1.9695, acc-0.4574, test loss-1.9704, acc-0.4475\n",
      "Iter-33550, train loss-2.0039, acc-0.4800, valid loss-1.9694, acc-0.4574, test loss-1.9703, acc-0.4474\n",
      "Iter-33560, train loss-1.9845, acc-0.4400, valid loss-1.9693, acc-0.4578, test loss-1.9703, acc-0.4475\n",
      "Iter-33570, train loss-1.9647, acc-0.5800, valid loss-1.9693, acc-0.4578, test loss-1.9702, acc-0.4475\n",
      "Iter-33580, train loss-1.9901, acc-0.4600, valid loss-1.9692, acc-0.4576, test loss-1.9701, acc-0.4474\n",
      "Iter-33590, train loss-1.9663, acc-0.4600, valid loss-1.9691, acc-0.4580, test loss-1.9700, acc-0.4474\n",
      "Iter-33600, train loss-1.9712, acc-0.4200, valid loss-1.9690, acc-0.4578, test loss-1.9700, acc-0.4476\n",
      "Iter-33610, train loss-1.9552, acc-0.4400, valid loss-1.9690, acc-0.4576, test loss-1.9699, acc-0.4476\n",
      "Iter-33620, train loss-1.9954, acc-0.4600, valid loss-1.9689, acc-0.4576, test loss-1.9698, acc-0.4475\n",
      "Iter-33630, train loss-1.9997, acc-0.5200, valid loss-1.9688, acc-0.4580, test loss-1.9697, acc-0.4477\n",
      "Iter-33640, train loss-2.0578, acc-0.4400, valid loss-1.9688, acc-0.4578, test loss-1.9697, acc-0.4477\n",
      "Iter-33650, train loss-1.9401, acc-0.5200, valid loss-1.9687, acc-0.4578, test loss-1.9696, acc-0.4477\n",
      "Iter-33660, train loss-1.9829, acc-0.4000, valid loss-1.9686, acc-0.4578, test loss-1.9695, acc-0.4476\n",
      "Iter-33670, train loss-1.9177, acc-0.4200, valid loss-1.9685, acc-0.4582, test loss-1.9694, acc-0.4479\n",
      "Iter-33680, train loss-2.0360, acc-0.3800, valid loss-1.9684, acc-0.4582, test loss-1.9694, acc-0.4479\n",
      "Iter-33690, train loss-2.0770, acc-0.3600, valid loss-1.9684, acc-0.4582, test loss-1.9693, acc-0.4478\n",
      "Iter-33700, train loss-1.9656, acc-0.5000, valid loss-1.9683, acc-0.4576, test loss-1.9692, acc-0.4478\n",
      "Iter-33710, train loss-1.9993, acc-0.5000, valid loss-1.9682, acc-0.4580, test loss-1.9691, acc-0.4479\n",
      "Iter-33720, train loss-1.9510, acc-0.5200, valid loss-1.9681, acc-0.4576, test loss-1.9691, acc-0.4479\n",
      "Iter-33730, train loss-2.0062, acc-0.4000, valid loss-1.9681, acc-0.4580, test loss-1.9690, acc-0.4479\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-33740, train loss-1.9784, acc-0.4400, valid loss-1.9680, acc-0.4582, test loss-1.9689, acc-0.4479\n",
      "Iter-33750, train loss-1.9311, acc-0.5800, valid loss-1.9679, acc-0.4582, test loss-1.9688, acc-0.4478\n",
      "Iter-33760, train loss-1.9203, acc-0.5000, valid loss-1.9678, acc-0.4580, test loss-1.9688, acc-0.4479\n",
      "Iter-33770, train loss-1.9975, acc-0.4200, valid loss-1.9678, acc-0.4578, test loss-1.9687, acc-0.4478\n",
      "Iter-33780, train loss-1.9629, acc-0.4400, valid loss-1.9677, acc-0.4582, test loss-1.9686, acc-0.4479\n",
      "Iter-33790, train loss-1.9150, acc-0.5200, valid loss-1.9676, acc-0.4580, test loss-1.9685, acc-0.4478\n",
      "Iter-33800, train loss-1.9438, acc-0.4800, valid loss-1.9675, acc-0.4580, test loss-1.9685, acc-0.4476\n",
      "Iter-33810, train loss-1.9620, acc-0.5200, valid loss-1.9675, acc-0.4582, test loss-1.9684, acc-0.4479\n",
      "Iter-33820, train loss-1.9803, acc-0.4800, valid loss-1.9674, acc-0.4580, test loss-1.9683, acc-0.4479\n",
      "Iter-33830, train loss-2.0883, acc-0.3600, valid loss-1.9673, acc-0.4578, test loss-1.9682, acc-0.4479\n",
      "Iter-33840, train loss-2.0506, acc-0.3800, valid loss-1.9672, acc-0.4580, test loss-1.9682, acc-0.4478\n",
      "Iter-33850, train loss-1.9907, acc-0.4600, valid loss-1.9672, acc-0.4582, test loss-1.9681, acc-0.4478\n",
      "Iter-33860, train loss-1.9143, acc-0.5200, valid loss-1.9671, acc-0.4580, test loss-1.9680, acc-0.4478\n",
      "Iter-33870, train loss-1.9730, acc-0.4600, valid loss-1.9670, acc-0.4578, test loss-1.9679, acc-0.4478\n",
      "Iter-33880, train loss-1.8472, acc-0.4800, valid loss-1.9669, acc-0.4580, test loss-1.9679, acc-0.4478\n",
      "Iter-33890, train loss-1.9175, acc-0.5200, valid loss-1.9669, acc-0.4580, test loss-1.9678, acc-0.4478\n",
      "Iter-33900, train loss-2.0295, acc-0.4000, valid loss-1.9668, acc-0.4578, test loss-1.9677, acc-0.4480\n",
      "Iter-33910, train loss-1.9736, acc-0.4800, valid loss-1.9667, acc-0.4580, test loss-1.9676, acc-0.4476\n",
      "Iter-33920, train loss-1.9605, acc-0.3600, valid loss-1.9666, acc-0.4584, test loss-1.9675, acc-0.4475\n",
      "Iter-33930, train loss-2.0282, acc-0.3400, valid loss-1.9666, acc-0.4582, test loss-1.9675, acc-0.4475\n",
      "Iter-33940, train loss-2.0471, acc-0.4000, valid loss-1.9665, acc-0.4586, test loss-1.9674, acc-0.4476\n",
      "Iter-33950, train loss-1.9731, acc-0.4600, valid loss-1.9664, acc-0.4584, test loss-1.9673, acc-0.4477\n",
      "Iter-33960, train loss-1.9893, acc-0.4400, valid loss-1.9663, acc-0.4586, test loss-1.9672, acc-0.4476\n",
      "Iter-33970, train loss-1.8961, acc-0.5400, valid loss-1.9663, acc-0.4586, test loss-1.9672, acc-0.4480\n",
      "Iter-33980, train loss-1.9472, acc-0.5000, valid loss-1.9662, acc-0.4588, test loss-1.9671, acc-0.4482\n",
      "Iter-33990, train loss-2.0302, acc-0.4200, valid loss-1.9661, acc-0.4588, test loss-1.9670, acc-0.4481\n",
      "Iter-34000, train loss-1.9752, acc-0.4600, valid loss-1.9660, acc-0.4588, test loss-1.9669, acc-0.4481\n",
      "Iter-34010, train loss-2.0291, acc-0.4200, valid loss-1.9660, acc-0.4586, test loss-1.9669, acc-0.4481\n",
      "Iter-34020, train loss-1.9136, acc-0.4600, valid loss-1.9659, acc-0.4586, test loss-1.9668, acc-0.4480\n",
      "Iter-34030, train loss-1.9142, acc-0.5000, valid loss-1.9658, acc-0.4586, test loss-1.9667, acc-0.4480\n",
      "Iter-34040, train loss-2.0868, acc-0.3400, valid loss-1.9657, acc-0.4586, test loss-1.9666, acc-0.4480\n",
      "Iter-34050, train loss-1.9517, acc-0.4600, valid loss-1.9657, acc-0.4586, test loss-1.9666, acc-0.4482\n",
      "Iter-34060, train loss-2.0027, acc-0.4600, valid loss-1.9656, acc-0.4586, test loss-1.9665, acc-0.4481\n",
      "Iter-34070, train loss-1.9512, acc-0.5200, valid loss-1.9655, acc-0.4586, test loss-1.9664, acc-0.4482\n",
      "Iter-34080, train loss-2.0173, acc-0.4000, valid loss-1.9654, acc-0.4588, test loss-1.9663, acc-0.4482\n",
      "Iter-34090, train loss-1.9671, acc-0.4600, valid loss-1.9654, acc-0.4588, test loss-1.9663, acc-0.4481\n",
      "Iter-34100, train loss-1.9922, acc-0.4200, valid loss-1.9653, acc-0.4588, test loss-1.9662, acc-0.4480\n",
      "Iter-34110, train loss-2.0346, acc-0.3200, valid loss-1.9652, acc-0.4588, test loss-1.9661, acc-0.4479\n",
      "Iter-34120, train loss-1.9894, acc-0.3400, valid loss-1.9651, acc-0.4586, test loss-1.9660, acc-0.4479\n",
      "Iter-34130, train loss-1.9408, acc-0.5400, valid loss-1.9651, acc-0.4586, test loss-1.9660, acc-0.4479\n",
      "Iter-34140, train loss-1.9623, acc-0.5000, valid loss-1.9650, acc-0.4586, test loss-1.9659, acc-0.4482\n",
      "Iter-34150, train loss-1.9440, acc-0.4400, valid loss-1.9649, acc-0.4590, test loss-1.9658, acc-0.4483\n",
      "Iter-34160, train loss-1.9566, acc-0.5000, valid loss-1.9648, acc-0.4590, test loss-1.9657, acc-0.4484\n",
      "Iter-34170, train loss-1.8988, acc-0.6000, valid loss-1.9648, acc-0.4588, test loss-1.9657, acc-0.4485\n",
      "Iter-34180, train loss-1.9754, acc-0.4800, valid loss-1.9647, acc-0.4588, test loss-1.9656, acc-0.4486\n",
      "Iter-34190, train loss-1.9950, acc-0.4000, valid loss-1.9646, acc-0.4592, test loss-1.9655, acc-0.4486\n",
      "Iter-34200, train loss-1.9291, acc-0.5600, valid loss-1.9646, acc-0.4592, test loss-1.9654, acc-0.4485\n",
      "Iter-34210, train loss-1.9437, acc-0.4400, valid loss-1.9645, acc-0.4590, test loss-1.9654, acc-0.4485\n",
      "Iter-34220, train loss-2.0093, acc-0.4200, valid loss-1.9644, acc-0.4590, test loss-1.9653, acc-0.4483\n",
      "Iter-34230, train loss-1.9587, acc-0.4800, valid loss-1.9643, acc-0.4592, test loss-1.9652, acc-0.4485\n",
      "Iter-34240, train loss-2.0161, acc-0.4000, valid loss-1.9643, acc-0.4592, test loss-1.9651, acc-0.4485\n",
      "Iter-34250, train loss-1.9899, acc-0.5000, valid loss-1.9642, acc-0.4594, test loss-1.9651, acc-0.4486\n",
      "Iter-34260, train loss-1.9760, acc-0.4600, valid loss-1.9641, acc-0.4592, test loss-1.9650, acc-0.4487\n",
      "Iter-34270, train loss-2.0215, acc-0.4000, valid loss-1.9640, acc-0.4592, test loss-1.9649, acc-0.4487\n",
      "Iter-34280, train loss-1.9733, acc-0.4200, valid loss-1.9640, acc-0.4594, test loss-1.9649, acc-0.4487\n",
      "Iter-34290, train loss-1.9749, acc-0.3400, valid loss-1.9639, acc-0.4592, test loss-1.9648, acc-0.4487\n",
      "Iter-34300, train loss-1.9732, acc-0.5200, valid loss-1.9638, acc-0.4596, test loss-1.9647, acc-0.4488\n",
      "Iter-34310, train loss-1.9126, acc-0.5000, valid loss-1.9637, acc-0.4594, test loss-1.9646, acc-0.4487\n",
      "Iter-34320, train loss-1.9816, acc-0.4400, valid loss-1.9637, acc-0.4594, test loss-1.9645, acc-0.4487\n",
      "Iter-34330, train loss-1.9463, acc-0.4200, valid loss-1.9636, acc-0.4596, test loss-1.9645, acc-0.4487\n",
      "Iter-34340, train loss-1.9801, acc-0.5400, valid loss-1.9635, acc-0.4592, test loss-1.9644, acc-0.4486\n",
      "Iter-34350, train loss-1.9857, acc-0.5200, valid loss-1.9634, acc-0.4592, test loss-1.9643, acc-0.4486\n",
      "Iter-34360, train loss-1.9862, acc-0.4000, valid loss-1.9634, acc-0.4590, test loss-1.9642, acc-0.4486\n",
      "Iter-34370, train loss-1.9509, acc-0.5000, valid loss-1.9633, acc-0.4592, test loss-1.9642, acc-0.4488\n",
      "Iter-34380, train loss-1.9521, acc-0.4600, valid loss-1.9632, acc-0.4592, test loss-1.9641, acc-0.4486\n",
      "Iter-34390, train loss-1.8886, acc-0.5800, valid loss-1.9631, acc-0.4596, test loss-1.9640, acc-0.4484\n",
      "Iter-34400, train loss-2.0227, acc-0.3800, valid loss-1.9631, acc-0.4594, test loss-1.9639, acc-0.4485\n",
      "Iter-34410, train loss-1.9736, acc-0.4600, valid loss-1.9630, acc-0.4594, test loss-1.9639, acc-0.4484\n",
      "Iter-34420, train loss-1.9192, acc-0.4800, valid loss-1.9629, acc-0.4596, test loss-1.9638, acc-0.4481\n",
      "Iter-34430, train loss-1.9442, acc-0.5200, valid loss-1.9628, acc-0.4594, test loss-1.9637, acc-0.4482\n",
      "Iter-34440, train loss-1.9759, acc-0.4800, valid loss-1.9628, acc-0.4594, test loss-1.9636, acc-0.4485\n",
      "Iter-34450, train loss-2.0074, acc-0.5400, valid loss-1.9627, acc-0.4594, test loss-1.9636, acc-0.4487\n",
      "Iter-34460, train loss-1.9708, acc-0.3600, valid loss-1.9626, acc-0.4592, test loss-1.9635, acc-0.4482\n",
      "Iter-34470, train loss-1.9952, acc-0.5000, valid loss-1.9625, acc-0.4592, test loss-1.9634, acc-0.4483\n",
      "Iter-34480, train loss-1.9621, acc-0.4400, valid loss-1.9625, acc-0.4594, test loss-1.9633, acc-0.4483\n",
      "Iter-34490, train loss-1.9885, acc-0.4400, valid loss-1.9624, acc-0.4596, test loss-1.9633, acc-0.4481\n",
      "Iter-34500, train loss-1.9945, acc-0.3800, valid loss-1.9623, acc-0.4600, test loss-1.9632, acc-0.4484\n",
      "Iter-34510, train loss-1.9681, acc-0.4400, valid loss-1.9623, acc-0.4598, test loss-1.9631, acc-0.4484\n",
      "Iter-34520, train loss-1.8795, acc-0.6000, valid loss-1.9622, acc-0.4598, test loss-1.9631, acc-0.4485\n",
      "Iter-34530, train loss-1.9842, acc-0.4200, valid loss-1.9621, acc-0.4600, test loss-1.9630, acc-0.4483\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-34540, train loss-1.8955, acc-0.6000, valid loss-1.9620, acc-0.4602, test loss-1.9629, acc-0.4485\n",
      "Iter-34550, train loss-1.9164, acc-0.4400, valid loss-1.9619, acc-0.4604, test loss-1.9628, acc-0.4486\n",
      "Iter-34560, train loss-1.9938, acc-0.4600, valid loss-1.9619, acc-0.4604, test loss-1.9628, acc-0.4487\n",
      "Iter-34570, train loss-1.9456, acc-0.5400, valid loss-1.9618, acc-0.4604, test loss-1.9627, acc-0.4487\n",
      "Iter-34580, train loss-1.9394, acc-0.5200, valid loss-1.9617, acc-0.4606, test loss-1.9626, acc-0.4487\n",
      "Iter-34590, train loss-1.9217, acc-0.5600, valid loss-1.9617, acc-0.4602, test loss-1.9625, acc-0.4486\n",
      "Iter-34600, train loss-2.0340, acc-0.3400, valid loss-1.9616, acc-0.4600, test loss-1.9625, acc-0.4485\n",
      "Iter-34610, train loss-1.9741, acc-0.4400, valid loss-1.9615, acc-0.4602, test loss-1.9624, acc-0.4487\n",
      "Iter-34620, train loss-1.9895, acc-0.5000, valid loss-1.9614, acc-0.4602, test loss-1.9623, acc-0.4485\n",
      "Iter-34630, train loss-1.9924, acc-0.4400, valid loss-1.9614, acc-0.4606, test loss-1.9623, acc-0.4488\n",
      "Iter-34640, train loss-1.9823, acc-0.4200, valid loss-1.9613, acc-0.4602, test loss-1.9622, acc-0.4489\n",
      "Iter-34650, train loss-1.9247, acc-0.5200, valid loss-1.9612, acc-0.4604, test loss-1.9621, acc-0.4491\n",
      "Iter-34660, train loss-1.9996, acc-0.4200, valid loss-1.9611, acc-0.4608, test loss-1.9620, acc-0.4490\n",
      "Iter-34670, train loss-1.9388, acc-0.3600, valid loss-1.9611, acc-0.4604, test loss-1.9620, acc-0.4491\n",
      "Iter-34680, train loss-2.0296, acc-0.4000, valid loss-1.9610, acc-0.4604, test loss-1.9619, acc-0.4492\n",
      "Iter-34690, train loss-1.9457, acc-0.5200, valid loss-1.9609, acc-0.4602, test loss-1.9618, acc-0.4491\n",
      "Iter-34700, train loss-1.9768, acc-0.4400, valid loss-1.9608, acc-0.4604, test loss-1.9617, acc-0.4493\n",
      "Iter-34710, train loss-2.0004, acc-0.4200, valid loss-1.9608, acc-0.4604, test loss-1.9617, acc-0.4493\n",
      "Iter-34720, train loss-1.9627, acc-0.4000, valid loss-1.9607, acc-0.4604, test loss-1.9616, acc-0.4494\n",
      "Iter-34730, train loss-1.9948, acc-0.3600, valid loss-1.9606, acc-0.4602, test loss-1.9615, acc-0.4494\n",
      "Iter-34740, train loss-2.0197, acc-0.4200, valid loss-1.9605, acc-0.4608, test loss-1.9614, acc-0.4494\n",
      "Iter-34750, train loss-1.8965, acc-0.4800, valid loss-1.9605, acc-0.4602, test loss-1.9614, acc-0.4495\n",
      "Iter-34760, train loss-1.9936, acc-0.4600, valid loss-1.9604, acc-0.4600, test loss-1.9613, acc-0.4493\n",
      "Iter-34770, train loss-2.0154, acc-0.3400, valid loss-1.9603, acc-0.4600, test loss-1.9612, acc-0.4493\n",
      "Iter-34780, train loss-2.0226, acc-0.4000, valid loss-1.9602, acc-0.4604, test loss-1.9612, acc-0.4493\n",
      "Iter-34790, train loss-1.9377, acc-0.6000, valid loss-1.9602, acc-0.4602, test loss-1.9611, acc-0.4493\n",
      "Iter-34800, train loss-1.8884, acc-0.5600, valid loss-1.9601, acc-0.4602, test loss-1.9610, acc-0.4492\n",
      "Iter-34810, train loss-2.0084, acc-0.3800, valid loss-1.9600, acc-0.4600, test loss-1.9609, acc-0.4492\n",
      "Iter-34820, train loss-1.9368, acc-0.5200, valid loss-1.9599, acc-0.4600, test loss-1.9608, acc-0.4492\n",
      "Iter-34830, train loss-1.8981, acc-0.5600, valid loss-1.9599, acc-0.4602, test loss-1.9608, acc-0.4490\n",
      "Iter-34840, train loss-1.9959, acc-0.4600, valid loss-1.9598, acc-0.4602, test loss-1.9607, acc-0.4491\n",
      "Iter-34850, train loss-1.9451, acc-0.4600, valid loss-1.9597, acc-0.4602, test loss-1.9606, acc-0.4489\n",
      "Iter-34860, train loss-1.9341, acc-0.4600, valid loss-1.9596, acc-0.4602, test loss-1.9606, acc-0.4490\n",
      "Iter-34870, train loss-1.9041, acc-0.5200, valid loss-1.9596, acc-0.4602, test loss-1.9605, acc-0.4491\n",
      "Iter-34880, train loss-1.9488, acc-0.4800, valid loss-1.9595, acc-0.4600, test loss-1.9604, acc-0.4489\n",
      "Iter-34890, train loss-2.0354, acc-0.3200, valid loss-1.9594, acc-0.4602, test loss-1.9603, acc-0.4490\n",
      "Iter-34900, train loss-2.0101, acc-0.4600, valid loss-1.9593, acc-0.4602, test loss-1.9603, acc-0.4490\n",
      "Iter-34910, train loss-1.9016, acc-0.5200, valid loss-1.9593, acc-0.4598, test loss-1.9602, acc-0.4491\n",
      "Iter-34920, train loss-1.9133, acc-0.4600, valid loss-1.9592, acc-0.4598, test loss-1.9601, acc-0.4491\n",
      "Iter-34930, train loss-1.9759, acc-0.4400, valid loss-1.9591, acc-0.4600, test loss-1.9600, acc-0.4491\n",
      "Iter-34940, train loss-1.9829, acc-0.4600, valid loss-1.9590, acc-0.4604, test loss-1.9600, acc-0.4495\n",
      "Iter-34950, train loss-1.9634, acc-0.5000, valid loss-1.9590, acc-0.4602, test loss-1.9599, acc-0.4491\n",
      "Iter-34960, train loss-1.8942, acc-0.4600, valid loss-1.9589, acc-0.4602, test loss-1.9598, acc-0.4492\n",
      "Iter-34970, train loss-1.9273, acc-0.5800, valid loss-1.9588, acc-0.4600, test loss-1.9597, acc-0.4494\n",
      "Iter-34980, train loss-1.9582, acc-0.3400, valid loss-1.9587, acc-0.4598, test loss-1.9597, acc-0.4496\n",
      "Iter-34990, train loss-1.9998, acc-0.4200, valid loss-1.9587, acc-0.4600, test loss-1.9596, acc-0.4498\n",
      "Iter-35000, train loss-1.9517, acc-0.4800, valid loss-1.9586, acc-0.4602, test loss-1.9595, acc-0.4498\n",
      "Iter-35010, train loss-1.9775, acc-0.4000, valid loss-1.9585, acc-0.4604, test loss-1.9594, acc-0.4498\n",
      "Iter-35020, train loss-1.9974, acc-0.4400, valid loss-1.9584, acc-0.4602, test loss-1.9594, acc-0.4499\n",
      "Iter-35030, train loss-1.9703, acc-0.5400, valid loss-1.9584, acc-0.4602, test loss-1.9593, acc-0.4498\n",
      "Iter-35040, train loss-1.9756, acc-0.4000, valid loss-1.9583, acc-0.4604, test loss-1.9592, acc-0.4497\n",
      "Iter-35050, train loss-1.9599, acc-0.4400, valid loss-1.9582, acc-0.4602, test loss-1.9591, acc-0.4500\n",
      "Iter-35060, train loss-1.9817, acc-0.3800, valid loss-1.9582, acc-0.4602, test loss-1.9591, acc-0.4501\n",
      "Iter-35070, train loss-2.0790, acc-0.3200, valid loss-1.9581, acc-0.4602, test loss-1.9590, acc-0.4501\n",
      "Iter-35080, train loss-1.9921, acc-0.3600, valid loss-1.9580, acc-0.4604, test loss-1.9589, acc-0.4501\n",
      "Iter-35090, train loss-1.9958, acc-0.3600, valid loss-1.9579, acc-0.4606, test loss-1.9589, acc-0.4501\n",
      "Iter-35100, train loss-1.9075, acc-0.4400, valid loss-1.9579, acc-0.4604, test loss-1.9588, acc-0.4502\n",
      "Iter-35110, train loss-1.9410, acc-0.4600, valid loss-1.9578, acc-0.4602, test loss-1.9587, acc-0.4502\n",
      "Iter-35120, train loss-1.9278, acc-0.5000, valid loss-1.9577, acc-0.4604, test loss-1.9586, acc-0.4504\n",
      "Iter-35130, train loss-1.9617, acc-0.4400, valid loss-1.9576, acc-0.4606, test loss-1.9586, acc-0.4502\n",
      "Iter-35140, train loss-1.8795, acc-0.6200, valid loss-1.9575, acc-0.4604, test loss-1.9585, acc-0.4502\n",
      "Iter-35150, train loss-1.9441, acc-0.4400, valid loss-1.9575, acc-0.4604, test loss-1.9584, acc-0.4500\n",
      "Iter-35160, train loss-1.9685, acc-0.5200, valid loss-1.9574, acc-0.4606, test loss-1.9583, acc-0.4499\n",
      "Iter-35170, train loss-1.9949, acc-0.5000, valid loss-1.9573, acc-0.4604, test loss-1.9583, acc-0.4501\n",
      "Iter-35180, train loss-1.9919, acc-0.3800, valid loss-1.9573, acc-0.4608, test loss-1.9582, acc-0.4501\n",
      "Iter-35190, train loss-1.9286, acc-0.4800, valid loss-1.9572, acc-0.4608, test loss-1.9581, acc-0.4503\n",
      "Iter-35200, train loss-2.0206, acc-0.3400, valid loss-1.9571, acc-0.4608, test loss-1.9580, acc-0.4504\n",
      "Iter-35210, train loss-1.9904, acc-0.3800, valid loss-1.9570, acc-0.4610, test loss-1.9580, acc-0.4504\n",
      "Iter-35220, train loss-1.9721, acc-0.5400, valid loss-1.9570, acc-0.4610, test loss-1.9579, acc-0.4505\n",
      "Iter-35230, train loss-2.0255, acc-0.3200, valid loss-1.9569, acc-0.4612, test loss-1.9578, acc-0.4505\n",
      "Iter-35240, train loss-1.8916, acc-0.5600, valid loss-1.9568, acc-0.4614, test loss-1.9578, acc-0.4505\n",
      "Iter-35250, train loss-1.9985, acc-0.3400, valid loss-1.9568, acc-0.4612, test loss-1.9577, acc-0.4507\n",
      "Iter-35260, train loss-1.9683, acc-0.4200, valid loss-1.9567, acc-0.4614, test loss-1.9576, acc-0.4506\n",
      "Iter-35270, train loss-1.9026, acc-0.5400, valid loss-1.9566, acc-0.4614, test loss-1.9575, acc-0.4507\n",
      "Iter-35280, train loss-1.9376, acc-0.5000, valid loss-1.9565, acc-0.4614, test loss-1.9575, acc-0.4506\n",
      "Iter-35290, train loss-1.9353, acc-0.5400, valid loss-1.9565, acc-0.4614, test loss-1.9574, acc-0.4504\n",
      "Iter-35300, train loss-1.8684, acc-0.5800, valid loss-1.9564, acc-0.4612, test loss-1.9573, acc-0.4501\n",
      "Iter-35310, train loss-1.9122, acc-0.5200, valid loss-1.9563, acc-0.4610, test loss-1.9572, acc-0.4503\n",
      "Iter-35320, train loss-1.9557, acc-0.5000, valid loss-1.9562, acc-0.4610, test loss-1.9572, acc-0.4502\n",
      "Iter-35330, train loss-1.9748, acc-0.4400, valid loss-1.9562, acc-0.4610, test loss-1.9571, acc-0.4503\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-35340, train loss-1.9864, acc-0.4000, valid loss-1.9561, acc-0.4610, test loss-1.9570, acc-0.4503\n",
      "Iter-35350, train loss-1.9355, acc-0.4600, valid loss-1.9560, acc-0.4610, test loss-1.9569, acc-0.4503\n",
      "Iter-35360, train loss-2.0078, acc-0.4600, valid loss-1.9559, acc-0.4612, test loss-1.9569, acc-0.4502\n",
      "Iter-35370, train loss-1.9937, acc-0.3200, valid loss-1.9559, acc-0.4612, test loss-1.9568, acc-0.4502\n",
      "Iter-35380, train loss-2.0729, acc-0.3800, valid loss-1.9558, acc-0.4610, test loss-1.9567, acc-0.4499\n",
      "Iter-35390, train loss-1.9414, acc-0.4400, valid loss-1.9557, acc-0.4612, test loss-1.9567, acc-0.4499\n",
      "Iter-35400, train loss-2.0121, acc-0.3600, valid loss-1.9557, acc-0.4610, test loss-1.9566, acc-0.4499\n",
      "Iter-35410, train loss-1.9475, acc-0.5000, valid loss-1.9556, acc-0.4610, test loss-1.9565, acc-0.4500\n",
      "Iter-35420, train loss-1.9930, acc-0.5200, valid loss-1.9555, acc-0.4612, test loss-1.9564, acc-0.4502\n",
      "Iter-35430, train loss-1.9961, acc-0.4600, valid loss-1.9555, acc-0.4614, test loss-1.9564, acc-0.4502\n",
      "Iter-35440, train loss-2.0030, acc-0.4000, valid loss-1.9554, acc-0.4614, test loss-1.9563, acc-0.4501\n",
      "Iter-35450, train loss-1.9078, acc-0.5200, valid loss-1.9553, acc-0.4614, test loss-1.9562, acc-0.4501\n",
      "Iter-35460, train loss-1.9334, acc-0.5000, valid loss-1.9552, acc-0.4614, test loss-1.9562, acc-0.4502\n",
      "Iter-35470, train loss-2.0325, acc-0.4000, valid loss-1.9552, acc-0.4614, test loss-1.9561, acc-0.4502\n",
      "Iter-35480, train loss-2.0562, acc-0.4200, valid loss-1.9551, acc-0.4616, test loss-1.9560, acc-0.4501\n",
      "Iter-35490, train loss-1.9001, acc-0.5400, valid loss-1.9550, acc-0.4614, test loss-1.9559, acc-0.4502\n",
      "Iter-35500, train loss-1.8942, acc-0.5000, valid loss-1.9549, acc-0.4616, test loss-1.9559, acc-0.4502\n",
      "Iter-35510, train loss-1.9907, acc-0.3200, valid loss-1.9549, acc-0.4614, test loss-1.9558, acc-0.4504\n",
      "Iter-35520, train loss-1.9359, acc-0.5000, valid loss-1.9548, acc-0.4614, test loss-1.9557, acc-0.4506\n",
      "Iter-35530, train loss-1.9926, acc-0.3800, valid loss-1.9547, acc-0.4612, test loss-1.9556, acc-0.4505\n",
      "Iter-35540, train loss-2.0161, acc-0.2800, valid loss-1.9546, acc-0.4614, test loss-1.9556, acc-0.4505\n",
      "Iter-35550, train loss-1.9576, acc-0.4600, valid loss-1.9546, acc-0.4612, test loss-1.9555, acc-0.4504\n",
      "Iter-35560, train loss-1.9030, acc-0.5200, valid loss-1.9545, acc-0.4612, test loss-1.9554, acc-0.4506\n",
      "Iter-35570, train loss-2.0100, acc-0.3600, valid loss-1.9544, acc-0.4612, test loss-1.9554, acc-0.4503\n",
      "Iter-35580, train loss-1.9618, acc-0.3600, valid loss-1.9544, acc-0.4614, test loss-1.9553, acc-0.4504\n",
      "Iter-35590, train loss-1.9425, acc-0.4600, valid loss-1.9543, acc-0.4614, test loss-1.9552, acc-0.4505\n",
      "Iter-35600, train loss-1.9660, acc-0.4600, valid loss-1.9542, acc-0.4614, test loss-1.9551, acc-0.4507\n",
      "Iter-35610, train loss-1.9849, acc-0.5200, valid loss-1.9541, acc-0.4614, test loss-1.9551, acc-0.4507\n",
      "Iter-35620, train loss-1.8869, acc-0.5400, valid loss-1.9541, acc-0.4616, test loss-1.9550, acc-0.4507\n",
      "Iter-35630, train loss-1.8944, acc-0.5400, valid loss-1.9540, acc-0.4610, test loss-1.9549, acc-0.4505\n",
      "Iter-35640, train loss-1.9471, acc-0.5000, valid loss-1.9539, acc-0.4614, test loss-1.9548, acc-0.4506\n",
      "Iter-35650, train loss-2.0137, acc-0.3000, valid loss-1.9539, acc-0.4618, test loss-1.9548, acc-0.4507\n",
      "Iter-35660, train loss-1.9788, acc-0.4000, valid loss-1.9538, acc-0.4616, test loss-1.9547, acc-0.4505\n",
      "Iter-35670, train loss-1.9437, acc-0.5000, valid loss-1.9537, acc-0.4614, test loss-1.9546, acc-0.4507\n",
      "Iter-35680, train loss-1.9772, acc-0.4000, valid loss-1.9536, acc-0.4618, test loss-1.9546, acc-0.4508\n",
      "Iter-35690, train loss-2.0660, acc-0.3400, valid loss-1.9536, acc-0.4618, test loss-1.9545, acc-0.4508\n",
      "Iter-35700, train loss-1.9856, acc-0.3400, valid loss-1.9535, acc-0.4618, test loss-1.9544, acc-0.4508\n",
      "Iter-35710, train loss-1.9846, acc-0.5000, valid loss-1.9534, acc-0.4618, test loss-1.9543, acc-0.4507\n",
      "Iter-35720, train loss-2.0058, acc-0.3400, valid loss-1.9534, acc-0.4618, test loss-1.9543, acc-0.4507\n",
      "Iter-35730, train loss-2.0046, acc-0.4200, valid loss-1.9533, acc-0.4618, test loss-1.9542, acc-0.4508\n",
      "Iter-35740, train loss-2.0328, acc-0.3600, valid loss-1.9532, acc-0.4620, test loss-1.9541, acc-0.4509\n",
      "Iter-35750, train loss-2.0008, acc-0.5000, valid loss-1.9532, acc-0.4622, test loss-1.9541, acc-0.4509\n",
      "Iter-35760, train loss-1.9281, acc-0.5000, valid loss-1.9531, acc-0.4620, test loss-1.9540, acc-0.4512\n",
      "Iter-35770, train loss-1.9296, acc-0.4400, valid loss-1.9530, acc-0.4616, test loss-1.9539, acc-0.4512\n",
      "Iter-35780, train loss-2.0036, acc-0.4400, valid loss-1.9529, acc-0.4616, test loss-1.9538, acc-0.4512\n",
      "Iter-35790, train loss-1.9495, acc-0.4600, valid loss-1.9529, acc-0.4616, test loss-1.9538, acc-0.4513\n",
      "Iter-35800, train loss-1.9390, acc-0.4800, valid loss-1.9528, acc-0.4616, test loss-1.9537, acc-0.4513\n",
      "Iter-35810, train loss-1.9294, acc-0.4600, valid loss-1.9527, acc-0.4622, test loss-1.9536, acc-0.4514\n",
      "Iter-35820, train loss-1.9788, acc-0.4600, valid loss-1.9526, acc-0.4622, test loss-1.9535, acc-0.4514\n",
      "Iter-35830, train loss-2.0143, acc-0.3800, valid loss-1.9526, acc-0.4622, test loss-1.9535, acc-0.4512\n",
      "Iter-35840, train loss-2.0666, acc-0.2800, valid loss-1.9525, acc-0.4622, test loss-1.9534, acc-0.4513\n",
      "Iter-35850, train loss-1.9648, acc-0.4200, valid loss-1.9524, acc-0.4622, test loss-1.9533, acc-0.4512\n",
      "Iter-35860, train loss-1.9268, acc-0.5200, valid loss-1.9523, acc-0.4622, test loss-1.9532, acc-0.4511\n",
      "Iter-35870, train loss-1.9503, acc-0.4400, valid loss-1.9523, acc-0.4622, test loss-1.9532, acc-0.4509\n",
      "Iter-35880, train loss-2.0459, acc-0.3200, valid loss-1.9522, acc-0.4622, test loss-1.9531, acc-0.4512\n",
      "Iter-35890, train loss-2.0191, acc-0.4000, valid loss-1.9521, acc-0.4622, test loss-1.9530, acc-0.4510\n",
      "Iter-35900, train loss-1.9301, acc-0.4800, valid loss-1.9520, acc-0.4622, test loss-1.9530, acc-0.4511\n",
      "Iter-35910, train loss-2.0078, acc-0.2800, valid loss-1.9520, acc-0.4622, test loss-1.9529, acc-0.4511\n",
      "Iter-35920, train loss-1.8678, acc-0.6200, valid loss-1.9519, acc-0.4624, test loss-1.9528, acc-0.4512\n",
      "Iter-35930, train loss-1.8802, acc-0.5800, valid loss-1.9518, acc-0.4628, test loss-1.9527, acc-0.4514\n",
      "Iter-35940, train loss-1.9284, acc-0.4800, valid loss-1.9518, acc-0.4626, test loss-1.9527, acc-0.4513\n",
      "Iter-35950, train loss-2.0090, acc-0.4400, valid loss-1.9517, acc-0.4628, test loss-1.9526, acc-0.4513\n",
      "Iter-35960, train loss-1.8903, acc-0.4400, valid loss-1.9516, acc-0.4626, test loss-1.9525, acc-0.4515\n",
      "Iter-35970, train loss-1.9386, acc-0.4800, valid loss-1.9515, acc-0.4626, test loss-1.9524, acc-0.4516\n",
      "Iter-35980, train loss-1.8893, acc-0.4600, valid loss-1.9515, acc-0.4622, test loss-1.9524, acc-0.4517\n",
      "Iter-35990, train loss-1.9598, acc-0.5400, valid loss-1.9514, acc-0.4622, test loss-1.9523, acc-0.4517\n",
      "Iter-36000, train loss-1.9771, acc-0.4000, valid loss-1.9513, acc-0.4624, test loss-1.9522, acc-0.4517\n",
      "Iter-36010, train loss-1.9704, acc-0.4200, valid loss-1.9512, acc-0.4624, test loss-1.9521, acc-0.4517\n",
      "Iter-36020, train loss-1.9719, acc-0.5000, valid loss-1.9512, acc-0.4622, test loss-1.9521, acc-0.4517\n",
      "Iter-36030, train loss-1.9779, acc-0.4400, valid loss-1.9511, acc-0.4626, test loss-1.9520, acc-0.4517\n",
      "Iter-36040, train loss-1.9335, acc-0.4400, valid loss-1.9510, acc-0.4626, test loss-1.9519, acc-0.4517\n",
      "Iter-36050, train loss-1.9697, acc-0.4200, valid loss-1.9510, acc-0.4626, test loss-1.9519, acc-0.4517\n",
      "Iter-36060, train loss-1.9717, acc-0.4600, valid loss-1.9509, acc-0.4624, test loss-1.9518, acc-0.4520\n",
      "Iter-36070, train loss-1.8236, acc-0.6200, valid loss-1.9508, acc-0.4624, test loss-1.9517, acc-0.4519\n",
      "Iter-36080, train loss-1.9821, acc-0.5200, valid loss-1.9507, acc-0.4624, test loss-1.9516, acc-0.4519\n",
      "Iter-36090, train loss-1.9727, acc-0.4600, valid loss-1.9507, acc-0.4624, test loss-1.9516, acc-0.4519\n",
      "Iter-36100, train loss-2.0038, acc-0.4200, valid loss-1.9506, acc-0.4624, test loss-1.9515, acc-0.4519\n",
      "Iter-36110, train loss-1.9519, acc-0.4200, valid loss-1.9505, acc-0.4628, test loss-1.9514, acc-0.4519\n",
      "Iter-36120, train loss-1.9478, acc-0.5000, valid loss-1.9505, acc-0.4626, test loss-1.9513, acc-0.4519\n",
      "Iter-36130, train loss-2.0152, acc-0.4200, valid loss-1.9504, acc-0.4628, test loss-1.9513, acc-0.4519\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36140, train loss-1.9499, acc-0.4600, valid loss-1.9503, acc-0.4628, test loss-1.9512, acc-0.4519\n",
      "Iter-36150, train loss-1.9488, acc-0.4400, valid loss-1.9502, acc-0.4628, test loss-1.9511, acc-0.4519\n",
      "Iter-36160, train loss-2.0171, acc-0.3600, valid loss-1.9502, acc-0.4630, test loss-1.9511, acc-0.4520\n",
      "Iter-36170, train loss-1.9904, acc-0.3800, valid loss-1.9501, acc-0.4634, test loss-1.9510, acc-0.4522\n",
      "Iter-36180, train loss-1.9675, acc-0.4600, valid loss-1.9500, acc-0.4632, test loss-1.9509, acc-0.4523\n",
      "Iter-36190, train loss-2.0007, acc-0.3800, valid loss-1.9500, acc-0.4636, test loss-1.9508, acc-0.4524\n",
      "Iter-36200, train loss-1.9860, acc-0.4800, valid loss-1.9499, acc-0.4636, test loss-1.9508, acc-0.4524\n",
      "Iter-36210, train loss-2.0451, acc-0.2800, valid loss-1.9498, acc-0.4630, test loss-1.9507, acc-0.4523\n",
      "Iter-36220, train loss-1.9820, acc-0.5600, valid loss-1.9497, acc-0.4632, test loss-1.9506, acc-0.4522\n",
      "Iter-36230, train loss-1.9449, acc-0.4400, valid loss-1.9497, acc-0.4630, test loss-1.9506, acc-0.4521\n",
      "Iter-36240, train loss-1.9507, acc-0.4600, valid loss-1.9496, acc-0.4630, test loss-1.9505, acc-0.4523\n",
      "Iter-36250, train loss-2.0586, acc-0.2600, valid loss-1.9495, acc-0.4628, test loss-1.9504, acc-0.4523\n",
      "Iter-36260, train loss-1.9884, acc-0.3800, valid loss-1.9495, acc-0.4630, test loss-1.9503, acc-0.4522\n",
      "Iter-36270, train loss-1.9358, acc-0.4600, valid loss-1.9494, acc-0.4632, test loss-1.9503, acc-0.4521\n",
      "Iter-36280, train loss-2.0493, acc-0.3600, valid loss-1.9493, acc-0.4630, test loss-1.9502, acc-0.4521\n",
      "Iter-36290, train loss-1.9639, acc-0.4200, valid loss-1.9493, acc-0.4628, test loss-1.9501, acc-0.4521\n",
      "Iter-36300, train loss-1.9616, acc-0.5000, valid loss-1.9492, acc-0.4630, test loss-1.9501, acc-0.4522\n",
      "Iter-36310, train loss-1.9416, acc-0.5400, valid loss-1.9491, acc-0.4628, test loss-1.9500, acc-0.4521\n",
      "Iter-36320, train loss-2.0452, acc-0.4000, valid loss-1.9490, acc-0.4628, test loss-1.9499, acc-0.4521\n",
      "Iter-36330, train loss-1.9167, acc-0.4600, valid loss-1.9490, acc-0.4628, test loss-1.9499, acc-0.4520\n",
      "Iter-36340, train loss-1.9862, acc-0.5000, valid loss-1.9489, acc-0.4628, test loss-1.9498, acc-0.4521\n",
      "Iter-36350, train loss-1.9432, acc-0.4800, valid loss-1.9488, acc-0.4628, test loss-1.9497, acc-0.4521\n",
      "Iter-36360, train loss-1.8794, acc-0.5600, valid loss-1.9488, acc-0.4628, test loss-1.9496, acc-0.4522\n",
      "Iter-36370, train loss-1.9126, acc-0.5800, valid loss-1.9487, acc-0.4630, test loss-1.9496, acc-0.4522\n",
      "Iter-36380, train loss-1.9583, acc-0.5400, valid loss-1.9486, acc-0.4632, test loss-1.9495, acc-0.4524\n",
      "Iter-36390, train loss-2.0276, acc-0.4600, valid loss-1.9485, acc-0.4630, test loss-1.9494, acc-0.4524\n",
      "Iter-36400, train loss-1.9112, acc-0.5400, valid loss-1.9485, acc-0.4632, test loss-1.9494, acc-0.4524\n",
      "Iter-36410, train loss-1.9435, acc-0.4400, valid loss-1.9484, acc-0.4630, test loss-1.9493, acc-0.4524\n",
      "Iter-36420, train loss-1.9400, acc-0.4400, valid loss-1.9483, acc-0.4630, test loss-1.9492, acc-0.4524\n",
      "Iter-36430, train loss-1.9673, acc-0.4200, valid loss-1.9483, acc-0.4632, test loss-1.9491, acc-0.4524\n",
      "Iter-36440, train loss-1.9496, acc-0.4400, valid loss-1.9482, acc-0.4634, test loss-1.9491, acc-0.4525\n",
      "Iter-36450, train loss-1.9153, acc-0.5000, valid loss-1.9481, acc-0.4634, test loss-1.9490, acc-0.4526\n",
      "Iter-36460, train loss-1.9922, acc-0.4800, valid loss-1.9480, acc-0.4632, test loss-1.9489, acc-0.4525\n",
      "Iter-36470, train loss-1.9046, acc-0.4600, valid loss-1.9480, acc-0.4632, test loss-1.9489, acc-0.4526\n",
      "Iter-36480, train loss-1.9409, acc-0.5000, valid loss-1.9479, acc-0.4632, test loss-1.9488, acc-0.4525\n",
      "Iter-36490, train loss-1.9735, acc-0.4600, valid loss-1.9478, acc-0.4634, test loss-1.9487, acc-0.4525\n",
      "Iter-36500, train loss-2.0541, acc-0.3400, valid loss-1.9478, acc-0.4636, test loss-1.9486, acc-0.4527\n",
      "Iter-36510, train loss-1.9273, acc-0.4800, valid loss-1.9477, acc-0.4638, test loss-1.9486, acc-0.4526\n",
      "Iter-36520, train loss-1.8940, acc-0.5400, valid loss-1.9476, acc-0.4636, test loss-1.9485, acc-0.4524\n",
      "Iter-36530, train loss-1.9661, acc-0.4200, valid loss-1.9475, acc-0.4638, test loss-1.9484, acc-0.4527\n",
      "Iter-36540, train loss-1.9325, acc-0.4600, valid loss-1.9475, acc-0.4638, test loss-1.9483, acc-0.4527\n",
      "Iter-36550, train loss-1.9834, acc-0.3400, valid loss-1.9474, acc-0.4636, test loss-1.9483, acc-0.4526\n",
      "Iter-36560, train loss-1.9369, acc-0.5600, valid loss-1.9473, acc-0.4638, test loss-1.9482, acc-0.4525\n",
      "Iter-36570, train loss-1.9587, acc-0.4800, valid loss-1.9473, acc-0.4638, test loss-1.9481, acc-0.4527\n",
      "Iter-36580, train loss-1.9420, acc-0.4200, valid loss-1.9472, acc-0.4638, test loss-1.9481, acc-0.4527\n",
      "Iter-36590, train loss-1.8922, acc-0.4600, valid loss-1.9471, acc-0.4638, test loss-1.9480, acc-0.4526\n",
      "Iter-36600, train loss-1.9568, acc-0.3800, valid loss-1.9470, acc-0.4636, test loss-1.9479, acc-0.4526\n",
      "Iter-36610, train loss-1.9326, acc-0.5200, valid loss-1.9470, acc-0.4638, test loss-1.9478, acc-0.4526\n",
      "Iter-36620, train loss-1.9497, acc-0.5400, valid loss-1.9469, acc-0.4638, test loss-1.9478, acc-0.4527\n",
      "Iter-36630, train loss-1.9505, acc-0.4200, valid loss-1.9468, acc-0.4638, test loss-1.9477, acc-0.4527\n",
      "Iter-36640, train loss-1.9920, acc-0.4200, valid loss-1.9467, acc-0.4642, test loss-1.9476, acc-0.4527\n",
      "Iter-36650, train loss-1.9449, acc-0.4800, valid loss-1.9467, acc-0.4638, test loss-1.9475, acc-0.4527\n",
      "Iter-36660, train loss-1.9272, acc-0.4200, valid loss-1.9466, acc-0.4638, test loss-1.9475, acc-0.4529\n",
      "Iter-36670, train loss-1.8936, acc-0.4600, valid loss-1.9465, acc-0.4638, test loss-1.9474, acc-0.4530\n",
      "Iter-36680, train loss-1.9632, acc-0.5200, valid loss-1.9465, acc-0.4638, test loss-1.9473, acc-0.4531\n",
      "Iter-36690, train loss-2.0111, acc-0.4400, valid loss-1.9464, acc-0.4638, test loss-1.9473, acc-0.4530\n",
      "Iter-36700, train loss-1.8450, acc-0.5800, valid loss-1.9463, acc-0.4638, test loss-1.9472, acc-0.4529\n",
      "Iter-36710, train loss-1.9818, acc-0.4800, valid loss-1.9462, acc-0.4638, test loss-1.9471, acc-0.4529\n",
      "Iter-36720, train loss-1.9301, acc-0.5400, valid loss-1.9462, acc-0.4636, test loss-1.9471, acc-0.4530\n",
      "Iter-36730, train loss-2.0118, acc-0.3400, valid loss-1.9461, acc-0.4632, test loss-1.9470, acc-0.4530\n",
      "Iter-36740, train loss-1.9189, acc-0.6000, valid loss-1.9460, acc-0.4636, test loss-1.9469, acc-0.4530\n",
      "Iter-36750, train loss-2.0354, acc-0.3800, valid loss-1.9460, acc-0.4640, test loss-1.9468, acc-0.4530\n",
      "Iter-36760, train loss-1.9646, acc-0.4400, valid loss-1.9459, acc-0.4636, test loss-1.9468, acc-0.4533\n",
      "Iter-36770, train loss-2.0267, acc-0.3200, valid loss-1.9458, acc-0.4640, test loss-1.9467, acc-0.4529\n",
      "Iter-36780, train loss-1.9046, acc-0.4200, valid loss-1.9458, acc-0.4638, test loss-1.9466, acc-0.4531\n",
      "Iter-36790, train loss-1.9295, acc-0.5200, valid loss-1.9457, acc-0.4636, test loss-1.9466, acc-0.4534\n",
      "Iter-36800, train loss-1.9388, acc-0.5800, valid loss-1.9456, acc-0.4636, test loss-1.9465, acc-0.4534\n",
      "Iter-36810, train loss-1.9299, acc-0.5200, valid loss-1.9456, acc-0.4638, test loss-1.9464, acc-0.4535\n",
      "Iter-36820, train loss-1.9218, acc-0.4400, valid loss-1.9455, acc-0.4636, test loss-1.9464, acc-0.4534\n",
      "Iter-36830, train loss-1.9406, acc-0.4800, valid loss-1.9454, acc-0.4638, test loss-1.9463, acc-0.4535\n",
      "Iter-36840, train loss-1.9087, acc-0.5600, valid loss-1.9453, acc-0.4638, test loss-1.9462, acc-0.4535\n",
      "Iter-36850, train loss-1.9165, acc-0.4600, valid loss-1.9453, acc-0.4638, test loss-1.9461, acc-0.4535\n",
      "Iter-36860, train loss-2.0064, acc-0.4200, valid loss-1.9452, acc-0.4638, test loss-1.9461, acc-0.4533\n",
      "Iter-36870, train loss-2.0211, acc-0.4600, valid loss-1.9451, acc-0.4638, test loss-1.9460, acc-0.4533\n",
      "Iter-36880, train loss-1.9388, acc-0.4800, valid loss-1.9451, acc-0.4638, test loss-1.9459, acc-0.4533\n",
      "Iter-36890, train loss-2.0455, acc-0.3600, valid loss-1.9450, acc-0.4638, test loss-1.9459, acc-0.4535\n",
      "Iter-36900, train loss-1.9041, acc-0.5600, valid loss-1.9449, acc-0.4638, test loss-1.9458, acc-0.4533\n",
      "Iter-36910, train loss-1.9967, acc-0.4400, valid loss-1.9448, acc-0.4640, test loss-1.9457, acc-0.4535\n",
      "Iter-36920, train loss-1.9713, acc-0.3800, valid loss-1.9448, acc-0.4638, test loss-1.9456, acc-0.4535\n",
      "Iter-36930, train loss-1.9785, acc-0.4000, valid loss-1.9447, acc-0.4640, test loss-1.9456, acc-0.4534\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-36940, train loss-2.0178, acc-0.3600, valid loss-1.9446, acc-0.4642, test loss-1.9455, acc-0.4528\n",
      "Iter-36950, train loss-2.0734, acc-0.3200, valid loss-1.9446, acc-0.4640, test loss-1.9454, acc-0.4534\n",
      "Iter-36960, train loss-1.9046, acc-0.4800, valid loss-1.9445, acc-0.4640, test loss-1.9454, acc-0.4534\n",
      "Iter-36970, train loss-1.9770, acc-0.4200, valid loss-1.9444, acc-0.4640, test loss-1.9453, acc-0.4537\n",
      "Iter-36980, train loss-1.9650, acc-0.4200, valid loss-1.9444, acc-0.4640, test loss-1.9452, acc-0.4539\n",
      "Iter-36990, train loss-1.9161, acc-0.5200, valid loss-1.9443, acc-0.4640, test loss-1.9452, acc-0.4537\n",
      "Iter-37000, train loss-2.0076, acc-0.4200, valid loss-1.9442, acc-0.4640, test loss-1.9451, acc-0.4538\n",
      "Iter-37010, train loss-1.8994, acc-0.4600, valid loss-1.9441, acc-0.4640, test loss-1.9450, acc-0.4540\n",
      "Iter-37020, train loss-1.9373, acc-0.4200, valid loss-1.9441, acc-0.4640, test loss-1.9450, acc-0.4540\n",
      "Iter-37030, train loss-1.9928, acc-0.3600, valid loss-1.9440, acc-0.4644, test loss-1.9449, acc-0.4537\n",
      "Iter-37040, train loss-2.0415, acc-0.3000, valid loss-1.9439, acc-0.4646, test loss-1.9448, acc-0.4538\n",
      "Iter-37050, train loss-1.8494, acc-0.5400, valid loss-1.9439, acc-0.4644, test loss-1.9447, acc-0.4538\n",
      "Iter-37060, train loss-2.0278, acc-0.3000, valid loss-1.9438, acc-0.4642, test loss-1.9447, acc-0.4538\n",
      "Iter-37070, train loss-1.9347, acc-0.4200, valid loss-1.9437, acc-0.4638, test loss-1.9446, acc-0.4540\n",
      "Iter-37080, train loss-1.9029, acc-0.5200, valid loss-1.9436, acc-0.4640, test loss-1.9445, acc-0.4540\n",
      "Iter-37090, train loss-1.9125, acc-0.4800, valid loss-1.9436, acc-0.4638, test loss-1.9445, acc-0.4539\n",
      "Iter-37100, train loss-1.8572, acc-0.5600, valid loss-1.9435, acc-0.4640, test loss-1.9444, acc-0.4538\n",
      "Iter-37110, train loss-1.9696, acc-0.4400, valid loss-1.9434, acc-0.4642, test loss-1.9443, acc-0.4538\n",
      "Iter-37120, train loss-1.9151, acc-0.4400, valid loss-1.9433, acc-0.4640, test loss-1.9442, acc-0.4536\n",
      "Iter-37130, train loss-1.9930, acc-0.3600, valid loss-1.9433, acc-0.4642, test loss-1.9442, acc-0.4537\n",
      "Iter-37140, train loss-1.9438, acc-0.4400, valid loss-1.9432, acc-0.4642, test loss-1.9441, acc-0.4536\n",
      "Iter-37150, train loss-1.9706, acc-0.3800, valid loss-1.9431, acc-0.4642, test loss-1.9440, acc-0.4537\n",
      "Iter-37160, train loss-1.9730, acc-0.4000, valid loss-1.9431, acc-0.4642, test loss-1.9439, acc-0.4537\n",
      "Iter-37170, train loss-1.9590, acc-0.4200, valid loss-1.9430, acc-0.4642, test loss-1.9439, acc-0.4538\n",
      "Iter-37180, train loss-1.9142, acc-0.4200, valid loss-1.9429, acc-0.4640, test loss-1.9438, acc-0.4536\n",
      "Iter-37190, train loss-1.9371, acc-0.4800, valid loss-1.9428, acc-0.4640, test loss-1.9437, acc-0.4539\n",
      "Iter-37200, train loss-2.0404, acc-0.3800, valid loss-1.9428, acc-0.4640, test loss-1.9437, acc-0.4539\n",
      "Iter-37210, train loss-1.9564, acc-0.5200, valid loss-1.9427, acc-0.4642, test loss-1.9436, acc-0.4538\n",
      "Iter-37220, train loss-1.9917, acc-0.3400, valid loss-1.9426, acc-0.4642, test loss-1.9435, acc-0.4540\n",
      "Iter-37230, train loss-1.9638, acc-0.4800, valid loss-1.9426, acc-0.4644, test loss-1.9435, acc-0.4540\n",
      "Iter-37240, train loss-1.8957, acc-0.5000, valid loss-1.9425, acc-0.4644, test loss-1.9434, acc-0.4540\n",
      "Iter-37250, train loss-1.9529, acc-0.4000, valid loss-1.9424, acc-0.4644, test loss-1.9433, acc-0.4541\n",
      "Iter-37260, train loss-1.9773, acc-0.3200, valid loss-1.9424, acc-0.4646, test loss-1.9432, acc-0.4542\n",
      "Iter-37270, train loss-1.9777, acc-0.4000, valid loss-1.9423, acc-0.4646, test loss-1.9432, acc-0.4544\n",
      "Iter-37280, train loss-2.0235, acc-0.3400, valid loss-1.9422, acc-0.4646, test loss-1.9431, acc-0.4544\n",
      "Iter-37290, train loss-1.9737, acc-0.5000, valid loss-1.9421, acc-0.4646, test loss-1.9430, acc-0.4545\n",
      "Iter-37300, train loss-1.9906, acc-0.3800, valid loss-1.9421, acc-0.4646, test loss-1.9430, acc-0.4544\n",
      "Iter-37310, train loss-1.8836, acc-0.5400, valid loss-1.9420, acc-0.4646, test loss-1.9429, acc-0.4546\n",
      "Iter-37320, train loss-1.9963, acc-0.3800, valid loss-1.9419, acc-0.4646, test loss-1.9428, acc-0.4548\n",
      "Iter-37330, train loss-1.9606, acc-0.4600, valid loss-1.9419, acc-0.4648, test loss-1.9427, acc-0.4547\n",
      "Iter-37340, train loss-1.9418, acc-0.4800, valid loss-1.9418, acc-0.4646, test loss-1.9427, acc-0.4547\n",
      "Iter-37350, train loss-1.9392, acc-0.4200, valid loss-1.9417, acc-0.4646, test loss-1.9426, acc-0.4550\n",
      "Iter-37360, train loss-1.9300, acc-0.3800, valid loss-1.9416, acc-0.4646, test loss-1.9425, acc-0.4550\n",
      "Iter-37370, train loss-1.9440, acc-0.4800, valid loss-1.9416, acc-0.4648, test loss-1.9425, acc-0.4550\n",
      "Iter-37380, train loss-1.8734, acc-0.5200, valid loss-1.9415, acc-0.4648, test loss-1.9424, acc-0.4547\n",
      "Iter-37390, train loss-1.9696, acc-0.5200, valid loss-1.9414, acc-0.4648, test loss-1.9423, acc-0.4549\n",
      "Iter-37400, train loss-1.9371, acc-0.3800, valid loss-1.9414, acc-0.4648, test loss-1.9423, acc-0.4549\n",
      "Iter-37410, train loss-1.9112, acc-0.4400, valid loss-1.9413, acc-0.4648, test loss-1.9422, acc-0.4549\n",
      "Iter-37420, train loss-2.0167, acc-0.3800, valid loss-1.9412, acc-0.4648, test loss-1.9421, acc-0.4551\n",
      "Iter-37430, train loss-2.0485, acc-0.2800, valid loss-1.9412, acc-0.4648, test loss-1.9420, acc-0.4550\n",
      "Iter-37440, train loss-1.9945, acc-0.4000, valid loss-1.9411, acc-0.4648, test loss-1.9420, acc-0.4552\n",
      "Iter-37450, train loss-1.9067, acc-0.4800, valid loss-1.9410, acc-0.4648, test loss-1.9419, acc-0.4553\n",
      "Iter-37460, train loss-1.9515, acc-0.4200, valid loss-1.9409, acc-0.4648, test loss-1.9418, acc-0.4554\n",
      "Iter-37470, train loss-1.9590, acc-0.4200, valid loss-1.9409, acc-0.4648, test loss-1.9418, acc-0.4555\n",
      "Iter-37480, train loss-1.9341, acc-0.5000, valid loss-1.9408, acc-0.4646, test loss-1.9417, acc-0.4554\n",
      "Iter-37490, train loss-1.9032, acc-0.4800, valid loss-1.9407, acc-0.4646, test loss-1.9416, acc-0.4556\n",
      "Iter-37500, train loss-1.8488, acc-0.5400, valid loss-1.9407, acc-0.4648, test loss-1.9415, acc-0.4556\n",
      "Iter-37510, train loss-1.9227, acc-0.4800, valid loss-1.9406, acc-0.4646, test loss-1.9415, acc-0.4556\n",
      "Iter-37520, train loss-1.9293, acc-0.4400, valid loss-1.9405, acc-0.4646, test loss-1.9414, acc-0.4558\n",
      "Iter-37530, train loss-1.9766, acc-0.5000, valid loss-1.9404, acc-0.4646, test loss-1.9413, acc-0.4560\n",
      "Iter-37540, train loss-1.8921, acc-0.5200, valid loss-1.9404, acc-0.4650, test loss-1.9413, acc-0.4557\n",
      "Iter-37550, train loss-1.9354, acc-0.4400, valid loss-1.9403, acc-0.4652, test loss-1.9412, acc-0.4558\n",
      "Iter-37560, train loss-1.9056, acc-0.6000, valid loss-1.9402, acc-0.4652, test loss-1.9411, acc-0.4559\n",
      "Iter-37570, train loss-1.9835, acc-0.3600, valid loss-1.9402, acc-0.4650, test loss-1.9411, acc-0.4559\n",
      "Iter-37580, train loss-1.8922, acc-0.5200, valid loss-1.9401, acc-0.4650, test loss-1.9410, acc-0.4558\n",
      "Iter-37590, train loss-1.9044, acc-0.4600, valid loss-1.9400, acc-0.4650, test loss-1.9409, acc-0.4557\n",
      "Iter-37600, train loss-1.9754, acc-0.4400, valid loss-1.9400, acc-0.4650, test loss-1.9408, acc-0.4559\n",
      "Iter-37610, train loss-1.9793, acc-0.3200, valid loss-1.9399, acc-0.4648, test loss-1.9408, acc-0.4558\n",
      "Iter-37620, train loss-1.9027, acc-0.5600, valid loss-1.9398, acc-0.4648, test loss-1.9407, acc-0.4559\n",
      "Iter-37630, train loss-1.9517, acc-0.5000, valid loss-1.9398, acc-0.4646, test loss-1.9406, acc-0.4559\n",
      "Iter-37640, train loss-1.8986, acc-0.4600, valid loss-1.9397, acc-0.4648, test loss-1.9406, acc-0.4559\n",
      "Iter-37650, train loss-1.9436, acc-0.5000, valid loss-1.9396, acc-0.4652, test loss-1.9405, acc-0.4559\n",
      "Iter-37660, train loss-2.0429, acc-0.4200, valid loss-1.9395, acc-0.4648, test loss-1.9404, acc-0.4559\n",
      "Iter-37670, train loss-1.9442, acc-0.4600, valid loss-1.9395, acc-0.4648, test loss-1.9404, acc-0.4555\n",
      "Iter-37680, train loss-1.9222, acc-0.4800, valid loss-1.9394, acc-0.4648, test loss-1.9403, acc-0.4557\n",
      "Iter-37690, train loss-1.9659, acc-0.4200, valid loss-1.9393, acc-0.4648, test loss-1.9402, acc-0.4558\n",
      "Iter-37700, train loss-1.9396, acc-0.4200, valid loss-1.9393, acc-0.4648, test loss-1.9401, acc-0.4559\n",
      "Iter-37710, train loss-1.8930, acc-0.4800, valid loss-1.9392, acc-0.4648, test loss-1.9401, acc-0.4559\n",
      "Iter-37720, train loss-1.9554, acc-0.4400, valid loss-1.9391, acc-0.4650, test loss-1.9400, acc-0.4558\n",
      "Iter-37730, train loss-1.9133, acc-0.5000, valid loss-1.9390, acc-0.4648, test loss-1.9399, acc-0.4559\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-37740, train loss-1.9580, acc-0.5400, valid loss-1.9390, acc-0.4650, test loss-1.9399, acc-0.4559\n",
      "Iter-37750, train loss-1.8555, acc-0.6600, valid loss-1.9389, acc-0.4650, test loss-1.9398, acc-0.4560\n",
      "Iter-37760, train loss-2.0212, acc-0.3600, valid loss-1.9388, acc-0.4654, test loss-1.9397, acc-0.4560\n",
      "Iter-37770, train loss-2.0246, acc-0.4000, valid loss-1.9388, acc-0.4654, test loss-1.9396, acc-0.4560\n",
      "Iter-37780, train loss-1.9817, acc-0.3800, valid loss-1.9387, acc-0.4652, test loss-1.9396, acc-0.4560\n",
      "Iter-37790, train loss-2.0673, acc-0.3000, valid loss-1.9386, acc-0.4652, test loss-1.9395, acc-0.4558\n",
      "Iter-37800, train loss-2.0664, acc-0.3400, valid loss-1.9386, acc-0.4652, test loss-1.9394, acc-0.4559\n",
      "Iter-37810, train loss-1.9196, acc-0.5600, valid loss-1.9385, acc-0.4654, test loss-1.9394, acc-0.4557\n",
      "Iter-37820, train loss-1.9517, acc-0.4200, valid loss-1.9384, acc-0.4654, test loss-1.9393, acc-0.4557\n",
      "Iter-37830, train loss-1.9886, acc-0.4200, valid loss-1.9383, acc-0.4656, test loss-1.9392, acc-0.4557\n",
      "Iter-37840, train loss-1.9797, acc-0.4200, valid loss-1.9383, acc-0.4656, test loss-1.9392, acc-0.4558\n",
      "Iter-37850, train loss-1.9495, acc-0.4400, valid loss-1.9382, acc-0.4660, test loss-1.9391, acc-0.4558\n",
      "Iter-37860, train loss-1.9803, acc-0.3400, valid loss-1.9381, acc-0.4658, test loss-1.9390, acc-0.4557\n",
      "Iter-37870, train loss-1.9715, acc-0.3600, valid loss-1.9381, acc-0.4658, test loss-1.9390, acc-0.4558\n",
      "Iter-37880, train loss-2.0443, acc-0.3600, valid loss-1.9380, acc-0.4662, test loss-1.9389, acc-0.4560\n",
      "Iter-37890, train loss-1.9683, acc-0.4400, valid loss-1.9379, acc-0.4662, test loss-1.9388, acc-0.4562\n",
      "Iter-37900, train loss-2.0102, acc-0.4000, valid loss-1.9379, acc-0.4664, test loss-1.9387, acc-0.4564\n",
      "Iter-37910, train loss-1.9571, acc-0.4000, valid loss-1.9378, acc-0.4664, test loss-1.9387, acc-0.4564\n",
      "Iter-37920, train loss-2.0296, acc-0.3000, valid loss-1.9377, acc-0.4660, test loss-1.9386, acc-0.4562\n",
      "Iter-37930, train loss-1.9264, acc-0.4600, valid loss-1.9376, acc-0.4658, test loss-1.9385, acc-0.4561\n",
      "Iter-37940, train loss-2.0341, acc-0.3800, valid loss-1.9376, acc-0.4660, test loss-1.9385, acc-0.4562\n",
      "Iter-37950, train loss-1.9742, acc-0.4000, valid loss-1.9375, acc-0.4660, test loss-1.9384, acc-0.4562\n",
      "Iter-37960, train loss-1.9475, acc-0.5000, valid loss-1.9374, acc-0.4658, test loss-1.9383, acc-0.4563\n",
      "Iter-37970, train loss-1.9630, acc-0.5200, valid loss-1.9374, acc-0.4662, test loss-1.9383, acc-0.4561\n",
      "Iter-37980, train loss-2.0160, acc-0.3800, valid loss-1.9373, acc-0.4662, test loss-1.9382, acc-0.4560\n",
      "Iter-37990, train loss-1.9590, acc-0.4800, valid loss-1.9372, acc-0.4662, test loss-1.9381, acc-0.4560\n",
      "Iter-38000, train loss-1.9276, acc-0.4600, valid loss-1.9372, acc-0.4664, test loss-1.9380, acc-0.4560\n",
      "Iter-38010, train loss-1.8942, acc-0.4400, valid loss-1.9371, acc-0.4660, test loss-1.9380, acc-0.4560\n",
      "Iter-38020, train loss-1.9585, acc-0.5200, valid loss-1.9370, acc-0.4662, test loss-1.9379, acc-0.4560\n",
      "Iter-38030, train loss-1.9642, acc-0.3400, valid loss-1.9369, acc-0.4666, test loss-1.9378, acc-0.4560\n",
      "Iter-38040, train loss-1.9263, acc-0.4200, valid loss-1.9369, acc-0.4668, test loss-1.9377, acc-0.4558\n",
      "Iter-38050, train loss-1.9319, acc-0.5200, valid loss-1.9368, acc-0.4670, test loss-1.9377, acc-0.4560\n",
      "Iter-38060, train loss-1.9516, acc-0.4800, valid loss-1.9367, acc-0.4670, test loss-1.9376, acc-0.4561\n",
      "Iter-38070, train loss-1.8731, acc-0.4800, valid loss-1.9367, acc-0.4670, test loss-1.9375, acc-0.4561\n",
      "Iter-38080, train loss-1.9352, acc-0.5200, valid loss-1.9366, acc-0.4666, test loss-1.9375, acc-0.4563\n",
      "Iter-38090, train loss-1.8898, acc-0.6400, valid loss-1.9365, acc-0.4668, test loss-1.9374, acc-0.4563\n",
      "Iter-38100, train loss-1.9351, acc-0.4200, valid loss-1.9365, acc-0.4668, test loss-1.9373, acc-0.4561\n",
      "Iter-38110, train loss-1.9648, acc-0.3200, valid loss-1.9364, acc-0.4668, test loss-1.9373, acc-0.4560\n",
      "Iter-38120, train loss-1.9407, acc-0.4800, valid loss-1.9363, acc-0.4666, test loss-1.9372, acc-0.4563\n",
      "Iter-38130, train loss-1.9217, acc-0.5200, valid loss-1.9363, acc-0.4666, test loss-1.9371, acc-0.4562\n",
      "Iter-38140, train loss-1.9753, acc-0.4400, valid loss-1.9362, acc-0.4670, test loss-1.9371, acc-0.4561\n",
      "Iter-38150, train loss-1.8978, acc-0.5400, valid loss-1.9361, acc-0.4668, test loss-1.9370, acc-0.4563\n",
      "Iter-38160, train loss-1.8973, acc-0.5200, valid loss-1.9361, acc-0.4666, test loss-1.9369, acc-0.4563\n",
      "Iter-38170, train loss-1.9295, acc-0.4600, valid loss-1.9360, acc-0.4668, test loss-1.9369, acc-0.4565\n",
      "Iter-38180, train loss-1.8886, acc-0.4600, valid loss-1.9359, acc-0.4666, test loss-1.9368, acc-0.4565\n",
      "Iter-38190, train loss-1.9994, acc-0.4000, valid loss-1.9358, acc-0.4668, test loss-1.9367, acc-0.4562\n",
      "Iter-38200, train loss-1.8688, acc-0.5800, valid loss-1.9358, acc-0.4666, test loss-1.9366, acc-0.4561\n",
      "Iter-38210, train loss-1.9341, acc-0.4600, valid loss-1.9357, acc-0.4670, test loss-1.9366, acc-0.4561\n",
      "Iter-38220, train loss-1.8886, acc-0.5000, valid loss-1.9356, acc-0.4668, test loss-1.9365, acc-0.4563\n",
      "Iter-38230, train loss-1.9747, acc-0.4000, valid loss-1.9356, acc-0.4668, test loss-1.9364, acc-0.4567\n",
      "Iter-38240, train loss-1.9177, acc-0.4000, valid loss-1.9355, acc-0.4666, test loss-1.9364, acc-0.4568\n",
      "Iter-38250, train loss-2.0058, acc-0.4200, valid loss-1.9354, acc-0.4668, test loss-1.9363, acc-0.4566\n",
      "Iter-38260, train loss-1.9220, acc-0.4800, valid loss-1.9354, acc-0.4668, test loss-1.9362, acc-0.4566\n",
      "Iter-38270, train loss-1.9400, acc-0.4400, valid loss-1.9353, acc-0.4668, test loss-1.9361, acc-0.4567\n",
      "Iter-38280, train loss-1.9285, acc-0.5400, valid loss-1.9352, acc-0.4666, test loss-1.9361, acc-0.4567\n",
      "Iter-38290, train loss-2.0279, acc-0.3800, valid loss-1.9351, acc-0.4666, test loss-1.9360, acc-0.4566\n",
      "Iter-38300, train loss-1.9219, acc-0.5000, valid loss-1.9351, acc-0.4666, test loss-1.9359, acc-0.4565\n",
      "Iter-38310, train loss-2.0028, acc-0.3000, valid loss-1.9350, acc-0.4666, test loss-1.9359, acc-0.4566\n",
      "Iter-38320, train loss-1.9171, acc-0.4000, valid loss-1.9349, acc-0.4668, test loss-1.9358, acc-0.4565\n",
      "Iter-38330, train loss-1.9303, acc-0.4800, valid loss-1.9349, acc-0.4666, test loss-1.9357, acc-0.4567\n",
      "Iter-38340, train loss-1.9535, acc-0.4400, valid loss-1.9348, acc-0.4666, test loss-1.9357, acc-0.4568\n",
      "Iter-38350, train loss-1.9630, acc-0.4800, valid loss-1.9347, acc-0.4666, test loss-1.9356, acc-0.4568\n",
      "Iter-38360, train loss-1.8637, acc-0.5600, valid loss-1.9347, acc-0.4666, test loss-1.9355, acc-0.4568\n",
      "Iter-38370, train loss-1.9773, acc-0.4400, valid loss-1.9346, acc-0.4668, test loss-1.9355, acc-0.4571\n",
      "Iter-38380, train loss-1.9088, acc-0.5200, valid loss-1.9345, acc-0.4668, test loss-1.9354, acc-0.4570\n",
      "Iter-38390, train loss-2.0130, acc-0.3800, valid loss-1.9345, acc-0.4672, test loss-1.9353, acc-0.4570\n",
      "Iter-38400, train loss-2.0120, acc-0.3400, valid loss-1.9344, acc-0.4668, test loss-1.9352, acc-0.4570\n",
      "Iter-38410, train loss-1.9150, acc-0.4400, valid loss-1.9343, acc-0.4670, test loss-1.9352, acc-0.4571\n",
      "Iter-38420, train loss-1.8962, acc-0.5000, valid loss-1.9343, acc-0.4672, test loss-1.9351, acc-0.4571\n",
      "Iter-38430, train loss-1.9288, acc-0.4800, valid loss-1.9342, acc-0.4674, test loss-1.9350, acc-0.4571\n",
      "Iter-38440, train loss-1.9898, acc-0.3800, valid loss-1.9341, acc-0.4674, test loss-1.9350, acc-0.4573\n",
      "Iter-38450, train loss-1.9594, acc-0.3600, valid loss-1.9341, acc-0.4674, test loss-1.9349, acc-0.4575\n",
      "Iter-38460, train loss-1.9311, acc-0.5200, valid loss-1.9340, acc-0.4676, test loss-1.9348, acc-0.4575\n",
      "Iter-38470, train loss-1.8929, acc-0.4400, valid loss-1.9339, acc-0.4676, test loss-1.9348, acc-0.4574\n",
      "Iter-38480, train loss-1.9907, acc-0.3400, valid loss-1.9339, acc-0.4676, test loss-1.9347, acc-0.4573\n",
      "Iter-38490, train loss-1.9266, acc-0.5000, valid loss-1.9338, acc-0.4674, test loss-1.9346, acc-0.4574\n",
      "Iter-38500, train loss-1.8794, acc-0.4800, valid loss-1.9337, acc-0.4676, test loss-1.9346, acc-0.4574\n",
      "Iter-38510, train loss-1.8848, acc-0.5000, valid loss-1.9336, acc-0.4672, test loss-1.9345, acc-0.4573\n",
      "Iter-38520, train loss-1.9928, acc-0.3600, valid loss-1.9336, acc-0.4676, test loss-1.9344, acc-0.4573\n",
      "Iter-38530, train loss-1.9154, acc-0.5000, valid loss-1.9335, acc-0.4670, test loss-1.9343, acc-0.4576\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-38540, train loss-1.8870, acc-0.4800, valid loss-1.9334, acc-0.4676, test loss-1.9343, acc-0.4579\n",
      "Iter-38550, train loss-1.8770, acc-0.5400, valid loss-1.9334, acc-0.4672, test loss-1.9342, acc-0.4578\n",
      "Iter-38560, train loss-1.8994, acc-0.4800, valid loss-1.9333, acc-0.4672, test loss-1.9341, acc-0.4576\n",
      "Iter-38570, train loss-1.8945, acc-0.5200, valid loss-1.9332, acc-0.4674, test loss-1.9341, acc-0.4578\n",
      "Iter-38580, train loss-1.9502, acc-0.5000, valid loss-1.9332, acc-0.4674, test loss-1.9340, acc-0.4578\n",
      "Iter-38590, train loss-1.9552, acc-0.4400, valid loss-1.9331, acc-0.4676, test loss-1.9339, acc-0.4580\n",
      "Iter-38600, train loss-1.8737, acc-0.5200, valid loss-1.9330, acc-0.4676, test loss-1.9339, acc-0.4578\n",
      "Iter-38610, train loss-1.8895, acc-0.4000, valid loss-1.9330, acc-0.4678, test loss-1.9338, acc-0.4578\n",
      "Iter-38620, train loss-1.8849, acc-0.6000, valid loss-1.9329, acc-0.4676, test loss-1.9337, acc-0.4577\n",
      "Iter-38630, train loss-1.9252, acc-0.4200, valid loss-1.9328, acc-0.4678, test loss-1.9336, acc-0.4576\n",
      "Iter-38640, train loss-1.9627, acc-0.4000, valid loss-1.9327, acc-0.4678, test loss-1.9336, acc-0.4577\n",
      "Iter-38650, train loss-1.9809, acc-0.5000, valid loss-1.9327, acc-0.4676, test loss-1.9335, acc-0.4579\n",
      "Iter-38660, train loss-1.9249, acc-0.4400, valid loss-1.9326, acc-0.4678, test loss-1.9334, acc-0.4580\n",
      "Iter-38670, train loss-1.9606, acc-0.4800, valid loss-1.9325, acc-0.4678, test loss-1.9334, acc-0.4581\n",
      "Iter-38680, train loss-1.9431, acc-0.4600, valid loss-1.9325, acc-0.4676, test loss-1.9333, acc-0.4583\n",
      "Iter-38690, train loss-1.9467, acc-0.4600, valid loss-1.9324, acc-0.4676, test loss-1.9333, acc-0.4581\n",
      "Iter-38700, train loss-1.9372, acc-0.4600, valid loss-1.9323, acc-0.4676, test loss-1.9332, acc-0.4583\n",
      "Iter-38710, train loss-1.9573, acc-0.5000, valid loss-1.9323, acc-0.4676, test loss-1.9331, acc-0.4581\n",
      "Iter-38720, train loss-1.9855, acc-0.4200, valid loss-1.9322, acc-0.4678, test loss-1.9330, acc-0.4581\n",
      "Iter-38730, train loss-1.8716, acc-0.5400, valid loss-1.9321, acc-0.4676, test loss-1.9330, acc-0.4584\n",
      "Iter-38740, train loss-1.9088, acc-0.5800, valid loss-1.9321, acc-0.4674, test loss-1.9329, acc-0.4583\n",
      "Iter-38750, train loss-1.9299, acc-0.4800, valid loss-1.9320, acc-0.4674, test loss-1.9328, acc-0.4583\n",
      "Iter-38760, train loss-1.8999, acc-0.4800, valid loss-1.9319, acc-0.4678, test loss-1.9328, acc-0.4584\n",
      "Iter-38770, train loss-2.0177, acc-0.3800, valid loss-1.9319, acc-0.4676, test loss-1.9327, acc-0.4584\n",
      "Iter-38780, train loss-1.9027, acc-0.5000, valid loss-1.9318, acc-0.4676, test loss-1.9326, acc-0.4583\n",
      "Iter-38790, train loss-1.9184, acc-0.4400, valid loss-1.9317, acc-0.4674, test loss-1.9326, acc-0.4582\n",
      "Iter-38800, train loss-2.0161, acc-0.4000, valid loss-1.9317, acc-0.4678, test loss-1.9325, acc-0.4583\n",
      "Iter-38810, train loss-1.9636, acc-0.3400, valid loss-1.9316, acc-0.4674, test loss-1.9324, acc-0.4584\n",
      "Iter-38820, train loss-1.9104, acc-0.5400, valid loss-1.9315, acc-0.4674, test loss-1.9323, acc-0.4583\n",
      "Iter-38830, train loss-1.9092, acc-0.5800, valid loss-1.9315, acc-0.4676, test loss-1.9323, acc-0.4585\n",
      "Iter-38840, train loss-1.9202, acc-0.5800, valid loss-1.9314, acc-0.4678, test loss-1.9322, acc-0.4584\n",
      "Iter-38850, train loss-1.8653, acc-0.6000, valid loss-1.9313, acc-0.4680, test loss-1.9321, acc-0.4585\n",
      "Iter-38860, train loss-1.9420, acc-0.4600, valid loss-1.9312, acc-0.4680, test loss-1.9321, acc-0.4584\n",
      "Iter-38870, train loss-1.9158, acc-0.4800, valid loss-1.9312, acc-0.4682, test loss-1.9320, acc-0.4584\n",
      "Iter-38880, train loss-1.9609, acc-0.4600, valid loss-1.9311, acc-0.4684, test loss-1.9319, acc-0.4586\n",
      "Iter-38890, train loss-2.0601, acc-0.2800, valid loss-1.9310, acc-0.4682, test loss-1.9319, acc-0.4588\n",
      "Iter-38900, train loss-2.0520, acc-0.3200, valid loss-1.9310, acc-0.4684, test loss-1.9318, acc-0.4588\n",
      "Iter-38910, train loss-1.9907, acc-0.4200, valid loss-1.9309, acc-0.4686, test loss-1.9317, acc-0.4589\n",
      "Iter-38920, train loss-1.9344, acc-0.4400, valid loss-1.9308, acc-0.4686, test loss-1.9317, acc-0.4591\n",
      "Iter-38930, train loss-1.9903, acc-0.4600, valid loss-1.9308, acc-0.4684, test loss-1.9316, acc-0.4590\n",
      "Iter-38940, train loss-1.9634, acc-0.4000, valid loss-1.9307, acc-0.4682, test loss-1.9315, acc-0.4589\n",
      "Iter-38950, train loss-1.9184, acc-0.5200, valid loss-1.9306, acc-0.4680, test loss-1.9315, acc-0.4590\n",
      "Iter-38960, train loss-1.9177, acc-0.5000, valid loss-1.9306, acc-0.4678, test loss-1.9314, acc-0.4589\n",
      "Iter-38970, train loss-1.8552, acc-0.5400, valid loss-1.9305, acc-0.4684, test loss-1.9313, acc-0.4588\n",
      "Iter-38980, train loss-1.8984, acc-0.5200, valid loss-1.9304, acc-0.4682, test loss-1.9312, acc-0.4589\n",
      "Iter-38990, train loss-1.9711, acc-0.4400, valid loss-1.9303, acc-0.4682, test loss-1.9312, acc-0.4591\n",
      "Iter-39000, train loss-1.9519, acc-0.5200, valid loss-1.9303, acc-0.4682, test loss-1.9311, acc-0.4589\n",
      "Iter-39010, train loss-1.9045, acc-0.4800, valid loss-1.9302, acc-0.4682, test loss-1.9310, acc-0.4587\n",
      "Iter-39020, train loss-1.9427, acc-0.4200, valid loss-1.9301, acc-0.4682, test loss-1.9310, acc-0.4590\n",
      "Iter-39030, train loss-1.8954, acc-0.4400, valid loss-1.9301, acc-0.4682, test loss-1.9309, acc-0.4588\n",
      "Iter-39040, train loss-1.9814, acc-0.3800, valid loss-1.9300, acc-0.4684, test loss-1.9308, acc-0.4586\n",
      "Iter-39050, train loss-1.9176, acc-0.4400, valid loss-1.9299, acc-0.4682, test loss-1.9308, acc-0.4586\n",
      "Iter-39060, train loss-1.8891, acc-0.5000, valid loss-1.9299, acc-0.4684, test loss-1.9307, acc-0.4588\n",
      "Iter-39070, train loss-2.0054, acc-0.3400, valid loss-1.9298, acc-0.4682, test loss-1.9306, acc-0.4588\n",
      "Iter-39080, train loss-1.9676, acc-0.4400, valid loss-1.9297, acc-0.4684, test loss-1.9306, acc-0.4586\n",
      "Iter-39090, train loss-1.9945, acc-0.3800, valid loss-1.9297, acc-0.4684, test loss-1.9305, acc-0.4586\n",
      "Iter-39100, train loss-1.9515, acc-0.4800, valid loss-1.9296, acc-0.4686, test loss-1.9304, acc-0.4586\n",
      "Iter-39110, train loss-1.9235, acc-0.4800, valid loss-1.9295, acc-0.4686, test loss-1.9304, acc-0.4588\n",
      "Iter-39120, train loss-1.9899, acc-0.4000, valid loss-1.9294, acc-0.4686, test loss-1.9303, acc-0.4590\n",
      "Iter-39130, train loss-1.9553, acc-0.5000, valid loss-1.9294, acc-0.4686, test loss-1.9302, acc-0.4587\n",
      "Iter-39140, train loss-2.0056, acc-0.3800, valid loss-1.9293, acc-0.4686, test loss-1.9301, acc-0.4588\n",
      "Iter-39150, train loss-1.9981, acc-0.4600, valid loss-1.9292, acc-0.4684, test loss-1.9301, acc-0.4590\n",
      "Iter-39160, train loss-1.8880, acc-0.5400, valid loss-1.9292, acc-0.4686, test loss-1.9300, acc-0.4591\n",
      "Iter-39170, train loss-1.9415, acc-0.4200, valid loss-1.9291, acc-0.4684, test loss-1.9299, acc-0.4590\n",
      "Iter-39180, train loss-1.9091, acc-0.4400, valid loss-1.9290, acc-0.4684, test loss-1.9299, acc-0.4591\n",
      "Iter-39190, train loss-1.9253, acc-0.3600, valid loss-1.9290, acc-0.4684, test loss-1.9298, acc-0.4589\n",
      "Iter-39200, train loss-1.9373, acc-0.5600, valid loss-1.9289, acc-0.4684, test loss-1.9297, acc-0.4590\n",
      "Iter-39210, train loss-1.9347, acc-0.4800, valid loss-1.9288, acc-0.4684, test loss-1.9297, acc-0.4591\n",
      "Iter-39220, train loss-1.9415, acc-0.4400, valid loss-1.9287, acc-0.4684, test loss-1.9296, acc-0.4589\n",
      "Iter-39230, train loss-1.9719, acc-0.3800, valid loss-1.9287, acc-0.4684, test loss-1.9295, acc-0.4592\n",
      "Iter-39240, train loss-1.9839, acc-0.4200, valid loss-1.9286, acc-0.4684, test loss-1.9295, acc-0.4590\n",
      "Iter-39250, train loss-1.9076, acc-0.4800, valid loss-1.9285, acc-0.4684, test loss-1.9294, acc-0.4589\n",
      "Iter-39260, train loss-1.9660, acc-0.4600, valid loss-1.9285, acc-0.4684, test loss-1.9293, acc-0.4589\n",
      "Iter-39270, train loss-1.9396, acc-0.4600, valid loss-1.9284, acc-0.4684, test loss-1.9293, acc-0.4591\n",
      "Iter-39280, train loss-1.9080, acc-0.4600, valid loss-1.9283, acc-0.4684, test loss-1.9292, acc-0.4587\n",
      "Iter-39290, train loss-1.9872, acc-0.4600, valid loss-1.9283, acc-0.4684, test loss-1.9291, acc-0.4585\n",
      "Iter-39300, train loss-1.8790, acc-0.5200, valid loss-1.9282, acc-0.4684, test loss-1.9291, acc-0.4583\n",
      "Iter-39310, train loss-1.9980, acc-0.4000, valid loss-1.9281, acc-0.4690, test loss-1.9290, acc-0.4587\n",
      "Iter-39320, train loss-1.9431, acc-0.3400, valid loss-1.9281, acc-0.4692, test loss-1.9289, acc-0.4586\n",
      "Iter-39330, train loss-1.9576, acc-0.3200, valid loss-1.9280, acc-0.4688, test loss-1.9289, acc-0.4588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-39340, train loss-2.0054, acc-0.4000, valid loss-1.9279, acc-0.4694, test loss-1.9288, acc-0.4590\n",
      "Iter-39350, train loss-1.9574, acc-0.3400, valid loss-1.9279, acc-0.4694, test loss-1.9287, acc-0.4587\n",
      "Iter-39360, train loss-1.8852, acc-0.4800, valid loss-1.9278, acc-0.4694, test loss-1.9287, acc-0.4588\n",
      "Iter-39370, train loss-1.9959, acc-0.3800, valid loss-1.9277, acc-0.4694, test loss-1.9286, acc-0.4588\n",
      "Iter-39380, train loss-1.9081, acc-0.5600, valid loss-1.9277, acc-0.4694, test loss-1.9285, acc-0.4588\n",
      "Iter-39390, train loss-1.9193, acc-0.5200, valid loss-1.9276, acc-0.4694, test loss-1.9285, acc-0.4589\n",
      "Iter-39400, train loss-1.9063, acc-0.4400, valid loss-1.9275, acc-0.4698, test loss-1.9284, acc-0.4587\n",
      "Iter-39410, train loss-1.8957, acc-0.4800, valid loss-1.9274, acc-0.4696, test loss-1.9283, acc-0.4586\n",
      "Iter-39420, train loss-1.9223, acc-0.4600, valid loss-1.9274, acc-0.4696, test loss-1.9282, acc-0.4586\n",
      "Iter-39430, train loss-1.9494, acc-0.4800, valid loss-1.9273, acc-0.4698, test loss-1.9282, acc-0.4586\n",
      "Iter-39440, train loss-1.8893, acc-0.5200, valid loss-1.9272, acc-0.4696, test loss-1.9281, acc-0.4586\n",
      "Iter-39450, train loss-1.8140, acc-0.5200, valid loss-1.9272, acc-0.4696, test loss-1.9280, acc-0.4587\n",
      "Iter-39460, train loss-1.9199, acc-0.5200, valid loss-1.9271, acc-0.4698, test loss-1.9280, acc-0.4588\n",
      "Iter-39470, train loss-1.9164, acc-0.4800, valid loss-1.9270, acc-0.4698, test loss-1.9279, acc-0.4591\n",
      "Iter-39480, train loss-1.9370, acc-0.5000, valid loss-1.9270, acc-0.4698, test loss-1.9278, acc-0.4592\n",
      "Iter-39490, train loss-1.9509, acc-0.3800, valid loss-1.9269, acc-0.4698, test loss-1.9278, acc-0.4588\n",
      "Iter-39500, train loss-1.8350, acc-0.5200, valid loss-1.9268, acc-0.4700, test loss-1.9277, acc-0.4587\n",
      "Iter-39510, train loss-2.0143, acc-0.3800, valid loss-1.9268, acc-0.4700, test loss-1.9276, acc-0.4589\n",
      "Iter-39520, train loss-1.8916, acc-0.5200, valid loss-1.9267, acc-0.4700, test loss-1.9276, acc-0.4588\n",
      "Iter-39530, train loss-1.9847, acc-0.4000, valid loss-1.9266, acc-0.4696, test loss-1.9275, acc-0.4590\n",
      "Iter-39540, train loss-1.9631, acc-0.3800, valid loss-1.9266, acc-0.4702, test loss-1.9274, acc-0.4590\n",
      "Iter-39550, train loss-1.9289, acc-0.5200, valid loss-1.9265, acc-0.4700, test loss-1.9274, acc-0.4589\n",
      "Iter-39560, train loss-1.9954, acc-0.3600, valid loss-1.9264, acc-0.4700, test loss-1.9273, acc-0.4589\n",
      "Iter-39570, train loss-1.9769, acc-0.4000, valid loss-1.9264, acc-0.4702, test loss-1.9272, acc-0.4588\n",
      "Iter-39580, train loss-1.9591, acc-0.4200, valid loss-1.9263, acc-0.4702, test loss-1.9272, acc-0.4587\n",
      "Iter-39590, train loss-1.9079, acc-0.5200, valid loss-1.9262, acc-0.4704, test loss-1.9271, acc-0.4588\n",
      "Iter-39600, train loss-1.9202, acc-0.4800, valid loss-1.9261, acc-0.4700, test loss-1.9270, acc-0.4587\n",
      "Iter-39610, train loss-2.0295, acc-0.3200, valid loss-1.9261, acc-0.4706, test loss-1.9270, acc-0.4587\n",
      "Iter-39620, train loss-1.9862, acc-0.4000, valid loss-1.9260, acc-0.4706, test loss-1.9269, acc-0.4588\n",
      "Iter-39630, train loss-1.9860, acc-0.3600, valid loss-1.9259, acc-0.4706, test loss-1.9268, acc-0.4589\n",
      "Iter-39640, train loss-1.8783, acc-0.5400, valid loss-1.9259, acc-0.4706, test loss-1.9268, acc-0.4588\n",
      "Iter-39650, train loss-1.9530, acc-0.4800, valid loss-1.9258, acc-0.4704, test loss-1.9267, acc-0.4589\n",
      "Iter-39660, train loss-1.9933, acc-0.3600, valid loss-1.9257, acc-0.4708, test loss-1.9266, acc-0.4589\n",
      "Iter-39670, train loss-1.9067, acc-0.5600, valid loss-1.9257, acc-0.4704, test loss-1.9265, acc-0.4589\n",
      "Iter-39680, train loss-1.8695, acc-0.4800, valid loss-1.9256, acc-0.4700, test loss-1.9265, acc-0.4590\n",
      "Iter-39690, train loss-2.0062, acc-0.3800, valid loss-1.9255, acc-0.4702, test loss-1.9264, acc-0.4588\n",
      "Iter-39700, train loss-1.8831, acc-0.4400, valid loss-1.9255, acc-0.4704, test loss-1.9263, acc-0.4588\n",
      "Iter-39710, train loss-1.9507, acc-0.4400, valid loss-1.9254, acc-0.4704, test loss-1.9263, acc-0.4589\n",
      "Iter-39720, train loss-1.8749, acc-0.5000, valid loss-1.9253, acc-0.4706, test loss-1.9262, acc-0.4591\n",
      "Iter-39730, train loss-1.9523, acc-0.3600, valid loss-1.9253, acc-0.4706, test loss-1.9261, acc-0.4591\n",
      "Iter-39740, train loss-1.9335, acc-0.3800, valid loss-1.9252, acc-0.4708, test loss-1.9261, acc-0.4591\n",
      "Iter-39750, train loss-2.0120, acc-0.4200, valid loss-1.9251, acc-0.4708, test loss-1.9260, acc-0.4592\n",
      "Iter-39760, train loss-1.9191, acc-0.4200, valid loss-1.9251, acc-0.4706, test loss-1.9259, acc-0.4590\n",
      "Iter-39770, train loss-1.9846, acc-0.4600, valid loss-1.9250, acc-0.4708, test loss-1.9259, acc-0.4593\n",
      "Iter-39780, train loss-1.9128, acc-0.4200, valid loss-1.9249, acc-0.4708, test loss-1.9258, acc-0.4593\n",
      "Iter-39790, train loss-1.9010, acc-0.5200, valid loss-1.9249, acc-0.4710, test loss-1.9257, acc-0.4593\n",
      "Iter-39800, train loss-1.9782, acc-0.3000, valid loss-1.9248, acc-0.4708, test loss-1.9257, acc-0.4595\n",
      "Iter-39810, train loss-1.9580, acc-0.5000, valid loss-1.9247, acc-0.4712, test loss-1.9256, acc-0.4593\n",
      "Iter-39820, train loss-1.9266, acc-0.4600, valid loss-1.9247, acc-0.4712, test loss-1.9255, acc-0.4594\n",
      "Iter-39830, train loss-2.0094, acc-0.4200, valid loss-1.9246, acc-0.4712, test loss-1.9255, acc-0.4593\n",
      "Iter-39840, train loss-1.9950, acc-0.4000, valid loss-1.9245, acc-0.4710, test loss-1.9254, acc-0.4597\n",
      "Iter-39850, train loss-1.9779, acc-0.3400, valid loss-1.9245, acc-0.4710, test loss-1.9253, acc-0.4595\n",
      "Iter-39860, train loss-1.8942, acc-0.4400, valid loss-1.9244, acc-0.4708, test loss-1.9253, acc-0.4595\n",
      "Iter-39870, train loss-1.9621, acc-0.4200, valid loss-1.9243, acc-0.4710, test loss-1.9252, acc-0.4595\n",
      "Iter-39880, train loss-1.8897, acc-0.5000, valid loss-1.9242, acc-0.4710, test loss-1.9251, acc-0.4593\n",
      "Iter-39890, train loss-1.9059, acc-0.5200, valid loss-1.9242, acc-0.4710, test loss-1.9251, acc-0.4597\n",
      "Iter-39900, train loss-1.9462, acc-0.4600, valid loss-1.9241, acc-0.4710, test loss-1.9250, acc-0.4597\n",
      "Iter-39910, train loss-1.9265, acc-0.5200, valid loss-1.9240, acc-0.4712, test loss-1.9249, acc-0.4597\n",
      "Iter-39920, train loss-2.0058, acc-0.3400, valid loss-1.9240, acc-0.4710, test loss-1.9249, acc-0.4599\n",
      "Iter-39930, train loss-1.9045, acc-0.4200, valid loss-1.9239, acc-0.4712, test loss-1.9248, acc-0.4601\n",
      "Iter-39940, train loss-1.9066, acc-0.4400, valid loss-1.9238, acc-0.4714, test loss-1.9247, acc-0.4599\n",
      "Iter-39950, train loss-1.8992, acc-0.5200, valid loss-1.9238, acc-0.4714, test loss-1.9247, acc-0.4600\n",
      "Iter-39960, train loss-1.9859, acc-0.3800, valid loss-1.9237, acc-0.4714, test loss-1.9246, acc-0.4600\n",
      "Iter-39970, train loss-1.8922, acc-0.4400, valid loss-1.9236, acc-0.4714, test loss-1.9245, acc-0.4601\n",
      "Iter-39980, train loss-1.9325, acc-0.4200, valid loss-1.9236, acc-0.4714, test loss-1.9245, acc-0.4600\n",
      "Iter-39990, train loss-1.8954, acc-0.5600, valid loss-1.9235, acc-0.4714, test loss-1.9244, acc-0.4599\n",
      "Iter-40000, train loss-1.9085, acc-0.5400, valid loss-1.9234, acc-0.4714, test loss-1.9243, acc-0.4600\n",
      "Iter-40010, train loss-1.8894, acc-0.4600, valid loss-1.9234, acc-0.4712, test loss-1.9243, acc-0.4600\n",
      "Iter-40020, train loss-1.9480, acc-0.4400, valid loss-1.9233, acc-0.4714, test loss-1.9242, acc-0.4601\n",
      "Iter-40030, train loss-1.9046, acc-0.5200, valid loss-1.9232, acc-0.4712, test loss-1.9241, acc-0.4601\n",
      "Iter-40040, train loss-1.9385, acc-0.5400, valid loss-1.9232, acc-0.4712, test loss-1.9241, acc-0.4603\n",
      "Iter-40050, train loss-1.9930, acc-0.3800, valid loss-1.9231, acc-0.4712, test loss-1.9240, acc-0.4602\n",
      "Iter-40060, train loss-1.8930, acc-0.5000, valid loss-1.9230, acc-0.4714, test loss-1.9239, acc-0.4604\n",
      "Iter-40070, train loss-1.9142, acc-0.5000, valid loss-1.9230, acc-0.4714, test loss-1.9239, acc-0.4603\n",
      "Iter-40080, train loss-1.9649, acc-0.5000, valid loss-1.9229, acc-0.4714, test loss-1.9238, acc-0.4603\n",
      "Iter-40090, train loss-1.9654, acc-0.4600, valid loss-1.9228, acc-0.4716, test loss-1.9237, acc-0.4604\n",
      "Iter-40100, train loss-1.9578, acc-0.4600, valid loss-1.9228, acc-0.4716, test loss-1.9237, acc-0.4603\n",
      "Iter-40110, train loss-1.8623, acc-0.5400, valid loss-1.9227, acc-0.4716, test loss-1.9236, acc-0.4604\n",
      "Iter-40120, train loss-1.9404, acc-0.5400, valid loss-1.9226, acc-0.4718, test loss-1.9235, acc-0.4605\n",
      "Iter-40130, train loss-1.9257, acc-0.5000, valid loss-1.9226, acc-0.4714, test loss-1.9234, acc-0.4608\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40140, train loss-1.8686, acc-0.5600, valid loss-1.9225, acc-0.4718, test loss-1.9234, acc-0.4606\n",
      "Iter-40150, train loss-1.8957, acc-0.5000, valid loss-1.9224, acc-0.4716, test loss-1.9233, acc-0.4605\n",
      "Iter-40160, train loss-1.8544, acc-0.5400, valid loss-1.9224, acc-0.4716, test loss-1.9232, acc-0.4606\n",
      "Iter-40170, train loss-1.8820, acc-0.6400, valid loss-1.9223, acc-0.4716, test loss-1.9232, acc-0.4608\n",
      "Iter-40180, train loss-1.9878, acc-0.3200, valid loss-1.9222, acc-0.4716, test loss-1.9231, acc-0.4605\n",
      "Iter-40190, train loss-1.9289, acc-0.4200, valid loss-1.9222, acc-0.4716, test loss-1.9230, acc-0.4603\n",
      "Iter-40200, train loss-1.9053, acc-0.4800, valid loss-1.9221, acc-0.4716, test loss-1.9230, acc-0.4604\n",
      "Iter-40210, train loss-1.9420, acc-0.5200, valid loss-1.9220, acc-0.4718, test loss-1.9229, acc-0.4609\n",
      "Iter-40220, train loss-1.8893, acc-0.4800, valid loss-1.9220, acc-0.4718, test loss-1.9228, acc-0.4608\n",
      "Iter-40230, train loss-1.9316, acc-0.5600, valid loss-1.9219, acc-0.4718, test loss-1.9228, acc-0.4607\n",
      "Iter-40240, train loss-1.9572, acc-0.4400, valid loss-1.9218, acc-0.4720, test loss-1.9227, acc-0.4608\n",
      "Iter-40250, train loss-1.9740, acc-0.3800, valid loss-1.9217, acc-0.4720, test loss-1.9226, acc-0.4610\n",
      "Iter-40260, train loss-1.9325, acc-0.4400, valid loss-1.9217, acc-0.4720, test loss-1.9226, acc-0.4609\n",
      "Iter-40270, train loss-1.9350, acc-0.4600, valid loss-1.9216, acc-0.4720, test loss-1.9225, acc-0.4610\n",
      "Iter-40280, train loss-1.9128, acc-0.5000, valid loss-1.9215, acc-0.4720, test loss-1.9224, acc-0.4611\n",
      "Iter-40290, train loss-1.9566, acc-0.3600, valid loss-1.9215, acc-0.4720, test loss-1.9224, acc-0.4611\n",
      "Iter-40300, train loss-1.8846, acc-0.5800, valid loss-1.9214, acc-0.4718, test loss-1.9223, acc-0.4609\n",
      "Iter-40310, train loss-1.8876, acc-0.5000, valid loss-1.9213, acc-0.4720, test loss-1.9222, acc-0.4610\n",
      "Iter-40320, train loss-1.8893, acc-0.5000, valid loss-1.9213, acc-0.4722, test loss-1.9222, acc-0.4609\n",
      "Iter-40330, train loss-1.8805, acc-0.5400, valid loss-1.9212, acc-0.4720, test loss-1.9221, acc-0.4610\n",
      "Iter-40340, train loss-1.9249, acc-0.4200, valid loss-1.9211, acc-0.4720, test loss-1.9220, acc-0.4612\n",
      "Iter-40350, train loss-1.9580, acc-0.4400, valid loss-1.9211, acc-0.4718, test loss-1.9220, acc-0.4615\n",
      "Iter-40360, train loss-1.9674, acc-0.4800, valid loss-1.9210, acc-0.4716, test loss-1.9219, acc-0.4612\n",
      "Iter-40370, train loss-1.9361, acc-0.4000, valid loss-1.9209, acc-0.4720, test loss-1.9218, acc-0.4614\n",
      "Iter-40380, train loss-1.9967, acc-0.4800, valid loss-1.9209, acc-0.4720, test loss-1.9218, acc-0.4613\n",
      "Iter-40390, train loss-2.0055, acc-0.3800, valid loss-1.9208, acc-0.4718, test loss-1.9217, acc-0.4612\n",
      "Iter-40400, train loss-1.9025, acc-0.4800, valid loss-1.9207, acc-0.4718, test loss-1.9216, acc-0.4613\n",
      "Iter-40410, train loss-1.8837, acc-0.4600, valid loss-1.9207, acc-0.4720, test loss-1.9216, acc-0.4614\n",
      "Iter-40420, train loss-1.9780, acc-0.3600, valid loss-1.9206, acc-0.4718, test loss-1.9215, acc-0.4617\n",
      "Iter-40430, train loss-1.9226, acc-0.4600, valid loss-1.9205, acc-0.4722, test loss-1.9214, acc-0.4618\n",
      "Iter-40440, train loss-1.9336, acc-0.4800, valid loss-1.9205, acc-0.4720, test loss-1.9214, acc-0.4618\n",
      "Iter-40450, train loss-1.8989, acc-0.4000, valid loss-1.9204, acc-0.4722, test loss-1.9213, acc-0.4616\n",
      "Iter-40460, train loss-1.9542, acc-0.4600, valid loss-1.9203, acc-0.4720, test loss-1.9212, acc-0.4616\n",
      "Iter-40470, train loss-2.0434, acc-0.3800, valid loss-1.9203, acc-0.4720, test loss-1.9212, acc-0.4617\n",
      "Iter-40480, train loss-1.9172, acc-0.5400, valid loss-1.9202, acc-0.4720, test loss-1.9211, acc-0.4616\n",
      "Iter-40490, train loss-1.8650, acc-0.5000, valid loss-1.9201, acc-0.4720, test loss-1.9210, acc-0.4615\n",
      "Iter-40500, train loss-1.9316, acc-0.4600, valid loss-1.9201, acc-0.4720, test loss-1.9210, acc-0.4615\n",
      "Iter-40510, train loss-1.9742, acc-0.4600, valid loss-1.9200, acc-0.4720, test loss-1.9209, acc-0.4617\n",
      "Iter-40520, train loss-1.9591, acc-0.3800, valid loss-1.9199, acc-0.4720, test loss-1.9208, acc-0.4619\n",
      "Iter-40530, train loss-1.9846, acc-0.3400, valid loss-1.9199, acc-0.4720, test loss-1.9208, acc-0.4620\n",
      "Iter-40540, train loss-1.8443, acc-0.5800, valid loss-1.9198, acc-0.4722, test loss-1.9207, acc-0.4620\n",
      "Iter-40550, train loss-1.9922, acc-0.3000, valid loss-1.9197, acc-0.4720, test loss-1.9206, acc-0.4620\n",
      "Iter-40560, train loss-1.8364, acc-0.5600, valid loss-1.9197, acc-0.4722, test loss-1.9206, acc-0.4619\n",
      "Iter-40570, train loss-1.9232, acc-0.5200, valid loss-1.9196, acc-0.4720, test loss-1.9205, acc-0.4618\n",
      "Iter-40580, train loss-1.9175, acc-0.5000, valid loss-1.9195, acc-0.4720, test loss-1.9204, acc-0.4619\n",
      "Iter-40590, train loss-1.9553, acc-0.4400, valid loss-1.9195, acc-0.4720, test loss-1.9204, acc-0.4623\n",
      "Iter-40600, train loss-1.8035, acc-0.6600, valid loss-1.9194, acc-0.4720, test loss-1.9203, acc-0.4622\n",
      "Iter-40610, train loss-1.9045, acc-0.6200, valid loss-1.9193, acc-0.4720, test loss-1.9202, acc-0.4620\n",
      "Iter-40620, train loss-1.9531, acc-0.4600, valid loss-1.9193, acc-0.4720, test loss-1.9202, acc-0.4622\n",
      "Iter-40630, train loss-1.9121, acc-0.5800, valid loss-1.9192, acc-0.4720, test loss-1.9201, acc-0.4622\n",
      "Iter-40640, train loss-1.9879, acc-0.4000, valid loss-1.9191, acc-0.4722, test loss-1.9200, acc-0.4620\n",
      "Iter-40650, train loss-1.9612, acc-0.4000, valid loss-1.9191, acc-0.4720, test loss-1.9200, acc-0.4624\n",
      "Iter-40660, train loss-1.9562, acc-0.3400, valid loss-1.9190, acc-0.4720, test loss-1.9199, acc-0.4622\n",
      "Iter-40670, train loss-1.9404, acc-0.3600, valid loss-1.9189, acc-0.4722, test loss-1.9198, acc-0.4623\n",
      "Iter-40680, train loss-1.9473, acc-0.5600, valid loss-1.9189, acc-0.4722, test loss-1.9198, acc-0.4622\n",
      "Iter-40690, train loss-1.8242, acc-0.5600, valid loss-1.9188, acc-0.4722, test loss-1.9197, acc-0.4626\n",
      "Iter-40700, train loss-1.9955, acc-0.3000, valid loss-1.9187, acc-0.4722, test loss-1.9196, acc-0.4622\n",
      "Iter-40710, train loss-1.9525, acc-0.5000, valid loss-1.9187, acc-0.4722, test loss-1.9196, acc-0.4623\n",
      "Iter-40720, train loss-1.8956, acc-0.5000, valid loss-1.9186, acc-0.4720, test loss-1.9195, acc-0.4622\n",
      "Iter-40730, train loss-1.9585, acc-0.4400, valid loss-1.9185, acc-0.4720, test loss-1.9194, acc-0.4624\n",
      "Iter-40740, train loss-1.9536, acc-0.5400, valid loss-1.9185, acc-0.4722, test loss-1.9194, acc-0.4629\n",
      "Iter-40750, train loss-1.9632, acc-0.4200, valid loss-1.9184, acc-0.4720, test loss-1.9193, acc-0.4628\n",
      "Iter-40760, train loss-1.9798, acc-0.3800, valid loss-1.9183, acc-0.4724, test loss-1.9192, acc-0.4627\n",
      "Iter-40770, train loss-1.9111, acc-0.3800, valid loss-1.9183, acc-0.4724, test loss-1.9192, acc-0.4628\n",
      "Iter-40780, train loss-1.9521, acc-0.4600, valid loss-1.9182, acc-0.4722, test loss-1.9191, acc-0.4631\n",
      "Iter-40790, train loss-1.9451, acc-0.4600, valid loss-1.9181, acc-0.4724, test loss-1.9190, acc-0.4630\n",
      "Iter-40800, train loss-1.9381, acc-0.4400, valid loss-1.9181, acc-0.4722, test loss-1.9190, acc-0.4631\n",
      "Iter-40810, train loss-2.0042, acc-0.4000, valid loss-1.9180, acc-0.4720, test loss-1.9189, acc-0.4630\n",
      "Iter-40820, train loss-1.8604, acc-0.5000, valid loss-1.9179, acc-0.4724, test loss-1.9188, acc-0.4630\n",
      "Iter-40830, train loss-1.8547, acc-0.4400, valid loss-1.9179, acc-0.4726, test loss-1.9188, acc-0.4628\n",
      "Iter-40840, train loss-1.9660, acc-0.4400, valid loss-1.9178, acc-0.4726, test loss-1.9187, acc-0.4627\n",
      "Iter-40850, train loss-2.0262, acc-0.3600, valid loss-1.9177, acc-0.4726, test loss-1.9186, acc-0.4626\n",
      "Iter-40860, train loss-1.9082, acc-0.4600, valid loss-1.9177, acc-0.4724, test loss-1.9186, acc-0.4629\n",
      "Iter-40870, train loss-1.9095, acc-0.4400, valid loss-1.9176, acc-0.4726, test loss-1.9185, acc-0.4628\n",
      "Iter-40880, train loss-1.9067, acc-0.4600, valid loss-1.9175, acc-0.4730, test loss-1.9184, acc-0.4630\n",
      "Iter-40890, train loss-1.8933, acc-0.4000, valid loss-1.9175, acc-0.4730, test loss-1.9184, acc-0.4629\n",
      "Iter-40900, train loss-1.9072, acc-0.4800, valid loss-1.9174, acc-0.4728, test loss-1.9183, acc-0.4627\n",
      "Iter-40910, train loss-1.8913, acc-0.4200, valid loss-1.9173, acc-0.4726, test loss-1.9182, acc-0.4629\n",
      "Iter-40920, train loss-1.8454, acc-0.5200, valid loss-1.9173, acc-0.4730, test loss-1.9182, acc-0.4628\n",
      "Iter-40930, train loss-1.8973, acc-0.4600, valid loss-1.9172, acc-0.4732, test loss-1.9181, acc-0.4627\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-40940, train loss-1.8572, acc-0.5600, valid loss-1.9171, acc-0.4734, test loss-1.9180, acc-0.4628\n",
      "Iter-40950, train loss-1.9556, acc-0.4800, valid loss-1.9171, acc-0.4732, test loss-1.9180, acc-0.4628\n",
      "Iter-40960, train loss-1.8660, acc-0.5200, valid loss-1.9170, acc-0.4730, test loss-1.9179, acc-0.4628\n",
      "Iter-40970, train loss-1.8464, acc-0.5400, valid loss-1.9169, acc-0.4728, test loss-1.9178, acc-0.4628\n",
      "Iter-40980, train loss-1.8948, acc-0.5400, valid loss-1.9169, acc-0.4730, test loss-1.9178, acc-0.4628\n",
      "Iter-40990, train loss-1.9215, acc-0.4200, valid loss-1.9168, acc-0.4730, test loss-1.9177, acc-0.4629\n",
      "Iter-41000, train loss-1.9442, acc-0.4600, valid loss-1.9167, acc-0.4730, test loss-1.9176, acc-0.4628\n",
      "Iter-41010, train loss-1.8533, acc-0.5000, valid loss-1.9167, acc-0.4730, test loss-1.9176, acc-0.4629\n",
      "Iter-41020, train loss-1.9759, acc-0.4000, valid loss-1.9166, acc-0.4730, test loss-1.9175, acc-0.4629\n",
      "Iter-41030, train loss-1.9381, acc-0.4400, valid loss-1.9165, acc-0.4728, test loss-1.9174, acc-0.4627\n",
      "Iter-41040, train loss-1.9233, acc-0.4400, valid loss-1.9165, acc-0.4728, test loss-1.9174, acc-0.4630\n",
      "Iter-41050, train loss-1.9488, acc-0.4400, valid loss-1.9164, acc-0.4732, test loss-1.9173, acc-0.4628\n",
      "Iter-41060, train loss-1.9275, acc-0.4600, valid loss-1.9163, acc-0.4728, test loss-1.9172, acc-0.4628\n",
      "Iter-41070, train loss-1.8911, acc-0.5200, valid loss-1.9163, acc-0.4730, test loss-1.9172, acc-0.4629\n",
      "Iter-41080, train loss-1.9766, acc-0.5000, valid loss-1.9162, acc-0.4730, test loss-1.9171, acc-0.4629\n",
      "Iter-41090, train loss-1.9369, acc-0.4600, valid loss-1.9161, acc-0.4730, test loss-1.9170, acc-0.4629\n",
      "Iter-41100, train loss-2.0241, acc-0.3600, valid loss-1.9161, acc-0.4732, test loss-1.9170, acc-0.4631\n",
      "Iter-41110, train loss-1.8755, acc-0.5400, valid loss-1.9160, acc-0.4730, test loss-1.9169, acc-0.4631\n",
      "Iter-41120, train loss-1.9377, acc-0.5000, valid loss-1.9159, acc-0.4732, test loss-1.9168, acc-0.4628\n",
      "Iter-41130, train loss-1.9647, acc-0.4400, valid loss-1.9159, acc-0.4732, test loss-1.9168, acc-0.4629\n",
      "Iter-41140, train loss-1.8652, acc-0.5200, valid loss-1.9158, acc-0.4732, test loss-1.9167, acc-0.4629\n",
      "Iter-41150, train loss-1.9725, acc-0.3800, valid loss-1.9157, acc-0.4732, test loss-1.9166, acc-0.4630\n",
      "Iter-41160, train loss-1.9630, acc-0.4200, valid loss-1.9157, acc-0.4732, test loss-1.9166, acc-0.4629\n",
      "Iter-41170, train loss-1.9565, acc-0.4200, valid loss-1.9156, acc-0.4734, test loss-1.9165, acc-0.4630\n",
      "Iter-41180, train loss-1.8045, acc-0.6000, valid loss-1.9155, acc-0.4734, test loss-1.9164, acc-0.4630\n",
      "Iter-41190, train loss-1.9608, acc-0.4600, valid loss-1.9155, acc-0.4734, test loss-1.9164, acc-0.4631\n",
      "Iter-41200, train loss-1.9077, acc-0.5200, valid loss-1.9154, acc-0.4734, test loss-1.9163, acc-0.4631\n",
      "Iter-41210, train loss-1.9492, acc-0.3400, valid loss-1.9153, acc-0.4732, test loss-1.9162, acc-0.4632\n",
      "Iter-41220, train loss-1.9031, acc-0.5600, valid loss-1.9153, acc-0.4734, test loss-1.9162, acc-0.4633\n",
      "Iter-41230, train loss-1.8603, acc-0.4400, valid loss-1.9152, acc-0.4730, test loss-1.9161, acc-0.4633\n",
      "Iter-41240, train loss-1.9390, acc-0.3800, valid loss-1.9151, acc-0.4730, test loss-1.9160, acc-0.4633\n",
      "Iter-41250, train loss-1.9327, acc-0.4400, valid loss-1.9151, acc-0.4732, test loss-1.9160, acc-0.4635\n",
      "Iter-41260, train loss-1.9836, acc-0.3600, valid loss-1.9150, acc-0.4732, test loss-1.9159, acc-0.4635\n",
      "Iter-41270, train loss-1.9090, acc-0.4400, valid loss-1.9149, acc-0.4732, test loss-1.9158, acc-0.4637\n",
      "Iter-41280, train loss-1.9046, acc-0.4400, valid loss-1.9149, acc-0.4730, test loss-1.9158, acc-0.4636\n",
      "Iter-41290, train loss-1.9507, acc-0.5000, valid loss-1.9148, acc-0.4732, test loss-1.9157, acc-0.4634\n",
      "Iter-41300, train loss-1.9184, acc-0.5400, valid loss-1.9148, acc-0.4730, test loss-1.9156, acc-0.4635\n",
      "Iter-41310, train loss-1.9708, acc-0.3400, valid loss-1.9147, acc-0.4730, test loss-1.9156, acc-0.4638\n",
      "Iter-41320, train loss-1.9453, acc-0.4800, valid loss-1.9146, acc-0.4730, test loss-1.9155, acc-0.4638\n",
      "Iter-41330, train loss-1.8910, acc-0.4200, valid loss-1.9146, acc-0.4730, test loss-1.9154, acc-0.4637\n",
      "Iter-41340, train loss-1.9259, acc-0.4000, valid loss-1.9145, acc-0.4730, test loss-1.9154, acc-0.4639\n",
      "Iter-41350, train loss-1.8929, acc-0.4400, valid loss-1.9144, acc-0.4732, test loss-1.9153, acc-0.4636\n",
      "Iter-41360, train loss-2.0034, acc-0.5000, valid loss-1.9144, acc-0.4732, test loss-1.9152, acc-0.4636\n",
      "Iter-41370, train loss-1.9191, acc-0.3800, valid loss-1.9143, acc-0.4732, test loss-1.9152, acc-0.4635\n",
      "Iter-41380, train loss-1.8558, acc-0.5200, valid loss-1.9142, acc-0.4730, test loss-1.9151, acc-0.4637\n",
      "Iter-41390, train loss-1.9867, acc-0.4000, valid loss-1.9142, acc-0.4730, test loss-1.9151, acc-0.4637\n",
      "Iter-41400, train loss-1.9359, acc-0.5000, valid loss-1.9141, acc-0.4730, test loss-1.9150, acc-0.4636\n",
      "Iter-41410, train loss-1.9150, acc-0.4800, valid loss-1.9140, acc-0.4730, test loss-1.9149, acc-0.4638\n",
      "Iter-41420, train loss-1.9295, acc-0.4400, valid loss-1.9140, acc-0.4730, test loss-1.9148, acc-0.4635\n",
      "Iter-41430, train loss-1.9399, acc-0.4800, valid loss-1.9139, acc-0.4732, test loss-1.9148, acc-0.4636\n",
      "Iter-41440, train loss-1.9300, acc-0.4800, valid loss-1.9138, acc-0.4730, test loss-1.9147, acc-0.4637\n",
      "Iter-41450, train loss-1.9114, acc-0.5400, valid loss-1.9138, acc-0.4734, test loss-1.9147, acc-0.4639\n",
      "Iter-41460, train loss-1.8880, acc-0.5600, valid loss-1.9137, acc-0.4732, test loss-1.9146, acc-0.4638\n",
      "Iter-41470, train loss-1.9051, acc-0.5000, valid loss-1.9136, acc-0.4734, test loss-1.9145, acc-0.4638\n",
      "Iter-41480, train loss-1.9090, acc-0.4200, valid loss-1.9135, acc-0.4734, test loss-1.9144, acc-0.4638\n",
      "Iter-41490, train loss-1.9052, acc-0.4000, valid loss-1.9135, acc-0.4734, test loss-1.9144, acc-0.4639\n",
      "Iter-41500, train loss-1.9823, acc-0.4200, valid loss-1.9134, acc-0.4732, test loss-1.9143, acc-0.4637\n",
      "Iter-41510, train loss-1.9332, acc-0.3400, valid loss-1.9134, acc-0.4732, test loss-1.9143, acc-0.4637\n",
      "Iter-41520, train loss-1.8748, acc-0.5400, valid loss-1.9133, acc-0.4732, test loss-1.9142, acc-0.4641\n",
      "Iter-41530, train loss-1.9665, acc-0.4600, valid loss-1.9132, acc-0.4734, test loss-1.9141, acc-0.4640\n",
      "Iter-41540, train loss-1.8903, acc-0.5800, valid loss-1.9132, acc-0.4734, test loss-1.9141, acc-0.4640\n",
      "Iter-41550, train loss-1.8467, acc-0.6000, valid loss-1.9131, acc-0.4732, test loss-1.9140, acc-0.4643\n",
      "Iter-41560, train loss-1.8928, acc-0.4600, valid loss-1.9130, acc-0.4734, test loss-1.9139, acc-0.4642\n",
      "Iter-41570, train loss-1.8411, acc-0.5400, valid loss-1.9130, acc-0.4732, test loss-1.9139, acc-0.4640\n",
      "Iter-41580, train loss-1.9709, acc-0.3800, valid loss-1.9129, acc-0.4732, test loss-1.9138, acc-0.4641\n",
      "Iter-41590, train loss-1.8156, acc-0.5400, valid loss-1.9128, acc-0.4734, test loss-1.9137, acc-0.4643\n",
      "Iter-41600, train loss-1.8982, acc-0.4000, valid loss-1.9128, acc-0.4730, test loss-1.9137, acc-0.4644\n",
      "Iter-41610, train loss-1.8966, acc-0.4800, valid loss-1.9127, acc-0.4728, test loss-1.9136, acc-0.4642\n",
      "Iter-41620, train loss-1.8882, acc-0.4800, valid loss-1.9126, acc-0.4730, test loss-1.9135, acc-0.4643\n",
      "Iter-41630, train loss-1.8940, acc-0.4800, valid loss-1.9126, acc-0.4732, test loss-1.9135, acc-0.4642\n",
      "Iter-41640, train loss-1.9337, acc-0.5000, valid loss-1.9125, acc-0.4732, test loss-1.9134, acc-0.4642\n",
      "Iter-41650, train loss-1.9361, acc-0.4600, valid loss-1.9124, acc-0.4732, test loss-1.9133, acc-0.4643\n",
      "Iter-41660, train loss-1.9352, acc-0.5200, valid loss-1.9124, acc-0.4734, test loss-1.9133, acc-0.4643\n",
      "Iter-41670, train loss-1.8716, acc-0.5000, valid loss-1.9123, acc-0.4732, test loss-1.9132, acc-0.4644\n",
      "Iter-41680, train loss-1.9164, acc-0.5000, valid loss-1.9122, acc-0.4732, test loss-1.9131, acc-0.4644\n",
      "Iter-41690, train loss-1.8915, acc-0.5400, valid loss-1.9122, acc-0.4732, test loss-1.9131, acc-0.4643\n",
      "Iter-41700, train loss-1.9170, acc-0.5000, valid loss-1.9121, acc-0.4734, test loss-1.9130, acc-0.4642\n",
      "Iter-41710, train loss-1.9364, acc-0.4800, valid loss-1.9120, acc-0.4732, test loss-1.9129, acc-0.4642\n",
      "Iter-41720, train loss-1.9749, acc-0.4200, valid loss-1.9120, acc-0.4732, test loss-1.9129, acc-0.4642\n",
      "Iter-41730, train loss-1.8745, acc-0.5200, valid loss-1.9119, acc-0.4732, test loss-1.9128, acc-0.4643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-41740, train loss-1.8951, acc-0.5200, valid loss-1.9118, acc-0.4730, test loss-1.9127, acc-0.4643\n",
      "Iter-41750, train loss-1.8654, acc-0.4400, valid loss-1.9118, acc-0.4732, test loss-1.9127, acc-0.4643\n",
      "Iter-41760, train loss-1.8963, acc-0.4600, valid loss-1.9117, acc-0.4732, test loss-1.9126, acc-0.4647\n",
      "Iter-41770, train loss-1.8669, acc-0.5000, valid loss-1.9116, acc-0.4734, test loss-1.9125, acc-0.4647\n",
      "Iter-41780, train loss-1.9233, acc-0.4800, valid loss-1.9116, acc-0.4732, test loss-1.9125, acc-0.4646\n",
      "Iter-41790, train loss-1.8801, acc-0.4600, valid loss-1.9115, acc-0.4734, test loss-1.9124, acc-0.4647\n",
      "Iter-41800, train loss-1.9343, acc-0.5000, valid loss-1.9114, acc-0.4734, test loss-1.9123, acc-0.4647\n",
      "Iter-41810, train loss-1.9044, acc-0.4600, valid loss-1.9114, acc-0.4734, test loss-1.9123, acc-0.4648\n",
      "Iter-41820, train loss-1.9529, acc-0.3200, valid loss-1.9113, acc-0.4734, test loss-1.9122, acc-0.4648\n",
      "Iter-41830, train loss-1.8581, acc-0.5400, valid loss-1.9112, acc-0.4734, test loss-1.9121, acc-0.4648\n",
      "Iter-41840, train loss-1.9396, acc-0.4000, valid loss-1.9112, acc-0.4736, test loss-1.9121, acc-0.4648\n",
      "Iter-41850, train loss-1.8532, acc-0.5000, valid loss-1.9111, acc-0.4736, test loss-1.9120, acc-0.4649\n",
      "Iter-41860, train loss-1.9863, acc-0.3200, valid loss-1.9111, acc-0.4736, test loss-1.9119, acc-0.4647\n",
      "Iter-41870, train loss-1.9153, acc-0.4000, valid loss-1.9110, acc-0.4736, test loss-1.9119, acc-0.4648\n",
      "Iter-41880, train loss-1.8714, acc-0.6200, valid loss-1.9109, acc-0.4734, test loss-1.9118, acc-0.4648\n",
      "Iter-41890, train loss-1.9649, acc-0.4000, valid loss-1.9108, acc-0.4734, test loss-1.9117, acc-0.4650\n",
      "Iter-41900, train loss-1.8964, acc-0.5200, valid loss-1.9108, acc-0.4734, test loss-1.9117, acc-0.4648\n",
      "Iter-41910, train loss-1.8591, acc-0.5800, valid loss-1.9107, acc-0.4734, test loss-1.9116, acc-0.4649\n",
      "Iter-41920, train loss-1.9326, acc-0.3800, valid loss-1.9106, acc-0.4736, test loss-1.9116, acc-0.4649\n",
      "Iter-41930, train loss-1.9717, acc-0.4000, valid loss-1.9106, acc-0.4736, test loss-1.9115, acc-0.4648\n",
      "Iter-41940, train loss-1.9400, acc-0.3800, valid loss-1.9105, acc-0.4736, test loss-1.9114, acc-0.4651\n",
      "Iter-41950, train loss-2.0266, acc-0.4200, valid loss-1.9104, acc-0.4736, test loss-1.9114, acc-0.4648\n",
      "Iter-41960, train loss-1.9016, acc-0.5800, valid loss-1.9104, acc-0.4736, test loss-1.9113, acc-0.4651\n",
      "Iter-41970, train loss-1.8748, acc-0.5000, valid loss-1.9103, acc-0.4736, test loss-1.9112, acc-0.4651\n",
      "Iter-41980, train loss-1.9360, acc-0.4600, valid loss-1.9102, acc-0.4736, test loss-1.9112, acc-0.4650\n",
      "Iter-41990, train loss-1.8956, acc-0.4200, valid loss-1.9102, acc-0.4736, test loss-1.9111, acc-0.4652\n",
      "Iter-42000, train loss-1.8859, acc-0.4400, valid loss-1.9101, acc-0.4736, test loss-1.9110, acc-0.4653\n",
      "Iter-42010, train loss-1.8541, acc-0.5800, valid loss-1.9101, acc-0.4736, test loss-1.9110, acc-0.4654\n",
      "Iter-42020, train loss-1.9500, acc-0.4200, valid loss-1.9100, acc-0.4736, test loss-1.9109, acc-0.4653\n",
      "Iter-42030, train loss-1.9167, acc-0.4400, valid loss-1.9099, acc-0.4736, test loss-1.9108, acc-0.4656\n",
      "Iter-42040, train loss-1.8937, acc-0.4600, valid loss-1.9099, acc-0.4736, test loss-1.9108, acc-0.4656\n",
      "Iter-42050, train loss-1.9141, acc-0.4000, valid loss-1.9098, acc-0.4736, test loss-1.9107, acc-0.4658\n",
      "Iter-42060, train loss-1.8861, acc-0.4400, valid loss-1.9097, acc-0.4736, test loss-1.9107, acc-0.4654\n",
      "Iter-42070, train loss-1.8730, acc-0.5200, valid loss-1.9097, acc-0.4734, test loss-1.9106, acc-0.4655\n",
      "Iter-42080, train loss-1.9513, acc-0.4600, valid loss-1.9096, acc-0.4736, test loss-1.9105, acc-0.4652\n",
      "Iter-42090, train loss-1.9493, acc-0.5400, valid loss-1.9095, acc-0.4736, test loss-1.9105, acc-0.4653\n",
      "Iter-42100, train loss-1.9025, acc-0.5000, valid loss-1.9095, acc-0.4734, test loss-1.9104, acc-0.4655\n",
      "Iter-42110, train loss-1.8663, acc-0.4400, valid loss-1.9094, acc-0.4734, test loss-1.9103, acc-0.4656\n",
      "Iter-42120, train loss-1.9660, acc-0.4400, valid loss-1.9093, acc-0.4734, test loss-1.9103, acc-0.4653\n",
      "Iter-42130, train loss-1.9074, acc-0.4400, valid loss-1.9093, acc-0.4736, test loss-1.9102, acc-0.4654\n",
      "Iter-42140, train loss-1.9525, acc-0.3600, valid loss-1.9092, acc-0.4736, test loss-1.9101, acc-0.4655\n",
      "Iter-42150, train loss-1.9023, acc-0.5400, valid loss-1.9091, acc-0.4736, test loss-1.9101, acc-0.4652\n",
      "Iter-42160, train loss-1.8495, acc-0.6200, valid loss-1.9091, acc-0.4736, test loss-1.9100, acc-0.4651\n",
      "Iter-42170, train loss-1.8439, acc-0.5600, valid loss-1.9090, acc-0.4734, test loss-1.9099, acc-0.4651\n",
      "Iter-42180, train loss-1.9862, acc-0.3400, valid loss-1.9090, acc-0.4734, test loss-1.9099, acc-0.4652\n",
      "Iter-42190, train loss-1.8482, acc-0.5800, valid loss-1.9089, acc-0.4734, test loss-1.9098, acc-0.4653\n",
      "Iter-42200, train loss-1.9458, acc-0.3800, valid loss-1.9088, acc-0.4734, test loss-1.9097, acc-0.4655\n",
      "Iter-42210, train loss-1.9562, acc-0.3800, valid loss-1.9088, acc-0.4734, test loss-1.9097, acc-0.4654\n",
      "Iter-42220, train loss-1.9895, acc-0.4000, valid loss-1.9087, acc-0.4734, test loss-1.9096, acc-0.4656\n",
      "Iter-42230, train loss-1.9220, acc-0.4600, valid loss-1.9086, acc-0.4732, test loss-1.9095, acc-0.4658\n",
      "Iter-42240, train loss-1.8228, acc-0.6000, valid loss-1.9086, acc-0.4732, test loss-1.9095, acc-0.4656\n",
      "Iter-42250, train loss-1.9492, acc-0.4600, valid loss-1.9085, acc-0.4732, test loss-1.9094, acc-0.4656\n",
      "Iter-42260, train loss-1.8781, acc-0.4000, valid loss-1.9084, acc-0.4732, test loss-1.9093, acc-0.4657\n",
      "Iter-42270, train loss-1.9472, acc-0.3600, valid loss-1.9084, acc-0.4732, test loss-1.9093, acc-0.4655\n",
      "Iter-42280, train loss-1.8791, acc-0.4800, valid loss-1.9083, acc-0.4736, test loss-1.9092, acc-0.4657\n",
      "Iter-42290, train loss-1.8703, acc-0.4800, valid loss-1.9082, acc-0.4736, test loss-1.9091, acc-0.4658\n",
      "Iter-42300, train loss-1.8994, acc-0.4600, valid loss-1.9082, acc-0.4736, test loss-1.9091, acc-0.4656\n",
      "Iter-42310, train loss-1.8867, acc-0.5400, valid loss-1.9081, acc-0.4736, test loss-1.9090, acc-0.4655\n",
      "Iter-42320, train loss-1.9482, acc-0.4800, valid loss-1.9081, acc-0.4736, test loss-1.9089, acc-0.4657\n",
      "Iter-42330, train loss-1.7944, acc-0.6000, valid loss-1.9080, acc-0.4734, test loss-1.9089, acc-0.4655\n",
      "Iter-42340, train loss-1.9327, acc-0.4600, valid loss-1.9079, acc-0.4738, test loss-1.9088, acc-0.4655\n",
      "Iter-42350, train loss-1.9513, acc-0.4200, valid loss-1.9078, acc-0.4738, test loss-1.9087, acc-0.4654\n",
      "Iter-42360, train loss-1.9843, acc-0.4800, valid loss-1.9078, acc-0.4738, test loss-1.9087, acc-0.4654\n",
      "Iter-42370, train loss-1.8935, acc-0.4200, valid loss-1.9077, acc-0.4736, test loss-1.9086, acc-0.4657\n",
      "Iter-42380, train loss-2.0016, acc-0.4200, valid loss-1.9077, acc-0.4738, test loss-1.9085, acc-0.4657\n",
      "Iter-42390, train loss-1.8575, acc-0.5400, valid loss-1.9076, acc-0.4738, test loss-1.9085, acc-0.4658\n",
      "Iter-42400, train loss-1.8905, acc-0.4600, valid loss-1.9075, acc-0.4738, test loss-1.9084, acc-0.4659\n",
      "Iter-42410, train loss-1.8711, acc-0.5600, valid loss-1.9075, acc-0.4738, test loss-1.9084, acc-0.4660\n",
      "Iter-42420, train loss-1.9659, acc-0.4800, valid loss-1.9074, acc-0.4738, test loss-1.9083, acc-0.4656\n",
      "Iter-42430, train loss-1.9162, acc-0.4200, valid loss-1.9073, acc-0.4736, test loss-1.9082, acc-0.4658\n",
      "Iter-42440, train loss-1.9252, acc-0.4600, valid loss-1.9073, acc-0.4736, test loss-1.9082, acc-0.4659\n",
      "Iter-42450, train loss-1.9009, acc-0.4800, valid loss-1.9072, acc-0.4736, test loss-1.9081, acc-0.4659\n",
      "Iter-42460, train loss-1.9927, acc-0.3800, valid loss-1.9071, acc-0.4736, test loss-1.9080, acc-0.4659\n",
      "Iter-42470, train loss-1.8760, acc-0.5200, valid loss-1.9071, acc-0.4736, test loss-1.9080, acc-0.4660\n",
      "Iter-42480, train loss-1.9076, acc-0.4000, valid loss-1.9070, acc-0.4736, test loss-1.9079, acc-0.4660\n",
      "Iter-42490, train loss-1.9409, acc-0.5200, valid loss-1.9069, acc-0.4736, test loss-1.9078, acc-0.4658\n",
      "Iter-42500, train loss-1.9152, acc-0.4800, valid loss-1.9069, acc-0.4736, test loss-1.9078, acc-0.4661\n",
      "Iter-42510, train loss-1.8947, acc-0.5000, valid loss-1.9068, acc-0.4736, test loss-1.9077, acc-0.4663\n",
      "Iter-42520, train loss-1.9777, acc-0.3200, valid loss-1.9067, acc-0.4736, test loss-1.9076, acc-0.4663\n",
      "Iter-42530, train loss-1.9622, acc-0.3800, valid loss-1.9067, acc-0.4736, test loss-1.9076, acc-0.4661\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-42540, train loss-1.9073, acc-0.4600, valid loss-1.9066, acc-0.4736, test loss-1.9075, acc-0.4665\n",
      "Iter-42550, train loss-1.8776, acc-0.4800, valid loss-1.9065, acc-0.4736, test loss-1.9074, acc-0.4663\n",
      "Iter-42560, train loss-1.9368, acc-0.4400, valid loss-1.9065, acc-0.4736, test loss-1.9074, acc-0.4663\n",
      "Iter-42570, train loss-1.9119, acc-0.4400, valid loss-1.9064, acc-0.4736, test loss-1.9073, acc-0.4662\n",
      "Iter-42580, train loss-1.9777, acc-0.3000, valid loss-1.9064, acc-0.4736, test loss-1.9072, acc-0.4663\n",
      "Iter-42590, train loss-1.9049, acc-0.5000, valid loss-1.9063, acc-0.4736, test loss-1.9072, acc-0.4663\n",
      "Iter-42600, train loss-1.9034, acc-0.4200, valid loss-1.9062, acc-0.4736, test loss-1.9071, acc-0.4665\n",
      "Iter-42610, train loss-1.8620, acc-0.5000, valid loss-1.9062, acc-0.4736, test loss-1.9070, acc-0.4666\n",
      "Iter-42620, train loss-1.8646, acc-0.4800, valid loss-1.9061, acc-0.4734, test loss-1.9070, acc-0.4668\n",
      "Iter-42630, train loss-1.8687, acc-0.5000, valid loss-1.9060, acc-0.4736, test loss-1.9069, acc-0.4668\n",
      "Iter-42640, train loss-1.9878, acc-0.4600, valid loss-1.9060, acc-0.4736, test loss-1.9069, acc-0.4670\n",
      "Iter-42650, train loss-1.9307, acc-0.4400, valid loss-1.9059, acc-0.4736, test loss-1.9068, acc-0.4672\n",
      "Iter-42660, train loss-1.9735, acc-0.3600, valid loss-1.9058, acc-0.4738, test loss-1.9067, acc-0.4672\n",
      "Iter-42670, train loss-1.8891, acc-0.5800, valid loss-1.9058, acc-0.4738, test loss-1.9067, acc-0.4670\n",
      "Iter-42680, train loss-1.9228, acc-0.5200, valid loss-1.9057, acc-0.4738, test loss-1.9066, acc-0.4672\n",
      "Iter-42690, train loss-1.8927, acc-0.4600, valid loss-1.9056, acc-0.4740, test loss-1.9065, acc-0.4673\n",
      "Iter-42700, train loss-1.8590, acc-0.5400, valid loss-1.9056, acc-0.4740, test loss-1.9065, acc-0.4674\n",
      "Iter-42710, train loss-2.0088, acc-0.4600, valid loss-1.9055, acc-0.4740, test loss-1.9064, acc-0.4673\n",
      "Iter-42720, train loss-1.9767, acc-0.4000, valid loss-1.9055, acc-0.4740, test loss-1.9063, acc-0.4672\n",
      "Iter-42730, train loss-1.9275, acc-0.4800, valid loss-1.9054, acc-0.4738, test loss-1.9063, acc-0.4672\n",
      "Iter-42740, train loss-1.8916, acc-0.4600, valid loss-1.9053, acc-0.4740, test loss-1.9062, acc-0.4672\n",
      "Iter-42750, train loss-1.9263, acc-0.4200, valid loss-1.9053, acc-0.4740, test loss-1.9061, acc-0.4674\n",
      "Iter-42760, train loss-1.9346, acc-0.5200, valid loss-1.9052, acc-0.4740, test loss-1.9061, acc-0.4674\n",
      "Iter-42770, train loss-1.9466, acc-0.4400, valid loss-1.9051, acc-0.4740, test loss-1.9060, acc-0.4673\n",
      "Iter-42780, train loss-1.9195, acc-0.4200, valid loss-1.9051, acc-0.4740, test loss-1.9060, acc-0.4674\n",
      "Iter-42790, train loss-1.9713, acc-0.4600, valid loss-1.9050, acc-0.4740, test loss-1.9059, acc-0.4674\n",
      "Iter-42800, train loss-1.9174, acc-0.5200, valid loss-1.9049, acc-0.4740, test loss-1.9058, acc-0.4674\n",
      "Iter-42810, train loss-1.9660, acc-0.3400, valid loss-1.9049, acc-0.4740, test loss-1.9058, acc-0.4674\n",
      "Iter-42820, train loss-1.9791, acc-0.3400, valid loss-1.9048, acc-0.4742, test loss-1.9057, acc-0.4674\n",
      "Iter-42830, train loss-1.8225, acc-0.5800, valid loss-1.9047, acc-0.4744, test loss-1.9056, acc-0.4676\n",
      "Iter-42840, train loss-1.9164, acc-0.5000, valid loss-1.9047, acc-0.4744, test loss-1.9056, acc-0.4677\n",
      "Iter-42850, train loss-1.9214, acc-0.4400, valid loss-1.9046, acc-0.4742, test loss-1.9055, acc-0.4676\n",
      "Iter-42860, train loss-1.8878, acc-0.5000, valid loss-1.9046, acc-0.4742, test loss-1.9054, acc-0.4677\n",
      "Iter-42870, train loss-1.9614, acc-0.4600, valid loss-1.9045, acc-0.4740, test loss-1.9054, acc-0.4677\n",
      "Iter-42880, train loss-1.8459, acc-0.5200, valid loss-1.9044, acc-0.4740, test loss-1.9053, acc-0.4677\n",
      "Iter-42890, train loss-1.8939, acc-0.5400, valid loss-1.9044, acc-0.4738, test loss-1.9052, acc-0.4676\n",
      "Iter-42900, train loss-1.9427, acc-0.4000, valid loss-1.9043, acc-0.4740, test loss-1.9052, acc-0.4677\n",
      "Iter-42910, train loss-1.9768, acc-0.4200, valid loss-1.9042, acc-0.4742, test loss-1.9051, acc-0.4675\n",
      "Iter-42920, train loss-1.8552, acc-0.6400, valid loss-1.9042, acc-0.4740, test loss-1.9051, acc-0.4676\n",
      "Iter-42930, train loss-1.8696, acc-0.5800, valid loss-1.9041, acc-0.4742, test loss-1.9050, acc-0.4675\n",
      "Iter-42940, train loss-1.9383, acc-0.5200, valid loss-1.9040, acc-0.4740, test loss-1.9049, acc-0.4675\n",
      "Iter-42950, train loss-1.8648, acc-0.5200, valid loss-1.9039, acc-0.4740, test loss-1.9049, acc-0.4674\n",
      "Iter-42960, train loss-1.8841, acc-0.3800, valid loss-1.9039, acc-0.4740, test loss-1.9048, acc-0.4674\n",
      "Iter-42970, train loss-1.9225, acc-0.4800, valid loss-1.9038, acc-0.4742, test loss-1.9047, acc-0.4673\n",
      "Iter-42980, train loss-1.9418, acc-0.4600, valid loss-1.9038, acc-0.4742, test loss-1.9047, acc-0.4673\n",
      "Iter-42990, train loss-1.8776, acc-0.4800, valid loss-1.9037, acc-0.4744, test loss-1.9046, acc-0.4676\n",
      "Iter-43000, train loss-1.8096, acc-0.5400, valid loss-1.9036, acc-0.4742, test loss-1.9045, acc-0.4676\n",
      "Iter-43010, train loss-1.9091, acc-0.4200, valid loss-1.9036, acc-0.4742, test loss-1.9045, acc-0.4674\n",
      "Iter-43020, train loss-1.8953, acc-0.4600, valid loss-1.9035, acc-0.4744, test loss-1.9044, acc-0.4676\n",
      "Iter-43030, train loss-1.9348, acc-0.4400, valid loss-1.9034, acc-0.4742, test loss-1.9043, acc-0.4676\n",
      "Iter-43040, train loss-1.8574, acc-0.4600, valid loss-1.9034, acc-0.4742, test loss-1.9043, acc-0.4675\n",
      "Iter-43050, train loss-1.9532, acc-0.3800, valid loss-1.9033, acc-0.4742, test loss-1.9042, acc-0.4677\n",
      "Iter-43060, train loss-1.9296, acc-0.4600, valid loss-1.9032, acc-0.4742, test loss-1.9042, acc-0.4677\n",
      "Iter-43070, train loss-1.8853, acc-0.6200, valid loss-1.9032, acc-0.4744, test loss-1.9041, acc-0.4677\n",
      "Iter-43080, train loss-1.8477, acc-0.5600, valid loss-1.9031, acc-0.4744, test loss-1.9040, acc-0.4679\n",
      "Iter-43090, train loss-1.9780, acc-0.3000, valid loss-1.9031, acc-0.4744, test loss-1.9040, acc-0.4678\n",
      "Iter-43100, train loss-1.9467, acc-0.4600, valid loss-1.9030, acc-0.4742, test loss-1.9039, acc-0.4677\n",
      "Iter-43110, train loss-1.9439, acc-0.4200, valid loss-1.9029, acc-0.4744, test loss-1.9038, acc-0.4677\n",
      "Iter-43120, train loss-1.9442, acc-0.4200, valid loss-1.9029, acc-0.4742, test loss-1.9038, acc-0.4678\n",
      "Iter-43130, train loss-1.9795, acc-0.4200, valid loss-1.9028, acc-0.4742, test loss-1.9037, acc-0.4678\n",
      "Iter-43140, train loss-1.8353, acc-0.5200, valid loss-1.9027, acc-0.4744, test loss-1.9036, acc-0.4679\n",
      "Iter-43150, train loss-1.8880, acc-0.4800, valid loss-1.9027, acc-0.4742, test loss-1.9036, acc-0.4680\n",
      "Iter-43160, train loss-1.8802, acc-0.3800, valid loss-1.9026, acc-0.4742, test loss-1.9035, acc-0.4681\n",
      "Iter-43170, train loss-1.8883, acc-0.4400, valid loss-1.9025, acc-0.4742, test loss-1.9035, acc-0.4681\n",
      "Iter-43180, train loss-1.8998, acc-0.5000, valid loss-1.9025, acc-0.4742, test loss-1.9034, acc-0.4681\n",
      "Iter-43190, train loss-1.8713, acc-0.4800, valid loss-1.9024, acc-0.4742, test loss-1.9033, acc-0.4680\n",
      "Iter-43200, train loss-1.8637, acc-0.4200, valid loss-1.9024, acc-0.4742, test loss-1.9033, acc-0.4680\n",
      "Iter-43210, train loss-1.9255, acc-0.4400, valid loss-1.9023, acc-0.4742, test loss-1.9032, acc-0.4680\n",
      "Iter-43220, train loss-1.8471, acc-0.5000, valid loss-1.9022, acc-0.4742, test loss-1.9031, acc-0.4681\n",
      "Iter-43230, train loss-1.8660, acc-0.4200, valid loss-1.9022, acc-0.4742, test loss-1.9031, acc-0.4681\n",
      "Iter-43240, train loss-1.8643, acc-0.5400, valid loss-1.9021, acc-0.4742, test loss-1.9030, acc-0.4681\n",
      "Iter-43250, train loss-1.9474, acc-0.4200, valid loss-1.9020, acc-0.4742, test loss-1.9029, acc-0.4681\n",
      "Iter-43260, train loss-1.9284, acc-0.4800, valid loss-1.9020, acc-0.4740, test loss-1.9029, acc-0.4681\n",
      "Iter-43270, train loss-1.9299, acc-0.4200, valid loss-1.9019, acc-0.4742, test loss-1.9028, acc-0.4681\n",
      "Iter-43280, train loss-1.9813, acc-0.3800, valid loss-1.9018, acc-0.4740, test loss-1.9027, acc-0.4681\n",
      "Iter-43290, train loss-1.9469, acc-0.4000, valid loss-1.9018, acc-0.4740, test loss-1.9027, acc-0.4681\n",
      "Iter-43300, train loss-1.9098, acc-0.4000, valid loss-1.9017, acc-0.4740, test loss-1.9026, acc-0.4681\n",
      "Iter-43310, train loss-1.9190, acc-0.4000, valid loss-1.9016, acc-0.4740, test loss-1.9026, acc-0.4681\n",
      "Iter-43320, train loss-1.8921, acc-0.5000, valid loss-1.9016, acc-0.4740, test loss-1.9025, acc-0.4680\n",
      "Iter-43330, train loss-1.9348, acc-0.3800, valid loss-1.9015, acc-0.4740, test loss-1.9024, acc-0.4682\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-43340, train loss-1.9468, acc-0.5400, valid loss-1.9015, acc-0.4740, test loss-1.9024, acc-0.4682\n",
      "Iter-43350, train loss-1.9530, acc-0.3800, valid loss-1.9014, acc-0.4742, test loss-1.9023, acc-0.4683\n",
      "Iter-43360, train loss-1.9940, acc-0.3800, valid loss-1.9013, acc-0.4740, test loss-1.9022, acc-0.4684\n",
      "Iter-43370, train loss-1.8927, acc-0.4200, valid loss-1.9013, acc-0.4738, test loss-1.9022, acc-0.4688\n",
      "Iter-43380, train loss-1.8734, acc-0.5400, valid loss-1.9012, acc-0.4736, test loss-1.9021, acc-0.4685\n",
      "Iter-43390, train loss-1.8903, acc-0.5800, valid loss-1.9011, acc-0.4740, test loss-1.9020, acc-0.4686\n",
      "Iter-43400, train loss-1.9820, acc-0.3600, valid loss-1.9011, acc-0.4738, test loss-1.9020, acc-0.4686\n",
      "Iter-43410, train loss-1.8893, acc-0.4400, valid loss-1.9010, acc-0.4740, test loss-1.9019, acc-0.4686\n",
      "Iter-43420, train loss-1.9778, acc-0.4000, valid loss-1.9010, acc-0.4742, test loss-1.9018, acc-0.4686\n",
      "Iter-43430, train loss-1.9612, acc-0.3800, valid loss-1.9009, acc-0.4742, test loss-1.9018, acc-0.4689\n",
      "Iter-43440, train loss-1.9656, acc-0.3800, valid loss-1.9008, acc-0.4742, test loss-1.9017, acc-0.4687\n",
      "Iter-43450, train loss-1.8659, acc-0.5000, valid loss-1.9008, acc-0.4742, test loss-1.9017, acc-0.4687\n",
      "Iter-43460, train loss-1.9053, acc-0.4000, valid loss-1.9007, acc-0.4744, test loss-1.9016, acc-0.4690\n",
      "Iter-43470, train loss-1.8779, acc-0.6000, valid loss-1.9006, acc-0.4744, test loss-1.9015, acc-0.4689\n",
      "Iter-43480, train loss-1.9123, acc-0.5000, valid loss-1.9006, acc-0.4740, test loss-1.9015, acc-0.4690\n",
      "Iter-43490, train loss-1.8417, acc-0.5800, valid loss-1.9005, acc-0.4738, test loss-1.9014, acc-0.4690\n",
      "Iter-43500, train loss-1.8664, acc-0.4600, valid loss-1.9004, acc-0.4738, test loss-1.9013, acc-0.4690\n",
      "Iter-43510, train loss-1.9408, acc-0.5200, valid loss-1.9004, acc-0.4738, test loss-1.9013, acc-0.4690\n",
      "Iter-43520, train loss-1.9425, acc-0.3600, valid loss-1.9003, acc-0.4740, test loss-1.9012, acc-0.4689\n",
      "Iter-43530, train loss-1.9632, acc-0.4000, valid loss-1.9003, acc-0.4736, test loss-1.9012, acc-0.4691\n",
      "Iter-43540, train loss-1.8547, acc-0.5400, valid loss-1.9002, acc-0.4736, test loss-1.9011, acc-0.4690\n",
      "Iter-43550, train loss-1.9370, acc-0.4000, valid loss-1.9001, acc-0.4740, test loss-1.9010, acc-0.4689\n",
      "Iter-43560, train loss-1.9597, acc-0.4200, valid loss-1.9001, acc-0.4736, test loss-1.9010, acc-0.4690\n",
      "Iter-43570, train loss-1.9680, acc-0.3800, valid loss-1.9000, acc-0.4738, test loss-1.9009, acc-0.4693\n",
      "Iter-43580, train loss-2.0147, acc-0.3000, valid loss-1.8999, acc-0.4736, test loss-1.9008, acc-0.4692\n",
      "Iter-43590, train loss-1.8662, acc-0.5200, valid loss-1.8999, acc-0.4738, test loss-1.9008, acc-0.4693\n",
      "Iter-43600, train loss-1.9344, acc-0.4000, valid loss-1.8998, acc-0.4738, test loss-1.9007, acc-0.4691\n",
      "Iter-43610, train loss-1.8578, acc-0.5200, valid loss-1.8997, acc-0.4738, test loss-1.9007, acc-0.4692\n",
      "Iter-43620, train loss-1.9273, acc-0.4000, valid loss-1.8997, acc-0.4738, test loss-1.9006, acc-0.4692\n",
      "Iter-43630, train loss-1.8806, acc-0.4800, valid loss-1.8996, acc-0.4738, test loss-1.9005, acc-0.4691\n",
      "Iter-43640, train loss-1.8971, acc-0.4800, valid loss-1.8995, acc-0.4738, test loss-1.9005, acc-0.4693\n",
      "Iter-43650, train loss-1.9045, acc-0.4400, valid loss-1.8995, acc-0.4740, test loss-1.9004, acc-0.4695\n",
      "Iter-43660, train loss-1.9014, acc-0.5200, valid loss-1.8994, acc-0.4740, test loss-1.9003, acc-0.4694\n",
      "Iter-43670, train loss-1.8711, acc-0.5000, valid loss-1.8994, acc-0.4738, test loss-1.9003, acc-0.4695\n",
      "Iter-43680, train loss-1.9331, acc-0.4800, valid loss-1.8993, acc-0.4740, test loss-1.9002, acc-0.4695\n",
      "Iter-43690, train loss-1.8230, acc-0.5600, valid loss-1.8992, acc-0.4740, test loss-1.9001, acc-0.4695\n",
      "Iter-43700, train loss-1.8917, acc-0.5800, valid loss-1.8992, acc-0.4742, test loss-1.9001, acc-0.4697\n",
      "Iter-43710, train loss-1.9030, acc-0.5400, valid loss-1.8991, acc-0.4740, test loss-1.9000, acc-0.4695\n",
      "Iter-43720, train loss-1.9405, acc-0.4400, valid loss-1.8991, acc-0.4738, test loss-1.8999, acc-0.4695\n",
      "Iter-43730, train loss-1.9455, acc-0.4600, valid loss-1.8990, acc-0.4736, test loss-1.8999, acc-0.4694\n",
      "Iter-43740, train loss-1.8873, acc-0.5200, valid loss-1.8989, acc-0.4738, test loss-1.8998, acc-0.4694\n",
      "Iter-43750, train loss-1.8550, acc-0.5400, valid loss-1.8989, acc-0.4738, test loss-1.8997, acc-0.4695\n",
      "Iter-43760, train loss-1.9565, acc-0.4000, valid loss-1.8988, acc-0.4740, test loss-1.8997, acc-0.4695\n",
      "Iter-43770, train loss-2.0101, acc-0.3400, valid loss-1.8987, acc-0.4738, test loss-1.8996, acc-0.4694\n",
      "Iter-43780, train loss-1.8644, acc-0.5000, valid loss-1.8987, acc-0.4736, test loss-1.8996, acc-0.4694\n",
      "Iter-43790, train loss-1.9229, acc-0.4600, valid loss-1.8986, acc-0.4736, test loss-1.8995, acc-0.4694\n",
      "Iter-43800, train loss-1.9613, acc-0.4600, valid loss-1.8985, acc-0.4736, test loss-1.8994, acc-0.4694\n",
      "Iter-43810, train loss-1.8447, acc-0.5600, valid loss-1.8985, acc-0.4736, test loss-1.8994, acc-0.4692\n",
      "Iter-43820, train loss-1.8842, acc-0.5400, valid loss-1.8984, acc-0.4738, test loss-1.8993, acc-0.4694\n",
      "Iter-43830, train loss-1.9355, acc-0.4200, valid loss-1.8984, acc-0.4736, test loss-1.8993, acc-0.4695\n",
      "Iter-43840, train loss-1.9434, acc-0.4000, valid loss-1.8983, acc-0.4738, test loss-1.8992, acc-0.4696\n",
      "Iter-43850, train loss-1.9254, acc-0.4800, valid loss-1.8982, acc-0.4736, test loss-1.8991, acc-0.4693\n",
      "Iter-43860, train loss-1.8782, acc-0.6000, valid loss-1.8982, acc-0.4736, test loss-1.8991, acc-0.4695\n",
      "Iter-43870, train loss-1.8255, acc-0.5800, valid loss-1.8981, acc-0.4742, test loss-1.8990, acc-0.4693\n",
      "Iter-43880, train loss-1.8753, acc-0.5600, valid loss-1.8980, acc-0.4742, test loss-1.8989, acc-0.4696\n",
      "Iter-43890, train loss-2.0260, acc-0.4000, valid loss-1.8980, acc-0.4740, test loss-1.8989, acc-0.4696\n",
      "Iter-43900, train loss-1.9540, acc-0.4200, valid loss-1.8979, acc-0.4740, test loss-1.8988, acc-0.4696\n",
      "Iter-43910, train loss-1.8923, acc-0.5000, valid loss-1.8979, acc-0.4744, test loss-1.8987, acc-0.4696\n",
      "Iter-43920, train loss-1.8712, acc-0.4800, valid loss-1.8978, acc-0.4742, test loss-1.8987, acc-0.4696\n",
      "Iter-43930, train loss-1.8474, acc-0.4800, valid loss-1.8977, acc-0.4742, test loss-1.8986, acc-0.4697\n",
      "Iter-43940, train loss-1.8708, acc-0.4600, valid loss-1.8977, acc-0.4746, test loss-1.8986, acc-0.4697\n",
      "Iter-43950, train loss-1.8620, acc-0.4200, valid loss-1.8976, acc-0.4742, test loss-1.8985, acc-0.4697\n",
      "Iter-43960, train loss-1.8410, acc-0.4800, valid loss-1.8975, acc-0.4748, test loss-1.8984, acc-0.4693\n",
      "Iter-43970, train loss-1.9075, acc-0.3800, valid loss-1.8975, acc-0.4750, test loss-1.8984, acc-0.4692\n",
      "Iter-43980, train loss-1.8947, acc-0.5000, valid loss-1.8974, acc-0.4744, test loss-1.8983, acc-0.4695\n",
      "Iter-43990, train loss-1.7232, acc-0.5800, valid loss-1.8973, acc-0.4750, test loss-1.8982, acc-0.4692\n",
      "Iter-44000, train loss-1.9455, acc-0.3800, valid loss-1.8973, acc-0.4748, test loss-1.8982, acc-0.4693\n",
      "Iter-44010, train loss-1.9328, acc-0.4400, valid loss-1.8972, acc-0.4746, test loss-1.8981, acc-0.4696\n",
      "Iter-44020, train loss-1.9457, acc-0.3400, valid loss-1.8972, acc-0.4744, test loss-1.8980, acc-0.4697\n",
      "Iter-44030, train loss-1.9658, acc-0.4600, valid loss-1.8971, acc-0.4748, test loss-1.8980, acc-0.4697\n",
      "Iter-44040, train loss-1.9517, acc-0.4600, valid loss-1.8970, acc-0.4752, test loss-1.8979, acc-0.4697\n",
      "Iter-44050, train loss-1.9672, acc-0.3800, valid loss-1.8970, acc-0.4752, test loss-1.8979, acc-0.4698\n",
      "Iter-44060, train loss-1.8421, acc-0.5000, valid loss-1.8969, acc-0.4752, test loss-1.8978, acc-0.4698\n",
      "Iter-44070, train loss-1.9265, acc-0.4200, valid loss-1.8968, acc-0.4752, test loss-1.8977, acc-0.4696\n",
      "Iter-44080, train loss-1.9168, acc-0.5200, valid loss-1.8968, acc-0.4752, test loss-1.8977, acc-0.4699\n",
      "Iter-44090, train loss-1.9100, acc-0.4200, valid loss-1.8967, acc-0.4752, test loss-1.8976, acc-0.4698\n",
      "Iter-44100, train loss-1.8632, acc-0.5200, valid loss-1.8967, acc-0.4752, test loss-1.8975, acc-0.4700\n",
      "Iter-44110, train loss-1.8663, acc-0.5200, valid loss-1.8966, acc-0.4752, test loss-1.8975, acc-0.4701\n",
      "Iter-44120, train loss-1.8771, acc-0.5000, valid loss-1.8965, acc-0.4752, test loss-1.8974, acc-0.4701\n",
      "Iter-44130, train loss-1.8359, acc-0.5400, valid loss-1.8965, acc-0.4752, test loss-1.8974, acc-0.4701\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44140, train loss-1.9263, acc-0.4400, valid loss-1.8964, acc-0.4752, test loss-1.8973, acc-0.4700\n",
      "Iter-44150, train loss-1.8612, acc-0.5200, valid loss-1.8964, acc-0.4748, test loss-1.8972, acc-0.4701\n",
      "Iter-44160, train loss-1.8357, acc-0.5200, valid loss-1.8963, acc-0.4752, test loss-1.8972, acc-0.4701\n",
      "Iter-44170, train loss-1.8239, acc-0.5800, valid loss-1.8962, acc-0.4752, test loss-1.8971, acc-0.4701\n",
      "Iter-44180, train loss-1.9480, acc-0.4400, valid loss-1.8962, acc-0.4752, test loss-1.8971, acc-0.4699\n",
      "Iter-44190, train loss-1.9401, acc-0.4600, valid loss-1.8961, acc-0.4752, test loss-1.8970, acc-0.4700\n",
      "Iter-44200, train loss-1.8133, acc-0.5800, valid loss-1.8960, acc-0.4752, test loss-1.8969, acc-0.4701\n",
      "Iter-44210, train loss-1.9209, acc-0.4600, valid loss-1.8960, acc-0.4752, test loss-1.8969, acc-0.4701\n",
      "Iter-44220, train loss-1.9228, acc-0.3800, valid loss-1.8959, acc-0.4756, test loss-1.8968, acc-0.4699\n",
      "Iter-44230, train loss-1.9156, acc-0.5000, valid loss-1.8958, acc-0.4756, test loss-1.8967, acc-0.4700\n",
      "Iter-44240, train loss-1.9171, acc-0.4400, valid loss-1.8958, acc-0.4756, test loss-1.8967, acc-0.4704\n",
      "Iter-44250, train loss-1.8264, acc-0.5800, valid loss-1.8957, acc-0.4754, test loss-1.8966, acc-0.4704\n",
      "Iter-44260, train loss-1.7765, acc-0.5600, valid loss-1.8957, acc-0.4752, test loss-1.8965, acc-0.4703\n",
      "Iter-44270, train loss-1.7846, acc-0.5200, valid loss-1.8956, acc-0.4754, test loss-1.8965, acc-0.4705\n",
      "Iter-44280, train loss-1.8909, acc-0.5200, valid loss-1.8955, acc-0.4754, test loss-1.8964, acc-0.4703\n",
      "Iter-44290, train loss-1.8023, acc-0.5600, valid loss-1.8955, acc-0.4754, test loss-1.8964, acc-0.4701\n",
      "Iter-44300, train loss-1.8984, acc-0.4600, valid loss-1.8954, acc-0.4756, test loss-1.8963, acc-0.4702\n",
      "Iter-44310, train loss-1.8516, acc-0.5200, valid loss-1.8954, acc-0.4756, test loss-1.8962, acc-0.4703\n",
      "Iter-44320, train loss-1.9250, acc-0.4200, valid loss-1.8953, acc-0.4756, test loss-1.8962, acc-0.4702\n",
      "Iter-44330, train loss-1.7491, acc-0.6200, valid loss-1.8952, acc-0.4754, test loss-1.8961, acc-0.4703\n",
      "Iter-44340, train loss-1.9672, acc-0.5400, valid loss-1.8952, acc-0.4754, test loss-1.8960, acc-0.4702\n",
      "Iter-44350, train loss-1.9889, acc-0.3600, valid loss-1.8951, acc-0.4754, test loss-1.8960, acc-0.4704\n",
      "Iter-44360, train loss-1.9327, acc-0.4800, valid loss-1.8950, acc-0.4754, test loss-1.8959, acc-0.4705\n",
      "Iter-44370, train loss-1.9801, acc-0.3800, valid loss-1.8950, acc-0.4752, test loss-1.8959, acc-0.4705\n",
      "Iter-44380, train loss-1.8801, acc-0.5200, valid loss-1.8949, acc-0.4752, test loss-1.8958, acc-0.4705\n",
      "Iter-44390, train loss-1.9471, acc-0.5200, valid loss-1.8949, acc-0.4754, test loss-1.8957, acc-0.4705\n",
      "Iter-44400, train loss-1.8483, acc-0.5400, valid loss-1.8948, acc-0.4754, test loss-1.8957, acc-0.4703\n",
      "Iter-44410, train loss-1.9662, acc-0.4800, valid loss-1.8947, acc-0.4754, test loss-1.8956, acc-0.4705\n",
      "Iter-44420, train loss-1.9332, acc-0.4000, valid loss-1.8947, acc-0.4754, test loss-1.8955, acc-0.4704\n",
      "Iter-44430, train loss-1.8959, acc-0.4400, valid loss-1.8946, acc-0.4754, test loss-1.8955, acc-0.4703\n",
      "Iter-44440, train loss-1.8977, acc-0.5200, valid loss-1.8946, acc-0.4754, test loss-1.8954, acc-0.4703\n",
      "Iter-44450, train loss-1.9260, acc-0.4200, valid loss-1.8945, acc-0.4756, test loss-1.8954, acc-0.4705\n",
      "Iter-44460, train loss-1.8067, acc-0.5400, valid loss-1.8944, acc-0.4756, test loss-1.8953, acc-0.4705\n",
      "Iter-44470, train loss-1.9044, acc-0.4600, valid loss-1.8944, acc-0.4756, test loss-1.8952, acc-0.4704\n",
      "Iter-44480, train loss-1.9108, acc-0.5000, valid loss-1.8943, acc-0.4752, test loss-1.8952, acc-0.4705\n",
      "Iter-44490, train loss-1.8348, acc-0.5200, valid loss-1.8942, acc-0.4752, test loss-1.8951, acc-0.4704\n",
      "Iter-44500, train loss-1.8780, acc-0.5400, valid loss-1.8942, acc-0.4754, test loss-1.8950, acc-0.4705\n",
      "Iter-44510, train loss-1.9833, acc-0.3400, valid loss-1.8941, acc-0.4756, test loss-1.8950, acc-0.4704\n",
      "Iter-44520, train loss-1.9145, acc-0.4400, valid loss-1.8940, acc-0.4756, test loss-1.8949, acc-0.4704\n",
      "Iter-44530, train loss-1.9592, acc-0.4000, valid loss-1.8940, acc-0.4758, test loss-1.8948, acc-0.4705\n",
      "Iter-44540, train loss-1.9511, acc-0.5600, valid loss-1.8939, acc-0.4758, test loss-1.8948, acc-0.4705\n",
      "Iter-44550, train loss-1.8954, acc-0.4400, valid loss-1.8939, acc-0.4762, test loss-1.8947, acc-0.4705\n",
      "Iter-44560, train loss-1.8064, acc-0.5400, valid loss-1.8938, acc-0.4762, test loss-1.8947, acc-0.4703\n",
      "Iter-44570, train loss-1.9048, acc-0.4400, valid loss-1.8937, acc-0.4758, test loss-1.8946, acc-0.4705\n",
      "Iter-44580, train loss-1.9984, acc-0.4200, valid loss-1.8937, acc-0.4758, test loss-1.8945, acc-0.4704\n",
      "Iter-44590, train loss-1.9201, acc-0.5000, valid loss-1.8936, acc-0.4758, test loss-1.8945, acc-0.4705\n",
      "Iter-44600, train loss-1.9096, acc-0.4200, valid loss-1.8936, acc-0.4758, test loss-1.8944, acc-0.4705\n",
      "Iter-44610, train loss-1.8998, acc-0.4800, valid loss-1.8935, acc-0.4756, test loss-1.8944, acc-0.4705\n",
      "Iter-44620, train loss-1.8864, acc-0.4600, valid loss-1.8934, acc-0.4758, test loss-1.8943, acc-0.4705\n",
      "Iter-44630, train loss-1.8968, acc-0.4000, valid loss-1.8934, acc-0.4758, test loss-1.8942, acc-0.4705\n",
      "Iter-44640, train loss-1.8999, acc-0.5200, valid loss-1.8933, acc-0.4758, test loss-1.8942, acc-0.4705\n",
      "Iter-44650, train loss-1.9462, acc-0.3600, valid loss-1.8932, acc-0.4758, test loss-1.8941, acc-0.4704\n",
      "Iter-44660, train loss-1.9074, acc-0.4600, valid loss-1.8932, acc-0.4760, test loss-1.8940, acc-0.4706\n",
      "Iter-44670, train loss-1.9496, acc-0.3600, valid loss-1.8931, acc-0.4758, test loss-1.8940, acc-0.4705\n",
      "Iter-44680, train loss-1.8720, acc-0.5600, valid loss-1.8931, acc-0.4758, test loss-1.8939, acc-0.4703\n",
      "Iter-44690, train loss-1.8671, acc-0.5600, valid loss-1.8930, acc-0.4756, test loss-1.8939, acc-0.4705\n",
      "Iter-44700, train loss-1.8938, acc-0.5000, valid loss-1.8929, acc-0.4756, test loss-1.8938, acc-0.4705\n",
      "Iter-44710, train loss-1.9588, acc-0.3800, valid loss-1.8929, acc-0.4756, test loss-1.8937, acc-0.4703\n",
      "Iter-44720, train loss-1.9152, acc-0.3800, valid loss-1.8928, acc-0.4758, test loss-1.8937, acc-0.4705\n",
      "Iter-44730, train loss-1.9446, acc-0.4600, valid loss-1.8928, acc-0.4760, test loss-1.8936, acc-0.4706\n",
      "Iter-44740, train loss-1.8684, acc-0.4800, valid loss-1.8927, acc-0.4758, test loss-1.8936, acc-0.4704\n",
      "Iter-44750, train loss-1.9749, acc-0.3600, valid loss-1.8926, acc-0.4762, test loss-1.8935, acc-0.4706\n",
      "Iter-44760, train loss-1.8642, acc-0.4400, valid loss-1.8926, acc-0.4762, test loss-1.8934, acc-0.4706\n",
      "Iter-44770, train loss-1.8278, acc-0.5200, valid loss-1.8925, acc-0.4762, test loss-1.8934, acc-0.4707\n",
      "Iter-44780, train loss-1.9040, acc-0.5000, valid loss-1.8924, acc-0.4760, test loss-1.8933, acc-0.4707\n",
      "Iter-44790, train loss-1.9270, acc-0.4800, valid loss-1.8924, acc-0.4762, test loss-1.8932, acc-0.4707\n",
      "Iter-44800, train loss-1.8904, acc-0.4800, valid loss-1.8923, acc-0.4760, test loss-1.8932, acc-0.4708\n",
      "Iter-44810, train loss-1.9170, acc-0.3800, valid loss-1.8923, acc-0.4760, test loss-1.8931, acc-0.4707\n",
      "Iter-44820, train loss-1.8655, acc-0.6200, valid loss-1.8922, acc-0.4762, test loss-1.8931, acc-0.4710\n",
      "Iter-44830, train loss-1.8075, acc-0.5200, valid loss-1.8921, acc-0.4764, test loss-1.8930, acc-0.4708\n",
      "Iter-44840, train loss-1.9139, acc-0.4600, valid loss-1.8921, acc-0.4762, test loss-1.8929, acc-0.4709\n",
      "Iter-44850, train loss-1.8280, acc-0.5400, valid loss-1.8920, acc-0.4762, test loss-1.8929, acc-0.4709\n",
      "Iter-44860, train loss-1.9242, acc-0.5000, valid loss-1.8919, acc-0.4760, test loss-1.8928, acc-0.4709\n",
      "Iter-44870, train loss-1.9030, acc-0.4400, valid loss-1.8919, acc-0.4762, test loss-1.8928, acc-0.4710\n",
      "Iter-44880, train loss-1.9224, acc-0.4800, valid loss-1.8918, acc-0.4762, test loss-1.8927, acc-0.4711\n",
      "Iter-44890, train loss-1.8230, acc-0.5000, valid loss-1.8918, acc-0.4762, test loss-1.8926, acc-0.4711\n",
      "Iter-44900, train loss-1.8710, acc-0.5600, valid loss-1.8917, acc-0.4764, test loss-1.8926, acc-0.4710\n",
      "Iter-44910, train loss-1.9079, acc-0.4800, valid loss-1.8916, acc-0.4764, test loss-1.8925, acc-0.4709\n",
      "Iter-44920, train loss-1.9338, acc-0.4200, valid loss-1.8916, acc-0.4764, test loss-1.8924, acc-0.4709\n",
      "Iter-44930, train loss-1.8769, acc-0.4600, valid loss-1.8915, acc-0.4764, test loss-1.8924, acc-0.4709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-44940, train loss-1.8663, acc-0.4400, valid loss-1.8914, acc-0.4764, test loss-1.8923, acc-0.4709\n",
      "Iter-44950, train loss-1.9034, acc-0.3600, valid loss-1.8914, acc-0.4764, test loss-1.8922, acc-0.4709\n",
      "Iter-44960, train loss-1.7633, acc-0.5800, valid loss-1.8913, acc-0.4764, test loss-1.8922, acc-0.4709\n",
      "Iter-44970, train loss-1.8978, acc-0.4400, valid loss-1.8912, acc-0.4764, test loss-1.8921, acc-0.4709\n",
      "Iter-44980, train loss-1.8248, acc-0.5600, valid loss-1.8912, acc-0.4764, test loss-1.8920, acc-0.4710\n",
      "Iter-44990, train loss-1.9761, acc-0.3600, valid loss-1.8911, acc-0.4760, test loss-1.8920, acc-0.4711\n",
      "Iter-45000, train loss-1.9272, acc-0.3600, valid loss-1.8910, acc-0.4760, test loss-1.8919, acc-0.4711\n",
      "Iter-45010, train loss-1.8681, acc-0.5200, valid loss-1.8910, acc-0.4762, test loss-1.8919, acc-0.4710\n",
      "Iter-45020, train loss-1.9039, acc-0.4800, valid loss-1.8909, acc-0.4766, test loss-1.8918, acc-0.4709\n",
      "Iter-45030, train loss-1.9387, acc-0.3400, valid loss-1.8909, acc-0.4766, test loss-1.8917, acc-0.4709\n",
      "Iter-45040, train loss-1.9599, acc-0.5000, valid loss-1.8908, acc-0.4766, test loss-1.8917, acc-0.4709\n",
      "Iter-45050, train loss-1.9265, acc-0.3600, valid loss-1.8907, acc-0.4766, test loss-1.8916, acc-0.4710\n",
      "Iter-45060, train loss-1.8536, acc-0.4800, valid loss-1.8907, acc-0.4768, test loss-1.8916, acc-0.4710\n",
      "Iter-45070, train loss-1.9156, acc-0.4400, valid loss-1.8906, acc-0.4768, test loss-1.8915, acc-0.4710\n",
      "Iter-45080, train loss-1.9352, acc-0.4600, valid loss-1.8906, acc-0.4772, test loss-1.8914, acc-0.4710\n",
      "Iter-45090, train loss-1.9374, acc-0.4600, valid loss-1.8905, acc-0.4770, test loss-1.8914, acc-0.4710\n",
      "Iter-45100, train loss-1.8253, acc-0.4600, valid loss-1.8904, acc-0.4770, test loss-1.8913, acc-0.4710\n",
      "Iter-45110, train loss-1.9338, acc-0.5000, valid loss-1.8904, acc-0.4768, test loss-1.8912, acc-0.4711\n",
      "Iter-45120, train loss-1.9189, acc-0.4600, valid loss-1.8903, acc-0.4772, test loss-1.8912, acc-0.4709\n",
      "Iter-45130, train loss-1.9528, acc-0.3800, valid loss-1.8902, acc-0.4772, test loss-1.8911, acc-0.4710\n",
      "Iter-45140, train loss-1.7662, acc-0.6200, valid loss-1.8902, acc-0.4772, test loss-1.8911, acc-0.4711\n",
      "Iter-45150, train loss-1.8441, acc-0.5800, valid loss-1.8901, acc-0.4772, test loss-1.8910, acc-0.4709\n",
      "Iter-45160, train loss-1.8413, acc-0.5800, valid loss-1.8900, acc-0.4772, test loss-1.8909, acc-0.4709\n",
      "Iter-45170, train loss-1.8551, acc-0.4200, valid loss-1.8900, acc-0.4772, test loss-1.8909, acc-0.4710\n",
      "Iter-45180, train loss-2.0214, acc-0.3200, valid loss-1.8899, acc-0.4772, test loss-1.8908, acc-0.4709\n",
      "Iter-45190, train loss-1.9011, acc-0.4400, valid loss-1.8899, acc-0.4772, test loss-1.8907, acc-0.4709\n",
      "Iter-45200, train loss-1.9099, acc-0.4400, valid loss-1.8898, acc-0.4772, test loss-1.8907, acc-0.4709\n",
      "Iter-45210, train loss-1.8666, acc-0.5200, valid loss-1.8897, acc-0.4774, test loss-1.8906, acc-0.4709\n",
      "Iter-45220, train loss-1.7743, acc-0.5800, valid loss-1.8897, acc-0.4774, test loss-1.8906, acc-0.4709\n",
      "Iter-45230, train loss-1.8584, acc-0.5000, valid loss-1.8896, acc-0.4774, test loss-1.8905, acc-0.4711\n",
      "Iter-45240, train loss-1.8867, acc-0.5200, valid loss-1.8895, acc-0.4774, test loss-1.8904, acc-0.4711\n",
      "Iter-45250, train loss-1.9373, acc-0.5000, valid loss-1.8895, acc-0.4774, test loss-1.8904, acc-0.4711\n",
      "Iter-45260, train loss-1.9038, acc-0.5400, valid loss-1.8894, acc-0.4770, test loss-1.8903, acc-0.4710\n",
      "Iter-45270, train loss-1.9289, acc-0.4000, valid loss-1.8894, acc-0.4770, test loss-1.8902, acc-0.4710\n",
      "Iter-45280, train loss-1.9546, acc-0.3600, valid loss-1.8893, acc-0.4770, test loss-1.8902, acc-0.4711\n",
      "Iter-45290, train loss-1.9043, acc-0.4400, valid loss-1.8892, acc-0.4774, test loss-1.8901, acc-0.4709\n",
      "Iter-45300, train loss-1.8328, acc-0.5000, valid loss-1.8892, acc-0.4770, test loss-1.8901, acc-0.4710\n",
      "Iter-45310, train loss-1.8914, acc-0.4400, valid loss-1.8891, acc-0.4770, test loss-1.8900, acc-0.4710\n",
      "Iter-45320, train loss-2.0221, acc-0.2800, valid loss-1.8890, acc-0.4772, test loss-1.8899, acc-0.4708\n",
      "Iter-45330, train loss-1.9115, acc-0.5000, valid loss-1.8890, acc-0.4770, test loss-1.8899, acc-0.4709\n",
      "Iter-45340, train loss-1.8768, acc-0.4400, valid loss-1.8889, acc-0.4768, test loss-1.8898, acc-0.4709\n",
      "Iter-45350, train loss-1.8262, acc-0.4600, valid loss-1.8888, acc-0.4768, test loss-1.8897, acc-0.4709\n",
      "Iter-45360, train loss-1.8721, acc-0.5400, valid loss-1.8888, acc-0.4770, test loss-1.8897, acc-0.4709\n",
      "Iter-45370, train loss-1.9245, acc-0.3800, valid loss-1.8887, acc-0.4770, test loss-1.8896, acc-0.4709\n",
      "Iter-45380, train loss-1.8224, acc-0.5600, valid loss-1.8887, acc-0.4766, test loss-1.8896, acc-0.4707\n",
      "Iter-45390, train loss-1.8683, acc-0.4000, valid loss-1.8886, acc-0.4768, test loss-1.8895, acc-0.4707\n",
      "Iter-45400, train loss-1.9784, acc-0.3600, valid loss-1.8885, acc-0.4766, test loss-1.8894, acc-0.4708\n",
      "Iter-45410, train loss-1.9660, acc-0.3800, valid loss-1.8885, acc-0.4766, test loss-1.8894, acc-0.4707\n",
      "Iter-45420, train loss-1.9666, acc-0.4000, valid loss-1.8884, acc-0.4768, test loss-1.8893, acc-0.4707\n",
      "Iter-45430, train loss-1.9064, acc-0.5600, valid loss-1.8884, acc-0.4768, test loss-1.8892, acc-0.4708\n",
      "Iter-45440, train loss-1.9549, acc-0.4200, valid loss-1.8883, acc-0.4770, test loss-1.8892, acc-0.4709\n",
      "Iter-45450, train loss-1.9489, acc-0.5000, valid loss-1.8882, acc-0.4770, test loss-1.8891, acc-0.4709\n",
      "Iter-45460, train loss-1.9646, acc-0.4600, valid loss-1.8882, acc-0.4770, test loss-1.8891, acc-0.4709\n",
      "Iter-45470, train loss-1.9126, acc-0.4200, valid loss-1.8881, acc-0.4770, test loss-1.8890, acc-0.4709\n",
      "Iter-45480, train loss-1.8447, acc-0.5400, valid loss-1.8880, acc-0.4768, test loss-1.8889, acc-0.4707\n",
      "Iter-45490, train loss-1.9410, acc-0.4400, valid loss-1.8880, acc-0.4768, test loss-1.8889, acc-0.4707\n",
      "Iter-45500, train loss-1.9424, acc-0.3800, valid loss-1.8879, acc-0.4768, test loss-1.8888, acc-0.4707\n",
      "Iter-45510, train loss-1.8865, acc-0.4800, valid loss-1.8879, acc-0.4768, test loss-1.8887, acc-0.4707\n",
      "Iter-45520, train loss-1.8255, acc-0.5800, valid loss-1.8878, acc-0.4768, test loss-1.8887, acc-0.4707\n",
      "Iter-45530, train loss-1.9123, acc-0.5000, valid loss-1.8877, acc-0.4770, test loss-1.8886, acc-0.4707\n",
      "Iter-45540, train loss-1.8878, acc-0.4800, valid loss-1.8877, acc-0.4770, test loss-1.8886, acc-0.4707\n",
      "Iter-45550, train loss-1.9104, acc-0.3600, valid loss-1.8876, acc-0.4768, test loss-1.8885, acc-0.4707\n",
      "Iter-45560, train loss-1.8741, acc-0.5400, valid loss-1.8875, acc-0.4768, test loss-1.8884, acc-0.4707\n",
      "Iter-45570, train loss-1.9950, acc-0.4000, valid loss-1.8875, acc-0.4768, test loss-1.8884, acc-0.4707\n",
      "Iter-45580, train loss-1.8742, acc-0.5200, valid loss-1.8874, acc-0.4770, test loss-1.8883, acc-0.4707\n",
      "Iter-45590, train loss-1.8816, acc-0.5000, valid loss-1.8874, acc-0.4770, test loss-1.8883, acc-0.4707\n",
      "Iter-45600, train loss-1.9250, acc-0.4000, valid loss-1.8873, acc-0.4770, test loss-1.8882, acc-0.4707\n",
      "Iter-45610, train loss-1.8855, acc-0.4200, valid loss-1.8872, acc-0.4770, test loss-1.8881, acc-0.4707\n",
      "Iter-45620, train loss-1.9057, acc-0.4200, valid loss-1.8872, acc-0.4772, test loss-1.8881, acc-0.4708\n",
      "Iter-45630, train loss-1.8794, acc-0.4200, valid loss-1.8871, acc-0.4772, test loss-1.8880, acc-0.4709\n",
      "Iter-45640, train loss-1.8980, acc-0.5600, valid loss-1.8870, acc-0.4772, test loss-1.8879, acc-0.4710\n",
      "Iter-45650, train loss-1.8368, acc-0.4800, valid loss-1.8870, acc-0.4774, test loss-1.8879, acc-0.4710\n",
      "Iter-45660, train loss-1.9432, acc-0.4000, valid loss-1.8869, acc-0.4774, test loss-1.8878, acc-0.4710\n",
      "Iter-45670, train loss-1.9544, acc-0.3800, valid loss-1.8869, acc-0.4776, test loss-1.8878, acc-0.4710\n",
      "Iter-45680, train loss-1.8224, acc-0.6800, valid loss-1.8868, acc-0.4780, test loss-1.8877, acc-0.4710\n",
      "Iter-45690, train loss-1.9514, acc-0.4800, valid loss-1.8867, acc-0.4780, test loss-1.8876, acc-0.4710\n",
      "Iter-45700, train loss-1.8302, acc-0.5000, valid loss-1.8867, acc-0.4780, test loss-1.8876, acc-0.4710\n",
      "Iter-45710, train loss-1.8617, acc-0.4800, valid loss-1.8866, acc-0.4780, test loss-1.8875, acc-0.4710\n",
      "Iter-45720, train loss-1.8855, acc-0.5200, valid loss-1.8866, acc-0.4782, test loss-1.8874, acc-0.4711\n",
      "Iter-45730, train loss-1.9541, acc-0.3800, valid loss-1.8865, acc-0.4782, test loss-1.8874, acc-0.4711\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-45740, train loss-1.8579, acc-0.5400, valid loss-1.8864, acc-0.4784, test loss-1.8873, acc-0.4710\n",
      "Iter-45750, train loss-1.8073, acc-0.5400, valid loss-1.8864, acc-0.4786, test loss-1.8873, acc-0.4712\n",
      "Iter-45760, train loss-1.8509, acc-0.3800, valid loss-1.8863, acc-0.4786, test loss-1.8872, acc-0.4710\n",
      "Iter-45770, train loss-1.9269, acc-0.5000, valid loss-1.8862, acc-0.4782, test loss-1.8871, acc-0.4711\n",
      "Iter-45780, train loss-1.9778, acc-0.4000, valid loss-1.8862, acc-0.4784, test loss-1.8871, acc-0.4712\n",
      "Iter-45790, train loss-1.9478, acc-0.4400, valid loss-1.8861, acc-0.4786, test loss-1.8870, acc-0.4713\n",
      "Iter-45800, train loss-1.8612, acc-0.4600, valid loss-1.8861, acc-0.4786, test loss-1.8869, acc-0.4713\n",
      "Iter-45810, train loss-1.9716, acc-0.4200, valid loss-1.8860, acc-0.4786, test loss-1.8869, acc-0.4713\n",
      "Iter-45820, train loss-2.0306, acc-0.3600, valid loss-1.8859, acc-0.4786, test loss-1.8868, acc-0.4713\n",
      "Iter-45830, train loss-1.9443, acc-0.5600, valid loss-1.8859, acc-0.4784, test loss-1.8868, acc-0.4713\n",
      "Iter-45840, train loss-1.8721, acc-0.4800, valid loss-1.8858, acc-0.4784, test loss-1.8867, acc-0.4715\n",
      "Iter-45850, train loss-1.9304, acc-0.4000, valid loss-1.8858, acc-0.4784, test loss-1.8866, acc-0.4717\n",
      "Iter-45860, train loss-1.8939, acc-0.5400, valid loss-1.8857, acc-0.4782, test loss-1.8866, acc-0.4716\n",
      "Iter-45870, train loss-1.8431, acc-0.5400, valid loss-1.8856, acc-0.4782, test loss-1.8865, acc-0.4717\n",
      "Iter-45880, train loss-1.8050, acc-0.5400, valid loss-1.8856, acc-0.4782, test loss-1.8865, acc-0.4716\n",
      "Iter-45890, train loss-1.8580, acc-0.4600, valid loss-1.8855, acc-0.4780, test loss-1.8864, acc-0.4714\n",
      "Iter-45900, train loss-1.8988, acc-0.4400, valid loss-1.8854, acc-0.4784, test loss-1.8863, acc-0.4716\n",
      "Iter-45910, train loss-1.8377, acc-0.5800, valid loss-1.8854, acc-0.4782, test loss-1.8863, acc-0.4717\n",
      "Iter-45920, train loss-1.8616, acc-0.5800, valid loss-1.8853, acc-0.4784, test loss-1.8862, acc-0.4716\n",
      "Iter-45930, train loss-1.8843, acc-0.4600, valid loss-1.8853, acc-0.4786, test loss-1.8862, acc-0.4716\n",
      "Iter-45940, train loss-1.9718, acc-0.3600, valid loss-1.8852, acc-0.4786, test loss-1.8861, acc-0.4716\n",
      "Iter-45950, train loss-1.9258, acc-0.4600, valid loss-1.8852, acc-0.4786, test loss-1.8860, acc-0.4716\n",
      "Iter-45960, train loss-1.9094, acc-0.5000, valid loss-1.8851, acc-0.4786, test loss-1.8860, acc-0.4716\n",
      "Iter-45970, train loss-1.9739, acc-0.4400, valid loss-1.8850, acc-0.4782, test loss-1.8859, acc-0.4716\n",
      "Iter-45980, train loss-1.9248, acc-0.4800, valid loss-1.8850, acc-0.4782, test loss-1.8859, acc-0.4716\n",
      "Iter-45990, train loss-1.9150, acc-0.4000, valid loss-1.8849, acc-0.4782, test loss-1.8858, acc-0.4717\n",
      "Iter-46000, train loss-1.9634, acc-0.4200, valid loss-1.8848, acc-0.4780, test loss-1.8857, acc-0.4720\n",
      "Iter-46010, train loss-1.8768, acc-0.5200, valid loss-1.8848, acc-0.4780, test loss-1.8857, acc-0.4719\n",
      "Iter-46020, train loss-1.9149, acc-0.5200, valid loss-1.8847, acc-0.4782, test loss-1.8856, acc-0.4723\n",
      "Iter-46030, train loss-1.8639, acc-0.4400, valid loss-1.8847, acc-0.4780, test loss-1.8855, acc-0.4721\n",
      "Iter-46040, train loss-1.8795, acc-0.5200, valid loss-1.8846, acc-0.4780, test loss-1.8855, acc-0.4721\n",
      "Iter-46050, train loss-1.8273, acc-0.5800, valid loss-1.8845, acc-0.4782, test loss-1.8854, acc-0.4723\n",
      "Iter-46060, train loss-1.8962, acc-0.4600, valid loss-1.8845, acc-0.4784, test loss-1.8854, acc-0.4720\n",
      "Iter-46070, train loss-1.8468, acc-0.5800, valid loss-1.8844, acc-0.4784, test loss-1.8853, acc-0.4725\n",
      "Iter-46080, train loss-1.8492, acc-0.5600, valid loss-1.8844, acc-0.4784, test loss-1.8852, acc-0.4726\n",
      "Iter-46090, train loss-1.9363, acc-0.4600, valid loss-1.8843, acc-0.4784, test loss-1.8852, acc-0.4725\n",
      "Iter-46100, train loss-1.8722, acc-0.5600, valid loss-1.8842, acc-0.4784, test loss-1.8851, acc-0.4723\n",
      "Iter-46110, train loss-1.9316, acc-0.5800, valid loss-1.8842, acc-0.4784, test loss-1.8851, acc-0.4726\n",
      "Iter-46120, train loss-1.9165, acc-0.5200, valid loss-1.8841, acc-0.4784, test loss-1.8850, acc-0.4726\n",
      "Iter-46130, train loss-1.8751, acc-0.4600, valid loss-1.8841, acc-0.4784, test loss-1.8850, acc-0.4725\n",
      "Iter-46140, train loss-1.8693, acc-0.4200, valid loss-1.8840, acc-0.4784, test loss-1.8849, acc-0.4726\n",
      "Iter-46150, train loss-1.8949, acc-0.4800, valid loss-1.8839, acc-0.4784, test loss-1.8848, acc-0.4728\n",
      "Iter-46160, train loss-1.8526, acc-0.4800, valid loss-1.8839, acc-0.4784, test loss-1.8848, acc-0.4728\n",
      "Iter-46170, train loss-1.8650, acc-0.5400, valid loss-1.8838, acc-0.4786, test loss-1.8847, acc-0.4728\n",
      "Iter-46180, train loss-1.9723, acc-0.3600, valid loss-1.8838, acc-0.4786, test loss-1.8847, acc-0.4727\n",
      "Iter-46190, train loss-1.8740, acc-0.4000, valid loss-1.8837, acc-0.4786, test loss-1.8846, acc-0.4729\n",
      "Iter-46200, train loss-1.8836, acc-0.5000, valid loss-1.8836, acc-0.4786, test loss-1.8845, acc-0.4727\n",
      "Iter-46210, train loss-1.9284, acc-0.4200, valid loss-1.8836, acc-0.4786, test loss-1.8845, acc-0.4728\n",
      "Iter-46220, train loss-1.8846, acc-0.4000, valid loss-1.8835, acc-0.4784, test loss-1.8844, acc-0.4728\n",
      "Iter-46230, train loss-1.9346, acc-0.4200, valid loss-1.8835, acc-0.4784, test loss-1.8843, acc-0.4729\n",
      "Iter-46240, train loss-1.8501, acc-0.4800, valid loss-1.8834, acc-0.4786, test loss-1.8843, acc-0.4727\n",
      "Iter-46250, train loss-1.9182, acc-0.4200, valid loss-1.8833, acc-0.4790, test loss-1.8842, acc-0.4729\n",
      "Iter-46260, train loss-1.8843, acc-0.4800, valid loss-1.8833, acc-0.4794, test loss-1.8842, acc-0.4731\n",
      "Iter-46270, train loss-1.9073, acc-0.5400, valid loss-1.8832, acc-0.4794, test loss-1.8841, acc-0.4729\n",
      "Iter-46280, train loss-1.8493, acc-0.4800, valid loss-1.8832, acc-0.4794, test loss-1.8840, acc-0.4730\n",
      "Iter-46290, train loss-1.8472, acc-0.5200, valid loss-1.8831, acc-0.4792, test loss-1.8840, acc-0.4729\n",
      "Iter-46300, train loss-1.9352, acc-0.4200, valid loss-1.8830, acc-0.4786, test loss-1.8839, acc-0.4730\n",
      "Iter-46310, train loss-1.8580, acc-0.4800, valid loss-1.8830, acc-0.4790, test loss-1.8839, acc-0.4731\n",
      "Iter-46320, train loss-1.9334, acc-0.4000, valid loss-1.8829, acc-0.4790, test loss-1.8838, acc-0.4731\n",
      "Iter-46330, train loss-1.9207, acc-0.4400, valid loss-1.8828, acc-0.4794, test loss-1.8837, acc-0.4731\n",
      "Iter-46340, train loss-1.9642, acc-0.3800, valid loss-1.8828, acc-0.4794, test loss-1.8837, acc-0.4733\n",
      "Iter-46350, train loss-1.8069, acc-0.5200, valid loss-1.8827, acc-0.4794, test loss-1.8836, acc-0.4734\n",
      "Iter-46360, train loss-1.8716, acc-0.3200, valid loss-1.8827, acc-0.4794, test loss-1.8835, acc-0.4734\n",
      "Iter-46370, train loss-1.8948, acc-0.5400, valid loss-1.8826, acc-0.4794, test loss-1.8835, acc-0.4734\n",
      "Iter-46380, train loss-1.8780, acc-0.4600, valid loss-1.8825, acc-0.4794, test loss-1.8834, acc-0.4732\n",
      "Iter-46390, train loss-1.8297, acc-0.4800, valid loss-1.8825, acc-0.4792, test loss-1.8834, acc-0.4732\n",
      "Iter-46400, train loss-1.9043, acc-0.4800, valid loss-1.8824, acc-0.4790, test loss-1.8833, acc-0.4731\n",
      "Iter-46410, train loss-1.8549, acc-0.5400, valid loss-1.8823, acc-0.4792, test loss-1.8832, acc-0.4730\n",
      "Iter-46420, train loss-1.8370, acc-0.5600, valid loss-1.8823, acc-0.4792, test loss-1.8832, acc-0.4732\n",
      "Iter-46430, train loss-1.9171, acc-0.5200, valid loss-1.8822, acc-0.4792, test loss-1.8831, acc-0.4733\n",
      "Iter-46440, train loss-1.7942, acc-0.5000, valid loss-1.8821, acc-0.4790, test loss-1.8830, acc-0.4730\n",
      "Iter-46450, train loss-1.8491, acc-0.5200, valid loss-1.8821, acc-0.4790, test loss-1.8830, acc-0.4732\n",
      "Iter-46460, train loss-2.0002, acc-0.2800, valid loss-1.8820, acc-0.4790, test loss-1.8829, acc-0.4731\n",
      "Iter-46470, train loss-1.8701, acc-0.5200, valid loss-1.8820, acc-0.4790, test loss-1.8829, acc-0.4731\n",
      "Iter-46480, train loss-1.9672, acc-0.3200, valid loss-1.8819, acc-0.4794, test loss-1.8828, acc-0.4734\n",
      "Iter-46490, train loss-1.9847, acc-0.3000, valid loss-1.8818, acc-0.4794, test loss-1.8827, acc-0.4734\n",
      "Iter-46500, train loss-1.9430, acc-0.5200, valid loss-1.8818, acc-0.4794, test loss-1.8827, acc-0.4736\n",
      "Iter-46510, train loss-1.9657, acc-0.4000, valid loss-1.8817, acc-0.4794, test loss-1.8826, acc-0.4734\n",
      "Iter-46520, train loss-1.9664, acc-0.3600, valid loss-1.8817, acc-0.4792, test loss-1.8826, acc-0.4735\n",
      "Iter-46530, train loss-1.8281, acc-0.6000, valid loss-1.8816, acc-0.4794, test loss-1.8825, acc-0.4737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-46540, train loss-1.8977, acc-0.4000, valid loss-1.8815, acc-0.4792, test loss-1.8824, acc-0.4736\n",
      "Iter-46550, train loss-1.9611, acc-0.3800, valid loss-1.8815, acc-0.4794, test loss-1.8824, acc-0.4736\n",
      "Iter-46560, train loss-1.9764, acc-0.3400, valid loss-1.8814, acc-0.4794, test loss-1.8823, acc-0.4737\n",
      "Iter-46570, train loss-1.9528, acc-0.4200, valid loss-1.8814, acc-0.4794, test loss-1.8823, acc-0.4735\n",
      "Iter-46580, train loss-1.9368, acc-0.4200, valid loss-1.8813, acc-0.4792, test loss-1.8822, acc-0.4736\n",
      "Iter-46590, train loss-1.9116, acc-0.5200, valid loss-1.8812, acc-0.4792, test loss-1.8821, acc-0.4736\n",
      "Iter-46600, train loss-1.8523, acc-0.5200, valid loss-1.8812, acc-0.4792, test loss-1.8821, acc-0.4737\n",
      "Iter-46610, train loss-1.9410, acc-0.4400, valid loss-1.8811, acc-0.4792, test loss-1.8820, acc-0.4738\n",
      "Iter-46620, train loss-1.8880, acc-0.5400, valid loss-1.8811, acc-0.4794, test loss-1.8819, acc-0.4738\n",
      "Iter-46630, train loss-1.8586, acc-0.4800, valid loss-1.8810, acc-0.4794, test loss-1.8819, acc-0.4738\n",
      "Iter-46640, train loss-1.7280, acc-0.6400, valid loss-1.8809, acc-0.4792, test loss-1.8818, acc-0.4737\n",
      "Iter-46650, train loss-1.8504, acc-0.5800, valid loss-1.8809, acc-0.4794, test loss-1.8818, acc-0.4738\n",
      "Iter-46660, train loss-1.8433, acc-0.6000, valid loss-1.8808, acc-0.4794, test loss-1.8817, acc-0.4737\n",
      "Iter-46670, train loss-1.8165, acc-0.4800, valid loss-1.8808, acc-0.4794, test loss-1.8816, acc-0.4737\n",
      "Iter-46680, train loss-1.8379, acc-0.5000, valid loss-1.8807, acc-0.4796, test loss-1.8816, acc-0.4737\n",
      "Iter-46690, train loss-1.8941, acc-0.4400, valid loss-1.8806, acc-0.4796, test loss-1.8815, acc-0.4737\n",
      "Iter-46700, train loss-1.9542, acc-0.4200, valid loss-1.8806, acc-0.4796, test loss-1.8815, acc-0.4737\n",
      "Iter-46710, train loss-1.8939, acc-0.4800, valid loss-1.8805, acc-0.4796, test loss-1.8814, acc-0.4737\n",
      "Iter-46720, train loss-1.9563, acc-0.4400, valid loss-1.8805, acc-0.4798, test loss-1.8813, acc-0.4736\n",
      "Iter-46730, train loss-1.9490, acc-0.3800, valid loss-1.8804, acc-0.4796, test loss-1.8813, acc-0.4739\n",
      "Iter-46740, train loss-1.8610, acc-0.6000, valid loss-1.8803, acc-0.4796, test loss-1.8812, acc-0.4739\n",
      "Iter-46750, train loss-1.8793, acc-0.4800, valid loss-1.8803, acc-0.4796, test loss-1.8812, acc-0.4737\n",
      "Iter-46760, train loss-1.9664, acc-0.4400, valid loss-1.8802, acc-0.4796, test loss-1.8811, acc-0.4741\n",
      "Iter-46770, train loss-1.9941, acc-0.4400, valid loss-1.8802, acc-0.4796, test loss-1.8810, acc-0.4739\n",
      "Iter-46780, train loss-1.9077, acc-0.4600, valid loss-1.8801, acc-0.4794, test loss-1.8810, acc-0.4741\n",
      "Iter-46790, train loss-1.9592, acc-0.3600, valid loss-1.8800, acc-0.4794, test loss-1.8809, acc-0.4742\n",
      "Iter-46800, train loss-1.8487, acc-0.5200, valid loss-1.8800, acc-0.4796, test loss-1.8809, acc-0.4741\n",
      "Iter-46810, train loss-1.8256, acc-0.5200, valid loss-1.8799, acc-0.4794, test loss-1.8808, acc-0.4743\n",
      "Iter-46820, train loss-1.8846, acc-0.4800, valid loss-1.8799, acc-0.4794, test loss-1.8807, acc-0.4743\n",
      "Iter-46830, train loss-1.8526, acc-0.4600, valid loss-1.8798, acc-0.4794, test loss-1.8807, acc-0.4741\n",
      "Iter-46840, train loss-1.9404, acc-0.5000, valid loss-1.8797, acc-0.4794, test loss-1.8806, acc-0.4744\n",
      "Iter-46850, train loss-1.8710, acc-0.4600, valid loss-1.8797, acc-0.4798, test loss-1.8806, acc-0.4747\n",
      "Iter-46860, train loss-1.9100, acc-0.4400, valid loss-1.8796, acc-0.4798, test loss-1.8805, acc-0.4747\n",
      "Iter-46870, train loss-1.9704, acc-0.4400, valid loss-1.8796, acc-0.4802, test loss-1.8804, acc-0.4747\n",
      "Iter-46880, train loss-1.8909, acc-0.4400, valid loss-1.8795, acc-0.4804, test loss-1.8804, acc-0.4748\n",
      "Iter-46890, train loss-1.7774, acc-0.5400, valid loss-1.8794, acc-0.4804, test loss-1.8803, acc-0.4750\n",
      "Iter-46900, train loss-1.9359, acc-0.4400, valid loss-1.8794, acc-0.4804, test loss-1.8803, acc-0.4748\n",
      "Iter-46910, train loss-1.8845, acc-0.4800, valid loss-1.8793, acc-0.4802, test loss-1.8802, acc-0.4748\n",
      "Iter-46920, train loss-1.9808, acc-0.5400, valid loss-1.8793, acc-0.4800, test loss-1.8801, acc-0.4748\n",
      "Iter-46930, train loss-1.9140, acc-0.4800, valid loss-1.8792, acc-0.4802, test loss-1.8801, acc-0.4747\n",
      "Iter-46940, train loss-1.8428, acc-0.4400, valid loss-1.8791, acc-0.4798, test loss-1.8800, acc-0.4744\n",
      "Iter-46950, train loss-1.9088, acc-0.4800, valid loss-1.8791, acc-0.4802, test loss-1.8800, acc-0.4746\n",
      "Iter-46960, train loss-1.8963, acc-0.4400, valid loss-1.8790, acc-0.4798, test loss-1.8799, acc-0.4746\n",
      "Iter-46970, train loss-1.9625, acc-0.4400, valid loss-1.8790, acc-0.4798, test loss-1.8798, acc-0.4747\n",
      "Iter-46980, train loss-1.8853, acc-0.3800, valid loss-1.8789, acc-0.4800, test loss-1.8798, acc-0.4748\n",
      "Iter-46990, train loss-1.8724, acc-0.4600, valid loss-1.8789, acc-0.4802, test loss-1.8797, acc-0.4748\n",
      "Iter-47000, train loss-1.9012, acc-0.4400, valid loss-1.8788, acc-0.4804, test loss-1.8797, acc-0.4748\n",
      "Iter-47010, train loss-1.9037, acc-0.4200, valid loss-1.8787, acc-0.4802, test loss-1.8796, acc-0.4750\n",
      "Iter-47020, train loss-1.8246, acc-0.5400, valid loss-1.8787, acc-0.4802, test loss-1.8795, acc-0.4749\n",
      "Iter-47030, train loss-1.8833, acc-0.4600, valid loss-1.8786, acc-0.4802, test loss-1.8795, acc-0.4748\n",
      "Iter-47040, train loss-1.8576, acc-0.5000, valid loss-1.8786, acc-0.4802, test loss-1.8794, acc-0.4749\n",
      "Iter-47050, train loss-1.9136, acc-0.5000, valid loss-1.8785, acc-0.4802, test loss-1.8794, acc-0.4748\n",
      "Iter-47060, train loss-1.8832, acc-0.4800, valid loss-1.8784, acc-0.4802, test loss-1.8793, acc-0.4746\n",
      "Iter-47070, train loss-1.8360, acc-0.5400, valid loss-1.8784, acc-0.4804, test loss-1.8792, acc-0.4749\n",
      "Iter-47080, train loss-1.8476, acc-0.5200, valid loss-1.8783, acc-0.4804, test loss-1.8792, acc-0.4750\n",
      "Iter-47090, train loss-1.9529, acc-0.5200, valid loss-1.8783, acc-0.4804, test loss-1.8791, acc-0.4747\n",
      "Iter-47100, train loss-1.9211, acc-0.4200, valid loss-1.8782, acc-0.4804, test loss-1.8791, acc-0.4749\n",
      "Iter-47110, train loss-1.8145, acc-0.5400, valid loss-1.8781, acc-0.4804, test loss-1.8790, acc-0.4750\n",
      "Iter-47120, train loss-1.8337, acc-0.4600, valid loss-1.8781, acc-0.4804, test loss-1.8789, acc-0.4750\n",
      "Iter-47130, train loss-1.9006, acc-0.4000, valid loss-1.8780, acc-0.4806, test loss-1.8789, acc-0.4752\n",
      "Iter-47140, train loss-1.8982, acc-0.5800, valid loss-1.8780, acc-0.4804, test loss-1.8788, acc-0.4748\n",
      "Iter-47150, train loss-1.7816, acc-0.5800, valid loss-1.8779, acc-0.4804, test loss-1.8788, acc-0.4749\n",
      "Iter-47160, train loss-1.9124, acc-0.3800, valid loss-1.8778, acc-0.4804, test loss-1.8787, acc-0.4750\n",
      "Iter-47170, train loss-1.9071, acc-0.3400, valid loss-1.8778, acc-0.4802, test loss-1.8786, acc-0.4751\n",
      "Iter-47180, train loss-1.8941, acc-0.5200, valid loss-1.8777, acc-0.4802, test loss-1.8786, acc-0.4748\n",
      "Iter-47190, train loss-1.8582, acc-0.5200, valid loss-1.8777, acc-0.4804, test loss-1.8785, acc-0.4749\n",
      "Iter-47200, train loss-2.0266, acc-0.3400, valid loss-1.8776, acc-0.4806, test loss-1.8784, acc-0.4751\n",
      "Iter-47210, train loss-1.8486, acc-0.4800, valid loss-1.8775, acc-0.4806, test loss-1.8784, acc-0.4751\n",
      "Iter-47220, train loss-1.8604, acc-0.5000, valid loss-1.8775, acc-0.4808, test loss-1.8783, acc-0.4749\n",
      "Iter-47230, train loss-1.9116, acc-0.4400, valid loss-1.8774, acc-0.4806, test loss-1.8783, acc-0.4751\n",
      "Iter-47240, train loss-1.8314, acc-0.5200, valid loss-1.8774, acc-0.4806, test loss-1.8782, acc-0.4751\n",
      "Iter-47250, train loss-1.8983, acc-0.4000, valid loss-1.8773, acc-0.4806, test loss-1.8781, acc-0.4751\n",
      "Iter-47260, train loss-1.8353, acc-0.5800, valid loss-1.8772, acc-0.4806, test loss-1.8781, acc-0.4751\n",
      "Iter-47270, train loss-1.8742, acc-0.5200, valid loss-1.8772, acc-0.4806, test loss-1.8780, acc-0.4751\n",
      "Iter-47280, train loss-1.9251, acc-0.4200, valid loss-1.8771, acc-0.4806, test loss-1.8780, acc-0.4752\n",
      "Iter-47290, train loss-1.8908, acc-0.4200, valid loss-1.8771, acc-0.4808, test loss-1.8779, acc-0.4751\n",
      "Iter-47300, train loss-1.8987, acc-0.3600, valid loss-1.8770, acc-0.4810, test loss-1.8779, acc-0.4752\n",
      "Iter-47310, train loss-1.8351, acc-0.5600, valid loss-1.8769, acc-0.4808, test loss-1.8778, acc-0.4753\n",
      "Iter-47320, train loss-1.8549, acc-0.4800, valid loss-1.8769, acc-0.4810, test loss-1.8777, acc-0.4753\n",
      "Iter-47330, train loss-1.9417, acc-0.3600, valid loss-1.8768, acc-0.4810, test loss-1.8777, acc-0.4755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-47340, train loss-1.8081, acc-0.5200, valid loss-1.8768, acc-0.4810, test loss-1.8776, acc-0.4752\n",
      "Iter-47350, train loss-1.8584, acc-0.5000, valid loss-1.8767, acc-0.4812, test loss-1.8775, acc-0.4756\n",
      "Iter-47360, train loss-1.8235, acc-0.5200, valid loss-1.8767, acc-0.4812, test loss-1.8775, acc-0.4757\n",
      "Iter-47370, train loss-1.8320, acc-0.5600, valid loss-1.8766, acc-0.4812, test loss-1.8774, acc-0.4760\n",
      "Iter-47380, train loss-1.8922, acc-0.5000, valid loss-1.8765, acc-0.4812, test loss-1.8774, acc-0.4759\n",
      "Iter-47390, train loss-1.9981, acc-0.3400, valid loss-1.8765, acc-0.4812, test loss-1.8773, acc-0.4759\n",
      "Iter-47400, train loss-1.9210, acc-0.4600, valid loss-1.8764, acc-0.4812, test loss-1.8772, acc-0.4760\n",
      "Iter-47410, train loss-1.8882, acc-0.5000, valid loss-1.8764, acc-0.4812, test loss-1.8772, acc-0.4760\n",
      "Iter-47420, train loss-1.8844, acc-0.5600, valid loss-1.8763, acc-0.4814, test loss-1.8771, acc-0.4760\n",
      "Iter-47430, train loss-1.8258, acc-0.4600, valid loss-1.8762, acc-0.4814, test loss-1.8771, acc-0.4759\n",
      "Iter-47440, train loss-1.9060, acc-0.4000, valid loss-1.8762, acc-0.4814, test loss-1.8770, acc-0.4760\n",
      "Iter-47450, train loss-1.9344, acc-0.4600, valid loss-1.8761, acc-0.4814, test loss-1.8769, acc-0.4760\n",
      "Iter-47460, train loss-1.8221, acc-0.5800, valid loss-1.8761, acc-0.4814, test loss-1.8769, acc-0.4758\n",
      "Iter-47470, train loss-1.7825, acc-0.5600, valid loss-1.8760, acc-0.4814, test loss-1.8768, acc-0.4758\n",
      "Iter-47480, train loss-1.9821, acc-0.4000, valid loss-1.8759, acc-0.4814, test loss-1.8768, acc-0.4757\n",
      "Iter-47490, train loss-1.8769, acc-0.5200, valid loss-1.8759, acc-0.4814, test loss-1.8767, acc-0.4759\n",
      "Iter-47500, train loss-1.9302, acc-0.4000, valid loss-1.8758, acc-0.4816, test loss-1.8766, acc-0.4757\n",
      "Iter-47510, train loss-1.9469, acc-0.2800, valid loss-1.8758, acc-0.4816, test loss-1.8766, acc-0.4758\n",
      "Iter-47520, train loss-1.8771, acc-0.4600, valid loss-1.8757, acc-0.4814, test loss-1.8765, acc-0.4759\n",
      "Iter-47530, train loss-1.8927, acc-0.5000, valid loss-1.8756, acc-0.4816, test loss-1.8765, acc-0.4760\n",
      "Iter-47540, train loss-1.8519, acc-0.4200, valid loss-1.8756, acc-0.4814, test loss-1.8764, acc-0.4761\n",
      "Iter-47550, train loss-1.9633, acc-0.4400, valid loss-1.8755, acc-0.4814, test loss-1.8763, acc-0.4760\n",
      "Iter-47560, train loss-1.9611, acc-0.3600, valid loss-1.8754, acc-0.4816, test loss-1.8763, acc-0.4759\n",
      "Iter-47570, train loss-1.9966, acc-0.3200, valid loss-1.8754, acc-0.4814, test loss-1.8762, acc-0.4758\n",
      "Iter-47580, train loss-1.8739, acc-0.4400, valid loss-1.8753, acc-0.4816, test loss-1.8762, acc-0.4757\n",
      "Iter-47590, train loss-1.9426, acc-0.4000, valid loss-1.8753, acc-0.4816, test loss-1.8761, acc-0.4758\n",
      "Iter-47600, train loss-1.8313, acc-0.5600, valid loss-1.8752, acc-0.4818, test loss-1.8761, acc-0.4759\n",
      "Iter-47610, train loss-1.8944, acc-0.4800, valid loss-1.8752, acc-0.4816, test loss-1.8760, acc-0.4760\n",
      "Iter-47620, train loss-1.9037, acc-0.4600, valid loss-1.8751, acc-0.4818, test loss-1.8759, acc-0.4762\n",
      "Iter-47630, train loss-1.8611, acc-0.5400, valid loss-1.8751, acc-0.4818, test loss-1.8759, acc-0.4762\n",
      "Iter-47640, train loss-1.8378, acc-0.4600, valid loss-1.8750, acc-0.4818, test loss-1.8758, acc-0.4762\n",
      "Iter-47650, train loss-1.9267, acc-0.4400, valid loss-1.8749, acc-0.4824, test loss-1.8758, acc-0.4763\n",
      "Iter-47660, train loss-1.9255, acc-0.5000, valid loss-1.8749, acc-0.4824, test loss-1.8757, acc-0.4763\n",
      "Iter-47670, train loss-1.9134, acc-0.4800, valid loss-1.8748, acc-0.4820, test loss-1.8756, acc-0.4761\n",
      "Iter-47680, train loss-1.8539, acc-0.4600, valid loss-1.8748, acc-0.4824, test loss-1.8756, acc-0.4762\n",
      "Iter-47690, train loss-1.9755, acc-0.4000, valid loss-1.8747, acc-0.4826, test loss-1.8755, acc-0.4762\n",
      "Iter-47700, train loss-1.8685, acc-0.5600, valid loss-1.8746, acc-0.4824, test loss-1.8755, acc-0.4762\n",
      "Iter-47710, train loss-1.8688, acc-0.5200, valid loss-1.8746, acc-0.4824, test loss-1.8754, acc-0.4764\n",
      "Iter-47720, train loss-1.9162, acc-0.4800, valid loss-1.8745, acc-0.4826, test loss-1.8753, acc-0.4764\n",
      "Iter-47730, train loss-1.9798, acc-0.4400, valid loss-1.8745, acc-0.4824, test loss-1.8753, acc-0.4766\n",
      "Iter-47740, train loss-1.8747, acc-0.5000, valid loss-1.8744, acc-0.4824, test loss-1.8752, acc-0.4766\n",
      "Iter-47750, train loss-1.8485, acc-0.5000, valid loss-1.8743, acc-0.4822, test loss-1.8752, acc-0.4765\n",
      "Iter-47760, train loss-1.8836, acc-0.5400, valid loss-1.8743, acc-0.4822, test loss-1.8751, acc-0.4766\n",
      "Iter-47770, train loss-1.9160, acc-0.4600, valid loss-1.8742, acc-0.4824, test loss-1.8751, acc-0.4767\n",
      "Iter-47780, train loss-1.9571, acc-0.4000, valid loss-1.8742, acc-0.4824, test loss-1.8750, acc-0.4767\n",
      "Iter-47790, train loss-1.8097, acc-0.5400, valid loss-1.8741, acc-0.4824, test loss-1.8749, acc-0.4767\n",
      "Iter-47800, train loss-1.9366, acc-0.3400, valid loss-1.8740, acc-0.4824, test loss-1.8749, acc-0.4766\n",
      "Iter-47810, train loss-1.8292, acc-0.5400, valid loss-1.8740, acc-0.4824, test loss-1.8748, acc-0.4766\n",
      "Iter-47820, train loss-1.8628, acc-0.5600, valid loss-1.8739, acc-0.4824, test loss-1.8747, acc-0.4765\n",
      "Iter-47830, train loss-1.9511, acc-0.4000, valid loss-1.8739, acc-0.4822, test loss-1.8747, acc-0.4765\n",
      "Iter-47840, train loss-1.8693, acc-0.4600, valid loss-1.8738, acc-0.4824, test loss-1.8746, acc-0.4765\n",
      "Iter-47850, train loss-1.9465, acc-0.4600, valid loss-1.8737, acc-0.4824, test loss-1.8746, acc-0.4765\n",
      "Iter-47860, train loss-1.8357, acc-0.5600, valid loss-1.8737, acc-0.4820, test loss-1.8745, acc-0.4764\n",
      "Iter-47870, train loss-1.8413, acc-0.5200, valid loss-1.8736, acc-0.4822, test loss-1.8745, acc-0.4765\n",
      "Iter-47880, train loss-1.7780, acc-0.5800, valid loss-1.8736, acc-0.4822, test loss-1.8744, acc-0.4765\n",
      "Iter-47890, train loss-1.9004, acc-0.4600, valid loss-1.8735, acc-0.4822, test loss-1.8743, acc-0.4764\n",
      "Iter-47900, train loss-1.8978, acc-0.4200, valid loss-1.8734, acc-0.4822, test loss-1.8743, acc-0.4766\n",
      "Iter-47910, train loss-1.7670, acc-0.6000, valid loss-1.8734, acc-0.4822, test loss-1.8742, acc-0.4765\n",
      "Iter-47920, train loss-1.8684, acc-0.4200, valid loss-1.8733, acc-0.4822, test loss-1.8742, acc-0.4765\n",
      "Iter-47930, train loss-1.9299, acc-0.4000, valid loss-1.8733, acc-0.4822, test loss-1.8741, acc-0.4764\n",
      "Iter-47940, train loss-1.8907, acc-0.4000, valid loss-1.8732, acc-0.4822, test loss-1.8740, acc-0.4763\n",
      "Iter-47950, train loss-1.9321, acc-0.4400, valid loss-1.8731, acc-0.4822, test loss-1.8740, acc-0.4764\n",
      "Iter-47960, train loss-1.8453, acc-0.5400, valid loss-1.8731, acc-0.4820, test loss-1.8739, acc-0.4764\n",
      "Iter-47970, train loss-1.8234, acc-0.5000, valid loss-1.8730, acc-0.4822, test loss-1.8739, acc-0.4765\n",
      "Iter-47980, train loss-1.8479, acc-0.5600, valid loss-1.8730, acc-0.4824, test loss-1.8738, acc-0.4766\n",
      "Iter-47990, train loss-1.8733, acc-0.4800, valid loss-1.8729, acc-0.4824, test loss-1.8737, acc-0.4767\n",
      "Iter-48000, train loss-1.8268, acc-0.5600, valid loss-1.8728, acc-0.4824, test loss-1.8737, acc-0.4768\n",
      "Iter-48010, train loss-1.8500, acc-0.5200, valid loss-1.8728, acc-0.4824, test loss-1.8736, acc-0.4768\n",
      "Iter-48020, train loss-1.8624, acc-0.4600, valid loss-1.8727, acc-0.4820, test loss-1.8736, acc-0.4768\n",
      "Iter-48030, train loss-1.8124, acc-0.4600, valid loss-1.8727, acc-0.4820, test loss-1.8735, acc-0.4767\n",
      "Iter-48040, train loss-1.9083, acc-0.4400, valid loss-1.8726, acc-0.4820, test loss-1.8734, acc-0.4767\n",
      "Iter-48050, train loss-1.8800, acc-0.4200, valid loss-1.8725, acc-0.4820, test loss-1.8734, acc-0.4768\n",
      "Iter-48060, train loss-1.8668, acc-0.4800, valid loss-1.8725, acc-0.4822, test loss-1.8733, acc-0.4767\n",
      "Iter-48070, train loss-1.9207, acc-0.4600, valid loss-1.8724, acc-0.4824, test loss-1.8733, acc-0.4768\n",
      "Iter-48080, train loss-1.9617, acc-0.3600, valid loss-1.8724, acc-0.4822, test loss-1.8732, acc-0.4768\n",
      "Iter-48090, train loss-1.8443, acc-0.4800, valid loss-1.8723, acc-0.4824, test loss-1.8731, acc-0.4768\n",
      "Iter-48100, train loss-1.9732, acc-0.3800, valid loss-1.8722, acc-0.4824, test loss-1.8731, acc-0.4768\n",
      "Iter-48110, train loss-1.8236, acc-0.5000, valid loss-1.8722, acc-0.4824, test loss-1.8730, acc-0.4767\n",
      "Iter-48120, train loss-1.9022, acc-0.4400, valid loss-1.8721, acc-0.4822, test loss-1.8730, acc-0.4769\n",
      "Iter-48130, train loss-1.8420, acc-0.4200, valid loss-1.8721, acc-0.4824, test loss-1.8729, acc-0.4769\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48140, train loss-1.8678, acc-0.4600, valid loss-1.8720, acc-0.4824, test loss-1.8728, acc-0.4768\n",
      "Iter-48150, train loss-1.8546, acc-0.5600, valid loss-1.8719, acc-0.4824, test loss-1.8728, acc-0.4767\n",
      "Iter-48160, train loss-1.9589, acc-0.4600, valid loss-1.8719, acc-0.4824, test loss-1.8727, acc-0.4768\n",
      "Iter-48170, train loss-1.9493, acc-0.3800, valid loss-1.8718, acc-0.4824, test loss-1.8727, acc-0.4768\n",
      "Iter-48180, train loss-1.8734, acc-0.4400, valid loss-1.8718, acc-0.4828, test loss-1.8726, acc-0.4768\n",
      "Iter-48190, train loss-1.8729, acc-0.5600, valid loss-1.8717, acc-0.4826, test loss-1.8725, acc-0.4769\n",
      "Iter-48200, train loss-1.8670, acc-0.4400, valid loss-1.8716, acc-0.4826, test loss-1.8725, acc-0.4769\n",
      "Iter-48210, train loss-1.9608, acc-0.3600, valid loss-1.8716, acc-0.4828, test loss-1.8724, acc-0.4768\n",
      "Iter-48220, train loss-1.8537, acc-0.5200, valid loss-1.8715, acc-0.4828, test loss-1.8724, acc-0.4769\n",
      "Iter-48230, train loss-1.8099, acc-0.6400, valid loss-1.8715, acc-0.4828, test loss-1.8723, acc-0.4769\n",
      "Iter-48240, train loss-1.8863, acc-0.4600, valid loss-1.8714, acc-0.4826, test loss-1.8722, acc-0.4771\n",
      "Iter-48250, train loss-1.8740, acc-0.4800, valid loss-1.8714, acc-0.4826, test loss-1.8722, acc-0.4769\n",
      "Iter-48260, train loss-1.9056, acc-0.4800, valid loss-1.8713, acc-0.4826, test loss-1.8721, acc-0.4770\n",
      "Iter-48270, train loss-1.8995, acc-0.4800, valid loss-1.8712, acc-0.4826, test loss-1.8721, acc-0.4770\n",
      "Iter-48280, train loss-1.9375, acc-0.3800, valid loss-1.8712, acc-0.4826, test loss-1.8720, acc-0.4769\n",
      "Iter-48290, train loss-1.8543, acc-0.5400, valid loss-1.8711, acc-0.4828, test loss-1.8720, acc-0.4770\n",
      "Iter-48300, train loss-1.9031, acc-0.5000, valid loss-1.8711, acc-0.4828, test loss-1.8719, acc-0.4769\n",
      "Iter-48310, train loss-1.8966, acc-0.4600, valid loss-1.8710, acc-0.4826, test loss-1.8718, acc-0.4769\n",
      "Iter-48320, train loss-1.8096, acc-0.6000, valid loss-1.8710, acc-0.4832, test loss-1.8718, acc-0.4768\n",
      "Iter-48330, train loss-1.8897, acc-0.4000, valid loss-1.8709, acc-0.4828, test loss-1.8717, acc-0.4769\n",
      "Iter-48340, train loss-1.9652, acc-0.3600, valid loss-1.8708, acc-0.4828, test loss-1.8717, acc-0.4769\n",
      "Iter-48350, train loss-1.9541, acc-0.4800, valid loss-1.8708, acc-0.4830, test loss-1.8716, acc-0.4768\n",
      "Iter-48360, train loss-1.8402, acc-0.5200, valid loss-1.8707, acc-0.4830, test loss-1.8715, acc-0.4768\n",
      "Iter-48370, train loss-1.8583, acc-0.4600, valid loss-1.8707, acc-0.4824, test loss-1.8715, acc-0.4769\n",
      "Iter-48380, train loss-1.9146, acc-0.4000, valid loss-1.8706, acc-0.4826, test loss-1.8714, acc-0.4769\n",
      "Iter-48390, train loss-1.8976, acc-0.4400, valid loss-1.8705, acc-0.4830, test loss-1.8714, acc-0.4769\n",
      "Iter-48400, train loss-1.8869, acc-0.4600, valid loss-1.8705, acc-0.4826, test loss-1.8713, acc-0.4769\n",
      "Iter-48410, train loss-1.8644, acc-0.5000, valid loss-1.8704, acc-0.4826, test loss-1.8713, acc-0.4769\n",
      "Iter-48420, train loss-1.8431, acc-0.5600, valid loss-1.8704, acc-0.4828, test loss-1.8712, acc-0.4769\n",
      "Iter-48430, train loss-1.9971, acc-0.3000, valid loss-1.8703, acc-0.4830, test loss-1.8711, acc-0.4770\n",
      "Iter-48440, train loss-1.9417, acc-0.3400, valid loss-1.8702, acc-0.4832, test loss-1.8711, acc-0.4770\n",
      "Iter-48450, train loss-1.8903, acc-0.4600, valid loss-1.8702, acc-0.4832, test loss-1.8710, acc-0.4770\n",
      "Iter-48460, train loss-1.7249, acc-0.6600, valid loss-1.8701, acc-0.4832, test loss-1.8710, acc-0.4770\n",
      "Iter-48470, train loss-1.9024, acc-0.3800, valid loss-1.8701, acc-0.4832, test loss-1.8709, acc-0.4770\n",
      "Iter-48480, train loss-1.8586, acc-0.5400, valid loss-1.8700, acc-0.4830, test loss-1.8708, acc-0.4771\n",
      "Iter-48490, train loss-1.8909, acc-0.4200, valid loss-1.8700, acc-0.4832, test loss-1.8708, acc-0.4772\n",
      "Iter-48500, train loss-1.8915, acc-0.5000, valid loss-1.8699, acc-0.4832, test loss-1.8707, acc-0.4772\n",
      "Iter-48510, train loss-1.8988, acc-0.4600, valid loss-1.8698, acc-0.4832, test loss-1.8707, acc-0.4772\n",
      "Iter-48520, train loss-1.8624, acc-0.4800, valid loss-1.8698, acc-0.4832, test loss-1.8706, acc-0.4772\n",
      "Iter-48530, train loss-1.8703, acc-0.5400, valid loss-1.8697, acc-0.4830, test loss-1.8705, acc-0.4772\n",
      "Iter-48540, train loss-1.8600, acc-0.5200, valid loss-1.8697, acc-0.4830, test loss-1.8705, acc-0.4772\n",
      "Iter-48550, train loss-1.8798, acc-0.4600, valid loss-1.8696, acc-0.4834, test loss-1.8704, acc-0.4771\n",
      "Iter-48560, train loss-1.8621, acc-0.5400, valid loss-1.8695, acc-0.4838, test loss-1.8704, acc-0.4772\n",
      "Iter-48570, train loss-1.9222, acc-0.3600, valid loss-1.8695, acc-0.4838, test loss-1.8703, acc-0.4772\n",
      "Iter-48580, train loss-1.9268, acc-0.4800, valid loss-1.8694, acc-0.4836, test loss-1.8703, acc-0.4774\n",
      "Iter-48590, train loss-1.9089, acc-0.5400, valid loss-1.8694, acc-0.4836, test loss-1.8702, acc-0.4776\n",
      "Iter-48600, train loss-1.9661, acc-0.3200, valid loss-1.8693, acc-0.4836, test loss-1.8701, acc-0.4774\n",
      "Iter-48610, train loss-1.7731, acc-0.5400, valid loss-1.8693, acc-0.4834, test loss-1.8701, acc-0.4774\n",
      "Iter-48620, train loss-1.8773, acc-0.4600, valid loss-1.8692, acc-0.4834, test loss-1.8700, acc-0.4776\n",
      "Iter-48630, train loss-1.8778, acc-0.5600, valid loss-1.8691, acc-0.4834, test loss-1.8700, acc-0.4774\n",
      "Iter-48640, train loss-1.8615, acc-0.4200, valid loss-1.8691, acc-0.4834, test loss-1.8699, acc-0.4774\n",
      "Iter-48650, train loss-1.8676, acc-0.4800, valid loss-1.8690, acc-0.4834, test loss-1.8698, acc-0.4776\n",
      "Iter-48660, train loss-1.8691, acc-0.4800, valid loss-1.8690, acc-0.4834, test loss-1.8698, acc-0.4775\n",
      "Iter-48670, train loss-1.8164, acc-0.4400, valid loss-1.8689, acc-0.4834, test loss-1.8697, acc-0.4775\n",
      "Iter-48680, train loss-1.9067, acc-0.3800, valid loss-1.8688, acc-0.4834, test loss-1.8697, acc-0.4774\n",
      "Iter-48690, train loss-1.9085, acc-0.4200, valid loss-1.8688, acc-0.4834, test loss-1.8696, acc-0.4775\n",
      "Iter-48700, train loss-1.9242, acc-0.4600, valid loss-1.8687, acc-0.4834, test loss-1.8695, acc-0.4777\n",
      "Iter-48710, train loss-1.8475, acc-0.4800, valid loss-1.8687, acc-0.4834, test loss-1.8695, acc-0.4778\n",
      "Iter-48720, train loss-1.9646, acc-0.4000, valid loss-1.8686, acc-0.4834, test loss-1.8694, acc-0.4780\n",
      "Iter-48730, train loss-1.8860, acc-0.4800, valid loss-1.8686, acc-0.4834, test loss-1.8694, acc-0.4781\n",
      "Iter-48740, train loss-1.9974, acc-0.3200, valid loss-1.8685, acc-0.4836, test loss-1.8693, acc-0.4781\n",
      "Iter-48750, train loss-1.9543, acc-0.3600, valid loss-1.8684, acc-0.4838, test loss-1.8693, acc-0.4781\n",
      "Iter-48760, train loss-1.8975, acc-0.3200, valid loss-1.8684, acc-0.4838, test loss-1.8692, acc-0.4779\n",
      "Iter-48770, train loss-1.8538, acc-0.4600, valid loss-1.8683, acc-0.4838, test loss-1.8691, acc-0.4780\n",
      "Iter-48780, train loss-1.8150, acc-0.5000, valid loss-1.8683, acc-0.4836, test loss-1.8691, acc-0.4781\n",
      "Iter-48790, train loss-1.8083, acc-0.5000, valid loss-1.8682, acc-0.4838, test loss-1.8690, acc-0.4781\n",
      "Iter-48800, train loss-1.8712, acc-0.4600, valid loss-1.8682, acc-0.4840, test loss-1.8690, acc-0.4782\n",
      "Iter-48810, train loss-1.8651, acc-0.5000, valid loss-1.8681, acc-0.4842, test loss-1.8689, acc-0.4781\n",
      "Iter-48820, train loss-1.8747, acc-0.4600, valid loss-1.8680, acc-0.4842, test loss-1.8688, acc-0.4782\n",
      "Iter-48830, train loss-1.8616, acc-0.5000, valid loss-1.8680, acc-0.4842, test loss-1.8688, acc-0.4781\n",
      "Iter-48840, train loss-1.9383, acc-0.4200, valid loss-1.8679, acc-0.4844, test loss-1.8687, acc-0.4781\n",
      "Iter-48850, train loss-1.8943, acc-0.4400, valid loss-1.8678, acc-0.4844, test loss-1.8687, acc-0.4781\n",
      "Iter-48860, train loss-1.9268, acc-0.3000, valid loss-1.8678, acc-0.4844, test loss-1.8686, acc-0.4781\n",
      "Iter-48870, train loss-1.9155, acc-0.4800, valid loss-1.8677, acc-0.4842, test loss-1.8686, acc-0.4782\n",
      "Iter-48880, train loss-1.9366, acc-0.3800, valid loss-1.8677, acc-0.4842, test loss-1.8685, acc-0.4782\n",
      "Iter-48890, train loss-1.8895, acc-0.4600, valid loss-1.8676, acc-0.4842, test loss-1.8684, acc-0.4782\n",
      "Iter-48900, train loss-1.8699, acc-0.4400, valid loss-1.8676, acc-0.4838, test loss-1.8684, acc-0.4782\n",
      "Iter-48910, train loss-2.0292, acc-0.4000, valid loss-1.8675, acc-0.4840, test loss-1.8683, acc-0.4785\n",
      "Iter-48920, train loss-1.8563, acc-0.6400, valid loss-1.8674, acc-0.4842, test loss-1.8683, acc-0.4784\n",
      "Iter-48930, train loss-1.8392, acc-0.6200, valid loss-1.8674, acc-0.4842, test loss-1.8682, acc-0.4784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-48940, train loss-1.8071, acc-0.5400, valid loss-1.8673, acc-0.4842, test loss-1.8682, acc-0.4783\n",
      "Iter-48950, train loss-1.8985, acc-0.4400, valid loss-1.8673, acc-0.4842, test loss-1.8681, acc-0.4783\n",
      "Iter-48960, train loss-1.8286, acc-0.5000, valid loss-1.8672, acc-0.4842, test loss-1.8680, acc-0.4782\n",
      "Iter-48970, train loss-1.8411, acc-0.4800, valid loss-1.8671, acc-0.4842, test loss-1.8680, acc-0.4783\n",
      "Iter-48980, train loss-1.9615, acc-0.3400, valid loss-1.8671, acc-0.4840, test loss-1.8679, acc-0.4785\n",
      "Iter-48990, train loss-1.8500, acc-0.4200, valid loss-1.8670, acc-0.4840, test loss-1.8679, acc-0.4785\n",
      "Iter-49000, train loss-1.7913, acc-0.6400, valid loss-1.8670, acc-0.4836, test loss-1.8678, acc-0.4784\n",
      "Iter-49010, train loss-1.8411, acc-0.5000, valid loss-1.8669, acc-0.4838, test loss-1.8677, acc-0.4785\n",
      "Iter-49020, train loss-1.8534, acc-0.5200, valid loss-1.8668, acc-0.4838, test loss-1.8677, acc-0.4785\n",
      "Iter-49030, train loss-1.8668, acc-0.5400, valid loss-1.8668, acc-0.4838, test loss-1.8676, acc-0.4784\n",
      "Iter-49040, train loss-1.8572, acc-0.3800, valid loss-1.8667, acc-0.4838, test loss-1.8676, acc-0.4784\n",
      "Iter-49050, train loss-1.9290, acc-0.4400, valid loss-1.8667, acc-0.4840, test loss-1.8675, acc-0.4784\n",
      "Iter-49060, train loss-1.9391, acc-0.4200, valid loss-1.8666, acc-0.4840, test loss-1.8675, acc-0.4784\n",
      "Iter-49070, train loss-1.8726, acc-0.4600, valid loss-1.8666, acc-0.4838, test loss-1.8674, acc-0.4784\n",
      "Iter-49080, train loss-1.8831, acc-0.4000, valid loss-1.8665, acc-0.4840, test loss-1.8673, acc-0.4788\n",
      "Iter-49090, train loss-1.9398, acc-0.4000, valid loss-1.8664, acc-0.4840, test loss-1.8673, acc-0.4789\n",
      "Iter-49100, train loss-1.9037, acc-0.5000, valid loss-1.8664, acc-0.4840, test loss-1.8672, acc-0.4787\n",
      "Iter-49110, train loss-1.8364, acc-0.5400, valid loss-1.8663, acc-0.4840, test loss-1.8672, acc-0.4789\n",
      "Iter-49120, train loss-1.8282, acc-0.5200, valid loss-1.8663, acc-0.4842, test loss-1.8671, acc-0.4789\n",
      "Iter-49130, train loss-1.8542, acc-0.5400, valid loss-1.8662, acc-0.4840, test loss-1.8670, acc-0.4787\n",
      "Iter-49140, train loss-1.9178, acc-0.4200, valid loss-1.8661, acc-0.4842, test loss-1.8670, acc-0.4788\n",
      "Iter-49150, train loss-1.8593, acc-0.4800, valid loss-1.8661, acc-0.4840, test loss-1.8669, acc-0.4786\n",
      "Iter-49160, train loss-1.8574, acc-0.5000, valid loss-1.8660, acc-0.4840, test loss-1.8669, acc-0.4786\n",
      "Iter-49170, train loss-1.8223, acc-0.5000, valid loss-1.8660, acc-0.4842, test loss-1.8668, acc-0.4788\n",
      "Iter-49180, train loss-1.8262, acc-0.5000, valid loss-1.8659, acc-0.4842, test loss-1.8667, acc-0.4789\n",
      "Iter-49190, train loss-1.9118, acc-0.4800, valid loss-1.8658, acc-0.4844, test loss-1.8667, acc-0.4788\n",
      "Iter-49200, train loss-1.8444, acc-0.5000, valid loss-1.8658, acc-0.4844, test loss-1.8666, acc-0.4788\n",
      "Iter-49210, train loss-1.8189, acc-0.5400, valid loss-1.8657, acc-0.4844, test loss-1.8666, acc-0.4788\n",
      "Iter-49220, train loss-1.8269, acc-0.4800, valid loss-1.8657, acc-0.4844, test loss-1.8665, acc-0.4788\n",
      "Iter-49230, train loss-1.9993, acc-0.3600, valid loss-1.8656, acc-0.4844, test loss-1.8665, acc-0.4789\n",
      "Iter-49240, train loss-1.9025, acc-0.3800, valid loss-1.8656, acc-0.4844, test loss-1.8664, acc-0.4787\n",
      "Iter-49250, train loss-1.8046, acc-0.4200, valid loss-1.8655, acc-0.4844, test loss-1.8663, acc-0.4787\n",
      "Iter-49260, train loss-1.7990, acc-0.6200, valid loss-1.8654, acc-0.4844, test loss-1.8663, acc-0.4790\n",
      "Iter-49270, train loss-1.8391, acc-0.5200, valid loss-1.8654, acc-0.4844, test loss-1.8662, acc-0.4789\n",
      "Iter-49280, train loss-1.8234, acc-0.5600, valid loss-1.8653, acc-0.4844, test loss-1.8662, acc-0.4790\n",
      "Iter-49290, train loss-1.7741, acc-0.5400, valid loss-1.8653, acc-0.4844, test loss-1.8661, acc-0.4790\n",
      "Iter-49300, train loss-1.8579, acc-0.4400, valid loss-1.8652, acc-0.4844, test loss-1.8660, acc-0.4790\n",
      "Iter-49310, train loss-1.9187, acc-0.4400, valid loss-1.8652, acc-0.4844, test loss-1.8660, acc-0.4791\n",
      "Iter-49320, train loss-1.9051, acc-0.4600, valid loss-1.8651, acc-0.4844, test loss-1.8659, acc-0.4790\n",
      "Iter-49330, train loss-1.8191, acc-0.5200, valid loss-1.8650, acc-0.4842, test loss-1.8659, acc-0.4789\n",
      "Iter-49340, train loss-1.8917, acc-0.4600, valid loss-1.8650, acc-0.4842, test loss-1.8658, acc-0.4790\n",
      "Iter-49350, train loss-1.8446, acc-0.4800, valid loss-1.8649, acc-0.4842, test loss-1.8658, acc-0.4790\n",
      "Iter-49360, train loss-1.8412, acc-0.4600, valid loss-1.8649, acc-0.4844, test loss-1.8657, acc-0.4790\n",
      "Iter-49370, train loss-1.8151, acc-0.5000, valid loss-1.8648, acc-0.4844, test loss-1.8656, acc-0.4791\n",
      "Iter-49380, train loss-1.8601, acc-0.4800, valid loss-1.8647, acc-0.4844, test loss-1.8656, acc-0.4791\n",
      "Iter-49390, train loss-1.8851, acc-0.4200, valid loss-1.8647, acc-0.4844, test loss-1.8655, acc-0.4790\n",
      "Iter-49400, train loss-1.8667, acc-0.4200, valid loss-1.8646, acc-0.4846, test loss-1.8655, acc-0.4791\n",
      "Iter-49410, train loss-1.8997, acc-0.4400, valid loss-1.8646, acc-0.4846, test loss-1.8654, acc-0.4793\n",
      "Iter-49420, train loss-1.8812, acc-0.4800, valid loss-1.8645, acc-0.4846, test loss-1.8653, acc-0.4792\n",
      "Iter-49430, train loss-1.9026, acc-0.3600, valid loss-1.8645, acc-0.4846, test loss-1.8653, acc-0.4792\n",
      "Iter-49440, train loss-1.8637, acc-0.4800, valid loss-1.8644, acc-0.4846, test loss-1.8652, acc-0.4792\n",
      "Iter-49450, train loss-1.8491, acc-0.5200, valid loss-1.8643, acc-0.4846, test loss-1.8652, acc-0.4793\n",
      "Iter-49460, train loss-1.9708, acc-0.4600, valid loss-1.8643, acc-0.4846, test loss-1.8651, acc-0.4792\n",
      "Iter-49470, train loss-1.8837, acc-0.5200, valid loss-1.8642, acc-0.4848, test loss-1.8651, acc-0.4794\n",
      "Iter-49480, train loss-2.0113, acc-0.4000, valid loss-1.8642, acc-0.4850, test loss-1.8650, acc-0.4794\n",
      "Iter-49490, train loss-1.7956, acc-0.5400, valid loss-1.8641, acc-0.4850, test loss-1.8649, acc-0.4792\n",
      "Iter-49500, train loss-1.8802, acc-0.4200, valid loss-1.8641, acc-0.4852, test loss-1.8649, acc-0.4792\n",
      "Iter-49510, train loss-1.9326, acc-0.4400, valid loss-1.8640, acc-0.4848, test loss-1.8648, acc-0.4794\n",
      "Iter-49520, train loss-1.8116, acc-0.5200, valid loss-1.8640, acc-0.4848, test loss-1.8648, acc-0.4795\n",
      "Iter-49530, train loss-1.8763, acc-0.5400, valid loss-1.8639, acc-0.4848, test loss-1.8647, acc-0.4796\n",
      "Iter-49540, train loss-1.9844, acc-0.4400, valid loss-1.8638, acc-0.4848, test loss-1.8647, acc-0.4797\n",
      "Iter-49550, train loss-1.8460, acc-0.6000, valid loss-1.8638, acc-0.4848, test loss-1.8646, acc-0.4796\n",
      "Iter-49560, train loss-1.8384, acc-0.4600, valid loss-1.8637, acc-0.4850, test loss-1.8645, acc-0.4795\n",
      "Iter-49570, train loss-1.8131, acc-0.6000, valid loss-1.8637, acc-0.4850, test loss-1.8645, acc-0.4794\n",
      "Iter-49580, train loss-1.9093, acc-0.3800, valid loss-1.8636, acc-0.4848, test loss-1.8644, acc-0.4794\n",
      "Iter-49590, train loss-1.8514, acc-0.5000, valid loss-1.8636, acc-0.4848, test loss-1.8644, acc-0.4795\n",
      "Iter-49600, train loss-1.8114, acc-0.5200, valid loss-1.8635, acc-0.4846, test loss-1.8643, acc-0.4795\n",
      "Iter-49610, train loss-1.8204, acc-0.5000, valid loss-1.8634, acc-0.4846, test loss-1.8643, acc-0.4794\n",
      "Iter-49620, train loss-1.9432, acc-0.3800, valid loss-1.8634, acc-0.4846, test loss-1.8642, acc-0.4793\n",
      "Iter-49630, train loss-1.9273, acc-0.4600, valid loss-1.8633, acc-0.4846, test loss-1.8641, acc-0.4794\n",
      "Iter-49640, train loss-1.8988, acc-0.4600, valid loss-1.8633, acc-0.4846, test loss-1.8641, acc-0.4795\n",
      "Iter-49650, train loss-1.8318, acc-0.5400, valid loss-1.8632, acc-0.4846, test loss-1.8640, acc-0.4796\n",
      "Iter-49660, train loss-1.9706, acc-0.4400, valid loss-1.8631, acc-0.4846, test loss-1.8640, acc-0.4794\n",
      "Iter-49670, train loss-1.8947, acc-0.4800, valid loss-1.8631, acc-0.4844, test loss-1.8639, acc-0.4797\n",
      "Iter-49680, train loss-1.8767, acc-0.4000, valid loss-1.8630, acc-0.4844, test loss-1.8639, acc-0.4797\n",
      "Iter-49690, train loss-1.9151, acc-0.4000, valid loss-1.8630, acc-0.4844, test loss-1.8638, acc-0.4797\n",
      "Iter-49700, train loss-1.8192, acc-0.5200, valid loss-1.8629, acc-0.4844, test loss-1.8637, acc-0.4799\n",
      "Iter-49710, train loss-1.7732, acc-0.5200, valid loss-1.8629, acc-0.4844, test loss-1.8637, acc-0.4800\n",
      "Iter-49720, train loss-1.8360, acc-0.4400, valid loss-1.8628, acc-0.4846, test loss-1.8636, acc-0.4801\n",
      "Iter-49730, train loss-1.8959, acc-0.4000, valid loss-1.8627, acc-0.4846, test loss-1.8636, acc-0.4801\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-49740, train loss-1.8633, acc-0.4200, valid loss-1.8627, acc-0.4848, test loss-1.8635, acc-0.4801\n",
      "Iter-49750, train loss-1.9640, acc-0.3800, valid loss-1.8626, acc-0.4848, test loss-1.8635, acc-0.4800\n",
      "Iter-49760, train loss-1.9523, acc-0.5000, valid loss-1.8626, acc-0.4848, test loss-1.8634, acc-0.4802\n",
      "Iter-49770, train loss-1.7736, acc-0.5600, valid loss-1.8625, acc-0.4848, test loss-1.8633, acc-0.4802\n",
      "Iter-49780, train loss-1.8902, acc-0.4800, valid loss-1.8625, acc-0.4846, test loss-1.8633, acc-0.4802\n",
      "Iter-49790, train loss-1.8325, acc-0.5200, valid loss-1.8624, acc-0.4848, test loss-1.8632, acc-0.4804\n",
      "Iter-49800, train loss-1.9176, acc-0.4000, valid loss-1.8623, acc-0.4848, test loss-1.8632, acc-0.4802\n",
      "Iter-49810, train loss-1.8622, acc-0.4400, valid loss-1.8623, acc-0.4848, test loss-1.8631, acc-0.4802\n",
      "Iter-49820, train loss-1.8706, acc-0.4200, valid loss-1.8622, acc-0.4850, test loss-1.8631, acc-0.4802\n",
      "Iter-49830, train loss-1.7959, acc-0.5400, valid loss-1.8622, acc-0.4850, test loss-1.8630, acc-0.4801\n",
      "Iter-49840, train loss-1.8837, acc-0.5600, valid loss-1.8621, acc-0.4848, test loss-1.8629, acc-0.4801\n",
      "Iter-49850, train loss-1.8754, acc-0.4600, valid loss-1.8620, acc-0.4848, test loss-1.8629, acc-0.4802\n",
      "Iter-49860, train loss-1.8777, acc-0.5200, valid loss-1.8620, acc-0.4850, test loss-1.8628, acc-0.4801\n",
      "Iter-49870, train loss-1.8575, acc-0.5000, valid loss-1.8619, acc-0.4850, test loss-1.8628, acc-0.4801\n",
      "Iter-49880, train loss-1.8623, acc-0.5600, valid loss-1.8619, acc-0.4852, test loss-1.8627, acc-0.4801\n",
      "Iter-49890, train loss-1.8355, acc-0.5400, valid loss-1.8618, acc-0.4852, test loss-1.8627, acc-0.4801\n",
      "Iter-49900, train loss-1.8292, acc-0.4600, valid loss-1.8617, acc-0.4852, test loss-1.8626, acc-0.4801\n",
      "Iter-49910, train loss-1.7955, acc-0.4600, valid loss-1.8617, acc-0.4854, test loss-1.8625, acc-0.4802\n",
      "Iter-49920, train loss-1.9687, acc-0.3800, valid loss-1.8616, acc-0.4854, test loss-1.8625, acc-0.4803\n",
      "Iter-49930, train loss-1.8651, acc-0.5000, valid loss-1.8616, acc-0.4854, test loss-1.8624, acc-0.4803\n",
      "Iter-49940, train loss-1.8467, acc-0.4600, valid loss-1.8615, acc-0.4854, test loss-1.8624, acc-0.4804\n",
      "Iter-49950, train loss-1.8965, acc-0.4400, valid loss-1.8615, acc-0.4856, test loss-1.8623, acc-0.4806\n",
      "Iter-49960, train loss-1.7958, acc-0.6200, valid loss-1.8614, acc-0.4856, test loss-1.8622, acc-0.4804\n",
      "Iter-49970, train loss-1.8031, acc-0.5400, valid loss-1.8613, acc-0.4858, test loss-1.8622, acc-0.4804\n",
      "Iter-49980, train loss-1.8654, acc-0.4600, valid loss-1.8613, acc-0.4860, test loss-1.8621, acc-0.4804\n",
      "Iter-49990, train loss-1.9674, acc-0.3000, valid loss-1.8612, acc-0.4858, test loss-1.8621, acc-0.4805\n",
      "Iter-50000, train loss-1.8472, acc-0.4600, valid loss-1.8612, acc-0.4856, test loss-1.8620, acc-0.4806\n",
      "Iter-50010, train loss-1.8545, acc-0.4600, valid loss-1.8611, acc-0.4856, test loss-1.8620, acc-0.4803\n",
      "Iter-50020, train loss-1.9748, acc-0.3400, valid loss-1.8611, acc-0.4854, test loss-1.8619, acc-0.4804\n",
      "Iter-50030, train loss-1.7848, acc-0.5400, valid loss-1.8610, acc-0.4854, test loss-1.8618, acc-0.4804\n",
      "Iter-50040, train loss-1.8400, acc-0.4800, valid loss-1.8609, acc-0.4854, test loss-1.8618, acc-0.4804\n",
      "Iter-50050, train loss-1.9063, acc-0.4400, valid loss-1.8609, acc-0.4854, test loss-1.8617, acc-0.4806\n",
      "Iter-50060, train loss-1.9164, acc-0.4600, valid loss-1.8608, acc-0.4854, test loss-1.8617, acc-0.4805\n",
      "Iter-50070, train loss-1.8312, acc-0.5400, valid loss-1.8608, acc-0.4854, test loss-1.8616, acc-0.4809\n",
      "Iter-50080, train loss-1.8206, acc-0.4600, valid loss-1.8607, acc-0.4854, test loss-1.8615, acc-0.4809\n",
      "Iter-50090, train loss-1.8592, acc-0.4800, valid loss-1.8607, acc-0.4854, test loss-1.8615, acc-0.4809\n",
      "Iter-50100, train loss-1.8691, acc-0.4400, valid loss-1.8606, acc-0.4854, test loss-1.8614, acc-0.4808\n",
      "Iter-50110, train loss-1.8909, acc-0.3200, valid loss-1.8605, acc-0.4858, test loss-1.8614, acc-0.4809\n",
      "Iter-50120, train loss-1.7856, acc-0.4600, valid loss-1.8605, acc-0.4858, test loss-1.8613, acc-0.4807\n",
      "Iter-50130, train loss-1.8851, acc-0.4400, valid loss-1.8604, acc-0.4858, test loss-1.8613, acc-0.4808\n",
      "Iter-50140, train loss-1.8647, acc-0.4400, valid loss-1.8604, acc-0.4858, test loss-1.8612, acc-0.4810\n",
      "Iter-50150, train loss-1.9109, acc-0.4400, valid loss-1.8603, acc-0.4858, test loss-1.8611, acc-0.4808\n",
      "Iter-50160, train loss-1.8586, acc-0.5000, valid loss-1.8603, acc-0.4856, test loss-1.8611, acc-0.4808\n",
      "Iter-50170, train loss-1.9192, acc-0.4600, valid loss-1.8602, acc-0.4856, test loss-1.8610, acc-0.4807\n",
      "Iter-50180, train loss-1.9250, acc-0.4000, valid loss-1.8601, acc-0.4858, test loss-1.8610, acc-0.4807\n",
      "Iter-50190, train loss-1.8651, acc-0.4200, valid loss-1.8601, acc-0.4858, test loss-1.8609, acc-0.4809\n",
      "Iter-50200, train loss-1.8844, acc-0.4800, valid loss-1.8600, acc-0.4858, test loss-1.8609, acc-0.4810\n",
      "Iter-50210, train loss-1.8589, acc-0.5000, valid loss-1.8600, acc-0.4858, test loss-1.8608, acc-0.4809\n",
      "Iter-50220, train loss-1.7921, acc-0.6000, valid loss-1.8599, acc-0.4856, test loss-1.8607, acc-0.4808\n",
      "Iter-50230, train loss-1.9497, acc-0.3800, valid loss-1.8599, acc-0.4858, test loss-1.8607, acc-0.4810\n",
      "Iter-50240, train loss-1.8515, acc-0.5000, valid loss-1.8598, acc-0.4858, test loss-1.8606, acc-0.4812\n",
      "Iter-50250, train loss-1.8567, acc-0.4400, valid loss-1.8598, acc-0.4860, test loss-1.8606, acc-0.4814\n",
      "Iter-50260, train loss-1.9331, acc-0.4200, valid loss-1.8597, acc-0.4860, test loss-1.8605, acc-0.4812\n",
      "Iter-50270, train loss-1.9281, acc-0.4000, valid loss-1.8596, acc-0.4860, test loss-1.8605, acc-0.4813\n",
      "Iter-50280, train loss-1.8310, acc-0.4400, valid loss-1.8596, acc-0.4860, test loss-1.8604, acc-0.4813\n",
      "Iter-50290, train loss-1.9511, acc-0.3600, valid loss-1.8595, acc-0.4858, test loss-1.8603, acc-0.4814\n",
      "Iter-50300, train loss-1.9081, acc-0.4200, valid loss-1.8595, acc-0.4860, test loss-1.8603, acc-0.4814\n",
      "Iter-50310, train loss-1.8742, acc-0.3800, valid loss-1.8594, acc-0.4860, test loss-1.8602, acc-0.4814\n",
      "Iter-50320, train loss-1.8568, acc-0.5600, valid loss-1.8594, acc-0.4860, test loss-1.8602, acc-0.4813\n",
      "Iter-50330, train loss-1.8914, acc-0.4800, valid loss-1.8593, acc-0.4860, test loss-1.8601, acc-0.4813\n",
      "Iter-50340, train loss-1.9254, acc-0.3600, valid loss-1.8592, acc-0.4860, test loss-1.8601, acc-0.4814\n",
      "Iter-50350, train loss-1.8594, acc-0.5200, valid loss-1.8592, acc-0.4858, test loss-1.8600, acc-0.4812\n",
      "Iter-50360, train loss-1.8208, acc-0.5800, valid loss-1.8591, acc-0.4858, test loss-1.8599, acc-0.4814\n",
      "Iter-50370, train loss-1.8069, acc-0.4400, valid loss-1.8591, acc-0.4858, test loss-1.8599, acc-0.4814\n",
      "Iter-50380, train loss-1.7888, acc-0.5600, valid loss-1.8590, acc-0.4860, test loss-1.8598, acc-0.4815\n",
      "Iter-50390, train loss-1.8827, acc-0.4200, valid loss-1.8589, acc-0.4860, test loss-1.8598, acc-0.4812\n",
      "Iter-50400, train loss-1.8666, acc-0.3600, valid loss-1.8589, acc-0.4862, test loss-1.8597, acc-0.4813\n",
      "Iter-50410, train loss-1.8788, acc-0.4200, valid loss-1.8588, acc-0.4860, test loss-1.8597, acc-0.4812\n",
      "Iter-50420, train loss-1.7879, acc-0.5800, valid loss-1.8588, acc-0.4860, test loss-1.8596, acc-0.4814\n",
      "Iter-50430, train loss-1.8848, acc-0.4600, valid loss-1.8587, acc-0.4858, test loss-1.8595, acc-0.4816\n",
      "Iter-50440, train loss-1.8853, acc-0.4600, valid loss-1.8587, acc-0.4858, test loss-1.8595, acc-0.4815\n",
      "Iter-50450, train loss-1.8578, acc-0.4400, valid loss-1.8586, acc-0.4858, test loss-1.8594, acc-0.4815\n",
      "Iter-50460, train loss-1.8683, acc-0.4400, valid loss-1.8585, acc-0.4858, test loss-1.8594, acc-0.4814\n",
      "Iter-50470, train loss-1.9783, acc-0.3400, valid loss-1.8585, acc-0.4860, test loss-1.8593, acc-0.4814\n",
      "Iter-50480, train loss-1.9444, acc-0.4400, valid loss-1.8584, acc-0.4860, test loss-1.8593, acc-0.4814\n",
      "Iter-50490, train loss-1.8965, acc-0.3600, valid loss-1.8584, acc-0.4862, test loss-1.8592, acc-0.4813\n",
      "Iter-50500, train loss-1.8172, acc-0.4600, valid loss-1.8583, acc-0.4860, test loss-1.8591, acc-0.4814\n",
      "Iter-50510, train loss-1.8980, acc-0.4800, valid loss-1.8582, acc-0.4860, test loss-1.8591, acc-0.4814\n",
      "Iter-50520, train loss-1.8382, acc-0.4400, valid loss-1.8582, acc-0.4860, test loss-1.8590, acc-0.4815\n",
      "Iter-50530, train loss-1.7886, acc-0.6400, valid loss-1.8581, acc-0.4860, test loss-1.8590, acc-0.4814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-50540, train loss-1.8988, acc-0.4400, valid loss-1.8581, acc-0.4860, test loss-1.8589, acc-0.4814\n",
      "Iter-50550, train loss-1.7449, acc-0.5800, valid loss-1.8580, acc-0.4860, test loss-1.8589, acc-0.4814\n",
      "Iter-50560, train loss-1.8558, acc-0.5000, valid loss-1.8580, acc-0.4860, test loss-1.8588, acc-0.4814\n",
      "Iter-50570, train loss-1.8340, acc-0.5800, valid loss-1.8579, acc-0.4860, test loss-1.8587, acc-0.4815\n",
      "Iter-50580, train loss-1.7955, acc-0.5000, valid loss-1.8578, acc-0.4862, test loss-1.8587, acc-0.4815\n",
      "Iter-50590, train loss-1.8242, acc-0.5200, valid loss-1.8578, acc-0.4860, test loss-1.8586, acc-0.4815\n",
      "Iter-50600, train loss-1.9442, acc-0.3400, valid loss-1.8577, acc-0.4860, test loss-1.8586, acc-0.4815\n",
      "Iter-50610, train loss-1.7958, acc-0.5200, valid loss-1.8577, acc-0.4860, test loss-1.8585, acc-0.4814\n",
      "Iter-50620, train loss-1.8857, acc-0.4400, valid loss-1.8576, acc-0.4858, test loss-1.8584, acc-0.4815\n",
      "Iter-50630, train loss-1.8870, acc-0.4800, valid loss-1.8575, acc-0.4860, test loss-1.8584, acc-0.4814\n",
      "Iter-50640, train loss-1.8353, acc-0.5600, valid loss-1.8575, acc-0.4858, test loss-1.8583, acc-0.4814\n",
      "Iter-50650, train loss-1.8398, acc-0.5000, valid loss-1.8574, acc-0.4856, test loss-1.8583, acc-0.4815\n",
      "Iter-50660, train loss-1.9203, acc-0.4200, valid loss-1.8574, acc-0.4858, test loss-1.8582, acc-0.4816\n",
      "Iter-50670, train loss-1.8456, acc-0.4200, valid loss-1.8573, acc-0.4856, test loss-1.8581, acc-0.4815\n",
      "Iter-50680, train loss-1.8761, acc-0.4400, valid loss-1.8572, acc-0.4856, test loss-1.8581, acc-0.4815\n",
      "Iter-50690, train loss-1.9316, acc-0.4000, valid loss-1.8572, acc-0.4856, test loss-1.8580, acc-0.4813\n",
      "Iter-50700, train loss-1.8530, acc-0.5200, valid loss-1.8571, acc-0.4854, test loss-1.8580, acc-0.4813\n",
      "Iter-50710, train loss-1.8839, acc-0.4600, valid loss-1.8571, acc-0.4858, test loss-1.8579, acc-0.4813\n",
      "Iter-50720, train loss-1.8564, acc-0.5000, valid loss-1.8570, acc-0.4856, test loss-1.8579, acc-0.4813\n",
      "Iter-50730, train loss-1.8694, acc-0.5000, valid loss-1.8570, acc-0.4858, test loss-1.8578, acc-0.4814\n",
      "Iter-50740, train loss-1.8670, acc-0.4400, valid loss-1.8569, acc-0.4856, test loss-1.8578, acc-0.4816\n",
      "Iter-50750, train loss-1.9506, acc-0.4000, valid loss-1.8569, acc-0.4858, test loss-1.8577, acc-0.4817\n",
      "Iter-50760, train loss-1.9603, acc-0.4200, valid loss-1.8568, acc-0.4858, test loss-1.8576, acc-0.4818\n",
      "Iter-50770, train loss-1.8423, acc-0.5000, valid loss-1.8567, acc-0.4856, test loss-1.8576, acc-0.4816\n",
      "Iter-50780, train loss-1.9362, acc-0.3800, valid loss-1.8567, acc-0.4860, test loss-1.8575, acc-0.4816\n",
      "Iter-50790, train loss-1.9313, acc-0.3600, valid loss-1.8566, acc-0.4864, test loss-1.8575, acc-0.4817\n",
      "Iter-50800, train loss-1.9381, acc-0.4000, valid loss-1.8566, acc-0.4862, test loss-1.8574, acc-0.4817\n",
      "Iter-50810, train loss-1.8015, acc-0.5600, valid loss-1.8565, acc-0.4864, test loss-1.8574, acc-0.4817\n",
      "Iter-50820, train loss-1.9289, acc-0.4000, valid loss-1.8565, acc-0.4864, test loss-1.8573, acc-0.4817\n",
      "Iter-50830, train loss-1.8956, acc-0.5200, valid loss-1.8564, acc-0.4860, test loss-1.8572, acc-0.4817\n",
      "Iter-50840, train loss-1.9096, acc-0.4600, valid loss-1.8564, acc-0.4862, test loss-1.8572, acc-0.4817\n",
      "Iter-50850, train loss-1.8469, acc-0.5000, valid loss-1.8563, acc-0.4860, test loss-1.8571, acc-0.4818\n",
      "Iter-50860, train loss-1.8693, acc-0.5000, valid loss-1.8562, acc-0.4862, test loss-1.8571, acc-0.4815\n",
      "Iter-50870, train loss-1.8584, acc-0.4800, valid loss-1.8562, acc-0.4860, test loss-1.8570, acc-0.4817\n",
      "Iter-50880, train loss-1.9086, acc-0.4000, valid loss-1.8561, acc-0.4862, test loss-1.8570, acc-0.4821\n",
      "Iter-50890, train loss-1.8276, acc-0.4800, valid loss-1.8561, acc-0.4862, test loss-1.8569, acc-0.4817\n",
      "Iter-50900, train loss-1.9000, acc-0.5200, valid loss-1.8560, acc-0.4860, test loss-1.8569, acc-0.4816\n",
      "Iter-50910, train loss-1.8513, acc-0.4400, valid loss-1.8560, acc-0.4860, test loss-1.8568, acc-0.4815\n",
      "Iter-50920, train loss-1.8172, acc-0.5200, valid loss-1.8559, acc-0.4860, test loss-1.8567, acc-0.4815\n",
      "Iter-50930, train loss-1.8662, acc-0.4800, valid loss-1.8558, acc-0.4860, test loss-1.8567, acc-0.4816\n",
      "Iter-50940, train loss-1.8821, acc-0.4000, valid loss-1.8558, acc-0.4858, test loss-1.8566, acc-0.4814\n",
      "Iter-50950, train loss-1.8815, acc-0.4600, valid loss-1.8557, acc-0.4856, test loss-1.8566, acc-0.4814\n",
      "Iter-50960, train loss-1.9205, acc-0.3800, valid loss-1.8557, acc-0.4854, test loss-1.8565, acc-0.4813\n",
      "Iter-50970, train loss-1.8084, acc-0.6200, valid loss-1.8556, acc-0.4854, test loss-1.8564, acc-0.4813\n",
      "Iter-50980, train loss-1.8735, acc-0.4000, valid loss-1.8555, acc-0.4854, test loss-1.8564, acc-0.4813\n",
      "Iter-50990, train loss-1.8409, acc-0.6000, valid loss-1.8555, acc-0.4858, test loss-1.8563, acc-0.4816\n",
      "Iter-51000, train loss-1.8647, acc-0.5000, valid loss-1.8554, acc-0.4860, test loss-1.8563, acc-0.4817\n",
      "Iter-51010, train loss-1.8690, acc-0.4600, valid loss-1.8554, acc-0.4860, test loss-1.8562, acc-0.4819\n",
      "Iter-51020, train loss-1.8712, acc-0.4000, valid loss-1.8553, acc-0.4856, test loss-1.8562, acc-0.4817\n",
      "Iter-51030, train loss-1.8557, acc-0.4600, valid loss-1.8553, acc-0.4860, test loss-1.8561, acc-0.4817\n",
      "Iter-51040, train loss-1.8546, acc-0.4200, valid loss-1.8552, acc-0.4864, test loss-1.8560, acc-0.4816\n",
      "Iter-51050, train loss-1.9305, acc-0.4000, valid loss-1.8551, acc-0.4866, test loss-1.8560, acc-0.4816\n",
      "Iter-51060, train loss-1.8682, acc-0.5800, valid loss-1.8551, acc-0.4866, test loss-1.8559, acc-0.4815\n",
      "Iter-51070, train loss-1.9703, acc-0.3000, valid loss-1.8550, acc-0.4868, test loss-1.8559, acc-0.4817\n",
      "Iter-51080, train loss-1.8240, acc-0.6400, valid loss-1.8550, acc-0.4866, test loss-1.8558, acc-0.4816\n",
      "Iter-51090, train loss-1.8512, acc-0.4000, valid loss-1.8549, acc-0.4868, test loss-1.8558, acc-0.4817\n",
      "Iter-51100, train loss-1.8008, acc-0.5000, valid loss-1.8549, acc-0.4864, test loss-1.8557, acc-0.4816\n",
      "Iter-51110, train loss-1.8783, acc-0.4400, valid loss-1.8548, acc-0.4860, test loss-1.8556, acc-0.4815\n",
      "Iter-51120, train loss-1.8532, acc-0.5200, valid loss-1.8547, acc-0.4864, test loss-1.8556, acc-0.4814\n",
      "Iter-51130, train loss-1.9605, acc-0.4400, valid loss-1.8547, acc-0.4862, test loss-1.8555, acc-0.4815\n",
      "Iter-51140, train loss-1.8982, acc-0.4600, valid loss-1.8546, acc-0.4862, test loss-1.8555, acc-0.4817\n",
      "Iter-51150, train loss-1.8111, acc-0.4400, valid loss-1.8546, acc-0.4866, test loss-1.8554, acc-0.4819\n",
      "Iter-51160, train loss-1.8741, acc-0.4200, valid loss-1.8545, acc-0.4866, test loss-1.8554, acc-0.4817\n",
      "Iter-51170, train loss-1.8560, acc-0.5600, valid loss-1.8545, acc-0.4868, test loss-1.8553, acc-0.4817\n",
      "Iter-51180, train loss-1.8881, acc-0.4400, valid loss-1.8544, acc-0.4868, test loss-1.8552, acc-0.4818\n",
      "Iter-51190, train loss-1.9097, acc-0.4800, valid loss-1.8544, acc-0.4872, test loss-1.8552, acc-0.4820\n",
      "Iter-51200, train loss-1.8604, acc-0.5200, valid loss-1.8543, acc-0.4870, test loss-1.8551, acc-0.4818\n",
      "Iter-51210, train loss-1.9399, acc-0.4400, valid loss-1.8543, acc-0.4870, test loss-1.8551, acc-0.4818\n",
      "Iter-51220, train loss-1.8995, acc-0.5000, valid loss-1.8542, acc-0.4870, test loss-1.8550, acc-0.4818\n",
      "Iter-51230, train loss-1.9020, acc-0.4800, valid loss-1.8541, acc-0.4870, test loss-1.8550, acc-0.4818\n",
      "Iter-51240, train loss-1.8055, acc-0.5200, valid loss-1.8541, acc-0.4872, test loss-1.8549, acc-0.4818\n",
      "Iter-51250, train loss-1.9421, acc-0.4000, valid loss-1.8540, acc-0.4872, test loss-1.8549, acc-0.4818\n",
      "Iter-51260, train loss-1.8584, acc-0.5400, valid loss-1.8540, acc-0.4872, test loss-1.8548, acc-0.4818\n",
      "Iter-51270, train loss-1.8527, acc-0.5000, valid loss-1.8539, acc-0.4872, test loss-1.8548, acc-0.4818\n",
      "Iter-51280, train loss-1.8125, acc-0.5600, valid loss-1.8539, acc-0.4870, test loss-1.8547, acc-0.4820\n",
      "Iter-51290, train loss-1.9339, acc-0.4600, valid loss-1.8538, acc-0.4870, test loss-1.8546, acc-0.4819\n",
      "Iter-51300, train loss-1.8106, acc-0.5200, valid loss-1.8538, acc-0.4874, test loss-1.8546, acc-0.4822\n",
      "Iter-51310, train loss-1.9077, acc-0.4800, valid loss-1.8537, acc-0.4872, test loss-1.8545, acc-0.4821\n",
      "Iter-51320, train loss-1.8366, acc-0.5200, valid loss-1.8537, acc-0.4872, test loss-1.8545, acc-0.4820\n",
      "Iter-51330, train loss-1.8834, acc-0.5000, valid loss-1.8536, acc-0.4874, test loss-1.8544, acc-0.4821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-51340, train loss-1.8535, acc-0.3800, valid loss-1.8535, acc-0.4874, test loss-1.8544, acc-0.4821\n",
      "Iter-51350, train loss-1.9064, acc-0.4400, valid loss-1.8535, acc-0.4874, test loss-1.8543, acc-0.4822\n",
      "Iter-51360, train loss-1.9010, acc-0.3800, valid loss-1.8534, acc-0.4874, test loss-1.8542, acc-0.4824\n",
      "Iter-51370, train loss-1.9143, acc-0.3800, valid loss-1.8534, acc-0.4874, test loss-1.8542, acc-0.4823\n",
      "Iter-51380, train loss-1.8537, acc-0.5400, valid loss-1.8533, acc-0.4874, test loss-1.8541, acc-0.4824\n",
      "Iter-51390, train loss-1.8693, acc-0.4800, valid loss-1.8533, acc-0.4874, test loss-1.8541, acc-0.4824\n",
      "Iter-51400, train loss-1.7489, acc-0.6400, valid loss-1.8532, acc-0.4874, test loss-1.8540, acc-0.4824\n",
      "Iter-51410, train loss-1.8841, acc-0.4400, valid loss-1.8532, acc-0.4876, test loss-1.8540, acc-0.4824\n",
      "Iter-51420, train loss-1.8361, acc-0.5000, valid loss-1.8531, acc-0.4878, test loss-1.8539, acc-0.4825\n",
      "Iter-51430, train loss-1.8008, acc-0.5600, valid loss-1.8530, acc-0.4878, test loss-1.8539, acc-0.4825\n",
      "Iter-51440, train loss-1.9064, acc-0.5400, valid loss-1.8530, acc-0.4876, test loss-1.8538, acc-0.4826\n",
      "Iter-51450, train loss-1.8621, acc-0.5400, valid loss-1.8529, acc-0.4876, test loss-1.8538, acc-0.4827\n",
      "Iter-51460, train loss-1.8520, acc-0.4800, valid loss-1.8529, acc-0.4876, test loss-1.8537, acc-0.4825\n",
      "Iter-51470, train loss-1.7764, acc-0.6000, valid loss-1.8528, acc-0.4874, test loss-1.8536, acc-0.4826\n",
      "Iter-51480, train loss-1.7908, acc-0.5800, valid loss-1.8528, acc-0.4876, test loss-1.8536, acc-0.4826\n",
      "Iter-51490, train loss-1.9980, acc-0.4200, valid loss-1.8527, acc-0.4876, test loss-1.8535, acc-0.4826\n",
      "Iter-51500, train loss-1.7873, acc-0.5200, valid loss-1.8526, acc-0.4876, test loss-1.8535, acc-0.4825\n",
      "Iter-51510, train loss-1.7843, acc-0.5000, valid loss-1.8526, acc-0.4876, test loss-1.8534, acc-0.4825\n",
      "Iter-51520, train loss-1.8677, acc-0.4400, valid loss-1.8525, acc-0.4876, test loss-1.8534, acc-0.4826\n",
      "Iter-51530, train loss-1.9387, acc-0.3800, valid loss-1.8525, acc-0.4876, test loss-1.8533, acc-0.4826\n",
      "Iter-51540, train loss-1.8192, acc-0.5000, valid loss-1.8524, acc-0.4878, test loss-1.8532, acc-0.4826\n",
      "Iter-51550, train loss-1.8544, acc-0.5000, valid loss-1.8524, acc-0.4876, test loss-1.8532, acc-0.4826\n",
      "Iter-51560, train loss-1.7127, acc-0.6600, valid loss-1.8523, acc-0.4876, test loss-1.8531, acc-0.4828\n",
      "Iter-51570, train loss-1.8743, acc-0.4800, valid loss-1.8523, acc-0.4876, test loss-1.8531, acc-0.4828\n",
      "Iter-51580, train loss-1.8228, acc-0.5000, valid loss-1.8522, acc-0.4876, test loss-1.8530, acc-0.4829\n",
      "Iter-51590, train loss-1.8216, acc-0.6000, valid loss-1.8521, acc-0.4878, test loss-1.8530, acc-0.4829\n",
      "Iter-51600, train loss-1.9503, acc-0.4200, valid loss-1.8521, acc-0.4878, test loss-1.8529, acc-0.4828\n",
      "Iter-51610, train loss-1.7591, acc-0.5200, valid loss-1.8520, acc-0.4878, test loss-1.8529, acc-0.4827\n",
      "Iter-51620, train loss-1.8312, acc-0.4800, valid loss-1.8520, acc-0.4878, test loss-1.8528, acc-0.4827\n",
      "Iter-51630, train loss-1.7774, acc-0.5600, valid loss-1.8519, acc-0.4876, test loss-1.8527, acc-0.4827\n",
      "Iter-51640, train loss-1.9071, acc-0.4400, valid loss-1.8519, acc-0.4878, test loss-1.8527, acc-0.4827\n",
      "Iter-51650, train loss-1.8981, acc-0.4800, valid loss-1.8518, acc-0.4878, test loss-1.8526, acc-0.4830\n",
      "Iter-51660, train loss-1.7925, acc-0.5000, valid loss-1.8518, acc-0.4878, test loss-1.8526, acc-0.4828\n",
      "Iter-51670, train loss-1.8121, acc-0.6000, valid loss-1.8517, acc-0.4880, test loss-1.8525, acc-0.4829\n",
      "Iter-51680, train loss-1.8652, acc-0.5000, valid loss-1.8516, acc-0.4882, test loss-1.8525, acc-0.4828\n",
      "Iter-51690, train loss-1.8037, acc-0.5400, valid loss-1.8516, acc-0.4878, test loss-1.8524, acc-0.4830\n",
      "Iter-51700, train loss-1.8306, acc-0.4000, valid loss-1.8515, acc-0.4882, test loss-1.8523, acc-0.4828\n",
      "Iter-51710, train loss-1.8577, acc-0.4800, valid loss-1.8515, acc-0.4878, test loss-1.8523, acc-0.4828\n",
      "Iter-51720, train loss-1.8899, acc-0.4400, valid loss-1.8514, acc-0.4880, test loss-1.8522, acc-0.4828\n",
      "Iter-51730, train loss-1.9464, acc-0.3600, valid loss-1.8514, acc-0.4882, test loss-1.8522, acc-0.4829\n",
      "Iter-51740, train loss-1.8442, acc-0.5000, valid loss-1.8513, acc-0.4882, test loss-1.8521, acc-0.4829\n",
      "Iter-51750, train loss-1.8092, acc-0.5400, valid loss-1.8513, acc-0.4882, test loss-1.8521, acc-0.4832\n",
      "Iter-51760, train loss-1.9053, acc-0.4200, valid loss-1.8512, acc-0.4882, test loss-1.8520, acc-0.4833\n",
      "Iter-51770, train loss-1.8751, acc-0.3800, valid loss-1.8511, acc-0.4884, test loss-1.8520, acc-0.4831\n",
      "Iter-51780, train loss-1.8653, acc-0.4400, valid loss-1.8511, acc-0.4884, test loss-1.8519, acc-0.4833\n",
      "Iter-51790, train loss-1.8021, acc-0.5600, valid loss-1.8510, acc-0.4884, test loss-1.8519, acc-0.4833\n",
      "Iter-51800, train loss-1.8896, acc-0.3800, valid loss-1.8510, acc-0.4884, test loss-1.8518, acc-0.4832\n",
      "Iter-51810, train loss-1.9091, acc-0.4600, valid loss-1.8509, acc-0.4884, test loss-1.8517, acc-0.4834\n",
      "Iter-51820, train loss-1.7913, acc-0.5800, valid loss-1.8509, acc-0.4886, test loss-1.8517, acc-0.4832\n",
      "Iter-51830, train loss-1.9107, acc-0.4200, valid loss-1.8508, acc-0.4886, test loss-1.8516, acc-0.4833\n",
      "Iter-51840, train loss-1.8282, acc-0.5000, valid loss-1.8507, acc-0.4884, test loss-1.8516, acc-0.4834\n",
      "Iter-51850, train loss-2.0028, acc-0.3400, valid loss-1.8507, acc-0.4884, test loss-1.8515, acc-0.4836\n",
      "Iter-51860, train loss-1.8402, acc-0.5000, valid loss-1.8506, acc-0.4886, test loss-1.8515, acc-0.4837\n",
      "Iter-51870, train loss-1.7604, acc-0.5200, valid loss-1.8506, acc-0.4886, test loss-1.8514, acc-0.4836\n",
      "Iter-51880, train loss-1.8255, acc-0.5400, valid loss-1.8505, acc-0.4884, test loss-1.8513, acc-0.4833\n",
      "Iter-51890, train loss-1.8693, acc-0.5000, valid loss-1.8505, acc-0.4886, test loss-1.8513, acc-0.4832\n",
      "Iter-51900, train loss-1.8178, acc-0.4600, valid loss-1.8504, acc-0.4886, test loss-1.8512, acc-0.4832\n",
      "Iter-51910, train loss-1.8844, acc-0.4400, valid loss-1.8503, acc-0.4884, test loss-1.8512, acc-0.4833\n",
      "Iter-51920, train loss-1.9418, acc-0.4400, valid loss-1.8503, acc-0.4884, test loss-1.8511, acc-0.4832\n",
      "Iter-51930, train loss-1.8002, acc-0.5600, valid loss-1.8502, acc-0.4884, test loss-1.8511, acc-0.4831\n",
      "Iter-51940, train loss-1.8523, acc-0.5400, valid loss-1.8502, acc-0.4886, test loss-1.8510, acc-0.4835\n",
      "Iter-51950, train loss-1.8837, acc-0.4200, valid loss-1.8501, acc-0.4886, test loss-1.8510, acc-0.4835\n",
      "Iter-51960, train loss-1.7517, acc-0.6200, valid loss-1.8501, acc-0.4884, test loss-1.8509, acc-0.4834\n",
      "Iter-51970, train loss-1.8619, acc-0.5200, valid loss-1.8500, acc-0.4884, test loss-1.8508, acc-0.4838\n",
      "Iter-51980, train loss-1.8575, acc-0.4200, valid loss-1.8500, acc-0.4886, test loss-1.8508, acc-0.4839\n",
      "Iter-51990, train loss-1.8257, acc-0.4600, valid loss-1.8499, acc-0.4886, test loss-1.8507, acc-0.4838\n",
      "Iter-52000, train loss-1.7257, acc-0.5800, valid loss-1.8498, acc-0.4886, test loss-1.8507, acc-0.4840\n",
      "Iter-52010, train loss-1.8474, acc-0.5200, valid loss-1.8498, acc-0.4886, test loss-1.8506, acc-0.4838\n",
      "Iter-52020, train loss-1.8726, acc-0.5400, valid loss-1.8497, acc-0.4884, test loss-1.8506, acc-0.4836\n",
      "Iter-52030, train loss-1.8804, acc-0.4400, valid loss-1.8497, acc-0.4882, test loss-1.8505, acc-0.4838\n",
      "Iter-52040, train loss-1.8884, acc-0.4600, valid loss-1.8496, acc-0.4882, test loss-1.8505, acc-0.4839\n",
      "Iter-52050, train loss-1.8636, acc-0.5600, valid loss-1.8496, acc-0.4880, test loss-1.8504, acc-0.4834\n",
      "Iter-52060, train loss-1.9230, acc-0.3400, valid loss-1.8495, acc-0.4882, test loss-1.8503, acc-0.4837\n",
      "Iter-52070, train loss-1.9481, acc-0.3000, valid loss-1.8494, acc-0.4882, test loss-1.8503, acc-0.4837\n",
      "Iter-52080, train loss-1.9036, acc-0.4200, valid loss-1.8494, acc-0.4882, test loss-1.8502, acc-0.4840\n",
      "Iter-52090, train loss-1.8692, acc-0.5200, valid loss-1.8493, acc-0.4880, test loss-1.8502, acc-0.4840\n",
      "Iter-52100, train loss-1.8562, acc-0.5600, valid loss-1.8493, acc-0.4878, test loss-1.8501, acc-0.4840\n",
      "Iter-52110, train loss-1.8816, acc-0.4200, valid loss-1.8492, acc-0.4882, test loss-1.8501, acc-0.4843\n",
      "Iter-52120, train loss-1.7775, acc-0.4600, valid loss-1.8492, acc-0.4880, test loss-1.8500, acc-0.4843\n",
      "Iter-52130, train loss-1.9420, acc-0.4400, valid loss-1.8491, acc-0.4878, test loss-1.8499, acc-0.4842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52140, train loss-1.8326, acc-0.5200, valid loss-1.8490, acc-0.4880, test loss-1.8499, acc-0.4842\n",
      "Iter-52150, train loss-1.8750, acc-0.5600, valid loss-1.8490, acc-0.4878, test loss-1.8498, acc-0.4839\n",
      "Iter-52160, train loss-1.7854, acc-0.4600, valid loss-1.8489, acc-0.4882, test loss-1.8498, acc-0.4840\n",
      "Iter-52170, train loss-1.8581, acc-0.5000, valid loss-1.8489, acc-0.4880, test loss-1.8497, acc-0.4841\n",
      "Iter-52180, train loss-1.8278, acc-0.5600, valid loss-1.8488, acc-0.4882, test loss-1.8497, acc-0.4840\n",
      "Iter-52190, train loss-1.9363, acc-0.4200, valid loss-1.8488, acc-0.4884, test loss-1.8496, acc-0.4841\n",
      "Iter-52200, train loss-1.7823, acc-0.5200, valid loss-1.8487, acc-0.4882, test loss-1.8496, acc-0.4840\n",
      "Iter-52210, train loss-1.8429, acc-0.5600, valid loss-1.8487, acc-0.4882, test loss-1.8495, acc-0.4839\n",
      "Iter-52220, train loss-1.8615, acc-0.4600, valid loss-1.8486, acc-0.4884, test loss-1.8494, acc-0.4838\n",
      "Iter-52230, train loss-1.9515, acc-0.4200, valid loss-1.8485, acc-0.4886, test loss-1.8494, acc-0.4838\n",
      "Iter-52240, train loss-1.6957, acc-0.6600, valid loss-1.8485, acc-0.4888, test loss-1.8493, acc-0.4840\n",
      "Iter-52250, train loss-1.8707, acc-0.5600, valid loss-1.8484, acc-0.4888, test loss-1.8493, acc-0.4838\n",
      "Iter-52260, train loss-1.8084, acc-0.5600, valid loss-1.8484, acc-0.4886, test loss-1.8492, acc-0.4839\n",
      "Iter-52270, train loss-1.9199, acc-0.4000, valid loss-1.8483, acc-0.4888, test loss-1.8492, acc-0.4839\n",
      "Iter-52280, train loss-1.8901, acc-0.4800, valid loss-1.8483, acc-0.4884, test loss-1.8491, acc-0.4840\n",
      "Iter-52290, train loss-1.9071, acc-0.4200, valid loss-1.8482, acc-0.4888, test loss-1.8491, acc-0.4839\n",
      "Iter-52300, train loss-1.8411, acc-0.4400, valid loss-1.8482, acc-0.4888, test loss-1.8490, acc-0.4840\n",
      "Iter-52310, train loss-1.9619, acc-0.3800, valid loss-1.8481, acc-0.4888, test loss-1.8489, acc-0.4838\n",
      "Iter-52320, train loss-1.9286, acc-0.4000, valid loss-1.8481, acc-0.4886, test loss-1.8489, acc-0.4837\n",
      "Iter-52330, train loss-1.8518, acc-0.4800, valid loss-1.8480, acc-0.4886, test loss-1.8488, acc-0.4835\n",
      "Iter-52340, train loss-1.8390, acc-0.4600, valid loss-1.8479, acc-0.4886, test loss-1.8488, acc-0.4837\n",
      "Iter-52350, train loss-1.7818, acc-0.5400, valid loss-1.8479, acc-0.4888, test loss-1.8487, acc-0.4836\n",
      "Iter-52360, train loss-1.8187, acc-0.5400, valid loss-1.8478, acc-0.4888, test loss-1.8487, acc-0.4838\n",
      "Iter-52370, train loss-1.8834, acc-0.4800, valid loss-1.8478, acc-0.4888, test loss-1.8486, acc-0.4836\n",
      "Iter-52380, train loss-1.9158, acc-0.4200, valid loss-1.8477, acc-0.4886, test loss-1.8486, acc-0.4837\n",
      "Iter-52390, train loss-1.8359, acc-0.5200, valid loss-1.8477, acc-0.4888, test loss-1.8485, acc-0.4838\n",
      "Iter-52400, train loss-1.8685, acc-0.3600, valid loss-1.8476, acc-0.4892, test loss-1.8484, acc-0.4839\n",
      "Iter-52410, train loss-1.8277, acc-0.5000, valid loss-1.8476, acc-0.4890, test loss-1.8484, acc-0.4839\n",
      "Iter-52420, train loss-1.8497, acc-0.5000, valid loss-1.8475, acc-0.4892, test loss-1.8483, acc-0.4840\n",
      "Iter-52430, train loss-1.8144, acc-0.5400, valid loss-1.8474, acc-0.4892, test loss-1.8483, acc-0.4841\n",
      "Iter-52440, train loss-1.8339, acc-0.4800, valid loss-1.8474, acc-0.4892, test loss-1.8482, acc-0.4842\n",
      "Iter-52450, train loss-1.8593, acc-0.4400, valid loss-1.8473, acc-0.4892, test loss-1.8482, acc-0.4843\n",
      "Iter-52460, train loss-1.7888, acc-0.4600, valid loss-1.8473, acc-0.4894, test loss-1.8481, acc-0.4845\n",
      "Iter-52470, train loss-1.8182, acc-0.5600, valid loss-1.8472, acc-0.4896, test loss-1.8481, acc-0.4843\n",
      "Iter-52480, train loss-1.7874, acc-0.4800, valid loss-1.8472, acc-0.4896, test loss-1.8480, acc-0.4845\n",
      "Iter-52490, train loss-1.8078, acc-0.4800, valid loss-1.8471, acc-0.4896, test loss-1.8479, acc-0.4846\n",
      "Iter-52500, train loss-1.7924, acc-0.4800, valid loss-1.8471, acc-0.4896, test loss-1.8479, acc-0.4841\n",
      "Iter-52510, train loss-1.8212, acc-0.4800, valid loss-1.8470, acc-0.4896, test loss-1.8478, acc-0.4844\n",
      "Iter-52520, train loss-1.8754, acc-0.4800, valid loss-1.8470, acc-0.4896, test loss-1.8478, acc-0.4844\n",
      "Iter-52530, train loss-1.8912, acc-0.4200, valid loss-1.8469, acc-0.4898, test loss-1.8477, acc-0.4843\n",
      "Iter-52540, train loss-1.7511, acc-0.6000, valid loss-1.8468, acc-0.4898, test loss-1.8477, acc-0.4841\n",
      "Iter-52550, train loss-1.8167, acc-0.4800, valid loss-1.8468, acc-0.4898, test loss-1.8476, acc-0.4842\n",
      "Iter-52560, train loss-1.8660, acc-0.4600, valid loss-1.8467, acc-0.4894, test loss-1.8476, acc-0.4841\n",
      "Iter-52570, train loss-1.9139, acc-0.3400, valid loss-1.8467, acc-0.4896, test loss-1.8475, acc-0.4841\n",
      "Iter-52580, train loss-1.7901, acc-0.5400, valid loss-1.8466, acc-0.4898, test loss-1.8474, acc-0.4841\n",
      "Iter-52590, train loss-1.8669, acc-0.4400, valid loss-1.8466, acc-0.4898, test loss-1.8474, acc-0.4842\n",
      "Iter-52600, train loss-1.8647, acc-0.5200, valid loss-1.8465, acc-0.4898, test loss-1.8473, acc-0.4841\n",
      "Iter-52610, train loss-1.8307, acc-0.5600, valid loss-1.8465, acc-0.4896, test loss-1.8473, acc-0.4842\n",
      "Iter-52620, train loss-1.8332, acc-0.5000, valid loss-1.8464, acc-0.4896, test loss-1.8472, acc-0.4842\n",
      "Iter-52630, train loss-1.9939, acc-0.2800, valid loss-1.8464, acc-0.4898, test loss-1.8472, acc-0.4842\n",
      "Iter-52640, train loss-1.8646, acc-0.5600, valid loss-1.8463, acc-0.4898, test loss-1.8471, acc-0.4843\n",
      "Iter-52650, train loss-1.7744, acc-0.5600, valid loss-1.8462, acc-0.4900, test loss-1.8471, acc-0.4842\n",
      "Iter-52660, train loss-1.9269, acc-0.4200, valid loss-1.8462, acc-0.4900, test loss-1.8470, acc-0.4842\n",
      "Iter-52670, train loss-1.7671, acc-0.6600, valid loss-1.8461, acc-0.4898, test loss-1.8470, acc-0.4844\n",
      "Iter-52680, train loss-1.8374, acc-0.4800, valid loss-1.8461, acc-0.4898, test loss-1.8469, acc-0.4845\n",
      "Iter-52690, train loss-1.7240, acc-0.5600, valid loss-1.8460, acc-0.4898, test loss-1.8468, acc-0.4843\n",
      "Iter-52700, train loss-1.8829, acc-0.4000, valid loss-1.8460, acc-0.4896, test loss-1.8468, acc-0.4843\n",
      "Iter-52710, train loss-1.9342, acc-0.3800, valid loss-1.8459, acc-0.4896, test loss-1.8467, acc-0.4844\n",
      "Iter-52720, train loss-1.8896, acc-0.4000, valid loss-1.8459, acc-0.4896, test loss-1.8467, acc-0.4845\n",
      "Iter-52730, train loss-1.9089, acc-0.4000, valid loss-1.8458, acc-0.4898, test loss-1.8466, acc-0.4845\n",
      "Iter-52740, train loss-1.8385, acc-0.4600, valid loss-1.8457, acc-0.4900, test loss-1.8466, acc-0.4845\n",
      "Iter-52750, train loss-1.7917, acc-0.5600, valid loss-1.8457, acc-0.4902, test loss-1.8465, acc-0.4844\n",
      "Iter-52760, train loss-1.9422, acc-0.4400, valid loss-1.8456, acc-0.4902, test loss-1.8465, acc-0.4844\n",
      "Iter-52770, train loss-1.9135, acc-0.4600, valid loss-1.8456, acc-0.4902, test loss-1.8464, acc-0.4844\n",
      "Iter-52780, train loss-1.9069, acc-0.4800, valid loss-1.8455, acc-0.4902, test loss-1.8463, acc-0.4844\n",
      "Iter-52790, train loss-1.8643, acc-0.4200, valid loss-1.8455, acc-0.4902, test loss-1.8463, acc-0.4844\n",
      "Iter-52800, train loss-1.8384, acc-0.5000, valid loss-1.8454, acc-0.4900, test loss-1.8462, acc-0.4843\n",
      "Iter-52810, train loss-1.8598, acc-0.4000, valid loss-1.8453, acc-0.4902, test loss-1.8462, acc-0.4844\n",
      "Iter-52820, train loss-1.8329, acc-0.4800, valid loss-1.8453, acc-0.4904, test loss-1.8461, acc-0.4844\n",
      "Iter-52830, train loss-1.8773, acc-0.5200, valid loss-1.8452, acc-0.4902, test loss-1.8461, acc-0.4843\n",
      "Iter-52840, train loss-1.8283, acc-0.4600, valid loss-1.8452, acc-0.4902, test loss-1.8460, acc-0.4843\n",
      "Iter-52850, train loss-1.9684, acc-0.4000, valid loss-1.8451, acc-0.4902, test loss-1.8460, acc-0.4843\n",
      "Iter-52860, train loss-1.8261, acc-0.5000, valid loss-1.8451, acc-0.4902, test loss-1.8459, acc-0.4843\n",
      "Iter-52870, train loss-1.9340, acc-0.3400, valid loss-1.8450, acc-0.4900, test loss-1.8458, acc-0.4843\n",
      "Iter-52880, train loss-1.9400, acc-0.4000, valid loss-1.8450, acc-0.4900, test loss-1.8458, acc-0.4843\n",
      "Iter-52890, train loss-1.8939, acc-0.4000, valid loss-1.8449, acc-0.4902, test loss-1.8457, acc-0.4843\n",
      "Iter-52900, train loss-1.8680, acc-0.5200, valid loss-1.8448, acc-0.4900, test loss-1.8457, acc-0.4843\n",
      "Iter-52910, train loss-1.8996, acc-0.5000, valid loss-1.8448, acc-0.4898, test loss-1.8456, acc-0.4844\n",
      "Iter-52920, train loss-1.7275, acc-0.5200, valid loss-1.8447, acc-0.4900, test loss-1.8456, acc-0.4844\n",
      "Iter-52930, train loss-1.9672, acc-0.4000, valid loss-1.8447, acc-0.4900, test loss-1.8455, acc-0.4843\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-52940, train loss-1.7966, acc-0.5800, valid loss-1.8446, acc-0.4900, test loss-1.8455, acc-0.4843\n",
      "Iter-52950, train loss-1.7637, acc-0.5200, valid loss-1.8446, acc-0.4904, test loss-1.8454, acc-0.4843\n",
      "Iter-52960, train loss-1.8050, acc-0.5000, valid loss-1.8445, acc-0.4902, test loss-1.8453, acc-0.4842\n",
      "Iter-52970, train loss-1.9334, acc-0.4000, valid loss-1.8445, acc-0.4904, test loss-1.8453, acc-0.4844\n",
      "Iter-52980, train loss-1.8814, acc-0.5000, valid loss-1.8444, acc-0.4906, test loss-1.8452, acc-0.4844\n",
      "Iter-52990, train loss-1.7428, acc-0.5600, valid loss-1.8443, acc-0.4904, test loss-1.8452, acc-0.4842\n",
      "Iter-53000, train loss-1.8993, acc-0.4400, valid loss-1.8443, acc-0.4904, test loss-1.8451, acc-0.4842\n",
      "Iter-53010, train loss-1.8577, acc-0.4200, valid loss-1.8442, acc-0.4904, test loss-1.8451, acc-0.4843\n",
      "Iter-53020, train loss-1.8718, acc-0.4000, valid loss-1.8442, acc-0.4904, test loss-1.8450, acc-0.4844\n",
      "Iter-53030, train loss-1.9306, acc-0.3200, valid loss-1.8441, acc-0.4904, test loss-1.8450, acc-0.4844\n",
      "Iter-53040, train loss-1.8650, acc-0.4600, valid loss-1.8441, acc-0.4902, test loss-1.8449, acc-0.4844\n",
      "Iter-53050, train loss-1.8987, acc-0.4400, valid loss-1.8440, acc-0.4904, test loss-1.8448, acc-0.4844\n",
      "Iter-53060, train loss-1.8624, acc-0.4600, valid loss-1.8439, acc-0.4906, test loss-1.8448, acc-0.4843\n",
      "Iter-53070, train loss-1.8240, acc-0.5200, valid loss-1.8439, acc-0.4906, test loss-1.8447, acc-0.4847\n",
      "Iter-53080, train loss-1.9056, acc-0.4400, valid loss-1.8438, acc-0.4908, test loss-1.8447, acc-0.4846\n",
      "Iter-53090, train loss-1.7985, acc-0.5600, valid loss-1.8438, acc-0.4904, test loss-1.8446, acc-0.4844\n",
      "Iter-53100, train loss-1.8752, acc-0.5200, valid loss-1.8437, acc-0.4908, test loss-1.8446, acc-0.4845\n",
      "Iter-53110, train loss-1.8624, acc-0.5200, valid loss-1.8437, acc-0.4908, test loss-1.8445, acc-0.4845\n",
      "Iter-53120, train loss-1.9338, acc-0.4200, valid loss-1.8436, acc-0.4906, test loss-1.8445, acc-0.4843\n",
      "Iter-53130, train loss-1.9349, acc-0.3400, valid loss-1.8436, acc-0.4910, test loss-1.8444, acc-0.4843\n",
      "Iter-53140, train loss-1.8055, acc-0.4200, valid loss-1.8435, acc-0.4904, test loss-1.8443, acc-0.4844\n",
      "Iter-53150, train loss-1.8311, acc-0.4200, valid loss-1.8434, acc-0.4904, test loss-1.8443, acc-0.4843\n",
      "Iter-53160, train loss-1.8216, acc-0.5000, valid loss-1.8434, acc-0.4906, test loss-1.8442, acc-0.4844\n",
      "Iter-53170, train loss-1.8676, acc-0.5200, valid loss-1.8433, acc-0.4906, test loss-1.8442, acc-0.4845\n",
      "Iter-53180, train loss-1.7494, acc-0.5600, valid loss-1.8433, acc-0.4898, test loss-1.8441, acc-0.4845\n",
      "Iter-53190, train loss-1.8448, acc-0.4200, valid loss-1.8432, acc-0.4896, test loss-1.8441, acc-0.4844\n",
      "Iter-53200, train loss-1.8269, acc-0.5000, valid loss-1.8432, acc-0.4900, test loss-1.8440, acc-0.4844\n",
      "Iter-53210, train loss-1.9972, acc-0.4200, valid loss-1.8431, acc-0.4898, test loss-1.8439, acc-0.4843\n",
      "Iter-53220, train loss-1.7998, acc-0.4800, valid loss-1.8430, acc-0.4900, test loss-1.8439, acc-0.4845\n",
      "Iter-53230, train loss-1.8721, acc-0.4200, valid loss-1.8430, acc-0.4894, test loss-1.8438, acc-0.4844\n",
      "Iter-53240, train loss-1.7702, acc-0.4800, valid loss-1.8429, acc-0.4894, test loss-1.8438, acc-0.4844\n",
      "Iter-53250, train loss-1.7641, acc-0.6000, valid loss-1.8429, acc-0.4896, test loss-1.8437, acc-0.4847\n",
      "Iter-53260, train loss-1.7868, acc-0.4800, valid loss-1.8428, acc-0.4894, test loss-1.8437, acc-0.4845\n",
      "Iter-53270, train loss-1.8257, acc-0.5200, valid loss-1.8428, acc-0.4894, test loss-1.8436, acc-0.4846\n",
      "Iter-53280, train loss-1.8623, acc-0.5200, valid loss-1.8427, acc-0.4898, test loss-1.8436, acc-0.4845\n",
      "Iter-53290, train loss-1.8846, acc-0.4800, valid loss-1.8427, acc-0.4898, test loss-1.8435, acc-0.4845\n",
      "Iter-53300, train loss-1.8572, acc-0.5000, valid loss-1.8426, acc-0.4900, test loss-1.8435, acc-0.4843\n",
      "Iter-53310, train loss-1.8974, acc-0.4400, valid loss-1.8426, acc-0.4900, test loss-1.8434, acc-0.4843\n",
      "Iter-53320, train loss-1.8065, acc-0.4600, valid loss-1.8425, acc-0.4904, test loss-1.8433, acc-0.4841\n",
      "Iter-53330, train loss-1.8868, acc-0.4000, valid loss-1.8424, acc-0.4902, test loss-1.8433, acc-0.4846\n",
      "Iter-53340, train loss-1.8934, acc-0.4800, valid loss-1.8424, acc-0.4904, test loss-1.8432, acc-0.4843\n",
      "Iter-53350, train loss-1.8214, acc-0.4600, valid loss-1.8423, acc-0.4902, test loss-1.8432, acc-0.4844\n",
      "Iter-53360, train loss-1.8939, acc-0.4800, valid loss-1.8423, acc-0.4902, test loss-1.8431, acc-0.4844\n",
      "Iter-53370, train loss-1.7535, acc-0.6000, valid loss-1.8422, acc-0.4900, test loss-1.8431, acc-0.4843\n",
      "Iter-53380, train loss-1.8351, acc-0.4800, valid loss-1.8422, acc-0.4902, test loss-1.8430, acc-0.4840\n",
      "Iter-53390, train loss-1.8913, acc-0.4400, valid loss-1.8421, acc-0.4900, test loss-1.8430, acc-0.4844\n",
      "Iter-53400, train loss-1.8811, acc-0.4000, valid loss-1.8421, acc-0.4902, test loss-1.8429, acc-0.4844\n",
      "Iter-53410, train loss-1.8608, acc-0.4400, valid loss-1.8420, acc-0.4902, test loss-1.8429, acc-0.4844\n",
      "Iter-53420, train loss-1.8381, acc-0.5800, valid loss-1.8420, acc-0.4904, test loss-1.8428, acc-0.4846\n",
      "Iter-53430, train loss-1.9114, acc-0.4200, valid loss-1.8419, acc-0.4900, test loss-1.8427, acc-0.4847\n",
      "Iter-53440, train loss-1.8286, acc-0.4600, valid loss-1.8419, acc-0.4900, test loss-1.8427, acc-0.4849\n",
      "Iter-53450, train loss-1.8954, acc-0.4400, valid loss-1.8418, acc-0.4902, test loss-1.8426, acc-0.4850\n",
      "Iter-53460, train loss-1.8993, acc-0.3800, valid loss-1.8417, acc-0.4904, test loss-1.8426, acc-0.4850\n",
      "Iter-53470, train loss-1.8014, acc-0.5200, valid loss-1.8417, acc-0.4906, test loss-1.8425, acc-0.4850\n",
      "Iter-53480, train loss-1.7900, acc-0.5800, valid loss-1.8416, acc-0.4902, test loss-1.8425, acc-0.4850\n",
      "Iter-53490, train loss-1.7962, acc-0.6000, valid loss-1.8416, acc-0.4906, test loss-1.8424, acc-0.4851\n",
      "Iter-53500, train loss-1.8473, acc-0.5200, valid loss-1.8415, acc-0.4902, test loss-1.8424, acc-0.4851\n",
      "Iter-53510, train loss-1.8137, acc-0.5000, valid loss-1.8415, acc-0.4900, test loss-1.8423, acc-0.4852\n",
      "Iter-53520, train loss-1.8363, acc-0.5000, valid loss-1.8414, acc-0.4904, test loss-1.8423, acc-0.4849\n",
      "Iter-53530, train loss-1.7723, acc-0.5800, valid loss-1.8414, acc-0.4904, test loss-1.8422, acc-0.4849\n",
      "Iter-53540, train loss-1.8279, acc-0.5200, valid loss-1.8413, acc-0.4906, test loss-1.8421, acc-0.4848\n",
      "Iter-53550, train loss-1.9044, acc-0.4200, valid loss-1.8413, acc-0.4904, test loss-1.8421, acc-0.4849\n",
      "Iter-53560, train loss-1.7947, acc-0.4600, valid loss-1.8412, acc-0.4904, test loss-1.8420, acc-0.4848\n",
      "Iter-53570, train loss-1.9068, acc-0.4600, valid loss-1.8411, acc-0.4904, test loss-1.8420, acc-0.4851\n",
      "Iter-53580, train loss-1.8222, acc-0.6000, valid loss-1.8411, acc-0.4904, test loss-1.8419, acc-0.4851\n",
      "Iter-53590, train loss-1.8785, acc-0.5400, valid loss-1.8410, acc-0.4904, test loss-1.8419, acc-0.4853\n",
      "Iter-53600, train loss-1.9198, acc-0.4400, valid loss-1.8410, acc-0.4902, test loss-1.8418, acc-0.4853\n",
      "Iter-53610, train loss-1.9703, acc-0.3200, valid loss-1.8409, acc-0.4904, test loss-1.8418, acc-0.4851\n",
      "Iter-53620, train loss-1.8453, acc-0.5000, valid loss-1.8409, acc-0.4902, test loss-1.8417, acc-0.4851\n",
      "Iter-53630, train loss-1.7936, acc-0.5200, valid loss-1.8408, acc-0.4904, test loss-1.8417, acc-0.4854\n",
      "Iter-53640, train loss-1.8672, acc-0.4400, valid loss-1.8408, acc-0.4904, test loss-1.8416, acc-0.4855\n",
      "Iter-53650, train loss-1.8358, acc-0.4400, valid loss-1.8407, acc-0.4906, test loss-1.8415, acc-0.4855\n",
      "Iter-53660, train loss-1.7730, acc-0.5400, valid loss-1.8407, acc-0.4904, test loss-1.8415, acc-0.4855\n",
      "Iter-53670, train loss-1.8861, acc-0.3800, valid loss-1.8406, acc-0.4902, test loss-1.8414, acc-0.4855\n",
      "Iter-53680, train loss-1.8571, acc-0.4400, valid loss-1.8406, acc-0.4902, test loss-1.8414, acc-0.4854\n",
      "Iter-53690, train loss-1.8666, acc-0.4000, valid loss-1.8405, acc-0.4902, test loss-1.8413, acc-0.4854\n",
      "Iter-53700, train loss-1.8851, acc-0.4600, valid loss-1.8404, acc-0.4902, test loss-1.8413, acc-0.4854\n",
      "Iter-53710, train loss-1.8833, acc-0.5000, valid loss-1.8404, acc-0.4902, test loss-1.8412, acc-0.4853\n",
      "Iter-53720, train loss-1.8365, acc-0.5400, valid loss-1.8403, acc-0.4904, test loss-1.8412, acc-0.4854\n",
      "Iter-53730, train loss-1.8098, acc-0.4800, valid loss-1.8403, acc-0.4904, test loss-1.8411, acc-0.4853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-53740, train loss-1.7921, acc-0.5200, valid loss-1.8402, acc-0.4906, test loss-1.8411, acc-0.4853\n",
      "Iter-53750, train loss-1.8527, acc-0.5000, valid loss-1.8402, acc-0.4906, test loss-1.8410, acc-0.4853\n",
      "Iter-53760, train loss-1.7794, acc-0.5000, valid loss-1.8401, acc-0.4904, test loss-1.8410, acc-0.4852\n",
      "Iter-53770, train loss-1.8856, acc-0.4000, valid loss-1.8401, acc-0.4904, test loss-1.8409, acc-0.4853\n",
      "Iter-53780, train loss-1.8079, acc-0.5000, valid loss-1.8400, acc-0.4906, test loss-1.8408, acc-0.4854\n",
      "Iter-53790, train loss-1.9151, acc-0.2400, valid loss-1.8400, acc-0.4904, test loss-1.8408, acc-0.4854\n",
      "Iter-53800, train loss-1.8573, acc-0.4400, valid loss-1.8399, acc-0.4906, test loss-1.8407, acc-0.4853\n",
      "Iter-53810, train loss-1.8752, acc-0.5000, valid loss-1.8398, acc-0.4906, test loss-1.8407, acc-0.4854\n",
      "Iter-53820, train loss-1.8571, acc-0.4800, valid loss-1.8398, acc-0.4906, test loss-1.8406, acc-0.4854\n",
      "Iter-53830, train loss-1.8936, acc-0.4600, valid loss-1.8397, acc-0.4908, test loss-1.8406, acc-0.4857\n",
      "Iter-53840, train loss-1.8685, acc-0.5000, valid loss-1.8397, acc-0.4906, test loss-1.8405, acc-0.4857\n",
      "Iter-53850, train loss-1.7956, acc-0.5000, valid loss-1.8396, acc-0.4906, test loss-1.8405, acc-0.4859\n",
      "Iter-53860, train loss-1.8338, acc-0.5200, valid loss-1.8396, acc-0.4908, test loss-1.8404, acc-0.4859\n",
      "Iter-53870, train loss-1.8126, acc-0.5200, valid loss-1.8395, acc-0.4910, test loss-1.8404, acc-0.4860\n",
      "Iter-53880, train loss-1.8292, acc-0.4800, valid loss-1.8395, acc-0.4908, test loss-1.8403, acc-0.4860\n",
      "Iter-53890, train loss-1.9832, acc-0.3600, valid loss-1.8394, acc-0.4906, test loss-1.8402, acc-0.4859\n",
      "Iter-53900, train loss-1.8574, acc-0.5000, valid loss-1.8394, acc-0.4906, test loss-1.8402, acc-0.4859\n",
      "Iter-53910, train loss-1.7465, acc-0.5600, valid loss-1.8393, acc-0.4906, test loss-1.8401, acc-0.4857\n",
      "Iter-53920, train loss-1.8120, acc-0.4600, valid loss-1.8393, acc-0.4906, test loss-1.8401, acc-0.4860\n",
      "Iter-53930, train loss-1.8510, acc-0.4200, valid loss-1.8392, acc-0.4908, test loss-1.8400, acc-0.4858\n",
      "Iter-53940, train loss-1.8440, acc-0.4600, valid loss-1.8392, acc-0.4908, test loss-1.8400, acc-0.4859\n",
      "Iter-53950, train loss-1.9005, acc-0.4600, valid loss-1.8391, acc-0.4910, test loss-1.8399, acc-0.4859\n",
      "Iter-53960, train loss-1.8416, acc-0.5800, valid loss-1.8390, acc-0.4908, test loss-1.8399, acc-0.4860\n",
      "Iter-53970, train loss-1.8778, acc-0.4000, valid loss-1.8390, acc-0.4910, test loss-1.8398, acc-0.4862\n",
      "Iter-53980, train loss-1.9022, acc-0.4000, valid loss-1.8389, acc-0.4910, test loss-1.8398, acc-0.4860\n",
      "Iter-53990, train loss-1.8865, acc-0.4400, valid loss-1.8389, acc-0.4912, test loss-1.8397, acc-0.4860\n",
      "Iter-54000, train loss-1.7976, acc-0.5600, valid loss-1.8388, acc-0.4912, test loss-1.8397, acc-0.4860\n",
      "Iter-54010, train loss-1.8884, acc-0.4800, valid loss-1.8388, acc-0.4912, test loss-1.8396, acc-0.4860\n",
      "Iter-54020, train loss-1.7644, acc-0.5800, valid loss-1.8387, acc-0.4912, test loss-1.8396, acc-0.4861\n",
      "Iter-54030, train loss-1.7800, acc-0.5200, valid loss-1.8387, acc-0.4912, test loss-1.8395, acc-0.4862\n",
      "Iter-54040, train loss-1.9939, acc-0.3400, valid loss-1.8386, acc-0.4912, test loss-1.8394, acc-0.4861\n",
      "Iter-54050, train loss-1.8591, acc-0.3800, valid loss-1.8386, acc-0.4912, test loss-1.8394, acc-0.4860\n",
      "Iter-54060, train loss-1.8437, acc-0.4400, valid loss-1.8385, acc-0.4912, test loss-1.8393, acc-0.4861\n",
      "Iter-54070, train loss-1.8260, acc-0.4600, valid loss-1.8384, acc-0.4912, test loss-1.8393, acc-0.4861\n",
      "Iter-54080, train loss-1.7741, acc-0.6000, valid loss-1.8384, acc-0.4912, test loss-1.8392, acc-0.4861\n",
      "Iter-54090, train loss-1.8542, acc-0.4000, valid loss-1.8383, acc-0.4912, test loss-1.8392, acc-0.4860\n",
      "Iter-54100, train loss-1.7591, acc-0.6000, valid loss-1.8383, acc-0.4914, test loss-1.8391, acc-0.4860\n",
      "Iter-54110, train loss-1.8764, acc-0.4400, valid loss-1.8382, acc-0.4912, test loss-1.8391, acc-0.4861\n",
      "Iter-54120, train loss-1.8191, acc-0.5200, valid loss-1.8382, acc-0.4914, test loss-1.8390, acc-0.4863\n",
      "Iter-54130, train loss-1.8310, acc-0.4800, valid loss-1.8381, acc-0.4910, test loss-1.8390, acc-0.4862\n",
      "Iter-54140, train loss-1.8933, acc-0.4200, valid loss-1.8381, acc-0.4912, test loss-1.8389, acc-0.4862\n",
      "Iter-54150, train loss-1.8472, acc-0.4800, valid loss-1.8380, acc-0.4912, test loss-1.8388, acc-0.4863\n",
      "Iter-54160, train loss-1.9211, acc-0.3800, valid loss-1.8379, acc-0.4914, test loss-1.8388, acc-0.4864\n",
      "Iter-54170, train loss-1.7989, acc-0.5800, valid loss-1.8379, acc-0.4912, test loss-1.8387, acc-0.4865\n",
      "Iter-54180, train loss-1.8099, acc-0.5400, valid loss-1.8378, acc-0.4916, test loss-1.8387, acc-0.4864\n",
      "Iter-54190, train loss-1.8940, acc-0.3800, valid loss-1.8378, acc-0.4912, test loss-1.8386, acc-0.4861\n",
      "Iter-54200, train loss-1.7261, acc-0.5800, valid loss-1.8377, acc-0.4912, test loss-1.8386, acc-0.4861\n",
      "Iter-54210, train loss-1.8269, acc-0.4400, valid loss-1.8377, acc-0.4914, test loss-1.8385, acc-0.4864\n",
      "Iter-54220, train loss-1.8021, acc-0.4600, valid loss-1.8376, acc-0.4916, test loss-1.8385, acc-0.4863\n",
      "Iter-54230, train loss-1.9428, acc-0.4200, valid loss-1.8376, acc-0.4916, test loss-1.8384, acc-0.4865\n",
      "Iter-54240, train loss-1.8698, acc-0.4400, valid loss-1.8375, acc-0.4914, test loss-1.8384, acc-0.4865\n",
      "Iter-54250, train loss-1.9333, acc-0.3400, valid loss-1.8375, acc-0.4916, test loss-1.8383, acc-0.4863\n",
      "Iter-54260, train loss-1.9442, acc-0.4000, valid loss-1.8374, acc-0.4916, test loss-1.8383, acc-0.4866\n",
      "Iter-54270, train loss-1.9034, acc-0.4400, valid loss-1.8374, acc-0.4918, test loss-1.8382, acc-0.4863\n",
      "Iter-54280, train loss-1.7976, acc-0.5400, valid loss-1.8373, acc-0.4916, test loss-1.8381, acc-0.4865\n",
      "Iter-54290, train loss-1.8628, acc-0.5000, valid loss-1.8373, acc-0.4914, test loss-1.8381, acc-0.4864\n",
      "Iter-54300, train loss-1.8255, acc-0.5000, valid loss-1.8372, acc-0.4916, test loss-1.8380, acc-0.4865\n",
      "Iter-54310, train loss-1.8922, acc-0.4200, valid loss-1.8372, acc-0.4916, test loss-1.8380, acc-0.4865\n",
      "Iter-54320, train loss-1.8431, acc-0.4800, valid loss-1.8371, acc-0.4918, test loss-1.8379, acc-0.4867\n",
      "Iter-54330, train loss-1.9181, acc-0.4400, valid loss-1.8370, acc-0.4918, test loss-1.8379, acc-0.4866\n",
      "Iter-54340, train loss-1.9333, acc-0.4000, valid loss-1.8370, acc-0.4918, test loss-1.8378, acc-0.4867\n",
      "Iter-54350, train loss-1.8789, acc-0.4200, valid loss-1.8369, acc-0.4916, test loss-1.8378, acc-0.4867\n",
      "Iter-54360, train loss-1.8870, acc-0.4800, valid loss-1.8369, acc-0.4916, test loss-1.8377, acc-0.4868\n",
      "Iter-54370, train loss-1.7807, acc-0.4800, valid loss-1.8368, acc-0.4914, test loss-1.8377, acc-0.4869\n",
      "Iter-54380, train loss-1.8464, acc-0.4800, valid loss-1.8368, acc-0.4914, test loss-1.8376, acc-0.4868\n",
      "Iter-54390, train loss-1.9325, acc-0.4400, valid loss-1.8367, acc-0.4916, test loss-1.8376, acc-0.4868\n",
      "Iter-54400, train loss-1.7870, acc-0.5000, valid loss-1.8367, acc-0.4916, test loss-1.8375, acc-0.4867\n",
      "Iter-54410, train loss-1.8221, acc-0.4400, valid loss-1.8366, acc-0.4918, test loss-1.8374, acc-0.4868\n",
      "Iter-54420, train loss-1.8418, acc-0.4200, valid loss-1.8365, acc-0.4918, test loss-1.8374, acc-0.4869\n",
      "Iter-54430, train loss-1.9261, acc-0.4200, valid loss-1.8365, acc-0.4916, test loss-1.8373, acc-0.4869\n",
      "Iter-54440, train loss-1.8188, acc-0.5000, valid loss-1.8364, acc-0.4918, test loss-1.8373, acc-0.4869\n",
      "Iter-54450, train loss-1.8277, acc-0.4800, valid loss-1.8364, acc-0.4918, test loss-1.8372, acc-0.4869\n",
      "Iter-54460, train loss-1.8777, acc-0.4600, valid loss-1.8363, acc-0.4920, test loss-1.8372, acc-0.4868\n",
      "Iter-54470, train loss-1.8845, acc-0.4400, valid loss-1.8363, acc-0.4920, test loss-1.8371, acc-0.4870\n",
      "Iter-54480, train loss-1.8083, acc-0.4800, valid loss-1.8362, acc-0.4920, test loss-1.8371, acc-0.4871\n",
      "Iter-54490, train loss-1.8411, acc-0.5400, valid loss-1.8362, acc-0.4920, test loss-1.8370, acc-0.4871\n",
      "Iter-54500, train loss-1.8176, acc-0.4400, valid loss-1.8361, acc-0.4920, test loss-1.8370, acc-0.4871\n",
      "Iter-54510, train loss-1.8487, acc-0.4000, valid loss-1.8361, acc-0.4922, test loss-1.8369, acc-0.4870\n",
      "Iter-54520, train loss-1.8397, acc-0.5800, valid loss-1.8360, acc-0.4922, test loss-1.8369, acc-0.4869\n",
      "Iter-54530, train loss-1.7495, acc-0.5600, valid loss-1.8359, acc-0.4920, test loss-1.8368, acc-0.4868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-54540, train loss-1.8305, acc-0.5200, valid loss-1.8359, acc-0.4920, test loss-1.8367, acc-0.4868\n",
      "Iter-54550, train loss-1.8745, acc-0.4200, valid loss-1.8358, acc-0.4920, test loss-1.8367, acc-0.4868\n",
      "Iter-54560, train loss-1.8076, acc-0.4600, valid loss-1.8358, acc-0.4920, test loss-1.8366, acc-0.4868\n",
      "Iter-54570, train loss-1.8107, acc-0.5600, valid loss-1.8357, acc-0.4920, test loss-1.8366, acc-0.4868\n",
      "Iter-54580, train loss-1.7414, acc-0.5600, valid loss-1.8357, acc-0.4922, test loss-1.8365, acc-0.4870\n",
      "Iter-54590, train loss-1.8129, acc-0.5000, valid loss-1.8356, acc-0.4922, test loss-1.8365, acc-0.4869\n",
      "Iter-54600, train loss-1.8626, acc-0.5200, valid loss-1.8356, acc-0.4922, test loss-1.8364, acc-0.4870\n",
      "Iter-54610, train loss-1.7197, acc-0.5800, valid loss-1.8355, acc-0.4924, test loss-1.8364, acc-0.4870\n",
      "Iter-54620, train loss-1.7628, acc-0.6400, valid loss-1.8355, acc-0.4922, test loss-1.8363, acc-0.4869\n",
      "Iter-54630, train loss-1.7949, acc-0.5400, valid loss-1.8354, acc-0.4924, test loss-1.8363, acc-0.4870\n",
      "Iter-54640, train loss-1.8340, acc-0.4200, valid loss-1.8354, acc-0.4922, test loss-1.8362, acc-0.4870\n",
      "Iter-54650, train loss-1.7274, acc-0.6400, valid loss-1.8353, acc-0.4924, test loss-1.8361, acc-0.4870\n",
      "Iter-54660, train loss-1.8529, acc-0.5000, valid loss-1.8352, acc-0.4922, test loss-1.8361, acc-0.4872\n",
      "Iter-54670, train loss-1.8623, acc-0.4800, valid loss-1.8352, acc-0.4922, test loss-1.8360, acc-0.4872\n",
      "Iter-54680, train loss-1.8762, acc-0.4400, valid loss-1.8351, acc-0.4924, test loss-1.8360, acc-0.4872\n",
      "Iter-54690, train loss-1.8431, acc-0.6000, valid loss-1.8351, acc-0.4924, test loss-1.8359, acc-0.4872\n",
      "Iter-54700, train loss-1.8218, acc-0.4800, valid loss-1.8350, acc-0.4924, test loss-1.8359, acc-0.4871\n",
      "Iter-54710, train loss-1.8061, acc-0.5000, valid loss-1.8350, acc-0.4922, test loss-1.8358, acc-0.4872\n",
      "Iter-54720, train loss-1.7556, acc-0.6000, valid loss-1.8349, acc-0.4924, test loss-1.8358, acc-0.4872\n",
      "Iter-54730, train loss-1.9528, acc-0.3600, valid loss-1.8349, acc-0.4922, test loss-1.8357, acc-0.4872\n",
      "Iter-54740, train loss-1.7750, acc-0.5400, valid loss-1.8348, acc-0.4926, test loss-1.8357, acc-0.4873\n",
      "Iter-54750, train loss-1.8064, acc-0.4600, valid loss-1.8348, acc-0.4924, test loss-1.8356, acc-0.4874\n",
      "Iter-54760, train loss-1.8559, acc-0.5000, valid loss-1.8347, acc-0.4924, test loss-1.8356, acc-0.4874\n",
      "Iter-54770, train loss-1.7286, acc-0.6000, valid loss-1.8346, acc-0.4926, test loss-1.8355, acc-0.4875\n",
      "Iter-54780, train loss-1.8896, acc-0.4800, valid loss-1.8346, acc-0.4926, test loss-1.8355, acc-0.4874\n",
      "Iter-54790, train loss-1.8103, acc-0.5400, valid loss-1.8345, acc-0.4924, test loss-1.8354, acc-0.4874\n",
      "Iter-54800, train loss-1.8098, acc-0.5000, valid loss-1.8345, acc-0.4924, test loss-1.8353, acc-0.4874\n",
      "Iter-54810, train loss-1.8731, acc-0.4600, valid loss-1.8344, acc-0.4924, test loss-1.8353, acc-0.4874\n",
      "Iter-54820, train loss-1.8773, acc-0.5000, valid loss-1.8344, acc-0.4920, test loss-1.8352, acc-0.4873\n",
      "Iter-54830, train loss-1.8173, acc-0.5800, valid loss-1.8343, acc-0.4920, test loss-1.8352, acc-0.4872\n",
      "Iter-54840, train loss-1.8669, acc-0.4800, valid loss-1.8343, acc-0.4920, test loss-1.8351, acc-0.4872\n",
      "Iter-54850, train loss-1.8014, acc-0.5000, valid loss-1.8342, acc-0.4920, test loss-1.8351, acc-0.4872\n",
      "Iter-54860, train loss-1.9176, acc-0.4200, valid loss-1.8342, acc-0.4922, test loss-1.8350, acc-0.4873\n",
      "Iter-54870, train loss-1.8847, acc-0.4200, valid loss-1.8341, acc-0.4922, test loss-1.8350, acc-0.4872\n",
      "Iter-54880, train loss-1.8266, acc-0.5200, valid loss-1.8341, acc-0.4922, test loss-1.8349, acc-0.4873\n",
      "Iter-54890, train loss-1.8463, acc-0.5000, valid loss-1.8340, acc-0.4922, test loss-1.8349, acc-0.4874\n",
      "Iter-54900, train loss-1.9159, acc-0.4600, valid loss-1.8339, acc-0.4922, test loss-1.8348, acc-0.4875\n",
      "Iter-54910, train loss-1.8399, acc-0.4800, valid loss-1.8339, acc-0.4922, test loss-1.8347, acc-0.4876\n",
      "Iter-54920, train loss-1.8190, acc-0.4800, valid loss-1.8338, acc-0.4922, test loss-1.8347, acc-0.4877\n",
      "Iter-54930, train loss-1.8644, acc-0.4600, valid loss-1.8338, acc-0.4922, test loss-1.8346, acc-0.4877\n",
      "Iter-54940, train loss-1.9059, acc-0.3800, valid loss-1.8337, acc-0.4922, test loss-1.8346, acc-0.4878\n",
      "Iter-54950, train loss-1.7855, acc-0.5600, valid loss-1.8337, acc-0.4924, test loss-1.8345, acc-0.4878\n",
      "Iter-54960, train loss-1.7738, acc-0.5200, valid loss-1.8336, acc-0.4924, test loss-1.8345, acc-0.4877\n",
      "Iter-54970, train loss-1.9327, acc-0.4400, valid loss-1.8336, acc-0.4922, test loss-1.8344, acc-0.4878\n",
      "Iter-54980, train loss-1.8495, acc-0.4200, valid loss-1.8335, acc-0.4924, test loss-1.8344, acc-0.4877\n",
      "Iter-54990, train loss-1.8450, acc-0.4200, valid loss-1.8335, acc-0.4924, test loss-1.8343, acc-0.4878\n",
      "Iter-55000, train loss-1.8437, acc-0.5000, valid loss-1.8334, acc-0.4924, test loss-1.8343, acc-0.4878\n",
      "Iter-55010, train loss-1.8447, acc-0.5800, valid loss-1.8334, acc-0.4926, test loss-1.8342, acc-0.4878\n",
      "Iter-55020, train loss-1.8410, acc-0.5000, valid loss-1.8333, acc-0.4926, test loss-1.8342, acc-0.4879\n",
      "Iter-55030, train loss-1.8048, acc-0.5200, valid loss-1.8333, acc-0.4922, test loss-1.8341, acc-0.4877\n",
      "Iter-55040, train loss-1.8829, acc-0.3400, valid loss-1.8332, acc-0.4922, test loss-1.8340, acc-0.4879\n",
      "Iter-55050, train loss-1.8069, acc-0.4800, valid loss-1.8331, acc-0.4924, test loss-1.8340, acc-0.4879\n",
      "Iter-55060, train loss-1.7853, acc-0.5000, valid loss-1.8331, acc-0.4922, test loss-1.8339, acc-0.4878\n",
      "Iter-55070, train loss-1.7721, acc-0.5800, valid loss-1.8330, acc-0.4924, test loss-1.8339, acc-0.4878\n",
      "Iter-55080, train loss-1.8644, acc-0.4400, valid loss-1.8330, acc-0.4924, test loss-1.8338, acc-0.4878\n",
      "Iter-55090, train loss-1.8223, acc-0.5600, valid loss-1.8329, acc-0.4924, test loss-1.8338, acc-0.4878\n",
      "Iter-55100, train loss-1.7759, acc-0.5200, valid loss-1.8329, acc-0.4926, test loss-1.8337, acc-0.4879\n",
      "Iter-55110, train loss-1.8339, acc-0.5800, valid loss-1.8328, acc-0.4930, test loss-1.8337, acc-0.4879\n",
      "Iter-55120, train loss-1.7689, acc-0.5000, valid loss-1.8328, acc-0.4928, test loss-1.8336, acc-0.4879\n",
      "Iter-55130, train loss-1.8262, acc-0.5200, valid loss-1.8327, acc-0.4930, test loss-1.8336, acc-0.4881\n",
      "Iter-55140, train loss-1.7968, acc-0.4800, valid loss-1.8327, acc-0.4928, test loss-1.8335, acc-0.4879\n",
      "Iter-55150, train loss-1.9305, acc-0.4800, valid loss-1.8326, acc-0.4928, test loss-1.8335, acc-0.4880\n",
      "Iter-55160, train loss-1.8356, acc-0.4200, valid loss-1.8326, acc-0.4928, test loss-1.8334, acc-0.4880\n",
      "Iter-55170, train loss-1.8068, acc-0.5800, valid loss-1.8325, acc-0.4928, test loss-1.8333, acc-0.4881\n",
      "Iter-55180, train loss-1.8815, acc-0.4000, valid loss-1.8325, acc-0.4928, test loss-1.8333, acc-0.4879\n",
      "Iter-55190, train loss-1.8514, acc-0.4800, valid loss-1.8324, acc-0.4928, test loss-1.8332, acc-0.4879\n",
      "Iter-55200, train loss-1.8548, acc-0.4200, valid loss-1.8323, acc-0.4928, test loss-1.8332, acc-0.4881\n",
      "Iter-55210, train loss-1.8449, acc-0.4600, valid loss-1.8323, acc-0.4928, test loss-1.8331, acc-0.4880\n",
      "Iter-55220, train loss-1.8447, acc-0.4800, valid loss-1.8322, acc-0.4926, test loss-1.8331, acc-0.4881\n",
      "Iter-55230, train loss-1.8256, acc-0.5400, valid loss-1.8322, acc-0.4926, test loss-1.8330, acc-0.4881\n",
      "Iter-55240, train loss-1.9014, acc-0.3200, valid loss-1.8321, acc-0.4926, test loss-1.8330, acc-0.4880\n",
      "Iter-55250, train loss-1.8917, acc-0.5200, valid loss-1.8321, acc-0.4926, test loss-1.8329, acc-0.4882\n",
      "Iter-55260, train loss-1.8482, acc-0.5400, valid loss-1.8320, acc-0.4926, test loss-1.8329, acc-0.4882\n",
      "Iter-55270, train loss-1.8275, acc-0.5000, valid loss-1.8320, acc-0.4928, test loss-1.8328, acc-0.4881\n",
      "Iter-55280, train loss-1.7773, acc-0.5000, valid loss-1.8319, acc-0.4928, test loss-1.8328, acc-0.4881\n",
      "Iter-55290, train loss-1.7561, acc-0.6200, valid loss-1.8319, acc-0.4932, test loss-1.8327, acc-0.4882\n",
      "Iter-55300, train loss-1.8292, acc-0.5000, valid loss-1.8318, acc-0.4930, test loss-1.8327, acc-0.4882\n",
      "Iter-55310, train loss-1.9174, acc-0.3800, valid loss-1.8318, acc-0.4932, test loss-1.8326, acc-0.4883\n",
      "Iter-55320, train loss-1.7532, acc-0.5600, valid loss-1.8317, acc-0.4928, test loss-1.8325, acc-0.4884\n",
      "Iter-55330, train loss-1.7847, acc-0.5200, valid loss-1.8316, acc-0.4930, test loss-1.8325, acc-0.4884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-55340, train loss-1.7892, acc-0.5200, valid loss-1.8316, acc-0.4928, test loss-1.8324, acc-0.4885\n",
      "Iter-55350, train loss-1.9074, acc-0.4400, valid loss-1.8315, acc-0.4930, test loss-1.8324, acc-0.4884\n",
      "Iter-55360, train loss-1.8495, acc-0.4400, valid loss-1.8315, acc-0.4930, test loss-1.8323, acc-0.4881\n",
      "Iter-55370, train loss-1.9684, acc-0.4000, valid loss-1.8314, acc-0.4930, test loss-1.8323, acc-0.4882\n",
      "Iter-55380, train loss-1.9530, acc-0.4400, valid loss-1.8314, acc-0.4928, test loss-1.8322, acc-0.4881\n",
      "Iter-55390, train loss-1.7966, acc-0.3800, valid loss-1.8313, acc-0.4930, test loss-1.8322, acc-0.4883\n",
      "Iter-55400, train loss-1.8226, acc-0.4200, valid loss-1.8313, acc-0.4930, test loss-1.8321, acc-0.4882\n",
      "Iter-55410, train loss-1.7994, acc-0.5600, valid loss-1.8312, acc-0.4928, test loss-1.8321, acc-0.4881\n",
      "Iter-55420, train loss-1.8751, acc-0.4000, valid loss-1.8312, acc-0.4928, test loss-1.8320, acc-0.4881\n",
      "Iter-55430, train loss-1.7749, acc-0.5200, valid loss-1.8311, acc-0.4930, test loss-1.8320, acc-0.4882\n",
      "Iter-55440, train loss-1.8425, acc-0.4200, valid loss-1.8311, acc-0.4930, test loss-1.8319, acc-0.4881\n",
      "Iter-55450, train loss-1.8203, acc-0.4400, valid loss-1.8310, acc-0.4930, test loss-1.8319, acc-0.4884\n",
      "Iter-55460, train loss-1.8923, acc-0.4400, valid loss-1.8310, acc-0.4932, test loss-1.8318, acc-0.4884\n",
      "Iter-55470, train loss-1.8437, acc-0.5000, valid loss-1.8309, acc-0.4932, test loss-1.8318, acc-0.4883\n",
      "Iter-55480, train loss-1.8218, acc-0.5000, valid loss-1.8309, acc-0.4934, test loss-1.8317, acc-0.4883\n",
      "Iter-55490, train loss-1.8169, acc-0.5600, valid loss-1.8308, acc-0.4934, test loss-1.8317, acc-0.4885\n",
      "Iter-55500, train loss-1.8047, acc-0.5600, valid loss-1.8308, acc-0.4934, test loss-1.8316, acc-0.4881\n",
      "Iter-55510, train loss-1.8223, acc-0.5000, valid loss-1.8307, acc-0.4934, test loss-1.8316, acc-0.4883\n",
      "Iter-55520, train loss-1.8081, acc-0.5400, valid loss-1.8306, acc-0.4934, test loss-1.8315, acc-0.4884\n",
      "Iter-55530, train loss-1.8966, acc-0.4400, valid loss-1.8306, acc-0.4934, test loss-1.8315, acc-0.4883\n",
      "Iter-55540, train loss-1.8616, acc-0.4400, valid loss-1.8305, acc-0.4932, test loss-1.8314, acc-0.4883\n",
      "Iter-55550, train loss-1.8150, acc-0.5000, valid loss-1.8305, acc-0.4936, test loss-1.8313, acc-0.4883\n",
      "Iter-55560, train loss-1.8347, acc-0.5800, valid loss-1.8304, acc-0.4936, test loss-1.8313, acc-0.4883\n",
      "Iter-55570, train loss-1.8787, acc-0.4800, valid loss-1.8304, acc-0.4936, test loss-1.8312, acc-0.4884\n",
      "Iter-55580, train loss-1.8020, acc-0.5000, valid loss-1.8303, acc-0.4936, test loss-1.8312, acc-0.4884\n",
      "Iter-55590, train loss-1.8327, acc-0.3800, valid loss-1.8303, acc-0.4934, test loss-1.8311, acc-0.4883\n",
      "Iter-55600, train loss-1.8631, acc-0.4400, valid loss-1.8302, acc-0.4936, test loss-1.8311, acc-0.4885\n",
      "Iter-55610, train loss-1.9153, acc-0.3400, valid loss-1.8302, acc-0.4938, test loss-1.8310, acc-0.4884\n",
      "Iter-55620, train loss-1.7528, acc-0.6000, valid loss-1.8301, acc-0.4936, test loss-1.8310, acc-0.4884\n",
      "Iter-55630, train loss-1.9046, acc-0.4600, valid loss-1.8301, acc-0.4936, test loss-1.8309, acc-0.4884\n",
      "Iter-55640, train loss-1.8699, acc-0.4600, valid loss-1.8300, acc-0.4936, test loss-1.8309, acc-0.4884\n",
      "Iter-55650, train loss-1.8350, acc-0.5000, valid loss-1.8300, acc-0.4932, test loss-1.8308, acc-0.4884\n",
      "Iter-55660, train loss-1.8198, acc-0.4600, valid loss-1.8299, acc-0.4932, test loss-1.8308, acc-0.4884\n",
      "Iter-55670, train loss-1.7540, acc-0.4800, valid loss-1.8299, acc-0.4930, test loss-1.8307, acc-0.4885\n",
      "Iter-55680, train loss-1.8575, acc-0.4200, valid loss-1.8298, acc-0.4932, test loss-1.8307, acc-0.4883\n",
      "Iter-55690, train loss-1.8612, acc-0.4400, valid loss-1.8298, acc-0.4942, test loss-1.8306, acc-0.4883\n",
      "Iter-55700, train loss-1.7766, acc-0.4600, valid loss-1.8297, acc-0.4942, test loss-1.8306, acc-0.4885\n",
      "Iter-55710, train loss-1.8196, acc-0.4600, valid loss-1.8297, acc-0.4942, test loss-1.8305, acc-0.4886\n",
      "Iter-55720, train loss-1.8586, acc-0.4800, valid loss-1.8296, acc-0.4942, test loss-1.8305, acc-0.4886\n",
      "Iter-55730, train loss-1.7683, acc-0.6200, valid loss-1.8296, acc-0.4940, test loss-1.8304, acc-0.4884\n",
      "Iter-55740, train loss-1.8098, acc-0.4400, valid loss-1.8295, acc-0.4942, test loss-1.8304, acc-0.4887\n",
      "Iter-55750, train loss-1.8514, acc-0.4800, valid loss-1.8294, acc-0.4940, test loss-1.8303, acc-0.4887\n",
      "Iter-55760, train loss-1.8482, acc-0.4400, valid loss-1.8294, acc-0.4940, test loss-1.8303, acc-0.4887\n",
      "Iter-55770, train loss-1.8329, acc-0.5200, valid loss-1.8293, acc-0.4940, test loss-1.8302, acc-0.4886\n",
      "Iter-55780, train loss-1.8240, acc-0.3600, valid loss-1.8293, acc-0.4940, test loss-1.8302, acc-0.4888\n",
      "Iter-55790, train loss-1.9130, acc-0.4000, valid loss-1.8292, acc-0.4942, test loss-1.8301, acc-0.4887\n",
      "Iter-55800, train loss-1.7709, acc-0.6200, valid loss-1.8292, acc-0.4942, test loss-1.8301, acc-0.4886\n",
      "Iter-55810, train loss-1.7836, acc-0.4800, valid loss-1.8291, acc-0.4940, test loss-1.8300, acc-0.4886\n",
      "Iter-55820, train loss-1.7415, acc-0.6000, valid loss-1.8291, acc-0.4942, test loss-1.8300, acc-0.4887\n",
      "Iter-55830, train loss-1.8276, acc-0.4800, valid loss-1.8290, acc-0.4942, test loss-1.8299, acc-0.4888\n",
      "Iter-55840, train loss-1.8133, acc-0.5400, valid loss-1.8290, acc-0.4942, test loss-1.8298, acc-0.4889\n",
      "Iter-55850, train loss-1.8932, acc-0.4200, valid loss-1.8289, acc-0.4940, test loss-1.8298, acc-0.4888\n",
      "Iter-55860, train loss-1.9381, acc-0.3800, valid loss-1.8289, acc-0.4940, test loss-1.8297, acc-0.4889\n",
      "Iter-55870, train loss-1.8884, acc-0.4800, valid loss-1.8288, acc-0.4940, test loss-1.8297, acc-0.4889\n",
      "Iter-55880, train loss-1.8452, acc-0.4600, valid loss-1.8288, acc-0.4942, test loss-1.8296, acc-0.4889\n",
      "Iter-55890, train loss-1.8845, acc-0.4400, valid loss-1.8287, acc-0.4942, test loss-1.8296, acc-0.4889\n",
      "Iter-55900, train loss-1.8017, acc-0.4600, valid loss-1.8287, acc-0.4942, test loss-1.8295, acc-0.4889\n",
      "Iter-55910, train loss-1.8668, acc-0.4400, valid loss-1.8286, acc-0.4942, test loss-1.8295, acc-0.4889\n",
      "Iter-55920, train loss-1.7524, acc-0.6400, valid loss-1.8286, acc-0.4942, test loss-1.8294, acc-0.4889\n",
      "Iter-55930, train loss-1.9545, acc-0.3400, valid loss-1.8285, acc-0.4942, test loss-1.8294, acc-0.4889\n",
      "Iter-55940, train loss-1.7676, acc-0.6400, valid loss-1.8284, acc-0.4942, test loss-1.8293, acc-0.4889\n",
      "Iter-55950, train loss-1.8435, acc-0.4800, valid loss-1.8284, acc-0.4944, test loss-1.8293, acc-0.4889\n",
      "Iter-55960, train loss-1.8831, acc-0.4200, valid loss-1.8283, acc-0.4944, test loss-1.8292, acc-0.4889\n",
      "Iter-55970, train loss-1.8416, acc-0.4400, valid loss-1.8283, acc-0.4944, test loss-1.8292, acc-0.4889\n",
      "Iter-55980, train loss-1.8862, acc-0.5800, valid loss-1.8282, acc-0.4944, test loss-1.8291, acc-0.4886\n",
      "Iter-55990, train loss-1.8525, acc-0.4600, valid loss-1.8282, acc-0.4944, test loss-1.8291, acc-0.4887\n",
      "Iter-56000, train loss-1.8448, acc-0.4800, valid loss-1.8281, acc-0.4944, test loss-1.8290, acc-0.4887\n",
      "Iter-56010, train loss-1.8498, acc-0.5000, valid loss-1.8281, acc-0.4944, test loss-1.8290, acc-0.4888\n",
      "Iter-56020, train loss-1.9140, acc-0.3800, valid loss-1.8280, acc-0.4944, test loss-1.8289, acc-0.4887\n",
      "Iter-56030, train loss-1.8577, acc-0.3800, valid loss-1.8280, acc-0.4944, test loss-1.8288, acc-0.4888\n",
      "Iter-56040, train loss-1.7854, acc-0.5800, valid loss-1.8279, acc-0.4946, test loss-1.8288, acc-0.4887\n",
      "Iter-56050, train loss-1.9608, acc-0.2800, valid loss-1.8279, acc-0.4946, test loss-1.8287, acc-0.4889\n",
      "Iter-56060, train loss-1.7885, acc-0.4600, valid loss-1.8278, acc-0.4946, test loss-1.8287, acc-0.4887\n",
      "Iter-56070, train loss-1.7683, acc-0.5600, valid loss-1.8278, acc-0.4946, test loss-1.8286, acc-0.4887\n",
      "Iter-56080, train loss-1.8609, acc-0.4600, valid loss-1.8277, acc-0.4946, test loss-1.8286, acc-0.4887\n",
      "Iter-56090, train loss-1.8170, acc-0.4800, valid loss-1.8277, acc-0.4946, test loss-1.8285, acc-0.4888\n",
      "Iter-56100, train loss-1.8474, acc-0.5000, valid loss-1.8276, acc-0.4944, test loss-1.8285, acc-0.4890\n",
      "Iter-56110, train loss-1.8767, acc-0.4000, valid loss-1.8276, acc-0.4944, test loss-1.8284, acc-0.4891\n",
      "Iter-56120, train loss-1.7955, acc-0.5400, valid loss-1.8275, acc-0.4946, test loss-1.8284, acc-0.4890\n",
      "Iter-56130, train loss-1.7960, acc-0.5200, valid loss-1.8275, acc-0.4946, test loss-1.8283, acc-0.4893\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56140, train loss-1.8474, acc-0.4400, valid loss-1.8274, acc-0.4946, test loss-1.8283, acc-0.4892\n",
      "Iter-56150, train loss-1.7934, acc-0.5000, valid loss-1.8274, acc-0.4948, test loss-1.8282, acc-0.4892\n",
      "Iter-56160, train loss-1.7942, acc-0.4800, valid loss-1.8273, acc-0.4948, test loss-1.8282, acc-0.4892\n",
      "Iter-56170, train loss-1.8251, acc-0.4000, valid loss-1.8272, acc-0.4948, test loss-1.8281, acc-0.4891\n",
      "Iter-56180, train loss-1.8094, acc-0.5000, valid loss-1.8272, acc-0.4948, test loss-1.8281, acc-0.4892\n",
      "Iter-56190, train loss-1.8778, acc-0.4800, valid loss-1.8271, acc-0.4948, test loss-1.8280, acc-0.4891\n",
      "Iter-56200, train loss-1.8233, acc-0.4000, valid loss-1.8271, acc-0.4948, test loss-1.8280, acc-0.4890\n",
      "Iter-56210, train loss-1.8756, acc-0.3800, valid loss-1.8270, acc-0.4948, test loss-1.8279, acc-0.4893\n",
      "Iter-56220, train loss-1.7717, acc-0.5600, valid loss-1.8270, acc-0.4948, test loss-1.8279, acc-0.4891\n",
      "Iter-56230, train loss-1.9308, acc-0.3200, valid loss-1.8269, acc-0.4948, test loss-1.8278, acc-0.4893\n",
      "Iter-56240, train loss-1.7458, acc-0.5000, valid loss-1.8269, acc-0.4948, test loss-1.8278, acc-0.4896\n",
      "Iter-56250, train loss-1.8220, acc-0.4800, valid loss-1.8268, acc-0.4946, test loss-1.8277, acc-0.4895\n",
      "Iter-56260, train loss-1.8510, acc-0.4000, valid loss-1.8268, acc-0.4946, test loss-1.8276, acc-0.4894\n",
      "Iter-56270, train loss-1.8025, acc-0.4400, valid loss-1.8267, acc-0.4948, test loss-1.8276, acc-0.4895\n",
      "Iter-56280, train loss-1.8283, acc-0.4200, valid loss-1.8267, acc-0.4946, test loss-1.8275, acc-0.4895\n",
      "Iter-56290, train loss-1.8019, acc-0.5800, valid loss-1.8266, acc-0.4948, test loss-1.8275, acc-0.4894\n",
      "Iter-56300, train loss-1.9032, acc-0.4000, valid loss-1.8266, acc-0.4948, test loss-1.8274, acc-0.4896\n",
      "Iter-56310, train loss-1.7732, acc-0.4600, valid loss-1.8265, acc-0.4948, test loss-1.8274, acc-0.4896\n",
      "Iter-56320, train loss-1.9267, acc-0.3600, valid loss-1.8265, acc-0.4948, test loss-1.8273, acc-0.4895\n",
      "Iter-56330, train loss-1.8769, acc-0.4600, valid loss-1.8264, acc-0.4948, test loss-1.8273, acc-0.4895\n",
      "Iter-56340, train loss-1.8529, acc-0.4600, valid loss-1.8264, acc-0.4948, test loss-1.8272, acc-0.4894\n",
      "Iter-56350, train loss-1.7739, acc-0.6000, valid loss-1.8263, acc-0.4948, test loss-1.8272, acc-0.4894\n",
      "Iter-56360, train loss-1.8633, acc-0.4400, valid loss-1.8263, acc-0.4948, test loss-1.8271, acc-0.4894\n",
      "Iter-56370, train loss-1.8579, acc-0.4400, valid loss-1.8262, acc-0.4948, test loss-1.8271, acc-0.4896\n",
      "Iter-56380, train loss-1.7250, acc-0.5200, valid loss-1.8261, acc-0.4948, test loss-1.8270, acc-0.4896\n",
      "Iter-56390, train loss-1.8585, acc-0.4600, valid loss-1.8261, acc-0.4948, test loss-1.8270, acc-0.4896\n",
      "Iter-56400, train loss-1.8801, acc-0.4400, valid loss-1.8260, acc-0.4948, test loss-1.8269, acc-0.4895\n",
      "Iter-56410, train loss-1.8018, acc-0.5200, valid loss-1.8260, acc-0.4948, test loss-1.8269, acc-0.4897\n",
      "Iter-56420, train loss-1.8410, acc-0.4400, valid loss-1.8259, acc-0.4948, test loss-1.8268, acc-0.4898\n",
      "Iter-56430, train loss-1.8541, acc-0.5000, valid loss-1.8259, acc-0.4948, test loss-1.8268, acc-0.4898\n",
      "Iter-56440, train loss-1.7827, acc-0.4200, valid loss-1.8258, acc-0.4948, test loss-1.8267, acc-0.4897\n",
      "Iter-56450, train loss-1.8108, acc-0.4600, valid loss-1.8258, acc-0.4950, test loss-1.8266, acc-0.4898\n",
      "Iter-56460, train loss-1.8840, acc-0.5400, valid loss-1.8257, acc-0.4950, test loss-1.8266, acc-0.4898\n",
      "Iter-56470, train loss-1.8850, acc-0.4800, valid loss-1.8257, acc-0.4950, test loss-1.8265, acc-0.4898\n",
      "Iter-56480, train loss-1.7892, acc-0.5000, valid loss-1.8256, acc-0.4950, test loss-1.8265, acc-0.4897\n",
      "Iter-56490, train loss-1.7438, acc-0.5800, valid loss-1.8256, acc-0.4952, test loss-1.8264, acc-0.4898\n",
      "Iter-56500, train loss-1.8707, acc-0.4800, valid loss-1.8255, acc-0.4952, test loss-1.8264, acc-0.4898\n",
      "Iter-56510, train loss-1.8078, acc-0.4400, valid loss-1.8255, acc-0.4952, test loss-1.8263, acc-0.4900\n",
      "Iter-56520, train loss-1.9321, acc-0.4000, valid loss-1.8254, acc-0.4948, test loss-1.8263, acc-0.4900\n",
      "Iter-56530, train loss-1.8435, acc-0.4400, valid loss-1.8254, acc-0.4948, test loss-1.8262, acc-0.4901\n",
      "Iter-56540, train loss-1.7216, acc-0.6200, valid loss-1.8253, acc-0.4948, test loss-1.8262, acc-0.4901\n",
      "Iter-56550, train loss-1.8631, acc-0.4200, valid loss-1.8253, acc-0.4950, test loss-1.8261, acc-0.4899\n",
      "Iter-56560, train loss-1.7905, acc-0.5000, valid loss-1.8252, acc-0.4950, test loss-1.8261, acc-0.4899\n",
      "Iter-56570, train loss-1.8437, acc-0.4800, valid loss-1.8251, acc-0.4950, test loss-1.8260, acc-0.4899\n",
      "Iter-56580, train loss-1.9000, acc-0.4000, valid loss-1.8251, acc-0.4948, test loss-1.8260, acc-0.4897\n",
      "Iter-56590, train loss-1.8776, acc-0.4400, valid loss-1.8250, acc-0.4948, test loss-1.8259, acc-0.4897\n",
      "Iter-56600, train loss-1.9161, acc-0.4000, valid loss-1.8250, acc-0.4948, test loss-1.8259, acc-0.4895\n",
      "Iter-56610, train loss-1.7816, acc-0.5200, valid loss-1.8249, acc-0.4948, test loss-1.8258, acc-0.4896\n",
      "Iter-56620, train loss-1.8696, acc-0.4200, valid loss-1.8249, acc-0.4950, test loss-1.8258, acc-0.4898\n",
      "Iter-56630, train loss-1.8661, acc-0.4600, valid loss-1.8248, acc-0.4948, test loss-1.8257, acc-0.4899\n",
      "Iter-56640, train loss-1.8617, acc-0.4800, valid loss-1.8248, acc-0.4948, test loss-1.8257, acc-0.4900\n",
      "Iter-56650, train loss-1.8675, acc-0.4600, valid loss-1.8247, acc-0.4950, test loss-1.8256, acc-0.4899\n",
      "Iter-56660, train loss-1.8855, acc-0.5000, valid loss-1.8247, acc-0.4950, test loss-1.8256, acc-0.4899\n",
      "Iter-56670, train loss-1.8919, acc-0.4800, valid loss-1.8246, acc-0.4948, test loss-1.8255, acc-0.4899\n",
      "Iter-56680, train loss-1.7861, acc-0.5400, valid loss-1.8246, acc-0.4948, test loss-1.8254, acc-0.4900\n",
      "Iter-56690, train loss-1.9573, acc-0.4000, valid loss-1.8245, acc-0.4948, test loss-1.8254, acc-0.4900\n",
      "Iter-56700, train loss-1.8411, acc-0.5200, valid loss-1.8245, acc-0.4950, test loss-1.8253, acc-0.4900\n",
      "Iter-56710, train loss-1.8805, acc-0.4400, valid loss-1.8244, acc-0.4950, test loss-1.8253, acc-0.4900\n",
      "Iter-56720, train loss-1.8400, acc-0.4800, valid loss-1.8244, acc-0.4952, test loss-1.8252, acc-0.4900\n",
      "Iter-56730, train loss-1.7740, acc-0.5400, valid loss-1.8243, acc-0.4950, test loss-1.8252, acc-0.4901\n",
      "Iter-56740, train loss-1.8214, acc-0.5200, valid loss-1.8243, acc-0.4950, test loss-1.8251, acc-0.4901\n",
      "Iter-56750, train loss-1.9162, acc-0.4400, valid loss-1.8242, acc-0.4948, test loss-1.8251, acc-0.4900\n",
      "Iter-56760, train loss-1.7819, acc-0.5400, valid loss-1.8242, acc-0.4950, test loss-1.8250, acc-0.4901\n",
      "Iter-56770, train loss-1.8227, acc-0.4800, valid loss-1.8241, acc-0.4952, test loss-1.8250, acc-0.4900\n",
      "Iter-56780, train loss-1.7848, acc-0.5000, valid loss-1.8241, acc-0.4952, test loss-1.8249, acc-0.4902\n",
      "Iter-56790, train loss-1.8384, acc-0.5600, valid loss-1.8240, acc-0.4950, test loss-1.8249, acc-0.4902\n",
      "Iter-56800, train loss-1.9302, acc-0.3600, valid loss-1.8240, acc-0.4952, test loss-1.8248, acc-0.4901\n",
      "Iter-56810, train loss-1.8289, acc-0.4600, valid loss-1.8239, acc-0.4952, test loss-1.8248, acc-0.4901\n",
      "Iter-56820, train loss-1.8355, acc-0.4600, valid loss-1.8239, acc-0.4952, test loss-1.8247, acc-0.4902\n",
      "Iter-56830, train loss-1.9793, acc-0.4800, valid loss-1.8238, acc-0.4952, test loss-1.8247, acc-0.4902\n",
      "Iter-56840, train loss-1.8088, acc-0.5600, valid loss-1.8238, acc-0.4952, test loss-1.8246, acc-0.4901\n",
      "Iter-56850, train loss-1.9120, acc-0.4000, valid loss-1.8237, acc-0.4954, test loss-1.8246, acc-0.4902\n",
      "Iter-56860, train loss-1.8308, acc-0.4800, valid loss-1.8237, acc-0.4952, test loss-1.8245, acc-0.4900\n",
      "Iter-56870, train loss-1.8200, acc-0.5000, valid loss-1.8236, acc-0.4948, test loss-1.8245, acc-0.4902\n",
      "Iter-56880, train loss-1.8608, acc-0.5000, valid loss-1.8235, acc-0.4952, test loss-1.8244, acc-0.4902\n",
      "Iter-56890, train loss-1.8141, acc-0.5200, valid loss-1.8235, acc-0.4950, test loss-1.8244, acc-0.4900\n",
      "Iter-56900, train loss-1.8456, acc-0.4000, valid loss-1.8234, acc-0.4950, test loss-1.8243, acc-0.4901\n",
      "Iter-56910, train loss-1.7813, acc-0.5000, valid loss-1.8234, acc-0.4952, test loss-1.8242, acc-0.4901\n",
      "Iter-56920, train loss-1.8827, acc-0.4000, valid loss-1.8233, acc-0.4954, test loss-1.8242, acc-0.4900\n",
      "Iter-56930, train loss-1.8114, acc-0.4400, valid loss-1.8233, acc-0.4954, test loss-1.8241, acc-0.4900\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-56940, train loss-1.8542, acc-0.4200, valid loss-1.8232, acc-0.4954, test loss-1.8241, acc-0.4900\n",
      "Iter-56950, train loss-1.7942, acc-0.5200, valid loss-1.8232, acc-0.4954, test loss-1.8240, acc-0.4900\n",
      "Iter-56960, train loss-1.8212, acc-0.5400, valid loss-1.8231, acc-0.4956, test loss-1.8240, acc-0.4901\n",
      "Iter-56970, train loss-1.8378, acc-0.4400, valid loss-1.8231, acc-0.4952, test loss-1.8239, acc-0.4901\n",
      "Iter-56980, train loss-1.7396, acc-0.5400, valid loss-1.8230, acc-0.4954, test loss-1.8239, acc-0.4901\n",
      "Iter-56990, train loss-1.9113, acc-0.4200, valid loss-1.8230, acc-0.4952, test loss-1.8238, acc-0.4903\n",
      "Iter-57000, train loss-1.8605, acc-0.4800, valid loss-1.8229, acc-0.4954, test loss-1.8238, acc-0.4903\n",
      "Iter-57010, train loss-1.9910, acc-0.3800, valid loss-1.8229, acc-0.4956, test loss-1.8237, acc-0.4904\n",
      "Iter-57020, train loss-1.8936, acc-0.3800, valid loss-1.8228, acc-0.4954, test loss-1.8237, acc-0.4904\n",
      "Iter-57030, train loss-1.9280, acc-0.4400, valid loss-1.8228, acc-0.4954, test loss-1.8236, acc-0.4904\n",
      "Iter-57040, train loss-1.6975, acc-0.7000, valid loss-1.8227, acc-0.4954, test loss-1.8236, acc-0.4904\n",
      "Iter-57050, train loss-1.8171, acc-0.5400, valid loss-1.8227, acc-0.4954, test loss-1.8235, acc-0.4904\n",
      "Iter-57060, train loss-1.8457, acc-0.4600, valid loss-1.8226, acc-0.4954, test loss-1.8235, acc-0.4904\n",
      "Iter-57070, train loss-1.8864, acc-0.4800, valid loss-1.8226, acc-0.4958, test loss-1.8234, acc-0.4904\n",
      "Iter-57080, train loss-1.8814, acc-0.3800, valid loss-1.8225, acc-0.4956, test loss-1.8234, acc-0.4904\n",
      "Iter-57090, train loss-1.8491, acc-0.4400, valid loss-1.8225, acc-0.4956, test loss-1.8233, acc-0.4901\n",
      "Iter-57100, train loss-1.8200, acc-0.4800, valid loss-1.8224, acc-0.4956, test loss-1.8233, acc-0.4901\n",
      "Iter-57110, train loss-1.8322, acc-0.5000, valid loss-1.8224, acc-0.4956, test loss-1.8232, acc-0.4901\n",
      "Iter-57120, train loss-1.8561, acc-0.5200, valid loss-1.8223, acc-0.4956, test loss-1.8232, acc-0.4900\n",
      "Iter-57130, train loss-1.8360, acc-0.4400, valid loss-1.8222, acc-0.4956, test loss-1.8231, acc-0.4900\n",
      "Iter-57140, train loss-1.8967, acc-0.4800, valid loss-1.8222, acc-0.4954, test loss-1.8231, acc-0.4900\n",
      "Iter-57150, train loss-1.8280, acc-0.5200, valid loss-1.8221, acc-0.4954, test loss-1.8230, acc-0.4901\n",
      "Iter-57160, train loss-1.8163, acc-0.5400, valid loss-1.8221, acc-0.4954, test loss-1.8230, acc-0.4900\n",
      "Iter-57170, train loss-1.9122, acc-0.4800, valid loss-1.8220, acc-0.4954, test loss-1.8229, acc-0.4899\n",
      "Iter-57180, train loss-1.8522, acc-0.5400, valid loss-1.8220, acc-0.4954, test loss-1.8229, acc-0.4899\n",
      "Iter-57190, train loss-1.9110, acc-0.3400, valid loss-1.8219, acc-0.4954, test loss-1.8228, acc-0.4901\n",
      "Iter-57200, train loss-1.8038, acc-0.4800, valid loss-1.8219, acc-0.4954, test loss-1.8227, acc-0.4900\n",
      "Iter-57210, train loss-1.7702, acc-0.5600, valid loss-1.8218, acc-0.4954, test loss-1.8227, acc-0.4900\n",
      "Iter-57220, train loss-1.8361, acc-0.3800, valid loss-1.8218, acc-0.4952, test loss-1.8226, acc-0.4900\n",
      "Iter-57230, train loss-1.8067, acc-0.5800, valid loss-1.8217, acc-0.4952, test loss-1.8226, acc-0.4902\n",
      "Iter-57240, train loss-1.8147, acc-0.6000, valid loss-1.8217, acc-0.4954, test loss-1.8225, acc-0.4903\n",
      "Iter-57250, train loss-1.9148, acc-0.4000, valid loss-1.8216, acc-0.4952, test loss-1.8225, acc-0.4903\n",
      "Iter-57260, train loss-1.8284, acc-0.4400, valid loss-1.8216, acc-0.4954, test loss-1.8224, acc-0.4903\n",
      "Iter-57270, train loss-1.8614, acc-0.4800, valid loss-1.8215, acc-0.4954, test loss-1.8224, acc-0.4903\n",
      "Iter-57280, train loss-1.9017, acc-0.3800, valid loss-1.8215, acc-0.4954, test loss-1.8223, acc-0.4903\n",
      "Iter-57290, train loss-1.8831, acc-0.4800, valid loss-1.8214, acc-0.4954, test loss-1.8223, acc-0.4902\n",
      "Iter-57300, train loss-1.7746, acc-0.5000, valid loss-1.8213, acc-0.4952, test loss-1.8222, acc-0.4902\n",
      "Iter-57310, train loss-1.7142, acc-0.6400, valid loss-1.8213, acc-0.4954, test loss-1.8222, acc-0.4903\n",
      "Iter-57320, train loss-1.8384, acc-0.4600, valid loss-1.8212, acc-0.4950, test loss-1.8221, acc-0.4902\n",
      "Iter-57330, train loss-1.8510, acc-0.5200, valid loss-1.8212, acc-0.4958, test loss-1.8221, acc-0.4902\n",
      "Iter-57340, train loss-1.8914, acc-0.4400, valid loss-1.8211, acc-0.4950, test loss-1.8220, acc-0.4902\n",
      "Iter-57350, train loss-1.8795, acc-0.4800, valid loss-1.8211, acc-0.4954, test loss-1.8220, acc-0.4903\n",
      "Iter-57360, train loss-1.8592, acc-0.4800, valid loss-1.8210, acc-0.4956, test loss-1.8219, acc-0.4903\n",
      "Iter-57370, train loss-1.8178, acc-0.5200, valid loss-1.8210, acc-0.4954, test loss-1.8219, acc-0.4903\n",
      "Iter-57380, train loss-1.8730, acc-0.5000, valid loss-1.8209, acc-0.4956, test loss-1.8218, acc-0.4903\n",
      "Iter-57390, train loss-1.8480, acc-0.4000, valid loss-1.8209, acc-0.4958, test loss-1.8218, acc-0.4903\n",
      "Iter-57400, train loss-1.8917, acc-0.3600, valid loss-1.8208, acc-0.4958, test loss-1.8217, acc-0.4903\n",
      "Iter-57410, train loss-1.9217, acc-0.5000, valid loss-1.8208, acc-0.4954, test loss-1.8217, acc-0.4903\n",
      "Iter-57420, train loss-1.8494, acc-0.5200, valid loss-1.8207, acc-0.4954, test loss-1.8216, acc-0.4903\n",
      "Iter-57430, train loss-1.9175, acc-0.4600, valid loss-1.8207, acc-0.4956, test loss-1.8216, acc-0.4904\n",
      "Iter-57440, train loss-1.7961, acc-0.4400, valid loss-1.8206, acc-0.4956, test loss-1.8215, acc-0.4904\n",
      "Iter-57450, train loss-1.8139, acc-0.5600, valid loss-1.8206, acc-0.4956, test loss-1.8215, acc-0.4904\n",
      "Iter-57460, train loss-1.8164, acc-0.4600, valid loss-1.8205, acc-0.4956, test loss-1.8214, acc-0.4903\n",
      "Iter-57470, train loss-1.7902, acc-0.5000, valid loss-1.8205, acc-0.4958, test loss-1.8214, acc-0.4903\n",
      "Iter-57480, train loss-1.7565, acc-0.5400, valid loss-1.8204, acc-0.4958, test loss-1.8213, acc-0.4903\n",
      "Iter-57490, train loss-1.8294, acc-0.5600, valid loss-1.8203, acc-0.4958, test loss-1.8213, acc-0.4903\n",
      "Iter-57500, train loss-1.7992, acc-0.5000, valid loss-1.8203, acc-0.4958, test loss-1.8212, acc-0.4904\n",
      "Iter-57510, train loss-1.7703, acc-0.5000, valid loss-1.8202, acc-0.4958, test loss-1.8212, acc-0.4904\n",
      "Iter-57520, train loss-1.8087, acc-0.4800, valid loss-1.8202, acc-0.4956, test loss-1.8211, acc-0.4903\n",
      "Iter-57530, train loss-1.8413, acc-0.4800, valid loss-1.8201, acc-0.4960, test loss-1.8210, acc-0.4904\n",
      "Iter-57540, train loss-1.7926, acc-0.5200, valid loss-1.8201, acc-0.4958, test loss-1.8210, acc-0.4904\n",
      "Iter-57550, train loss-1.8325, acc-0.5200, valid loss-1.8200, acc-0.4958, test loss-1.8209, acc-0.4905\n",
      "Iter-57560, train loss-1.8166, acc-0.4000, valid loss-1.8200, acc-0.4958, test loss-1.8209, acc-0.4905\n",
      "Iter-57570, train loss-1.9736, acc-0.3600, valid loss-1.8199, acc-0.4958, test loss-1.8208, acc-0.4906\n",
      "Iter-57580, train loss-1.8403, acc-0.4200, valid loss-1.8199, acc-0.4960, test loss-1.8208, acc-0.4907\n",
      "Iter-57590, train loss-1.8242, acc-0.4600, valid loss-1.8198, acc-0.4960, test loss-1.8207, acc-0.4904\n",
      "Iter-57600, train loss-1.8853, acc-0.3800, valid loss-1.8198, acc-0.4958, test loss-1.8207, acc-0.4905\n",
      "Iter-57610, train loss-1.8446, acc-0.4200, valid loss-1.8197, acc-0.4960, test loss-1.8206, acc-0.4904\n",
      "Iter-57620, train loss-1.7985, acc-0.5800, valid loss-1.8197, acc-0.4960, test loss-1.8206, acc-0.4904\n",
      "Iter-57630, train loss-1.9781, acc-0.3800, valid loss-1.8196, acc-0.4960, test loss-1.8205, acc-0.4904\n",
      "Iter-57640, train loss-2.0100, acc-0.3400, valid loss-1.8196, acc-0.4960, test loss-1.8205, acc-0.4906\n",
      "Iter-57650, train loss-1.7131, acc-0.5600, valid loss-1.8195, acc-0.4958, test loss-1.8204, acc-0.4907\n",
      "Iter-57660, train loss-1.8089, acc-0.4400, valid loss-1.8195, acc-0.4956, test loss-1.8204, acc-0.4905\n",
      "Iter-57670, train loss-1.7981, acc-0.5000, valid loss-1.8194, acc-0.4956, test loss-1.8203, acc-0.4907\n",
      "Iter-57680, train loss-1.8892, acc-0.4400, valid loss-1.8194, acc-0.4956, test loss-1.8203, acc-0.4903\n",
      "Iter-57690, train loss-1.7814, acc-0.5000, valid loss-1.8193, acc-0.4956, test loss-1.8202, acc-0.4905\n",
      "Iter-57700, train loss-1.9436, acc-0.4200, valid loss-1.8193, acc-0.4954, test loss-1.8202, acc-0.4905\n",
      "Iter-57710, train loss-1.8398, acc-0.4600, valid loss-1.8192, acc-0.4954, test loss-1.8201, acc-0.4905\n",
      "Iter-57720, train loss-1.9042, acc-0.4200, valid loss-1.8192, acc-0.4954, test loss-1.8201, acc-0.4905\n",
      "Iter-57730, train loss-1.8251, acc-0.5000, valid loss-1.8191, acc-0.4960, test loss-1.8200, acc-0.4907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-57740, train loss-1.7546, acc-0.6000, valid loss-1.8191, acc-0.4954, test loss-1.8200, acc-0.4907\n",
      "Iter-57750, train loss-1.8657, acc-0.3400, valid loss-1.8190, acc-0.4956, test loss-1.8199, acc-0.4907\n",
      "Iter-57760, train loss-1.8238, acc-0.5600, valid loss-1.8190, acc-0.4956, test loss-1.8199, acc-0.4907\n",
      "Iter-57770, train loss-1.7442, acc-0.5000, valid loss-1.8189, acc-0.4958, test loss-1.8198, acc-0.4907\n",
      "Iter-57780, train loss-1.8949, acc-0.4600, valid loss-1.8189, acc-0.4958, test loss-1.8198, acc-0.4908\n",
      "Iter-57790, train loss-1.8370, acc-0.5000, valid loss-1.8188, acc-0.4960, test loss-1.8197, acc-0.4906\n",
      "Iter-57800, train loss-1.9071, acc-0.4600, valid loss-1.8188, acc-0.4964, test loss-1.8197, acc-0.4908\n",
      "Iter-57810, train loss-1.8447, acc-0.4800, valid loss-1.8187, acc-0.4964, test loss-1.8196, acc-0.4908\n",
      "Iter-57820, train loss-1.7387, acc-0.5800, valid loss-1.8187, acc-0.4968, test loss-1.8196, acc-0.4907\n",
      "Iter-57830, train loss-1.7473, acc-0.5200, valid loss-1.8186, acc-0.4964, test loss-1.8195, acc-0.4905\n",
      "Iter-57840, train loss-1.8333, acc-0.5200, valid loss-1.8186, acc-0.4962, test loss-1.8195, acc-0.4905\n",
      "Iter-57850, train loss-1.8991, acc-0.4200, valid loss-1.8185, acc-0.4962, test loss-1.8194, acc-0.4904\n",
      "Iter-57860, train loss-1.8798, acc-0.4600, valid loss-1.8184, acc-0.4964, test loss-1.8194, acc-0.4906\n",
      "Iter-57870, train loss-1.8689, acc-0.3800, valid loss-1.8184, acc-0.4964, test loss-1.8193, acc-0.4906\n",
      "Iter-57880, train loss-1.9147, acc-0.3200, valid loss-1.8183, acc-0.4962, test loss-1.8193, acc-0.4906\n",
      "Iter-57890, train loss-1.8524, acc-0.4400, valid loss-1.8183, acc-0.4964, test loss-1.8192, acc-0.4907\n",
      "Iter-57900, train loss-1.9396, acc-0.3800, valid loss-1.8182, acc-0.4964, test loss-1.8191, acc-0.4907\n",
      "Iter-57910, train loss-1.8550, acc-0.4400, valid loss-1.8182, acc-0.4962, test loss-1.8191, acc-0.4907\n",
      "Iter-57920, train loss-1.7943, acc-0.4200, valid loss-1.8181, acc-0.4960, test loss-1.8190, acc-0.4907\n",
      "Iter-57930, train loss-1.7732, acc-0.5000, valid loss-1.8181, acc-0.4962, test loss-1.8190, acc-0.4907\n",
      "Iter-57940, train loss-1.7587, acc-0.6200, valid loss-1.8180, acc-0.4964, test loss-1.8189, acc-0.4908\n",
      "Iter-57950, train loss-1.8397, acc-0.4800, valid loss-1.8180, acc-0.4964, test loss-1.8189, acc-0.4906\n",
      "Iter-57960, train loss-1.8292, acc-0.4800, valid loss-1.8179, acc-0.4964, test loss-1.8188, acc-0.4906\n",
      "Iter-57970, train loss-1.7942, acc-0.4600, valid loss-1.8179, acc-0.4962, test loss-1.8188, acc-0.4907\n",
      "Iter-57980, train loss-1.7705, acc-0.4800, valid loss-1.8178, acc-0.4964, test loss-1.8187, acc-0.4906\n",
      "Iter-57990, train loss-1.8249, acc-0.4400, valid loss-1.8178, acc-0.4962, test loss-1.8187, acc-0.4908\n",
      "Iter-58000, train loss-1.7943, acc-0.6000, valid loss-1.8177, acc-0.4964, test loss-1.8186, acc-0.4906\n",
      "Iter-58010, train loss-1.8102, acc-0.3600, valid loss-1.8177, acc-0.4964, test loss-1.8186, acc-0.4907\n",
      "Iter-58020, train loss-1.8565, acc-0.4800, valid loss-1.8176, acc-0.4964, test loss-1.8185, acc-0.4906\n",
      "Iter-58030, train loss-1.7831, acc-0.5200, valid loss-1.8176, acc-0.4964, test loss-1.8185, acc-0.4906\n",
      "Iter-58040, train loss-1.8704, acc-0.4600, valid loss-1.8175, acc-0.4964, test loss-1.8184, acc-0.4906\n",
      "Iter-58050, train loss-1.7200, acc-0.5200, valid loss-1.8175, acc-0.4964, test loss-1.8184, acc-0.4907\n",
      "Iter-58060, train loss-1.8294, acc-0.5400, valid loss-1.8174, acc-0.4964, test loss-1.8183, acc-0.4907\n",
      "Iter-58070, train loss-1.8047, acc-0.5200, valid loss-1.8174, acc-0.4964, test loss-1.8183, acc-0.4907\n",
      "Iter-58080, train loss-1.8255, acc-0.5800, valid loss-1.8173, acc-0.4964, test loss-1.8182, acc-0.4907\n",
      "Iter-58090, train loss-1.8766, acc-0.5000, valid loss-1.8173, acc-0.4964, test loss-1.8182, acc-0.4906\n",
      "Iter-58100, train loss-1.8267, acc-0.5000, valid loss-1.8172, acc-0.4964, test loss-1.8181, acc-0.4905\n",
      "Iter-58110, train loss-1.8531, acc-0.3800, valid loss-1.8172, acc-0.4964, test loss-1.8181, acc-0.4906\n",
      "Iter-58120, train loss-1.8075, acc-0.4200, valid loss-1.8171, acc-0.4964, test loss-1.8180, acc-0.4906\n",
      "Iter-58130, train loss-1.6974, acc-0.4600, valid loss-1.8171, acc-0.4964, test loss-1.8180, acc-0.4906\n",
      "Iter-58140, train loss-1.8338, acc-0.4600, valid loss-1.8170, acc-0.4964, test loss-1.8179, acc-0.4907\n",
      "Iter-58150, train loss-1.9263, acc-0.4200, valid loss-1.8170, acc-0.4964, test loss-1.8179, acc-0.4907\n",
      "Iter-58160, train loss-1.8480, acc-0.5000, valid loss-1.8169, acc-0.4964, test loss-1.8178, acc-0.4908\n",
      "Iter-58170, train loss-1.8556, acc-0.4200, valid loss-1.8169, acc-0.4964, test loss-1.8178, acc-0.4908\n",
      "Iter-58180, train loss-1.8054, acc-0.4800, valid loss-1.8168, acc-0.4964, test loss-1.8177, acc-0.4908\n",
      "Iter-58190, train loss-1.9029, acc-0.4000, valid loss-1.8168, acc-0.4966, test loss-1.8177, acc-0.4908\n",
      "Iter-58200, train loss-1.8269, acc-0.5400, valid loss-1.8167, acc-0.4966, test loss-1.8176, acc-0.4910\n",
      "Iter-58210, train loss-1.9818, acc-0.3800, valid loss-1.8167, acc-0.4968, test loss-1.8176, acc-0.4910\n",
      "Iter-58220, train loss-1.7417, acc-0.5400, valid loss-1.8166, acc-0.4968, test loss-1.8175, acc-0.4910\n",
      "Iter-58230, train loss-1.8526, acc-0.5200, valid loss-1.8165, acc-0.4968, test loss-1.8175, acc-0.4910\n",
      "Iter-58240, train loss-1.9125, acc-0.4400, valid loss-1.8165, acc-0.4968, test loss-1.8174, acc-0.4910\n",
      "Iter-58250, train loss-1.8386, acc-0.5200, valid loss-1.8165, acc-0.4968, test loss-1.8174, acc-0.4910\n",
      "Iter-58260, train loss-1.8710, acc-0.4200, valid loss-1.8164, acc-0.4970, test loss-1.8173, acc-0.4911\n",
      "Iter-58270, train loss-1.9034, acc-0.4000, valid loss-1.8163, acc-0.4970, test loss-1.8173, acc-0.4911\n",
      "Iter-58280, train loss-1.8099, acc-0.5000, valid loss-1.8163, acc-0.4968, test loss-1.8172, acc-0.4911\n",
      "Iter-58290, train loss-1.8540, acc-0.4000, valid loss-1.8163, acc-0.4970, test loss-1.8172, acc-0.4910\n",
      "Iter-58300, train loss-1.8712, acc-0.4600, valid loss-1.8162, acc-0.4970, test loss-1.8171, acc-0.4909\n",
      "Iter-58310, train loss-1.7919, acc-0.4800, valid loss-1.8162, acc-0.4968, test loss-1.8171, acc-0.4911\n",
      "Iter-58320, train loss-1.7811, acc-0.5800, valid loss-1.8161, acc-0.4968, test loss-1.8170, acc-0.4909\n",
      "Iter-58330, train loss-1.7523, acc-0.5000, valid loss-1.8161, acc-0.4966, test loss-1.8170, acc-0.4911\n",
      "Iter-58340, train loss-1.8622, acc-0.2800, valid loss-1.8160, acc-0.4964, test loss-1.8169, acc-0.4910\n",
      "Iter-58350, train loss-1.8788, acc-0.4800, valid loss-1.8160, acc-0.4966, test loss-1.8169, acc-0.4913\n",
      "Iter-58360, train loss-1.8276, acc-0.4800, valid loss-1.8159, acc-0.4966, test loss-1.8168, acc-0.4912\n",
      "Iter-58370, train loss-1.9489, acc-0.3400, valid loss-1.8159, acc-0.4966, test loss-1.8168, acc-0.4914\n",
      "Iter-58380, train loss-1.9055, acc-0.5000, valid loss-1.8158, acc-0.4966, test loss-1.8167, acc-0.4913\n",
      "Iter-58390, train loss-1.9525, acc-0.3600, valid loss-1.8158, acc-0.4964, test loss-1.8167, acc-0.4913\n",
      "Iter-58400, train loss-1.7428, acc-0.5600, valid loss-1.8157, acc-0.4964, test loss-1.8166, acc-0.4913\n",
      "Iter-58410, train loss-1.9015, acc-0.4200, valid loss-1.8157, acc-0.4966, test loss-1.8166, acc-0.4913\n",
      "Iter-58420, train loss-1.8750, acc-0.3800, valid loss-1.8156, acc-0.4966, test loss-1.8165, acc-0.4914\n",
      "Iter-58430, train loss-1.8407, acc-0.4400, valid loss-1.8156, acc-0.4964, test loss-1.8165, acc-0.4913\n",
      "Iter-58440, train loss-1.7887, acc-0.5800, valid loss-1.8155, acc-0.4964, test loss-1.8164, acc-0.4914\n",
      "Iter-58450, train loss-1.8731, acc-0.4400, valid loss-1.8155, acc-0.4964, test loss-1.8164, acc-0.4914\n",
      "Iter-58460, train loss-1.7845, acc-0.5400, valid loss-1.8154, acc-0.4968, test loss-1.8163, acc-0.4914\n",
      "Iter-58470, train loss-1.8424, acc-0.3800, valid loss-1.8154, acc-0.4968, test loss-1.8163, acc-0.4913\n",
      "Iter-58480, train loss-1.8443, acc-0.3600, valid loss-1.8153, acc-0.4968, test loss-1.8162, acc-0.4912\n",
      "Iter-58490, train loss-1.8688, acc-0.4600, valid loss-1.8152, acc-0.4968, test loss-1.8162, acc-0.4912\n",
      "Iter-58500, train loss-1.7877, acc-0.4800, valid loss-1.8152, acc-0.4970, test loss-1.8161, acc-0.4912\n",
      "Iter-58510, train loss-1.7984, acc-0.4800, valid loss-1.8151, acc-0.4970, test loss-1.8161, acc-0.4913\n",
      "Iter-58520, train loss-1.8535, acc-0.4800, valid loss-1.8151, acc-0.4970, test loss-1.8160, acc-0.4915\n",
      "Iter-58530, train loss-1.9022, acc-0.3600, valid loss-1.8150, acc-0.4972, test loss-1.8160, acc-0.4916\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-58540, train loss-1.7658, acc-0.5400, valid loss-1.8150, acc-0.4972, test loss-1.8159, acc-0.4915\n",
      "Iter-58550, train loss-1.8862, acc-0.4000, valid loss-1.8149, acc-0.4974, test loss-1.8159, acc-0.4914\n",
      "Iter-58560, train loss-1.8126, acc-0.4400, valid loss-1.8149, acc-0.4972, test loss-1.8158, acc-0.4914\n",
      "Iter-58570, train loss-1.7531, acc-0.5000, valid loss-1.8148, acc-0.4972, test loss-1.8158, acc-0.4914\n",
      "Iter-58580, train loss-1.8659, acc-0.5200, valid loss-1.8148, acc-0.4972, test loss-1.8157, acc-0.4915\n",
      "Iter-58590, train loss-1.8516, acc-0.5200, valid loss-1.8147, acc-0.4974, test loss-1.8157, acc-0.4915\n",
      "Iter-58600, train loss-1.7925, acc-0.5600, valid loss-1.8147, acc-0.4972, test loss-1.8156, acc-0.4916\n",
      "Iter-58610, train loss-1.7680, acc-0.5800, valid loss-1.8146, acc-0.4974, test loss-1.8156, acc-0.4916\n",
      "Iter-58620, train loss-1.7842, acc-0.5000, valid loss-1.8146, acc-0.4972, test loss-1.8155, acc-0.4915\n",
      "Iter-58630, train loss-1.8324, acc-0.4600, valid loss-1.8145, acc-0.4972, test loss-1.8155, acc-0.4914\n",
      "Iter-58640, train loss-1.8171, acc-0.5800, valid loss-1.8145, acc-0.4972, test loss-1.8154, acc-0.4914\n",
      "Iter-58650, train loss-1.9018, acc-0.5000, valid loss-1.8144, acc-0.4972, test loss-1.8154, acc-0.4914\n",
      "Iter-58660, train loss-1.9078, acc-0.3800, valid loss-1.8144, acc-0.4974, test loss-1.8153, acc-0.4915\n",
      "Iter-58670, train loss-1.7317, acc-0.5000, valid loss-1.8143, acc-0.4972, test loss-1.8153, acc-0.4917\n",
      "Iter-58680, train loss-1.8000, acc-0.5400, valid loss-1.8143, acc-0.4972, test loss-1.8152, acc-0.4918\n",
      "Iter-58690, train loss-1.8185, acc-0.5200, valid loss-1.8142, acc-0.4972, test loss-1.8152, acc-0.4918\n",
      "Iter-58700, train loss-1.8309, acc-0.3600, valid loss-1.8142, acc-0.4972, test loss-1.8151, acc-0.4918\n",
      "Iter-58710, train loss-1.8406, acc-0.4800, valid loss-1.8141, acc-0.4972, test loss-1.8151, acc-0.4916\n",
      "Iter-58720, train loss-1.7415, acc-0.6600, valid loss-1.8141, acc-0.4972, test loss-1.8150, acc-0.4916\n",
      "Iter-58730, train loss-1.8268, acc-0.5000, valid loss-1.8140, acc-0.4974, test loss-1.8150, acc-0.4916\n",
      "Iter-58740, train loss-1.7220, acc-0.5200, valid loss-1.8140, acc-0.4974, test loss-1.8149, acc-0.4916\n",
      "Iter-58750, train loss-1.8988, acc-0.4000, valid loss-1.8139, acc-0.4972, test loss-1.8149, acc-0.4916\n",
      "Iter-58760, train loss-1.8334, acc-0.5200, valid loss-1.8139, acc-0.4972, test loss-1.8148, acc-0.4916\n",
      "Iter-58770, train loss-1.7724, acc-0.5400, valid loss-1.8138, acc-0.4972, test loss-1.8148, acc-0.4916\n",
      "Iter-58780, train loss-1.8476, acc-0.4600, valid loss-1.8138, acc-0.4970, test loss-1.8147, acc-0.4915\n",
      "Iter-58790, train loss-1.7745, acc-0.5000, valid loss-1.8137, acc-0.4972, test loss-1.8147, acc-0.4914\n",
      "Iter-58800, train loss-1.8824, acc-0.4400, valid loss-1.8137, acc-0.4972, test loss-1.8146, acc-0.4916\n",
      "Iter-58810, train loss-1.8233, acc-0.4800, valid loss-1.8136, acc-0.4972, test loss-1.8146, acc-0.4916\n",
      "Iter-58820, train loss-1.7836, acc-0.5600, valid loss-1.8136, acc-0.4972, test loss-1.8145, acc-0.4917\n",
      "Iter-58830, train loss-1.8357, acc-0.5000, valid loss-1.8135, acc-0.4972, test loss-1.8145, acc-0.4917\n",
      "Iter-58840, train loss-1.7712, acc-0.5400, valid loss-1.8135, acc-0.4972, test loss-1.8144, acc-0.4919\n",
      "Iter-58850, train loss-1.7771, acc-0.5200, valid loss-1.8134, acc-0.4970, test loss-1.8144, acc-0.4916\n",
      "Iter-58860, train loss-1.8465, acc-0.4000, valid loss-1.8134, acc-0.4970, test loss-1.8143, acc-0.4918\n",
      "Iter-58870, train loss-1.8112, acc-0.5400, valid loss-1.8133, acc-0.4970, test loss-1.8142, acc-0.4919\n",
      "Iter-58880, train loss-1.7677, acc-0.5000, valid loss-1.8133, acc-0.4970, test loss-1.8142, acc-0.4918\n",
      "Iter-58890, train loss-1.8056, acc-0.5200, valid loss-1.8132, acc-0.4972, test loss-1.8141, acc-0.4918\n",
      "Iter-58900, train loss-1.8495, acc-0.4200, valid loss-1.8132, acc-0.4972, test loss-1.8141, acc-0.4920\n",
      "Iter-58910, train loss-1.8483, acc-0.4200, valid loss-1.8131, acc-0.4972, test loss-1.8140, acc-0.4919\n",
      "Iter-58920, train loss-1.8775, acc-0.5000, valid loss-1.8131, acc-0.4970, test loss-1.8140, acc-0.4921\n",
      "Iter-58930, train loss-1.8326, acc-0.5600, valid loss-1.8130, acc-0.4970, test loss-1.8139, acc-0.4922\n",
      "Iter-58940, train loss-1.8909, acc-0.4200, valid loss-1.8130, acc-0.4970, test loss-1.8139, acc-0.4921\n",
      "Iter-58950, train loss-1.7611, acc-0.5800, valid loss-1.8129, acc-0.4970, test loss-1.8138, acc-0.4922\n",
      "Iter-58960, train loss-1.9202, acc-0.4200, valid loss-1.8129, acc-0.4970, test loss-1.8138, acc-0.4921\n",
      "Iter-58970, train loss-1.8053, acc-0.5800, valid loss-1.8128, acc-0.4972, test loss-1.8137, acc-0.4921\n",
      "Iter-58980, train loss-1.8643, acc-0.3600, valid loss-1.8128, acc-0.4972, test loss-1.8137, acc-0.4921\n",
      "Iter-58990, train loss-1.8929, acc-0.4600, valid loss-1.8127, acc-0.4972, test loss-1.8136, acc-0.4922\n",
      "Iter-59000, train loss-1.7922, acc-0.5600, valid loss-1.8127, acc-0.4970, test loss-1.8136, acc-0.4923\n",
      "Iter-59010, train loss-1.8001, acc-0.5200, valid loss-1.8126, acc-0.4970, test loss-1.8135, acc-0.4924\n",
      "Iter-59020, train loss-1.8071, acc-0.5200, valid loss-1.8126, acc-0.4970, test loss-1.8135, acc-0.4924\n",
      "Iter-59030, train loss-1.8551, acc-0.3600, valid loss-1.8125, acc-0.4972, test loss-1.8134, acc-0.4924\n",
      "Iter-59040, train loss-1.9956, acc-0.3400, valid loss-1.8125, acc-0.4974, test loss-1.8134, acc-0.4925\n",
      "Iter-59050, train loss-1.8731, acc-0.4200, valid loss-1.8124, acc-0.4972, test loss-1.8133, acc-0.4927\n",
      "Iter-59060, train loss-1.8241, acc-0.5600, valid loss-1.8124, acc-0.4974, test loss-1.8133, acc-0.4926\n",
      "Iter-59070, train loss-1.7736, acc-0.4800, valid loss-1.8123, acc-0.4974, test loss-1.8132, acc-0.4927\n",
      "Iter-59080, train loss-1.8543, acc-0.4200, valid loss-1.8123, acc-0.4976, test loss-1.8132, acc-0.4927\n",
      "Iter-59090, train loss-1.8248, acc-0.4400, valid loss-1.8122, acc-0.4976, test loss-1.8131, acc-0.4926\n",
      "Iter-59100, train loss-1.7533, acc-0.6400, valid loss-1.8122, acc-0.4980, test loss-1.8131, acc-0.4927\n",
      "Iter-59110, train loss-1.8600, acc-0.5000, valid loss-1.8121, acc-0.4980, test loss-1.8130, acc-0.4927\n",
      "Iter-59120, train loss-1.8276, acc-0.5400, valid loss-1.8121, acc-0.4980, test loss-1.8130, acc-0.4929\n",
      "Iter-59130, train loss-1.8725, acc-0.4400, valid loss-1.8120, acc-0.4980, test loss-1.8129, acc-0.4929\n",
      "Iter-59140, train loss-1.8694, acc-0.3800, valid loss-1.8120, acc-0.4982, test loss-1.8129, acc-0.4932\n",
      "Iter-59150, train loss-1.8805, acc-0.4600, valid loss-1.8119, acc-0.4980, test loss-1.8128, acc-0.4933\n",
      "Iter-59160, train loss-1.9006, acc-0.4800, valid loss-1.8119, acc-0.4980, test loss-1.8128, acc-0.4930\n",
      "Iter-59170, train loss-1.8398, acc-0.5200, valid loss-1.8118, acc-0.4980, test loss-1.8127, acc-0.4930\n",
      "Iter-59180, train loss-1.9517, acc-0.4800, valid loss-1.8118, acc-0.4980, test loss-1.8127, acc-0.4931\n",
      "Iter-59190, train loss-1.7177, acc-0.6400, valid loss-1.8117, acc-0.4980, test loss-1.8126, acc-0.4928\n",
      "Iter-59200, train loss-1.7634, acc-0.5800, valid loss-1.8117, acc-0.4980, test loss-1.8126, acc-0.4928\n",
      "Iter-59210, train loss-1.6942, acc-0.6000, valid loss-1.8116, acc-0.4980, test loss-1.8125, acc-0.4929\n",
      "Iter-59220, train loss-1.7539, acc-0.6000, valid loss-1.8116, acc-0.4982, test loss-1.8125, acc-0.4928\n",
      "Iter-59230, train loss-1.7688, acc-0.5200, valid loss-1.8115, acc-0.4982, test loss-1.8124, acc-0.4927\n",
      "Iter-59240, train loss-1.8455, acc-0.4800, valid loss-1.8115, acc-0.4982, test loss-1.8124, acc-0.4930\n",
      "Iter-59250, train loss-1.8135, acc-0.4400, valid loss-1.8114, acc-0.4982, test loss-1.8124, acc-0.4930\n",
      "Iter-59260, train loss-1.8743, acc-0.4200, valid loss-1.8114, acc-0.4980, test loss-1.8123, acc-0.4929\n",
      "Iter-59270, train loss-1.8683, acc-0.4200, valid loss-1.8113, acc-0.4982, test loss-1.8123, acc-0.4928\n",
      "Iter-59280, train loss-1.9077, acc-0.4800, valid loss-1.8113, acc-0.4984, test loss-1.8122, acc-0.4930\n",
      "Iter-59290, train loss-1.7979, acc-0.5200, valid loss-1.8112, acc-0.4986, test loss-1.8121, acc-0.4929\n",
      "Iter-59300, train loss-1.8074, acc-0.5000, valid loss-1.8112, acc-0.4982, test loss-1.8121, acc-0.4929\n",
      "Iter-59310, train loss-1.8011, acc-0.4400, valid loss-1.8111, acc-0.4982, test loss-1.8120, acc-0.4927\n",
      "Iter-59320, train loss-1.7643, acc-0.5200, valid loss-1.8111, acc-0.4984, test loss-1.8120, acc-0.4927\n",
      "Iter-59330, train loss-1.8541, acc-0.5200, valid loss-1.8110, acc-0.4986, test loss-1.8119, acc-0.4927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-59340, train loss-1.7987, acc-0.4200, valid loss-1.8110, acc-0.4986, test loss-1.8119, acc-0.4928\n",
      "Iter-59350, train loss-1.7445, acc-0.6400, valid loss-1.8109, acc-0.4982, test loss-1.8118, acc-0.4929\n",
      "Iter-59360, train loss-1.9643, acc-0.4400, valid loss-1.8109, acc-0.4982, test loss-1.8118, acc-0.4929\n",
      "Iter-59370, train loss-1.8991, acc-0.4200, valid loss-1.8108, acc-0.4982, test loss-1.8118, acc-0.4928\n",
      "Iter-59380, train loss-1.7397, acc-0.5800, valid loss-1.8108, acc-0.4982, test loss-1.8117, acc-0.4928\n",
      "Iter-59390, train loss-1.8799, acc-0.4200, valid loss-1.8107, acc-0.4982, test loss-1.8117, acc-0.4928\n",
      "Iter-59400, train loss-1.8287, acc-0.5200, valid loss-1.8107, acc-0.4982, test loss-1.8116, acc-0.4927\n",
      "Iter-59410, train loss-1.8844, acc-0.5000, valid loss-1.8106, acc-0.4984, test loss-1.8116, acc-0.4928\n",
      "Iter-59420, train loss-1.8362, acc-0.4600, valid loss-1.8106, acc-0.4984, test loss-1.8115, acc-0.4927\n",
      "Iter-59430, train loss-1.8473, acc-0.5200, valid loss-1.8105, acc-0.4982, test loss-1.8115, acc-0.4927\n",
      "Iter-59440, train loss-1.7865, acc-0.4800, valid loss-1.8105, acc-0.4982, test loss-1.8114, acc-0.4929\n",
      "Iter-59450, train loss-1.8809, acc-0.4200, valid loss-1.8104, acc-0.4982, test loss-1.8114, acc-0.4928\n",
      "Iter-59460, train loss-1.8653, acc-0.4000, valid loss-1.8104, acc-0.4982, test loss-1.8113, acc-0.4928\n",
      "Iter-59470, train loss-1.8548, acc-0.5600, valid loss-1.8103, acc-0.4986, test loss-1.8113, acc-0.4929\n",
      "Iter-59480, train loss-1.8422, acc-0.5000, valid loss-1.8103, acc-0.4986, test loss-1.8112, acc-0.4929\n",
      "Iter-59490, train loss-1.8690, acc-0.4400, valid loss-1.8102, acc-0.4984, test loss-1.8112, acc-0.4928\n",
      "Iter-59500, train loss-1.7909, acc-0.4800, valid loss-1.8102, acc-0.4986, test loss-1.8111, acc-0.4929\n",
      "Iter-59510, train loss-1.7621, acc-0.5600, valid loss-1.8101, acc-0.4986, test loss-1.8111, acc-0.4929\n",
      "Iter-59520, train loss-1.8861, acc-0.4200, valid loss-1.8101, acc-0.4986, test loss-1.8110, acc-0.4931\n",
      "Iter-59530, train loss-1.8555, acc-0.4200, valid loss-1.8100, acc-0.4984, test loss-1.8110, acc-0.4932\n",
      "Iter-59540, train loss-1.9133, acc-0.3800, valid loss-1.8100, acc-0.4984, test loss-1.8109, acc-0.4932\n",
      "Iter-59550, train loss-1.8313, acc-0.5000, valid loss-1.8099, acc-0.4984, test loss-1.8109, acc-0.4931\n",
      "Iter-59560, train loss-1.8856, acc-0.3800, valid loss-1.8099, acc-0.4988, test loss-1.8108, acc-0.4928\n",
      "Iter-59570, train loss-1.8479, acc-0.4400, valid loss-1.8098, acc-0.4986, test loss-1.8108, acc-0.4930\n",
      "Iter-59580, train loss-1.8047, acc-0.4600, valid loss-1.8098, acc-0.4984, test loss-1.8107, acc-0.4928\n",
      "Iter-59590, train loss-1.8723, acc-0.4600, valid loss-1.8097, acc-0.4984, test loss-1.8107, acc-0.4930\n",
      "Iter-59600, train loss-1.8064, acc-0.5600, valid loss-1.8097, acc-0.4984, test loss-1.8106, acc-0.4930\n",
      "Iter-59610, train loss-1.7722, acc-0.5200, valid loss-1.8096, acc-0.4986, test loss-1.8106, acc-0.4928\n",
      "Iter-59620, train loss-1.7303, acc-0.6000, valid loss-1.8096, acc-0.4986, test loss-1.8105, acc-0.4930\n",
      "Iter-59630, train loss-1.8174, acc-0.4400, valid loss-1.8095, acc-0.4986, test loss-1.8105, acc-0.4930\n",
      "Iter-59640, train loss-1.8508, acc-0.4400, valid loss-1.8095, acc-0.4986, test loss-1.8104, acc-0.4929\n",
      "Iter-59650, train loss-1.8522, acc-0.4600, valid loss-1.8094, acc-0.4988, test loss-1.8104, acc-0.4929\n",
      "Iter-59660, train loss-1.8596, acc-0.4600, valid loss-1.8094, acc-0.4990, test loss-1.8103, acc-0.4929\n",
      "Iter-59670, train loss-1.7998, acc-0.5000, valid loss-1.8093, acc-0.4986, test loss-1.8103, acc-0.4929\n",
      "Iter-59680, train loss-1.8328, acc-0.4800, valid loss-1.8093, acc-0.4990, test loss-1.8102, acc-0.4930\n",
      "Iter-59690, train loss-1.9846, acc-0.3400, valid loss-1.8092, acc-0.4986, test loss-1.8102, acc-0.4931\n",
      "Iter-59700, train loss-1.8017, acc-0.6000, valid loss-1.8092, acc-0.4986, test loss-1.8101, acc-0.4931\n",
      "Iter-59710, train loss-1.7832, acc-0.5400, valid loss-1.8091, acc-0.4986, test loss-1.8101, acc-0.4930\n",
      "Iter-59720, train loss-1.8616, acc-0.4200, valid loss-1.8091, acc-0.4990, test loss-1.8100, acc-0.4931\n",
      "Iter-59730, train loss-1.7926, acc-0.5800, valid loss-1.8090, acc-0.4986, test loss-1.8100, acc-0.4932\n",
      "Iter-59740, train loss-1.7868, acc-0.5400, valid loss-1.8090, acc-0.4988, test loss-1.8099, acc-0.4930\n",
      "Iter-59750, train loss-1.8266, acc-0.5400, valid loss-1.8089, acc-0.4988, test loss-1.8099, acc-0.4930\n",
      "Iter-59760, train loss-1.8342, acc-0.4000, valid loss-1.8089, acc-0.4986, test loss-1.8098, acc-0.4931\n",
      "Iter-59770, train loss-1.7820, acc-0.5600, valid loss-1.8088, acc-0.4986, test loss-1.8098, acc-0.4931\n",
      "Iter-59780, train loss-1.7827, acc-0.6000, valid loss-1.8088, acc-0.4990, test loss-1.8097, acc-0.4932\n",
      "Iter-59790, train loss-1.7811, acc-0.4200, valid loss-1.8088, acc-0.4990, test loss-1.8097, acc-0.4931\n",
      "Iter-59800, train loss-1.8688, acc-0.5000, valid loss-1.8087, acc-0.4990, test loss-1.8096, acc-0.4931\n",
      "Iter-59810, train loss-1.8840, acc-0.4200, valid loss-1.8087, acc-0.4990, test loss-1.8096, acc-0.4930\n",
      "Iter-59820, train loss-1.8167, acc-0.4400, valid loss-1.8086, acc-0.4990, test loss-1.8095, acc-0.4930\n",
      "Iter-59830, train loss-1.7817, acc-0.4400, valid loss-1.8086, acc-0.4988, test loss-1.8095, acc-0.4930\n",
      "Iter-59840, train loss-1.7537, acc-0.5800, valid loss-1.8085, acc-0.4988, test loss-1.8094, acc-0.4930\n",
      "Iter-59850, train loss-1.8923, acc-0.4200, valid loss-1.8085, acc-0.4990, test loss-1.8094, acc-0.4930\n",
      "Iter-59860, train loss-1.8408, acc-0.4800, valid loss-1.8084, acc-0.4990, test loss-1.8093, acc-0.4929\n",
      "Iter-59870, train loss-1.7731, acc-0.6000, valid loss-1.8084, acc-0.4990, test loss-1.8093, acc-0.4928\n",
      "Iter-59880, train loss-1.9210, acc-0.4200, valid loss-1.8083, acc-0.4990, test loss-1.8092, acc-0.4928\n",
      "Iter-59890, train loss-1.8786, acc-0.4800, valid loss-1.8083, acc-0.4990, test loss-1.8092, acc-0.4929\n",
      "Iter-59900, train loss-1.9008, acc-0.3600, valid loss-1.8082, acc-0.4990, test loss-1.8091, acc-0.4929\n",
      "Iter-59910, train loss-1.7631, acc-0.6400, valid loss-1.8082, acc-0.4988, test loss-1.8091, acc-0.4929\n",
      "Iter-59920, train loss-1.7749, acc-0.6200, valid loss-1.8081, acc-0.4990, test loss-1.8090, acc-0.4927\n",
      "Iter-59930, train loss-1.7544, acc-0.5600, valid loss-1.8081, acc-0.4988, test loss-1.8090, acc-0.4929\n",
      "Iter-59940, train loss-1.8080, acc-0.5000, valid loss-1.8080, acc-0.4986, test loss-1.8089, acc-0.4929\n",
      "Iter-59950, train loss-1.6949, acc-0.5400, valid loss-1.8080, acc-0.4984, test loss-1.8089, acc-0.4929\n",
      "Iter-59960, train loss-1.9224, acc-0.5200, valid loss-1.8079, acc-0.4986, test loss-1.8088, acc-0.4930\n",
      "Iter-59970, train loss-1.9220, acc-0.3600, valid loss-1.8079, acc-0.4988, test loss-1.8088, acc-0.4927\n",
      "Iter-59980, train loss-1.7210, acc-0.5400, valid loss-1.8078, acc-0.4992, test loss-1.8087, acc-0.4927\n",
      "Iter-59990, train loss-1.7906, acc-0.5200, valid loss-1.8078, acc-0.4990, test loss-1.8087, acc-0.4928\n",
      "Iter-60000, train loss-1.9421, acc-0.3800, valid loss-1.8077, acc-0.4990, test loss-1.8086, acc-0.4927\n",
      "Iter-60010, train loss-1.8129, acc-0.5200, valid loss-1.8077, acc-0.4990, test loss-1.8086, acc-0.4927\n",
      "Iter-60020, train loss-1.7465, acc-0.5800, valid loss-1.8076, acc-0.4988, test loss-1.8085, acc-0.4928\n",
      "Iter-60030, train loss-1.8166, acc-0.5000, valid loss-1.8076, acc-0.4988, test loss-1.8085, acc-0.4928\n",
      "Iter-60040, train loss-1.7760, acc-0.5800, valid loss-1.8075, acc-0.4988, test loss-1.8084, acc-0.4928\n",
      "Iter-60050, train loss-1.9247, acc-0.3800, valid loss-1.8075, acc-0.4988, test loss-1.8084, acc-0.4929\n",
      "Iter-60060, train loss-1.8724, acc-0.4800, valid loss-1.8074, acc-0.4990, test loss-1.8083, acc-0.4929\n",
      "Iter-60070, train loss-1.7607, acc-0.6000, valid loss-1.8074, acc-0.4988, test loss-1.8083, acc-0.4929\n",
      "Iter-60080, train loss-1.8235, acc-0.5000, valid loss-1.8073, acc-0.4988, test loss-1.8082, acc-0.4929\n",
      "Iter-60090, train loss-1.8475, acc-0.4200, valid loss-1.8073, acc-0.4988, test loss-1.8082, acc-0.4931\n",
      "Iter-60100, train loss-1.7678, acc-0.5200, valid loss-1.8072, acc-0.4988, test loss-1.8081, acc-0.4930\n",
      "Iter-60110, train loss-1.7341, acc-0.5600, valid loss-1.8072, acc-0.4988, test loss-1.8081, acc-0.4930\n",
      "Iter-60120, train loss-1.7375, acc-0.5600, valid loss-1.8071, acc-0.4990, test loss-1.8080, acc-0.4930\n",
      "Iter-60130, train loss-1.8554, acc-0.5000, valid loss-1.8071, acc-0.4990, test loss-1.8080, acc-0.4930\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60140, train loss-1.8266, acc-0.5000, valid loss-1.8070, acc-0.4990, test loss-1.8079, acc-0.4930\n",
      "Iter-60150, train loss-1.8505, acc-0.4800, valid loss-1.8070, acc-0.4992, test loss-1.8079, acc-0.4929\n",
      "Iter-60160, train loss-1.7538, acc-0.6000, valid loss-1.8069, acc-0.4996, test loss-1.8078, acc-0.4931\n",
      "Iter-60170, train loss-1.9024, acc-0.4800, valid loss-1.8069, acc-0.4992, test loss-1.8078, acc-0.4931\n",
      "Iter-60180, train loss-1.7978, acc-0.5400, valid loss-1.8068, acc-0.4994, test loss-1.8077, acc-0.4930\n",
      "Iter-60190, train loss-1.8476, acc-0.4600, valid loss-1.8068, acc-0.4994, test loss-1.8077, acc-0.4929\n",
      "Iter-60200, train loss-1.7611, acc-0.5200, valid loss-1.8067, acc-0.4994, test loss-1.8076, acc-0.4929\n",
      "Iter-60210, train loss-1.7770, acc-0.6000, valid loss-1.8067, acc-0.4994, test loss-1.8076, acc-0.4930\n",
      "Iter-60220, train loss-1.8962, acc-0.4200, valid loss-1.8066, acc-0.4994, test loss-1.8076, acc-0.4928\n",
      "Iter-60230, train loss-1.8860, acc-0.4200, valid loss-1.8066, acc-0.4994, test loss-1.8075, acc-0.4928\n",
      "Iter-60240, train loss-1.8157, acc-0.4600, valid loss-1.8065, acc-0.4992, test loss-1.8074, acc-0.4929\n",
      "Iter-60250, train loss-1.7933, acc-0.5600, valid loss-1.8065, acc-0.4996, test loss-1.8074, acc-0.4931\n",
      "Iter-60260, train loss-1.8698, acc-0.4200, valid loss-1.8064, acc-0.4996, test loss-1.8074, acc-0.4932\n",
      "Iter-60270, train loss-1.7861, acc-0.4400, valid loss-1.8064, acc-0.4996, test loss-1.8073, acc-0.4931\n",
      "Iter-60280, train loss-1.7949, acc-0.4800, valid loss-1.8064, acc-0.4998, test loss-1.8073, acc-0.4932\n",
      "Iter-60290, train loss-1.7714, acc-0.5200, valid loss-1.8063, acc-0.4996, test loss-1.8072, acc-0.4932\n",
      "Iter-60300, train loss-1.8749, acc-0.4000, valid loss-1.8063, acc-0.4996, test loss-1.8072, acc-0.4933\n",
      "Iter-60310, train loss-1.8566, acc-0.5000, valid loss-1.8062, acc-0.4994, test loss-1.8071, acc-0.4933\n",
      "Iter-60320, train loss-1.8188, acc-0.5800, valid loss-1.8062, acc-0.4996, test loss-1.8071, acc-0.4934\n",
      "Iter-60330, train loss-1.8268, acc-0.5200, valid loss-1.8061, acc-0.4998, test loss-1.8070, acc-0.4935\n",
      "Iter-60340, train loss-1.7791, acc-0.5600, valid loss-1.8061, acc-0.4998, test loss-1.8070, acc-0.4933\n",
      "Iter-60350, train loss-1.7706, acc-0.6200, valid loss-1.8060, acc-0.4996, test loss-1.8069, acc-0.4932\n",
      "Iter-60360, train loss-1.8062, acc-0.5200, valid loss-1.8060, acc-0.4998, test loss-1.8069, acc-0.4933\n",
      "Iter-60370, train loss-1.8202, acc-0.4600, valid loss-1.8059, acc-0.4998, test loss-1.8068, acc-0.4931\n",
      "Iter-60380, train loss-1.8401, acc-0.4800, valid loss-1.8059, acc-0.4996, test loss-1.8068, acc-0.4930\n",
      "Iter-60390, train loss-1.8404, acc-0.5000, valid loss-1.8058, acc-0.4998, test loss-1.8067, acc-0.4934\n",
      "Iter-60400, train loss-1.8102, acc-0.5000, valid loss-1.8058, acc-0.5000, test loss-1.8067, acc-0.4932\n",
      "Iter-60410, train loss-1.8788, acc-0.4200, valid loss-1.8057, acc-0.4998, test loss-1.8066, acc-0.4933\n",
      "Iter-60420, train loss-1.8647, acc-0.3600, valid loss-1.8057, acc-0.5000, test loss-1.8066, acc-0.4933\n",
      "Iter-60430, train loss-1.8248, acc-0.5600, valid loss-1.8056, acc-0.4998, test loss-1.8065, acc-0.4933\n",
      "Iter-60440, train loss-1.7960, acc-0.4800, valid loss-1.8056, acc-0.4998, test loss-1.8065, acc-0.4933\n",
      "Iter-60450, train loss-1.8127, acc-0.5400, valid loss-1.8055, acc-0.4998, test loss-1.8064, acc-0.4934\n",
      "Iter-60460, train loss-1.9557, acc-0.4200, valid loss-1.8055, acc-0.4998, test loss-1.8064, acc-0.4934\n",
      "Iter-60470, train loss-1.7162, acc-0.5400, valid loss-1.8054, acc-0.4998, test loss-1.8063, acc-0.4934\n",
      "Iter-60480, train loss-1.8552, acc-0.4600, valid loss-1.8054, acc-0.4998, test loss-1.8063, acc-0.4934\n",
      "Iter-60490, train loss-1.9282, acc-0.3800, valid loss-1.8053, acc-0.4998, test loss-1.8062, acc-0.4932\n",
      "Iter-60500, train loss-1.9069, acc-0.4000, valid loss-1.8053, acc-0.4998, test loss-1.8062, acc-0.4931\n",
      "Iter-60510, train loss-1.7826, acc-0.5400, valid loss-1.8052, acc-0.4996, test loss-1.8061, acc-0.4932\n",
      "Iter-60520, train loss-1.7825, acc-0.4800, valid loss-1.8052, acc-0.4998, test loss-1.8061, acc-0.4930\n",
      "Iter-60530, train loss-1.8649, acc-0.3800, valid loss-1.8051, acc-0.4996, test loss-1.8060, acc-0.4932\n",
      "Iter-60540, train loss-1.7049, acc-0.5400, valid loss-1.8051, acc-0.4998, test loss-1.8060, acc-0.4936\n",
      "Iter-60550, train loss-1.8379, acc-0.4800, valid loss-1.8050, acc-0.4998, test loss-1.8059, acc-0.4938\n",
      "Iter-60560, train loss-1.7892, acc-0.5400, valid loss-1.8050, acc-0.5000, test loss-1.8059, acc-0.4935\n",
      "Iter-60570, train loss-1.8219, acc-0.5400, valid loss-1.8049, acc-0.4998, test loss-1.8058, acc-0.4936\n",
      "Iter-60580, train loss-1.8283, acc-0.5600, valid loss-1.8049, acc-0.4998, test loss-1.8058, acc-0.4937\n",
      "Iter-60590, train loss-1.7926, acc-0.4600, valid loss-1.8048, acc-0.4998, test loss-1.8057, acc-0.4937\n",
      "Iter-60600, train loss-1.8882, acc-0.3600, valid loss-1.8048, acc-0.4998, test loss-1.8057, acc-0.4939\n",
      "Iter-60610, train loss-1.7457, acc-0.5400, valid loss-1.8047, acc-0.4996, test loss-1.8056, acc-0.4939\n",
      "Iter-60620, train loss-1.8519, acc-0.4200, valid loss-1.8047, acc-0.4998, test loss-1.8056, acc-0.4937\n",
      "Iter-60630, train loss-1.8533, acc-0.4600, valid loss-1.8046, acc-0.4996, test loss-1.8055, acc-0.4937\n",
      "Iter-60640, train loss-1.8054, acc-0.5200, valid loss-1.8046, acc-0.4998, test loss-1.8055, acc-0.4938\n",
      "Iter-60650, train loss-1.8528, acc-0.4000, valid loss-1.8045, acc-0.5000, test loss-1.8054, acc-0.4938\n",
      "Iter-60660, train loss-1.8164, acc-0.4600, valid loss-1.8045, acc-0.5000, test loss-1.8054, acc-0.4936\n",
      "Iter-60670, train loss-1.7351, acc-0.5800, valid loss-1.8044, acc-0.5000, test loss-1.8053, acc-0.4938\n",
      "Iter-60680, train loss-1.8075, acc-0.5000, valid loss-1.8044, acc-0.5000, test loss-1.8053, acc-0.4939\n",
      "Iter-60690, train loss-1.8005, acc-0.4600, valid loss-1.8043, acc-0.5000, test loss-1.8052, acc-0.4939\n",
      "Iter-60700, train loss-1.7905, acc-0.5600, valid loss-1.8043, acc-0.5000, test loss-1.8052, acc-0.4938\n",
      "Iter-60710, train loss-1.8883, acc-0.4400, valid loss-1.8042, acc-0.5000, test loss-1.8051, acc-0.4939\n",
      "Iter-60720, train loss-1.8320, acc-0.4800, valid loss-1.8042, acc-0.5000, test loss-1.8051, acc-0.4940\n",
      "Iter-60730, train loss-1.8491, acc-0.5200, valid loss-1.8041, acc-0.5000, test loss-1.8050, acc-0.4939\n",
      "Iter-60740, train loss-1.7808, acc-0.4800, valid loss-1.8041, acc-0.4998, test loss-1.8050, acc-0.4941\n",
      "Iter-60750, train loss-1.8681, acc-0.3400, valid loss-1.8040, acc-0.4998, test loss-1.8049, acc-0.4941\n",
      "Iter-60760, train loss-1.7895, acc-0.5800, valid loss-1.8040, acc-0.4998, test loss-1.8049, acc-0.4941\n",
      "Iter-60770, train loss-1.8394, acc-0.5000, valid loss-1.8039, acc-0.5000, test loss-1.8049, acc-0.4939\n",
      "Iter-60780, train loss-1.8994, acc-0.4600, valid loss-1.8039, acc-0.5000, test loss-1.8048, acc-0.4941\n",
      "Iter-60790, train loss-1.6738, acc-0.6000, valid loss-1.8038, acc-0.5000, test loss-1.8048, acc-0.4940\n",
      "Iter-60800, train loss-1.8087, acc-0.5400, valid loss-1.8038, acc-0.5002, test loss-1.8047, acc-0.4941\n",
      "Iter-60810, train loss-1.8181, acc-0.5000, valid loss-1.8038, acc-0.5002, test loss-1.8047, acc-0.4943\n",
      "Iter-60820, train loss-1.7969, acc-0.5000, valid loss-1.8037, acc-0.5000, test loss-1.8046, acc-0.4943\n",
      "Iter-60830, train loss-1.7386, acc-0.5600, valid loss-1.8037, acc-0.5000, test loss-1.8046, acc-0.4944\n",
      "Iter-60840, train loss-1.8146, acc-0.4400, valid loss-1.8036, acc-0.5000, test loss-1.8045, acc-0.4944\n",
      "Iter-60850, train loss-1.8473, acc-0.4200, valid loss-1.8036, acc-0.5000, test loss-1.8045, acc-0.4945\n",
      "Iter-60860, train loss-1.8135, acc-0.5400, valid loss-1.8035, acc-0.5000, test loss-1.8044, acc-0.4946\n",
      "Iter-60870, train loss-1.7464, acc-0.5800, valid loss-1.8035, acc-0.5000, test loss-1.8044, acc-0.4945\n",
      "Iter-60880, train loss-1.9134, acc-0.4000, valid loss-1.8034, acc-0.5000, test loss-1.8043, acc-0.4946\n",
      "Iter-60890, train loss-1.8005, acc-0.5800, valid loss-1.8034, acc-0.5000, test loss-1.8043, acc-0.4946\n",
      "Iter-60900, train loss-1.7269, acc-0.4800, valid loss-1.8033, acc-0.5000, test loss-1.8042, acc-0.4944\n",
      "Iter-60910, train loss-1.8192, acc-0.5000, valid loss-1.8033, acc-0.5000, test loss-1.8042, acc-0.4946\n",
      "Iter-60920, train loss-1.8911, acc-0.4800, valid loss-1.8032, acc-0.5000, test loss-1.8041, acc-0.4946\n",
      "Iter-60930, train loss-1.7872, acc-0.4000, valid loss-1.8032, acc-0.5000, test loss-1.8041, acc-0.4946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-60940, train loss-1.8190, acc-0.5600, valid loss-1.8031, acc-0.5000, test loss-1.8040, acc-0.4947\n",
      "Iter-60950, train loss-1.8646, acc-0.4200, valid loss-1.8031, acc-0.5000, test loss-1.8040, acc-0.4947\n",
      "Iter-60960, train loss-1.8338, acc-0.4400, valid loss-1.8030, acc-0.5000, test loss-1.8039, acc-0.4947\n",
      "Iter-60970, train loss-1.8673, acc-0.3600, valid loss-1.8030, acc-0.4996, test loss-1.8039, acc-0.4948\n",
      "Iter-60980, train loss-1.8441, acc-0.4400, valid loss-1.8030, acc-0.5000, test loss-1.8038, acc-0.4947\n",
      "Iter-60990, train loss-1.8682, acc-0.4800, valid loss-1.8029, acc-0.4998, test loss-1.8038, acc-0.4948\n",
      "Iter-61000, train loss-1.7980, acc-0.5200, valid loss-1.8029, acc-0.5000, test loss-1.8037, acc-0.4947\n",
      "Iter-61010, train loss-1.7365, acc-0.6400, valid loss-1.8028, acc-0.4998, test loss-1.8037, acc-0.4947\n",
      "Iter-61020, train loss-1.8626, acc-0.5200, valid loss-1.8028, acc-0.4996, test loss-1.8036, acc-0.4948\n",
      "Iter-61030, train loss-1.9121, acc-0.4200, valid loss-1.8027, acc-0.4996, test loss-1.8036, acc-0.4948\n",
      "Iter-61040, train loss-1.8902, acc-0.4600, valid loss-1.8026, acc-0.4996, test loss-1.8035, acc-0.4948\n",
      "Iter-61050, train loss-1.8188, acc-0.4800, valid loss-1.8026, acc-0.4998, test loss-1.8035, acc-0.4948\n",
      "Iter-61060, train loss-1.8374, acc-0.5200, valid loss-1.8026, acc-0.5000, test loss-1.8035, acc-0.4948\n",
      "Iter-61070, train loss-1.7451, acc-0.6200, valid loss-1.8025, acc-0.5000, test loss-1.8034, acc-0.4949\n",
      "Iter-61080, train loss-1.6720, acc-0.5600, valid loss-1.8025, acc-0.5000, test loss-1.8034, acc-0.4951\n",
      "Iter-61090, train loss-1.8563, acc-0.4400, valid loss-1.8024, acc-0.4998, test loss-1.8033, acc-0.4950\n",
      "Iter-61100, train loss-1.7298, acc-0.5000, valid loss-1.8024, acc-0.4998, test loss-1.8033, acc-0.4950\n",
      "Iter-61110, train loss-1.7330, acc-0.6400, valid loss-1.8023, acc-0.4996, test loss-1.8032, acc-0.4949\n",
      "Iter-61120, train loss-1.6692, acc-0.6800, valid loss-1.8023, acc-0.4998, test loss-1.8031, acc-0.4950\n",
      "Iter-61130, train loss-1.8013, acc-0.5200, valid loss-1.8022, acc-0.4998, test loss-1.8031, acc-0.4949\n",
      "Iter-61140, train loss-1.7364, acc-0.4600, valid loss-1.8022, acc-0.4998, test loss-1.8031, acc-0.4949\n",
      "Iter-61150, train loss-1.8852, acc-0.4800, valid loss-1.8021, acc-0.4998, test loss-1.8030, acc-0.4951\n",
      "Iter-61160, train loss-1.9751, acc-0.3200, valid loss-1.8021, acc-0.4996, test loss-1.8030, acc-0.4951\n",
      "Iter-61170, train loss-1.8303, acc-0.5200, valid loss-1.8020, acc-0.4998, test loss-1.8029, acc-0.4951\n",
      "Iter-61180, train loss-1.7484, acc-0.4400, valid loss-1.8020, acc-0.4996, test loss-1.8029, acc-0.4951\n",
      "Iter-61190, train loss-1.7462, acc-0.6000, valid loss-1.8019, acc-0.4998, test loss-1.8028, acc-0.4952\n",
      "Iter-61200, train loss-1.8508, acc-0.4600, valid loss-1.8019, acc-0.4998, test loss-1.8028, acc-0.4952\n",
      "Iter-61210, train loss-1.8488, acc-0.5200, valid loss-1.8018, acc-0.4996, test loss-1.8027, acc-0.4952\n",
      "Iter-61220, train loss-1.8008, acc-0.5400, valid loss-1.8018, acc-0.4994, test loss-1.8027, acc-0.4951\n",
      "Iter-61230, train loss-1.8285, acc-0.5200, valid loss-1.8017, acc-0.4996, test loss-1.8026, acc-0.4951\n",
      "Iter-61240, train loss-1.8036, acc-0.5400, valid loss-1.8017, acc-0.4994, test loss-1.8026, acc-0.4951\n",
      "Iter-61250, train loss-1.8292, acc-0.4800, valid loss-1.8016, acc-0.4994, test loss-1.8025, acc-0.4949\n",
      "Iter-61260, train loss-1.8941, acc-0.3200, valid loss-1.8016, acc-0.4992, test loss-1.8025, acc-0.4947\n",
      "Iter-61270, train loss-1.7528, acc-0.5000, valid loss-1.8015, acc-0.4990, test loss-1.8024, acc-0.4948\n",
      "Iter-61280, train loss-1.8714, acc-0.3600, valid loss-1.8015, acc-0.4992, test loss-1.8024, acc-0.4949\n",
      "Iter-61290, train loss-1.7937, acc-0.4800, valid loss-1.8014, acc-0.4990, test loss-1.8023, acc-0.4948\n",
      "Iter-61300, train loss-1.7343, acc-0.5200, valid loss-1.8014, acc-0.4992, test loss-1.8023, acc-0.4948\n",
      "Iter-61310, train loss-1.8579, acc-0.4800, valid loss-1.8013, acc-0.4994, test loss-1.8022, acc-0.4951\n",
      "Iter-61320, train loss-1.8302, acc-0.4000, valid loss-1.8013, acc-0.4994, test loss-1.8022, acc-0.4950\n",
      "Iter-61330, train loss-1.8279, acc-0.4400, valid loss-1.8012, acc-0.4994, test loss-1.8021, acc-0.4949\n",
      "Iter-61340, train loss-1.8851, acc-0.4400, valid loss-1.8012, acc-0.4992, test loss-1.8021, acc-0.4948\n",
      "Iter-61350, train loss-1.7613, acc-0.6000, valid loss-1.8011, acc-0.4992, test loss-1.8020, acc-0.4950\n",
      "Iter-61360, train loss-1.8813, acc-0.3800, valid loss-1.8011, acc-0.4992, test loss-1.8020, acc-0.4950\n",
      "Iter-61370, train loss-1.7233, acc-0.6600, valid loss-1.8010, acc-0.4992, test loss-1.8019, acc-0.4953\n",
      "Iter-61380, train loss-1.6633, acc-0.6800, valid loss-1.8010, acc-0.4992, test loss-1.8019, acc-0.4952\n",
      "Iter-61390, train loss-1.7450, acc-0.5400, valid loss-1.8009, acc-0.4992, test loss-1.8018, acc-0.4949\n",
      "Iter-61400, train loss-1.7534, acc-0.5800, valid loss-1.8009, acc-0.4992, test loss-1.8018, acc-0.4949\n",
      "Iter-61410, train loss-1.8448, acc-0.5200, valid loss-1.8008, acc-0.4992, test loss-1.8017, acc-0.4950\n",
      "Iter-61420, train loss-1.7778, acc-0.5200, valid loss-1.8008, acc-0.4992, test loss-1.8017, acc-0.4949\n",
      "Iter-61430, train loss-1.7136, acc-0.5000, valid loss-1.8007, acc-0.4992, test loss-1.8016, acc-0.4949\n",
      "Iter-61440, train loss-1.8543, acc-0.4000, valid loss-1.8007, acc-0.4990, test loss-1.8016, acc-0.4949\n",
      "Iter-61450, train loss-1.7317, acc-0.5200, valid loss-1.8006, acc-0.4990, test loss-1.8015, acc-0.4949\n"
     ]
    }
   ],
   "source": [
    "# Hyper-parameters\n",
    "n_iter = 100000 # number of epochs\n",
    "alpha = 1e-3 # learning_rate\n",
    "mb_size = 50 # 2**10==1024 # width, timestep for sequential data or minibatch size\n",
    "print_after = 10 # n_iter//10 # print loss for train, valid, and test\n",
    "num_hidden_units = 32 # number of kernels/ filters in each layer\n",
    "num_input_units = X_train.shape[1] # noise added at the input lavel as input noise we can use dX or for more improvement\n",
    "num_output_units = y_train.max() + 1 # number of classes in this classification problem\n",
    "num_layers = 2 # depth \n",
    "\n",
    "# Build the model/NN and learn it: running session.\n",
    "nn = FFNN(C=num_output_units, D=num_input_units, H=num_hidden_units, L=num_layers)\n",
    "\n",
    "nn.sgd(train_set=(X_train, y_train), val_set=(X_val, y_val), mb_size=mb_size, alpha=alpha, \n",
    "           n_iter=n_iter, print_after=print_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Display the learning curve and losses for training, validation, and testing\n",
    "# %matplotlib inline\n",
    "# %config InlineBackend.figure_format = 'retina'\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(nn.losses['train'], label='Train loss')\n",
    "plt.plot(nn.losses['valid'], label='Valid loss')\n",
    "plt.plot(nn.losses['test'], label='Test loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nn.losses['train_acc'], label='Train accuracy')\n",
    "plt.plot(nn.losses['valid_acc'], label='Valid accuracy')\n",
    "plt.plot(nn.losses['test_acc'], label='Test accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
