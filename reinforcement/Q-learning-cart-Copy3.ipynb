{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Q-learning\n",
    "\n",
    "In this notebook, we'll build a neural network that can learn to play games through reinforcement learning. More specifically, we'll use Q-learning to train an agent to play a game called [Cart-Pole](https://gym.openai.com/envs/CartPole-v0). In this game, a freely swinging pole is attached to a cart. The cart can move to the left and right, and the goal is to keep the pole upright as long as possible.\n",
    "\n",
    "![Cart-Pole](assets/cart-pole.jpg)\n",
    "\n",
    "We can simulate this game using [OpenAI Gym](https://gym.openai.com/). First, let's check out how OpenAI Gym works. Then, we'll get into training an agent to play the Cart-Pole game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note:** Make sure you have OpenAI Gym cloned into the same directory with this notebook. I've included `gym` as a submodule, so you can run `git submodule --init --recursive` to pull the contents into the `gym` repo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mWARN: gym.spaces.Box autodetected dtype as <class 'numpy.float32'>. Please provide explicit dtype.\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/arasdar/anaconda3/envs/env/lib/python3.6/site-packages/gym/__init__.py:22: UserWarning: DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.\n",
      "  warnings.warn('DEPRECATION WARNING: to improve load times, gym no longer automatically loads gym.spaces. Please run \"import gym.spaces\" to load gym.spaces on your own. This warning will turn into an error in a future version of gym.')\n"
     ]
    }
   ],
   "source": [
    "# Create the Cart-Pole game environment\n",
    "env = gym.make('CartPole-v0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We interact with the simulation through `env`. To show the simulation running, you can use `env.render()` to render one frame. Passing in an action as an integer to `env.step` will generate the next step in the simulation.  You can see how many actions are possible from `env.action_space` and to get a random action you can use `env.action_space.sample()`. This is general to all Gym games. In the Cart-Pole game, there are two possible actions, moving the cart left or right. So there are two actions we can take, encoded as 0 and 1.\n",
    "\n",
    "Run the code below to watch the simulation run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "state, action, reward, done, info\n",
      "[ 0.14484091  1.15899641 -0.2171274  -1.99853303] 0 1.0 True {}\n",
      "state, action, reward, done, info\n",
      "[-0.10593986 -0.93815841  0.21964675  1.73781463] 0 1.0 True {}\n",
      "state, action, reward, done, info\n",
      "[ 0.10584616  0.97726318 -0.21944104 -1.78747062] 1 1.0 True {}\n",
      "state, action, reward, done, info\n",
      "[ 0.11808262  1.34625522 -0.21847809 -2.29440815] 1 1.0 True {}\n",
      "state, action, reward, done, info\n",
      "[-0.21424401 -1.00566039  0.22603744  1.6844058 ] 1 1.0 True {}\n",
      "state, action, reward, done, info\n",
      "[ 0.21348068  0.78964734 -0.22638012 -1.34958902] 0 1.0 True {}\n"
     ]
    }
   ],
   "source": [
    "env.reset()\n",
    "rewards = []\n",
    "for _ in range(100):\n",
    "#     env.render()\n",
    "    action = env.action_space.sample()\n",
    "    state, reward, done, info = env.step(action) # take a random action\n",
    "    rewards.append(reward)\n",
    "    if done:\n",
    "        print('state, action, reward, done, info')\n",
    "        print(state, action, reward, done, info)\n",
    "        rewards = []\n",
    "        env.reset()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To shut the window showing the simulation, use `env.close()`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you ran the simulation above, we can look at the rewards:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.0, 1.0, 1.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(rewards[-20:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The game resets after the pole has fallen past a certain angle. For each frame while the simulation is running, it returns a reward of 1.0. The longer the game runs, the more reward we get. Then, our network's goal is to maximize the reward by keeping the pole vertical. It will do this by moving the cart to the left and the right."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Network\n",
    "\n",
    "We train our Q-learning agent using the Bellman Equation:\n",
    "\n",
    "$$\n",
    "Q(s, a) = r + \\gamma \\max{Q(s', a')}\n",
    "$$\n",
    "\n",
    "where $s$ is a state, $a$ is an action, and $s'$ is the next state from state $s$ and action $a$.\n",
    "\n",
    "Before we used this equation to learn values for a Q-_table_. However, for this game there are a huge number of states available. The state has four values: the position and velocity of the cart, and the position and velocity of the pole. These are all real-valued numbers, so ignoring floating point precisions, you practically have infinite states. Instead of using a table then, we'll replace it with a neural network that will approximate the Q-table lookup function.\n",
    "\n",
    "<img src=\"assets/deep-q-learning.png\" width=450px>\n",
    "\n",
    "Now, our Q value, $Q(s, a)$ is calculated by passing in a state to the network. The output will be Q-values for each available action, with fully connected hidden layers.\n",
    "\n",
    "<img src=\"assets/q-network.png\" width=550px>\n",
    "\n",
    "\n",
    "As I showed before, we can define our targets for training as $\\hat{Q}(s,a) = r + \\gamma \\max{Q(s', a')}$. Then we update the weights by minimizing $(\\hat{Q}(s,a) - Q(s,a))^2$. \n",
    "\n",
    "For this Cart-Pole game, we have four inputs, one for each value in the state, and two outputs, one for each action. To get $\\hat{Q}$, we'll first choose an action, then simulate the game using that action. This will get us the next state, $s'$, and the reward. With that, we can calculate $\\hat{Q}$ then pass it back into the $Q$ network to run the optimizer and update the weights.\n",
    "\n",
    "Below is my implementation of the Q-network. I used two fully connected layers with ReLU activations. Two seems to be good enough, three might be better. Feel free to try it out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_input(state_size):\n",
    "    # Given data\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "    actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "    # Target Q values for training\n",
    "    targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "    return inputs_, actions_, targetQs_    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(x, hidden_size, action_size):\n",
    "    with tf.variable_scope('generator'):\n",
    "        # First fully connected layer\n",
    "        h1 = tf.layers.dense(inputs=x, units=hidden_size)\n",
    "        #bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "        nl1 = tf.maximum(0.1 * h1, h1)\n",
    "        \n",
    "        # Second fully connected layer\n",
    "        h2 = tf.layers.dense(nl1, hidden_size)\n",
    "        #bn2 = tf.layers.batch_normalization(h2, training=training)\n",
    "        nl2 = tf.maximum(0.1 * h2, h2)\n",
    "        \n",
    "        # Output layer\n",
    "        logits = tf.layers.dense(nl2, action_size)\n",
    "        # out = tf.tanh(logits)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_loss(inputs_, hidden_size, actions_, action_size, targetQs_):\n",
    "    # Output layer\n",
    "    output = generator(x=inputs_, hidden_size=hidden_size, action_size=action_size)        \n",
    "\n",
    "    # One hot encode the actions to later choose the Q-value for the action\n",
    "    one_hot_actions = tf.one_hot(actions_, action_size)\n",
    "\n",
    "    ### Train with loss (targetQ - Q)^2\n",
    "    # output has length 2, for two actions. This next line chooses\n",
    "    # one value from output (per row) according to the one-hot encoded actions.\n",
    "    Q = tf.reduce_sum(tf.multiply(output, one_hot_actions), axis=1)\n",
    "\n",
    "    # error backpropagation: loss and opt\n",
    "    loss = tf.reduce_mean(tf.square(targetQs_ - Q))\n",
    "    \n",
    "    return output, Q, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QNetwork:\n",
    "    def __init__(self, state_size, action_size, hidden_size):\n",
    "        # Data of the Model: make the data available inside the framework\n",
    "        self.inputs_, self.actions_, self.targetQs_ = model_input(state_size=state_size)\n",
    "\n",
    "        # Create the Model: calculating the loss and forwad pass\n",
    "        self.output, self.Q, self.loss = model_loss(action_size=action_size, actions_=self.actions_, \n",
    "                                                    hidden_size=hidden_size, \n",
    "                                                    inputs_=self.inputs_, targetQs_=self.targetQs_)\n",
    "\n",
    "        # Update the model: backward pass and backprop\n",
    "        self.opt = tf.train.AdamOptimizer().minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class QNetwork:\n",
    "#     def __init__(self, learning_rate=0.01, state_size=4, action_size=2, hidden_size=10, name='QNetwork'):\n",
    "#         # state inputs to the Q-network\n",
    "#         with tf.variable_scope(name):\n",
    "#             # Given data\n",
    "#             self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs')\n",
    "#             self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "\n",
    "#             # One hot encode the actions to later choose the Q-value for the action\n",
    "#             one_hot_actions = tf.one_hot(self.actions_, action_size)\n",
    "\n",
    "#             # ReLU hidden layers\n",
    "#             fc1 = tf.contrib.layers.fully_connected(self.inputs_, hidden_size)\n",
    "#             fc2 = tf.contrib.layers.fully_connected(fc1, hidden_size)\n",
    "\n",
    "#             # Linear output layer\n",
    "#             self.output = tf.contrib.layers.fully_connected(fc2, action_size, activation_fn=None)\n",
    "                    \n",
    "#             ### Train with loss (targetQ - Q)^2\n",
    "#             # output has length 2, for two actions. This next line chooses\n",
    "#             # one value from output (per row) according to the one-hot encoded actions.\n",
    "#             self.Q = tf.reduce_sum(tf.multiply(self.output, one_hot_actions), axis=1)\n",
    "\n",
    "#             # Target Q values for training\n",
    "#             self.targetQs_ = tf.placeholder(tf.float32, [None], name='target')\n",
    "\n",
    "#             # error backpropagation: loss and opt\n",
    "#             self.loss = tf.reduce_mean(tf.square(self.targetQs_ - self.Q))\n",
    "#             self.opt = tf.train.AdamOptimizer(learning_rate).minimize(self.loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf.layers.dense(\n",
    "#     inputs, --- GOOD\n",
    "#     units, ----- GOOD\n",
    "#     activation=None,\n",
    "#     use_bias=True,  ----------- GOOD\n",
    "#     kernel_initializer=None,\n",
    "#     bias_initializer=tf.zeros_initializer(), ----------GOOD\n",
    "#     kernel_regularizer=None,\n",
    "#     bias_regularizer=None,\n",
    "#     activity_regularizer=None,\n",
    "#     kernel_constraint=None,\n",
    "#     bias_constraint=None,\n",
    "#     trainable=True, ----------------- ???\n",
    "#     name=None,\n",
    "#     reuse=None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generator(in_state, state_size=4, action_size=2, hidden_size=10, alpha=0.1, reuse=False, training=True):\n",
    "#     with tf.variable_scope('generator', reuse=reuse):\n",
    "#         # First fully connected layer\n",
    "#         h1 = tf.layers.dense(inputs=in_state, units=hidden_size)\n",
    "#         bn1 = tf.layers.batch_normalization(h1, training=training)\n",
    "#         nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(nl1, hidden_size)\n",
    "#         bn2 = tf.layers.batch_normalization(h2, training=training)\n",
    "#         nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits_state_next = tf.layers.dense(nl2, state_size, trainable=False)        \n",
    "#         logits_action = tf.layers.dense(nl2, action_size, trainable=False)        \n",
    "#         # out = tf.tanh(logits)\n",
    "\n",
    "#         return logits_state_next, logits_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def discriminator(in_state_next, out_action, action_size=2, hidden_size=10, reuse=False, alpha=0.1):\n",
    "#     with tf.variable_scope('discriminator', reuse=reuse):\n",
    "#         # First fully connected layer\n",
    "#         fused = tf.concat(values=[in_state_next, out_action], axis=1)\n",
    "#         h1 = tf.layers.dense(fused, hidden_size)\n",
    "#         bn1 = tf.layers.batch_normalization(h1, training=True)\n",
    "#         nl1 = tf.maximum(alpha * bn1, bn1)\n",
    "        \n",
    "#         # Second fully connected layer\n",
    "#         h2 = tf.layers.dense(nl1, hidden_size)\n",
    "#         bn2 = tf.layers.batch_normalization(h2, training=True)\n",
    "#         nl2 = tf.maximum(alpha * bn2, bn2)\n",
    "        \n",
    "#         # Output layer\n",
    "#         logits = tf.layers.dense(nl2, 1, trainable=False)   \n",
    "#         out = tf.sigmoid(logits)\n",
    "\n",
    "#         # logits for loss and reward/prob/out\n",
    "#         return out, logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_inputs(state_size=4):\n",
    "#     # Current input states\n",
    "#     inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs') # NxCin\n",
    "#     # print(self.inputs_)\n",
    "\n",
    "#     # Current output action: for generation/prediction\n",
    "#     actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "#     # print(actions_)\n",
    "\n",
    "#     # Next input real and generated/fake/predicted\n",
    "#     inputs_next = tf.placeholder(tf.float32, [None, state_size], name='inputs_next') # NxCin\n",
    "#     # print(self.inputs_next)\n",
    "    \n",
    "#     return inputs_, actions_, inputs_next"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_loss(inputs_, actions_, inputs_next, action_size=2, hidden_size=10, alpha=0.1):\n",
    "#     \"\"\"\n",
    "#     Get the loss for the discriminator and generator\n",
    "#     :param inputs_: real input states given\n",
    "#     :param actions_: real actions given\n",
    "#     :param inputs_next: real next input states given\n",
    "#     :return: A tuple of (discriminator loss, generator loss)\n",
    "#     \"\"\"\n",
    "#     input_state_gen, out_action_gen = generator(in_state=inputs_, hidden_size=hidden_size)\n",
    "#     _, d_logits_fake = discriminator(in_state_next=input_state_gen, out_action=out_action_gen, hidden_size=hidden_size)\n",
    "#     actions_onehot = tf.one_hot(actions_, action_size)\n",
    "#     _, d_logits_real = discriminator(in_state_next=inputs_next, out_action=actions_onehot, hidden_size=hidden_size, reuse=True)\n",
    "\n",
    "#     d_loss_real = tf.reduce_mean(\n",
    "#         tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_real, labels=tf.ones_like(d_logits_real)))\n",
    "#     d_loss_fake = tf.reduce_mean(\n",
    "#         tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.zeros_like(d_logits_fake)))\n",
    "#     d_loss = d_loss_real + d_loss_fake\n",
    "    \n",
    "#     g_loss = tf.reduce_mean(\n",
    "#         tf.nn.sigmoid_cross_entropy_with_logits(logits=d_logits_fake, labels=tf.ones_like(d_logits_fake)))\n",
    "    \n",
    "#     return d_loss, g_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def model_opt(d_loss, g_loss, learning_rate):\n",
    "#     \"\"\"\n",
    "#     Get optimization operations\n",
    "#     :param d_loss: Discriminator loss Tensor for reward function\n",
    "#     :param g_loss: Generator loss Tensor for action & next state predicton\n",
    "#     :param learning_rate: Learning Rate Placeholder\n",
    "#     :return: A tuple of (discriminator training operation, generator training operation)\n",
    "#     \"\"\"\n",
    "#     # Get weights and bias to update\n",
    "#     t_vars = tf.trainable_variables()\n",
    "#     d_vars = [var for var in t_vars if var.name.startswith('discriminator')]\n",
    "#     g_vars = [var for var in t_vars if var.name.startswith('generator')]\n",
    "\n",
    "#     # Optimize\n",
    "#     with tf.control_dependencies(tf.get_collection(tf.GraphKeys.UPDATE_OPS)):\n",
    "#         d_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(d_loss, var_list=d_vars)\n",
    "#         g_train_opt = tf.train.AdamOptimizer(learning_rate).minimize(g_loss, var_list=g_vars)\n",
    "\n",
    "#     return d_train_opt, g_train_opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Net:\n",
    "#     def __init__(self, action_size=2, state_size=4, hidden_size=10, learning_rate=0.01, alpha=0.1):\n",
    "#         tf.reset_default_graph()\n",
    "        \n",
    "#         # Transfer the data into the framework: model the input/given data\n",
    "#         self.inputs_, self.actions_, self.inputs_next = model_inputs(state_size=state_size)\n",
    "        \n",
    "#         # Creating the model inside the framework: Model forward prop for caculating the loss\n",
    "#         self.d_loss, self.g_loss = model_loss(inputs_=self.inputs_, actions_=self.actions_, inputs_next=self.inputs_next, \n",
    "#                                               hidden_size=hidden_size)\n",
    "        \n",
    "#         # Updating the model inside the framework: Model the backprop for updating the model\n",
    "#         self.d_opt, self.g_opt = model_opt(d_loss=self.d_loss, g_loss=self.g_loss, learning_rate=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # def generator(in_state, state_size=4, action_size=2, hidden_size=10, name='generator', reuse=False, ):\n",
    "# #     # state inputs to the Q-network2\n",
    "# #     with tf.variable_scope(name, reuse=reuse): # for saving the generator weights and biases (model parameters)\n",
    "\n",
    "# #         # ReLU hidden layers: generators\n",
    "# #         fc1 = tf.contrib.layers.fully_connected(in_state, hidden_size)\n",
    "# #         fc2 = tf.contrib.layers.fully_connected(fc1, hidden_size)\n",
    "\n",
    "# #         # Linear output layer\n",
    "# #         logits_state_next = tf.contrib.layers.fully_connected(fc2, state_size, activation_fn=None, trainable=False)\n",
    "# #         logits_action = tf.contrib.layers.fully_connected(fc2, action_size, activation_fn=None, trainable=False)\n",
    "\n",
    "# #         # # Split it into in and out\n",
    "# #         # logits_state_next, logits_action = tf.split(value=logits, num_or_size_splits=[state_size, action_size], axis=1)\n",
    "\n",
    "# #         # logits_action is for applying to the env or env.step and the predicted next state is for D\n",
    "# #         return logits_state_next, logits_action\n",
    "\n",
    "# # def discriminator(in_state_next, out_action, action_size=2, hidden_size=10, name='discriminator', reuse=False):\n",
    "# #     # state inputs to the Q-network2\n",
    "# #     with tf.variable_scope(name, reuse=reuse):\n",
    "        \n",
    "# #         # ReLU hidden layers: discriminator\n",
    "# #         fused = tf.concat(values=[in_state_next, out_action], axis=1)\n",
    "# #         # print(in_state_next.shape, out_action.shape, fused.shape)\n",
    "# #         fc1 = tf.contrib.layers.fully_connected(fused, hidden_size)\n",
    "# #         fc2 = tf.contrib.layers.fully_connected(fc1, hidden_size)\n",
    "\n",
    "# #         # Linear output layer: logits and prob/logistics\n",
    "# #         logits = tf.contrib.layers.fully_connected(fc2, 1, activation_fn=None)\n",
    "# #         # reward = tf.sigmoid(x=logits) # for reward accumulation -  reward: 0-1\n",
    "\n",
    "# #         # outputing the logits and prob reward: logits for loss and prob for accumulaion\n",
    "# #         return logits\n",
    "\n",
    "# # # This GAN for iDRL\n",
    "# class Net:\n",
    "#     def __init__(self, state_size=4, action_size=2, hidden_size=10, learning_rate=0.01):            \n",
    "#         # Current input states\n",
    "#         self.inputs_ = tf.placeholder(tf.float32, [None, state_size], name='inputs') # NxCin\n",
    "#         # print(self.inputs_)\n",
    "\n",
    "#         # Current output action: for generation/prediction\n",
    "#         self.actions_ = tf.placeholder(tf.int32, [None], name='actions')\n",
    "#         actions_onehot = tf.one_hot(self.actions_, action_size)\n",
    "#         # print(actions_onehot)\n",
    "\n",
    "#         # Next input real and generated/fake/predicted\n",
    "#         self.inputs_next = tf.placeholder(tf.float32, [None, state_size], name='inputs_next') # NxCin\n",
    "#         # print(self.inputs_next)\n",
    "\n",
    "#         # Linear output layer\n",
    "#         inputs_next_gen, self.output_gen = generator(self.inputs_)\n",
    "\n",
    "#         # Linear output layer\n",
    "#         d_logits_fake = discriminator(inputs_next_gen, self.output_gen) # , self.d_reward_fake\n",
    "#         d_logits_real = discriminator(self.inputs_next, actions_onehot, reuse=True) #, self.d_reward_real\n",
    "\n",
    "#         d_loss_fake = tf.nn.sigmoid_cross_entropy_with_logits(labels=d_logits_fake, \n",
    "#                                                       logits=tf.zeros_like(d_logits_fake))\n",
    "#         d_loss_real = tf.nn.sigmoid_cross_entropy_with_logits(labels=d_logits_real, \n",
    "#                                                       logits=tf.ones_like(d_logits_real))\n",
    "\n",
    "#         self.d_loss = d_loss_fake + d_loss_real\n",
    "#         self.g_loss = tf.nn.sigmoid_cross_entropy_with_logits(labels=d_logits_fake, \n",
    "#                                                       logits=tf.ones_like(d_logits_fake))\n",
    "\n",
    "#         self.d_opt = tf.train.AdamOptimizer(learning_rate).minimize(self.d_loss)\n",
    "#         self.g_opt = tf.train.AdamOptimizer(learning_rate).minimize(self.g_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experience replay\n",
    "\n",
    "Reinforcement learning algorithms can have stability issues due to correlations between states. To reduce correlations when training, we can store the agent's experiences and later draw a random mini-batch of those experiences to train on. \n",
    "\n",
    "Here, we'll create a `Memory` object that will store our experiences, our transitions $<s, a, r, s'>$. This memory will have a maxmium capacity, so we can keep newer experiences in memory while getting rid of older experiences. Then, we'll sample a random mini-batch of transitions $<s, a, r, s'>$ and train on those.\n",
    "\n",
    "Below, I've implemented a `Memory` object. If you're unfamiliar with `deque`, this is a double-ended queue. You can think of it like a tube open on both sides. You can put objects in either side of the tube. But if it's full, adding anything more will push an object out the other side. This is a great data structure to use for the memory buffer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import deque\n",
    "class Memory():\n",
    "    def __init__(self, max_size = 1000):\n",
    "        self.buffer = deque(maxlen=max_size)\n",
    "    \n",
    "    def add(self, experience):\n",
    "        self.buffer.append(experience)\n",
    "            \n",
    "    def sample(self, batch_size):\n",
    "        idx = np.random.choice(np.arange(len(self.buffer)), \n",
    "                               size=batch_size, \n",
    "                               replace=False)\n",
    "        return [self.buffer[ii] for ii in idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploration - Exploitation\n",
    "\n",
    "To learn about the environment and rules of the game, the agent needs to explore by taking random actions. We'll do this by choosing a random action with some probability $\\epsilon$ (epsilon).  That is, with some probability $\\epsilon$ the agent will make a random action and with probability $1 - \\epsilon$, the agent will choose an action from $Q(s,a)$. This is called an **$\\epsilon$-greedy policy**.\n",
    "\n",
    "\n",
    "At first, the agent needs to do a lot of exploring. Later when it has learned more, the agent can favor choosing actions based on what it has learned. This is called _exploitation_. We'll set it up so the agent is more likely to explore early in training, then more likely to exploit later in training."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-Learning training algorithm\n",
    "\n",
    "Putting all this together, we can list out the algorithm we'll use to train the network. We'll train the network in _episodes_. One *episode* is one simulation of the game. For this game, the goal is to keep the pole upright for 195 frames. So we can start a new episode once meeting that goal. The game ends if the pole tilts over too far, or if the cart moves too far the left or right. When a game ends, we'll start a new episode. Now, to train the agent:\n",
    "\n",
    "* Initialize the memory $D$\n",
    "* Initialize the action-value network $Q$ with random weights\n",
    "* **For** episode = 1, $M$ **do**\n",
    "  * **For** $t$, $T$ **do**\n",
    "     * With probability $\\epsilon$ select a random action $a_t$, otherwise select $a_t = \\mathrm{argmax}_a Q(s,a)$\n",
    "     * Execute action $a_t$ in simulator and observe reward $r_{t+1}$ and new state $s_{t+1}$\n",
    "     * Store transition $<s_t, a_t, r_{t+1}, s_{t+1}>$ in memory $D$\n",
    "     * Sample random mini-batch from $D$: $<s_j, a_j, r_j, s'_j>$\n",
    "     * Set $\\hat{Q}_j = r_j$ if the episode ends at $j+1$, otherwise set $\\hat{Q}_j = r_j + \\gamma \\max_{a'}{Q(s'_j, a')}$\n",
    "     * Make a gradient descent step with loss $(\\hat{Q}_j - Q(s_j, a_j))^2$\n",
    "  * **endfor**\n",
    "* **endfor**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameters\n",
    "\n",
    "One of the more difficult aspects of reinforcememt learning are the large number of hyperparameters. Not only are we tuning the network, but we're tuning the simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_episodes = 1000          # max number of episodes to learn from\n",
    "max_steps = 200                # max steps in an episode\n",
    "gamma = 0.99                   # future reward discount\n",
    "\n",
    "# Exploration parameters\n",
    "explore_start = 1.0            # exploration probability at start\n",
    "explore_stop = 0.01            # minimum exploration probability \n",
    "decay_rate = 0.0001            # exponential decay rate for exploration prob\n",
    "\n",
    "# Network parameters\n",
    "hidden_size = 10               # number of units in each Q-network hidden layer\n",
    "learning_rate = 0.0001         # Q-network learning rate\n",
    "\n",
    "# Memory parameters\n",
    "memory_size = 10000            # memory capacity\n",
    "batch_size = 20                # experience mini-batch size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.reset_default_graph()\n",
    "# mainQN = QNetwork(name='main', hidden_size=hidden_size, learning_rate=learning_rate)\n",
    "mainQN = QNetwork(action_size=2, hidden_size=hidden_size, state_size=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Populate the experience memory\n",
    "\n",
    "Here I'm re-initializing the simulation and pre-populating the memory. The agent is taking random actions and storing the transitions in memory. This will help the agent with exploring the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the simulation\n",
    "env.reset()\n",
    "\n",
    "# Take one random step to get the pole and cart moving\n",
    "state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "# init memory\n",
    "memory = Memory(max_size=memory_size)\n",
    "\n",
    "# Make a bunch of random actions and store the experiences\n",
    "for _ in range(batch_size):\n",
    "    # Uncomment the line below to watch the simulation\n",
    "    # env.render()\n",
    "\n",
    "    # Make a random action\n",
    "    action = env.action_space.sample()\n",
    "    next_state, reward, done, _ = env.step(action)\n",
    "\n",
    "    if done:\n",
    "        # The simulation fails so no next state\n",
    "        next_state = np.zeros(state.shape)\n",
    "        \n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        \n",
    "        # Start new episode\n",
    "        env.reset()\n",
    "        \n",
    "        # Take one random step to get the pole and cart moving\n",
    "        state, reward, done, _ = env.step(env.action_space.sample())\n",
    "    else:\n",
    "        # Add experience to memory\n",
    "        memory.add((state, action, reward, next_state))\n",
    "        state = next_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "Below we'll train our agent. If you want to watch it train, uncomment the `env.render()` line. This is slow because it's rendering the frames slower than the network can train. But, it's cool to watch the agent get better at the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 0 Total reward: 9.0 Training loss: 1.4482 Explore P: 0.9991\n",
      "Episode: 1 Total reward: 41.0 Training loss: 1.5172 Explore P: 0.9951\n",
      "Episode: 2 Total reward: 16.0 Training loss: 1.7637 Explore P: 0.9935\n",
      "Episode: 3 Total reward: 17.0 Training loss: 2.1905 Explore P: 0.9918\n",
      "Episode: 4 Total reward: 15.0 Training loss: 2.0588 Explore P: 0.9903\n",
      "Episode: 5 Total reward: 18.0 Training loss: 2.1024 Explore P: 0.9886\n",
      "Episode: 6 Total reward: 11.0 Training loss: 1.7803 Explore P: 0.9875\n",
      "Episode: 7 Total reward: 17.0 Training loss: 2.0683 Explore P: 0.9858\n",
      "Episode: 8 Total reward: 11.0 Training loss: 1.8170 Explore P: 0.9848\n",
      "Episode: 9 Total reward: 17.0 Training loss: 2.2534 Explore P: 0.9831\n",
      "Episode: 10 Total reward: 15.0 Training loss: 1.3738 Explore P: 0.9817\n",
      "Episode: 11 Total reward: 12.0 Training loss: 1.5427 Explore P: 0.9805\n",
      "Episode: 12 Total reward: 10.0 Training loss: 2.9226 Explore P: 0.9795\n",
      "Episode: 13 Total reward: 20.0 Training loss: 2.4830 Explore P: 0.9776\n",
      "Episode: 14 Total reward: 12.0 Training loss: 1.8499 Explore P: 0.9764\n",
      "Episode: 15 Total reward: 22.0 Training loss: 1.8419 Explore P: 0.9743\n",
      "Episode: 16 Total reward: 26.0 Training loss: 1.8572 Explore P: 0.9718\n",
      "Episode: 17 Total reward: 9.0 Training loss: 1.8092 Explore P: 0.9709\n",
      "Episode: 18 Total reward: 59.0 Training loss: 1.4319 Explore P: 0.9653\n",
      "Episode: 19 Total reward: 10.0 Training loss: 2.1316 Explore P: 0.9643\n",
      "Episode: 20 Total reward: 50.0 Training loss: 1.8783 Explore P: 0.9596\n",
      "Episode: 21 Total reward: 44.0 Training loss: 1.0548 Explore P: 0.9554\n",
      "Episode: 22 Total reward: 8.0 Training loss: 2.0956 Explore P: 0.9546\n",
      "Episode: 23 Total reward: 19.0 Training loss: 1.7404 Explore P: 0.9528\n",
      "Episode: 24 Total reward: 33.0 Training loss: 2.4048 Explore P: 0.9497\n",
      "Episode: 25 Total reward: 16.0 Training loss: 2.0046 Explore P: 0.9482\n",
      "Episode: 26 Total reward: 11.0 Training loss: 2.7130 Explore P: 0.9472\n",
      "Episode: 27 Total reward: 23.0 Training loss: 2.0008 Explore P: 0.9451\n",
      "Episode: 28 Total reward: 14.0 Training loss: 2.2846 Explore P: 0.9437\n",
      "Episode: 29 Total reward: 19.0 Training loss: 1.4220 Explore P: 0.9420\n",
      "Episode: 30 Total reward: 12.0 Training loss: 1.7639 Explore P: 0.9409\n",
      "Episode: 31 Total reward: 12.0 Training loss: 4.1642 Explore P: 0.9397\n",
      "Episode: 32 Total reward: 36.0 Training loss: 3.6997 Explore P: 0.9364\n",
      "Episode: 33 Total reward: 14.0 Training loss: 2.6668 Explore P: 0.9351\n",
      "Episode: 34 Total reward: 37.0 Training loss: 3.4449 Explore P: 0.9317\n",
      "Episode: 35 Total reward: 16.0 Training loss: 4.5700 Explore P: 0.9302\n",
      "Episode: 36 Total reward: 20.0 Training loss: 4.3869 Explore P: 0.9284\n",
      "Episode: 37 Total reward: 12.0 Training loss: 5.8388 Explore P: 0.9273\n",
      "Episode: 38 Total reward: 23.0 Training loss: 3.8462 Explore P: 0.9252\n",
      "Episode: 39 Total reward: 25.0 Training loss: 4.9762 Explore P: 0.9229\n",
      "Episode: 40 Total reward: 20.0 Training loss: 15.9639 Explore P: 0.9211\n",
      "Episode: 41 Total reward: 15.0 Training loss: 4.1651 Explore P: 0.9197\n",
      "Episode: 42 Total reward: 14.0 Training loss: 3.1326 Explore P: 0.9184\n",
      "Episode: 43 Total reward: 25.0 Training loss: 5.0631 Explore P: 0.9162\n",
      "Episode: 44 Total reward: 20.0 Training loss: 8.6410 Explore P: 0.9143\n",
      "Episode: 45 Total reward: 13.0 Training loss: 8.8307 Explore P: 0.9132\n",
      "Episode: 46 Total reward: 40.0 Training loss: 5.5844 Explore P: 0.9096\n",
      "Episode: 47 Total reward: 28.0 Training loss: 7.7615 Explore P: 0.9070\n",
      "Episode: 48 Total reward: 14.0 Training loss: 6.0870 Explore P: 0.9058\n",
      "Episode: 49 Total reward: 19.0 Training loss: 5.6379 Explore P: 0.9041\n",
      "Episode: 50 Total reward: 20.0 Training loss: 6.4822 Explore P: 0.9023\n",
      "Episode: 51 Total reward: 19.0 Training loss: 5.7443 Explore P: 0.9006\n",
      "Episode: 52 Total reward: 40.0 Training loss: 8.4032 Explore P: 0.8971\n",
      "Episode: 53 Total reward: 9.0 Training loss: 6.1704 Explore P: 0.8963\n",
      "Episode: 54 Total reward: 17.0 Training loss: 10.6275 Explore P: 0.8947\n",
      "Episode: 55 Total reward: 14.0 Training loss: 17.1758 Explore P: 0.8935\n",
      "Episode: 56 Total reward: 18.0 Training loss: 7.7979 Explore P: 0.8919\n",
      "Episode: 57 Total reward: 18.0 Training loss: 7.2624 Explore P: 0.8903\n",
      "Episode: 58 Total reward: 26.0 Training loss: 10.0881 Explore P: 0.8881\n",
      "Episode: 59 Total reward: 12.0 Training loss: 13.1633 Explore P: 0.8870\n",
      "Episode: 60 Total reward: 42.0 Training loss: 11.7487 Explore P: 0.8833\n",
      "Episode: 61 Total reward: 11.0 Training loss: 22.2877 Explore P: 0.8824\n",
      "Episode: 62 Total reward: 13.0 Training loss: 6.4130 Explore P: 0.8812\n",
      "Episode: 63 Total reward: 14.0 Training loss: 6.4753 Explore P: 0.8800\n",
      "Episode: 64 Total reward: 22.0 Training loss: 10.1458 Explore P: 0.8781\n",
      "Episode: 65 Total reward: 8.0 Training loss: 14.8961 Explore P: 0.8774\n",
      "Episode: 66 Total reward: 10.0 Training loss: 8.4105 Explore P: 0.8765\n",
      "Episode: 67 Total reward: 25.0 Training loss: 6.7914 Explore P: 0.8744\n",
      "Episode: 68 Total reward: 10.0 Training loss: 52.5529 Explore P: 0.8735\n",
      "Episode: 69 Total reward: 66.0 Training loss: 17.3408 Explore P: 0.8678\n",
      "Episode: 70 Total reward: 12.0 Training loss: 13.9572 Explore P: 0.8668\n",
      "Episode: 71 Total reward: 16.0 Training loss: 9.4343 Explore P: 0.8654\n",
      "Episode: 72 Total reward: 23.0 Training loss: 17.5591 Explore P: 0.8635\n",
      "Episode: 73 Total reward: 13.0 Training loss: 14.4439 Explore P: 0.8624\n",
      "Episode: 74 Total reward: 10.0 Training loss: 9.5347 Explore P: 0.8615\n",
      "Episode: 75 Total reward: 16.0 Training loss: 19.6297 Explore P: 0.8601\n",
      "Episode: 76 Total reward: 18.0 Training loss: 13.4332 Explore P: 0.8586\n",
      "Episode: 77 Total reward: 15.0 Training loss: 16.1081 Explore P: 0.8573\n",
      "Episode: 78 Total reward: 12.0 Training loss: 19.6563 Explore P: 0.8563\n",
      "Episode: 79 Total reward: 39.0 Training loss: 23.1270 Explore P: 0.8530\n",
      "Episode: 80 Total reward: 14.0 Training loss: 8.5202 Explore P: 0.8519\n",
      "Episode: 81 Total reward: 72.0 Training loss: 12.1742 Explore P: 0.8458\n",
      "Episode: 82 Total reward: 31.0 Training loss: 25.2046 Explore P: 0.8432\n",
      "Episode: 83 Total reward: 15.0 Training loss: 15.2821 Explore P: 0.8420\n",
      "Episode: 84 Total reward: 29.0 Training loss: 35.9490 Explore P: 0.8396\n",
      "Episode: 85 Total reward: 15.0 Training loss: 7.9486 Explore P: 0.8383\n",
      "Episode: 86 Total reward: 16.0 Training loss: 29.7730 Explore P: 0.8370\n",
      "Episode: 87 Total reward: 11.0 Training loss: 29.3723 Explore P: 0.8361\n",
      "Episode: 88 Total reward: 26.0 Training loss: 45.0594 Explore P: 0.8339\n",
      "Episode: 89 Total reward: 12.0 Training loss: 14.5485 Explore P: 0.8330\n",
      "Episode: 90 Total reward: 10.0 Training loss: 18.0247 Explore P: 0.8321\n",
      "Episode: 91 Total reward: 15.0 Training loss: 33.5568 Explore P: 0.8309\n",
      "Episode: 92 Total reward: 21.0 Training loss: 28.8405 Explore P: 0.8292\n",
      "Episode: 93 Total reward: 21.0 Training loss: 55.0008 Explore P: 0.8275\n",
      "Episode: 94 Total reward: 24.0 Training loss: 70.3090 Explore P: 0.8255\n",
      "Episode: 95 Total reward: 41.0 Training loss: 45.1552 Explore P: 0.8222\n",
      "Episode: 96 Total reward: 11.0 Training loss: 12.6717 Explore P: 0.8213\n",
      "Episode: 97 Total reward: 28.0 Training loss: 32.4742 Explore P: 0.8190\n",
      "Episode: 98 Total reward: 94.0 Training loss: 13.9744 Explore P: 0.8114\n",
      "Episode: 99 Total reward: 8.0 Training loss: 20.9780 Explore P: 0.8108\n",
      "Episode: 100 Total reward: 16.0 Training loss: 16.4821 Explore P: 0.8095\n",
      "Episode: 101 Total reward: 21.0 Training loss: 16.9306 Explore P: 0.8078\n",
      "Episode: 102 Total reward: 20.0 Training loss: 60.4894 Explore P: 0.8062\n",
      "Episode: 103 Total reward: 20.0 Training loss: 103.2971 Explore P: 0.8047\n",
      "Episode: 104 Total reward: 18.0 Training loss: 21.7111 Explore P: 0.8032\n",
      "Episode: 105 Total reward: 27.0 Training loss: 85.0538 Explore P: 0.8011\n",
      "Episode: 106 Total reward: 18.0 Training loss: 30.7438 Explore P: 0.7997\n",
      "Episode: 107 Total reward: 41.0 Training loss: 67.0444 Explore P: 0.7964\n",
      "Episode: 108 Total reward: 11.0 Training loss: 22.6006 Explore P: 0.7956\n",
      "Episode: 109 Total reward: 10.0 Training loss: 37.1655 Explore P: 0.7948\n",
      "Episode: 110 Total reward: 17.0 Training loss: 13.7900 Explore P: 0.7934\n",
      "Episode: 111 Total reward: 13.0 Training loss: 23.0742 Explore P: 0.7924\n",
      "Episode: 112 Total reward: 12.0 Training loss: 11.4363 Explore P: 0.7915\n",
      "Episode: 113 Total reward: 13.0 Training loss: 12.9333 Explore P: 0.7905\n",
      "Episode: 114 Total reward: 27.0 Training loss: 33.5512 Explore P: 0.7884\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 115 Total reward: 11.0 Training loss: 58.3858 Explore P: 0.7875\n",
      "Episode: 116 Total reward: 14.0 Training loss: 156.3174 Explore P: 0.7864\n",
      "Episode: 117 Total reward: 10.0 Training loss: 29.8580 Explore P: 0.7857\n",
      "Episode: 118 Total reward: 47.0 Training loss: 13.5208 Explore P: 0.7820\n",
      "Episode: 119 Total reward: 17.0 Training loss: 33.8896 Explore P: 0.7807\n",
      "Episode: 120 Total reward: 11.0 Training loss: 30.1755 Explore P: 0.7799\n",
      "Episode: 121 Total reward: 11.0 Training loss: 18.5243 Explore P: 0.7790\n",
      "Episode: 122 Total reward: 13.0 Training loss: 14.0945 Explore P: 0.7780\n",
      "Episode: 123 Total reward: 18.0 Training loss: 44.7529 Explore P: 0.7766\n",
      "Episode: 124 Total reward: 11.0 Training loss: 64.2847 Explore P: 0.7758\n",
      "Episode: 125 Total reward: 33.0 Training loss: 50.0081 Explore P: 0.7733\n",
      "Episode: 126 Total reward: 16.0 Training loss: 84.8965 Explore P: 0.7720\n",
      "Episode: 127 Total reward: 19.0 Training loss: 59.7037 Explore P: 0.7706\n",
      "Episode: 128 Total reward: 14.0 Training loss: 54.0005 Explore P: 0.7695\n",
      "Episode: 129 Total reward: 8.0 Training loss: 26.3322 Explore P: 0.7689\n",
      "Episode: 130 Total reward: 12.0 Training loss: 13.1281 Explore P: 0.7680\n",
      "Episode: 131 Total reward: 16.0 Training loss: 46.6316 Explore P: 0.7668\n",
      "Episode: 132 Total reward: 9.0 Training loss: 32.1813 Explore P: 0.7661\n",
      "Episode: 133 Total reward: 11.0 Training loss: 50.5453 Explore P: 0.7653\n",
      "Episode: 134 Total reward: 11.0 Training loss: 43.9775 Explore P: 0.7645\n",
      "Episode: 135 Total reward: 14.0 Training loss: 60.2937 Explore P: 0.7634\n",
      "Episode: 136 Total reward: 9.0 Training loss: 22.3209 Explore P: 0.7627\n",
      "Episode: 137 Total reward: 12.0 Training loss: 206.8614 Explore P: 0.7618\n",
      "Episode: 138 Total reward: 9.0 Training loss: 42.8383 Explore P: 0.7611\n",
      "Episode: 139 Total reward: 38.0 Training loss: 23.2543 Explore P: 0.7583\n",
      "Episode: 140 Total reward: 35.0 Training loss: 47.2501 Explore P: 0.7557\n",
      "Episode: 141 Total reward: 15.0 Training loss: 82.6170 Explore P: 0.7546\n",
      "Episode: 142 Total reward: 44.0 Training loss: 35.1040 Explore P: 0.7513\n",
      "Episode: 143 Total reward: 11.0 Training loss: 110.3158 Explore P: 0.7505\n",
      "Episode: 144 Total reward: 28.0 Training loss: 28.0299 Explore P: 0.7484\n",
      "Episode: 145 Total reward: 27.0 Training loss: 56.7323 Explore P: 0.7464\n",
      "Episode: 146 Total reward: 29.0 Training loss: 84.0354 Explore P: 0.7443\n",
      "Episode: 147 Total reward: 15.0 Training loss: 22.4206 Explore P: 0.7432\n",
      "Episode: 148 Total reward: 39.0 Training loss: 51.5990 Explore P: 0.7403\n",
      "Episode: 149 Total reward: 16.0 Training loss: 101.3595 Explore P: 0.7392\n",
      "Episode: 150 Total reward: 33.0 Training loss: 50.4387 Explore P: 0.7368\n",
      "Episode: 151 Total reward: 16.0 Training loss: 163.6084 Explore P: 0.7356\n",
      "Episode: 152 Total reward: 47.0 Training loss: 109.6992 Explore P: 0.7322\n",
      "Episode: 153 Total reward: 26.0 Training loss: 76.4961 Explore P: 0.7303\n",
      "Episode: 154 Total reward: 20.0 Training loss: 170.7979 Explore P: 0.7289\n",
      "Episode: 155 Total reward: 13.0 Training loss: 56.3792 Explore P: 0.7280\n",
      "Episode: 156 Total reward: 27.0 Training loss: 157.9975 Explore P: 0.7260\n",
      "Episode: 157 Total reward: 14.0 Training loss: 68.5374 Explore P: 0.7250\n",
      "Episode: 158 Total reward: 9.0 Training loss: 52.8950 Explore P: 0.7244\n",
      "Episode: 159 Total reward: 14.0 Training loss: 147.7233 Explore P: 0.7234\n",
      "Episode: 160 Total reward: 13.0 Training loss: 70.2560 Explore P: 0.7224\n",
      "Episode: 161 Total reward: 13.0 Training loss: 37.3531 Explore P: 0.7215\n",
      "Episode: 162 Total reward: 19.0 Training loss: 102.7931 Explore P: 0.7202\n",
      "Episode: 163 Total reward: 18.0 Training loss: 51.7261 Explore P: 0.7189\n",
      "Episode: 164 Total reward: 20.0 Training loss: 106.0222 Explore P: 0.7175\n",
      "Episode: 165 Total reward: 15.0 Training loss: 48.0082 Explore P: 0.7164\n",
      "Episode: 166 Total reward: 32.0 Training loss: 20.0320 Explore P: 0.7142\n",
      "Episode: 167 Total reward: 25.0 Training loss: 92.3137 Explore P: 0.7124\n",
      "Episode: 168 Total reward: 19.0 Training loss: 158.5394 Explore P: 0.7111\n",
      "Episode: 169 Total reward: 36.0 Training loss: 103.7923 Explore P: 0.7085\n",
      "Episode: 170 Total reward: 22.0 Training loss: 336.8890 Explore P: 0.7070\n",
      "Episode: 171 Total reward: 13.0 Training loss: 75.3120 Explore P: 0.7061\n",
      "Episode: 172 Total reward: 46.0 Training loss: 49.1205 Explore P: 0.7029\n",
      "Episode: 173 Total reward: 26.0 Training loss: 74.5318 Explore P: 0.7011\n",
      "Episode: 174 Total reward: 24.0 Training loss: 54.1959 Explore P: 0.6995\n",
      "Episode: 175 Total reward: 13.0 Training loss: 53.0012 Explore P: 0.6986\n",
      "Episode: 176 Total reward: 23.0 Training loss: 282.1875 Explore P: 0.6970\n",
      "Episode: 177 Total reward: 29.0 Training loss: 32.9602 Explore P: 0.6950\n",
      "Episode: 178 Total reward: 17.0 Training loss: 29.8239 Explore P: 0.6938\n",
      "Episode: 179 Total reward: 10.0 Training loss: 30.1789 Explore P: 0.6931\n",
      "Episode: 180 Total reward: 15.0 Training loss: 18.2855 Explore P: 0.6921\n",
      "Episode: 181 Total reward: 18.0 Training loss: 55.6649 Explore P: 0.6909\n",
      "Episode: 182 Total reward: 13.0 Training loss: 46.1557 Explore P: 0.6900\n",
      "Episode: 183 Total reward: 17.0 Training loss: 15.4610 Explore P: 0.6889\n",
      "Episode: 184 Total reward: 12.0 Training loss: 65.0792 Explore P: 0.6880\n",
      "Episode: 185 Total reward: 12.0 Training loss: 67.6920 Explore P: 0.6872\n",
      "Episode: 186 Total reward: 14.0 Training loss: 22.5953 Explore P: 0.6863\n",
      "Episode: 187 Total reward: 16.0 Training loss: 50.4820 Explore P: 0.6852\n",
      "Episode: 188 Total reward: 20.0 Training loss: 71.7297 Explore P: 0.6838\n",
      "Episode: 189 Total reward: 26.0 Training loss: 222.6361 Explore P: 0.6821\n",
      "Episode: 190 Total reward: 19.0 Training loss: 55.3934 Explore P: 0.6808\n",
      "Episode: 191 Total reward: 22.0 Training loss: 45.8087 Explore P: 0.6793\n",
      "Episode: 192 Total reward: 10.0 Training loss: 76.5594 Explore P: 0.6787\n",
      "Episode: 193 Total reward: 28.0 Training loss: 138.1097 Explore P: 0.6768\n",
      "Episode: 194 Total reward: 13.0 Training loss: 77.6205 Explore P: 0.6759\n",
      "Episode: 195 Total reward: 14.0 Training loss: 67.4759 Explore P: 0.6750\n",
      "Episode: 196 Total reward: 12.0 Training loss: 381.9377 Explore P: 0.6742\n",
      "Episode: 197 Total reward: 17.0 Training loss: 50.5615 Explore P: 0.6731\n",
      "Episode: 198 Total reward: 10.0 Training loss: 80.4720 Explore P: 0.6724\n",
      "Episode: 199 Total reward: 8.0 Training loss: 95.8312 Explore P: 0.6719\n",
      "Episode: 200 Total reward: 20.0 Training loss: 124.9972 Explore P: 0.6706\n",
      "Episode: 201 Total reward: 17.0 Training loss: 56.8621 Explore P: 0.6694\n",
      "Episode: 202 Total reward: 14.0 Training loss: 123.1231 Explore P: 0.6685\n",
      "Episode: 203 Total reward: 10.0 Training loss: 197.1234 Explore P: 0.6679\n",
      "Episode: 204 Total reward: 22.0 Training loss: 124.9840 Explore P: 0.6664\n",
      "Episode: 205 Total reward: 9.0 Training loss: 96.5752 Explore P: 0.6658\n",
      "Episode: 206 Total reward: 30.0 Training loss: 80.0985 Explore P: 0.6639\n",
      "Episode: 207 Total reward: 10.0 Training loss: 143.7013 Explore P: 0.6632\n",
      "Episode: 208 Total reward: 15.0 Training loss: 45.3068 Explore P: 0.6622\n",
      "Episode: 209 Total reward: 34.0 Training loss: 42.3062 Explore P: 0.6600\n",
      "Episode: 210 Total reward: 27.0 Training loss: 127.8767 Explore P: 0.6583\n",
      "Episode: 211 Total reward: 18.0 Training loss: 98.5568 Explore P: 0.6571\n",
      "Episode: 212 Total reward: 21.0 Training loss: 73.0134 Explore P: 0.6557\n",
      "Episode: 213 Total reward: 12.0 Training loss: 121.1473 Explore P: 0.6550\n",
      "Episode: 214 Total reward: 17.0 Training loss: 198.8167 Explore P: 0.6539\n",
      "Episode: 215 Total reward: 10.0 Training loss: 193.0030 Explore P: 0.6532\n",
      "Episode: 216 Total reward: 12.0 Training loss: 131.9207 Explore P: 0.6525\n",
      "Episode: 217 Total reward: 35.0 Training loss: 44.7320 Explore P: 0.6502\n",
      "Episode: 218 Total reward: 19.0 Training loss: 65.4684 Explore P: 0.6490\n",
      "Episode: 219 Total reward: 18.0 Training loss: 50.9041 Explore P: 0.6479\n",
      "Episode: 220 Total reward: 11.0 Training loss: 61.7284 Explore P: 0.6471\n",
      "Episode: 221 Total reward: 22.0 Training loss: 128.3127 Explore P: 0.6457\n",
      "Episode: 222 Total reward: 13.0 Training loss: 27.3976 Explore P: 0.6449\n",
      "Episode: 223 Total reward: 10.0 Training loss: 43.6368 Explore P: 0.6443\n",
      "Episode: 224 Total reward: 27.0 Training loss: 99.4066 Explore P: 0.6426\n",
      "Episode: 225 Total reward: 31.0 Training loss: 109.7102 Explore P: 0.6406\n",
      "Episode: 226 Total reward: 8.0 Training loss: 108.2186 Explore P: 0.6401\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 227 Total reward: 41.0 Training loss: 123.1595 Explore P: 0.6375\n",
      "Episode: 228 Total reward: 18.0 Training loss: 218.7782 Explore P: 0.6364\n",
      "Episode: 229 Total reward: 11.0 Training loss: 90.7480 Explore P: 0.6357\n",
      "Episode: 230 Total reward: 43.0 Training loss: 79.1417 Explore P: 0.6330\n",
      "Episode: 231 Total reward: 35.0 Training loss: 133.7305 Explore P: 0.6309\n",
      "Episode: 232 Total reward: 13.0 Training loss: 68.2368 Explore P: 0.6301\n",
      "Episode: 233 Total reward: 17.0 Training loss: 96.4765 Explore P: 0.6290\n",
      "Episode: 234 Total reward: 9.0 Training loss: 125.5867 Explore P: 0.6284\n",
      "Episode: 235 Total reward: 17.0 Training loss: 145.2978 Explore P: 0.6274\n",
      "Episode: 236 Total reward: 19.0 Training loss: 402.7740 Explore P: 0.6262\n",
      "Episode: 237 Total reward: 21.0 Training loss: 99.0446 Explore P: 0.6249\n",
      "Episode: 238 Total reward: 11.0 Training loss: 52.2116 Explore P: 0.6243\n",
      "Episode: 239 Total reward: 13.0 Training loss: 37.9457 Explore P: 0.6235\n",
      "Episode: 240 Total reward: 12.0 Training loss: 85.6891 Explore P: 0.6227\n",
      "Episode: 241 Total reward: 7.0 Training loss: 98.4123 Explore P: 0.6223\n",
      "Episode: 242 Total reward: 12.0 Training loss: 77.6411 Explore P: 0.6216\n",
      "Episode: 243 Total reward: 12.0 Training loss: 94.4668 Explore P: 0.6208\n",
      "Episode: 244 Total reward: 14.0 Training loss: 160.2748 Explore P: 0.6200\n",
      "Episode: 245 Total reward: 13.0 Training loss: 57.2288 Explore P: 0.6192\n",
      "Episode: 246 Total reward: 24.0 Training loss: 63.9163 Explore P: 0.6177\n",
      "Episode: 247 Total reward: 32.0 Training loss: 184.9795 Explore P: 0.6158\n",
      "Episode: 248 Total reward: 9.0 Training loss: 109.1466 Explore P: 0.6152\n",
      "Episode: 249 Total reward: 10.0 Training loss: 100.5756 Explore P: 0.6146\n",
      "Episode: 250 Total reward: 11.0 Training loss: 113.3949 Explore P: 0.6140\n",
      "Episode: 251 Total reward: 8.0 Training loss: 122.1208 Explore P: 0.6135\n",
      "Episode: 252 Total reward: 9.0 Training loss: 64.5081 Explore P: 0.6129\n",
      "Episode: 253 Total reward: 13.0 Training loss: 36.6628 Explore P: 0.6121\n",
      "Episode: 254 Total reward: 9.0 Training loss: 135.2485 Explore P: 0.6116\n",
      "Episode: 255 Total reward: 13.0 Training loss: 250.2751 Explore P: 0.6108\n",
      "Episode: 256 Total reward: 30.0 Training loss: 38.3673 Explore P: 0.6090\n",
      "Episode: 257 Total reward: 18.0 Training loss: 204.3433 Explore P: 0.6079\n",
      "Episode: 258 Total reward: 9.0 Training loss: 76.9949 Explore P: 0.6074\n",
      "Episode: 259 Total reward: 11.0 Training loss: 187.9339 Explore P: 0.6068\n",
      "Episode: 260 Total reward: 17.0 Training loss: 33.1134 Explore P: 0.6057\n",
      "Episode: 261 Total reward: 11.0 Training loss: 73.9862 Explore P: 0.6051\n",
      "Episode: 262 Total reward: 11.0 Training loss: 73.9985 Explore P: 0.6044\n",
      "Episode: 263 Total reward: 10.0 Training loss: 428.8202 Explore P: 0.6038\n",
      "Episode: 264 Total reward: 17.0 Training loss: 92.6764 Explore P: 0.6028\n",
      "Episode: 265 Total reward: 21.0 Training loss: 121.7846 Explore P: 0.6016\n",
      "Episode: 266 Total reward: 26.0 Training loss: 78.5100 Explore P: 0.6000\n",
      "Episode: 267 Total reward: 12.0 Training loss: 109.1672 Explore P: 0.5993\n",
      "Episode: 268 Total reward: 15.0 Training loss: 142.8921 Explore P: 0.5985\n",
      "Episode: 269 Total reward: 24.0 Training loss: 251.9036 Explore P: 0.5970\n",
      "Episode: 270 Total reward: 11.0 Training loss: 145.7642 Explore P: 0.5964\n",
      "Episode: 271 Total reward: 9.0 Training loss: 124.0730 Explore P: 0.5959\n",
      "Episode: 272 Total reward: 16.0 Training loss: 156.5361 Explore P: 0.5949\n",
      "Episode: 273 Total reward: 17.0 Training loss: 55.1942 Explore P: 0.5939\n",
      "Episode: 274 Total reward: 9.0 Training loss: 163.5734 Explore P: 0.5934\n",
      "Episode: 275 Total reward: 10.0 Training loss: 669.4835 Explore P: 0.5928\n",
      "Episode: 276 Total reward: 9.0 Training loss: 324.1281 Explore P: 0.5923\n",
      "Episode: 277 Total reward: 11.0 Training loss: 184.4491 Explore P: 0.5917\n",
      "Episode: 278 Total reward: 16.0 Training loss: 122.4089 Explore P: 0.5907\n",
      "Episode: 279 Total reward: 35.0 Training loss: 89.4364 Explore P: 0.5887\n",
      "Episode: 280 Total reward: 10.0 Training loss: 83.9469 Explore P: 0.5881\n",
      "Episode: 281 Total reward: 20.0 Training loss: 72.7325 Explore P: 0.5870\n",
      "Episode: 282 Total reward: 8.0 Training loss: 117.3063 Explore P: 0.5865\n",
      "Episode: 283 Total reward: 28.0 Training loss: 278.7934 Explore P: 0.5849\n",
      "Episode: 284 Total reward: 21.0 Training loss: 192.6248 Explore P: 0.5837\n",
      "Episode: 285 Total reward: 13.0 Training loss: 113.4151 Explore P: 0.5830\n",
      "Episode: 286 Total reward: 15.0 Training loss: 144.2747 Explore P: 0.5821\n",
      "Episode: 287 Total reward: 10.0 Training loss: 118.7858 Explore P: 0.5815\n",
      "Episode: 288 Total reward: 13.0 Training loss: 204.7086 Explore P: 0.5808\n",
      "Episode: 289 Total reward: 21.0 Training loss: 207.5291 Explore P: 0.5796\n",
      "Episode: 290 Total reward: 17.0 Training loss: 84.6661 Explore P: 0.5786\n",
      "Episode: 291 Total reward: 16.0 Training loss: 133.4480 Explore P: 0.5777\n",
      "Episode: 292 Total reward: 32.0 Training loss: 252.6870 Explore P: 0.5759\n",
      "Episode: 293 Total reward: 10.0 Training loss: 58.5342 Explore P: 0.5753\n",
      "Episode: 294 Total reward: 13.0 Training loss: 79.6737 Explore P: 0.5746\n",
      "Episode: 295 Total reward: 10.0 Training loss: 574.5673 Explore P: 0.5740\n",
      "Episode: 296 Total reward: 16.0 Training loss: 95.2112 Explore P: 0.5731\n",
      "Episode: 297 Total reward: 8.0 Training loss: 112.8501 Explore P: 0.5727\n",
      "Episode: 298 Total reward: 16.0 Training loss: 101.5614 Explore P: 0.5718\n",
      "Episode: 299 Total reward: 11.0 Training loss: 174.9573 Explore P: 0.5712\n",
      "Episode: 300 Total reward: 12.0 Training loss: 89.9995 Explore P: 0.5705\n",
      "Episode: 301 Total reward: 13.0 Training loss: 137.8528 Explore P: 0.5698\n",
      "Episode: 302 Total reward: 11.0 Training loss: 93.9696 Explore P: 0.5691\n",
      "Episode: 303 Total reward: 13.0 Training loss: 203.2022 Explore P: 0.5684\n",
      "Episode: 304 Total reward: 11.0 Training loss: 96.2267 Explore P: 0.5678\n",
      "Episode: 305 Total reward: 12.0 Training loss: 77.0072 Explore P: 0.5671\n",
      "Episode: 306 Total reward: 12.0 Training loss: 119.3241 Explore P: 0.5665\n",
      "Episode: 307 Total reward: 12.0 Training loss: 118.7427 Explore P: 0.5658\n",
      "Episode: 308 Total reward: 27.0 Training loss: 93.5750 Explore P: 0.5643\n",
      "Episode: 309 Total reward: 10.0 Training loss: 143.6585 Explore P: 0.5637\n",
      "Episode: 310 Total reward: 12.0 Training loss: 94.6976 Explore P: 0.5631\n",
      "Episode: 311 Total reward: 12.0 Training loss: 157.8277 Explore P: 0.5624\n",
      "Episode: 312 Total reward: 13.0 Training loss: 182.9211 Explore P: 0.5617\n",
      "Episode: 313 Total reward: 11.0 Training loss: 145.6251 Explore P: 0.5611\n",
      "Episode: 314 Total reward: 10.0 Training loss: 634.1552 Explore P: 0.5605\n",
      "Episode: 315 Total reward: 10.0 Training loss: 155.0091 Explore P: 0.5600\n",
      "Episode: 316 Total reward: 11.0 Training loss: 174.8441 Explore P: 0.5594\n",
      "Episode: 317 Total reward: 26.0 Training loss: 121.5269 Explore P: 0.5580\n",
      "Episode: 318 Total reward: 13.0 Training loss: 215.0269 Explore P: 0.5572\n",
      "Episode: 319 Total reward: 25.0 Training loss: 77.0931 Explore P: 0.5559\n",
      "Episode: 320 Total reward: 28.0 Training loss: 155.0620 Explore P: 0.5544\n",
      "Episode: 321 Total reward: 10.0 Training loss: 236.4774 Explore P: 0.5538\n",
      "Episode: 322 Total reward: 11.0 Training loss: 174.0690 Explore P: 0.5532\n",
      "Episode: 323 Total reward: 17.0 Training loss: 64.2561 Explore P: 0.5523\n",
      "Episode: 324 Total reward: 21.0 Training loss: 54.5413 Explore P: 0.5512\n",
      "Episode: 325 Total reward: 24.0 Training loss: 175.5901 Explore P: 0.5499\n",
      "Episode: 326 Total reward: 10.0 Training loss: 408.0069 Explore P: 0.5493\n",
      "Episode: 327 Total reward: 10.0 Training loss: 111.1748 Explore P: 0.5488\n",
      "Episode: 328 Total reward: 14.0 Training loss: 144.0922 Explore P: 0.5480\n",
      "Episode: 329 Total reward: 18.0 Training loss: 179.1109 Explore P: 0.5471\n",
      "Episode: 330 Total reward: 13.0 Training loss: 454.9702 Explore P: 0.5464\n",
      "Episode: 331 Total reward: 13.0 Training loss: 68.3079 Explore P: 0.5457\n",
      "Episode: 332 Total reward: 13.0 Training loss: 67.1750 Explore P: 0.5450\n",
      "Episode: 333 Total reward: 17.0 Training loss: 495.5692 Explore P: 0.5441\n",
      "Episode: 334 Total reward: 13.0 Training loss: 143.1910 Explore P: 0.5434\n",
      "Episode: 335 Total reward: 8.0 Training loss: 279.9463 Explore P: 0.5429\n",
      "Episode: 336 Total reward: 15.0 Training loss: 203.9273 Explore P: 0.5421\n",
      "Episode: 337 Total reward: 16.0 Training loss: 281.6890 Explore P: 0.5413\n",
      "Episode: 338 Total reward: 9.0 Training loss: 598.1991 Explore P: 0.5408\n",
      "Episode: 339 Total reward: 10.0 Training loss: 107.4159 Explore P: 0.5403\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 340 Total reward: 11.0 Training loss: 121.6161 Explore P: 0.5397\n",
      "Episode: 341 Total reward: 17.0 Training loss: 258.4526 Explore P: 0.5388\n",
      "Episode: 342 Total reward: 16.0 Training loss: 549.2612 Explore P: 0.5380\n",
      "Episode: 343 Total reward: 47.0 Training loss: 68.7500 Explore P: 0.5355\n",
      "Episode: 344 Total reward: 10.0 Training loss: 503.6154 Explore P: 0.5350\n",
      "Episode: 345 Total reward: 9.0 Training loss: 142.3783 Explore P: 0.5345\n",
      "Episode: 346 Total reward: 11.0 Training loss: 47.4566 Explore P: 0.5339\n",
      "Episode: 347 Total reward: 12.0 Training loss: 113.2213 Explore P: 0.5333\n",
      "Episode: 348 Total reward: 13.0 Training loss: 185.3131 Explore P: 0.5326\n",
      "Episode: 349 Total reward: 26.0 Training loss: 80.8375 Explore P: 0.5312\n",
      "Episode: 350 Total reward: 9.0 Training loss: 429.9455 Explore P: 0.5308\n",
      "Episode: 351 Total reward: 13.0 Training loss: 38.7454 Explore P: 0.5301\n",
      "Episode: 352 Total reward: 12.0 Training loss: 157.3003 Explore P: 0.5295\n",
      "Episode: 353 Total reward: 14.0 Training loss: 123.3258 Explore P: 0.5287\n",
      "Episode: 354 Total reward: 8.0 Training loss: 268.3320 Explore P: 0.5283\n",
      "Episode: 355 Total reward: 13.0 Training loss: 175.0130 Explore P: 0.5277\n",
      "Episode: 356 Total reward: 8.0 Training loss: 318.4383 Explore P: 0.5272\n",
      "Episode: 357 Total reward: 17.0 Training loss: 118.0517 Explore P: 0.5264\n",
      "Episode: 358 Total reward: 15.0 Training loss: 237.6721 Explore P: 0.5256\n",
      "Episode: 359 Total reward: 11.0 Training loss: 104.3936 Explore P: 0.5250\n",
      "Episode: 360 Total reward: 17.0 Training loss: 81.3484 Explore P: 0.5241\n",
      "Episode: 361 Total reward: 15.0 Training loss: 38.4241 Explore P: 0.5234\n",
      "Episode: 362 Total reward: 18.0 Training loss: 119.7496 Explore P: 0.5225\n",
      "Episode: 363 Total reward: 38.0 Training loss: 143.9407 Explore P: 0.5205\n",
      "Episode: 364 Total reward: 9.0 Training loss: 161.1852 Explore P: 0.5200\n",
      "Episode: 365 Total reward: 14.0 Training loss: 280.3065 Explore P: 0.5193\n",
      "Episode: 366 Total reward: 8.0 Training loss: 102.1965 Explore P: 0.5189\n",
      "Episode: 367 Total reward: 15.0 Training loss: 73.2214 Explore P: 0.5182\n",
      "Episode: 368 Total reward: 14.0 Training loss: 213.0039 Explore P: 0.5175\n",
      "Episode: 369 Total reward: 15.0 Training loss: 237.3138 Explore P: 0.5167\n",
      "Episode: 370 Total reward: 9.0 Training loss: 384.3485 Explore P: 0.5162\n",
      "Episode: 371 Total reward: 9.0 Training loss: 69.1989 Explore P: 0.5158\n",
      "Episode: 372 Total reward: 18.0 Training loss: 165.9642 Explore P: 0.5149\n",
      "Episode: 373 Total reward: 15.0 Training loss: 263.9758 Explore P: 0.5141\n",
      "Episode: 374 Total reward: 15.0 Training loss: 73.2259 Explore P: 0.5134\n",
      "Episode: 375 Total reward: 12.0 Training loss: 182.1640 Explore P: 0.5128\n",
      "Episode: 376 Total reward: 8.0 Training loss: 206.6864 Explore P: 0.5124\n",
      "Episode: 377 Total reward: 20.0 Training loss: 112.5144 Explore P: 0.5114\n",
      "Episode: 378 Total reward: 21.0 Training loss: 106.0616 Explore P: 0.5103\n",
      "Episode: 379 Total reward: 13.0 Training loss: 340.0457 Explore P: 0.5096\n",
      "Episode: 380 Total reward: 11.0 Training loss: 213.9112 Explore P: 0.5091\n",
      "Episode: 381 Total reward: 20.0 Training loss: 207.7551 Explore P: 0.5081\n",
      "Episode: 382 Total reward: 39.0 Training loss: 185.8905 Explore P: 0.5062\n",
      "Episode: 383 Total reward: 31.0 Training loss: 415.9492 Explore P: 0.5046\n",
      "Episode: 384 Total reward: 14.0 Training loss: 590.1683 Explore P: 0.5039\n",
      "Episode: 385 Total reward: 11.0 Training loss: 87.6477 Explore P: 0.5034\n",
      "Episode: 386 Total reward: 18.0 Training loss: 275.0165 Explore P: 0.5025\n",
      "Episode: 387 Total reward: 13.0 Training loss: 285.2333 Explore P: 0.5019\n",
      "Episode: 388 Total reward: 15.0 Training loss: 163.9300 Explore P: 0.5011\n",
      "Episode: 389 Total reward: 9.0 Training loss: 193.9899 Explore P: 0.5007\n",
      "Episode: 390 Total reward: 11.0 Training loss: 181.1706 Explore P: 0.5001\n",
      "Episode: 391 Total reward: 12.0 Training loss: 264.6515 Explore P: 0.4996\n",
      "Episode: 392 Total reward: 11.0 Training loss: 332.1066 Explore P: 0.4990\n",
      "Episode: 393 Total reward: 34.0 Training loss: 315.9380 Explore P: 0.4974\n",
      "Episode: 394 Total reward: 24.0 Training loss: 218.7486 Explore P: 0.4962\n",
      "Episode: 395 Total reward: 12.0 Training loss: 156.8619 Explore P: 0.4956\n",
      "Episode: 396 Total reward: 14.0 Training loss: 74.3382 Explore P: 0.4949\n",
      "Episode: 397 Total reward: 10.0 Training loss: 418.7691 Explore P: 0.4944\n",
      "Episode: 398 Total reward: 13.0 Training loss: 318.2361 Explore P: 0.4938\n",
      "Episode: 399 Total reward: 15.0 Training loss: 752.6528 Explore P: 0.4931\n",
      "Episode: 400 Total reward: 14.0 Training loss: 158.7414 Explore P: 0.4924\n",
      "Episode: 401 Total reward: 10.0 Training loss: 83.8249 Explore P: 0.4919\n",
      "Episode: 402 Total reward: 22.0 Training loss: 252.6207 Explore P: 0.4909\n",
      "Episode: 403 Total reward: 11.0 Training loss: 271.7007 Explore P: 0.4903\n",
      "Episode: 404 Total reward: 8.0 Training loss: 226.2843 Explore P: 0.4900\n",
      "Episode: 405 Total reward: 24.0 Training loss: 629.2672 Explore P: 0.4888\n",
      "Episode: 406 Total reward: 16.0 Training loss: 551.3875 Explore P: 0.4880\n",
      "Episode: 407 Total reward: 20.0 Training loss: 248.0755 Explore P: 0.4871\n",
      "Episode: 408 Total reward: 27.0 Training loss: 204.6754 Explore P: 0.4858\n",
      "Episode: 409 Total reward: 20.0 Training loss: 117.1786 Explore P: 0.4849\n",
      "Episode: 410 Total reward: 13.0 Training loss: 147.1409 Explore P: 0.4842\n",
      "Episode: 411 Total reward: 12.0 Training loss: 148.8064 Explore P: 0.4837\n",
      "Episode: 412 Total reward: 25.0 Training loss: 197.2759 Explore P: 0.4825\n",
      "Episode: 413 Total reward: 11.0 Training loss: 932.9669 Explore P: 0.4820\n",
      "Episode: 414 Total reward: 11.0 Training loss: 105.8249 Explore P: 0.4814\n",
      "Episode: 415 Total reward: 11.0 Training loss: 187.1152 Explore P: 0.4809\n",
      "Episode: 416 Total reward: 19.0 Training loss: 161.1775 Explore P: 0.4800\n",
      "Episode: 417 Total reward: 9.0 Training loss: 154.6369 Explore P: 0.4796\n",
      "Episode: 418 Total reward: 12.0 Training loss: 385.8853 Explore P: 0.4790\n",
      "Episode: 419 Total reward: 10.0 Training loss: 197.4726 Explore P: 0.4786\n",
      "Episode: 420 Total reward: 19.0 Training loss: 102.8948 Explore P: 0.4777\n",
      "Episode: 421 Total reward: 18.0 Training loss: 64.9582 Explore P: 0.4768\n",
      "Episode: 422 Total reward: 15.0 Training loss: 839.5194 Explore P: 0.4761\n",
      "Episode: 423 Total reward: 14.0 Training loss: 403.8964 Explore P: 0.4755\n",
      "Episode: 424 Total reward: 10.0 Training loss: 195.7261 Explore P: 0.4750\n",
      "Episode: 425 Total reward: 10.0 Training loss: 623.8596 Explore P: 0.4746\n",
      "Episode: 426 Total reward: 8.0 Training loss: 183.0565 Explore P: 0.4742\n",
      "Episode: 427 Total reward: 12.0 Training loss: 169.2454 Explore P: 0.4736\n",
      "Episode: 428 Total reward: 19.0 Training loss: 218.3531 Explore P: 0.4728\n",
      "Episode: 429 Total reward: 10.0 Training loss: 84.5876 Explore P: 0.4723\n",
      "Episode: 430 Total reward: 19.0 Training loss: 195.7143 Explore P: 0.4714\n",
      "Episode: 431 Total reward: 9.0 Training loss: 82.7337 Explore P: 0.4710\n",
      "Episode: 432 Total reward: 13.0 Training loss: 317.5826 Explore P: 0.4704\n",
      "Episode: 433 Total reward: 11.0 Training loss: 94.5559 Explore P: 0.4699\n",
      "Episode: 434 Total reward: 10.0 Training loss: 174.5314 Explore P: 0.4694\n",
      "Episode: 435 Total reward: 15.0 Training loss: 317.2519 Explore P: 0.4687\n",
      "Episode: 436 Total reward: 10.0 Training loss: 338.2471 Explore P: 0.4683\n",
      "Episode: 437 Total reward: 9.0 Training loss: 191.1447 Explore P: 0.4679\n",
      "Episode: 438 Total reward: 9.0 Training loss: 83.5950 Explore P: 0.4675\n",
      "Episode: 439 Total reward: 11.0 Training loss: 352.8808 Explore P: 0.4670\n",
      "Episode: 440 Total reward: 7.0 Training loss: 179.7099 Explore P: 0.4666\n",
      "Episode: 441 Total reward: 12.0 Training loss: 183.7903 Explore P: 0.4661\n",
      "Episode: 442 Total reward: 9.0 Training loss: 69.7123 Explore P: 0.4657\n",
      "Episode: 443 Total reward: 16.0 Training loss: 231.6440 Explore P: 0.4650\n",
      "Episode: 444 Total reward: 14.0 Training loss: 544.6058 Explore P: 0.4643\n",
      "Episode: 445 Total reward: 26.0 Training loss: 216.0842 Explore P: 0.4631\n",
      "Episode: 446 Total reward: 12.0 Training loss: 211.9236 Explore P: 0.4626\n",
      "Episode: 447 Total reward: 9.0 Training loss: 90.3483 Explore P: 0.4622\n",
      "Episode: 448 Total reward: 13.0 Training loss: 224.6003 Explore P: 0.4616\n",
      "Episode: 449 Total reward: 11.0 Training loss: 113.4499 Explore P: 0.4611\n",
      "Episode: 450 Total reward: 14.0 Training loss: 209.5835 Explore P: 0.4605\n",
      "Episode: 451 Total reward: 12.0 Training loss: 159.1547 Explore P: 0.4599\n",
      "Episode: 452 Total reward: 13.0 Training loss: 560.2451 Explore P: 0.4594\n",
      "Episode: 453 Total reward: 12.0 Training loss: 190.6985 Explore P: 0.4588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 454 Total reward: 11.0 Training loss: 218.9820 Explore P: 0.4583\n",
      "Episode: 455 Total reward: 15.0 Training loss: 192.1127 Explore P: 0.4576\n",
      "Episode: 456 Total reward: 15.0 Training loss: 104.5276 Explore P: 0.4570\n",
      "Episode: 457 Total reward: 12.0 Training loss: 233.4664 Explore P: 0.4564\n",
      "Episode: 458 Total reward: 9.0 Training loss: 427.3822 Explore P: 0.4560\n",
      "Episode: 459 Total reward: 10.0 Training loss: 417.2458 Explore P: 0.4556\n",
      "Episode: 460 Total reward: 10.0 Training loss: 369.2206 Explore P: 0.4551\n",
      "Episode: 461 Total reward: 8.0 Training loss: 672.7832 Explore P: 0.4548\n",
      "Episode: 462 Total reward: 8.0 Training loss: 128.7998 Explore P: 0.4544\n",
      "Episode: 463 Total reward: 13.0 Training loss: 173.7343 Explore P: 0.4539\n",
      "Episode: 464 Total reward: 15.0 Training loss: 134.2703 Explore P: 0.4532\n",
      "Episode: 465 Total reward: 12.0 Training loss: 233.2464 Explore P: 0.4527\n",
      "Episode: 466 Total reward: 9.0 Training loss: 266.2939 Explore P: 0.4523\n",
      "Episode: 467 Total reward: 10.0 Training loss: 796.6432 Explore P: 0.4518\n",
      "Episode: 468 Total reward: 10.0 Training loss: 1057.9592 Explore P: 0.4514\n",
      "Episode: 469 Total reward: 33.0 Training loss: 300.9814 Explore P: 0.4499\n",
      "Episode: 470 Total reward: 15.0 Training loss: 718.7905 Explore P: 0.4493\n",
      "Episode: 471 Total reward: 9.0 Training loss: 307.9871 Explore P: 0.4489\n",
      "Episode: 472 Total reward: 13.0 Training loss: 1012.7098 Explore P: 0.4483\n",
      "Episode: 473 Total reward: 11.0 Training loss: 205.1965 Explore P: 0.4478\n",
      "Episode: 474 Total reward: 11.0 Training loss: 950.7331 Explore P: 0.4473\n",
      "Episode: 475 Total reward: 15.0 Training loss: 207.2321 Explore P: 0.4467\n",
      "Episode: 476 Total reward: 11.0 Training loss: 260.0867 Explore P: 0.4462\n",
      "Episode: 477 Total reward: 8.0 Training loss: 248.9490 Explore P: 0.4459\n",
      "Episode: 478 Total reward: 10.0 Training loss: 297.4128 Explore P: 0.4454\n",
      "Episode: 479 Total reward: 12.0 Training loss: 793.0015 Explore P: 0.4449\n",
      "Episode: 480 Total reward: 9.0 Training loss: 200.4697 Explore P: 0.4445\n",
      "Episode: 481 Total reward: 11.0 Training loss: 231.0546 Explore P: 0.4440\n",
      "Episode: 482 Total reward: 14.0 Training loss: 69.1057 Explore P: 0.4434\n",
      "Episode: 483 Total reward: 8.0 Training loss: 192.5785 Explore P: 0.4431\n",
      "Episode: 484 Total reward: 15.0 Training loss: 147.1517 Explore P: 0.4424\n",
      "Episode: 485 Total reward: 11.0 Training loss: 247.6509 Explore P: 0.4419\n",
      "Episode: 486 Total reward: 12.0 Training loss: 118.3215 Explore P: 0.4414\n",
      "Episode: 487 Total reward: 12.0 Training loss: 257.6693 Explore P: 0.4409\n",
      "Episode: 488 Total reward: 16.0 Training loss: 264.8089 Explore P: 0.4402\n",
      "Episode: 489 Total reward: 8.0 Training loss: 126.0883 Explore P: 0.4399\n",
      "Episode: 490 Total reward: 9.0 Training loss: 124.1913 Explore P: 0.4395\n",
      "Episode: 491 Total reward: 7.0 Training loss: 116.9720 Explore P: 0.4392\n",
      "Episode: 492 Total reward: 13.0 Training loss: 204.1711 Explore P: 0.4386\n",
      "Episode: 493 Total reward: 13.0 Training loss: 245.1913 Explore P: 0.4381\n",
      "Episode: 494 Total reward: 17.0 Training loss: 60.9958 Explore P: 0.4374\n",
      "Episode: 495 Total reward: 7.0 Training loss: 214.8998 Explore P: 0.4371\n",
      "Episode: 496 Total reward: 11.0 Training loss: 436.0982 Explore P: 0.4366\n",
      "Episode: 497 Total reward: 13.0 Training loss: 255.0993 Explore P: 0.4360\n",
      "Episode: 498 Total reward: 18.0 Training loss: 251.1933 Explore P: 0.4353\n",
      "Episode: 499 Total reward: 12.0 Training loss: 152.3213 Explore P: 0.4348\n",
      "Episode: 500 Total reward: 20.0 Training loss: 558.5099 Explore P: 0.4339\n",
      "Episode: 501 Total reward: 14.0 Training loss: 175.8369 Explore P: 0.4333\n",
      "Episode: 502 Total reward: 23.0 Training loss: 411.8255 Explore P: 0.4323\n",
      "Episode: 503 Total reward: 11.0 Training loss: 613.0670 Explore P: 0.4319\n",
      "Episode: 504 Total reward: 8.0 Training loss: 125.1817 Explore P: 0.4315\n",
      "Episode: 505 Total reward: 8.0 Training loss: 167.0476 Explore P: 0.4312\n",
      "Episode: 506 Total reward: 33.0 Training loss: 71.7050 Explore P: 0.4298\n",
      "Episode: 507 Total reward: 11.0 Training loss: 252.4048 Explore P: 0.4293\n",
      "Episode: 508 Total reward: 11.0 Training loss: 190.8163 Explore P: 0.4289\n",
      "Episode: 509 Total reward: 14.0 Training loss: 105.8214 Explore P: 0.4283\n",
      "Episode: 510 Total reward: 7.0 Training loss: 300.1211 Explore P: 0.4280\n",
      "Episode: 511 Total reward: 9.0 Training loss: 227.2681 Explore P: 0.4276\n",
      "Episode: 512 Total reward: 12.0 Training loss: 248.3735 Explore P: 0.4271\n",
      "Episode: 513 Total reward: 13.0 Training loss: 103.2708 Explore P: 0.4266\n",
      "Episode: 514 Total reward: 16.0 Training loss: 260.7954 Explore P: 0.4259\n",
      "Episode: 515 Total reward: 12.0 Training loss: 221.2379 Explore P: 0.4254\n",
      "Episode: 516 Total reward: 16.0 Training loss: 187.5299 Explore P: 0.4248\n",
      "Episode: 517 Total reward: 10.0 Training loss: 153.9618 Explore P: 0.4243\n",
      "Episode: 518 Total reward: 9.0 Training loss: 280.7007 Explore P: 0.4240\n",
      "Episode: 519 Total reward: 18.0 Training loss: 937.8553 Explore P: 0.4232\n",
      "Episode: 520 Total reward: 8.0 Training loss: 478.8307 Explore P: 0.4229\n",
      "Episode: 521 Total reward: 17.0 Training loss: 190.7682 Explore P: 0.4222\n",
      "Episode: 522 Total reward: 13.0 Training loss: 129.2911 Explore P: 0.4217\n",
      "Episode: 523 Total reward: 13.0 Training loss: 89.7149 Explore P: 0.4211\n",
      "Episode: 524 Total reward: 11.0 Training loss: 141.8072 Explore P: 0.4207\n",
      "Episode: 525 Total reward: 9.0 Training loss: 241.8924 Explore P: 0.4203\n",
      "Episode: 526 Total reward: 12.0 Training loss: 340.7635 Explore P: 0.4198\n",
      "Episode: 527 Total reward: 14.0 Training loss: 200.9500 Explore P: 0.4192\n",
      "Episode: 528 Total reward: 9.0 Training loss: 796.6603 Explore P: 0.4189\n",
      "Episode: 529 Total reward: 10.0 Training loss: 284.9188 Explore P: 0.4185\n",
      "Episode: 530 Total reward: 14.0 Training loss: 977.3480 Explore P: 0.4179\n",
      "Episode: 531 Total reward: 13.0 Training loss: 323.4111 Explore P: 0.4174\n",
      "Episode: 532 Total reward: 14.0 Training loss: 298.6383 Explore P: 0.4168\n",
      "Episode: 533 Total reward: 13.0 Training loss: 343.9503 Explore P: 0.4163\n",
      "Episode: 534 Total reward: 9.0 Training loss: 253.3468 Explore P: 0.4159\n",
      "Episode: 535 Total reward: 11.0 Training loss: 2641.3828 Explore P: 0.4155\n",
      "Episode: 536 Total reward: 8.0 Training loss: 128.5807 Explore P: 0.4151\n",
      "Episode: 537 Total reward: 15.0 Training loss: 1181.5325 Explore P: 0.4145\n",
      "Episode: 538 Total reward: 25.0 Training loss: 259.6992 Explore P: 0.4135\n",
      "Episode: 539 Total reward: 12.0 Training loss: 277.7652 Explore P: 0.4130\n",
      "Episode: 540 Total reward: 11.0 Training loss: 126.2190 Explore P: 0.4126\n",
      "Episode: 541 Total reward: 8.0 Training loss: 416.6021 Explore P: 0.4123\n",
      "Episode: 542 Total reward: 8.0 Training loss: 422.2144 Explore P: 0.4119\n",
      "Episode: 543 Total reward: 10.0 Training loss: 191.6139 Explore P: 0.4115\n",
      "Episode: 544 Total reward: 14.0 Training loss: 191.4141 Explore P: 0.4110\n",
      "Episode: 545 Total reward: 20.0 Training loss: 788.5755 Explore P: 0.4102\n",
      "Episode: 546 Total reward: 15.0 Training loss: 389.2628 Explore P: 0.4096\n",
      "Episode: 547 Total reward: 19.0 Training loss: 182.0874 Explore P: 0.4088\n",
      "Episode: 548 Total reward: 24.0 Training loss: 389.5721 Explore P: 0.4079\n",
      "Episode: 549 Total reward: 11.0 Training loss: 459.2416 Explore P: 0.4074\n",
      "Episode: 550 Total reward: 12.0 Training loss: 800.1395 Explore P: 0.4069\n",
      "Episode: 551 Total reward: 12.0 Training loss: 503.5432 Explore P: 0.4065\n",
      "Episode: 552 Total reward: 18.0 Training loss: 238.2863 Explore P: 0.4058\n",
      "Episode: 553 Total reward: 9.0 Training loss: 328.4688 Explore P: 0.4054\n",
      "Episode: 554 Total reward: 10.0 Training loss: 341.1567 Explore P: 0.4050\n",
      "Episode: 555 Total reward: 23.0 Training loss: 274.5443 Explore P: 0.4041\n",
      "Episode: 556 Total reward: 8.0 Training loss: 97.6534 Explore P: 0.4038\n",
      "Episode: 557 Total reward: 17.0 Training loss: 479.1898 Explore P: 0.4031\n",
      "Episode: 558 Total reward: 8.0 Training loss: 209.8546 Explore P: 0.4028\n",
      "Episode: 559 Total reward: 10.0 Training loss: 1468.6174 Explore P: 0.4024\n",
      "Episode: 560 Total reward: 17.0 Training loss: 89.7152 Explore P: 0.4017\n",
      "Episode: 561 Total reward: 22.0 Training loss: 713.8568 Explore P: 0.4009\n",
      "Episode: 562 Total reward: 14.0 Training loss: 399.8305 Explore P: 0.4003\n",
      "Episode: 563 Total reward: 21.0 Training loss: 242.6662 Explore P: 0.3995\n",
      "Episode: 564 Total reward: 10.0 Training loss: 189.8842 Explore P: 0.3991\n",
      "Episode: 565 Total reward: 18.0 Training loss: 334.9431 Explore P: 0.3984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 566 Total reward: 8.0 Training loss: 159.4303 Explore P: 0.3981\n",
      "Episode: 567 Total reward: 12.0 Training loss: 253.3800 Explore P: 0.3977\n",
      "Episode: 568 Total reward: 14.0 Training loss: 275.6045 Explore P: 0.3971\n",
      "Episode: 569 Total reward: 12.0 Training loss: 122.9640 Explore P: 0.3966\n",
      "Episode: 570 Total reward: 11.0 Training loss: 272.0470 Explore P: 0.3962\n",
      "Episode: 571 Total reward: 22.0 Training loss: 212.0760 Explore P: 0.3954\n",
      "Episode: 572 Total reward: 11.0 Training loss: 294.4380 Explore P: 0.3949\n",
      "Episode: 573 Total reward: 10.0 Training loss: 924.0939 Explore P: 0.3946\n",
      "Episode: 574 Total reward: 11.0 Training loss: 301.0912 Explore P: 0.3941\n",
      "Episode: 575 Total reward: 13.0 Training loss: 1076.8193 Explore P: 0.3936\n",
      "Episode: 576 Total reward: 13.0 Training loss: 133.5395 Explore P: 0.3931\n",
      "Episode: 577 Total reward: 11.0 Training loss: 220.0165 Explore P: 0.3927\n",
      "Episode: 578 Total reward: 9.0 Training loss: 585.6987 Explore P: 0.3924\n",
      "Episode: 579 Total reward: 11.0 Training loss: 47.4295 Explore P: 0.3920\n",
      "Episode: 580 Total reward: 13.0 Training loss: 1567.9966 Explore P: 0.3915\n",
      "Episode: 581 Total reward: 19.0 Training loss: 210.0196 Explore P: 0.3907\n",
      "Episode: 582 Total reward: 17.0 Training loss: 205.7994 Explore P: 0.3901\n",
      "Episode: 583 Total reward: 20.0 Training loss: 91.7717 Explore P: 0.3893\n",
      "Episode: 584 Total reward: 11.0 Training loss: 169.0988 Explore P: 0.3889\n",
      "Episode: 585 Total reward: 8.0 Training loss: 275.2885 Explore P: 0.3886\n",
      "Episode: 586 Total reward: 9.0 Training loss: 449.8698 Explore P: 0.3883\n",
      "Episode: 587 Total reward: 11.0 Training loss: 329.0008 Explore P: 0.3879\n",
      "Episode: 588 Total reward: 22.0 Training loss: 130.7738 Explore P: 0.3870\n",
      "Episode: 589 Total reward: 9.0 Training loss: 226.3272 Explore P: 0.3867\n",
      "Episode: 590 Total reward: 12.0 Training loss: 269.2637 Explore P: 0.3862\n",
      "Episode: 591 Total reward: 13.0 Training loss: 366.7736 Explore P: 0.3857\n",
      "Episode: 592 Total reward: 12.0 Training loss: 326.7204 Explore P: 0.3853\n",
      "Episode: 593 Total reward: 14.0 Training loss: 237.6139 Explore P: 0.3848\n",
      "Episode: 594 Total reward: 12.0 Training loss: 1017.5316 Explore P: 0.3843\n",
      "Episode: 595 Total reward: 17.0 Training loss: 152.1364 Explore P: 0.3837\n",
      "Episode: 596 Total reward: 17.0 Training loss: 554.6490 Explore P: 0.3830\n",
      "Episode: 597 Total reward: 8.0 Training loss: 217.0114 Explore P: 0.3827\n",
      "Episode: 598 Total reward: 8.0 Training loss: 334.7876 Explore P: 0.3825\n",
      "Episode: 599 Total reward: 13.0 Training loss: 1836.9147 Explore P: 0.3820\n",
      "Episode: 600 Total reward: 9.0 Training loss: 373.2561 Explore P: 0.3816\n",
      "Episode: 601 Total reward: 11.0 Training loss: 133.4189 Explore P: 0.3812\n",
      "Episode: 602 Total reward: 11.0 Training loss: 375.9928 Explore P: 0.3808\n",
      "Episode: 603 Total reward: 11.0 Training loss: 591.7493 Explore P: 0.3804\n",
      "Episode: 604 Total reward: 20.0 Training loss: 654.6448 Explore P: 0.3797\n",
      "Episode: 605 Total reward: 9.0 Training loss: 542.0563 Explore P: 0.3793\n",
      "Episode: 606 Total reward: 12.0 Training loss: 294.8724 Explore P: 0.3789\n",
      "Episode: 607 Total reward: 13.0 Training loss: 272.2960 Explore P: 0.3784\n",
      "Episode: 608 Total reward: 12.0 Training loss: 87.8460 Explore P: 0.3780\n",
      "Episode: 609 Total reward: 12.0 Training loss: 48.5956 Explore P: 0.3775\n",
      "Episode: 610 Total reward: 17.0 Training loss: 331.2093 Explore P: 0.3769\n",
      "Episode: 611 Total reward: 15.0 Training loss: 319.3593 Explore P: 0.3764\n",
      "Episode: 612 Total reward: 8.0 Training loss: 172.3813 Explore P: 0.3761\n",
      "Episode: 613 Total reward: 9.0 Training loss: 234.7620 Explore P: 0.3757\n",
      "Episode: 614 Total reward: 13.0 Training loss: 205.7132 Explore P: 0.3753\n",
      "Episode: 615 Total reward: 9.0 Training loss: 240.7967 Explore P: 0.3749\n",
      "Episode: 616 Total reward: 14.0 Training loss: 337.9105 Explore P: 0.3744\n",
      "Episode: 617 Total reward: 15.0 Training loss: 460.4100 Explore P: 0.3739\n",
      "Episode: 618 Total reward: 18.0 Training loss: 217.7579 Explore P: 0.3732\n",
      "Episode: 619 Total reward: 16.0 Training loss: 239.6693 Explore P: 0.3726\n",
      "Episode: 620 Total reward: 15.0 Training loss: 272.0448 Explore P: 0.3721\n",
      "Episode: 621 Total reward: 10.0 Training loss: 642.8288 Explore P: 0.3717\n",
      "Episode: 622 Total reward: 11.0 Training loss: 172.7901 Explore P: 0.3713\n",
      "Episode: 623 Total reward: 11.0 Training loss: 47.1207 Explore P: 0.3709\n",
      "Episode: 624 Total reward: 13.0 Training loss: 380.5215 Explore P: 0.3705\n",
      "Episode: 625 Total reward: 14.0 Training loss: 462.6558 Explore P: 0.3700\n",
      "Episode: 626 Total reward: 18.0 Training loss: 376.9102 Explore P: 0.3693\n",
      "Episode: 627 Total reward: 12.0 Training loss: 429.0430 Explore P: 0.3689\n",
      "Episode: 628 Total reward: 10.0 Training loss: 99.8685 Explore P: 0.3685\n",
      "Episode: 629 Total reward: 11.0 Training loss: 255.8689 Explore P: 0.3681\n",
      "Episode: 630 Total reward: 16.0 Training loss: 362.8438 Explore P: 0.3676\n",
      "Episode: 631 Total reward: 11.0 Training loss: 298.4160 Explore P: 0.3672\n",
      "Episode: 632 Total reward: 14.0 Training loss: 377.3421 Explore P: 0.3667\n",
      "Episode: 633 Total reward: 15.0 Training loss: 512.3987 Explore P: 0.3661\n",
      "Episode: 634 Total reward: 21.0 Training loss: 259.6077 Explore P: 0.3654\n",
      "Episode: 635 Total reward: 11.0 Training loss: 273.0780 Explore P: 0.3650\n",
      "Episode: 636 Total reward: 11.0 Training loss: 953.3079 Explore P: 0.3646\n",
      "Episode: 637 Total reward: 9.0 Training loss: 583.4213 Explore P: 0.3643\n",
      "Episode: 638 Total reward: 13.0 Training loss: 310.9902 Explore P: 0.3638\n",
      "Episode: 639 Total reward: 10.0 Training loss: 390.4600 Explore P: 0.3635\n",
      "Episode: 640 Total reward: 10.0 Training loss: 697.8192 Explore P: 0.3631\n",
      "Episode: 641 Total reward: 9.0 Training loss: 692.8395 Explore P: 0.3628\n",
      "Episode: 642 Total reward: 10.0 Training loss: 129.1449 Explore P: 0.3624\n",
      "Episode: 643 Total reward: 10.0 Training loss: 223.5635 Explore P: 0.3621\n",
      "Episode: 644 Total reward: 9.0 Training loss: 719.4996 Explore P: 0.3618\n",
      "Episode: 645 Total reward: 9.0 Training loss: 292.9274 Explore P: 0.3615\n",
      "Episode: 646 Total reward: 20.0 Training loss: 370.7682 Explore P: 0.3608\n",
      "Episode: 647 Total reward: 19.0 Training loss: 156.0393 Explore P: 0.3601\n",
      "Episode: 648 Total reward: 31.0 Training loss: 206.8979 Explore P: 0.3590\n",
      "Episode: 649 Total reward: 35.0 Training loss: 457.6631 Explore P: 0.3578\n",
      "Episode: 650 Total reward: 10.0 Training loss: 757.0934 Explore P: 0.3574\n",
      "Episode: 651 Total reward: 11.0 Training loss: 205.6588 Explore P: 0.3571\n",
      "Episode: 652 Total reward: 7.0 Training loss: 393.4665 Explore P: 0.3568\n",
      "Episode: 653 Total reward: 8.0 Training loss: 593.1874 Explore P: 0.3565\n",
      "Episode: 654 Total reward: 16.0 Training loss: 693.1644 Explore P: 0.3560\n",
      "Episode: 655 Total reward: 11.0 Training loss: 233.5614 Explore P: 0.3556\n",
      "Episode: 656 Total reward: 11.0 Training loss: 638.9332 Explore P: 0.3552\n",
      "Episode: 657 Total reward: 10.0 Training loss: 98.0511 Explore P: 0.3549\n",
      "Episode: 658 Total reward: 14.0 Training loss: 357.2578 Explore P: 0.3544\n",
      "Episode: 659 Total reward: 11.0 Training loss: 277.1590 Explore P: 0.3540\n",
      "Episode: 660 Total reward: 12.0 Training loss: 1740.1840 Explore P: 0.3536\n",
      "Episode: 661 Total reward: 16.0 Training loss: 861.3333 Explore P: 0.3531\n",
      "Episode: 662 Total reward: 9.0 Training loss: 948.3469 Explore P: 0.3528\n",
      "Episode: 663 Total reward: 15.0 Training loss: 1364.4451 Explore P: 0.3522\n",
      "Episode: 664 Total reward: 9.0 Training loss: 792.0551 Explore P: 0.3519\n",
      "Episode: 665 Total reward: 11.0 Training loss: 233.5546 Explore P: 0.3516\n",
      "Episode: 666 Total reward: 17.0 Training loss: 675.5279 Explore P: 0.3510\n",
      "Episode: 667 Total reward: 8.0 Training loss: 265.8891 Explore P: 0.3507\n",
      "Episode: 668 Total reward: 9.0 Training loss: 202.0499 Explore P: 0.3504\n",
      "Episode: 669 Total reward: 12.0 Training loss: 220.4723 Explore P: 0.3500\n",
      "Episode: 670 Total reward: 16.0 Training loss: 320.2176 Explore P: 0.3494\n",
      "Episode: 671 Total reward: 8.0 Training loss: 458.7383 Explore P: 0.3492\n",
      "Episode: 672 Total reward: 11.0 Training loss: 441.5555 Explore P: 0.3488\n",
      "Episode: 673 Total reward: 11.0 Training loss: 243.9824 Explore P: 0.3484\n",
      "Episode: 674 Total reward: 9.0 Training loss: 286.6492 Explore P: 0.3481\n",
      "Episode: 675 Total reward: 9.0 Training loss: 392.2276 Explore P: 0.3478\n",
      "Episode: 676 Total reward: 9.0 Training loss: 718.3256 Explore P: 0.3475\n",
      "Episode: 677 Total reward: 10.0 Training loss: 257.9156 Explore P: 0.3472\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 678 Total reward: 16.0 Training loss: 529.5197 Explore P: 0.3466\n",
      "Episode: 679 Total reward: 15.0 Training loss: 195.5587 Explore P: 0.3461\n",
      "Episode: 680 Total reward: 13.0 Training loss: 306.1851 Explore P: 0.3457\n",
      "Episode: 681 Total reward: 8.0 Training loss: 293.6048 Explore P: 0.3454\n",
      "Episode: 682 Total reward: 12.0 Training loss: 1128.3994 Explore P: 0.3450\n",
      "Episode: 683 Total reward: 8.0 Training loss: 884.4778 Explore P: 0.3448\n",
      "Episode: 684 Total reward: 10.0 Training loss: 523.8362 Explore P: 0.3444\n",
      "Episode: 685 Total reward: 11.0 Training loss: 427.2219 Explore P: 0.3441\n",
      "Episode: 686 Total reward: 11.0 Training loss: 680.3798 Explore P: 0.3437\n",
      "Episode: 687 Total reward: 10.0 Training loss: 1385.9314 Explore P: 0.3434\n",
      "Episode: 688 Total reward: 10.0 Training loss: 901.7336 Explore P: 0.3430\n",
      "Episode: 689 Total reward: 14.0 Training loss: 150.2247 Explore P: 0.3426\n",
      "Episode: 690 Total reward: 19.0 Training loss: 139.7038 Explore P: 0.3419\n",
      "Episode: 691 Total reward: 13.0 Training loss: 290.0474 Explore P: 0.3415\n",
      "Episode: 692 Total reward: 12.0 Training loss: 818.3572 Explore P: 0.3411\n",
      "Episode: 693 Total reward: 10.0 Training loss: 127.2735 Explore P: 0.3408\n",
      "Episode: 694 Total reward: 14.0 Training loss: 364.2441 Explore P: 0.3403\n",
      "Episode: 695 Total reward: 10.0 Training loss: 335.9565 Explore P: 0.3400\n",
      "Episode: 696 Total reward: 11.0 Training loss: 554.1295 Explore P: 0.3396\n",
      "Episode: 697 Total reward: 9.0 Training loss: 643.0559 Explore P: 0.3393\n",
      "Episode: 698 Total reward: 9.0 Training loss: 333.1429 Explore P: 0.3390\n",
      "Episode: 699 Total reward: 8.0 Training loss: 347.5342 Explore P: 0.3388\n",
      "Episode: 700 Total reward: 20.0 Training loss: 286.9448 Explore P: 0.3381\n",
      "Episode: 701 Total reward: 14.0 Training loss: 241.6407 Explore P: 0.3376\n",
      "Episode: 702 Total reward: 8.0 Training loss: 270.8650 Explore P: 0.3374\n",
      "Episode: 703 Total reward: 12.0 Training loss: 2700.8501 Explore P: 0.3370\n",
      "Episode: 704 Total reward: 10.0 Training loss: 444.1392 Explore P: 0.3367\n",
      "Episode: 705 Total reward: 8.0 Training loss: 297.2863 Explore P: 0.3364\n",
      "Episode: 706 Total reward: 10.0 Training loss: 216.2454 Explore P: 0.3361\n",
      "Episode: 707 Total reward: 13.0 Training loss: 408.1696 Explore P: 0.3356\n",
      "Episode: 708 Total reward: 12.0 Training loss: 298.4212 Explore P: 0.3353\n",
      "Episode: 709 Total reward: 11.0 Training loss: 737.1844 Explore P: 0.3349\n",
      "Episode: 710 Total reward: 7.0 Training loss: 687.4604 Explore P: 0.3347\n",
      "Episode: 711 Total reward: 10.0 Training loss: 393.8800 Explore P: 0.3343\n",
      "Episode: 712 Total reward: 10.0 Training loss: 260.0173 Explore P: 0.3340\n",
      "Episode: 713 Total reward: 13.0 Training loss: 547.2472 Explore P: 0.3336\n",
      "Episode: 714 Total reward: 9.0 Training loss: 554.1737 Explore P: 0.3333\n",
      "Episode: 715 Total reward: 8.0 Training loss: 411.4927 Explore P: 0.3330\n",
      "Episode: 716 Total reward: 13.0 Training loss: 290.3885 Explore P: 0.3326\n",
      "Episode: 717 Total reward: 11.0 Training loss: 868.5844 Explore P: 0.3323\n",
      "Episode: 718 Total reward: 10.0 Training loss: 410.9886 Explore P: 0.3320\n",
      "Episode: 719 Total reward: 11.0 Training loss: 599.1230 Explore P: 0.3316\n",
      "Episode: 720 Total reward: 10.0 Training loss: 184.5546 Explore P: 0.3313\n",
      "Episode: 721 Total reward: 14.0 Training loss: 330.3828 Explore P: 0.3308\n",
      "Episode: 722 Total reward: 13.0 Training loss: 546.0651 Explore P: 0.3304\n",
      "Episode: 723 Total reward: 16.0 Training loss: 509.8959 Explore P: 0.3299\n",
      "Episode: 724 Total reward: 10.0 Training loss: 257.8567 Explore P: 0.3296\n",
      "Episode: 725 Total reward: 8.0 Training loss: 483.1021 Explore P: 0.3293\n",
      "Episode: 726 Total reward: 9.0 Training loss: 505.7117 Explore P: 0.3290\n",
      "Episode: 727 Total reward: 14.0 Training loss: 307.7928 Explore P: 0.3286\n",
      "Episode: 728 Total reward: 12.0 Training loss: 505.9305 Explore P: 0.3282\n",
      "Episode: 729 Total reward: 11.0 Training loss: 165.6230 Explore P: 0.3279\n",
      "Episode: 730 Total reward: 13.0 Training loss: 182.3075 Explore P: 0.3274\n",
      "Episode: 731 Total reward: 13.0 Training loss: 306.3003 Explore P: 0.3270\n",
      "Episode: 732 Total reward: 12.0 Training loss: 280.7492 Explore P: 0.3267\n",
      "Episode: 733 Total reward: 11.0 Training loss: 825.0057 Explore P: 0.3263\n",
      "Episode: 734 Total reward: 9.0 Training loss: 100.9577 Explore P: 0.3260\n",
      "Episode: 735 Total reward: 12.0 Training loss: 245.2969 Explore P: 0.3256\n",
      "Episode: 736 Total reward: 11.0 Training loss: 565.6683 Explore P: 0.3253\n",
      "Episode: 737 Total reward: 10.0 Training loss: 333.4923 Explore P: 0.3250\n",
      "Episode: 738 Total reward: 8.0 Training loss: 1585.1207 Explore P: 0.3247\n",
      "Episode: 739 Total reward: 13.0 Training loss: 1277.4517 Explore P: 0.3243\n",
      "Episode: 740 Total reward: 12.0 Training loss: 647.9417 Explore P: 0.3239\n",
      "Episode: 741 Total reward: 8.0 Training loss: 965.2195 Explore P: 0.3237\n",
      "Episode: 742 Total reward: 12.0 Training loss: 393.4611 Explore P: 0.3233\n",
      "Episode: 743 Total reward: 9.0 Training loss: 1522.9539 Explore P: 0.3230\n",
      "Episode: 744 Total reward: 9.0 Training loss: 281.3869 Explore P: 0.3228\n",
      "Episode: 745 Total reward: 12.0 Training loss: 269.4349 Explore P: 0.3224\n",
      "Episode: 746 Total reward: 11.0 Training loss: 533.2139 Explore P: 0.3220\n",
      "Episode: 747 Total reward: 11.0 Training loss: 535.3715 Explore P: 0.3217\n",
      "Episode: 748 Total reward: 13.0 Training loss: 643.7998 Explore P: 0.3213\n",
      "Episode: 749 Total reward: 9.0 Training loss: 124.6170 Explore P: 0.3210\n",
      "Episode: 750 Total reward: 14.0 Training loss: 925.9344 Explore P: 0.3206\n",
      "Episode: 751 Total reward: 8.0 Training loss: 659.5579 Explore P: 0.3203\n",
      "Episode: 752 Total reward: 16.0 Training loss: 255.5499 Explore P: 0.3198\n",
      "Episode: 753 Total reward: 24.0 Training loss: 512.6571 Explore P: 0.3191\n",
      "Episode: 754 Total reward: 12.0 Training loss: 316.1749 Explore P: 0.3187\n",
      "Episode: 755 Total reward: 10.0 Training loss: 192.9262 Explore P: 0.3184\n",
      "Episode: 756 Total reward: 8.0 Training loss: 1336.3666 Explore P: 0.3182\n",
      "Episode: 757 Total reward: 10.0 Training loss: 1034.7360 Explore P: 0.3178\n",
      "Episode: 758 Total reward: 20.0 Training loss: 1044.2095 Explore P: 0.3172\n",
      "Episode: 759 Total reward: 11.0 Training loss: 287.9710 Explore P: 0.3169\n",
      "Episode: 760 Total reward: 9.0 Training loss: 287.4953 Explore P: 0.3166\n",
      "Episode: 761 Total reward: 9.0 Training loss: 864.7935 Explore P: 0.3163\n",
      "Episode: 762 Total reward: 15.0 Training loss: 735.7988 Explore P: 0.3159\n",
      "Episode: 763 Total reward: 11.0 Training loss: 211.4702 Explore P: 0.3155\n",
      "Episode: 764 Total reward: 15.0 Training loss: 543.6306 Explore P: 0.3151\n",
      "Episode: 765 Total reward: 15.0 Training loss: 304.6851 Explore P: 0.3146\n",
      "Episode: 766 Total reward: 10.0 Training loss: 239.2289 Explore P: 0.3143\n",
      "Episode: 767 Total reward: 8.0 Training loss: 139.5391 Explore P: 0.3141\n",
      "Episode: 768 Total reward: 11.0 Training loss: 134.2471 Explore P: 0.3137\n",
      "Episode: 769 Total reward: 10.0 Training loss: 417.8688 Explore P: 0.3134\n",
      "Episode: 770 Total reward: 9.0 Training loss: 202.4630 Explore P: 0.3132\n",
      "Episode: 771 Total reward: 10.0 Training loss: 557.9728 Explore P: 0.3129\n",
      "Episode: 772 Total reward: 10.0 Training loss: 703.9116 Explore P: 0.3126\n",
      "Episode: 773 Total reward: 13.0 Training loss: 238.5330 Explore P: 0.3122\n",
      "Episode: 774 Total reward: 21.0 Training loss: 63.9339 Explore P: 0.3115\n",
      "Episode: 775 Total reward: 11.0 Training loss: 1007.0042 Explore P: 0.3112\n",
      "Episode: 776 Total reward: 10.0 Training loss: 248.5762 Explore P: 0.3109\n",
      "Episode: 777 Total reward: 9.0 Training loss: 374.0565 Explore P: 0.3106\n",
      "Episode: 778 Total reward: 11.0 Training loss: 602.5233 Explore P: 0.3103\n",
      "Episode: 779 Total reward: 9.0 Training loss: 524.6451 Explore P: 0.3100\n",
      "Episode: 780 Total reward: 14.0 Training loss: 243.2281 Explore P: 0.3096\n",
      "Episode: 781 Total reward: 11.0 Training loss: 579.2157 Explore P: 0.3093\n",
      "Episode: 782 Total reward: 9.0 Training loss: 538.1672 Explore P: 0.3090\n",
      "Episode: 783 Total reward: 9.0 Training loss: 1240.6771 Explore P: 0.3087\n",
      "Episode: 784 Total reward: 7.0 Training loss: 669.0889 Explore P: 0.3085\n",
      "Episode: 785 Total reward: 11.0 Training loss: 780.3951 Explore P: 0.3082\n",
      "Episode: 786 Total reward: 9.0 Training loss: 308.5778 Explore P: 0.3079\n",
      "Episode: 787 Total reward: 9.0 Training loss: 318.8565 Explore P: 0.3077\n",
      "Episode: 788 Total reward: 9.0 Training loss: 344.3035 Explore P: 0.3074\n",
      "Episode: 789 Total reward: 10.0 Training loss: 1242.4355 Explore P: 0.3071\n",
      "Episode: 790 Total reward: 9.0 Training loss: 193.4447 Explore P: 0.3068\n",
      "Episode: 791 Total reward: 12.0 Training loss: 797.3075 Explore P: 0.3065\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 792 Total reward: 11.0 Training loss: 211.1755 Explore P: 0.3062\n",
      "Episode: 793 Total reward: 21.0 Training loss: 166.8294 Explore P: 0.3055\n",
      "Episode: 794 Total reward: 11.0 Training loss: 597.2951 Explore P: 0.3052\n",
      "Episode: 795 Total reward: 15.0 Training loss: 583.2572 Explore P: 0.3048\n",
      "Episode: 796 Total reward: 10.0 Training loss: 978.8058 Explore P: 0.3045\n",
      "Episode: 797 Total reward: 12.0 Training loss: 180.7534 Explore P: 0.3041\n",
      "Episode: 798 Total reward: 8.0 Training loss: 372.7596 Explore P: 0.3039\n",
      "Episode: 799 Total reward: 9.0 Training loss: 221.8494 Explore P: 0.3036\n",
      "Episode: 800 Total reward: 10.0 Training loss: 290.0557 Explore P: 0.3033\n",
      "Episode: 801 Total reward: 12.0 Training loss: 198.1001 Explore P: 0.3030\n",
      "Episode: 802 Total reward: 11.0 Training loss: 898.0194 Explore P: 0.3027\n",
      "Episode: 803 Total reward: 10.0 Training loss: 4178.0420 Explore P: 0.3024\n",
      "Episode: 804 Total reward: 9.0 Training loss: 825.3236 Explore P: 0.3021\n",
      "Episode: 805 Total reward: 9.0 Training loss: 492.2597 Explore P: 0.3018\n",
      "Episode: 806 Total reward: 11.0 Training loss: 447.9609 Explore P: 0.3015\n",
      "Episode: 807 Total reward: 8.0 Training loss: 449.5718 Explore P: 0.3013\n",
      "Episode: 808 Total reward: 10.0 Training loss: 616.9845 Explore P: 0.3010\n",
      "Episode: 809 Total reward: 11.0 Training loss: 451.3460 Explore P: 0.3007\n",
      "Episode: 810 Total reward: 9.0 Training loss: 296.7145 Explore P: 0.3004\n",
      "Episode: 811 Total reward: 18.0 Training loss: 258.9980 Explore P: 0.2999\n",
      "Episode: 812 Total reward: 13.0 Training loss: 558.8221 Explore P: 0.2995\n",
      "Episode: 813 Total reward: 12.0 Training loss: 341.2254 Explore P: 0.2992\n",
      "Episode: 814 Total reward: 9.0 Training loss: 1063.5083 Explore P: 0.2989\n",
      "Episode: 815 Total reward: 11.0 Training loss: 152.0866 Explore P: 0.2986\n",
      "Episode: 816 Total reward: 7.0 Training loss: 433.0643 Explore P: 0.2984\n",
      "Episode: 817 Total reward: 12.0 Training loss: 621.8905 Explore P: 0.2980\n",
      "Episode: 818 Total reward: 9.0 Training loss: 248.5484 Explore P: 0.2978\n",
      "Episode: 819 Total reward: 9.0 Training loss: 556.4149 Explore P: 0.2975\n",
      "Episode: 820 Total reward: 8.0 Training loss: 232.0124 Explore P: 0.2973\n",
      "Episode: 821 Total reward: 10.0 Training loss: 336.4645 Explore P: 0.2970\n",
      "Episode: 822 Total reward: 12.0 Training loss: 608.9011 Explore P: 0.2967\n",
      "Episode: 823 Total reward: 8.0 Training loss: 404.0832 Explore P: 0.2964\n",
      "Episode: 824 Total reward: 19.0 Training loss: 456.0841 Explore P: 0.2959\n",
      "Episode: 825 Total reward: 9.0 Training loss: 200.6065 Explore P: 0.2956\n",
      "Episode: 826 Total reward: 11.0 Training loss: 694.5623 Explore P: 0.2953\n",
      "Episode: 827 Total reward: 10.0 Training loss: 413.6244 Explore P: 0.2950\n",
      "Episode: 828 Total reward: 18.0 Training loss: 504.4365 Explore P: 0.2945\n",
      "Episode: 829 Total reward: 11.0 Training loss: 646.8729 Explore P: 0.2942\n",
      "Episode: 830 Total reward: 16.0 Training loss: 382.5338 Explore P: 0.2938\n",
      "Episode: 831 Total reward: 9.0 Training loss: 869.3086 Explore P: 0.2935\n",
      "Episode: 832 Total reward: 16.0 Training loss: 331.4617 Explore P: 0.2930\n",
      "Episode: 833 Total reward: 15.0 Training loss: 1858.9183 Explore P: 0.2926\n",
      "Episode: 834 Total reward: 10.0 Training loss: 283.5797 Explore P: 0.2923\n",
      "Episode: 835 Total reward: 8.0 Training loss: 381.4006 Explore P: 0.2921\n",
      "Episode: 836 Total reward: 29.0 Training loss: 500.2411 Explore P: 0.2913\n",
      "Episode: 837 Total reward: 8.0 Training loss: 949.8361 Explore P: 0.2911\n",
      "Episode: 838 Total reward: 8.0 Training loss: 730.1476 Explore P: 0.2908\n",
      "Episode: 839 Total reward: 10.0 Training loss: 197.6082 Explore P: 0.2906\n",
      "Episode: 840 Total reward: 9.0 Training loss: 395.0513 Explore P: 0.2903\n",
      "Episode: 841 Total reward: 9.0 Training loss: 223.7124 Explore P: 0.2901\n",
      "Episode: 842 Total reward: 13.0 Training loss: 503.6157 Explore P: 0.2897\n",
      "Episode: 843 Total reward: 11.0 Training loss: 366.5240 Explore P: 0.2894\n",
      "Episode: 844 Total reward: 10.0 Training loss: 648.3174 Explore P: 0.2891\n",
      "Episode: 845 Total reward: 10.0 Training loss: 585.6940 Explore P: 0.2888\n",
      "Episode: 846 Total reward: 13.0 Training loss: 381.2025 Explore P: 0.2885\n",
      "Episode: 847 Total reward: 9.0 Training loss: 238.5639 Explore P: 0.2882\n",
      "Episode: 848 Total reward: 9.0 Training loss: 357.9932 Explore P: 0.2880\n",
      "Episode: 849 Total reward: 11.0 Training loss: 666.6880 Explore P: 0.2877\n",
      "Episode: 850 Total reward: 13.0 Training loss: 1057.1511 Explore P: 0.2873\n",
      "Episode: 851 Total reward: 9.0 Training loss: 549.6197 Explore P: 0.2871\n",
      "Episode: 852 Total reward: 21.0 Training loss: 531.1821 Explore P: 0.2865\n",
      "Episode: 853 Total reward: 10.0 Training loss: 135.8043 Explore P: 0.2862\n",
      "Episode: 854 Total reward: 11.0 Training loss: 970.9881 Explore P: 0.2859\n",
      "Episode: 855 Total reward: 10.0 Training loss: 91.1670 Explore P: 0.2856\n",
      "Episode: 856 Total reward: 11.0 Training loss: 489.4260 Explore P: 0.2853\n",
      "Episode: 857 Total reward: 10.0 Training loss: 252.7909 Explore P: 0.2850\n",
      "Episode: 858 Total reward: 12.0 Training loss: 83.9880 Explore P: 0.2847\n",
      "Episode: 859 Total reward: 10.0 Training loss: 314.4917 Explore P: 0.2844\n",
      "Episode: 860 Total reward: 12.0 Training loss: 3926.6433 Explore P: 0.2841\n",
      "Episode: 861 Total reward: 9.0 Training loss: 1064.8265 Explore P: 0.2839\n",
      "Episode: 862 Total reward: 10.0 Training loss: 472.0324 Explore P: 0.2836\n",
      "Episode: 863 Total reward: 8.0 Training loss: 238.3719 Explore P: 0.2834\n",
      "Episode: 864 Total reward: 11.0 Training loss: 415.6381 Explore P: 0.2831\n",
      "Episode: 865 Total reward: 15.0 Training loss: 1032.0043 Explore P: 0.2827\n",
      "Episode: 866 Total reward: 10.0 Training loss: 440.4452 Explore P: 0.2824\n",
      "Episode: 867 Total reward: 13.0 Training loss: 929.0065 Explore P: 0.2820\n",
      "Episode: 868 Total reward: 13.0 Training loss: 592.8679 Explore P: 0.2817\n",
      "Episode: 869 Total reward: 11.0 Training loss: 456.1100 Explore P: 0.2814\n",
      "Episode: 870 Total reward: 13.0 Training loss: 901.1437 Explore P: 0.2810\n",
      "Episode: 871 Total reward: 11.0 Training loss: 235.1612 Explore P: 0.2807\n",
      "Episode: 872 Total reward: 8.0 Training loss: 1158.5934 Explore P: 0.2805\n",
      "Episode: 873 Total reward: 19.0 Training loss: 355.3502 Explore P: 0.2800\n",
      "Episode: 874 Total reward: 14.0 Training loss: 1380.9386 Explore P: 0.2796\n",
      "Episode: 875 Total reward: 13.0 Training loss: 485.1440 Explore P: 0.2793\n",
      "Episode: 876 Total reward: 9.0 Training loss: 762.8543 Explore P: 0.2790\n",
      "Episode: 877 Total reward: 10.0 Training loss: 721.0627 Explore P: 0.2788\n",
      "Episode: 878 Total reward: 11.0 Training loss: 309.3045 Explore P: 0.2785\n",
      "Episode: 879 Total reward: 12.0 Training loss: 3720.9902 Explore P: 0.2781\n",
      "Episode: 880 Total reward: 18.0 Training loss: 554.1104 Explore P: 0.2777\n",
      "Episode: 881 Total reward: 10.0 Training loss: 1335.2948 Explore P: 0.2774\n",
      "Episode: 882 Total reward: 13.0 Training loss: 267.2236 Explore P: 0.2770\n",
      "Episode: 883 Total reward: 13.0 Training loss: 2182.4939 Explore P: 0.2767\n",
      "Episode: 884 Total reward: 11.0 Training loss: 472.0548 Explore P: 0.2764\n",
      "Episode: 885 Total reward: 9.0 Training loss: 918.6496 Explore P: 0.2762\n",
      "Episode: 886 Total reward: 12.0 Training loss: 120.1669 Explore P: 0.2758\n",
      "Episode: 887 Total reward: 10.0 Training loss: 504.3294 Explore P: 0.2756\n",
      "Episode: 888 Total reward: 19.0 Training loss: 448.4147 Explore P: 0.2751\n",
      "Episode: 889 Total reward: 9.0 Training loss: 246.3090 Explore P: 0.2748\n",
      "Episode: 890 Total reward: 9.0 Training loss: 1315.5634 Explore P: 0.2746\n",
      "Episode: 891 Total reward: 9.0 Training loss: 949.9581 Explore P: 0.2744\n",
      "Episode: 892 Total reward: 11.0 Training loss: 789.8491 Explore P: 0.2741\n",
      "Episode: 893 Total reward: 9.0 Training loss: 346.9604 Explore P: 0.2738\n",
      "Episode: 894 Total reward: 13.0 Training loss: 840.7762 Explore P: 0.2735\n",
      "Episode: 895 Total reward: 10.0 Training loss: 531.1938 Explore P: 0.2732\n",
      "Episode: 896 Total reward: 11.0 Training loss: 777.9882 Explore P: 0.2729\n",
      "Episode: 897 Total reward: 15.0 Training loss: 613.8781 Explore P: 0.2725\n",
      "Episode: 898 Total reward: 13.0 Training loss: 415.9901 Explore P: 0.2722\n",
      "Episode: 899 Total reward: 13.0 Training loss: 908.9833 Explore P: 0.2719\n",
      "Episode: 900 Total reward: 12.0 Training loss: 228.9449 Explore P: 0.2715\n",
      "Episode: 901 Total reward: 7.0 Training loss: 738.4396 Explore P: 0.2714\n",
      "Episode: 902 Total reward: 14.0 Training loss: 139.1537 Explore P: 0.2710\n",
      "Episode: 903 Total reward: 11.0 Training loss: 217.3582 Explore P: 0.2707\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 904 Total reward: 11.0 Training loss: 647.9349 Explore P: 0.2704\n",
      "Episode: 905 Total reward: 10.0 Training loss: 689.2789 Explore P: 0.2702\n",
      "Episode: 906 Total reward: 8.0 Training loss: 550.0653 Explore P: 0.2700\n",
      "Episode: 907 Total reward: 9.0 Training loss: 3196.9819 Explore P: 0.2697\n",
      "Episode: 908 Total reward: 9.0 Training loss: 697.0248 Explore P: 0.2695\n",
      "Episode: 909 Total reward: 12.0 Training loss: 292.6762 Explore P: 0.2692\n",
      "Episode: 910 Total reward: 10.0 Training loss: 505.6658 Explore P: 0.2689\n",
      "Episode: 911 Total reward: 10.0 Training loss: 640.2740 Explore P: 0.2687\n",
      "Episode: 912 Total reward: 14.0 Training loss: 617.2511 Explore P: 0.2683\n",
      "Episode: 913 Total reward: 12.0 Training loss: 1857.7646 Explore P: 0.2680\n",
      "Episode: 914 Total reward: 10.0 Training loss: 868.2733 Explore P: 0.2677\n",
      "Episode: 915 Total reward: 9.0 Training loss: 815.0500 Explore P: 0.2675\n",
      "Episode: 916 Total reward: 9.0 Training loss: 229.8778 Explore P: 0.2673\n",
      "Episode: 917 Total reward: 11.0 Training loss: 402.7572 Explore P: 0.2670\n",
      "Episode: 918 Total reward: 12.0 Training loss: 718.9510 Explore P: 0.2667\n",
      "Episode: 919 Total reward: 12.0 Training loss: 563.1421 Explore P: 0.2664\n",
      "Episode: 920 Total reward: 8.0 Training loss: 909.0033 Explore P: 0.2662\n",
      "Episode: 921 Total reward: 11.0 Training loss: 127.8985 Explore P: 0.2659\n",
      "Episode: 922 Total reward: 13.0 Training loss: 1232.0238 Explore P: 0.2655\n",
      "Episode: 923 Total reward: 12.0 Training loss: 1067.0416 Explore P: 0.2652\n",
      "Episode: 924 Total reward: 12.0 Training loss: 751.4443 Explore P: 0.2649\n",
      "Episode: 925 Total reward: 8.0 Training loss: 815.3000 Explore P: 0.2647\n",
      "Episode: 926 Total reward: 10.0 Training loss: 641.9974 Explore P: 0.2645\n",
      "Episode: 927 Total reward: 9.0 Training loss: 798.6955 Explore P: 0.2642\n",
      "Episode: 928 Total reward: 9.0 Training loss: 408.0136 Explore P: 0.2640\n",
      "Episode: 929 Total reward: 10.0 Training loss: 1348.2756 Explore P: 0.2638\n",
      "Episode: 930 Total reward: 10.0 Training loss: 170.6063 Explore P: 0.2635\n",
      "Episode: 931 Total reward: 10.0 Training loss: 159.7951 Explore P: 0.2633\n",
      "Episode: 932 Total reward: 10.0 Training loss: 2085.5498 Explore P: 0.2630\n",
      "Episode: 933 Total reward: 9.0 Training loss: 936.3880 Explore P: 0.2628\n",
      "Episode: 934 Total reward: 10.0 Training loss: 2633.3296 Explore P: 0.2625\n",
      "Episode: 935 Total reward: 11.0 Training loss: 473.4796 Explore P: 0.2622\n",
      "Episode: 936 Total reward: 9.0 Training loss: 851.1447 Explore P: 0.2620\n",
      "Episode: 937 Total reward: 8.0 Training loss: 363.3690 Explore P: 0.2618\n",
      "Episode: 938 Total reward: 11.0 Training loss: 2196.9038 Explore P: 0.2615\n",
      "Episode: 939 Total reward: 8.0 Training loss: 898.9945 Explore P: 0.2613\n",
      "Episode: 940 Total reward: 12.0 Training loss: 1218.4583 Explore P: 0.2610\n",
      "Episode: 941 Total reward: 9.0 Training loss: 580.7924 Explore P: 0.2608\n",
      "Episode: 942 Total reward: 11.0 Training loss: 1076.0281 Explore P: 0.2605\n",
      "Episode: 943 Total reward: 11.0 Training loss: 1361.7672 Explore P: 0.2603\n",
      "Episode: 944 Total reward: 11.0 Training loss: 347.5738 Explore P: 0.2600\n",
      "Episode: 945 Total reward: 13.0 Training loss: 195.0114 Explore P: 0.2597\n",
      "Episode: 946 Total reward: 12.0 Training loss: 396.5180 Explore P: 0.2594\n",
      "Episode: 947 Total reward: 10.0 Training loss: 210.2886 Explore P: 0.2591\n",
      "Episode: 948 Total reward: 11.0 Training loss: 525.3324 Explore P: 0.2588\n",
      "Episode: 949 Total reward: 11.0 Training loss: 245.2922 Explore P: 0.2586\n",
      "Episode: 950 Total reward: 10.0 Training loss: 443.0023 Explore P: 0.2583\n",
      "Episode: 951 Total reward: 27.0 Training loss: 774.4366 Explore P: 0.2576\n",
      "Episode: 952 Total reward: 7.0 Training loss: 505.3983 Explore P: 0.2575\n",
      "Episode: 953 Total reward: 9.0 Training loss: 636.9474 Explore P: 0.2573\n",
      "Episode: 954 Total reward: 12.0 Training loss: 1971.5784 Explore P: 0.2570\n",
      "Episode: 955 Total reward: 8.0 Training loss: 131.5528 Explore P: 0.2568\n",
      "Episode: 956 Total reward: 12.0 Training loss: 824.5287 Explore P: 0.2565\n",
      "Episode: 957 Total reward: 13.0 Training loss: 549.6490 Explore P: 0.2561\n",
      "Episode: 958 Total reward: 14.0 Training loss: 447.9286 Explore P: 0.2558\n",
      "Episode: 959 Total reward: 20.0 Training loss: 2631.2188 Explore P: 0.2553\n",
      "Episode: 960 Total reward: 14.0 Training loss: 552.6443 Explore P: 0.2550\n",
      "Episode: 961 Total reward: 22.0 Training loss: 823.4149 Explore P: 0.2544\n",
      "Episode: 962 Total reward: 8.0 Training loss: 513.3815 Explore P: 0.2542\n",
      "Episode: 963 Total reward: 13.0 Training loss: 3277.5171 Explore P: 0.2539\n",
      "Episode: 964 Total reward: 13.0 Training loss: 845.5764 Explore P: 0.2536\n",
      "Episode: 965 Total reward: 12.0 Training loss: 1939.0385 Explore P: 0.2533\n",
      "Episode: 966 Total reward: 8.0 Training loss: 288.2512 Explore P: 0.2531\n",
      "Episode: 967 Total reward: 9.0 Training loss: 450.2615 Explore P: 0.2529\n",
      "Episode: 968 Total reward: 29.0 Training loss: 821.7770 Explore P: 0.2522\n",
      "Episode: 969 Total reward: 12.0 Training loss: 354.7663 Explore P: 0.2519\n",
      "Episode: 970 Total reward: 8.0 Training loss: 1336.7080 Explore P: 0.2517\n",
      "Episode: 971 Total reward: 10.0 Training loss: 575.5295 Explore P: 0.2515\n",
      "Episode: 972 Total reward: 12.0 Training loss: 834.0906 Explore P: 0.2512\n",
      "Episode: 973 Total reward: 16.0 Training loss: 628.5412 Explore P: 0.2508\n",
      "Episode: 974 Total reward: 13.0 Training loss: 748.4432 Explore P: 0.2505\n",
      "Episode: 975 Total reward: 12.0 Training loss: 215.4334 Explore P: 0.2502\n",
      "Episode: 976 Total reward: 14.0 Training loss: 1302.2601 Explore P: 0.2498\n",
      "Episode: 977 Total reward: 11.0 Training loss: 607.0229 Explore P: 0.2496\n",
      "Episode: 978 Total reward: 11.0 Training loss: 343.8824 Explore P: 0.2493\n",
      "Episode: 979 Total reward: 8.0 Training loss: 808.1921 Explore P: 0.2491\n",
      "Episode: 980 Total reward: 9.0 Training loss: 645.7638 Explore P: 0.2489\n",
      "Episode: 981 Total reward: 10.0 Training loss: 304.2180 Explore P: 0.2487\n",
      "Episode: 982 Total reward: 11.0 Training loss: 188.4842 Explore P: 0.2484\n",
      "Episode: 983 Total reward: 12.0 Training loss: 169.5632 Explore P: 0.2481\n",
      "Episode: 984 Total reward: 12.0 Training loss: 328.0602 Explore P: 0.2478\n",
      "Episode: 985 Total reward: 13.0 Training loss: 635.6774 Explore P: 0.2475\n",
      "Episode: 986 Total reward: 17.0 Training loss: 441.2241 Explore P: 0.2471\n",
      "Episode: 987 Total reward: 12.0 Training loss: 452.4099 Explore P: 0.2468\n",
      "Episode: 988 Total reward: 11.0 Training loss: 891.0713 Explore P: 0.2466\n",
      "Episode: 989 Total reward: 11.0 Training loss: 333.9225 Explore P: 0.2463\n",
      "Episode: 990 Total reward: 10.0 Training loss: 681.6345 Explore P: 0.2461\n",
      "Episode: 991 Total reward: 10.0 Training loss: 337.1438 Explore P: 0.2459\n",
      "Episode: 992 Total reward: 13.0 Training loss: 1912.5085 Explore P: 0.2455\n",
      "Episode: 993 Total reward: 9.0 Training loss: 651.3502 Explore P: 0.2453\n",
      "Episode: 994 Total reward: 8.0 Training loss: 620.4679 Explore P: 0.2451\n",
      "Episode: 995 Total reward: 10.0 Training loss: 1085.6310 Explore P: 0.2449\n",
      "Episode: 996 Total reward: 8.0 Training loss: 607.9156 Explore P: 0.2447\n",
      "Episode: 997 Total reward: 9.0 Training loss: 302.4699 Explore P: 0.2445\n",
      "Episode: 998 Total reward: 11.0 Training loss: 334.9546 Explore P: 0.2443\n",
      "Episode: 999 Total reward: 10.0 Training loss: 1900.9775 Explore P: 0.2440\n",
      "Episode: 1000 Total reward: 10.0 Training loss: 556.1741 Explore P: 0.2438\n",
      "Episode: 1001 Total reward: 12.0 Training loss: 423.8655 Explore P: 0.2435\n",
      "Episode: 1002 Total reward: 12.0 Training loss: 642.5292 Explore P: 0.2432\n",
      "Episode: 1003 Total reward: 11.0 Training loss: 454.8718 Explore P: 0.2430\n",
      "Episode: 1004 Total reward: 9.0 Training loss: 219.6966 Explore P: 0.2428\n",
      "Episode: 1005 Total reward: 10.0 Training loss: 699.4363 Explore P: 0.2425\n",
      "Episode: 1006 Total reward: 10.0 Training loss: 1915.9606 Explore P: 0.2423\n",
      "Episode: 1007 Total reward: 14.0 Training loss: 315.7835 Explore P: 0.2420\n",
      "Episode: 1008 Total reward: 10.0 Training loss: 1982.8549 Explore P: 0.2417\n",
      "Episode: 1009 Total reward: 9.0 Training loss: 457.8959 Explore P: 0.2415\n",
      "Episode: 1010 Total reward: 12.0 Training loss: 1881.9010 Explore P: 0.2413\n",
      "Episode: 1011 Total reward: 10.0 Training loss: 209.8119 Explore P: 0.2410\n",
      "Episode: 1012 Total reward: 8.0 Training loss: 242.3999 Explore P: 0.2408\n",
      "Episode: 1013 Total reward: 11.0 Training loss: 840.8358 Explore P: 0.2406\n",
      "Episode: 1014 Total reward: 13.0 Training loss: 2580.0610 Explore P: 0.2403\n",
      "Episode: 1015 Total reward: 11.0 Training loss: 737.0168 Explore P: 0.2400\n",
      "Episode: 1016 Total reward: 10.0 Training loss: 619.5573 Explore P: 0.2398\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1017 Total reward: 11.0 Training loss: 1208.1055 Explore P: 0.2395\n",
      "Episode: 1018 Total reward: 10.0 Training loss: 1322.2396 Explore P: 0.2393\n",
      "Episode: 1019 Total reward: 9.0 Training loss: 806.2779 Explore P: 0.2391\n",
      "Episode: 1020 Total reward: 11.0 Training loss: 395.6642 Explore P: 0.2389\n",
      "Episode: 1021 Total reward: 33.0 Training loss: 1022.0863 Explore P: 0.2381\n",
      "Episode: 1022 Total reward: 12.0 Training loss: 150.2519 Explore P: 0.2378\n",
      "Episode: 1023 Total reward: 12.0 Training loss: 763.6758 Explore P: 0.2376\n",
      "Episode: 1024 Total reward: 8.0 Training loss: 193.6178 Explore P: 0.2374\n",
      "Episode: 1025 Total reward: 12.0 Training loss: 320.6198 Explore P: 0.2371\n",
      "Episode: 1026 Total reward: 8.0 Training loss: 717.2416 Explore P: 0.2369\n",
      "Episode: 1027 Total reward: 8.0 Training loss: 886.4008 Explore P: 0.2367\n",
      "Episode: 1028 Total reward: 9.0 Training loss: 406.2302 Explore P: 0.2365\n",
      "Episode: 1029 Total reward: 10.0 Training loss: 286.4001 Explore P: 0.2363\n",
      "Episode: 1030 Total reward: 11.0 Training loss: 1986.0750 Explore P: 0.2361\n",
      "Episode: 1031 Total reward: 11.0 Training loss: 900.5348 Explore P: 0.2358\n",
      "Episode: 1032 Total reward: 12.0 Training loss: 611.0513 Explore P: 0.2355\n",
      "Episode: 1033 Total reward: 8.0 Training loss: 3463.0625 Explore P: 0.2354\n",
      "Episode: 1034 Total reward: 9.0 Training loss: 667.6007 Explore P: 0.2352\n",
      "Episode: 1035 Total reward: 10.0 Training loss: 730.0560 Explore P: 0.2349\n",
      "Episode: 1036 Total reward: 10.0 Training loss: 271.0728 Explore P: 0.2347\n",
      "Episode: 1037 Total reward: 12.0 Training loss: 336.7414 Explore P: 0.2344\n",
      "Episode: 1038 Total reward: 11.0 Training loss: 439.2216 Explore P: 0.2342\n",
      "Episode: 1039 Total reward: 17.0 Training loss: 2649.7297 Explore P: 0.2338\n",
      "Episode: 1040 Total reward: 9.0 Training loss: 445.6523 Explore P: 0.2336\n",
      "Episode: 1041 Total reward: 16.0 Training loss: 1132.6542 Explore P: 0.2333\n",
      "Episode: 1042 Total reward: 14.0 Training loss: 1189.6351 Explore P: 0.2329\n",
      "Episode: 1043 Total reward: 17.0 Training loss: 2921.7478 Explore P: 0.2326\n",
      "Episode: 1044 Total reward: 11.0 Training loss: 637.9093 Explore P: 0.2323\n",
      "Episode: 1045 Total reward: 29.0 Training loss: 2314.1602 Explore P: 0.2317\n",
      "Episode: 1046 Total reward: 9.0 Training loss: 414.3114 Explore P: 0.2315\n",
      "Episode: 1047 Total reward: 22.0 Training loss: 606.3114 Explore P: 0.2310\n",
      "Episode: 1048 Total reward: 9.0 Training loss: 583.7202 Explore P: 0.2308\n",
      "Episode: 1049 Total reward: 9.0 Training loss: 124.7756 Explore P: 0.2306\n",
      "Episode: 1050 Total reward: 9.0 Training loss: 155.9641 Explore P: 0.2304\n",
      "Episode: 1051 Total reward: 9.0 Training loss: 994.2257 Explore P: 0.2302\n",
      "Episode: 1052 Total reward: 9.0 Training loss: 340.2350 Explore P: 0.2300\n",
      "Episode: 1053 Total reward: 9.0 Training loss: 2853.8630 Explore P: 0.2298\n",
      "Episode: 1054 Total reward: 9.0 Training loss: 1431.0223 Explore P: 0.2296\n",
      "Episode: 1055 Total reward: 16.0 Training loss: 661.6915 Explore P: 0.2292\n",
      "Episode: 1056 Total reward: 9.0 Training loss: 127.7521 Explore P: 0.2291\n",
      "Episode: 1057 Total reward: 9.0 Training loss: 791.8040 Explore P: 0.2289\n",
      "Episode: 1058 Total reward: 10.0 Training loss: 685.9922 Explore P: 0.2286\n",
      "Episode: 1059 Total reward: 25.0 Training loss: 512.3090 Explore P: 0.2281\n",
      "Episode: 1060 Total reward: 9.0 Training loss: 223.6655 Explore P: 0.2279\n",
      "Episode: 1061 Total reward: 13.0 Training loss: 1018.2752 Explore P: 0.2276\n",
      "Episode: 1062 Total reward: 14.0 Training loss: 283.3904 Explore P: 0.2273\n",
      "Episode: 1063 Total reward: 10.0 Training loss: 2553.0566 Explore P: 0.2271\n",
      "Episode: 1064 Total reward: 8.0 Training loss: 821.7480 Explore P: 0.2269\n",
      "Episode: 1065 Total reward: 20.0 Training loss: 1816.5648 Explore P: 0.2265\n",
      "Episode: 1066 Total reward: 11.0 Training loss: 679.4467 Explore P: 0.2262\n",
      "Episode: 1067 Total reward: 8.0 Training loss: 586.6835 Explore P: 0.2261\n",
      "Episode: 1068 Total reward: 20.0 Training loss: 632.0278 Explore P: 0.2256\n",
      "Episode: 1069 Total reward: 8.0 Training loss: 701.1323 Explore P: 0.2255\n",
      "Episode: 1070 Total reward: 10.0 Training loss: 2566.5496 Explore P: 0.2253\n",
      "Episode: 1071 Total reward: 7.0 Training loss: 987.3622 Explore P: 0.2251\n",
      "Episode: 1072 Total reward: 13.0 Training loss: 377.5107 Explore P: 0.2248\n",
      "Episode: 1073 Total reward: 10.0 Training loss: 652.5380 Explore P: 0.2246\n",
      "Episode: 1074 Total reward: 11.0 Training loss: 602.1261 Explore P: 0.2244\n",
      "Episode: 1075 Total reward: 13.0 Training loss: 577.6284 Explore P: 0.2241\n",
      "Episode: 1076 Total reward: 12.0 Training loss: 312.7336 Explore P: 0.2238\n",
      "Episode: 1077 Total reward: 13.0 Training loss: 1141.0848 Explore P: 0.2236\n",
      "Episode: 1078 Total reward: 11.0 Training loss: 570.9733 Explore P: 0.2233\n",
      "Episode: 1079 Total reward: 11.0 Training loss: 425.6224 Explore P: 0.2231\n",
      "Episode: 1080 Total reward: 12.0 Training loss: 2256.3804 Explore P: 0.2228\n",
      "Episode: 1081 Total reward: 7.0 Training loss: 188.0854 Explore P: 0.2227\n",
      "Episode: 1082 Total reward: 15.0 Training loss: 305.5719 Explore P: 0.2224\n",
      "Episode: 1083 Total reward: 9.0 Training loss: 478.2649 Explore P: 0.2222\n",
      "Episode: 1084 Total reward: 8.0 Training loss: 329.2676 Explore P: 0.2220\n",
      "Episode: 1085 Total reward: 11.0 Training loss: 1092.5442 Explore P: 0.2218\n",
      "Episode: 1086 Total reward: 10.0 Training loss: 210.9654 Explore P: 0.2216\n",
      "Episode: 1087 Total reward: 8.0 Training loss: 410.2987 Explore P: 0.2214\n",
      "Episode: 1088 Total reward: 11.0 Training loss: 1034.6355 Explore P: 0.2212\n",
      "Episode: 1089 Total reward: 8.0 Training loss: 697.9146 Explore P: 0.2210\n",
      "Episode: 1090 Total reward: 12.0 Training loss: 335.7574 Explore P: 0.2207\n",
      "Episode: 1091 Total reward: 9.0 Training loss: 704.9634 Explore P: 0.2205\n",
      "Episode: 1092 Total reward: 11.0 Training loss: 1203.9128 Explore P: 0.2203\n",
      "Episode: 1093 Total reward: 13.0 Training loss: 504.5979 Explore P: 0.2200\n",
      "Episode: 1094 Total reward: 7.0 Training loss: 3266.8521 Explore P: 0.2199\n",
      "Episode: 1095 Total reward: 10.0 Training loss: 148.3978 Explore P: 0.2197\n",
      "Episode: 1096 Total reward: 12.0 Training loss: 1333.7219 Explore P: 0.2194\n",
      "Episode: 1097 Total reward: 10.0 Training loss: 547.0098 Explore P: 0.2192\n",
      "Episode: 1098 Total reward: 12.0 Training loss: 389.3209 Explore P: 0.2190\n",
      "Episode: 1099 Total reward: 9.0 Training loss: 252.0829 Explore P: 0.2188\n",
      "Episode: 1100 Total reward: 9.0 Training loss: 514.3209 Explore P: 0.2186\n",
      "Episode: 1101 Total reward: 12.0 Training loss: 244.9868 Explore P: 0.2183\n",
      "Episode: 1102 Total reward: 9.0 Training loss: 290.1400 Explore P: 0.2182\n",
      "Episode: 1103 Total reward: 11.0 Training loss: 3698.4673 Explore P: 0.2179\n",
      "Episode: 1104 Total reward: 11.0 Training loss: 652.0079 Explore P: 0.2177\n",
      "Episode: 1105 Total reward: 17.0 Training loss: 315.3599 Explore P: 0.2173\n",
      "Episode: 1106 Total reward: 14.0 Training loss: 1125.2076 Explore P: 0.2171\n",
      "Episode: 1107 Total reward: 11.0 Training loss: 1200.0646 Explore P: 0.2168\n",
      "Episode: 1108 Total reward: 11.0 Training loss: 418.5525 Explore P: 0.2166\n",
      "Episode: 1109 Total reward: 9.0 Training loss: 1473.5022 Explore P: 0.2164\n",
      "Episode: 1110 Total reward: 11.0 Training loss: 1015.9072 Explore P: 0.2162\n",
      "Episode: 1111 Total reward: 13.0 Training loss: 2184.9973 Explore P: 0.2159\n",
      "Episode: 1112 Total reward: 9.0 Training loss: 1723.6794 Explore P: 0.2157\n",
      "Episode: 1113 Total reward: 10.0 Training loss: 1479.6458 Explore P: 0.2155\n",
      "Episode: 1114 Total reward: 14.0 Training loss: 717.5121 Explore P: 0.2152\n",
      "Episode: 1115 Total reward: 12.0 Training loss: 798.1403 Explore P: 0.2150\n",
      "Episode: 1116 Total reward: 27.0 Training loss: 697.4999 Explore P: 0.2144\n",
      "Episode: 1117 Total reward: 8.0 Training loss: 419.1746 Explore P: 0.2143\n",
      "Episode: 1118 Total reward: 11.0 Training loss: 175.1305 Explore P: 0.2141\n",
      "Episode: 1119 Total reward: 10.0 Training loss: 310.5104 Explore P: 0.2139\n",
      "Episode: 1120 Total reward: 8.0 Training loss: 3671.9792 Explore P: 0.2137\n",
      "Episode: 1121 Total reward: 15.0 Training loss: 2139.9226 Explore P: 0.2134\n",
      "Episode: 1122 Total reward: 7.0 Training loss: 465.4241 Explore P: 0.2132\n",
      "Episode: 1123 Total reward: 10.0 Training loss: 723.1748 Explore P: 0.2130\n",
      "Episode: 1124 Total reward: 11.0 Training loss: 282.6806 Explore P: 0.2128\n",
      "Episode: 1125 Total reward: 13.0 Training loss: 927.9230 Explore P: 0.2126\n",
      "Episode: 1126 Total reward: 10.0 Training loss: 1458.1287 Explore P: 0.2124\n",
      "Episode: 1127 Total reward: 11.0 Training loss: 266.1846 Explore P: 0.2121\n",
      "Episode: 1128 Total reward: 13.0 Training loss: 3626.8931 Explore P: 0.2119\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1129 Total reward: 15.0 Training loss: 764.3324 Explore P: 0.2116\n",
      "Episode: 1130 Total reward: 8.0 Training loss: 1862.6897 Explore P: 0.2114\n",
      "Episode: 1131 Total reward: 8.0 Training loss: 342.5875 Explore P: 0.2112\n",
      "Episode: 1132 Total reward: 9.0 Training loss: 254.9674 Explore P: 0.2111\n",
      "Episode: 1133 Total reward: 9.0 Training loss: 1285.2970 Explore P: 0.2109\n",
      "Episode: 1134 Total reward: 11.0 Training loss: 447.3548 Explore P: 0.2107\n",
      "Episode: 1135 Total reward: 9.0 Training loss: 771.2749 Explore P: 0.2105\n",
      "Episode: 1136 Total reward: 9.0 Training loss: 1013.0162 Explore P: 0.2103\n",
      "Episode: 1137 Total reward: 8.0 Training loss: 571.9601 Explore P: 0.2101\n",
      "Episode: 1138 Total reward: 11.0 Training loss: 233.5065 Explore P: 0.2099\n",
      "Episode: 1139 Total reward: 12.0 Training loss: 1536.8464 Explore P: 0.2097\n",
      "Episode: 1140 Total reward: 17.0 Training loss: 226.6895 Explore P: 0.2093\n",
      "Episode: 1141 Total reward: 10.0 Training loss: 2557.5022 Explore P: 0.2091\n",
      "Episode: 1142 Total reward: 7.0 Training loss: 107.6527 Explore P: 0.2090\n",
      "Episode: 1143 Total reward: 12.0 Training loss: 1112.2161 Explore P: 0.2088\n",
      "Episode: 1144 Total reward: 15.0 Training loss: 1306.6881 Explore P: 0.2085\n",
      "Episode: 1145 Total reward: 9.0 Training loss: 1302.9291 Explore P: 0.2083\n",
      "Episode: 1146 Total reward: 9.0 Training loss: 1276.4031 Explore P: 0.2081\n",
      "Episode: 1147 Total reward: 14.0 Training loss: 169.4732 Explore P: 0.2078\n",
      "Episode: 1148 Total reward: 9.0 Training loss: 247.7120 Explore P: 0.2077\n",
      "Episode: 1149 Total reward: 20.0 Training loss: 1744.7480 Explore P: 0.2073\n",
      "Episode: 1150 Total reward: 7.0 Training loss: 416.6473 Explore P: 0.2071\n",
      "Episode: 1151 Total reward: 9.0 Training loss: 2614.2422 Explore P: 0.2069\n",
      "Episode: 1152 Total reward: 9.0 Training loss: 1319.5426 Explore P: 0.2068\n",
      "Episode: 1153 Total reward: 11.0 Training loss: 1206.4468 Explore P: 0.2065\n",
      "Episode: 1154 Total reward: 9.0 Training loss: 492.4227 Explore P: 0.2064\n",
      "Episode: 1155 Total reward: 11.0 Training loss: 376.0627 Explore P: 0.2062\n",
      "Episode: 1156 Total reward: 9.0 Training loss: 296.3431 Explore P: 0.2060\n",
      "Episode: 1157 Total reward: 8.0 Training loss: 1845.4871 Explore P: 0.2058\n",
      "Episode: 1158 Total reward: 15.0 Training loss: 315.9004 Explore P: 0.2055\n",
      "Episode: 1159 Total reward: 17.0 Training loss: 230.6184 Explore P: 0.2052\n",
      "Episode: 1160 Total reward: 10.0 Training loss: 598.4613 Explore P: 0.2050\n",
      "Episode: 1161 Total reward: 14.0 Training loss: 1767.5072 Explore P: 0.2047\n",
      "Episode: 1162 Total reward: 8.0 Training loss: 144.3255 Explore P: 0.2046\n",
      "Episode: 1163 Total reward: 15.0 Training loss: 875.9189 Explore P: 0.2043\n",
      "Episode: 1164 Total reward: 9.0 Training loss: 1774.8473 Explore P: 0.2041\n",
      "Episode: 1165 Total reward: 11.0 Training loss: 642.3191 Explore P: 0.2039\n",
      "Episode: 1166 Total reward: 9.0 Training loss: 2500.0664 Explore P: 0.2037\n",
      "Episode: 1167 Total reward: 21.0 Training loss: 797.2349 Explore P: 0.2033\n",
      "Episode: 1168 Total reward: 13.0 Training loss: 632.6275 Explore P: 0.2031\n",
      "Episode: 1169 Total reward: 10.0 Training loss: 1754.7375 Explore P: 0.2029\n",
      "Episode: 1170 Total reward: 9.0 Training loss: 625.1165 Explore P: 0.2027\n",
      "Episode: 1171 Total reward: 13.0 Training loss: 362.1147 Explore P: 0.2024\n",
      "Episode: 1172 Total reward: 13.0 Training loss: 630.0151 Explore P: 0.2022\n",
      "Episode: 1173 Total reward: 15.0 Training loss: 603.7399 Explore P: 0.2019\n",
      "Episode: 1174 Total reward: 12.0 Training loss: 709.0557 Explore P: 0.2017\n",
      "Episode: 1175 Total reward: 10.0 Training loss: 690.1738 Explore P: 0.2015\n",
      "Episode: 1176 Total reward: 9.0 Training loss: 408.6387 Explore P: 0.2013\n",
      "Episode: 1177 Total reward: 8.0 Training loss: 1065.4929 Explore P: 0.2012\n",
      "Episode: 1178 Total reward: 8.0 Training loss: 907.9313 Explore P: 0.2010\n",
      "Episode: 1179 Total reward: 8.0 Training loss: 1270.4320 Explore P: 0.2009\n",
      "Episode: 1180 Total reward: 13.0 Training loss: 533.4147 Explore P: 0.2006\n",
      "Episode: 1181 Total reward: 12.0 Training loss: 1786.8977 Explore P: 0.2004\n",
      "Episode: 1182 Total reward: 10.0 Training loss: 2746.7363 Explore P: 0.2002\n",
      "Episode: 1183 Total reward: 8.0 Training loss: 486.5067 Explore P: 0.2000\n",
      "Episode: 1184 Total reward: 11.0 Training loss: 1719.0442 Explore P: 0.1998\n",
      "Episode: 1185 Total reward: 10.0 Training loss: 546.3524 Explore P: 0.1996\n",
      "Episode: 1186 Total reward: 9.0 Training loss: 324.2699 Explore P: 0.1995\n",
      "Episode: 1187 Total reward: 10.0 Training loss: 397.4929 Explore P: 0.1993\n",
      "Episode: 1188 Total reward: 10.0 Training loss: 622.2964 Explore P: 0.1991\n",
      "Episode: 1189 Total reward: 11.0 Training loss: 1102.3694 Explore P: 0.1989\n",
      "Episode: 1190 Total reward: 14.0 Training loss: 1109.8035 Explore P: 0.1986\n",
      "Episode: 1191 Total reward: 11.0 Training loss: 298.1993 Explore P: 0.1984\n",
      "Episode: 1192 Total reward: 8.0 Training loss: 292.8669 Explore P: 0.1983\n",
      "Episode: 1193 Total reward: 11.0 Training loss: 649.1551 Explore P: 0.1980\n",
      "Episode: 1194 Total reward: 11.0 Training loss: 432.6266 Explore P: 0.1978\n",
      "Episode: 1195 Total reward: 10.0 Training loss: 268.3752 Explore P: 0.1977\n",
      "Episode: 1196 Total reward: 12.0 Training loss: 2622.8450 Explore P: 0.1974\n",
      "Episode: 1197 Total reward: 10.0 Training loss: 983.4059 Explore P: 0.1972\n",
      "Episode: 1198 Total reward: 12.0 Training loss: 378.5725 Explore P: 0.1970\n",
      "Episode: 1199 Total reward: 11.0 Training loss: 809.6576 Explore P: 0.1968\n",
      "Episode: 1200 Total reward: 11.0 Training loss: 816.3911 Explore P: 0.1966\n",
      "Episode: 1201 Total reward: 11.0 Training loss: 1064.1891 Explore P: 0.1964\n",
      "Episode: 1202 Total reward: 7.0 Training loss: 475.7571 Explore P: 0.1963\n",
      "Episode: 1203 Total reward: 8.0 Training loss: 631.9582 Explore P: 0.1961\n",
      "Episode: 1204 Total reward: 12.0 Training loss: 236.8718 Explore P: 0.1959\n",
      "Episode: 1205 Total reward: 10.0 Training loss: 550.3539 Explore P: 0.1957\n",
      "Episode: 1206 Total reward: 11.0 Training loss: 906.8560 Explore P: 0.1955\n",
      "Episode: 1207 Total reward: 12.0 Training loss: 3099.9390 Explore P: 0.1953\n",
      "Episode: 1208 Total reward: 14.0 Training loss: 328.9551 Explore P: 0.1950\n",
      "Episode: 1209 Total reward: 14.0 Training loss: 1170.5989 Explore P: 0.1948\n",
      "Episode: 1210 Total reward: 9.0 Training loss: 425.0859 Explore P: 0.1946\n",
      "Episode: 1211 Total reward: 8.0 Training loss: 2504.7310 Explore P: 0.1945\n",
      "Episode: 1212 Total reward: 11.0 Training loss: 207.3831 Explore P: 0.1943\n",
      "Episode: 1213 Total reward: 11.0 Training loss: 2650.0984 Explore P: 0.1940\n",
      "Episode: 1214 Total reward: 12.0 Training loss: 586.8812 Explore P: 0.1938\n",
      "Episode: 1215 Total reward: 14.0 Training loss: 979.4935 Explore P: 0.1936\n",
      "Episode: 1216 Total reward: 10.0 Training loss: 573.0052 Explore P: 0.1934\n",
      "Episode: 1217 Total reward: 9.0 Training loss: 248.0464 Explore P: 0.1932\n",
      "Episode: 1218 Total reward: 11.0 Training loss: 940.8057 Explore P: 0.1930\n",
      "Episode: 1219 Total reward: 15.0 Training loss: 595.6146 Explore P: 0.1927\n",
      "Episode: 1220 Total reward: 13.0 Training loss: 2335.5688 Explore P: 0.1925\n",
      "Episode: 1221 Total reward: 7.0 Training loss: 114.8278 Explore P: 0.1924\n",
      "Episode: 1222 Total reward: 10.0 Training loss: 1363.6686 Explore P: 0.1922\n",
      "Episode: 1223 Total reward: 10.0 Training loss: 375.1075 Explore P: 0.1920\n",
      "Episode: 1224 Total reward: 13.0 Training loss: 1206.7594 Explore P: 0.1918\n",
      "Episode: 1225 Total reward: 9.0 Training loss: 122.9308 Explore P: 0.1916\n",
      "Episode: 1226 Total reward: 8.0 Training loss: 1632.2019 Explore P: 0.1915\n",
      "Episode: 1227 Total reward: 10.0 Training loss: 456.8061 Explore P: 0.1913\n",
      "Episode: 1228 Total reward: 7.0 Training loss: 936.6691 Explore P: 0.1912\n",
      "Episode: 1229 Total reward: 13.0 Training loss: 222.7340 Explore P: 0.1909\n",
      "Episode: 1230 Total reward: 9.0 Training loss: 266.0459 Explore P: 0.1908\n",
      "Episode: 1231 Total reward: 11.0 Training loss: 1692.7195 Explore P: 0.1906\n",
      "Episode: 1232 Total reward: 9.0 Training loss: 2760.8369 Explore P: 0.1904\n",
      "Episode: 1233 Total reward: 11.0 Training loss: 167.8433 Explore P: 0.1902\n",
      "Episode: 1234 Total reward: 11.0 Training loss: 243.7614 Explore P: 0.1900\n",
      "Episode: 1235 Total reward: 8.0 Training loss: 659.7488 Explore P: 0.1899\n",
      "Episode: 1236 Total reward: 17.0 Training loss: 1068.9097 Explore P: 0.1896\n",
      "Episode: 1237 Total reward: 10.0 Training loss: 294.2239 Explore P: 0.1894\n",
      "Episode: 1238 Total reward: 11.0 Training loss: 6360.8862 Explore P: 0.1892\n",
      "Episode: 1239 Total reward: 8.0 Training loss: 725.0370 Explore P: 0.1890\n",
      "Episode: 1240 Total reward: 10.0 Training loss: 1221.0920 Explore P: 0.1889\n",
      "Episode: 1241 Total reward: 8.0 Training loss: 768.4393 Explore P: 0.1887\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1242 Total reward: 11.0 Training loss: 886.2272 Explore P: 0.1885\n",
      "Episode: 1243 Total reward: 17.0 Training loss: 564.4727 Explore P: 0.1882\n",
      "Episode: 1244 Total reward: 10.0 Training loss: 1398.8438 Explore P: 0.1880\n",
      "Episode: 1245 Total reward: 11.0 Training loss: 484.2095 Explore P: 0.1878\n",
      "Episode: 1246 Total reward: 12.0 Training loss: 2145.2324 Explore P: 0.1876\n",
      "Episode: 1247 Total reward: 13.0 Training loss: 656.9036 Explore P: 0.1874\n",
      "Episode: 1248 Total reward: 9.0 Training loss: 525.8317 Explore P: 0.1872\n",
      "Episode: 1249 Total reward: 12.0 Training loss: 482.7843 Explore P: 0.1870\n",
      "Episode: 1250 Total reward: 9.0 Training loss: 581.8821 Explore P: 0.1869\n",
      "Episode: 1251 Total reward: 12.0 Training loss: 143.6229 Explore P: 0.1867\n",
      "Episode: 1252 Total reward: 11.0 Training loss: 2048.3813 Explore P: 0.1865\n",
      "Episode: 1253 Total reward: 14.0 Training loss: 4688.2158 Explore P: 0.1862\n",
      "Episode: 1254 Total reward: 13.0 Training loss: 380.2302 Explore P: 0.1860\n",
      "Episode: 1255 Total reward: 10.0 Training loss: 1158.6272 Explore P: 0.1858\n",
      "Episode: 1256 Total reward: 14.0 Training loss: 607.9033 Explore P: 0.1856\n",
      "Episode: 1257 Total reward: 7.0 Training loss: 344.9128 Explore P: 0.1854\n",
      "Episode: 1258 Total reward: 11.0 Training loss: 645.9320 Explore P: 0.1852\n",
      "Episode: 1259 Total reward: 11.0 Training loss: 1409.5618 Explore P: 0.1851\n",
      "Episode: 1260 Total reward: 11.0 Training loss: 700.2990 Explore P: 0.1849\n",
      "Episode: 1261 Total reward: 15.0 Training loss: 851.4578 Explore P: 0.1846\n",
      "Episode: 1262 Total reward: 9.0 Training loss: 827.2142 Explore P: 0.1844\n",
      "Episode: 1263 Total reward: 14.0 Training loss: 139.8374 Explore P: 0.1842\n",
      "Episode: 1264 Total reward: 8.0 Training loss: 390.2353 Explore P: 0.1841\n",
      "Episode: 1265 Total reward: 14.0 Training loss: 727.6119 Explore P: 0.1838\n",
      "Episode: 1266 Total reward: 10.0 Training loss: 1209.6624 Explore P: 0.1836\n",
      "Episode: 1267 Total reward: 9.0 Training loss: 478.5585 Explore P: 0.1835\n",
      "Episode: 1268 Total reward: 11.0 Training loss: 1730.3721 Explore P: 0.1833\n",
      "Episode: 1269 Total reward: 10.0 Training loss: 419.7248 Explore P: 0.1831\n",
      "Episode: 1270 Total reward: 11.0 Training loss: 417.2775 Explore P: 0.1829\n",
      "Episode: 1271 Total reward: 10.0 Training loss: 639.6542 Explore P: 0.1828\n",
      "Episode: 1272 Total reward: 9.0 Training loss: 703.6611 Explore P: 0.1826\n",
      "Episode: 1273 Total reward: 9.0 Training loss: 575.0196 Explore P: 0.1824\n",
      "Episode: 1274 Total reward: 18.0 Training loss: 1784.5599 Explore P: 0.1821\n",
      "Episode: 1275 Total reward: 10.0 Training loss: 712.1490 Explore P: 0.1820\n",
      "Episode: 1276 Total reward: 10.0 Training loss: 2910.8330 Explore P: 0.1818\n",
      "Episode: 1277 Total reward: 8.0 Training loss: 1219.6351 Explore P: 0.1817\n",
      "Episode: 1278 Total reward: 11.0 Training loss: 2086.6763 Explore P: 0.1815\n",
      "Episode: 1279 Total reward: 9.0 Training loss: 899.3564 Explore P: 0.1813\n",
      "Episode: 1280 Total reward: 9.0 Training loss: 445.2279 Explore P: 0.1812\n",
      "Episode: 1281 Total reward: 9.0 Training loss: 1313.4998 Explore P: 0.1810\n",
      "Episode: 1282 Total reward: 10.0 Training loss: 504.0939 Explore P: 0.1808\n",
      "Episode: 1283 Total reward: 10.0 Training loss: 323.9237 Explore P: 0.1807\n",
      "Episode: 1284 Total reward: 8.0 Training loss: 391.3064 Explore P: 0.1805\n",
      "Episode: 1285 Total reward: 14.0 Training loss: 338.9728 Explore P: 0.1803\n",
      "Episode: 1286 Total reward: 12.0 Training loss: 434.1240 Explore P: 0.1801\n",
      "Episode: 1287 Total reward: 8.0 Training loss: 1005.6533 Explore P: 0.1800\n",
      "Episode: 1288 Total reward: 11.0 Training loss: 302.1130 Explore P: 0.1798\n",
      "Episode: 1289 Total reward: 13.0 Training loss: 650.7520 Explore P: 0.1795\n",
      "Episode: 1290 Total reward: 11.0 Training loss: 501.1135 Explore P: 0.1794\n",
      "Episode: 1291 Total reward: 13.0 Training loss: 399.3162 Explore P: 0.1791\n",
      "Episode: 1292 Total reward: 11.0 Training loss: 661.4105 Explore P: 0.1790\n",
      "Episode: 1293 Total reward: 9.0 Training loss: 471.2469 Explore P: 0.1788\n",
      "Episode: 1294 Total reward: 9.0 Training loss: 423.5579 Explore P: 0.1786\n",
      "Episode: 1295 Total reward: 8.0 Training loss: 317.6291 Explore P: 0.1785\n",
      "Episode: 1296 Total reward: 9.0 Training loss: 184.5657 Explore P: 0.1784\n",
      "Episode: 1297 Total reward: 11.0 Training loss: 203.1703 Explore P: 0.1782\n",
      "Episode: 1298 Total reward: 11.0 Training loss: 849.9588 Explore P: 0.1780\n",
      "Episode: 1299 Total reward: 10.0 Training loss: 345.3775 Explore P: 0.1778\n",
      "Episode: 1300 Total reward: 9.0 Training loss: 183.4054 Explore P: 0.1777\n",
      "Episode: 1301 Total reward: 8.0 Training loss: 531.8893 Explore P: 0.1775\n",
      "Episode: 1302 Total reward: 13.0 Training loss: 1033.7761 Explore P: 0.1773\n",
      "Episode: 1303 Total reward: 11.0 Training loss: 466.8582 Explore P: 0.1771\n",
      "Episode: 1304 Total reward: 11.0 Training loss: 709.7086 Explore P: 0.1770\n",
      "Episode: 1305 Total reward: 11.0 Training loss: 353.4333 Explore P: 0.1768\n",
      "Episode: 1306 Total reward: 9.0 Training loss: 614.0482 Explore P: 0.1766\n",
      "Episode: 1307 Total reward: 12.0 Training loss: 1852.0082 Explore P: 0.1764\n",
      "Episode: 1308 Total reward: 9.0 Training loss: 1037.9684 Explore P: 0.1763\n",
      "Episode: 1309 Total reward: 7.0 Training loss: 719.3789 Explore P: 0.1762\n",
      "Episode: 1310 Total reward: 11.0 Training loss: 2390.0239 Explore P: 0.1760\n",
      "Episode: 1311 Total reward: 13.0 Training loss: 97.8495 Explore P: 0.1758\n",
      "Episode: 1312 Total reward: 8.0 Training loss: 185.8405 Explore P: 0.1756\n",
      "Episode: 1313 Total reward: 12.0 Training loss: 666.3231 Explore P: 0.1754\n",
      "Episode: 1314 Total reward: 10.0 Training loss: 724.8994 Explore P: 0.1753\n",
      "Episode: 1315 Total reward: 8.0 Training loss: 767.0949 Explore P: 0.1751\n",
      "Episode: 1316 Total reward: 8.0 Training loss: 1897.8281 Explore P: 0.1750\n",
      "Episode: 1317 Total reward: 9.0 Training loss: 2795.6997 Explore P: 0.1748\n",
      "Episode: 1318 Total reward: 11.0 Training loss: 260.1128 Explore P: 0.1747\n",
      "Episode: 1319 Total reward: 8.0 Training loss: 465.9504 Explore P: 0.1745\n",
      "Episode: 1320 Total reward: 11.0 Training loss: 764.8702 Explore P: 0.1744\n",
      "Episode: 1321 Total reward: 9.0 Training loss: 494.2281 Explore P: 0.1742\n",
      "Episode: 1322 Total reward: 15.0 Training loss: 113.7554 Explore P: 0.1740\n",
      "Episode: 1323 Total reward: 11.0 Training loss: 426.1209 Explore P: 0.1738\n",
      "Episode: 1324 Total reward: 12.0 Training loss: 1209.5397 Explore P: 0.1736\n",
      "Episode: 1325 Total reward: 10.0 Training loss: 716.4841 Explore P: 0.1734\n",
      "Episode: 1326 Total reward: 9.0 Training loss: 800.1422 Explore P: 0.1733\n",
      "Episode: 1327 Total reward: 7.0 Training loss: 443.3115 Explore P: 0.1732\n",
      "Episode: 1328 Total reward: 11.0 Training loss: 1763.8025 Explore P: 0.1730\n",
      "Episode: 1329 Total reward: 10.0 Training loss: 495.4818 Explore P: 0.1728\n",
      "Episode: 1330 Total reward: 9.0 Training loss: 2089.6860 Explore P: 0.1727\n",
      "Episode: 1331 Total reward: 8.0 Training loss: 464.5166 Explore P: 0.1725\n",
      "Episode: 1332 Total reward: 10.0 Training loss: 463.6187 Explore P: 0.1724\n",
      "Episode: 1333 Total reward: 9.0 Training loss: 2528.1106 Explore P: 0.1722\n",
      "Episode: 1334 Total reward: 11.0 Training loss: 363.3320 Explore P: 0.1721\n",
      "Episode: 1335 Total reward: 9.0 Training loss: 870.9896 Explore P: 0.1719\n",
      "Episode: 1336 Total reward: 10.0 Training loss: 943.1782 Explore P: 0.1717\n",
      "Episode: 1337 Total reward: 7.0 Training loss: 4220.7007 Explore P: 0.1716\n",
      "Episode: 1338 Total reward: 11.0 Training loss: 2404.7280 Explore P: 0.1715\n",
      "Episode: 1339 Total reward: 11.0 Training loss: 668.6720 Explore P: 0.1713\n",
      "Episode: 1340 Total reward: 10.0 Training loss: 1035.7693 Explore P: 0.1711\n",
      "Episode: 1341 Total reward: 8.0 Training loss: 2485.0505 Explore P: 0.1710\n",
      "Episode: 1342 Total reward: 9.0 Training loss: 499.2819 Explore P: 0.1708\n",
      "Episode: 1343 Total reward: 12.0 Training loss: 531.9929 Explore P: 0.1706\n",
      "Episode: 1344 Total reward: 10.0 Training loss: 499.4399 Explore P: 0.1705\n",
      "Episode: 1345 Total reward: 11.0 Training loss: 864.9910 Explore P: 0.1703\n",
      "Episode: 1346 Total reward: 11.0 Training loss: 880.0731 Explore P: 0.1701\n",
      "Episode: 1347 Total reward: 11.0 Training loss: 525.8718 Explore P: 0.1700\n",
      "Episode: 1348 Total reward: 11.0 Training loss: 1519.0212 Explore P: 0.1698\n",
      "Episode: 1349 Total reward: 8.0 Training loss: 735.5104 Explore P: 0.1697\n",
      "Episode: 1350 Total reward: 8.0 Training loss: 1636.7029 Explore P: 0.1695\n",
      "Episode: 1351 Total reward: 12.0 Training loss: 387.1216 Explore P: 0.1693\n",
      "Episode: 1352 Total reward: 9.0 Training loss: 491.8377 Explore P: 0.1692\n",
      "Episode: 1353 Total reward: 9.0 Training loss: 5025.0894 Explore P: 0.1690\n",
      "Episode: 1354 Total reward: 9.0 Training loss: 213.9216 Explore P: 0.1689\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1355 Total reward: 11.0 Training loss: 534.4569 Explore P: 0.1687\n",
      "Episode: 1356 Total reward: 12.0 Training loss: 503.7655 Explore P: 0.1685\n",
      "Episode: 1357 Total reward: 8.0 Training loss: 1113.6442 Explore P: 0.1684\n",
      "Episode: 1358 Total reward: 12.0 Training loss: 204.0066 Explore P: 0.1682\n",
      "Episode: 1359 Total reward: 11.0 Training loss: 1701.3330 Explore P: 0.1680\n",
      "Episode: 1360 Total reward: 10.0 Training loss: 603.1992 Explore P: 0.1679\n",
      "Episode: 1361 Total reward: 10.0 Training loss: 926.3101 Explore P: 0.1677\n",
      "Episode: 1362 Total reward: 10.0 Training loss: 370.4615 Explore P: 0.1676\n",
      "Episode: 1363 Total reward: 11.0 Training loss: 417.6152 Explore P: 0.1674\n",
      "Episode: 1364 Total reward: 10.0 Training loss: 114.2161 Explore P: 0.1672\n",
      "Episode: 1365 Total reward: 11.0 Training loss: 1418.1252 Explore P: 0.1671\n",
      "Episode: 1366 Total reward: 12.0 Training loss: 271.1321 Explore P: 0.1669\n",
      "Episode: 1367 Total reward: 7.0 Training loss: 213.8156 Explore P: 0.1668\n",
      "Episode: 1368 Total reward: 9.0 Training loss: 1434.9260 Explore P: 0.1666\n",
      "Episode: 1369 Total reward: 9.0 Training loss: 393.9216 Explore P: 0.1665\n",
      "Episode: 1370 Total reward: 16.0 Training loss: 447.4960 Explore P: 0.1662\n",
      "Episode: 1371 Total reward: 10.0 Training loss: 2291.8748 Explore P: 0.1661\n",
      "Episode: 1372 Total reward: 9.0 Training loss: 941.7816 Explore P: 0.1659\n",
      "Episode: 1373 Total reward: 10.0 Training loss: 2267.4036 Explore P: 0.1658\n",
      "Episode: 1374 Total reward: 11.0 Training loss: 207.2434 Explore P: 0.1656\n",
      "Episode: 1375 Total reward: 9.0 Training loss: 175.7196 Explore P: 0.1655\n",
      "Episode: 1376 Total reward: 16.0 Training loss: 327.3081 Explore P: 0.1652\n",
      "Episode: 1377 Total reward: 7.0 Training loss: 388.3322 Explore P: 0.1651\n",
      "Episode: 1378 Total reward: 11.0 Training loss: 719.7255 Explore P: 0.1650\n",
      "Episode: 1379 Total reward: 10.0 Training loss: 867.1949 Explore P: 0.1648\n",
      "Episode: 1380 Total reward: 8.0 Training loss: 133.6090 Explore P: 0.1647\n",
      "Episode: 1381 Total reward: 8.0 Training loss: 1580.9363 Explore P: 0.1645\n",
      "Episode: 1382 Total reward: 8.0 Training loss: 1083.1725 Explore P: 0.1644\n",
      "Episode: 1383 Total reward: 9.0 Training loss: 1013.3430 Explore P: 0.1643\n",
      "Episode: 1384 Total reward: 8.0 Training loss: 947.3830 Explore P: 0.1642\n",
      "Episode: 1385 Total reward: 10.0 Training loss: 1986.6230 Explore P: 0.1640\n",
      "Episode: 1386 Total reward: 7.0 Training loss: 1407.6343 Explore P: 0.1639\n",
      "Episode: 1387 Total reward: 7.0 Training loss: 6628.8398 Explore P: 0.1638\n",
      "Episode: 1388 Total reward: 15.0 Training loss: 1978.1602 Explore P: 0.1636\n",
      "Episode: 1389 Total reward: 12.0 Training loss: 789.5834 Explore P: 0.1634\n",
      "Episode: 1390 Total reward: 11.0 Training loss: 801.1752 Explore P: 0.1632\n",
      "Episode: 1391 Total reward: 15.0 Training loss: 587.7323 Explore P: 0.1630\n",
      "Episode: 1392 Total reward: 9.0 Training loss: 696.5997 Explore P: 0.1628\n",
      "Episode: 1393 Total reward: 8.0 Training loss: 1268.1887 Explore P: 0.1627\n",
      "Episode: 1394 Total reward: 13.0 Training loss: 465.7936 Explore P: 0.1625\n",
      "Episode: 1395 Total reward: 9.0 Training loss: 1847.0844 Explore P: 0.1624\n",
      "Episode: 1396 Total reward: 9.0 Training loss: 916.5096 Explore P: 0.1622\n",
      "Episode: 1397 Total reward: 11.0 Training loss: 132.4701 Explore P: 0.1621\n",
      "Episode: 1398 Total reward: 9.0 Training loss: 552.5438 Explore P: 0.1619\n",
      "Episode: 1399 Total reward: 8.0 Training loss: 759.5358 Explore P: 0.1618\n",
      "Episode: 1400 Total reward: 9.0 Training loss: 220.9552 Explore P: 0.1617\n",
      "Episode: 1401 Total reward: 9.0 Training loss: 9568.8691 Explore P: 0.1615\n",
      "Episode: 1402 Total reward: 10.0 Training loss: 996.1254 Explore P: 0.1614\n",
      "Episode: 1403 Total reward: 10.0 Training loss: 553.0570 Explore P: 0.1612\n",
      "Episode: 1404 Total reward: 8.0 Training loss: 1030.0455 Explore P: 0.1611\n",
      "Episode: 1405 Total reward: 9.0 Training loss: 3502.6235 Explore P: 0.1610\n",
      "Episode: 1406 Total reward: 9.0 Training loss: 4671.4111 Explore P: 0.1609\n",
      "Episode: 1407 Total reward: 10.0 Training loss: 1426.4814 Explore P: 0.1607\n",
      "Episode: 1408 Total reward: 10.0 Training loss: 407.6182 Explore P: 0.1606\n",
      "Episode: 1409 Total reward: 9.0 Training loss: 365.1553 Explore P: 0.1604\n",
      "Episode: 1410 Total reward: 10.0 Training loss: 1046.4358 Explore P: 0.1603\n",
      "Episode: 1411 Total reward: 9.0 Training loss: 614.8549 Explore P: 0.1601\n",
      "Episode: 1412 Total reward: 8.0 Training loss: 144.3399 Explore P: 0.1600\n",
      "Episode: 1413 Total reward: 11.0 Training loss: 424.5671 Explore P: 0.1598\n",
      "Episode: 1414 Total reward: 16.0 Training loss: 7797.1108 Explore P: 0.1596\n",
      "Episode: 1415 Total reward: 10.0 Training loss: 1935.6492 Explore P: 0.1595\n",
      "Episode: 1416 Total reward: 8.0 Training loss: 2321.1755 Explore P: 0.1593\n",
      "Episode: 1417 Total reward: 9.0 Training loss: 429.3803 Explore P: 0.1592\n",
      "Episode: 1418 Total reward: 11.0 Training loss: 360.5735 Explore P: 0.1590\n",
      "Episode: 1419 Total reward: 9.0 Training loss: 1295.0443 Explore P: 0.1589\n",
      "Episode: 1420 Total reward: 8.0 Training loss: 281.3378 Explore P: 0.1588\n",
      "Episode: 1421 Total reward: 11.0 Training loss: 359.6483 Explore P: 0.1586\n",
      "Episode: 1422 Total reward: 10.0 Training loss: 2177.6580 Explore P: 0.1585\n",
      "Episode: 1423 Total reward: 11.0 Training loss: 1991.9700 Explore P: 0.1583\n",
      "Episode: 1424 Total reward: 10.0 Training loss: 895.0197 Explore P: 0.1582\n",
      "Episode: 1425 Total reward: 16.0 Training loss: 320.2981 Explore P: 0.1579\n",
      "Episode: 1426 Total reward: 10.0 Training loss: 294.3906 Explore P: 0.1578\n",
      "Episode: 1427 Total reward: 11.0 Training loss: 716.5966 Explore P: 0.1576\n",
      "Episode: 1428 Total reward: 9.0 Training loss: 1379.7954 Explore P: 0.1575\n",
      "Episode: 1429 Total reward: 10.0 Training loss: 616.6627 Explore P: 0.1573\n",
      "Episode: 1430 Total reward: 11.0 Training loss: 3231.8235 Explore P: 0.1572\n",
      "Episode: 1431 Total reward: 9.0 Training loss: 957.4518 Explore P: 0.1570\n",
      "Episode: 1432 Total reward: 10.0 Training loss: 165.3986 Explore P: 0.1569\n",
      "Episode: 1433 Total reward: 21.0 Training loss: 624.2936 Explore P: 0.1566\n",
      "Episode: 1434 Total reward: 9.0 Training loss: 1665.3389 Explore P: 0.1565\n",
      "Episode: 1435 Total reward: 9.0 Training loss: 246.3257 Explore P: 0.1563\n",
      "Episode: 1436 Total reward: 12.0 Training loss: 78.0526 Explore P: 0.1561\n",
      "Episode: 1437 Total reward: 8.0 Training loss: 533.8959 Explore P: 0.1560\n",
      "Episode: 1438 Total reward: 16.0 Training loss: 545.9818 Explore P: 0.1558\n",
      "Episode: 1439 Total reward: 8.0 Training loss: 3061.1633 Explore P: 0.1557\n",
      "Episode: 1440 Total reward: 8.0 Training loss: 677.0819 Explore P: 0.1556\n",
      "Episode: 1441 Total reward: 11.0 Training loss: 1120.9232 Explore P: 0.1554\n",
      "Episode: 1442 Total reward: 14.0 Training loss: 1554.4440 Explore P: 0.1552\n",
      "Episode: 1443 Total reward: 13.0 Training loss: 3604.4512 Explore P: 0.1550\n",
      "Episode: 1444 Total reward: 17.0 Training loss: 547.5573 Explore P: 0.1548\n",
      "Episode: 1445 Total reward: 10.0 Training loss: 694.5548 Explore P: 0.1546\n",
      "Episode: 1446 Total reward: 11.0 Training loss: 871.8551 Explore P: 0.1545\n",
      "Episode: 1447 Total reward: 12.0 Training loss: 302.8139 Explore P: 0.1543\n",
      "Episode: 1448 Total reward: 9.0 Training loss: 1213.4338 Explore P: 0.1542\n",
      "Episode: 1449 Total reward: 13.0 Training loss: 445.3932 Explore P: 0.1540\n",
      "Episode: 1450 Total reward: 11.0 Training loss: 161.4715 Explore P: 0.1538\n",
      "Episode: 1451 Total reward: 15.0 Training loss: 791.5747 Explore P: 0.1536\n",
      "Episode: 1452 Total reward: 13.0 Training loss: 518.1713 Explore P: 0.1534\n",
      "Episode: 1453 Total reward: 10.0 Training loss: 906.7775 Explore P: 0.1533\n",
      "Episode: 1454 Total reward: 9.0 Training loss: 535.9245 Explore P: 0.1531\n",
      "Episode: 1455 Total reward: 11.0 Training loss: 1093.0494 Explore P: 0.1530\n",
      "Episode: 1456 Total reward: 9.0 Training loss: 624.6440 Explore P: 0.1529\n",
      "Episode: 1457 Total reward: 12.0 Training loss: 410.5303 Explore P: 0.1527\n",
      "Episode: 1458 Total reward: 8.0 Training loss: 339.8563 Explore P: 0.1526\n",
      "Episode: 1459 Total reward: 8.0 Training loss: 1258.8975 Explore P: 0.1525\n",
      "Episode: 1460 Total reward: 10.0 Training loss: 311.2819 Explore P: 0.1523\n",
      "Episode: 1461 Total reward: 13.0 Training loss: 1015.3098 Explore P: 0.1521\n",
      "Episode: 1462 Total reward: 15.0 Training loss: 1560.6702 Explore P: 0.1519\n",
      "Episode: 1463 Total reward: 13.0 Training loss: 233.6546 Explore P: 0.1517\n",
      "Episode: 1464 Total reward: 21.0 Training loss: 699.0406 Explore P: 0.1514\n",
      "Episode: 1465 Total reward: 11.0 Training loss: 2027.2705 Explore P: 0.1513\n",
      "Episode: 1466 Total reward: 9.0 Training loss: 759.9786 Explore P: 0.1511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1467 Total reward: 9.0 Training loss: 475.5817 Explore P: 0.1510\n",
      "Episode: 1468 Total reward: 22.0 Training loss: 1152.5129 Explore P: 0.1507\n",
      "Episode: 1469 Total reward: 10.0 Training loss: 396.8686 Explore P: 0.1506\n",
      "Episode: 1470 Total reward: 12.0 Training loss: 1099.8745 Explore P: 0.1504\n",
      "Episode: 1471 Total reward: 27.0 Training loss: 1168.1859 Explore P: 0.1500\n",
      "Episode: 1472 Total reward: 8.0 Training loss: 1255.2145 Explore P: 0.1499\n",
      "Episode: 1473 Total reward: 10.0 Training loss: 781.0021 Explore P: 0.1498\n",
      "Episode: 1474 Total reward: 9.0 Training loss: 247.9781 Explore P: 0.1496\n",
      "Episode: 1475 Total reward: 10.0 Training loss: 419.0500 Explore P: 0.1495\n",
      "Episode: 1476 Total reward: 8.0 Training loss: 517.3343 Explore P: 0.1494\n",
      "Episode: 1477 Total reward: 10.0 Training loss: 979.3057 Explore P: 0.1493\n",
      "Episode: 1478 Total reward: 8.0 Training loss: 1574.1454 Explore P: 0.1491\n",
      "Episode: 1479 Total reward: 10.0 Training loss: 435.9783 Explore P: 0.1490\n",
      "Episode: 1480 Total reward: 10.0 Training loss: 944.1500 Explore P: 0.1489\n",
      "Episode: 1481 Total reward: 12.0 Training loss: 594.7173 Explore P: 0.1487\n",
      "Episode: 1482 Total reward: 7.0 Training loss: 3640.5132 Explore P: 0.1486\n",
      "Episode: 1483 Total reward: 11.0 Training loss: 1781.6604 Explore P: 0.1484\n",
      "Episode: 1484 Total reward: 9.0 Training loss: 3633.8601 Explore P: 0.1483\n",
      "Episode: 1485 Total reward: 12.0 Training loss: 524.6109 Explore P: 0.1482\n",
      "Episode: 1486 Total reward: 10.0 Training loss: 1332.7021 Explore P: 0.1480\n",
      "Episode: 1487 Total reward: 8.0 Training loss: 531.4492 Explore P: 0.1479\n",
      "Episode: 1488 Total reward: 12.0 Training loss: 632.8517 Explore P: 0.1477\n",
      "Episode: 1489 Total reward: 9.0 Training loss: 1293.6447 Explore P: 0.1476\n",
      "Episode: 1490 Total reward: 12.0 Training loss: 537.3607 Explore P: 0.1475\n",
      "Episode: 1491 Total reward: 25.0 Training loss: 643.7567 Explore P: 0.1471\n",
      "Episode: 1492 Total reward: 11.0 Training loss: 494.9252 Explore P: 0.1470\n",
      "Episode: 1493 Total reward: 9.0 Training loss: 670.1197 Explore P: 0.1468\n",
      "Episode: 1494 Total reward: 10.0 Training loss: 746.4961 Explore P: 0.1467\n",
      "Episode: 1495 Total reward: 10.0 Training loss: 325.4190 Explore P: 0.1466\n",
      "Episode: 1496 Total reward: 11.0 Training loss: 760.7595 Explore P: 0.1464\n",
      "Episode: 1497 Total reward: 7.0 Training loss: 3840.1250 Explore P: 0.1463\n",
      "Episode: 1498 Total reward: 22.0 Training loss: 564.5672 Explore P: 0.1460\n",
      "Episode: 1499 Total reward: 13.0 Training loss: 1065.1359 Explore P: 0.1458\n",
      "Episode: 1500 Total reward: 11.0 Training loss: 1118.4413 Explore P: 0.1457\n",
      "Episode: 1501 Total reward: 11.0 Training loss: 1673.9524 Explore P: 0.1455\n",
      "Episode: 1502 Total reward: 12.0 Training loss: 426.1431 Explore P: 0.1454\n",
      "Episode: 1503 Total reward: 13.0 Training loss: 1140.0887 Explore P: 0.1452\n",
      "Episode: 1504 Total reward: 13.0 Training loss: 943.4559 Explore P: 0.1450\n",
      "Episode: 1505 Total reward: 15.0 Training loss: 523.0135 Explore P: 0.1448\n",
      "Episode: 1506 Total reward: 9.0 Training loss: 1284.4860 Explore P: 0.1447\n",
      "Episode: 1507 Total reward: 11.0 Training loss: 5870.4385 Explore P: 0.1446\n",
      "Episode: 1508 Total reward: 9.0 Training loss: 1452.6333 Explore P: 0.1444\n",
      "Episode: 1509 Total reward: 12.0 Training loss: 1647.6125 Explore P: 0.1443\n",
      "Episode: 1510 Total reward: 11.0 Training loss: 1933.5078 Explore P: 0.1441\n",
      "Episode: 1511 Total reward: 11.0 Training loss: 536.7353 Explore P: 0.1440\n",
      "Episode: 1512 Total reward: 11.0 Training loss: 407.5956 Explore P: 0.1438\n",
      "Episode: 1513 Total reward: 8.0 Training loss: 2416.2195 Explore P: 0.1437\n",
      "Episode: 1514 Total reward: 11.0 Training loss: 9400.0898 Explore P: 0.1436\n",
      "Episode: 1515 Total reward: 14.0 Training loss: 1097.8879 Explore P: 0.1434\n",
      "Episode: 1516 Total reward: 10.0 Training loss: 1221.3107 Explore P: 0.1433\n",
      "Episode: 1517 Total reward: 10.0 Training loss: 141.0621 Explore P: 0.1431\n",
      "Episode: 1518 Total reward: 10.0 Training loss: 376.3221 Explore P: 0.1430\n",
      "Episode: 1519 Total reward: 9.0 Training loss: 665.9667 Explore P: 0.1429\n",
      "Episode: 1520 Total reward: 8.0 Training loss: 196.5918 Explore P: 0.1428\n",
      "Episode: 1521 Total reward: 12.0 Training loss: 365.9978 Explore P: 0.1426\n",
      "Episode: 1522 Total reward: 8.0 Training loss: 116.7103 Explore P: 0.1425\n",
      "Episode: 1523 Total reward: 11.0 Training loss: 2865.6113 Explore P: 0.1424\n",
      "Episode: 1524 Total reward: 11.0 Training loss: 1385.9576 Explore P: 0.1422\n",
      "Episode: 1525 Total reward: 9.0 Training loss: 667.1966 Explore P: 0.1421\n",
      "Episode: 1526 Total reward: 9.0 Training loss: 862.3468 Explore P: 0.1420\n",
      "Episode: 1527 Total reward: 9.0 Training loss: 1016.5541 Explore P: 0.1419\n",
      "Episode: 1528 Total reward: 11.0 Training loss: 1208.1254 Explore P: 0.1417\n",
      "Episode: 1529 Total reward: 12.0 Training loss: 1843.3694 Explore P: 0.1416\n",
      "Episode: 1530 Total reward: 8.0 Training loss: 2802.5039 Explore P: 0.1414\n",
      "Episode: 1531 Total reward: 9.0 Training loss: 630.8704 Explore P: 0.1413\n",
      "Episode: 1532 Total reward: 10.0 Training loss: 3819.3730 Explore P: 0.1412\n",
      "Episode: 1533 Total reward: 9.0 Training loss: 251.7758 Explore P: 0.1411\n",
      "Episode: 1534 Total reward: 9.0 Training loss: 2368.8059 Explore P: 0.1410\n",
      "Episode: 1535 Total reward: 8.0 Training loss: 3252.9275 Explore P: 0.1409\n",
      "Episode: 1536 Total reward: 9.0 Training loss: 736.3226 Explore P: 0.1407\n",
      "Episode: 1537 Total reward: 12.0 Training loss: 1278.1119 Explore P: 0.1406\n",
      "Episode: 1538 Total reward: 10.0 Training loss: 8621.9150 Explore P: 0.1405\n",
      "Episode: 1539 Total reward: 10.0 Training loss: 937.2136 Explore P: 0.1403\n",
      "Episode: 1540 Total reward: 8.0 Training loss: 2539.0266 Explore P: 0.1402\n",
      "Episode: 1541 Total reward: 9.0 Training loss: 712.9446 Explore P: 0.1401\n",
      "Episode: 1542 Total reward: 10.0 Training loss: 620.2243 Explore P: 0.1400\n",
      "Episode: 1543 Total reward: 11.0 Training loss: 1045.1550 Explore P: 0.1398\n",
      "Episode: 1544 Total reward: 8.0 Training loss: 311.8753 Explore P: 0.1397\n",
      "Episode: 1545 Total reward: 9.0 Training loss: 741.5474 Explore P: 0.1396\n",
      "Episode: 1546 Total reward: 13.0 Training loss: 133.8835 Explore P: 0.1394\n",
      "Episode: 1547 Total reward: 9.0 Training loss: 694.8969 Explore P: 0.1393\n",
      "Episode: 1548 Total reward: 9.0 Training loss: 324.2927 Explore P: 0.1392\n",
      "Episode: 1549 Total reward: 7.0 Training loss: 2316.1086 Explore P: 0.1391\n",
      "Episode: 1550 Total reward: 10.0 Training loss: 716.0553 Explore P: 0.1390\n",
      "Episode: 1551 Total reward: 9.0 Training loss: 2580.5244 Explore P: 0.1389\n",
      "Episode: 1552 Total reward: 10.0 Training loss: 365.4112 Explore P: 0.1387\n",
      "Episode: 1553 Total reward: 11.0 Training loss: 523.0052 Explore P: 0.1386\n",
      "Episode: 1554 Total reward: 9.0 Training loss: 797.3259 Explore P: 0.1385\n",
      "Episode: 1555 Total reward: 11.0 Training loss: 898.2951 Explore P: 0.1383\n",
      "Episode: 1556 Total reward: 8.0 Training loss: 535.1354 Explore P: 0.1382\n",
      "Episode: 1557 Total reward: 9.0 Training loss: 5115.9150 Explore P: 0.1381\n",
      "Episode: 1558 Total reward: 12.0 Training loss: 548.8206 Explore P: 0.1380\n",
      "Episode: 1559 Total reward: 12.0 Training loss: 805.7936 Explore P: 0.1378\n",
      "Episode: 1560 Total reward: 9.0 Training loss: 984.3730 Explore P: 0.1377\n",
      "Episode: 1561 Total reward: 15.0 Training loss: 238.3953 Explore P: 0.1375\n",
      "Episode: 1562 Total reward: 11.0 Training loss: 376.6936 Explore P: 0.1374\n",
      "Episode: 1563 Total reward: 13.0 Training loss: 729.5184 Explore P: 0.1372\n",
      "Episode: 1564 Total reward: 9.0 Training loss: 356.6783 Explore P: 0.1371\n",
      "Episode: 1565 Total reward: 11.0 Training loss: 399.4521 Explore P: 0.1370\n",
      "Episode: 1566 Total reward: 14.0 Training loss: 3112.1372 Explore P: 0.1368\n",
      "Episode: 1567 Total reward: 14.0 Training loss: 1356.6713 Explore P: 0.1366\n",
      "Episode: 1568 Total reward: 10.0 Training loss: 470.6008 Explore P: 0.1365\n",
      "Episode: 1569 Total reward: 9.0 Training loss: 1427.4045 Explore P: 0.1364\n",
      "Episode: 1570 Total reward: 10.0 Training loss: 698.8802 Explore P: 0.1362\n",
      "Episode: 1571 Total reward: 9.0 Training loss: 850.4591 Explore P: 0.1361\n",
      "Episode: 1572 Total reward: 16.0 Training loss: 304.8985 Explore P: 0.1359\n",
      "Episode: 1573 Total reward: 15.0 Training loss: 1243.1250 Explore P: 0.1357\n",
      "Episode: 1574 Total reward: 11.0 Training loss: 583.5994 Explore P: 0.1356\n",
      "Episode: 1575 Total reward: 12.0 Training loss: 455.0771 Explore P: 0.1354\n",
      "Episode: 1576 Total reward: 11.0 Training loss: 10558.4199 Explore P: 0.1353\n",
      "Episode: 1577 Total reward: 11.0 Training loss: 2518.5359 Explore P: 0.1352\n",
      "Episode: 1578 Total reward: 12.0 Training loss: 735.2798 Explore P: 0.1350\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1579 Total reward: 9.0 Training loss: 875.1955 Explore P: 0.1349\n",
      "Episode: 1580 Total reward: 8.0 Training loss: 1475.4194 Explore P: 0.1348\n",
      "Episode: 1581 Total reward: 14.0 Training loss: 453.0890 Explore P: 0.1346\n",
      "Episode: 1582 Total reward: 11.0 Training loss: 820.7402 Explore P: 0.1345\n",
      "Episode: 1583 Total reward: 10.0 Training loss: 244.7767 Explore P: 0.1344\n",
      "Episode: 1584 Total reward: 11.0 Training loss: 506.2877 Explore P: 0.1342\n",
      "Episode: 1585 Total reward: 11.0 Training loss: 922.1885 Explore P: 0.1341\n",
      "Episode: 1586 Total reward: 13.0 Training loss: 421.5457 Explore P: 0.1339\n",
      "Episode: 1587 Total reward: 10.0 Training loss: 676.6223 Explore P: 0.1338\n",
      "Episode: 1588 Total reward: 10.0 Training loss: 1823.1012 Explore P: 0.1337\n",
      "Episode: 1589 Total reward: 8.0 Training loss: 914.1630 Explore P: 0.1336\n",
      "Episode: 1590 Total reward: 8.0 Training loss: 74.7118 Explore P: 0.1335\n",
      "Episode: 1591 Total reward: 16.0 Training loss: 921.3314 Explore P: 0.1333\n",
      "Episode: 1592 Total reward: 12.0 Training loss: 1165.7207 Explore P: 0.1331\n",
      "Episode: 1593 Total reward: 11.0 Training loss: 126.6436 Explore P: 0.1330\n",
      "Episode: 1594 Total reward: 9.0 Training loss: 236.4564 Explore P: 0.1329\n",
      "Episode: 1595 Total reward: 11.0 Training loss: 228.4036 Explore P: 0.1328\n",
      "Episode: 1596 Total reward: 14.0 Training loss: 559.9142 Explore P: 0.1326\n",
      "Episode: 1597 Total reward: 10.0 Training loss: 619.4347 Explore P: 0.1325\n",
      "Episode: 1598 Total reward: 9.0 Training loss: 580.6708 Explore P: 0.1324\n",
      "Episode: 1599 Total reward: 23.0 Training loss: 3105.6375 Explore P: 0.1321\n",
      "Episode: 1600 Total reward: 7.0 Training loss: 242.0589 Explore P: 0.1320\n",
      "Episode: 1601 Total reward: 11.0 Training loss: 562.1913 Explore P: 0.1319\n",
      "Episode: 1602 Total reward: 10.0 Training loss: 756.8503 Explore P: 0.1317\n",
      "Episode: 1603 Total reward: 10.0 Training loss: 1601.8873 Explore P: 0.1316\n",
      "Episode: 1604 Total reward: 13.0 Training loss: 2123.6411 Explore P: 0.1315\n",
      "Episode: 1605 Total reward: 7.0 Training loss: 916.0088 Explore P: 0.1314\n",
      "Episode: 1606 Total reward: 9.0 Training loss: 214.7141 Explore P: 0.1313\n",
      "Episode: 1607 Total reward: 7.0 Training loss: 2944.7434 Explore P: 0.1312\n",
      "Episode: 1608 Total reward: 11.0 Training loss: 1406.0508 Explore P: 0.1310\n",
      "Episode: 1609 Total reward: 10.0 Training loss: 1363.8904 Explore P: 0.1309\n",
      "Episode: 1610 Total reward: 9.0 Training loss: 1245.8610 Explore P: 0.1308\n",
      "Episode: 1611 Total reward: 12.0 Training loss: 959.0371 Explore P: 0.1307\n",
      "Episode: 1612 Total reward: 7.0 Training loss: 1894.0564 Explore P: 0.1306\n",
      "Episode: 1613 Total reward: 9.0 Training loss: 128.2741 Explore P: 0.1305\n",
      "Episode: 1614 Total reward: 9.0 Training loss: 834.0485 Explore P: 0.1304\n",
      "Episode: 1615 Total reward: 9.0 Training loss: 849.5077 Explore P: 0.1303\n",
      "Episode: 1616 Total reward: 12.0 Training loss: 822.3777 Explore P: 0.1301\n",
      "Episode: 1617 Total reward: 11.0 Training loss: 600.2717 Explore P: 0.1300\n",
      "Episode: 1618 Total reward: 11.0 Training loss: 227.8594 Explore P: 0.1298\n",
      "Episode: 1619 Total reward: 11.0 Training loss: 454.2773 Explore P: 0.1297\n",
      "Episode: 1620 Total reward: 9.0 Training loss: 826.7780 Explore P: 0.1296\n",
      "Episode: 1621 Total reward: 7.0 Training loss: 956.8180 Explore P: 0.1295\n",
      "Episode: 1622 Total reward: 10.0 Training loss: 422.1485 Explore P: 0.1294\n",
      "Episode: 1623 Total reward: 10.0 Training loss: 385.7753 Explore P: 0.1293\n",
      "Episode: 1624 Total reward: 13.0 Training loss: 225.2979 Explore P: 0.1291\n",
      "Episode: 1625 Total reward: 9.0 Training loss: 1278.0060 Explore P: 0.1290\n",
      "Episode: 1626 Total reward: 9.0 Training loss: 836.2236 Explore P: 0.1289\n",
      "Episode: 1627 Total reward: 11.0 Training loss: 2300.3906 Explore P: 0.1288\n",
      "Episode: 1628 Total reward: 12.0 Training loss: 813.4556 Explore P: 0.1286\n",
      "Episode: 1629 Total reward: 11.0 Training loss: 696.1647 Explore P: 0.1285\n",
      "Episode: 1630 Total reward: 11.0 Training loss: 717.0111 Explore P: 0.1284\n",
      "Episode: 1631 Total reward: 9.0 Training loss: 1308.7683 Explore P: 0.1283\n",
      "Episode: 1632 Total reward: 12.0 Training loss: 885.1046 Explore P: 0.1281\n",
      "Episode: 1633 Total reward: 11.0 Training loss: 1231.2112 Explore P: 0.1280\n",
      "Episode: 1634 Total reward: 11.0 Training loss: 1094.0271 Explore P: 0.1279\n",
      "Episode: 1635 Total reward: 11.0 Training loss: 88.9559 Explore P: 0.1277\n",
      "Episode: 1636 Total reward: 8.0 Training loss: 1445.1674 Explore P: 0.1276\n",
      "Episode: 1637 Total reward: 10.0 Training loss: 866.7139 Explore P: 0.1275\n",
      "Episode: 1638 Total reward: 7.0 Training loss: 1584.1404 Explore P: 0.1274\n",
      "Episode: 1639 Total reward: 12.0 Training loss: 1451.8625 Explore P: 0.1273\n",
      "Episode: 1640 Total reward: 15.0 Training loss: 1931.7172 Explore P: 0.1271\n",
      "Episode: 1641 Total reward: 8.0 Training loss: 1455.8577 Explore P: 0.1270\n",
      "Episode: 1642 Total reward: 9.0 Training loss: 862.4332 Explore P: 0.1269\n",
      "Episode: 1643 Total reward: 8.0 Training loss: 814.4720 Explore P: 0.1268\n",
      "Episode: 1644 Total reward: 10.0 Training loss: 158.3249 Explore P: 0.1267\n",
      "Episode: 1645 Total reward: 10.0 Training loss: 2386.9136 Explore P: 0.1266\n",
      "Episode: 1646 Total reward: 11.0 Training loss: 889.9862 Explore P: 0.1265\n",
      "Episode: 1647 Total reward: 8.0 Training loss: 606.0632 Explore P: 0.1264\n",
      "Episode: 1648 Total reward: 12.0 Training loss: 197.9123 Explore P: 0.1262\n",
      "Episode: 1649 Total reward: 9.0 Training loss: 197.1198 Explore P: 0.1261\n",
      "Episode: 1650 Total reward: 12.0 Training loss: 788.7852 Explore P: 0.1260\n",
      "Episode: 1651 Total reward: 9.0 Training loss: 1099.2527 Explore P: 0.1259\n",
      "Episode: 1652 Total reward: 16.0 Training loss: 2857.1719 Explore P: 0.1257\n",
      "Episode: 1653 Total reward: 10.0 Training loss: 4423.5322 Explore P: 0.1256\n",
      "Episode: 1654 Total reward: 11.0 Training loss: 285.5754 Explore P: 0.1255\n",
      "Episode: 1655 Total reward: 10.0 Training loss: 937.3127 Explore P: 0.1254\n",
      "Episode: 1656 Total reward: 11.0 Training loss: 1877.3284 Explore P: 0.1252\n",
      "Episode: 1657 Total reward: 11.0 Training loss: 884.4092 Explore P: 0.1251\n",
      "Episode: 1658 Total reward: 10.0 Training loss: 705.8046 Explore P: 0.1250\n",
      "Episode: 1659 Total reward: 10.0 Training loss: 1339.0914 Explore P: 0.1249\n",
      "Episode: 1660 Total reward: 10.0 Training loss: 638.8447 Explore P: 0.1248\n",
      "Episode: 1661 Total reward: 12.0 Training loss: 309.4389 Explore P: 0.1246\n",
      "Episode: 1662 Total reward: 11.0 Training loss: 3911.5984 Explore P: 0.1245\n",
      "Episode: 1663 Total reward: 12.0 Training loss: 194.1640 Explore P: 0.1244\n",
      "Episode: 1664 Total reward: 10.0 Training loss: 627.0720 Explore P: 0.1242\n",
      "Episode: 1665 Total reward: 10.0 Training loss: 590.2377 Explore P: 0.1241\n",
      "Episode: 1666 Total reward: 7.0 Training loss: 589.5760 Explore P: 0.1240\n",
      "Episode: 1667 Total reward: 11.0 Training loss: 1671.6660 Explore P: 0.1239\n",
      "Episode: 1668 Total reward: 10.0 Training loss: 719.9144 Explore P: 0.1238\n",
      "Episode: 1669 Total reward: 9.0 Training loss: 404.1812 Explore P: 0.1237\n",
      "Episode: 1670 Total reward: 13.0 Training loss: 437.3298 Explore P: 0.1236\n",
      "Episode: 1671 Total reward: 8.0 Training loss: 895.3676 Explore P: 0.1235\n",
      "Episode: 1672 Total reward: 10.0 Training loss: 827.0533 Explore P: 0.1234\n",
      "Episode: 1673 Total reward: 10.0 Training loss: 347.4042 Explore P: 0.1232\n",
      "Episode: 1674 Total reward: 10.0 Training loss: 396.7706 Explore P: 0.1231\n",
      "Episode: 1675 Total reward: 11.0 Training loss: 1016.5749 Explore P: 0.1230\n",
      "Episode: 1676 Total reward: 11.0 Training loss: 1182.9979 Explore P: 0.1229\n",
      "Episode: 1677 Total reward: 8.0 Training loss: 851.7281 Explore P: 0.1228\n",
      "Episode: 1678 Total reward: 9.0 Training loss: 216.0914 Explore P: 0.1227\n",
      "Episode: 1679 Total reward: 12.0 Training loss: 6217.2842 Explore P: 0.1226\n",
      "Episode: 1680 Total reward: 7.0 Training loss: 537.6032 Explore P: 0.1225\n",
      "Episode: 1681 Total reward: 14.0 Training loss: 559.9502 Explore P: 0.1223\n",
      "Episode: 1682 Total reward: 9.0 Training loss: 749.8372 Explore P: 0.1222\n",
      "Episode: 1683 Total reward: 11.0 Training loss: 346.6868 Explore P: 0.1221\n",
      "Episode: 1684 Total reward: 9.0 Training loss: 1744.0258 Explore P: 0.1220\n",
      "Episode: 1685 Total reward: 8.0 Training loss: 535.6868 Explore P: 0.1219\n",
      "Episode: 1686 Total reward: 10.0 Training loss: 163.2587 Explore P: 0.1218\n",
      "Episode: 1687 Total reward: 11.0 Training loss: 1783.0543 Explore P: 0.1217\n",
      "Episode: 1688 Total reward: 11.0 Training loss: 631.1876 Explore P: 0.1215\n",
      "Episode: 1689 Total reward: 8.0 Training loss: 864.6774 Explore P: 0.1215\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1690 Total reward: 12.0 Training loss: 1269.6592 Explore P: 0.1213\n",
      "Episode: 1691 Total reward: 12.0 Training loss: 1361.3364 Explore P: 0.1212\n",
      "Episode: 1692 Total reward: 8.0 Training loss: 1533.0305 Explore P: 0.1211\n",
      "Episode: 1693 Total reward: 10.0 Training loss: 184.7373 Explore P: 0.1210\n",
      "Episode: 1694 Total reward: 11.0 Training loss: 962.2733 Explore P: 0.1209\n",
      "Episode: 1695 Total reward: 8.0 Training loss: 769.1555 Explore P: 0.1208\n",
      "Episode: 1696 Total reward: 11.0 Training loss: 2376.6011 Explore P: 0.1207\n",
      "Episode: 1697 Total reward: 9.0 Training loss: 919.0116 Explore P: 0.1206\n",
      "Episode: 1698 Total reward: 10.0 Training loss: 1142.1670 Explore P: 0.1204\n",
      "Episode: 1699 Total reward: 10.0 Training loss: 1110.4471 Explore P: 0.1203\n",
      "Episode: 1700 Total reward: 13.0 Training loss: 924.0651 Explore P: 0.1202\n",
      "Episode: 1701 Total reward: 8.0 Training loss: 1114.1963 Explore P: 0.1201\n",
      "Episode: 1702 Total reward: 12.0 Training loss: 379.6609 Explore P: 0.1200\n",
      "Episode: 1703 Total reward: 11.0 Training loss: 1405.7516 Explore P: 0.1198\n",
      "Episode: 1704 Total reward: 9.0 Training loss: 836.4692 Explore P: 0.1197\n",
      "Episode: 1705 Total reward: 9.0 Training loss: 201.7881 Explore P: 0.1197\n",
      "Episode: 1706 Total reward: 12.0 Training loss: 2095.8765 Explore P: 0.1195\n",
      "Episode: 1707 Total reward: 9.0 Training loss: 592.8163 Explore P: 0.1194\n",
      "Episode: 1708 Total reward: 10.0 Training loss: 547.2990 Explore P: 0.1193\n",
      "Episode: 1709 Total reward: 11.0 Training loss: 788.6953 Explore P: 0.1192\n",
      "Episode: 1710 Total reward: 11.0 Training loss: 586.4142 Explore P: 0.1191\n",
      "Episode: 1711 Total reward: 8.0 Training loss: 144.7883 Explore P: 0.1190\n",
      "Episode: 1712 Total reward: 8.0 Training loss: 278.5217 Explore P: 0.1189\n",
      "Episode: 1713 Total reward: 12.0 Training loss: 773.0995 Explore P: 0.1188\n",
      "Episode: 1714 Total reward: 11.0 Training loss: 766.4736 Explore P: 0.1186\n",
      "Episode: 1715 Total reward: 11.0 Training loss: 4946.7422 Explore P: 0.1185\n",
      "Episode: 1716 Total reward: 10.0 Training loss: 1996.1547 Explore P: 0.1184\n",
      "Episode: 1717 Total reward: 8.0 Training loss: 957.9463 Explore P: 0.1183\n",
      "Episode: 1718 Total reward: 8.0 Training loss: 626.7826 Explore P: 0.1182\n",
      "Episode: 1719 Total reward: 9.0 Training loss: 1328.1805 Explore P: 0.1181\n",
      "Episode: 1720 Total reward: 10.0 Training loss: 2646.2185 Explore P: 0.1180\n",
      "Episode: 1721 Total reward: 9.0 Training loss: 2135.4897 Explore P: 0.1179\n",
      "Episode: 1722 Total reward: 11.0 Training loss: 602.0892 Explore P: 0.1178\n",
      "Episode: 1723 Total reward: 13.0 Training loss: 506.2955 Explore P: 0.1177\n",
      "Episode: 1724 Total reward: 11.0 Training loss: 204.9028 Explore P: 0.1176\n",
      "Episode: 1725 Total reward: 8.0 Training loss: 419.4469 Explore P: 0.1175\n",
      "Episode: 1726 Total reward: 9.0 Training loss: 578.9686 Explore P: 0.1174\n",
      "Episode: 1727 Total reward: 7.0 Training loss: 1793.7894 Explore P: 0.1173\n",
      "Episode: 1728 Total reward: 10.0 Training loss: 563.5276 Explore P: 0.1172\n",
      "Episode: 1729 Total reward: 7.0 Training loss: 3243.7192 Explore P: 0.1171\n",
      "Episode: 1730 Total reward: 7.0 Training loss: 198.4871 Explore P: 0.1171\n",
      "Episode: 1731 Total reward: 8.0 Training loss: 777.3224 Explore P: 0.1170\n",
      "Episode: 1732 Total reward: 8.0 Training loss: 315.6711 Explore P: 0.1169\n",
      "Episode: 1733 Total reward: 11.0 Training loss: 781.7479 Explore P: 0.1168\n",
      "Episode: 1734 Total reward: 11.0 Training loss: 1171.1301 Explore P: 0.1166\n",
      "Episode: 1735 Total reward: 7.0 Training loss: 1235.8486 Explore P: 0.1166\n",
      "Episode: 1736 Total reward: 10.0 Training loss: 469.8414 Explore P: 0.1165\n",
      "Episode: 1737 Total reward: 10.0 Training loss: 776.5517 Explore P: 0.1164\n",
      "Episode: 1738 Total reward: 11.0 Training loss: 979.0809 Explore P: 0.1162\n",
      "Episode: 1739 Total reward: 10.0 Training loss: 309.9509 Explore P: 0.1161\n",
      "Episode: 1740 Total reward: 8.0 Training loss: 1593.5588 Explore P: 0.1160\n",
      "Episode: 1741 Total reward: 7.0 Training loss: 461.5451 Explore P: 0.1160\n",
      "Episode: 1742 Total reward: 8.0 Training loss: 686.6244 Explore P: 0.1159\n",
      "Episode: 1743 Total reward: 13.0 Training loss: 1442.1227 Explore P: 0.1158\n",
      "Episode: 1744 Total reward: 15.0 Training loss: 1255.4795 Explore P: 0.1156\n",
      "Episode: 1745 Total reward: 9.0 Training loss: 1208.2610 Explore P: 0.1155\n",
      "Episode: 1746 Total reward: 9.0 Training loss: 757.4007 Explore P: 0.1154\n",
      "Episode: 1747 Total reward: 14.0 Training loss: 2636.4382 Explore P: 0.1153\n",
      "Episode: 1748 Total reward: 12.0 Training loss: 1510.0286 Explore P: 0.1151\n",
      "Episode: 1749 Total reward: 9.0 Training loss: 729.1486 Explore P: 0.1150\n",
      "Episode: 1750 Total reward: 10.0 Training loss: 780.1611 Explore P: 0.1149\n",
      "Episode: 1751 Total reward: 9.0 Training loss: 717.4986 Explore P: 0.1148\n",
      "Episode: 1752 Total reward: 11.0 Training loss: 441.7686 Explore P: 0.1147\n",
      "Episode: 1753 Total reward: 9.0 Training loss: 735.5955 Explore P: 0.1146\n",
      "Episode: 1754 Total reward: 11.0 Training loss: 509.0360 Explore P: 0.1145\n",
      "Episode: 1755 Total reward: 9.0 Training loss: 871.1707 Explore P: 0.1144\n",
      "Episode: 1756 Total reward: 10.0 Training loss: 324.0042 Explore P: 0.1143\n",
      "Episode: 1757 Total reward: 10.0 Training loss: 3021.9360 Explore P: 0.1142\n",
      "Episode: 1758 Total reward: 11.0 Training loss: 883.4920 Explore P: 0.1141\n",
      "Episode: 1759 Total reward: 13.0 Training loss: 1400.6573 Explore P: 0.1140\n",
      "Episode: 1760 Total reward: 9.0 Training loss: 628.0912 Explore P: 0.1139\n",
      "Episode: 1761 Total reward: 9.0 Training loss: 436.8857 Explore P: 0.1138\n",
      "Episode: 1762 Total reward: 8.0 Training loss: 756.0127 Explore P: 0.1137\n",
      "Episode: 1763 Total reward: 9.0 Training loss: 1850.9818 Explore P: 0.1136\n",
      "Episode: 1764 Total reward: 7.0 Training loss: 1006.9722 Explore P: 0.1135\n",
      "Episode: 1765 Total reward: 10.0 Training loss: 618.3431 Explore P: 0.1134\n",
      "Episode: 1766 Total reward: 8.0 Training loss: 673.0082 Explore P: 0.1133\n",
      "Episode: 1767 Total reward: 10.0 Training loss: 449.1218 Explore P: 0.1132\n",
      "Episode: 1768 Total reward: 11.0 Training loss: 264.0033 Explore P: 0.1131\n",
      "Episode: 1769 Total reward: 8.0 Training loss: 538.7904 Explore P: 0.1130\n",
      "Episode: 1770 Total reward: 10.0 Training loss: 816.8619 Explore P: 0.1129\n",
      "Episode: 1771 Total reward: 12.0 Training loss: 378.0079 Explore P: 0.1128\n",
      "Episode: 1772 Total reward: 9.0 Training loss: 3155.0864 Explore P: 0.1127\n",
      "Episode: 1773 Total reward: 11.0 Training loss: 687.0300 Explore P: 0.1126\n",
      "Episode: 1774 Total reward: 12.0 Training loss: 736.5654 Explore P: 0.1125\n",
      "Episode: 1775 Total reward: 12.0 Training loss: 499.2343 Explore P: 0.1124\n",
      "Episode: 1776 Total reward: 11.0 Training loss: 2808.7896 Explore P: 0.1122\n",
      "Episode: 1777 Total reward: 7.0 Training loss: 1972.5131 Explore P: 0.1122\n",
      "Episode: 1778 Total reward: 12.0 Training loss: 1110.1510 Explore P: 0.1121\n",
      "Episode: 1779 Total reward: 9.0 Training loss: 1352.1243 Explore P: 0.1120\n",
      "Episode: 1780 Total reward: 11.0 Training loss: 492.7895 Explore P: 0.1119\n",
      "Episode: 1781 Total reward: 9.0 Training loss: 1170.9961 Explore P: 0.1118\n",
      "Episode: 1782 Total reward: 10.0 Training loss: 237.4949 Explore P: 0.1117\n",
      "Episode: 1783 Total reward: 12.0 Training loss: 574.5043 Explore P: 0.1115\n",
      "Episode: 1784 Total reward: 10.0 Training loss: 273.0857 Explore P: 0.1114\n",
      "Episode: 1785 Total reward: 12.0 Training loss: 1365.9476 Explore P: 0.1113\n",
      "Episode: 1786 Total reward: 10.0 Training loss: 2522.6592 Explore P: 0.1112\n",
      "Episode: 1787 Total reward: 9.0 Training loss: 2036.9430 Explore P: 0.1111\n",
      "Episode: 1788 Total reward: 10.0 Training loss: 228.2204 Explore P: 0.1110\n",
      "Episode: 1789 Total reward: 9.0 Training loss: 1990.9746 Explore P: 0.1109\n",
      "Episode: 1790 Total reward: 9.0 Training loss: 295.6967 Explore P: 0.1108\n",
      "Episode: 1791 Total reward: 12.0 Training loss: 1170.5898 Explore P: 0.1107\n",
      "Episode: 1792 Total reward: 9.0 Training loss: 752.4207 Explore P: 0.1106\n",
      "Episode: 1793 Total reward: 9.0 Training loss: 684.1830 Explore P: 0.1105\n",
      "Episode: 1794 Total reward: 8.0 Training loss: 294.8734 Explore P: 0.1105\n",
      "Episode: 1795 Total reward: 9.0 Training loss: 371.6149 Explore P: 0.1104\n",
      "Episode: 1796 Total reward: 10.0 Training loss: 1039.3707 Explore P: 0.1103\n",
      "Episode: 1797 Total reward: 9.0 Training loss: 1113.2117 Explore P: 0.1102\n",
      "Episode: 1798 Total reward: 8.0 Training loss: 832.8250 Explore P: 0.1101\n",
      "Episode: 1799 Total reward: 11.0 Training loss: 982.9166 Explore P: 0.1100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1800 Total reward: 8.0 Training loss: 1155.3203 Explore P: 0.1099\n",
      "Episode: 1801 Total reward: 10.0 Training loss: 1191.8923 Explore P: 0.1098\n",
      "Episode: 1802 Total reward: 8.0 Training loss: 552.5432 Explore P: 0.1097\n",
      "Episode: 1803 Total reward: 9.0 Training loss: 484.3482 Explore P: 0.1096\n",
      "Episode: 1804 Total reward: 9.0 Training loss: 280.0808 Explore P: 0.1095\n",
      "Episode: 1805 Total reward: 12.0 Training loss: 688.3024 Explore P: 0.1094\n",
      "Episode: 1806 Total reward: 10.0 Training loss: 2552.0469 Explore P: 0.1093\n",
      "Episode: 1807 Total reward: 9.0 Training loss: 594.0002 Explore P: 0.1092\n",
      "Episode: 1808 Total reward: 8.0 Training loss: 5166.0078 Explore P: 0.1092\n",
      "Episode: 1809 Total reward: 9.0 Training loss: 749.6777 Explore P: 0.1091\n",
      "Episode: 1810 Total reward: 9.0 Training loss: 782.1964 Explore P: 0.1090\n",
      "Episode: 1811 Total reward: 12.0 Training loss: 1184.5212 Explore P: 0.1089\n",
      "Episode: 1812 Total reward: 8.0 Training loss: 822.5638 Explore P: 0.1088\n",
      "Episode: 1813 Total reward: 14.0 Training loss: 1467.3552 Explore P: 0.1086\n",
      "Episode: 1814 Total reward: 9.0 Training loss: 2818.5122 Explore P: 0.1086\n",
      "Episode: 1815 Total reward: 8.0 Training loss: 1708.4092 Explore P: 0.1085\n",
      "Episode: 1816 Total reward: 9.0 Training loss: 1055.1139 Explore P: 0.1084\n",
      "Episode: 1817 Total reward: 8.0 Training loss: 496.2374 Explore P: 0.1083\n",
      "Episode: 1818 Total reward: 11.0 Training loss: 1063.4294 Explore P: 0.1082\n",
      "Episode: 1819 Total reward: 10.0 Training loss: 1086.6696 Explore P: 0.1081\n",
      "Episode: 1820 Total reward: 9.0 Training loss: 260.2547 Explore P: 0.1080\n",
      "Episode: 1821 Total reward: 11.0 Training loss: 611.8007 Explore P: 0.1079\n",
      "Episode: 1822 Total reward: 11.0 Training loss: 4631.7368 Explore P: 0.1078\n",
      "Episode: 1823 Total reward: 7.0 Training loss: 539.1860 Explore P: 0.1077\n",
      "Episode: 1824 Total reward: 12.0 Training loss: 2886.7183 Explore P: 0.1076\n",
      "Episode: 1825 Total reward: 9.0 Training loss: 1061.7396 Explore P: 0.1075\n",
      "Episode: 1826 Total reward: 9.0 Training loss: 402.3351 Explore P: 0.1074\n",
      "Episode: 1827 Total reward: 14.0 Training loss: 1044.3657 Explore P: 0.1073\n",
      "Episode: 1828 Total reward: 10.0 Training loss: 722.0637 Explore P: 0.1072\n",
      "Episode: 1829 Total reward: 12.0 Training loss: 147.9255 Explore P: 0.1071\n",
      "Episode: 1830 Total reward: 11.0 Training loss: 2326.0886 Explore P: 0.1070\n",
      "Episode: 1831 Total reward: 9.0 Training loss: 553.7332 Explore P: 0.1069\n",
      "Episode: 1832 Total reward: 11.0 Training loss: 875.3975 Explore P: 0.1068\n",
      "Episode: 1833 Total reward: 8.0 Training loss: 522.7275 Explore P: 0.1067\n",
      "Episode: 1834 Total reward: 12.0 Training loss: 825.6401 Explore P: 0.1066\n",
      "Episode: 1835 Total reward: 10.0 Training loss: 256.4828 Explore P: 0.1065\n",
      "Episode: 1836 Total reward: 10.0 Training loss: 1427.7412 Explore P: 0.1064\n",
      "Episode: 1837 Total reward: 9.0 Training loss: 1673.8922 Explore P: 0.1063\n",
      "Episode: 1838 Total reward: 11.0 Training loss: 3836.0239 Explore P: 0.1062\n",
      "Episode: 1839 Total reward: 10.0 Training loss: 833.2728 Explore P: 0.1061\n",
      "Episode: 1840 Total reward: 10.0 Training loss: 1368.1536 Explore P: 0.1060\n",
      "Episode: 1841 Total reward: 7.0 Training loss: 2258.5083 Explore P: 0.1059\n",
      "Episode: 1842 Total reward: 9.0 Training loss: 1892.0413 Explore P: 0.1059\n",
      "Episode: 1843 Total reward: 9.0 Training loss: 737.9222 Explore P: 0.1058\n",
      "Episode: 1844 Total reward: 10.0 Training loss: 374.6176 Explore P: 0.1057\n",
      "Episode: 1845 Total reward: 11.0 Training loss: 304.5138 Explore P: 0.1056\n",
      "Episode: 1846 Total reward: 11.0 Training loss: 223.4983 Explore P: 0.1055\n",
      "Episode: 1847 Total reward: 10.0 Training loss: 558.1210 Explore P: 0.1054\n",
      "Episode: 1848 Total reward: 18.0 Training loss: 1262.7815 Explore P: 0.1052\n",
      "Episode: 1849 Total reward: 12.0 Training loss: 1450.6005 Explore P: 0.1051\n",
      "Episode: 1850 Total reward: 11.0 Training loss: 1673.7776 Explore P: 0.1050\n",
      "Episode: 1851 Total reward: 11.0 Training loss: 335.5949 Explore P: 0.1049\n",
      "Episode: 1852 Total reward: 11.0 Training loss: 810.0931 Explore P: 0.1048\n",
      "Episode: 1853 Total reward: 12.0 Training loss: 983.1550 Explore P: 0.1047\n",
      "Episode: 1854 Total reward: 8.0 Training loss: 968.2127 Explore P: 0.1046\n",
      "Episode: 1855 Total reward: 16.0 Training loss: 944.7539 Explore P: 0.1044\n",
      "Episode: 1856 Total reward: 10.0 Training loss: 468.3030 Explore P: 0.1043\n",
      "Episode: 1857 Total reward: 8.0 Training loss: 548.4058 Explore P: 0.1043\n",
      "Episode: 1858 Total reward: 11.0 Training loss: 441.9005 Explore P: 0.1042\n",
      "Episode: 1859 Total reward: 10.0 Training loss: 554.2567 Explore P: 0.1041\n",
      "Episode: 1860 Total reward: 8.0 Training loss: 768.2034 Explore P: 0.1040\n",
      "Episode: 1861 Total reward: 12.0 Training loss: 840.4421 Explore P: 0.1039\n",
      "Episode: 1862 Total reward: 10.0 Training loss: 357.8813 Explore P: 0.1038\n",
      "Episode: 1863 Total reward: 14.0 Training loss: 3014.9983 Explore P: 0.1037\n",
      "Episode: 1864 Total reward: 12.0 Training loss: 7406.7041 Explore P: 0.1035\n",
      "Episode: 1865 Total reward: 10.0 Training loss: 4039.7202 Explore P: 0.1034\n",
      "Episode: 1866 Total reward: 10.0 Training loss: 880.2687 Explore P: 0.1034\n",
      "Episode: 1867 Total reward: 10.0 Training loss: 848.1583 Explore P: 0.1033\n",
      "Episode: 1868 Total reward: 9.0 Training loss: 790.4188 Explore P: 0.1032\n",
      "Episode: 1869 Total reward: 7.0 Training loss: 97.0527 Explore P: 0.1031\n",
      "Episode: 1870 Total reward: 12.0 Training loss: 504.4087 Explore P: 0.1030\n",
      "Episode: 1871 Total reward: 15.0 Training loss: 945.3960 Explore P: 0.1029\n",
      "Episode: 1872 Total reward: 9.0 Training loss: 790.5050 Explore P: 0.1028\n",
      "Episode: 1873 Total reward: 10.0 Training loss: 518.0314 Explore P: 0.1027\n",
      "Episode: 1874 Total reward: 16.0 Training loss: 600.2430 Explore P: 0.1025\n",
      "Episode: 1875 Total reward: 9.0 Training loss: 712.8900 Explore P: 0.1025\n",
      "Episode: 1876 Total reward: 9.0 Training loss: 247.3731 Explore P: 0.1024\n",
      "Episode: 1877 Total reward: 10.0 Training loss: 613.8672 Explore P: 0.1023\n",
      "Episode: 1878 Total reward: 17.0 Training loss: 265.1785 Explore P: 0.1021\n",
      "Episode: 1879 Total reward: 9.0 Training loss: 836.2256 Explore P: 0.1020\n",
      "Episode: 1880 Total reward: 10.0 Training loss: 686.9743 Explore P: 0.1019\n",
      "Episode: 1881 Total reward: 20.0 Training loss: 841.6701 Explore P: 0.1018\n",
      "Episode: 1882 Total reward: 10.0 Training loss: 1668.4812 Explore P: 0.1017\n",
      "Episode: 1883 Total reward: 7.0 Training loss: 153.2278 Explore P: 0.1016\n",
      "Episode: 1884 Total reward: 10.0 Training loss: 178.0270 Explore P: 0.1015\n",
      "Episode: 1885 Total reward: 8.0 Training loss: 896.4274 Explore P: 0.1014\n",
      "Episode: 1886 Total reward: 9.0 Training loss: 861.2021 Explore P: 0.1014\n",
      "Episode: 1887 Total reward: 12.0 Training loss: 62.6852 Explore P: 0.1013\n",
      "Episode: 1888 Total reward: 11.0 Training loss: 323.5020 Explore P: 0.1011\n",
      "Episode: 1889 Total reward: 11.0 Training loss: 244.9108 Explore P: 0.1010\n",
      "Episode: 1890 Total reward: 9.0 Training loss: 1073.5143 Explore P: 0.1010\n",
      "Episode: 1891 Total reward: 13.0 Training loss: 731.1432 Explore P: 0.1008\n",
      "Episode: 1892 Total reward: 9.0 Training loss: 1709.3688 Explore P: 0.1008\n",
      "Episode: 1893 Total reward: 11.0 Training loss: 815.1864 Explore P: 0.1007\n",
      "Episode: 1894 Total reward: 8.0 Training loss: 489.0993 Explore P: 0.1006\n",
      "Episode: 1895 Total reward: 12.0 Training loss: 636.2894 Explore P: 0.1005\n",
      "Episode: 1896 Total reward: 10.0 Training loss: 1535.3848 Explore P: 0.1004\n",
      "Episode: 1897 Total reward: 10.0 Training loss: 887.7023 Explore P: 0.1003\n",
      "Episode: 1898 Total reward: 11.0 Training loss: 768.7206 Explore P: 0.1002\n",
      "Episode: 1899 Total reward: 8.0 Training loss: 335.3119 Explore P: 0.1001\n",
      "Episode: 1900 Total reward: 9.0 Training loss: 569.3796 Explore P: 0.1001\n",
      "Episode: 1901 Total reward: 10.0 Training loss: 1580.4899 Explore P: 0.1000\n",
      "Episode: 1902 Total reward: 11.0 Training loss: 539.2642 Explore P: 0.0999\n",
      "Episode: 1903 Total reward: 10.0 Training loss: 434.2664 Explore P: 0.0998\n",
      "Episode: 1904 Total reward: 9.0 Training loss: 974.6901 Explore P: 0.0997\n",
      "Episode: 1905 Total reward: 11.0 Training loss: 1118.6342 Explore P: 0.0996\n",
      "Episode: 1906 Total reward: 8.0 Training loss: 755.2777 Explore P: 0.0995\n",
      "Episode: 1907 Total reward: 8.0 Training loss: 1004.0621 Explore P: 0.0995\n",
      "Episode: 1908 Total reward: 9.0 Training loss: 511.0273 Explore P: 0.0994\n",
      "Episode: 1909 Total reward: 8.0 Training loss: 2273.1848 Explore P: 0.0993\n",
      "Episode: 1910 Total reward: 14.0 Training loss: 1510.4880 Explore P: 0.0992\n",
      "Episode: 1911 Total reward: 10.0 Training loss: 110.4066 Explore P: 0.0991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 1912 Total reward: 11.0 Training loss: 1046.3646 Explore P: 0.0990\n",
      "Episode: 1913 Total reward: 9.0 Training loss: 456.9622 Explore P: 0.0989\n",
      "Episode: 1914 Total reward: 9.0 Training loss: 857.8509 Explore P: 0.0988\n",
      "Episode: 1915 Total reward: 7.0 Training loss: 227.2881 Explore P: 0.0988\n",
      "Episode: 1916 Total reward: 8.0 Training loss: 461.6102 Explore P: 0.0987\n",
      "Episode: 1917 Total reward: 10.0 Training loss: 2066.4849 Explore P: 0.0986\n",
      "Episode: 1918 Total reward: 7.0 Training loss: 768.1760 Explore P: 0.0985\n",
      "Episode: 1919 Total reward: 9.0 Training loss: 516.0291 Explore P: 0.0985\n",
      "Episode: 1920 Total reward: 9.0 Training loss: 153.4846 Explore P: 0.0984\n",
      "Episode: 1921 Total reward: 12.0 Training loss: 808.9437 Explore P: 0.0983\n",
      "Episode: 1922 Total reward: 8.0 Training loss: 1443.4791 Explore P: 0.0982\n",
      "Episode: 1923 Total reward: 11.0 Training loss: 3519.0132 Explore P: 0.0981\n",
      "Episode: 1924 Total reward: 12.0 Training loss: 2362.8940 Explore P: 0.0980\n",
      "Episode: 1925 Total reward: 11.0 Training loss: 627.6582 Explore P: 0.0979\n",
      "Episode: 1926 Total reward: 11.0 Training loss: 2032.4242 Explore P: 0.0978\n",
      "Episode: 1927 Total reward: 10.0 Training loss: 470.2967 Explore P: 0.0977\n",
      "Episode: 1928 Total reward: 11.0 Training loss: 2191.5320 Explore P: 0.0976\n",
      "Episode: 1929 Total reward: 9.0 Training loss: 5809.4829 Explore P: 0.0975\n",
      "Episode: 1930 Total reward: 10.0 Training loss: 1175.2498 Explore P: 0.0975\n",
      "Episode: 1931 Total reward: 8.0 Training loss: 271.2910 Explore P: 0.0974\n",
      "Episode: 1932 Total reward: 9.0 Training loss: 2140.0322 Explore P: 0.0973\n",
      "Episode: 1933 Total reward: 9.0 Training loss: 2668.3621 Explore P: 0.0972\n",
      "Episode: 1934 Total reward: 11.0 Training loss: 791.2271 Explore P: 0.0971\n",
      "Episode: 1935 Total reward: 11.0 Training loss: 1294.2336 Explore P: 0.0970\n",
      "Episode: 1936 Total reward: 8.0 Training loss: 622.2872 Explore P: 0.0970\n",
      "Episode: 1937 Total reward: 9.0 Training loss: 1023.4260 Explore P: 0.0969\n",
      "Episode: 1938 Total reward: 11.0 Training loss: 580.5699 Explore P: 0.0968\n",
      "Episode: 1939 Total reward: 13.0 Training loss: 1020.6055 Explore P: 0.0967\n",
      "Episode: 1940 Total reward: 13.0 Training loss: 102.1187 Explore P: 0.0966\n",
      "Episode: 1941 Total reward: 10.0 Training loss: 2812.7104 Explore P: 0.0965\n",
      "Episode: 1942 Total reward: 9.0 Training loss: 537.9092 Explore P: 0.0964\n",
      "Episode: 1943 Total reward: 9.0 Training loss: 1175.8286 Explore P: 0.0963\n",
      "Episode: 1944 Total reward: 11.0 Training loss: 615.0307 Explore P: 0.0962\n",
      "Episode: 1945 Total reward: 10.0 Training loss: 637.1805 Explore P: 0.0962\n",
      "Episode: 1946 Total reward: 8.0 Training loss: 2224.4800 Explore P: 0.0961\n",
      "Episode: 1947 Total reward: 8.0 Training loss: 91.3423 Explore P: 0.0960\n",
      "Episode: 1948 Total reward: 7.0 Training loss: 1062.8367 Explore P: 0.0960\n",
      "Episode: 1949 Total reward: 7.0 Training loss: 991.4254 Explore P: 0.0959\n",
      "Episode: 1950 Total reward: 9.0 Training loss: 93.1655 Explore P: 0.0958\n",
      "Episode: 1951 Total reward: 27.0 Training loss: 1084.9397 Explore P: 0.0956\n",
      "Episode: 1952 Total reward: 10.0 Training loss: 619.0493 Explore P: 0.0955\n",
      "Episode: 1953 Total reward: 9.0 Training loss: 994.7487 Explore P: 0.0954\n",
      "Episode: 1954 Total reward: 9.0 Training loss: 4366.1650 Explore P: 0.0953\n",
      "Episode: 1955 Total reward: 10.0 Training loss: 446.2030 Explore P: 0.0953\n",
      "Episode: 1956 Total reward: 12.0 Training loss: 294.1182 Explore P: 0.0952\n",
      "Episode: 1957 Total reward: 9.0 Training loss: 1239.5452 Explore P: 0.0951\n",
      "Episode: 1958 Total reward: 11.0 Training loss: 1301.6104 Explore P: 0.0950\n",
      "Episode: 1959 Total reward: 11.0 Training loss: 500.0515 Explore P: 0.0949\n",
      "Episode: 1960 Total reward: 9.0 Training loss: 392.0946 Explore P: 0.0948\n",
      "Episode: 1961 Total reward: 19.0 Training loss: 469.8002 Explore P: 0.0947\n",
      "Episode: 1962 Total reward: 12.0 Training loss: 597.3483 Explore P: 0.0946\n",
      "Episode: 1963 Total reward: 8.0 Training loss: 870.7892 Explore P: 0.0945\n",
      "Episode: 1964 Total reward: 12.0 Training loss: 544.6973 Explore P: 0.0944\n",
      "Episode: 1965 Total reward: 11.0 Training loss: 1183.0278 Explore P: 0.0943\n",
      "Episode: 1966 Total reward: 9.0 Training loss: 2922.2119 Explore P: 0.0942\n",
      "Episode: 1967 Total reward: 11.0 Training loss: 720.0330 Explore P: 0.0941\n",
      "Episode: 1968 Total reward: 9.0 Training loss: 1152.5920 Explore P: 0.0940\n",
      "Episode: 1969 Total reward: 8.0 Training loss: 2293.2515 Explore P: 0.0940\n",
      "Episode: 1970 Total reward: 11.0 Training loss: 828.4652 Explore P: 0.0939\n",
      "Episode: 1971 Total reward: 9.0 Training loss: 3823.1758 Explore P: 0.0938\n",
      "Episode: 1972 Total reward: 9.0 Training loss: 7453.0845 Explore P: 0.0937\n",
      "Episode: 1973 Total reward: 9.0 Training loss: 1874.6365 Explore P: 0.0937\n",
      "Episode: 1974 Total reward: 11.0 Training loss: 4292.7095 Explore P: 0.0936\n",
      "Episode: 1975 Total reward: 9.0 Training loss: 1496.1946 Explore P: 0.0935\n",
      "Episode: 1976 Total reward: 10.0 Training loss: 969.6681 Explore P: 0.0934\n",
      "Episode: 1977 Total reward: 12.0 Training loss: 148.8136 Explore P: 0.0933\n",
      "Episode: 1978 Total reward: 13.0 Training loss: 2620.3872 Explore P: 0.0932\n",
      "Episode: 1979 Total reward: 10.0 Training loss: 1458.7688 Explore P: 0.0931\n",
      "Episode: 1980 Total reward: 9.0 Training loss: 404.6536 Explore P: 0.0930\n",
      "Episode: 1981 Total reward: 10.0 Training loss: 665.0686 Explore P: 0.0930\n",
      "Episode: 1982 Total reward: 8.0 Training loss: 163.9058 Explore P: 0.0929\n",
      "Episode: 1983 Total reward: 8.0 Training loss: 726.0618 Explore P: 0.0928\n",
      "Episode: 1984 Total reward: 15.0 Training loss: 554.2037 Explore P: 0.0927\n",
      "Episode: 1985 Total reward: 10.0 Training loss: 1083.9963 Explore P: 0.0926\n",
      "Episode: 1986 Total reward: 9.0 Training loss: 685.3315 Explore P: 0.0926\n",
      "Episode: 1987 Total reward: 10.0 Training loss: 453.0299 Explore P: 0.0925\n",
      "Episode: 1988 Total reward: 10.0 Training loss: 473.3146 Explore P: 0.0924\n",
      "Episode: 1989 Total reward: 7.0 Training loss: 1072.8665 Explore P: 0.0923\n",
      "Episode: 1990 Total reward: 12.0 Training loss: 411.2718 Explore P: 0.0922\n",
      "Episode: 1991 Total reward: 8.0 Training loss: 682.5226 Explore P: 0.0922\n",
      "Episode: 1992 Total reward: 11.0 Training loss: 1079.8761 Explore P: 0.0921\n",
      "Episode: 1993 Total reward: 7.0 Training loss: 695.3459 Explore P: 0.0920\n",
      "Episode: 1994 Total reward: 8.0 Training loss: 7684.7236 Explore P: 0.0919\n",
      "Episode: 1995 Total reward: 11.0 Training loss: 200.7450 Explore P: 0.0919\n",
      "Episode: 1996 Total reward: 12.0 Training loss: 1458.9990 Explore P: 0.0918\n",
      "Episode: 1997 Total reward: 8.0 Training loss: 758.1465 Explore P: 0.0917\n",
      "Episode: 1998 Total reward: 9.0 Training loss: 427.1227 Explore P: 0.0916\n",
      "Episode: 1999 Total reward: 11.0 Training loss: 1582.0802 Explore P: 0.0915\n",
      "Episode: 2000 Total reward: 10.0 Training loss: 118.8469 Explore P: 0.0915\n",
      "Episode: 2001 Total reward: 10.0 Training loss: 1123.1735 Explore P: 0.0914\n",
      "Episode: 2002 Total reward: 10.0 Training loss: 602.2529 Explore P: 0.0913\n",
      "Episode: 2003 Total reward: 9.0 Training loss: 384.8249 Explore P: 0.0912\n",
      "Episode: 2004 Total reward: 9.0 Training loss: 621.3132 Explore P: 0.0911\n",
      "Episode: 2005 Total reward: 10.0 Training loss: 656.7352 Explore P: 0.0911\n",
      "Episode: 2006 Total reward: 12.0 Training loss: 639.5270 Explore P: 0.0910\n",
      "Episode: 2007 Total reward: 7.0 Training loss: 693.9560 Explore P: 0.0909\n",
      "Episode: 2008 Total reward: 10.0 Training loss: 343.2581 Explore P: 0.0908\n",
      "Episode: 2009 Total reward: 12.0 Training loss: 492.7378 Explore P: 0.0907\n",
      "Episode: 2010 Total reward: 10.0 Training loss: 1580.4723 Explore P: 0.0906\n",
      "Episode: 2011 Total reward: 11.0 Training loss: 363.4937 Explore P: 0.0906\n",
      "Episode: 2012 Total reward: 12.0 Training loss: 932.4705 Explore P: 0.0905\n",
      "Episode: 2013 Total reward: 8.0 Training loss: 1052.9197 Explore P: 0.0904\n",
      "Episode: 2014 Total reward: 9.0 Training loss: 1701.7708 Explore P: 0.0903\n",
      "Episode: 2015 Total reward: 10.0 Training loss: 812.8907 Explore P: 0.0902\n",
      "Episode: 2016 Total reward: 9.0 Training loss: 370.9813 Explore P: 0.0902\n",
      "Episode: 2017 Total reward: 8.0 Training loss: 429.2821 Explore P: 0.0901\n",
      "Episode: 2018 Total reward: 7.0 Training loss: 859.6429 Explore P: 0.0901\n",
      "Episode: 2019 Total reward: 11.0 Training loss: 593.9127 Explore P: 0.0900\n",
      "Episode: 2020 Total reward: 9.0 Training loss: 774.2503 Explore P: 0.0899\n",
      "Episode: 2021 Total reward: 11.0 Training loss: 752.9032 Explore P: 0.0898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2022 Total reward: 8.0 Training loss: 522.7267 Explore P: 0.0897\n",
      "Episode: 2023 Total reward: 9.0 Training loss: 3426.7292 Explore P: 0.0897\n",
      "Episode: 2024 Total reward: 9.0 Training loss: 335.8749 Explore P: 0.0896\n",
      "Episode: 2025 Total reward: 12.0 Training loss: 605.6740 Explore P: 0.0895\n",
      "Episode: 2026 Total reward: 8.0 Training loss: 656.7494 Explore P: 0.0894\n",
      "Episode: 2027 Total reward: 8.0 Training loss: 206.0164 Explore P: 0.0894\n",
      "Episode: 2028 Total reward: 9.0 Training loss: 1583.2035 Explore P: 0.0893\n",
      "Episode: 2029 Total reward: 25.0 Training loss: 769.6021 Explore P: 0.0891\n",
      "Episode: 2030 Total reward: 10.0 Training loss: 1241.7194 Explore P: 0.0890\n",
      "Episode: 2031 Total reward: 7.0 Training loss: 1484.4441 Explore P: 0.0890\n",
      "Episode: 2032 Total reward: 11.0 Training loss: 1235.1852 Explore P: 0.0889\n",
      "Episode: 2033 Total reward: 7.0 Training loss: 605.5438 Explore P: 0.0888\n",
      "Episode: 2034 Total reward: 11.0 Training loss: 486.4554 Explore P: 0.0887\n",
      "Episode: 2035 Total reward: 8.0 Training loss: 924.0247 Explore P: 0.0887\n",
      "Episode: 2036 Total reward: 11.0 Training loss: 713.6817 Explore P: 0.0886\n",
      "Episode: 2037 Total reward: 7.0 Training loss: 363.1603 Explore P: 0.0885\n",
      "Episode: 2038 Total reward: 8.0 Training loss: 642.7281 Explore P: 0.0885\n",
      "Episode: 2039 Total reward: 9.0 Training loss: 1446.8568 Explore P: 0.0884\n",
      "Episode: 2040 Total reward: 12.0 Training loss: 953.2909 Explore P: 0.0883\n",
      "Episode: 2041 Total reward: 9.0 Training loss: 731.0345 Explore P: 0.0882\n",
      "Episode: 2042 Total reward: 8.0 Training loss: 469.7892 Explore P: 0.0882\n",
      "Episode: 2043 Total reward: 13.0 Training loss: 2209.5198 Explore P: 0.0881\n",
      "Episode: 2044 Total reward: 9.0 Training loss: 521.1783 Explore P: 0.0880\n",
      "Episode: 2045 Total reward: 8.0 Training loss: 1789.4231 Explore P: 0.0879\n",
      "Episode: 2046 Total reward: 11.0 Training loss: 864.9178 Explore P: 0.0879\n",
      "Episode: 2047 Total reward: 11.0 Training loss: 508.9286 Explore P: 0.0878\n",
      "Episode: 2048 Total reward: 13.0 Training loss: 1793.1344 Explore P: 0.0877\n",
      "Episode: 2049 Total reward: 10.0 Training loss: 361.7009 Explore P: 0.0876\n",
      "Episode: 2050 Total reward: 11.0 Training loss: 303.7973 Explore P: 0.0875\n",
      "Episode: 2051 Total reward: 13.0 Training loss: 2912.2395 Explore P: 0.0874\n",
      "Episode: 2052 Total reward: 11.0 Training loss: 154.4958 Explore P: 0.0873\n",
      "Episode: 2053 Total reward: 10.0 Training loss: 878.5043 Explore P: 0.0872\n",
      "Episode: 2054 Total reward: 11.0 Training loss: 757.9188 Explore P: 0.0872\n",
      "Episode: 2055 Total reward: 9.0 Training loss: 1274.3757 Explore P: 0.0871\n",
      "Episode: 2056 Total reward: 12.0 Training loss: 1497.1503 Explore P: 0.0870\n",
      "Episode: 2057 Total reward: 10.0 Training loss: 1061.6011 Explore P: 0.0869\n",
      "Episode: 2058 Total reward: 8.0 Training loss: 1094.2346 Explore P: 0.0869\n",
      "Episode: 2059 Total reward: 8.0 Training loss: 582.9844 Explore P: 0.0868\n",
      "Episode: 2060 Total reward: 11.0 Training loss: 1044.3749 Explore P: 0.0867\n",
      "Episode: 2061 Total reward: 12.0 Training loss: 1068.4686 Explore P: 0.0866\n",
      "Episode: 2062 Total reward: 9.0 Training loss: 332.2376 Explore P: 0.0866\n",
      "Episode: 2063 Total reward: 13.0 Training loss: 277.6802 Explore P: 0.0865\n",
      "Episode: 2064 Total reward: 9.0 Training loss: 2105.3210 Explore P: 0.0864\n",
      "Episode: 2065 Total reward: 7.0 Training loss: 628.4719 Explore P: 0.0863\n",
      "Episode: 2066 Total reward: 10.0 Training loss: 403.0740 Explore P: 0.0863\n",
      "Episode: 2067 Total reward: 8.0 Training loss: 2041.9525 Explore P: 0.0862\n",
      "Episode: 2068 Total reward: 9.0 Training loss: 1791.9727 Explore P: 0.0861\n",
      "Episode: 2069 Total reward: 14.0 Training loss: 622.7841 Explore P: 0.0860\n",
      "Episode: 2070 Total reward: 12.0 Training loss: 1193.1218 Explore P: 0.0859\n",
      "Episode: 2071 Total reward: 11.0 Training loss: 422.8481 Explore P: 0.0858\n",
      "Episode: 2072 Total reward: 11.0 Training loss: 364.0999 Explore P: 0.0858\n",
      "Episode: 2073 Total reward: 7.0 Training loss: 653.5744 Explore P: 0.0857\n",
      "Episode: 2074 Total reward: 9.0 Training loss: 851.9841 Explore P: 0.0856\n",
      "Episode: 2075 Total reward: 8.0 Training loss: 406.4207 Explore P: 0.0856\n",
      "Episode: 2076 Total reward: 13.0 Training loss: 1637.6266 Explore P: 0.0855\n",
      "Episode: 2077 Total reward: 12.0 Training loss: 619.4879 Explore P: 0.0854\n",
      "Episode: 2078 Total reward: 9.0 Training loss: 1316.7770 Explore P: 0.0853\n",
      "Episode: 2079 Total reward: 14.0 Training loss: 371.9540 Explore P: 0.0852\n",
      "Episode: 2080 Total reward: 11.0 Training loss: 384.0037 Explore P: 0.0851\n",
      "Episode: 2081 Total reward: 7.0 Training loss: 859.0186 Explore P: 0.0851\n",
      "Episode: 2082 Total reward: 12.0 Training loss: 2724.2720 Explore P: 0.0850\n",
      "Episode: 2083 Total reward: 13.0 Training loss: 472.3181 Explore P: 0.0849\n",
      "Episode: 2084 Total reward: 11.0 Training loss: 3180.1284 Explore P: 0.0848\n",
      "Episode: 2085 Total reward: 13.0 Training loss: 1330.0242 Explore P: 0.0847\n",
      "Episode: 2086 Total reward: 8.0 Training loss: 790.6794 Explore P: 0.0847\n",
      "Episode: 2087 Total reward: 8.0 Training loss: 686.8374 Explore P: 0.0846\n",
      "Episode: 2088 Total reward: 12.0 Training loss: 715.3837 Explore P: 0.0845\n",
      "Episode: 2089 Total reward: 13.0 Training loss: 2065.6113 Explore P: 0.0844\n",
      "Episode: 2090 Total reward: 9.0 Training loss: 884.6209 Explore P: 0.0843\n",
      "Episode: 2091 Total reward: 10.0 Training loss: 927.5220 Explore P: 0.0843\n",
      "Episode: 2092 Total reward: 9.0 Training loss: 1095.6721 Explore P: 0.0842\n",
      "Episode: 2093 Total reward: 11.0 Training loss: 1084.4232 Explore P: 0.0841\n",
      "Episode: 2094 Total reward: 10.0 Training loss: 464.4661 Explore P: 0.0840\n",
      "Episode: 2095 Total reward: 11.0 Training loss: 690.0669 Explore P: 0.0840\n",
      "Episode: 2096 Total reward: 9.0 Training loss: 1145.8635 Explore P: 0.0839\n",
      "Episode: 2097 Total reward: 8.0 Training loss: 1304.7205 Explore P: 0.0838\n",
      "Episode: 2098 Total reward: 9.0 Training loss: 637.7675 Explore P: 0.0838\n",
      "Episode: 2099 Total reward: 10.0 Training loss: 1206.6903 Explore P: 0.0837\n",
      "Episode: 2100 Total reward: 9.0 Training loss: 521.2303 Explore P: 0.0836\n",
      "Episode: 2101 Total reward: 10.0 Training loss: 1277.2781 Explore P: 0.0836\n",
      "Episode: 2102 Total reward: 12.0 Training loss: 1064.3845 Explore P: 0.0835\n",
      "Episode: 2103 Total reward: 9.0 Training loss: 80.7229 Explore P: 0.0834\n",
      "Episode: 2104 Total reward: 10.0 Training loss: 216.9721 Explore P: 0.0833\n",
      "Episode: 2105 Total reward: 10.0 Training loss: 73.0783 Explore P: 0.0833\n",
      "Episode: 2106 Total reward: 8.0 Training loss: 535.9803 Explore P: 0.0832\n",
      "Episode: 2107 Total reward: 11.0 Training loss: 1600.3069 Explore P: 0.0831\n",
      "Episode: 2108 Total reward: 8.0 Training loss: 4308.7627 Explore P: 0.0831\n",
      "Episode: 2109 Total reward: 11.0 Training loss: 525.2518 Explore P: 0.0830\n",
      "Episode: 2110 Total reward: 9.0 Training loss: 896.8102 Explore P: 0.0829\n",
      "Episode: 2111 Total reward: 10.0 Training loss: 348.1042 Explore P: 0.0828\n",
      "Episode: 2112 Total reward: 11.0 Training loss: 348.5288 Explore P: 0.0828\n",
      "Episode: 2113 Total reward: 10.0 Training loss: 604.4363 Explore P: 0.0827\n",
      "Episode: 2114 Total reward: 8.0 Training loss: 169.7235 Explore P: 0.0826\n",
      "Episode: 2115 Total reward: 12.0 Training loss: 462.2774 Explore P: 0.0825\n",
      "Episode: 2116 Total reward: 9.0 Training loss: 1104.7292 Explore P: 0.0825\n",
      "Episode: 2117 Total reward: 12.0 Training loss: 901.6691 Explore P: 0.0824\n",
      "Episode: 2118 Total reward: 9.0 Training loss: 2018.8328 Explore P: 0.0823\n",
      "Episode: 2119 Total reward: 7.0 Training loss: 500.8830 Explore P: 0.0823\n",
      "Episode: 2120 Total reward: 10.0 Training loss: 1490.1848 Explore P: 0.0822\n",
      "Episode: 2121 Total reward: 8.0 Training loss: 133.2679 Explore P: 0.0821\n",
      "Episode: 2122 Total reward: 8.0 Training loss: 523.3189 Explore P: 0.0821\n",
      "Episode: 2123 Total reward: 10.0 Training loss: 1186.3250 Explore P: 0.0820\n",
      "Episode: 2124 Total reward: 11.0 Training loss: 423.4330 Explore P: 0.0819\n",
      "Episode: 2125 Total reward: 10.0 Training loss: 4955.3491 Explore P: 0.0819\n",
      "Episode: 2126 Total reward: 11.0 Training loss: 296.9356 Explore P: 0.0818\n",
      "Episode: 2127 Total reward: 7.0 Training loss: 2098.1299 Explore P: 0.0817\n",
      "Episode: 2128 Total reward: 11.0 Training loss: 654.3632 Explore P: 0.0817\n",
      "Episode: 2129 Total reward: 9.0 Training loss: 1791.0010 Explore P: 0.0816\n",
      "Episode: 2130 Total reward: 11.0 Training loss: 591.4850 Explore P: 0.0815\n",
      "Episode: 2131 Total reward: 10.0 Training loss: 1098.4890 Explore P: 0.0814\n",
      "Episode: 2132 Total reward: 12.0 Training loss: 458.8915 Explore P: 0.0814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2133 Total reward: 12.0 Training loss: 782.1493 Explore P: 0.0813\n",
      "Episode: 2134 Total reward: 9.0 Training loss: 491.6829 Explore P: 0.0812\n",
      "Episode: 2135 Total reward: 11.0 Training loss: 1941.3699 Explore P: 0.0811\n",
      "Episode: 2136 Total reward: 8.0 Training loss: 1322.7582 Explore P: 0.0811\n",
      "Episode: 2137 Total reward: 12.0 Training loss: 1347.9244 Explore P: 0.0810\n",
      "Episode: 2138 Total reward: 10.0 Training loss: 126.2987 Explore P: 0.0809\n",
      "Episode: 2139 Total reward: 9.0 Training loss: 652.6063 Explore P: 0.0809\n",
      "Episode: 2140 Total reward: 9.0 Training loss: 255.1038 Explore P: 0.0808\n",
      "Episode: 2141 Total reward: 10.0 Training loss: 1241.1488 Explore P: 0.0807\n",
      "Episode: 2142 Total reward: 9.0 Training loss: 335.1991 Explore P: 0.0807\n",
      "Episode: 2143 Total reward: 11.0 Training loss: 365.8559 Explore P: 0.0806\n",
      "Episode: 2144 Total reward: 11.0 Training loss: 555.1097 Explore P: 0.0805\n",
      "Episode: 2145 Total reward: 10.0 Training loss: 2116.7117 Explore P: 0.0804\n",
      "Episode: 2146 Total reward: 10.0 Training loss: 2268.6899 Explore P: 0.0804\n",
      "Episode: 2147 Total reward: 10.0 Training loss: 1258.3123 Explore P: 0.0803\n",
      "Episode: 2148 Total reward: 8.0 Training loss: 459.3210 Explore P: 0.0802\n",
      "Episode: 2149 Total reward: 14.0 Training loss: 1498.9625 Explore P: 0.0801\n",
      "Episode: 2150 Total reward: 10.0 Training loss: 1364.0720 Explore P: 0.0801\n",
      "Episode: 2151 Total reward: 9.0 Training loss: 2059.8723 Explore P: 0.0800\n",
      "Episode: 2152 Total reward: 10.0 Training loss: 701.5293 Explore P: 0.0799\n",
      "Episode: 2153 Total reward: 8.0 Training loss: 1429.7837 Explore P: 0.0799\n",
      "Episode: 2154 Total reward: 11.0 Training loss: 2554.6824 Explore P: 0.0798\n",
      "Episode: 2155 Total reward: 11.0 Training loss: 691.7406 Explore P: 0.0797\n",
      "Episode: 2156 Total reward: 9.0 Training loss: 1133.3882 Explore P: 0.0797\n",
      "Episode: 2157 Total reward: 11.0 Training loss: 1214.0005 Explore P: 0.0796\n",
      "Episode: 2158 Total reward: 10.0 Training loss: 709.3842 Explore P: 0.0795\n",
      "Episode: 2159 Total reward: 10.0 Training loss: 178.0861 Explore P: 0.0794\n",
      "Episode: 2160 Total reward: 10.0 Training loss: 797.5298 Explore P: 0.0794\n",
      "Episode: 2161 Total reward: 11.0 Training loss: 2998.5105 Explore P: 0.0793\n",
      "Episode: 2162 Total reward: 10.0 Training loss: 1357.0193 Explore P: 0.0792\n",
      "Episode: 2163 Total reward: 12.0 Training loss: 253.0259 Explore P: 0.0791\n",
      "Episode: 2164 Total reward: 7.0 Training loss: 246.7383 Explore P: 0.0791\n",
      "Episode: 2165 Total reward: 12.0 Training loss: 4054.1909 Explore P: 0.0790\n",
      "Episode: 2166 Total reward: 10.0 Training loss: 371.3365 Explore P: 0.0789\n",
      "Episode: 2167 Total reward: 13.0 Training loss: 1441.8324 Explore P: 0.0789\n",
      "Episode: 2168 Total reward: 10.0 Training loss: 887.8486 Explore P: 0.0788\n",
      "Episode: 2169 Total reward: 12.0 Training loss: 2748.9136 Explore P: 0.0787\n",
      "Episode: 2170 Total reward: 12.0 Training loss: 444.0236 Explore P: 0.0786\n",
      "Episode: 2171 Total reward: 8.0 Training loss: 1233.7778 Explore P: 0.0786\n",
      "Episode: 2172 Total reward: 8.0 Training loss: 616.2704 Explore P: 0.0785\n",
      "Episode: 2173 Total reward: 7.0 Training loss: 1882.5447 Explore P: 0.0785\n",
      "Episode: 2174 Total reward: 11.0 Training loss: 396.1081 Explore P: 0.0784\n",
      "Episode: 2175 Total reward: 11.0 Training loss: 1290.6487 Explore P: 0.0783\n",
      "Episode: 2176 Total reward: 11.0 Training loss: 735.2015 Explore P: 0.0782\n",
      "Episode: 2177 Total reward: 8.0 Training loss: 736.2264 Explore P: 0.0782\n",
      "Episode: 2178 Total reward: 11.0 Training loss: 1045.2578 Explore P: 0.0781\n",
      "Episode: 2179 Total reward: 11.0 Training loss: 680.3242 Explore P: 0.0780\n",
      "Episode: 2180 Total reward: 8.0 Training loss: 1559.2588 Explore P: 0.0780\n",
      "Episode: 2181 Total reward: 8.0 Training loss: 807.5192 Explore P: 0.0779\n",
      "Episode: 2182 Total reward: 8.0 Training loss: 1550.9456 Explore P: 0.0779\n",
      "Episode: 2183 Total reward: 8.0 Training loss: 1122.2874 Explore P: 0.0778\n",
      "Episode: 2184 Total reward: 12.0 Training loss: 234.3580 Explore P: 0.0777\n",
      "Episode: 2185 Total reward: 9.0 Training loss: 2380.0737 Explore P: 0.0777\n",
      "Episode: 2186 Total reward: 12.0 Training loss: 1295.9934 Explore P: 0.0776\n",
      "Episode: 2187 Total reward: 10.0 Training loss: 1071.6901 Explore P: 0.0775\n",
      "Episode: 2188 Total reward: 11.0 Training loss: 157.7468 Explore P: 0.0775\n",
      "Episode: 2189 Total reward: 9.0 Training loss: 1341.4119 Explore P: 0.0774\n",
      "Episode: 2190 Total reward: 9.0 Training loss: 4650.7764 Explore P: 0.0773\n",
      "Episode: 2191 Total reward: 9.0 Training loss: 475.6947 Explore P: 0.0773\n",
      "Episode: 2192 Total reward: 9.0 Training loss: 421.6636 Explore P: 0.0772\n",
      "Episode: 2193 Total reward: 11.0 Training loss: 345.1985 Explore P: 0.0771\n",
      "Episode: 2194 Total reward: 11.0 Training loss: 537.2809 Explore P: 0.0771\n",
      "Episode: 2195 Total reward: 14.0 Training loss: 489.9839 Explore P: 0.0770\n",
      "Episode: 2196 Total reward: 30.0 Training loss: 95.3668 Explore P: 0.0768\n",
      "Episode: 2197 Total reward: 11.0 Training loss: 1013.1595 Explore P: 0.0767\n",
      "Episode: 2198 Total reward: 10.0 Training loss: 2472.2029 Explore P: 0.0766\n",
      "Episode: 2199 Total reward: 8.0 Training loss: 874.3544 Explore P: 0.0766\n",
      "Episode: 2200 Total reward: 11.0 Training loss: 961.0300 Explore P: 0.0765\n",
      "Episode: 2201 Total reward: 10.0 Training loss: 1481.5371 Explore P: 0.0764\n",
      "Episode: 2202 Total reward: 11.0 Training loss: 1162.9612 Explore P: 0.0764\n",
      "Episode: 2203 Total reward: 11.0 Training loss: 554.7540 Explore P: 0.0763\n",
      "Episode: 2204 Total reward: 9.0 Training loss: 463.7049 Explore P: 0.0762\n",
      "Episode: 2205 Total reward: 11.0 Training loss: 1029.6545 Explore P: 0.0762\n",
      "Episode: 2206 Total reward: 10.0 Training loss: 770.4378 Explore P: 0.0761\n",
      "Episode: 2207 Total reward: 11.0 Training loss: 1500.4567 Explore P: 0.0760\n",
      "Episode: 2208 Total reward: 8.0 Training loss: 4188.5288 Explore P: 0.0760\n",
      "Episode: 2209 Total reward: 8.0 Training loss: 3615.6743 Explore P: 0.0759\n",
      "Episode: 2210 Total reward: 8.0 Training loss: 702.4312 Explore P: 0.0759\n",
      "Episode: 2211 Total reward: 9.0 Training loss: 2122.9062 Explore P: 0.0758\n",
      "Episode: 2212 Total reward: 10.0 Training loss: 187.1767 Explore P: 0.0757\n",
      "Episode: 2213 Total reward: 8.0 Training loss: 1216.3904 Explore P: 0.0757\n",
      "Episode: 2214 Total reward: 9.0 Training loss: 1486.0745 Explore P: 0.0756\n",
      "Episode: 2215 Total reward: 9.0 Training loss: 458.7271 Explore P: 0.0756\n",
      "Episode: 2216 Total reward: 9.0 Training loss: 195.9240 Explore P: 0.0755\n",
      "Episode: 2217 Total reward: 10.0 Training loss: 2459.2163 Explore P: 0.0754\n",
      "Episode: 2218 Total reward: 10.0 Training loss: 3792.8472 Explore P: 0.0754\n",
      "Episode: 2219 Total reward: 8.0 Training loss: 778.7745 Explore P: 0.0753\n",
      "Episode: 2220 Total reward: 8.0 Training loss: 473.6136 Explore P: 0.0753\n",
      "Episode: 2221 Total reward: 9.0 Training loss: 2203.2869 Explore P: 0.0752\n",
      "Episode: 2222 Total reward: 9.0 Training loss: 979.1156 Explore P: 0.0752\n",
      "Episode: 2223 Total reward: 9.0 Training loss: 539.1342 Explore P: 0.0751\n",
      "Episode: 2224 Total reward: 9.0 Training loss: 2284.0308 Explore P: 0.0750\n",
      "Episode: 2225 Total reward: 8.0 Training loss: 607.6640 Explore P: 0.0750\n",
      "Episode: 2226 Total reward: 16.0 Training loss: 819.8104 Explore P: 0.0749\n",
      "Episode: 2227 Total reward: 10.0 Training loss: 1500.9406 Explore P: 0.0748\n",
      "Episode: 2228 Total reward: 9.0 Training loss: 1385.6173 Explore P: 0.0748\n",
      "Episode: 2229 Total reward: 10.0 Training loss: 1614.6134 Explore P: 0.0747\n",
      "Episode: 2230 Total reward: 15.0 Training loss: 2317.6528 Explore P: 0.0746\n",
      "Episode: 2231 Total reward: 12.0 Training loss: 859.8430 Explore P: 0.0745\n",
      "Episode: 2232 Total reward: 14.0 Training loss: 989.4108 Explore P: 0.0744\n",
      "Episode: 2233 Total reward: 8.0 Training loss: 1452.2646 Explore P: 0.0744\n",
      "Episode: 2234 Total reward: 10.0 Training loss: 947.1232 Explore P: 0.0743\n",
      "Episode: 2235 Total reward: 11.0 Training loss: 1049.3324 Explore P: 0.0742\n",
      "Episode: 2236 Total reward: 10.0 Training loss: 4083.5269 Explore P: 0.0742\n",
      "Episode: 2237 Total reward: 7.0 Training loss: 2912.7866 Explore P: 0.0741\n",
      "Episode: 2238 Total reward: 11.0 Training loss: 705.5980 Explore P: 0.0741\n",
      "Episode: 2239 Total reward: 8.0 Training loss: 306.4735 Explore P: 0.0740\n",
      "Episode: 2240 Total reward: 8.0 Training loss: 240.3097 Explore P: 0.0740\n",
      "Episode: 2241 Total reward: 13.0 Training loss: 591.6886 Explore P: 0.0739\n",
      "Episode: 2242 Total reward: 9.0 Training loss: 874.8597 Explore P: 0.0738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2243 Total reward: 11.0 Training loss: 505.0058 Explore P: 0.0737\n",
      "Episode: 2244 Total reward: 9.0 Training loss: 243.0229 Explore P: 0.0737\n",
      "Episode: 2245 Total reward: 8.0 Training loss: 3414.2969 Explore P: 0.0736\n",
      "Episode: 2246 Total reward: 10.0 Training loss: 1169.0864 Explore P: 0.0736\n",
      "Episode: 2247 Total reward: 8.0 Training loss: 335.9243 Explore P: 0.0735\n",
      "Episode: 2248 Total reward: 10.0 Training loss: 1956.2297 Explore P: 0.0735\n",
      "Episode: 2249 Total reward: 9.0 Training loss: 705.8117 Explore P: 0.0734\n",
      "Episode: 2250 Total reward: 9.0 Training loss: 1700.3461 Explore P: 0.0733\n",
      "Episode: 2251 Total reward: 12.0 Training loss: 1372.3264 Explore P: 0.0733\n",
      "Episode: 2252 Total reward: 8.0 Training loss: 556.4838 Explore P: 0.0732\n",
      "Episode: 2253 Total reward: 8.0 Training loss: 1297.5287 Explore P: 0.0732\n",
      "Episode: 2254 Total reward: 10.0 Training loss: 3010.7241 Explore P: 0.0731\n",
      "Episode: 2255 Total reward: 11.0 Training loss: 1024.2052 Explore P: 0.0730\n",
      "Episode: 2256 Total reward: 10.0 Training loss: 803.4591 Explore P: 0.0730\n",
      "Episode: 2257 Total reward: 11.0 Training loss: 583.0018 Explore P: 0.0729\n",
      "Episode: 2258 Total reward: 9.0 Training loss: 2012.7021 Explore P: 0.0728\n",
      "Episode: 2259 Total reward: 11.0 Training loss: 2470.2375 Explore P: 0.0728\n",
      "Episode: 2260 Total reward: 11.0 Training loss: 293.0853 Explore P: 0.0727\n",
      "Episode: 2261 Total reward: 10.0 Training loss: 1419.8954 Explore P: 0.0726\n",
      "Episode: 2262 Total reward: 9.0 Training loss: 421.5095 Explore P: 0.0726\n",
      "Episode: 2263 Total reward: 9.0 Training loss: 839.4993 Explore P: 0.0725\n",
      "Episode: 2264 Total reward: 9.0 Training loss: 426.3036 Explore P: 0.0725\n",
      "Episode: 2265 Total reward: 8.0 Training loss: 1387.4412 Explore P: 0.0724\n",
      "Episode: 2266 Total reward: 8.0 Training loss: 1198.1355 Explore P: 0.0724\n",
      "Episode: 2267 Total reward: 11.0 Training loss: 5513.4639 Explore P: 0.0723\n",
      "Episode: 2268 Total reward: 10.0 Training loss: 1150.1313 Explore P: 0.0722\n",
      "Episode: 2269 Total reward: 9.0 Training loss: 465.5556 Explore P: 0.0722\n",
      "Episode: 2270 Total reward: 12.0 Training loss: 1382.1820 Explore P: 0.0721\n",
      "Episode: 2271 Total reward: 10.0 Training loss: 512.1927 Explore P: 0.0721\n",
      "Episode: 2272 Total reward: 9.0 Training loss: 569.1039 Explore P: 0.0720\n",
      "Episode: 2273 Total reward: 8.0 Training loss: 513.6163 Explore P: 0.0719\n",
      "Episode: 2274 Total reward: 9.0 Training loss: 855.3588 Explore P: 0.0719\n",
      "Episode: 2275 Total reward: 10.0 Training loss: 1075.5750 Explore P: 0.0718\n",
      "Episode: 2276 Total reward: 11.0 Training loss: 326.0628 Explore P: 0.0718\n",
      "Episode: 2277 Total reward: 10.0 Training loss: 2083.6772 Explore P: 0.0717\n",
      "Episode: 2278 Total reward: 10.0 Training loss: 871.4867 Explore P: 0.0716\n",
      "Episode: 2279 Total reward: 11.0 Training loss: 3120.0911 Explore P: 0.0716\n",
      "Episode: 2280 Total reward: 8.0 Training loss: 836.2323 Explore P: 0.0715\n",
      "Episode: 2281 Total reward: 11.0 Training loss: 4275.2881 Explore P: 0.0715\n",
      "Episode: 2282 Total reward: 11.0 Training loss: 1000.5822 Explore P: 0.0714\n",
      "Episode: 2283 Total reward: 7.0 Training loss: 686.8922 Explore P: 0.0713\n",
      "Episode: 2284 Total reward: 11.0 Training loss: 684.5765 Explore P: 0.0713\n",
      "Episode: 2285 Total reward: 10.0 Training loss: 171.7343 Explore P: 0.0712\n",
      "Episode: 2286 Total reward: 13.0 Training loss: 4018.4238 Explore P: 0.0711\n",
      "Episode: 2287 Total reward: 10.0 Training loss: 821.7453 Explore P: 0.0711\n",
      "Episode: 2288 Total reward: 10.0 Training loss: 2516.7869 Explore P: 0.0710\n",
      "Episode: 2289 Total reward: 8.0 Training loss: 374.9087 Explore P: 0.0710\n",
      "Episode: 2290 Total reward: 9.0 Training loss: 413.6860 Explore P: 0.0709\n",
      "Episode: 2291 Total reward: 10.0 Training loss: 1466.6407 Explore P: 0.0708\n",
      "Episode: 2292 Total reward: 10.0 Training loss: 253.9235 Explore P: 0.0708\n",
      "Episode: 2293 Total reward: 14.0 Training loss: 220.6415 Explore P: 0.0707\n",
      "Episode: 2294 Total reward: 10.0 Training loss: 284.7049 Explore P: 0.0706\n",
      "Episode: 2295 Total reward: 8.0 Training loss: 285.9473 Explore P: 0.0706\n",
      "Episode: 2296 Total reward: 12.0 Training loss: 342.3852 Explore P: 0.0705\n",
      "Episode: 2297 Total reward: 7.0 Training loss: 335.3132 Explore P: 0.0705\n",
      "Episode: 2298 Total reward: 12.0 Training loss: 4056.9673 Explore P: 0.0704\n",
      "Episode: 2299 Total reward: 8.0 Training loss: 6229.0063 Explore P: 0.0704\n",
      "Episode: 2300 Total reward: 7.0 Training loss: 398.9934 Explore P: 0.0703\n",
      "Episode: 2301 Total reward: 11.0 Training loss: 1461.5049 Explore P: 0.0703\n",
      "Episode: 2302 Total reward: 8.0 Training loss: 524.0933 Explore P: 0.0702\n",
      "Episode: 2303 Total reward: 8.0 Training loss: 1139.0443 Explore P: 0.0702\n",
      "Episode: 2304 Total reward: 7.0 Training loss: 680.9564 Explore P: 0.0701\n",
      "Episode: 2305 Total reward: 8.0 Training loss: 402.1187 Explore P: 0.0701\n",
      "Episode: 2306 Total reward: 9.0 Training loss: 270.2957 Explore P: 0.0700\n",
      "Episode: 2307 Total reward: 9.0 Training loss: 736.6486 Explore P: 0.0700\n",
      "Episode: 2308 Total reward: 10.0 Training loss: 1495.0739 Explore P: 0.0699\n",
      "Episode: 2309 Total reward: 11.0 Training loss: 1686.8187 Explore P: 0.0698\n",
      "Episode: 2310 Total reward: 10.0 Training loss: 700.7273 Explore P: 0.0698\n",
      "Episode: 2311 Total reward: 12.0 Training loss: 449.9594 Explore P: 0.0697\n",
      "Episode: 2312 Total reward: 12.0 Training loss: 446.8302 Explore P: 0.0696\n",
      "Episode: 2313 Total reward: 11.0 Training loss: 309.0688 Explore P: 0.0696\n",
      "Episode: 2314 Total reward: 9.0 Training loss: 418.9547 Explore P: 0.0695\n",
      "Episode: 2315 Total reward: 11.0 Training loss: 770.9238 Explore P: 0.0694\n",
      "Episode: 2316 Total reward: 7.0 Training loss: 411.8903 Explore P: 0.0694\n",
      "Episode: 2317 Total reward: 11.0 Training loss: 710.8577 Explore P: 0.0693\n",
      "Episode: 2318 Total reward: 9.0 Training loss: 539.1494 Explore P: 0.0693\n",
      "Episode: 2319 Total reward: 7.0 Training loss: 5890.5542 Explore P: 0.0692\n",
      "Episode: 2320 Total reward: 11.0 Training loss: 700.7463 Explore P: 0.0692\n",
      "Episode: 2321 Total reward: 9.0 Training loss: 742.0533 Explore P: 0.0691\n",
      "Episode: 2322 Total reward: 11.0 Training loss: 906.2360 Explore P: 0.0691\n",
      "Episode: 2323 Total reward: 11.0 Training loss: 1377.8551 Explore P: 0.0690\n",
      "Episode: 2324 Total reward: 8.0 Training loss: 1181.4536 Explore P: 0.0689\n",
      "Episode: 2325 Total reward: 8.0 Training loss: 579.4707 Explore P: 0.0689\n",
      "Episode: 2326 Total reward: 10.0 Training loss: 939.9875 Explore P: 0.0688\n",
      "Episode: 2327 Total reward: 12.0 Training loss: 173.6126 Explore P: 0.0688\n",
      "Episode: 2328 Total reward: 11.0 Training loss: 804.7002 Explore P: 0.0687\n",
      "Episode: 2329 Total reward: 8.0 Training loss: 750.2589 Explore P: 0.0687\n",
      "Episode: 2330 Total reward: 10.0 Training loss: 1062.5221 Explore P: 0.0686\n",
      "Episode: 2331 Total reward: 9.0 Training loss: 1230.4287 Explore P: 0.0685\n",
      "Episode: 2332 Total reward: 11.0 Training loss: 611.0535 Explore P: 0.0685\n",
      "Episode: 2333 Total reward: 10.0 Training loss: 1198.0665 Explore P: 0.0684\n",
      "Episode: 2334 Total reward: 10.0 Training loss: 697.4429 Explore P: 0.0684\n",
      "Episode: 2335 Total reward: 11.0 Training loss: 1423.2313 Explore P: 0.0683\n",
      "Episode: 2336 Total reward: 8.0 Training loss: 446.2895 Explore P: 0.0683\n",
      "Episode: 2337 Total reward: 13.0 Training loss: 1067.8020 Explore P: 0.0682\n",
      "Episode: 2338 Total reward: 8.0 Training loss: 1387.7471 Explore P: 0.0681\n",
      "Episode: 2339 Total reward: 10.0 Training loss: 5104.6533 Explore P: 0.0681\n",
      "Episode: 2340 Total reward: 9.0 Training loss: 228.1458 Explore P: 0.0680\n",
      "Episode: 2341 Total reward: 9.0 Training loss: 237.4794 Explore P: 0.0680\n",
      "Episode: 2342 Total reward: 11.0 Training loss: 3307.0046 Explore P: 0.0679\n",
      "Episode: 2343 Total reward: 10.0 Training loss: 426.0199 Explore P: 0.0678\n",
      "Episode: 2344 Total reward: 7.0 Training loss: 729.7688 Explore P: 0.0678\n",
      "Episode: 2345 Total reward: 11.0 Training loss: 289.8363 Explore P: 0.0677\n",
      "Episode: 2346 Total reward: 11.0 Training loss: 1790.6390 Explore P: 0.0677\n",
      "Episode: 2347 Total reward: 8.0 Training loss: 1442.4059 Explore P: 0.0676\n",
      "Episode: 2348 Total reward: 9.0 Training loss: 1117.6692 Explore P: 0.0676\n",
      "Episode: 2349 Total reward: 11.0 Training loss: 948.5350 Explore P: 0.0675\n",
      "Episode: 2350 Total reward: 10.0 Training loss: 1602.7953 Explore P: 0.0675\n",
      "Episode: 2351 Total reward: 8.0 Training loss: 756.9565 Explore P: 0.0674\n",
      "Episode: 2352 Total reward: 11.0 Training loss: 469.3008 Explore P: 0.0674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2353 Total reward: 10.0 Training loss: 2984.6052 Explore P: 0.0673\n",
      "Episode: 2354 Total reward: 9.0 Training loss: 1618.4739 Explore P: 0.0672\n",
      "Episode: 2355 Total reward: 10.0 Training loss: 2900.6421 Explore P: 0.0672\n",
      "Episode: 2356 Total reward: 10.0 Training loss: 631.6990 Explore P: 0.0671\n",
      "Episode: 2357 Total reward: 8.0 Training loss: 916.0688 Explore P: 0.0671\n",
      "Episode: 2358 Total reward: 8.0 Training loss: 288.7195 Explore P: 0.0670\n",
      "Episode: 2359 Total reward: 9.0 Training loss: 298.9279 Explore P: 0.0670\n",
      "Episode: 2360 Total reward: 8.0 Training loss: 1454.8278 Explore P: 0.0669\n",
      "Episode: 2361 Total reward: 12.0 Training loss: 1705.6863 Explore P: 0.0669\n",
      "Episode: 2362 Total reward: 10.0 Training loss: 698.0524 Explore P: 0.0668\n",
      "Episode: 2363 Total reward: 12.0 Training loss: 1051.2500 Explore P: 0.0667\n",
      "Episode: 2364 Total reward: 10.0 Training loss: 340.8276 Explore P: 0.0667\n",
      "Episode: 2365 Total reward: 8.0 Training loss: 1929.5980 Explore P: 0.0666\n",
      "Episode: 2366 Total reward: 9.0 Training loss: 528.5583 Explore P: 0.0666\n",
      "Episode: 2367 Total reward: 9.0 Training loss: 1459.6472 Explore P: 0.0665\n",
      "Episode: 2368 Total reward: 9.0 Training loss: 157.9857 Explore P: 0.0665\n",
      "Episode: 2369 Total reward: 11.0 Training loss: 143.2204 Explore P: 0.0664\n",
      "Episode: 2370 Total reward: 8.0 Training loss: 1557.5154 Explore P: 0.0664\n",
      "Episode: 2371 Total reward: 9.0 Training loss: 167.0133 Explore P: 0.0663\n",
      "Episode: 2372 Total reward: 10.0 Training loss: 757.7894 Explore P: 0.0663\n",
      "Episode: 2373 Total reward: 14.0 Training loss: 4261.4180 Explore P: 0.0662\n",
      "Episode: 2374 Total reward: 10.0 Training loss: 320.0909 Explore P: 0.0661\n",
      "Episode: 2375 Total reward: 8.0 Training loss: 1164.1003 Explore P: 0.0661\n",
      "Episode: 2376 Total reward: 11.0 Training loss: 828.0677 Explore P: 0.0660\n",
      "Episode: 2377 Total reward: 11.0 Training loss: 664.3157 Explore P: 0.0660\n",
      "Episode: 2378 Total reward: 10.0 Training loss: 3104.4194 Explore P: 0.0659\n",
      "Episode: 2379 Total reward: 12.0 Training loss: 1827.3239 Explore P: 0.0659\n",
      "Episode: 2380 Total reward: 10.0 Training loss: 156.1892 Explore P: 0.0658\n",
      "Episode: 2381 Total reward: 7.0 Training loss: 417.8795 Explore P: 0.0658\n",
      "Episode: 2382 Total reward: 10.0 Training loss: 510.4281 Explore P: 0.0657\n",
      "Episode: 2383 Total reward: 8.0 Training loss: 1081.1697 Explore P: 0.0657\n",
      "Episode: 2384 Total reward: 8.0 Training loss: 724.2363 Explore P: 0.0656\n",
      "Episode: 2385 Total reward: 9.0 Training loss: 754.9403 Explore P: 0.0656\n",
      "Episode: 2386 Total reward: 13.0 Training loss: 207.9134 Explore P: 0.0655\n",
      "Episode: 2387 Total reward: 12.0 Training loss: 998.1042 Explore P: 0.0654\n",
      "Episode: 2388 Total reward: 10.0 Training loss: 917.9871 Explore P: 0.0654\n",
      "Episode: 2389 Total reward: 11.0 Training loss: 1496.5962 Explore P: 0.0653\n",
      "Episode: 2390 Total reward: 13.0 Training loss: 1215.7811 Explore P: 0.0652\n",
      "Episode: 2391 Total reward: 8.0 Training loss: 632.2444 Explore P: 0.0652\n",
      "Episode: 2392 Total reward: 8.0 Training loss: 422.6121 Explore P: 0.0651\n",
      "Episode: 2393 Total reward: 11.0 Training loss: 1620.2762 Explore P: 0.0651\n",
      "Episode: 2394 Total reward: 12.0 Training loss: 506.6467 Explore P: 0.0650\n",
      "Episode: 2395 Total reward: 8.0 Training loss: 697.7279 Explore P: 0.0650\n",
      "Episode: 2396 Total reward: 7.0 Training loss: 2700.4851 Explore P: 0.0649\n",
      "Episode: 2397 Total reward: 11.0 Training loss: 451.4506 Explore P: 0.0649\n",
      "Episode: 2398 Total reward: 13.0 Training loss: 528.8481 Explore P: 0.0648\n",
      "Episode: 2399 Total reward: 8.0 Training loss: 1065.5481 Explore P: 0.0648\n",
      "Episode: 2400 Total reward: 9.0 Training loss: 1262.7769 Explore P: 0.0647\n",
      "Episode: 2401 Total reward: 10.0 Training loss: 331.8732 Explore P: 0.0647\n",
      "Episode: 2402 Total reward: 12.0 Training loss: 4047.5496 Explore P: 0.0646\n",
      "Episode: 2403 Total reward: 8.0 Training loss: 1642.2230 Explore P: 0.0645\n",
      "Episode: 2404 Total reward: 7.0 Training loss: 1337.3029 Explore P: 0.0645\n",
      "Episode: 2405 Total reward: 10.0 Training loss: 1907.0873 Explore P: 0.0645\n",
      "Episode: 2406 Total reward: 8.0 Training loss: 1232.9622 Explore P: 0.0644\n",
      "Episode: 2407 Total reward: 10.0 Training loss: 489.7855 Explore P: 0.0644\n",
      "Episode: 2408 Total reward: 10.0 Training loss: 611.1998 Explore P: 0.0643\n",
      "Episode: 2409 Total reward: 25.0 Training loss: 1264.4242 Explore P: 0.0642\n",
      "Episode: 2410 Total reward: 14.0 Training loss: 929.6373 Explore P: 0.0641\n",
      "Episode: 2411 Total reward: 12.0 Training loss: 1633.7217 Explore P: 0.0640\n",
      "Episode: 2412 Total reward: 13.0 Training loss: 1248.8601 Explore P: 0.0640\n",
      "Episode: 2413 Total reward: 12.0 Training loss: 606.4603 Explore P: 0.0639\n",
      "Episode: 2414 Total reward: 10.0 Training loss: 1293.3909 Explore P: 0.0638\n",
      "Episode: 2415 Total reward: 14.0 Training loss: 1381.8907 Explore P: 0.0638\n",
      "Episode: 2416 Total reward: 9.0 Training loss: 1570.1121 Explore P: 0.0637\n",
      "Episode: 2417 Total reward: 10.0 Training loss: 659.9388 Explore P: 0.0637\n",
      "Episode: 2418 Total reward: 11.0 Training loss: 5809.2754 Explore P: 0.0636\n",
      "Episode: 2419 Total reward: 11.0 Training loss: 371.0115 Explore P: 0.0635\n",
      "Episode: 2420 Total reward: 17.0 Training loss: 1799.3910 Explore P: 0.0635\n",
      "Episode: 2421 Total reward: 8.0 Training loss: 608.0724 Explore P: 0.0634\n",
      "Episode: 2422 Total reward: 10.0 Training loss: 630.7795 Explore P: 0.0634\n",
      "Episode: 2423 Total reward: 14.0 Training loss: 376.6263 Explore P: 0.0633\n",
      "Episode: 2424 Total reward: 7.0 Training loss: 275.9365 Explore P: 0.0632\n",
      "Episode: 2425 Total reward: 11.0 Training loss: 809.7014 Explore P: 0.0632\n",
      "Episode: 2426 Total reward: 9.0 Training loss: 638.9498 Explore P: 0.0631\n",
      "Episode: 2427 Total reward: 10.0 Training loss: 3570.6965 Explore P: 0.0631\n",
      "Episode: 2428 Total reward: 8.0 Training loss: 1996.5400 Explore P: 0.0630\n",
      "Episode: 2429 Total reward: 12.0 Training loss: 543.0411 Explore P: 0.0630\n",
      "Episode: 2430 Total reward: 10.0 Training loss: 595.2617 Explore P: 0.0629\n",
      "Episode: 2431 Total reward: 12.0 Training loss: 1503.0267 Explore P: 0.0629\n",
      "Episode: 2432 Total reward: 9.0 Training loss: 759.8015 Explore P: 0.0628\n",
      "Episode: 2433 Total reward: 11.0 Training loss: 1225.1793 Explore P: 0.0628\n",
      "Episode: 2434 Total reward: 10.0 Training loss: 668.0013 Explore P: 0.0627\n",
      "Episode: 2435 Total reward: 9.0 Training loss: 521.4106 Explore P: 0.0627\n",
      "Episode: 2436 Total reward: 7.0 Training loss: 1792.5804 Explore P: 0.0626\n",
      "Episode: 2437 Total reward: 11.0 Training loss: 354.2857 Explore P: 0.0626\n",
      "Episode: 2438 Total reward: 9.0 Training loss: 821.7500 Explore P: 0.0625\n",
      "Episode: 2439 Total reward: 15.0 Training loss: 1495.6733 Explore P: 0.0624\n",
      "Episode: 2440 Total reward: 8.0 Training loss: 645.8027 Explore P: 0.0624\n",
      "Episode: 2441 Total reward: 11.0 Training loss: 4604.8804 Explore P: 0.0623\n",
      "Episode: 2442 Total reward: 9.0 Training loss: 1076.6444 Explore P: 0.0623\n",
      "Episode: 2443 Total reward: 11.0 Training loss: 903.2837 Explore P: 0.0622\n",
      "Episode: 2444 Total reward: 11.0 Training loss: 1294.5214 Explore P: 0.0622\n",
      "Episode: 2445 Total reward: 9.0 Training loss: 402.3643 Explore P: 0.0621\n",
      "Episode: 2446 Total reward: 11.0 Training loss: 489.4248 Explore P: 0.0621\n",
      "Episode: 2447 Total reward: 8.0 Training loss: 143.3130 Explore P: 0.0620\n",
      "Episode: 2448 Total reward: 10.0 Training loss: 356.6107 Explore P: 0.0620\n",
      "Episode: 2449 Total reward: 9.0 Training loss: 1738.6670 Explore P: 0.0619\n",
      "Episode: 2450 Total reward: 13.0 Training loss: 479.1737 Explore P: 0.0619\n",
      "Episode: 2451 Total reward: 8.0 Training loss: 558.9352 Explore P: 0.0618\n",
      "Episode: 2452 Total reward: 11.0 Training loss: 616.1370 Explore P: 0.0618\n",
      "Episode: 2453 Total reward: 11.0 Training loss: 1940.8972 Explore P: 0.0617\n",
      "Episode: 2454 Total reward: 9.0 Training loss: 1389.5898 Explore P: 0.0617\n",
      "Episode: 2455 Total reward: 12.0 Training loss: 816.6102 Explore P: 0.0616\n",
      "Episode: 2456 Total reward: 22.0 Training loss: 420.6219 Explore P: 0.0615\n",
      "Episode: 2457 Total reward: 23.0 Training loss: 1067.8008 Explore P: 0.0614\n",
      "Episode: 2458 Total reward: 11.0 Training loss: 606.9875 Explore P: 0.0613\n",
      "Episode: 2459 Total reward: 13.0 Training loss: 814.7982 Explore P: 0.0612\n",
      "Episode: 2460 Total reward: 10.0 Training loss: 232.4726 Explore P: 0.0612\n",
      "Episode: 2461 Total reward: 11.0 Training loss: 1264.8278 Explore P: 0.0611\n",
      "Episode: 2462 Total reward: 10.0 Training loss: 527.2180 Explore P: 0.0611\n",
      "Episode: 2463 Total reward: 12.0 Training loss: 2242.4517 Explore P: 0.0610\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2464 Total reward: 11.0 Training loss: 451.6665 Explore P: 0.0610\n",
      "Episode: 2465 Total reward: 9.0 Training loss: 986.0967 Explore P: 0.0609\n",
      "Episode: 2466 Total reward: 9.0 Training loss: 424.7643 Explore P: 0.0609\n",
      "Episode: 2467 Total reward: 7.0 Training loss: 373.4706 Explore P: 0.0608\n",
      "Episode: 2468 Total reward: 8.0 Training loss: 393.8846 Explore P: 0.0608\n",
      "Episode: 2469 Total reward: 10.0 Training loss: 1301.4844 Explore P: 0.0607\n",
      "Episode: 2470 Total reward: 9.0 Training loss: 504.1624 Explore P: 0.0607\n",
      "Episode: 2471 Total reward: 9.0 Training loss: 557.3654 Explore P: 0.0607\n",
      "Episode: 2472 Total reward: 10.0 Training loss: 117.9941 Explore P: 0.0606\n",
      "Episode: 2473 Total reward: 10.0 Training loss: 1047.0515 Explore P: 0.0606\n",
      "Episode: 2474 Total reward: 9.0 Training loss: 849.0616 Explore P: 0.0605\n",
      "Episode: 2475 Total reward: 11.0 Training loss: 1270.9502 Explore P: 0.0605\n",
      "Episode: 2476 Total reward: 9.0 Training loss: 111.2064 Explore P: 0.0604\n",
      "Episode: 2477 Total reward: 7.0 Training loss: 1523.5803 Explore P: 0.0604\n",
      "Episode: 2478 Total reward: 11.0 Training loss: 296.5204 Explore P: 0.0603\n",
      "Episode: 2479 Total reward: 7.0 Training loss: 2146.0571 Explore P: 0.0603\n",
      "Episode: 2480 Total reward: 9.0 Training loss: 1451.2113 Explore P: 0.0602\n",
      "Episode: 2481 Total reward: 9.0 Training loss: 1908.1160 Explore P: 0.0602\n",
      "Episode: 2482 Total reward: 7.0 Training loss: 986.7147 Explore P: 0.0602\n",
      "Episode: 2483 Total reward: 9.0 Training loss: 1754.7126 Explore P: 0.0601\n",
      "Episode: 2484 Total reward: 11.0 Training loss: 246.0621 Explore P: 0.0601\n",
      "Episode: 2485 Total reward: 10.0 Training loss: 542.5935 Explore P: 0.0600\n",
      "Episode: 2486 Total reward: 9.0 Training loss: 209.8631 Explore P: 0.0600\n",
      "Episode: 2487 Total reward: 11.0 Training loss: 880.2701 Explore P: 0.0599\n",
      "Episode: 2488 Total reward: 7.0 Training loss: 213.7829 Explore P: 0.0599\n",
      "Episode: 2489 Total reward: 7.0 Training loss: 2499.4233 Explore P: 0.0598\n",
      "Episode: 2490 Total reward: 10.0 Training loss: 2033.3073 Explore P: 0.0598\n",
      "Episode: 2491 Total reward: 9.0 Training loss: 1428.3704 Explore P: 0.0597\n",
      "Episode: 2492 Total reward: 9.0 Training loss: 1864.5715 Explore P: 0.0597\n",
      "Episode: 2493 Total reward: 11.0 Training loss: 175.6667 Explore P: 0.0596\n",
      "Episode: 2494 Total reward: 9.0 Training loss: 673.8440 Explore P: 0.0596\n",
      "Episode: 2495 Total reward: 7.0 Training loss: 786.3322 Explore P: 0.0596\n",
      "Episode: 2496 Total reward: 9.0 Training loss: 3653.8579 Explore P: 0.0595\n",
      "Episode: 2497 Total reward: 9.0 Training loss: 2464.8464 Explore P: 0.0595\n",
      "Episode: 2498 Total reward: 8.0 Training loss: 272.8572 Explore P: 0.0594\n",
      "Episode: 2499 Total reward: 10.0 Training loss: 201.1695 Explore P: 0.0594\n",
      "Episode: 2500 Total reward: 11.0 Training loss: 1936.2197 Explore P: 0.0593\n",
      "Episode: 2501 Total reward: 10.0 Training loss: 432.3683 Explore P: 0.0593\n",
      "Episode: 2502 Total reward: 10.0 Training loss: 1305.8695 Explore P: 0.0592\n",
      "Episode: 2503 Total reward: 10.0 Training loss: 646.0936 Explore P: 0.0592\n",
      "Episode: 2504 Total reward: 9.0 Training loss: 218.6519 Explore P: 0.0591\n",
      "Episode: 2505 Total reward: 11.0 Training loss: 756.9523 Explore P: 0.0591\n",
      "Episode: 2506 Total reward: 10.0 Training loss: 1048.2468 Explore P: 0.0590\n",
      "Episode: 2507 Total reward: 8.0 Training loss: 950.5593 Explore P: 0.0590\n",
      "Episode: 2508 Total reward: 11.0 Training loss: 142.4892 Explore P: 0.0589\n",
      "Episode: 2509 Total reward: 12.0 Training loss: 3431.2246 Explore P: 0.0589\n",
      "Episode: 2510 Total reward: 8.0 Training loss: 437.7711 Explore P: 0.0588\n",
      "Episode: 2511 Total reward: 12.0 Training loss: 824.3571 Explore P: 0.0588\n",
      "Episode: 2512 Total reward: 10.0 Training loss: 769.3724 Explore P: 0.0587\n",
      "Episode: 2513 Total reward: 10.0 Training loss: 1070.0677 Explore P: 0.0587\n",
      "Episode: 2514 Total reward: 12.0 Training loss: 1135.8503 Explore P: 0.0586\n",
      "Episode: 2515 Total reward: 12.0 Training loss: 606.3529 Explore P: 0.0586\n",
      "Episode: 2516 Total reward: 9.0 Training loss: 2808.4890 Explore P: 0.0585\n",
      "Episode: 2517 Total reward: 10.0 Training loss: 667.6031 Explore P: 0.0585\n",
      "Episode: 2518 Total reward: 10.0 Training loss: 1794.6309 Explore P: 0.0584\n",
      "Episode: 2519 Total reward: 8.0 Training loss: 1017.1774 Explore P: 0.0584\n",
      "Episode: 2520 Total reward: 13.0 Training loss: 506.6719 Explore P: 0.0583\n",
      "Episode: 2521 Total reward: 7.0 Training loss: 484.4190 Explore P: 0.0583\n",
      "Episode: 2522 Total reward: 11.0 Training loss: 900.6904 Explore P: 0.0582\n",
      "Episode: 2523 Total reward: 10.0 Training loss: 429.7182 Explore P: 0.0582\n",
      "Episode: 2524 Total reward: 9.0 Training loss: 627.5627 Explore P: 0.0582\n",
      "Episode: 2525 Total reward: 10.0 Training loss: 1465.6349 Explore P: 0.0581\n",
      "Episode: 2526 Total reward: 9.0 Training loss: 483.3741 Explore P: 0.0581\n",
      "Episode: 2527 Total reward: 10.0 Training loss: 247.2101 Explore P: 0.0580\n",
      "Episode: 2528 Total reward: 12.0 Training loss: 3121.3540 Explore P: 0.0580\n",
      "Episode: 2529 Total reward: 9.0 Training loss: 10473.0117 Explore P: 0.0579\n",
      "Episode: 2530 Total reward: 11.0 Training loss: 1224.5796 Explore P: 0.0579\n",
      "Episode: 2531 Total reward: 12.0 Training loss: 2255.3218 Explore P: 0.0578\n",
      "Episode: 2532 Total reward: 11.0 Training loss: 1364.6389 Explore P: 0.0578\n",
      "Episode: 2533 Total reward: 9.0 Training loss: 589.2796 Explore P: 0.0577\n",
      "Episode: 2534 Total reward: 9.0 Training loss: 1237.5886 Explore P: 0.0577\n",
      "Episode: 2535 Total reward: 12.0 Training loss: 2588.8608 Explore P: 0.0576\n",
      "Episode: 2536 Total reward: 9.0 Training loss: 1032.9796 Explore P: 0.0576\n",
      "Episode: 2537 Total reward: 7.0 Training loss: 1758.4352 Explore P: 0.0575\n",
      "Episode: 2538 Total reward: 13.0 Training loss: 431.2719 Explore P: 0.0575\n",
      "Episode: 2539 Total reward: 10.0 Training loss: 1346.3969 Explore P: 0.0574\n",
      "Episode: 2540 Total reward: 10.0 Training loss: 4701.5020 Explore P: 0.0574\n",
      "Episode: 2541 Total reward: 11.0 Training loss: 676.7440 Explore P: 0.0573\n",
      "Episode: 2542 Total reward: 10.0 Training loss: 796.9879 Explore P: 0.0573\n",
      "Episode: 2543 Total reward: 10.0 Training loss: 190.3107 Explore P: 0.0572\n",
      "Episode: 2544 Total reward: 11.0 Training loss: 281.0339 Explore P: 0.0572\n",
      "Episode: 2545 Total reward: 11.0 Training loss: 1308.1608 Explore P: 0.0571\n",
      "Episode: 2546 Total reward: 12.0 Training loss: 1096.7379 Explore P: 0.0571\n",
      "Episode: 2547 Total reward: 11.0 Training loss: 144.4433 Explore P: 0.0570\n",
      "Episode: 2548 Total reward: 10.0 Training loss: 475.7164 Explore P: 0.0570\n",
      "Episode: 2549 Total reward: 8.0 Training loss: 784.2380 Explore P: 0.0569\n",
      "Episode: 2550 Total reward: 10.0 Training loss: 599.8799 Explore P: 0.0569\n",
      "Episode: 2551 Total reward: 9.0 Training loss: 1031.3219 Explore P: 0.0568\n",
      "Episode: 2552 Total reward: 11.0 Training loss: 713.9012 Explore P: 0.0568\n",
      "Episode: 2553 Total reward: 12.0 Training loss: 514.3030 Explore P: 0.0567\n",
      "Episode: 2554 Total reward: 15.0 Training loss: 516.2133 Explore P: 0.0567\n",
      "Episode: 2555 Total reward: 9.0 Training loss: 1906.4519 Explore P: 0.0566\n",
      "Episode: 2556 Total reward: 12.0 Training loss: 2597.6206 Explore P: 0.0566\n",
      "Episode: 2557 Total reward: 8.0 Training loss: 1589.2699 Explore P: 0.0565\n",
      "Episode: 2558 Total reward: 8.0 Training loss: 1018.9076 Explore P: 0.0565\n",
      "Episode: 2559 Total reward: 10.0 Training loss: 660.1407 Explore P: 0.0564\n",
      "Episode: 2560 Total reward: 10.0 Training loss: 713.0887 Explore P: 0.0564\n",
      "Episode: 2561 Total reward: 12.0 Training loss: 1243.8900 Explore P: 0.0563\n",
      "Episode: 2562 Total reward: 9.0 Training loss: 1058.8132 Explore P: 0.0563\n",
      "Episode: 2563 Total reward: 11.0 Training loss: 228.3161 Explore P: 0.0563\n",
      "Episode: 2564 Total reward: 8.0 Training loss: 200.2992 Explore P: 0.0562\n",
      "Episode: 2565 Total reward: 9.0 Training loss: 86.9359 Explore P: 0.0562\n",
      "Episode: 2566 Total reward: 10.0 Training loss: 353.2578 Explore P: 0.0561\n",
      "Episode: 2567 Total reward: 8.0 Training loss: 607.6972 Explore P: 0.0561\n",
      "Episode: 2568 Total reward: 9.0 Training loss: 1171.4034 Explore P: 0.0560\n",
      "Episode: 2569 Total reward: 9.0 Training loss: 1524.7484 Explore P: 0.0560\n",
      "Episode: 2570 Total reward: 11.0 Training loss: 1197.4094 Explore P: 0.0560\n",
      "Episode: 2571 Total reward: 10.0 Training loss: 1497.4629 Explore P: 0.0559\n",
      "Episode: 2572 Total reward: 8.0 Training loss: 572.4173 Explore P: 0.0559\n",
      "Episode: 2573 Total reward: 10.0 Training loss: 6554.0342 Explore P: 0.0558\n",
      "Episode: 2574 Total reward: 7.0 Training loss: 1483.8820 Explore P: 0.0558\n",
      "Episode: 2575 Total reward: 11.0 Training loss: 776.1050 Explore P: 0.0557\n",
      "Episode: 2576 Total reward: 8.0 Training loss: 911.9222 Explore P: 0.0557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2577 Total reward: 12.0 Training loss: 356.8722 Explore P: 0.0557\n",
      "Episode: 2578 Total reward: 9.0 Training loss: 636.2106 Explore P: 0.0556\n",
      "Episode: 2579 Total reward: 10.0 Training loss: 1194.4077 Explore P: 0.0556\n",
      "Episode: 2580 Total reward: 12.0 Training loss: 521.3646 Explore P: 0.0555\n",
      "Episode: 2581 Total reward: 8.0 Training loss: 1468.6067 Explore P: 0.0555\n",
      "Episode: 2582 Total reward: 12.0 Training loss: 1009.8433 Explore P: 0.0554\n",
      "Episode: 2583 Total reward: 10.0 Training loss: 864.5492 Explore P: 0.0554\n",
      "Episode: 2584 Total reward: 11.0 Training loss: 221.1407 Explore P: 0.0553\n",
      "Episode: 2585 Total reward: 12.0 Training loss: 2132.1562 Explore P: 0.0553\n",
      "Episode: 2586 Total reward: 11.0 Training loss: 1569.6802 Explore P: 0.0552\n",
      "Episode: 2587 Total reward: 10.0 Training loss: 2246.5938 Explore P: 0.0552\n",
      "Episode: 2588 Total reward: 7.0 Training loss: 1412.7141 Explore P: 0.0551\n",
      "Episode: 2589 Total reward: 11.0 Training loss: 1057.7423 Explore P: 0.0551\n",
      "Episode: 2590 Total reward: 10.0 Training loss: 608.7699 Explore P: 0.0551\n",
      "Episode: 2591 Total reward: 11.0 Training loss: 1448.3344 Explore P: 0.0550\n",
      "Episode: 2592 Total reward: 8.0 Training loss: 2196.6531 Explore P: 0.0550\n",
      "Episode: 2593 Total reward: 8.0 Training loss: 8888.8320 Explore P: 0.0549\n",
      "Episode: 2594 Total reward: 9.0 Training loss: 799.7939 Explore P: 0.0549\n",
      "Episode: 2595 Total reward: 14.0 Training loss: 718.2601 Explore P: 0.0548\n",
      "Episode: 2596 Total reward: 10.0 Training loss: 627.4756 Explore P: 0.0548\n",
      "Episode: 2597 Total reward: 10.0 Training loss: 676.4506 Explore P: 0.0547\n",
      "Episode: 2598 Total reward: 12.0 Training loss: 1720.0459 Explore P: 0.0547\n",
      "Episode: 2599 Total reward: 9.0 Training loss: 626.3734 Explore P: 0.0546\n",
      "Episode: 2600 Total reward: 10.0 Training loss: 218.5509 Explore P: 0.0546\n",
      "Episode: 2601 Total reward: 10.0 Training loss: 866.0348 Explore P: 0.0546\n",
      "Episode: 2602 Total reward: 9.0 Training loss: 1771.2643 Explore P: 0.0545\n",
      "Episode: 2603 Total reward: 8.0 Training loss: 752.2219 Explore P: 0.0545\n",
      "Episode: 2604 Total reward: 9.0 Training loss: 931.9567 Explore P: 0.0544\n",
      "Episode: 2605 Total reward: 8.0 Training loss: 882.9764 Explore P: 0.0544\n",
      "Episode: 2606 Total reward: 10.0 Training loss: 2635.4019 Explore P: 0.0544\n",
      "Episode: 2607 Total reward: 11.0 Training loss: 564.2863 Explore P: 0.0543\n",
      "Episode: 2608 Total reward: 7.0 Training loss: 114.0769 Explore P: 0.0543\n",
      "Episode: 2609 Total reward: 9.0 Training loss: 326.4843 Explore P: 0.0542\n",
      "Episode: 2610 Total reward: 12.0 Training loss: 676.3562 Explore P: 0.0542\n",
      "Episode: 2611 Total reward: 7.0 Training loss: 759.5043 Explore P: 0.0542\n",
      "Episode: 2612 Total reward: 8.0 Training loss: 493.9070 Explore P: 0.0541\n",
      "Episode: 2613 Total reward: 9.0 Training loss: 4939.5381 Explore P: 0.0541\n",
      "Episode: 2614 Total reward: 11.0 Training loss: 782.3173 Explore P: 0.0540\n",
      "Episode: 2615 Total reward: 10.0 Training loss: 241.9592 Explore P: 0.0540\n",
      "Episode: 2616 Total reward: 9.0 Training loss: 686.0088 Explore P: 0.0539\n",
      "Episode: 2617 Total reward: 9.0 Training loss: 357.1400 Explore P: 0.0539\n",
      "Episode: 2618 Total reward: 8.0 Training loss: 217.8400 Explore P: 0.0539\n",
      "Episode: 2619 Total reward: 9.0 Training loss: 633.6337 Explore P: 0.0538\n",
      "Episode: 2620 Total reward: 11.0 Training loss: 580.4274 Explore P: 0.0538\n",
      "Episode: 2621 Total reward: 7.0 Training loss: 530.6281 Explore P: 0.0538\n",
      "Episode: 2622 Total reward: 10.0 Training loss: 1078.7056 Explore P: 0.0537\n",
      "Episode: 2623 Total reward: 9.0 Training loss: 1146.4545 Explore P: 0.0537\n",
      "Episode: 2624 Total reward: 10.0 Training loss: 1305.4036 Explore P: 0.0536\n",
      "Episode: 2625 Total reward: 8.0 Training loss: 5458.0371 Explore P: 0.0536\n",
      "Episode: 2626 Total reward: 11.0 Training loss: 265.7230 Explore P: 0.0535\n",
      "Episode: 2627 Total reward: 10.0 Training loss: 444.6655 Explore P: 0.0535\n",
      "Episode: 2628 Total reward: 11.0 Training loss: 1010.2228 Explore P: 0.0535\n",
      "Episode: 2629 Total reward: 11.0 Training loss: 522.6714 Explore P: 0.0534\n",
      "Episode: 2630 Total reward: 9.0 Training loss: 909.7585 Explore P: 0.0534\n",
      "Episode: 2631 Total reward: 10.0 Training loss: 587.4771 Explore P: 0.0533\n",
      "Episode: 2632 Total reward: 13.0 Training loss: 2283.5063 Explore P: 0.0533\n",
      "Episode: 2633 Total reward: 13.0 Training loss: 675.9708 Explore P: 0.0532\n",
      "Episode: 2634 Total reward: 11.0 Training loss: 1480.7656 Explore P: 0.0532\n",
      "Episode: 2635 Total reward: 11.0 Training loss: 3328.1145 Explore P: 0.0531\n",
      "Episode: 2636 Total reward: 9.0 Training loss: 565.5548 Explore P: 0.0531\n",
      "Episode: 2637 Total reward: 9.0 Training loss: 724.6050 Explore P: 0.0530\n",
      "Episode: 2638 Total reward: 11.0 Training loss: 505.7905 Explore P: 0.0530\n",
      "Episode: 2639 Total reward: 13.0 Training loss: 963.5848 Explore P: 0.0529\n",
      "Episode: 2640 Total reward: 10.0 Training loss: 326.0153 Explore P: 0.0529\n",
      "Episode: 2641 Total reward: 8.0 Training loss: 536.3633 Explore P: 0.0529\n",
      "Episode: 2642 Total reward: 13.0 Training loss: 457.7834 Explore P: 0.0528\n",
      "Episode: 2643 Total reward: 8.0 Training loss: 226.8778 Explore P: 0.0528\n",
      "Episode: 2644 Total reward: 9.0 Training loss: 1451.4938 Explore P: 0.0527\n",
      "Episode: 2645 Total reward: 10.0 Training loss: 2211.5259 Explore P: 0.0527\n",
      "Episode: 2646 Total reward: 11.0 Training loss: 531.1298 Explore P: 0.0526\n",
      "Episode: 2647 Total reward: 9.0 Training loss: 652.3278 Explore P: 0.0526\n",
      "Episode: 2648 Total reward: 14.0 Training loss: 2072.2910 Explore P: 0.0525\n",
      "Episode: 2649 Total reward: 11.0 Training loss: 1707.9685 Explore P: 0.0525\n",
      "Episode: 2650 Total reward: 8.0 Training loss: 1064.2344 Explore P: 0.0525\n",
      "Episode: 2651 Total reward: 11.0 Training loss: 2768.8335 Explore P: 0.0524\n",
      "Episode: 2652 Total reward: 15.0 Training loss: 716.8275 Explore P: 0.0524\n",
      "Episode: 2653 Total reward: 11.0 Training loss: 605.9352 Explore P: 0.0523\n",
      "Episode: 2654 Total reward: 12.0 Training loss: 567.1116 Explore P: 0.0523\n",
      "Episode: 2655 Total reward: 13.0 Training loss: 244.5130 Explore P: 0.0522\n",
      "Episode: 2656 Total reward: 10.0 Training loss: 504.1702 Explore P: 0.0522\n",
      "Episode: 2657 Total reward: 11.0 Training loss: 1043.1965 Explore P: 0.0521\n",
      "Episode: 2658 Total reward: 10.0 Training loss: 1076.8531 Explore P: 0.0521\n",
      "Episode: 2659 Total reward: 11.0 Training loss: 711.5519 Explore P: 0.0520\n",
      "Episode: 2660 Total reward: 9.0 Training loss: 620.7438 Explore P: 0.0520\n",
      "Episode: 2661 Total reward: 10.0 Training loss: 481.7974 Explore P: 0.0519\n",
      "Episode: 2662 Total reward: 10.0 Training loss: 809.8347 Explore P: 0.0519\n",
      "Episode: 2663 Total reward: 9.0 Training loss: 200.7803 Explore P: 0.0519\n",
      "Episode: 2664 Total reward: 11.0 Training loss: 702.0056 Explore P: 0.0518\n",
      "Episode: 2665 Total reward: 10.0 Training loss: 771.7303 Explore P: 0.0518\n",
      "Episode: 2666 Total reward: 8.0 Training loss: 1020.5353 Explore P: 0.0517\n",
      "Episode: 2667 Total reward: 8.0 Training loss: 1476.0498 Explore P: 0.0517\n",
      "Episode: 2668 Total reward: 10.0 Training loss: 1536.6807 Explore P: 0.0517\n",
      "Episode: 2669 Total reward: 10.0 Training loss: 773.3318 Explore P: 0.0516\n",
      "Episode: 2670 Total reward: 7.0 Training loss: 483.2477 Explore P: 0.0516\n",
      "Episode: 2671 Total reward: 9.0 Training loss: 2410.9224 Explore P: 0.0516\n",
      "Episode: 2672 Total reward: 9.0 Training loss: 1352.2393 Explore P: 0.0515\n",
      "Episode: 2673 Total reward: 11.0 Training loss: 556.6933 Explore P: 0.0515\n",
      "Episode: 2674 Total reward: 11.0 Training loss: 579.0742 Explore P: 0.0514\n",
      "Episode: 2675 Total reward: 8.0 Training loss: 742.0219 Explore P: 0.0514\n",
      "Episode: 2676 Total reward: 12.0 Training loss: 1084.5352 Explore P: 0.0513\n",
      "Episode: 2677 Total reward: 9.0 Training loss: 3088.4167 Explore P: 0.0513\n",
      "Episode: 2678 Total reward: 12.0 Training loss: 902.2521 Explore P: 0.0513\n",
      "Episode: 2679 Total reward: 9.0 Training loss: 1592.3020 Explore P: 0.0512\n",
      "Episode: 2680 Total reward: 11.0 Training loss: 335.6281 Explore P: 0.0512\n",
      "Episode: 2681 Total reward: 9.0 Training loss: 1169.0593 Explore P: 0.0511\n",
      "Episode: 2682 Total reward: 7.0 Training loss: 892.1470 Explore P: 0.0511\n",
      "Episode: 2683 Total reward: 8.0 Training loss: 2339.5903 Explore P: 0.0511\n",
      "Episode: 2684 Total reward: 10.0 Training loss: 679.8832 Explore P: 0.0510\n",
      "Episode: 2685 Total reward: 7.0 Training loss: 303.0649 Explore P: 0.0510\n",
      "Episode: 2686 Total reward: 13.0 Training loss: 968.7051 Explore P: 0.0510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2687 Total reward: 9.0 Training loss: 3105.6384 Explore P: 0.0509\n",
      "Episode: 2688 Total reward: 7.0 Training loss: 1157.7635 Explore P: 0.0509\n",
      "Episode: 2689 Total reward: 10.0 Training loss: 912.4404 Explore P: 0.0508\n",
      "Episode: 2690 Total reward: 11.0 Training loss: 231.6904 Explore P: 0.0508\n",
      "Episode: 2691 Total reward: 8.0 Training loss: 2403.8105 Explore P: 0.0508\n",
      "Episode: 2692 Total reward: 17.0 Training loss: 1191.8741 Explore P: 0.0507\n",
      "Episode: 2693 Total reward: 9.0 Training loss: 418.5536 Explore P: 0.0507\n",
      "Episode: 2694 Total reward: 7.0 Training loss: 569.9280 Explore P: 0.0506\n",
      "Episode: 2695 Total reward: 8.0 Training loss: 493.5771 Explore P: 0.0506\n",
      "Episode: 2696 Total reward: 9.0 Training loss: 1010.0292 Explore P: 0.0506\n",
      "Episode: 2697 Total reward: 8.0 Training loss: 439.8140 Explore P: 0.0505\n",
      "Episode: 2698 Total reward: 11.0 Training loss: 574.7064 Explore P: 0.0505\n",
      "Episode: 2699 Total reward: 11.0 Training loss: 682.4132 Explore P: 0.0504\n",
      "Episode: 2700 Total reward: 9.0 Training loss: 1057.6750 Explore P: 0.0504\n",
      "Episode: 2701 Total reward: 12.0 Training loss: 1884.4518 Explore P: 0.0504\n",
      "Episode: 2702 Total reward: 12.0 Training loss: 5110.0400 Explore P: 0.0503\n",
      "Episode: 2703 Total reward: 9.0 Training loss: 753.8001 Explore P: 0.0503\n",
      "Episode: 2704 Total reward: 10.0 Training loss: 1976.6282 Explore P: 0.0502\n",
      "Episode: 2705 Total reward: 8.0 Training loss: 988.6838 Explore P: 0.0502\n",
      "Episode: 2706 Total reward: 9.0 Training loss: 2205.6924 Explore P: 0.0502\n",
      "Episode: 2707 Total reward: 10.0 Training loss: 475.6335 Explore P: 0.0501\n",
      "Episode: 2708 Total reward: 12.0 Training loss: 341.9081 Explore P: 0.0501\n",
      "Episode: 2709 Total reward: 11.0 Training loss: 1485.6632 Explore P: 0.0500\n",
      "Episode: 2710 Total reward: 10.0 Training loss: 379.6361 Explore P: 0.0500\n",
      "Episode: 2711 Total reward: 12.0 Training loss: 2093.5884 Explore P: 0.0499\n",
      "Episode: 2712 Total reward: 8.0 Training loss: 1684.4675 Explore P: 0.0499\n",
      "Episode: 2713 Total reward: 11.0 Training loss: 1729.5916 Explore P: 0.0499\n",
      "Episode: 2714 Total reward: 11.0 Training loss: 664.8815 Explore P: 0.0498\n",
      "Episode: 2715 Total reward: 10.0 Training loss: 999.2702 Explore P: 0.0498\n",
      "Episode: 2716 Total reward: 11.0 Training loss: 235.8446 Explore P: 0.0497\n",
      "Episode: 2717 Total reward: 10.0 Training loss: 1019.0240 Explore P: 0.0497\n",
      "Episode: 2718 Total reward: 10.0 Training loss: 767.7552 Explore P: 0.0497\n",
      "Episode: 2719 Total reward: 10.0 Training loss: 1795.6168 Explore P: 0.0496\n",
      "Episode: 2720 Total reward: 11.0 Training loss: 826.8271 Explore P: 0.0496\n",
      "Episode: 2721 Total reward: 8.0 Training loss: 842.9385 Explore P: 0.0496\n",
      "Episode: 2722 Total reward: 9.0 Training loss: 475.6724 Explore P: 0.0495\n",
      "Episode: 2723 Total reward: 11.0 Training loss: 961.9523 Explore P: 0.0495\n",
      "Episode: 2724 Total reward: 11.0 Training loss: 567.8794 Explore P: 0.0494\n",
      "Episode: 2725 Total reward: 13.0 Training loss: 1109.0352 Explore P: 0.0494\n",
      "Episode: 2726 Total reward: 9.0 Training loss: 1583.8201 Explore P: 0.0493\n",
      "Episode: 2727 Total reward: 9.0 Training loss: 178.5142 Explore P: 0.0493\n",
      "Episode: 2728 Total reward: 10.0 Training loss: 857.3211 Explore P: 0.0493\n",
      "Episode: 2729 Total reward: 9.0 Training loss: 566.8499 Explore P: 0.0492\n",
      "Episode: 2730 Total reward: 11.0 Training loss: 881.0669 Explore P: 0.0492\n",
      "Episode: 2731 Total reward: 9.0 Training loss: 1995.9633 Explore P: 0.0492\n",
      "Episode: 2732 Total reward: 8.0 Training loss: 258.4650 Explore P: 0.0491\n",
      "Episode: 2733 Total reward: 8.0 Training loss: 1609.8583 Explore P: 0.0491\n",
      "Episode: 2734 Total reward: 9.0 Training loss: 713.6650 Explore P: 0.0491\n",
      "Episode: 2735 Total reward: 10.0 Training loss: 674.8546 Explore P: 0.0490\n",
      "Episode: 2736 Total reward: 8.0 Training loss: 1273.6034 Explore P: 0.0490\n",
      "Episode: 2737 Total reward: 10.0 Training loss: 1974.5322 Explore P: 0.0489\n",
      "Episode: 2738 Total reward: 9.0 Training loss: 1550.4182 Explore P: 0.0489\n",
      "Episode: 2739 Total reward: 11.0 Training loss: 479.1457 Explore P: 0.0489\n",
      "Episode: 2740 Total reward: 9.0 Training loss: 401.2442 Explore P: 0.0488\n",
      "Episode: 2741 Total reward: 12.0 Training loss: 768.2936 Explore P: 0.0488\n",
      "Episode: 2742 Total reward: 10.0 Training loss: 776.5983 Explore P: 0.0487\n",
      "Episode: 2743 Total reward: 9.0 Training loss: 1680.8199 Explore P: 0.0487\n",
      "Episode: 2744 Total reward: 11.0 Training loss: 1006.8500 Explore P: 0.0487\n",
      "Episode: 2745 Total reward: 11.0 Training loss: 317.6888 Explore P: 0.0486\n",
      "Episode: 2746 Total reward: 11.0 Training loss: 664.9380 Explore P: 0.0486\n",
      "Episode: 2747 Total reward: 10.0 Training loss: 1030.8522 Explore P: 0.0485\n",
      "Episode: 2748 Total reward: 11.0 Training loss: 883.6801 Explore P: 0.0485\n",
      "Episode: 2749 Total reward: 9.0 Training loss: 2814.5112 Explore P: 0.0485\n",
      "Episode: 2750 Total reward: 10.0 Training loss: 215.2390 Explore P: 0.0484\n",
      "Episode: 2751 Total reward: 11.0 Training loss: 433.2823 Explore P: 0.0484\n",
      "Episode: 2752 Total reward: 8.0 Training loss: 386.7188 Explore P: 0.0484\n",
      "Episode: 2753 Total reward: 9.0 Training loss: 956.5151 Explore P: 0.0483\n",
      "Episode: 2754 Total reward: 11.0 Training loss: 401.4554 Explore P: 0.0483\n",
      "Episode: 2755 Total reward: 12.0 Training loss: 2864.6992 Explore P: 0.0482\n",
      "Episode: 2756 Total reward: 8.0 Training loss: 1823.2828 Explore P: 0.0482\n",
      "Episode: 2757 Total reward: 9.0 Training loss: 688.0334 Explore P: 0.0482\n",
      "Episode: 2758 Total reward: 9.0 Training loss: 1151.4331 Explore P: 0.0481\n",
      "Episode: 2759 Total reward: 10.0 Training loss: 672.3638 Explore P: 0.0481\n",
      "Episode: 2760 Total reward: 9.0 Training loss: 2032.2722 Explore P: 0.0481\n",
      "Episode: 2761 Total reward: 14.0 Training loss: 1724.1172 Explore P: 0.0480\n",
      "Episode: 2762 Total reward: 7.0 Training loss: 1620.6555 Explore P: 0.0480\n",
      "Episode: 2763 Total reward: 12.0 Training loss: 430.5607 Explore P: 0.0479\n",
      "Episode: 2764 Total reward: 9.0 Training loss: 406.7424 Explore P: 0.0479\n",
      "Episode: 2765 Total reward: 7.0 Training loss: 251.7888 Explore P: 0.0479\n",
      "Episode: 2766 Total reward: 10.0 Training loss: 358.3624 Explore P: 0.0478\n",
      "Episode: 2767 Total reward: 10.0 Training loss: 292.9792 Explore P: 0.0478\n",
      "Episode: 2768 Total reward: 9.0 Training loss: 741.5114 Explore P: 0.0478\n",
      "Episode: 2769 Total reward: 9.0 Training loss: 1624.4736 Explore P: 0.0477\n",
      "Episode: 2770 Total reward: 13.0 Training loss: 1991.4547 Explore P: 0.0477\n",
      "Episode: 2771 Total reward: 12.0 Training loss: 1305.0282 Explore P: 0.0476\n",
      "Episode: 2772 Total reward: 9.0 Training loss: 1664.6189 Explore P: 0.0476\n",
      "Episode: 2773 Total reward: 10.0 Training loss: 8878.1748 Explore P: 0.0476\n",
      "Episode: 2774 Total reward: 11.0 Training loss: 541.4757 Explore P: 0.0475\n",
      "Episode: 2775 Total reward: 9.0 Training loss: 1652.9984 Explore P: 0.0475\n",
      "Episode: 2776 Total reward: 11.0 Training loss: 912.2920 Explore P: 0.0475\n",
      "Episode: 2777 Total reward: 11.0 Training loss: 927.0193 Explore P: 0.0474\n",
      "Episode: 2778 Total reward: 10.0 Training loss: 370.5885 Explore P: 0.0474\n",
      "Episode: 2779 Total reward: 10.0 Training loss: 1023.2184 Explore P: 0.0473\n",
      "Episode: 2780 Total reward: 11.0 Training loss: 7033.3892 Explore P: 0.0473\n",
      "Episode: 2781 Total reward: 9.0 Training loss: 959.8549 Explore P: 0.0473\n",
      "Episode: 2782 Total reward: 9.0 Training loss: 651.6553 Explore P: 0.0472\n",
      "Episode: 2783 Total reward: 13.0 Training loss: 178.5152 Explore P: 0.0472\n",
      "Episode: 2784 Total reward: 8.0 Training loss: 164.7411 Explore P: 0.0472\n",
      "Episode: 2785 Total reward: 11.0 Training loss: 3870.8501 Explore P: 0.0471\n",
      "Episode: 2786 Total reward: 10.0 Training loss: 147.5999 Explore P: 0.0471\n",
      "Episode: 2787 Total reward: 7.0 Training loss: 596.7053 Explore P: 0.0470\n",
      "Episode: 2788 Total reward: 11.0 Training loss: 753.4232 Explore P: 0.0470\n",
      "Episode: 2789 Total reward: 10.0 Training loss: 2104.0845 Explore P: 0.0470\n",
      "Episode: 2790 Total reward: 8.0 Training loss: 947.9406 Explore P: 0.0469\n",
      "Episode: 2791 Total reward: 12.0 Training loss: 1725.8929 Explore P: 0.0469\n",
      "Episode: 2792 Total reward: 9.0 Training loss: 1142.2552 Explore P: 0.0469\n",
      "Episode: 2793 Total reward: 9.0 Training loss: 1085.9028 Explore P: 0.0468\n",
      "Episode: 2794 Total reward: 9.0 Training loss: 2678.1426 Explore P: 0.0468\n",
      "Episode: 2795 Total reward: 8.0 Training loss: 480.1451 Explore P: 0.0468\n",
      "Episode: 2796 Total reward: 9.0 Training loss: 3295.1265 Explore P: 0.0467\n",
      "Episode: 2797 Total reward: 8.0 Training loss: 485.6298 Explore P: 0.0467\n",
      "Episode: 2798 Total reward: 8.0 Training loss: 773.8635 Explore P: 0.0467\n",
      "Episode: 2799 Total reward: 10.0 Training loss: 417.5565 Explore P: 0.0466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2800 Total reward: 8.0 Training loss: 892.8099 Explore P: 0.0466\n",
      "Episode: 2801 Total reward: 10.0 Training loss: 367.9200 Explore P: 0.0466\n",
      "Episode: 2802 Total reward: 12.0 Training loss: 873.4161 Explore P: 0.0465\n",
      "Episode: 2803 Total reward: 13.0 Training loss: 2383.9187 Explore P: 0.0465\n",
      "Episode: 2804 Total reward: 11.0 Training loss: 723.0585 Explore P: 0.0464\n",
      "Episode: 2805 Total reward: 10.0 Training loss: 1129.2628 Explore P: 0.0464\n",
      "Episode: 2806 Total reward: 7.0 Training loss: 263.3214 Explore P: 0.0464\n",
      "Episode: 2807 Total reward: 10.0 Training loss: 607.1155 Explore P: 0.0463\n",
      "Episode: 2808 Total reward: 11.0 Training loss: 2905.0374 Explore P: 0.0463\n",
      "Episode: 2809 Total reward: 7.0 Training loss: 872.5247 Explore P: 0.0463\n",
      "Episode: 2810 Total reward: 10.0 Training loss: 4478.3584 Explore P: 0.0462\n",
      "Episode: 2811 Total reward: 9.0 Training loss: 1634.7291 Explore P: 0.0462\n",
      "Episode: 2812 Total reward: 10.0 Training loss: 1228.5774 Explore P: 0.0462\n",
      "Episode: 2813 Total reward: 8.0 Training loss: 486.9302 Explore P: 0.0461\n",
      "Episode: 2814 Total reward: 11.0 Training loss: 629.4694 Explore P: 0.0461\n",
      "Episode: 2815 Total reward: 8.0 Training loss: 1244.0348 Explore P: 0.0461\n",
      "Episode: 2816 Total reward: 11.0 Training loss: 585.1755 Explore P: 0.0460\n",
      "Episode: 2817 Total reward: 8.0 Training loss: 6706.7993 Explore P: 0.0460\n",
      "Episode: 2818 Total reward: 9.0 Training loss: 1502.6475 Explore P: 0.0460\n",
      "Episode: 2819 Total reward: 11.0 Training loss: 467.6829 Explore P: 0.0459\n",
      "Episode: 2820 Total reward: 10.0 Training loss: 2583.9849 Explore P: 0.0459\n",
      "Episode: 2821 Total reward: 10.0 Training loss: 905.8990 Explore P: 0.0459\n",
      "Episode: 2822 Total reward: 9.0 Training loss: 172.2724 Explore P: 0.0458\n",
      "Episode: 2823 Total reward: 11.0 Training loss: 297.5131 Explore P: 0.0458\n",
      "Episode: 2824 Total reward: 9.0 Training loss: 1183.4725 Explore P: 0.0458\n",
      "Episode: 2825 Total reward: 11.0 Training loss: 408.1351 Explore P: 0.0457\n",
      "Episode: 2826 Total reward: 10.0 Training loss: 162.3018 Explore P: 0.0457\n",
      "Episode: 2827 Total reward: 10.0 Training loss: 1251.6587 Explore P: 0.0456\n",
      "Episode: 2828 Total reward: 11.0 Training loss: 699.0869 Explore P: 0.0456\n",
      "Episode: 2829 Total reward: 12.0 Training loss: 2260.7302 Explore P: 0.0456\n",
      "Episode: 2830 Total reward: 10.0 Training loss: 126.1332 Explore P: 0.0455\n",
      "Episode: 2831 Total reward: 12.0 Training loss: 438.9295 Explore P: 0.0455\n",
      "Episode: 2832 Total reward: 11.0 Training loss: 805.2177 Explore P: 0.0454\n",
      "Episode: 2833 Total reward: 8.0 Training loss: 3296.8438 Explore P: 0.0454\n",
      "Episode: 2834 Total reward: 10.0 Training loss: 1837.4156 Explore P: 0.0454\n",
      "Episode: 2835 Total reward: 10.0 Training loss: 505.7339 Explore P: 0.0454\n",
      "Episode: 2836 Total reward: 9.0 Training loss: 1512.1552 Explore P: 0.0453\n",
      "Episode: 2837 Total reward: 11.0 Training loss: 384.9930 Explore P: 0.0453\n",
      "Episode: 2838 Total reward: 10.0 Training loss: 206.5514 Explore P: 0.0452\n",
      "Episode: 2839 Total reward: 9.0 Training loss: 715.6241 Explore P: 0.0452\n",
      "Episode: 2840 Total reward: 11.0 Training loss: 393.0550 Explore P: 0.0452\n",
      "Episode: 2841 Total reward: 8.0 Training loss: 399.1552 Explore P: 0.0451\n",
      "Episode: 2842 Total reward: 11.0 Training loss: 146.3034 Explore P: 0.0451\n",
      "Episode: 2843 Total reward: 8.0 Training loss: 1384.8623 Explore P: 0.0451\n",
      "Episode: 2844 Total reward: 10.0 Training loss: 616.6058 Explore P: 0.0450\n",
      "Episode: 2845 Total reward: 8.0 Training loss: 1428.2195 Explore P: 0.0450\n",
      "Episode: 2846 Total reward: 9.0 Training loss: 421.5047 Explore P: 0.0450\n",
      "Episode: 2847 Total reward: 8.0 Training loss: 837.5652 Explore P: 0.0450\n",
      "Episode: 2848 Total reward: 9.0 Training loss: 697.4388 Explore P: 0.0449\n",
      "Episode: 2849 Total reward: 11.0 Training loss: 1319.5964 Explore P: 0.0449\n",
      "Episode: 2850 Total reward: 9.0 Training loss: 485.1577 Explore P: 0.0449\n",
      "Episode: 2851 Total reward: 7.0 Training loss: 1339.6310 Explore P: 0.0448\n",
      "Episode: 2852 Total reward: 9.0 Training loss: 1873.5485 Explore P: 0.0448\n",
      "Episode: 2853 Total reward: 9.0 Training loss: 288.2402 Explore P: 0.0448\n",
      "Episode: 2854 Total reward: 9.0 Training loss: 460.9162 Explore P: 0.0447\n",
      "Episode: 2855 Total reward: 7.0 Training loss: 541.0436 Explore P: 0.0447\n",
      "Episode: 2856 Total reward: 9.0 Training loss: 619.6756 Explore P: 0.0447\n",
      "Episode: 2857 Total reward: 7.0 Training loss: 584.7355 Explore P: 0.0447\n",
      "Episode: 2858 Total reward: 9.0 Training loss: 1517.5793 Explore P: 0.0446\n",
      "Episode: 2859 Total reward: 9.0 Training loss: 420.8486 Explore P: 0.0446\n",
      "Episode: 2860 Total reward: 11.0 Training loss: 896.1375 Explore P: 0.0446\n",
      "Episode: 2861 Total reward: 8.0 Training loss: 2447.5444 Explore P: 0.0445\n",
      "Episode: 2862 Total reward: 8.0 Training loss: 1370.0540 Explore P: 0.0445\n",
      "Episode: 2863 Total reward: 11.0 Training loss: 1700.4082 Explore P: 0.0445\n",
      "Episode: 2864 Total reward: 9.0 Training loss: 1619.8274 Explore P: 0.0444\n",
      "Episode: 2865 Total reward: 7.0 Training loss: 430.8917 Explore P: 0.0444\n",
      "Episode: 2866 Total reward: 12.0 Training loss: 3500.7136 Explore P: 0.0444\n",
      "Episode: 2867 Total reward: 11.0 Training loss: 599.3271 Explore P: 0.0443\n",
      "Episode: 2868 Total reward: 9.0 Training loss: 1559.7438 Explore P: 0.0443\n",
      "Episode: 2869 Total reward: 9.0 Training loss: 3132.8630 Explore P: 0.0443\n",
      "Episode: 2870 Total reward: 7.0 Training loss: 193.1315 Explore P: 0.0442\n",
      "Episode: 2871 Total reward: 11.0 Training loss: 2169.2908 Explore P: 0.0442\n",
      "Episode: 2872 Total reward: 8.0 Training loss: 1283.2285 Explore P: 0.0442\n",
      "Episode: 2873 Total reward: 10.0 Training loss: 313.4607 Explore P: 0.0441\n",
      "Episode: 2874 Total reward: 11.0 Training loss: 552.7522 Explore P: 0.0441\n",
      "Episode: 2875 Total reward: 11.0 Training loss: 681.0711 Explore P: 0.0441\n",
      "Episode: 2876 Total reward: 8.0 Training loss: 262.7387 Explore P: 0.0440\n",
      "Episode: 2877 Total reward: 9.0 Training loss: 3686.2856 Explore P: 0.0440\n",
      "Episode: 2878 Total reward: 8.0 Training loss: 1320.4504 Explore P: 0.0440\n",
      "Episode: 2879 Total reward: 11.0 Training loss: 3345.3215 Explore P: 0.0439\n",
      "Episode: 2880 Total reward: 11.0 Training loss: 990.1545 Explore P: 0.0439\n",
      "Episode: 2881 Total reward: 11.0 Training loss: 2130.4629 Explore P: 0.0439\n",
      "Episode: 2882 Total reward: 8.0 Training loss: 144.7671 Explore P: 0.0438\n",
      "Episode: 2883 Total reward: 11.0 Training loss: 305.6051 Explore P: 0.0438\n",
      "Episode: 2884 Total reward: 11.0 Training loss: 860.8373 Explore P: 0.0438\n",
      "Episode: 2885 Total reward: 10.0 Training loss: 135.4799 Explore P: 0.0437\n",
      "Episode: 2886 Total reward: 8.0 Training loss: 695.0374 Explore P: 0.0437\n",
      "Episode: 2887 Total reward: 10.0 Training loss: 599.6617 Explore P: 0.0437\n",
      "Episode: 2888 Total reward: 9.0 Training loss: 1338.0879 Explore P: 0.0436\n",
      "Episode: 2889 Total reward: 10.0 Training loss: 2461.8257 Explore P: 0.0436\n",
      "Episode: 2890 Total reward: 8.0 Training loss: 1258.6833 Explore P: 0.0436\n",
      "Episode: 2891 Total reward: 9.0 Training loss: 2535.8040 Explore P: 0.0436\n",
      "Episode: 2892 Total reward: 10.0 Training loss: 281.8252 Explore P: 0.0435\n",
      "Episode: 2893 Total reward: 9.0 Training loss: 441.4367 Explore P: 0.0435\n",
      "Episode: 2894 Total reward: 9.0 Training loss: 980.3265 Explore P: 0.0435\n",
      "Episode: 2895 Total reward: 8.0 Training loss: 549.7677 Explore P: 0.0434\n",
      "Episode: 2896 Total reward: 9.0 Training loss: 449.5492 Explore P: 0.0434\n",
      "Episode: 2897 Total reward: 13.0 Training loss: 537.3857 Explore P: 0.0434\n",
      "Episode: 2898 Total reward: 13.0 Training loss: 187.7438 Explore P: 0.0433\n",
      "Episode: 2899 Total reward: 8.0 Training loss: 516.8817 Explore P: 0.0433\n",
      "Episode: 2900 Total reward: 13.0 Training loss: 384.4905 Explore P: 0.0432\n",
      "Episode: 2901 Total reward: 10.0 Training loss: 927.1033 Explore P: 0.0432\n",
      "Episode: 2902 Total reward: 11.0 Training loss: 1232.1547 Explore P: 0.0432\n",
      "Episode: 2903 Total reward: 10.0 Training loss: 176.5055 Explore P: 0.0431\n",
      "Episode: 2904 Total reward: 11.0 Training loss: 844.8954 Explore P: 0.0431\n",
      "Episode: 2905 Total reward: 11.0 Training loss: 541.8908 Explore P: 0.0431\n",
      "Episode: 2906 Total reward: 10.0 Training loss: 271.9969 Explore P: 0.0430\n",
      "Episode: 2907 Total reward: 9.0 Training loss: 594.8882 Explore P: 0.0430\n",
      "Episode: 2908 Total reward: 11.0 Training loss: 1813.9010 Explore P: 0.0430\n",
      "Episode: 2909 Total reward: 10.0 Training loss: 2142.0894 Explore P: 0.0429\n",
      "Episode: 2910 Total reward: 7.0 Training loss: 604.6050 Explore P: 0.0429\n",
      "Episode: 2911 Total reward: 9.0 Training loss: 786.5420 Explore P: 0.0429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode: 2912 Total reward: 9.0 Training loss: 1205.4763 Explore P: 0.0429\n",
      "Episode: 2913 Total reward: 8.0 Training loss: 6448.0430 Explore P: 0.0428\n",
      "Episode: 2914 Total reward: 9.0 Training loss: 751.5561 Explore P: 0.0428\n",
      "Episode: 2915 Total reward: 12.0 Training loss: 1028.9854 Explore P: 0.0428\n",
      "Episode: 2916 Total reward: 10.0 Training loss: 184.5245 Explore P: 0.0427\n",
      "Episode: 2917 Total reward: 10.0 Training loss: 382.0249 Explore P: 0.0427\n",
      "Episode: 2918 Total reward: 8.0 Training loss: 511.7106 Explore P: 0.0427\n",
      "Episode: 2919 Total reward: 9.0 Training loss: 610.5814 Explore P: 0.0426\n",
      "Episode: 2920 Total reward: 9.0 Training loss: 1783.7067 Explore P: 0.0426\n",
      "Episode: 2921 Total reward: 12.0 Training loss: 1286.0676 Explore P: 0.0426\n",
      "Episode: 2922 Total reward: 10.0 Training loss: 1012.4710 Explore P: 0.0425\n",
      "Episode: 2923 Total reward: 7.0 Training loss: 587.4177 Explore P: 0.0425\n",
      "Episode: 2924 Total reward: 13.0 Training loss: 544.0016 Explore P: 0.0425\n",
      "Episode: 2925 Total reward: 9.0 Training loss: 2623.4299 Explore P: 0.0424\n",
      "Episode: 2926 Total reward: 9.0 Training loss: 931.2042 Explore P: 0.0424\n",
      "Episode: 2927 Total reward: 11.0 Training loss: 778.7318 Explore P: 0.0424\n",
      "Episode: 2928 Total reward: 7.0 Training loss: 173.2016 Explore P: 0.0424\n",
      "Episode: 2929 Total reward: 13.0 Training loss: 1111.5389 Explore P: 0.0423\n",
      "Episode: 2930 Total reward: 10.0 Training loss: 188.9992 Explore P: 0.0423\n",
      "Episode: 2931 Total reward: 8.0 Training loss: 393.4836 Explore P: 0.0423\n",
      "Episode: 2932 Total reward: 13.0 Training loss: 1038.7820 Explore P: 0.0422\n",
      "Episode: 2933 Total reward: 9.0 Training loss: 1078.8508 Explore P: 0.0422\n",
      "Episode: 2934 Total reward: 9.0 Training loss: 135.2735 Explore P: 0.0422\n",
      "Episode: 2935 Total reward: 9.0 Training loss: 514.6254 Explore P: 0.0421\n",
      "Episode: 2936 Total reward: 12.0 Training loss: 1205.9360 Explore P: 0.0421\n",
      "Episode: 2937 Total reward: 12.0 Training loss: 12408.4092 Explore P: 0.0421\n",
      "Episode: 2938 Total reward: 9.0 Training loss: 1208.7092 Explore P: 0.0420\n",
      "Episode: 2939 Total reward: 9.0 Training loss: 335.6678 Explore P: 0.0420\n",
      "Episode: 2940 Total reward: 12.0 Training loss: 1156.4719 Explore P: 0.0420\n",
      "Episode: 2941 Total reward: 9.0 Training loss: 1220.2549 Explore P: 0.0419\n",
      "Episode: 2942 Total reward: 8.0 Training loss: 976.2671 Explore P: 0.0419\n",
      "Episode: 2943 Total reward: 10.0 Training loss: 442.7577 Explore P: 0.0419\n",
      "Episode: 2944 Total reward: 12.0 Training loss: 691.0105 Explore P: 0.0418\n",
      "Episode: 2945 Total reward: 9.0 Training loss: 599.1040 Explore P: 0.0418\n",
      "Episode: 2946 Total reward: 8.0 Training loss: 2321.7549 Explore P: 0.0418\n",
      "Episode: 2947 Total reward: 9.0 Training loss: 716.1212 Explore P: 0.0418\n",
      "Episode: 2948 Total reward: 11.0 Training loss: 7485.5171 Explore P: 0.0417\n",
      "Episode: 2949 Total reward: 7.0 Training loss: 166.3388 Explore P: 0.0417\n",
      "Episode: 2950 Total reward: 10.0 Training loss: 565.0732 Explore P: 0.0417\n",
      "Episode: 2951 Total reward: 7.0 Training loss: 597.3284 Explore P: 0.0416\n",
      "Episode: 2952 Total reward: 11.0 Training loss: 700.2684 Explore P: 0.0416\n",
      "Episode: 2953 Total reward: 11.0 Training loss: 553.2162 Explore P: 0.0416\n",
      "Episode: 2954 Total reward: 10.0 Training loss: 859.2089 Explore P: 0.0415\n",
      "Episode: 2955 Total reward: 12.0 Training loss: 694.7704 Explore P: 0.0415\n",
      "Episode: 2956 Total reward: 10.0 Training loss: 4832.5376 Explore P: 0.0415\n",
      "Episode: 2957 Total reward: 11.0 Training loss: 1451.7246 Explore P: 0.0414\n",
      "Episode: 2958 Total reward: 11.0 Training loss: 913.7852 Explore P: 0.0414\n",
      "Episode: 2959 Total reward: 9.0 Training loss: 322.6222 Explore P: 0.0414\n",
      "Episode: 2960 Total reward: 9.0 Training loss: 532.9681 Explore P: 0.0413\n",
      "Episode: 2961 Total reward: 11.0 Training loss: 604.7814 Explore P: 0.0413\n",
      "Episode: 2962 Total reward: 8.0 Training loss: 1818.8879 Explore P: 0.0413\n",
      "Episode: 2963 Total reward: 12.0 Training loss: 282.1074 Explore P: 0.0412\n",
      "Episode: 2964 Total reward: 11.0 Training loss: 543.6484 Explore P: 0.0412\n",
      "Episode: 2965 Total reward: 8.0 Training loss: 681.0238 Explore P: 0.0412\n",
      "Episode: 2966 Total reward: 9.0 Training loss: 2029.6537 Explore P: 0.0412\n",
      "Episode: 2967 Total reward: 9.0 Training loss: 1165.8715 Explore P: 0.0411\n",
      "Episode: 2968 Total reward: 12.0 Training loss: 559.1158 Explore P: 0.0411\n",
      "Episode: 2969 Total reward: 10.0 Training loss: 1940.1309 Explore P: 0.0411\n",
      "Episode: 2970 Total reward: 12.0 Training loss: 6408.5991 Explore P: 0.0410\n",
      "Episode: 2971 Total reward: 10.0 Training loss: 392.9230 Explore P: 0.0410\n",
      "Episode: 2972 Total reward: 9.0 Training loss: 468.7591 Explore P: 0.0410\n",
      "Episode: 2973 Total reward: 8.0 Training loss: 846.3384 Explore P: 0.0409\n",
      "Episode: 2974 Total reward: 8.0 Training loss: 356.5769 Explore P: 0.0409\n",
      "Episode: 2975 Total reward: 9.0 Training loss: 672.6796 Explore P: 0.0409\n",
      "Episode: 2976 Total reward: 7.0 Training loss: 3315.5610 Explore P: 0.0409\n",
      "Episode: 2977 Total reward: 8.0 Training loss: 620.4955 Explore P: 0.0408\n",
      "Episode: 2978 Total reward: 11.0 Training loss: 1224.1252 Explore P: 0.0408\n",
      "Episode: 2979 Total reward: 9.0 Training loss: 176.5128 Explore P: 0.0408\n",
      "Episode: 2980 Total reward: 8.0 Training loss: 486.6017 Explore P: 0.0408\n",
      "Episode: 2981 Total reward: 12.0 Training loss: 423.6550 Explore P: 0.0407\n",
      "Episode: 2982 Total reward: 10.0 Training loss: 544.4347 Explore P: 0.0407\n",
      "Episode: 2983 Total reward: 8.0 Training loss: 1318.8220 Explore P: 0.0407\n",
      "Episode: 2984 Total reward: 8.0 Training loss: 3782.9114 Explore P: 0.0406\n",
      "Episode: 2985 Total reward: 10.0 Training loss: 1429.9966 Explore P: 0.0406\n",
      "Episode: 2986 Total reward: 8.0 Training loss: 1757.7708 Explore P: 0.0406\n",
      "Episode: 2987 Total reward: 9.0 Training loss: 347.5978 Explore P: 0.0406\n",
      "Episode: 2988 Total reward: 13.0 Training loss: 96.4140 Explore P: 0.0405\n",
      "Episode: 2989 Total reward: 8.0 Training loss: 597.7860 Explore P: 0.0405\n",
      "Episode: 2990 Total reward: 9.0 Training loss: 1245.5494 Explore P: 0.0405\n",
      "Episode: 2991 Total reward: 13.0 Training loss: 2793.8940 Explore P: 0.0404\n",
      "Episode: 2992 Total reward: 14.0 Training loss: 557.9120 Explore P: 0.0404\n",
      "Episode: 2993 Total reward: 9.0 Training loss: 486.8612 Explore P: 0.0404\n",
      "Episode: 2994 Total reward: 10.0 Training loss: 1422.3563 Explore P: 0.0403\n",
      "Episode: 2995 Total reward: 11.0 Training loss: 1165.7246 Explore P: 0.0403\n",
      "Episode: 2996 Total reward: 12.0 Training loss: 3710.9204 Explore P: 0.0403\n",
      "Episode: 2997 Total reward: 12.0 Training loss: 2135.6919 Explore P: 0.0402\n",
      "Episode: 2998 Total reward: 11.0 Training loss: 1200.4880 Explore P: 0.0402\n",
      "Episode: 2999 Total reward: 10.0 Training loss: 993.2982 Explore P: 0.0402\n"
     ]
    }
   ],
   "source": [
    "# Now train with experiences\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# Total rewards list for plotting\n",
    "rewards_list = []\n",
    "\n",
    "# TF session for training\n",
    "with tf.Session() as sess:\n",
    "    \n",
    "    # Initialize variables\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    step = 0\n",
    "    for ep in range(train_episodes):\n",
    "        total_reward = 0\n",
    "        \n",
    "        t = 0\n",
    "        while t < max_steps:\n",
    "            step += 1\n",
    "            \n",
    "            # Uncomment this next line to watch the training\n",
    "            # env.render() \n",
    "            \n",
    "            # Explore or Exploit\n",
    "            explore_p = explore_stop + (explore_start - explore_stop)*np.exp(-decay_rate*step) \n",
    "            if explore_p > np.random.rand():\n",
    "                # Make a random action\n",
    "                action = env.action_space.sample()\n",
    "            else:\n",
    "                # Get action from Q-network\n",
    "                feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "                Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "                action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "    \n",
    "            # Cumulative reward\n",
    "            total_reward += reward\n",
    "            \n",
    "            if done:\n",
    "                # the episode ends so no next state\n",
    "                next_state = np.zeros(state.shape)\n",
    "                t = max_steps\n",
    "                \n",
    "                print('Episode: {}'.format(ep),\n",
    "                      'Total reward: {}'.format(total_reward),\n",
    "                      'Training loss: {:.4f}'.format(loss),\n",
    "                      'Explore P: {:.4f}'.format(explore_p))\n",
    "                \n",
    "                # total rewards for plotting\n",
    "                rewards_list.append((ep, total_reward))\n",
    "                \n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                \n",
    "                # Start new episode\n",
    "                env.reset()\n",
    "                \n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                # Add experience to memory\n",
    "                memory.add((state, action, reward, next_state))\n",
    "                state = next_state\n",
    "                t += 1\n",
    "            \n",
    "            # Sample mini-batch from memory\n",
    "            batch = memory.sample(batch_size)\n",
    "            states = np.array([each[0] for each in batch])\n",
    "            actions = np.array([each[1] for each in batch])\n",
    "            rewards = np.array([each[2] for each in batch])\n",
    "            next_states = np.array([each[3] for each in batch])\n",
    "            \n",
    "            # Train network\n",
    "            target_Qs = sess.run(mainQN.output, feed_dict={mainQN.inputs_: next_states})\n",
    "\n",
    "            # Set target_Qs to 0 for states where episode ends\n",
    "            episode_ends = (next_states == np.zeros(states[0].shape)).all(axis=1)\n",
    "            target_Qs[episode_ends] = (0, 0)\n",
    "\n",
    "            # Bellman equation\n",
    "            targets = rewards + gamma * np.max(target_Qs, axis=1)\n",
    "\n",
    "            # Updating the model\n",
    "            loss, _ = sess.run([mainQN.loss, mainQN.opt],\n",
    "                                feed_dict={mainQN.inputs_: states,\n",
    "                                           mainQN.targetQs_: targets,\n",
    "                                           mainQN.actions_: actions})\n",
    "    # Save the trained model \n",
    "    saver.save(sess, \"checkpoints/cartpole__.ckpt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing training\n",
    "\n",
    "Below I'll plot the total rewards for each episode. I'm plotting the rolling average too, in blue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def running_mean(x, N):\n",
    "    cumsum = np.cumsum(np.insert(x, 0, 0)) \n",
    "    return (cumsum[N:] - cumsum[:-N]) / N "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0,0.5,'Total Reward')"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "eps, rews = np.array(rewards_list).T\n",
    "smoothed_rews = running_mean(rews, 10)\n",
    "plt.plot(eps[-len(smoothed_rews):], smoothed_rews)\n",
    "plt.plot(eps, rews, color='grey', alpha=0.3)\n",
    "plt.xlabel('Episode')\n",
    "plt.ylabel('Total Reward')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing\n",
    "\n",
    "Let's checkout how our trained agent plays the game."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/cartpole.ckpt\n"
     ]
    }
   ],
   "source": [
    "test_episodes = 10\n",
    "test_max_steps = 400\n",
    "env.reset()\n",
    "with tf.Session() as sess:\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    \n",
    "    for ep in range(1, test_episodes):\n",
    "        t = 0\n",
    "        while t < test_max_steps:\n",
    "            env.render() \n",
    "            \n",
    "            # Get action from Q-network\n",
    "            feed = {mainQN.inputs_: state.reshape((1, *state.shape))}\n",
    "            Qs = sess.run(mainQN.output, feed_dict=feed)\n",
    "            action = np.argmax(Qs)\n",
    "            \n",
    "            # Take action, get new state and reward\n",
    "            next_state, reward, done, _ = env.step(action)\n",
    "            \n",
    "            if done:\n",
    "                t = test_max_steps\n",
    "                env.reset()\n",
    "                # Take one random step to get the pole and cart moving\n",
    "                state, reward, done, _ = env.step(env.action_space.sample())\n",
    "\n",
    "            else:\n",
    "                state = next_state\n",
    "                t += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "env.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extending this\n",
    "\n",
    "So, Cart-Pole is a pretty simple game. However, the same model can be used to train an agent to play something much more complicated like Pong or Space Invaders. Instead of a state like we're using here though, you'd want to use convolutional layers to get the state from the screen images.\n",
    "\n",
    "![Deep Q-Learning Atari](assets/atari-network.png)\n",
    "\n",
    "I'll leave it as a challenge for you to use deep Q-learning to train an agent to play Atari games. Here's the original paper which will get you started: http://www.davidqiu.com:8888/research/nature14236.pdf."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
