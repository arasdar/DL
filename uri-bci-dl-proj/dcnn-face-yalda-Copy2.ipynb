{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18720, 205, 16) float64 (18720, 1) uint8\n",
      "0.833333333333 0.166666666667 0.0 0.0\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "BahramFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/BahramFace.mat')\n",
    "DJFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/DJFace.mat')\n",
    "NickFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/NickFace.mat')\n",
    "RoohiFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/RoohiFace.mat')\n",
    "SarahFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/SarahFace.mat')\n",
    "\n",
    "AllData = np.concatenate((BahramFace['Intensification_Data'],\n",
    "                            DJFace['Intensification_Data'],\n",
    "                            NickFace['Intensification_Data'],\n",
    "                            RoohiFace['Intensification_Data'],\n",
    "                            SarahFace['Intensification_Data']), axis=0)\n",
    "\n",
    "AllLabels = np.concatenate((BahramFace['Intensification_Label'],\n",
    "                            DJFace['Intensification_Label'],\n",
    "                            NickFace['Intensification_Label'],\n",
    "                            RoohiFace['Intensification_Label'],\n",
    "                            SarahFace['Intensification_Label']), axis=0)\n",
    "\n",
    "print(AllData.shape, AllData.dtype, AllLabels.shape, AllLabels.dtype)\n",
    "print(np.mean(AllLabels==0), np.mean(AllLabels==1), np.mean(AllLabels==2), np.mean(AllLabels==3))\n",
    "print((AllLabels +  1).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13104, 205, 16) (5616, 205, 16) (13104, 1) (5616, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "\n",
    "print(X_train_valid.shape, X_test.shape, Y_train_valid.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.834630647131 0.165369352869 0.0\n",
      "0.0 0.830306267806 0.169693732194 0.0\n",
      "(5616, 2) float64\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "X_train_valid_norm, X_test_norm = standardize(test=X_test, train=X_train_valid)\n",
    "\n",
    "# Onehot encoding/vectorizing the output data labels\n",
    "print(np.mean((Y_train_valid+1).reshape(-1)==0), np.mean((Y_train_valid+1).reshape(-1)==1),\n",
    "     np.mean((Y_train_valid+1).reshape(-1)==2), np.mean((Y_train_valid+1).reshape(-1)==3))\n",
    "\n",
    "print(np.mean((Y_test+1).reshape(-1)==0), np.mean((Y_test+1).reshape(-1)==1),\n",
    "     np.mean((Y_test+1).reshape(-1)==2), np.mean((Y_test+1).reshape(-1)==3))\n",
    "\n",
    "# Y_train_valid_onehot = one_hot(labels=(Y_train_valid+1).reshape(-1), n_class=2) \n",
    "# print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "Y_test_onehot = one_hot(labels=(Y_test+1).reshape(-1), n_class=2) \n",
    "print(Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train 30 % valid\n",
    "# get_batches from each train and valid the same\n",
    "# still it will be 70% to 30%\n",
    "# get_batches 83% vs 16%\n",
    "# get_batch 16% vs 16% each time\n",
    "# X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "X_train_norm, X_valid_norm, Y_train, Y_valid = train_test_split(X_train_valid_norm, Y_train_valid, \n",
    "                                                                              test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches2(X_norm, Y_labels):\n",
    "    # Input train or valid\n",
    "    # This is not-applicable to test\n",
    "    X, Y = X_norm, Y_labels #_onehot\n",
    "    AllLabels = Y_labels # 100%\n",
    "\n",
    "    # non = 0 is 87%  AllLabelZero\n",
    "    # tgt = 1 is 13%  AllLabelOne\n",
    "    AllLabelZero = (AllLabels==0).reshape(-1) # 87%\n",
    "    AllLabelOne = (AllLabels==1).reshape(-1) # 13%\n",
    "\n",
    "    X_non, Y_non = X[AllLabelZero], Y[AllLabelZero] # 87%\n",
    "    X_tgt, Y_tgt = X[AllLabelOne], Y[AllLabelOne] # 13%\n",
    "    #     print('X_non.shape, Y_non.shape', X_non.shape, Y_non.shape)\n",
    "    #     print('X_tgt.shape, Y_tgt.shape', X_tgt.shape, Y_tgt.shape)\n",
    "\n",
    "    # Non-target batch size for get_batches from non-target data\n",
    "    batch_size = X_tgt.shape[0] # 13% -> tgt = 1 is 13%  AllLabelOne\n",
    "    assert X_tgt.shape[0] == Y_tgt.shape[0]\n",
    "    #     print(batch_size)\n",
    "\n",
    "    # # 87% - 13% +1: non - tgt + 1\n",
    "    # n_batches = X_non.shape[0] - tgt_batch_size + 1 # stride=1 \n",
    "    # # max overlap for non-tgt 87% - 13% +1\n",
    "\n",
    "    #     # 87% // 13%: non/ tgt\n",
    "    #     # max overlap for non-tgt 87%// 13%\n",
    "    #     num_non_batches = X_non.shape[0]// tgt_batch_size # stride= tgt_batch_size \n",
    "    # #     print(num_non_batches)\n",
    "    #     # # n_batches = len(X) // batch_size # stride=batch_size # min overlap\n",
    "    #     X_non_, Y_non_ = X_non[:num_non_batches*tgt_batch_size], Y_non[:num_non_batches*tgt_batch_size]\n",
    "\n",
    "    n_batches = X_non.shape[0] // batch_size\n",
    "    X_non, Y_non = X_non[:n_batches*batch_size], Y_non[:n_batches*batch_size]\n",
    "    \n",
    "    #     \"\"\" Return a generator for batches \"\"\"\n",
    "    #     n_batches = len(X) // batch_size\n",
    "    #     X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over target batches: start, stop, step\n",
    "    for i in range(0, X_non.shape[0], batch_size):\n",
    "        #         print(i)\n",
    "        # each_train_valid_batch\n",
    "        each_X_norm = np.concatenate((X_non[i:i+batch_size], X_tgt), axis=0)\n",
    "        each_Y = np.concatenate((Y_non[i:i+batch_size], Y_tgt), axis=0)\n",
    "        each_Y_onehot = one_hot(labels=(each_Y+1).reshape(-1), n_class=2)\n",
    "#         np.random.shuffle(each_X_norm)\n",
    "#         np.random.shuffle(each_Y_onehot)\n",
    "        #         print('each_X_norm.shape, each_Y_onehot.shape', each_X_norm.shape, each_Y_onehot.shape)\n",
    "        #         print('each_X_norm.dtype, each_Y_onehot.dtype', each_X_norm.dtype, each_Y_onehot.dtype)\n",
    "        yield each_X_norm, each_Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_batches2 at 0x7f05e8610e08>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batches2(X_norm=X_valid_norm, Y_labels=Y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_batches2 at 0x7f05e8795db0>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batches2(X_norm=X_train_norm, Y_labels=Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len, n_channels 205 16\n",
      "n_classes [2]\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "# Input data\n",
    "# batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "# print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "print('seq_len, n_channels', seq_len, n_channels)\n",
    "\n",
    "# Output labels\n",
    "n_classes = Y_train_valid.max(axis=0)+1\n",
    "assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "print('n_classes', n_classes)\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.0001 #1e-4\n",
    "epochs = 200 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')\n",
    "print('inputs_.shape, labels_.shape', inputs_.shape, labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, conv1.shape, max_pool_1.shape (?, 205, 16) (?, 204, 32) (?, 102, 32)\n",
      "max_pool_1.shape, conv2.shape, max_pool_2.shape (?, 102, 32) (?, 102, 64) (?, 51, 64)\n",
      "max_pool_2.shape, conv3.shape, max_pool_3.shape (?, 51, 64) (?, 50, 128) (?, 25, 128)\n",
      "max_pool_3.shape, conv4.shape, max_pool_4.shape (?, 25, 128) (?, 24, 256) (?, 12, 256)\n",
      "max_pool_4.shape, flat.shape, logits.shape (?, 12, 256) (?, 3072) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n",
    "# (batch, 205, 16) --> (batch, 102, 32)\n",
    "# conv valid: (205-2+0)/1 + 1 = (203/1)+1 = 203 + 1=204\n",
    "# pool same: (204-2+0)/2 + 1 = (202/2)+1 = 101 + 1=102\n",
    "conv1 = tf.layers.conv1d(inputs=inputs_, filters=32, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_1 = tf.nn.dropout(max_pool_1, keep_prob=keep_prob_)\n",
    "print('inputs_.shape, conv1.shape, max_pool_1.shape', inputs_.shape, conv1.shape, max_pool_1.shape)\n",
    "\n",
    "# (batch, 102, 32) --> (batch, 51, 64)\n",
    "# conv same\n",
    "# pool same: (102-2+0)/2 + 1 = (100/2)+1 = 50 + 1=51\n",
    "conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=64, kernel_size=2, strides=1, padding='same', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_2 = tf.nn.dropout(max_pool_2, keep_prob=keep_prob_)\n",
    "print('max_pool_1.shape, conv2.shape, max_pool_2.shape', max_pool_1.shape, conv2.shape, max_pool_2.shape)\n",
    "\n",
    "# (batch, 51, 64) --> (batch, 25, 128)\n",
    "# conv valid: (51-2+0)/1 + 1 = (49/1)+1 = 49 + 1=50\n",
    "# pool same: (50-2+0)/2 + 1 = (48/2)+1 = 24 + 1=25\n",
    "conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=128, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_3 = tf.nn.dropout(max_pool_3, keep_prob=keep_prob_)\n",
    "print('max_pool_2.shape, conv3.shape, max_pool_3.shape', max_pool_2.shape, conv3.shape, max_pool_3.shape)\n",
    "\n",
    "# (batch, 25, 128) --> (batch, 12, 256)\n",
    "# conv valid: (25-2+0)/1 + 1 = (23/1)+1 = 23 + 1=24\n",
    "# pool same: (24-2+0)/2 + 1 = (22/2)+1 = 11 + 1=12\n",
    "conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=256, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_4 = tf.nn.dropout(max_pool_4, keep_prob=keep_prob_)\n",
    "print('max_pool_3.shape, conv4.shape, max_pool_4.shape', max_pool_3.shape, conv4.shape, max_pool_4.shape)\n",
    "\n",
    "# Flatten and add dropout + predicted output\n",
    "flat = tf.reshape(max_pool_4, (-1, 12*256))\n",
    "flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "logits = tf.layers.dense(flat, n_classes)\n",
    "print('max_pool_4.shape, flat.shape, logits.shape', max_pool_4.shape, flat.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_tensor, cost Tensor(\"Reshape_7:0\", shape=(?,), dtype=float32) Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "optimizer name: \"Adam_1\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam_1/update_conv1d_4/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_4/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_5/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_5/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_6/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_6/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_7/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_conv1d_7/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/update_dense_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam_1/update_dense_1/bias/ApplyAdam\"\n",
      "input: \"^Adam_1/Assign\"\n",
      "input: \"^Adam_1/Assign_1\"\n",
      "\n",
      "correct_pred, accuracy Tensor(\"Equal_1:0\", shape=(?,), dtype=bool) Tensor(\"accuracy_1:0\", shape=(), dtype=float32)\n",
      "confusion_matrix Tensor(\"confusion_matrix_1/SparseTensorDenseAdd:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "print('cost_tensor, cost', cost_tensor, cost)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "print('optimizer', optimizer)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "                                       labels=tf.argmax(labels_, 1))\n",
    "print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200 Train loss: 0.695843 Valid loss: 0.689248 Train acc: 0.520430 Valid acc: 0.551657\n",
      "Epoch: 2/200 Train loss: 0.691074 Valid loss: 0.685239 Train acc: 0.539146 Valid acc: 0.581425\n",
      "Epoch: 3/200 Train loss: 0.686019 Valid loss: 0.681397 Train acc: 0.554435 Valid acc: 0.599423\n",
      "Epoch: 4/200 Train loss: 0.680858 Valid loss: 0.677510 Train acc: 0.569926 Valid acc: 0.612233\n",
      "Epoch: 5/200 Train loss: 0.675701 Valid loss: 0.673574 Train acc: 0.585134 Valid acc: 0.623078\n",
      "Epoch: 6/200 Train loss: 0.670502 Valid loss: 0.669469 Train acc: 0.597614 Valid acc: 0.632259\n",
      "Epoch: 7/200 Train loss: 0.664962 Valid loss: 0.665153 Train acc: 0.609649 Valid acc: 0.639596\n",
      "Epoch: 8/200 Train loss: 0.659545 Valid loss: 0.660641 Train acc: 0.620296 Valid acc: 0.646603\n",
      "Epoch: 9/200 Train loss: 0.653934 Valid loss: 0.655896 Train acc: 0.629898 Valid acc: 0.653199\n",
      "Epoch: 10/200 Train loss: 0.647762 Valid loss: 0.650938 Train acc: 0.638327 Valid acc: 0.659168\n",
      "Epoch: 11/200 Train loss: 0.641434 Valid loss: 0.645812 Train acc: 0.646438 Valid acc: 0.664687\n",
      "Epoch: 12/200 Train loss: 0.635101 Valid loss: 0.640576 Train acc: 0.654234 Valid acc: 0.669864\n",
      "Epoch: 13/200 Train loss: 0.628602 Valid loss: 0.635237 Train acc: 0.660985 Valid acc: 0.674722\n",
      "Epoch: 14/200 Train loss: 0.621992 Valid loss: 0.629917 Train acc: 0.667262 Valid acc: 0.679363\n",
      "Epoch: 15/200 Train loss: 0.615397 Valid loss: 0.624687 Train acc: 0.673351 Valid acc: 0.683665\n",
      "Epoch: 16/200 Train loss: 0.608899 Valid loss: 0.619559 Train acc: 0.679104 Valid acc: 0.687698\n",
      "Epoch: 17/200 Train loss: 0.602652 Valid loss: 0.614516 Train acc: 0.684476 Valid acc: 0.691770\n",
      "Epoch: 18/200 Train loss: 0.596359 Valid loss: 0.609682 Train acc: 0.689662 Valid acc: 0.695623\n",
      "Epoch: 19/200 Train loss: 0.590352 Valid loss: 0.604987 Train acc: 0.694369 Valid acc: 0.699419\n",
      "Epoch: 20/200 Train loss: 0.584588 Valid loss: 0.600426 Train acc: 0.698750 Valid acc: 0.703060\n",
      "Epoch: 21/200 Train loss: 0.579084 Valid loss: 0.596058 Train acc: 0.702912 Valid acc: 0.706380\n",
      "Epoch: 22/200 Train loss: 0.573740 Valid loss: 0.591849 Train acc: 0.706867 Valid acc: 0.709434\n",
      "Epoch: 23/200 Train loss: 0.568558 Valid loss: 0.587768 Train acc: 0.710656 Valid acc: 0.712322\n",
      "Epoch: 24/200 Train loss: 0.563574 Valid loss: 0.583832 Train acc: 0.714267 Valid acc: 0.714936\n",
      "Epoch: 25/200 Train loss: 0.558696 Valid loss: 0.580058 Train acc: 0.717769 Valid acc: 0.717362\n",
      "Epoch: 26/200 Train loss: 0.554099 Valid loss: 0.576426 Train acc: 0.720911 Valid acc: 0.719602\n",
      "Epoch: 27/200 Train loss: 0.549645 Valid loss: 0.572931 Train acc: 0.723967 Valid acc: 0.721735\n",
      "Epoch: 28/200 Train loss: 0.545272 Valid loss: 0.569577 Train acc: 0.726975 Valid acc: 0.723794\n",
      "Epoch: 29/200 Train loss: 0.541118 Valid loss: 0.566363 Train acc: 0.729727 Valid acc: 0.725738\n",
      "Epoch: 30/200 Train loss: 0.537104 Valid loss: 0.563296 Train acc: 0.732453 Valid acc: 0.727500\n",
      "Epoch: 31/200 Train loss: 0.533282 Valid loss: 0.560352 Train acc: 0.734937 Valid acc: 0.729190\n",
      "Epoch: 32/200 Train loss: 0.529582 Valid loss: 0.557515 Train acc: 0.737502 Valid acc: 0.730845\n",
      "Epoch: 33/200 Train loss: 0.525985 Valid loss: 0.554794 Train acc: 0.739850 Valid acc: 0.732435\n",
      "Epoch: 34/200 Train loss: 0.522532 Valid loss: 0.552179 Train acc: 0.742111 Valid acc: 0.733956\n",
      "Epoch: 35/200 Train loss: 0.519215 Valid loss: 0.549654 Train acc: 0.744334 Valid acc: 0.735423\n",
      "Epoch: 36/200 Train loss: 0.515951 Valid loss: 0.547246 Train acc: 0.746502 Valid acc: 0.736865\n",
      "Epoch: 37/200 Train loss: 0.512848 Valid loss: 0.544916 Train acc: 0.748518 Valid acc: 0.738252\n",
      "Epoch: 38/200 Train loss: 0.509785 Valid loss: 0.542673 Train acc: 0.750536 Valid acc: 0.739599\n",
      "Epoch: 39/200 Train loss: 0.506880 Valid loss: 0.540534 Train acc: 0.752448 Valid acc: 0.740891\n",
      "Epoch: 40/200 Train loss: 0.504055 Valid loss: 0.538449 Train acc: 0.754244 Valid acc: 0.742174\n",
      "Epoch: 41/200 Train loss: 0.501236 Valid loss: 0.536454 Train acc: 0.756078 Valid acc: 0.743414\n",
      "Epoch: 42/200 Train loss: 0.498511 Valid loss: 0.534538 Train acc: 0.757808 Valid acc: 0.744605\n",
      "Epoch: 43/200 Train loss: 0.495892 Valid loss: 0.532674 Train acc: 0.759469 Valid acc: 0.745750\n",
      "Epoch: 44/200 Train loss: 0.493359 Valid loss: 0.530877 Train acc: 0.761046 Valid acc: 0.746857\n",
      "Epoch: 45/200 Train loss: 0.490866 Valid loss: 0.529137 Train acc: 0.762672 Valid acc: 0.747905\n",
      "Epoch: 46/200 Train loss: 0.488416 Valid loss: 0.527463 Train acc: 0.764214 Valid acc: 0.748933\n",
      "Epoch: 47/200 Train loss: 0.486046 Valid loss: 0.525836 Train acc: 0.765683 Valid acc: 0.749919\n",
      "Epoch: 48/200 Train loss: 0.483702 Valid loss: 0.524256 Train acc: 0.767140 Valid acc: 0.750886\n",
      "Epoch: 49/200 Train loss: 0.481439 Valid loss: 0.522728 Train acc: 0.768517 Valid acc: 0.751827\n",
      "Epoch: 50/200 Train loss: 0.479226 Valid loss: 0.521242 Train acc: 0.769883 Valid acc: 0.752742\n",
      "Epoch: 51/200 Train loss: 0.477068 Valid loss: 0.519834 Train acc: 0.771229 Valid acc: 0.753615\n",
      "Epoch: 52/200 Train loss: 0.474936 Valid loss: 0.518459 Train acc: 0.772548 Valid acc: 0.754458\n",
      "Epoch: 53/200 Train loss: 0.472854 Valid loss: 0.517129 Train acc: 0.773818 Valid acc: 0.755280\n",
      "Epoch: 54/200 Train loss: 0.470875 Valid loss: 0.515852 Train acc: 0.775047 Valid acc: 0.756083\n",
      "Epoch: 55/200 Train loss: 0.468893 Valid loss: 0.514608 Train acc: 0.776266 Valid acc: 0.756857\n",
      "Epoch: 56/200 Train loss: 0.466955 Valid loss: 0.513411 Train acc: 0.777444 Valid acc: 0.757601\n",
      "Epoch: 57/200 Train loss: 0.465057 Valid loss: 0.512254 Train acc: 0.778612 Valid acc: 0.758320\n",
      "Epoch: 58/200 Train loss: 0.463170 Valid loss: 0.511141 Train acc: 0.779756 Valid acc: 0.759026\n",
      "Epoch: 59/200 Train loss: 0.461297 Valid loss: 0.510052 Train acc: 0.780948 Valid acc: 0.759723\n",
      "Epoch: 60/200 Train loss: 0.459525 Valid loss: 0.509006 Train acc: 0.782005 Valid acc: 0.760401\n",
      "Epoch: 61/200 Train loss: 0.457761 Valid loss: 0.507982 Train acc: 0.783070 Valid acc: 0.761067\n",
      "Epoch: 62/200 Train loss: 0.456026 Valid loss: 0.506984 Train acc: 0.784114 Valid acc: 0.761706\n",
      "Epoch: 63/200 Train loss: 0.454282 Valid loss: 0.506028 Train acc: 0.785178 Valid acc: 0.762335\n",
      "Epoch: 64/200 Train loss: 0.452582 Valid loss: 0.505096 Train acc: 0.786205 Valid acc: 0.762930\n",
      "Epoch: 65/200 Train loss: 0.450928 Valid loss: 0.504213 Train acc: 0.787222 Valid acc: 0.763521\n",
      "Epoch: 66/200 Train loss: 0.449270 Valid loss: 0.503347 Train acc: 0.788230 Valid acc: 0.764084\n",
      "Epoch: 67/200 Train loss: 0.447637 Valid loss: 0.502528 Train acc: 0.789215 Valid acc: 0.764643\n",
      "Epoch: 68/200 Train loss: 0.446075 Valid loss: 0.501716 Train acc: 0.790155 Valid acc: 0.765183\n",
      "Epoch: 69/200 Train loss: 0.444500 Valid loss: 0.500935 Train acc: 0.791115 Valid acc: 0.765712\n",
      "Epoch: 70/200 Train loss: 0.442963 Valid loss: 0.500174 Train acc: 0.792018 Valid acc: 0.766237\n",
      "Epoch: 71/200 Train loss: 0.441429 Valid loss: 0.499430 Train acc: 0.792940 Valid acc: 0.766745\n",
      "Epoch: 72/200 Train loss: 0.439889 Valid loss: 0.498720 Train acc: 0.793867 Valid acc: 0.767243\n",
      "Epoch: 73/200 Train loss: 0.438379 Valid loss: 0.498045 Train acc: 0.794772 Valid acc: 0.767730\n",
      "Epoch: 74/200 Train loss: 0.436907 Valid loss: 0.497387 Train acc: 0.795623 Valid acc: 0.768209\n",
      "Epoch: 75/200 Train loss: 0.435436 Valid loss: 0.496745 Train acc: 0.796504 Valid acc: 0.768687\n",
      "Epoch: 76/200 Train loss: 0.434017 Valid loss: 0.496110 Train acc: 0.797344 Valid acc: 0.769161\n",
      "Epoch: 77/200 Train loss: 0.432572 Valid loss: 0.495504 Train acc: 0.798210 Valid acc: 0.769627\n",
      "Epoch: 78/200 Train loss: 0.431194 Valid loss: 0.494917 Train acc: 0.799018 Valid acc: 0.770084\n",
      "Epoch: 79/200 Train loss: 0.429813 Valid loss: 0.494348 Train acc: 0.799823 Valid acc: 0.770522\n",
      "Epoch: 80/200 Train loss: 0.428467 Valid loss: 0.493781 Train acc: 0.800613 Valid acc: 0.770964\n",
      "Epoch: 81/200 Train loss: 0.427106 Valid loss: 0.493230 Train acc: 0.801381 Valid acc: 0.771397\n",
      "Epoch: 82/200 Train loss: 0.425740 Valid loss: 0.492688 Train acc: 0.802190 Valid acc: 0.771837\n",
      "Epoch: 83/200 Train loss: 0.424438 Valid loss: 0.492163 Train acc: 0.802950 Valid acc: 0.772263\n",
      "Epoch: 84/200 Train loss: 0.423125 Valid loss: 0.491649 Train acc: 0.803721 Valid acc: 0.772686\n",
      "Epoch: 85/200 Train loss: 0.421812 Valid loss: 0.491159 Train acc: 0.804503 Valid acc: 0.773097\n",
      "Epoch: 86/200 Train loss: 0.420532 Valid loss: 0.490680 Train acc: 0.805255 Valid acc: 0.773511\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/200 Train loss: 0.419237 Valid loss: 0.490235 Train acc: 0.806024 Valid acc: 0.773902\n",
      "Epoch: 88/200 Train loss: 0.417951 Valid loss: 0.489796 Train acc: 0.806769 Valid acc: 0.774300\n",
      "Epoch: 89/200 Train loss: 0.416699 Valid loss: 0.489366 Train acc: 0.807498 Valid acc: 0.774694\n",
      "Epoch: 90/200 Train loss: 0.415463 Valid loss: 0.488947 Train acc: 0.808227 Valid acc: 0.775079\n",
      "Epoch: 91/200 Train loss: 0.414238 Valid loss: 0.488536 Train acc: 0.808942 Valid acc: 0.775448\n",
      "Epoch: 92/200 Train loss: 0.412993 Valid loss: 0.488147 Train acc: 0.809682 Valid acc: 0.775805\n",
      "Epoch: 93/200 Train loss: 0.411797 Valid loss: 0.487763 Train acc: 0.810396 Valid acc: 0.776166\n",
      "Epoch: 94/200 Train loss: 0.410588 Valid loss: 0.487396 Train acc: 0.811086 Valid acc: 0.776502\n",
      "Epoch: 95/200 Train loss: 0.409412 Valid loss: 0.487033 Train acc: 0.811754 Valid acc: 0.776818\n",
      "Epoch: 96/200 Train loss: 0.408205 Valid loss: 0.486690 Train acc: 0.812464 Valid acc: 0.777129\n",
      "Epoch: 97/200 Train loss: 0.407005 Valid loss: 0.486355 Train acc: 0.813159 Valid acc: 0.777444\n",
      "Epoch: 98/200 Train loss: 0.405829 Valid loss: 0.486034 Train acc: 0.813868 Valid acc: 0.777752\n",
      "Epoch: 99/200 Train loss: 0.404661 Valid loss: 0.485742 Train acc: 0.814552 Valid acc: 0.778052\n",
      "Epoch: 100/200 Train loss: 0.403503 Valid loss: 0.485446 Train acc: 0.815224 Valid acc: 0.778349\n",
      "Epoch: 101/200 Train loss: 0.402348 Valid loss: 0.485153 Train acc: 0.815895 Valid acc: 0.778638\n",
      "Epoch: 102/200 Train loss: 0.401193 Valid loss: 0.484887 Train acc: 0.816555 Valid acc: 0.778914\n",
      "Epoch: 103/200 Train loss: 0.400056 Valid loss: 0.484598 Train acc: 0.817189 Valid acc: 0.779181\n",
      "Epoch: 104/200 Train loss: 0.398911 Valid loss: 0.484336 Train acc: 0.817845 Valid acc: 0.779445\n",
      "Epoch: 105/200 Train loss: 0.397800 Valid loss: 0.484091 Train acc: 0.818494 Valid acc: 0.779707\n",
      "Epoch: 106/200 Train loss: 0.396706 Valid loss: 0.483851 Train acc: 0.819123 Valid acc: 0.779967\n",
      "Epoch: 107/200 Train loss: 0.395560 Valid loss: 0.483628 Train acc: 0.819782 Valid acc: 0.780226\n",
      "Epoch: 108/200 Train loss: 0.394463 Valid loss: 0.483404 Train acc: 0.820403 Valid acc: 0.780471\n",
      "Epoch: 109/200 Train loss: 0.393347 Valid loss: 0.483197 Train acc: 0.821042 Valid acc: 0.780718\n",
      "Epoch: 110/200 Train loss: 0.392260 Valid loss: 0.482993 Train acc: 0.821685 Valid acc: 0.780957\n",
      "Epoch: 111/200 Train loss: 0.391170 Valid loss: 0.482813 Train acc: 0.822277 Valid acc: 0.781199\n",
      "Epoch: 112/200 Train loss: 0.390096 Valid loss: 0.482627 Train acc: 0.822886 Valid acc: 0.781429\n",
      "Epoch: 113/200 Train loss: 0.389017 Valid loss: 0.482456 Train acc: 0.823507 Valid acc: 0.781662\n",
      "Epoch: 114/200 Train loss: 0.387959 Valid loss: 0.482294 Train acc: 0.824104 Valid acc: 0.781889\n",
      "Epoch: 115/200 Train loss: 0.386897 Valid loss: 0.482146 Train acc: 0.824709 Valid acc: 0.782112\n",
      "Epoch: 116/200 Train loss: 0.385839 Valid loss: 0.481994 Train acc: 0.825299 Valid acc: 0.782335\n",
      "Epoch: 117/200 Train loss: 0.384782 Valid loss: 0.481859 Train acc: 0.825923 Valid acc: 0.782543\n",
      "Epoch: 118/200 Train loss: 0.383740 Valid loss: 0.481734 Train acc: 0.826508 Valid acc: 0.782734\n",
      "Epoch: 119/200 Train loss: 0.382684 Valid loss: 0.481603 Train acc: 0.827094 Valid acc: 0.782929\n",
      "Epoch: 120/200 Train loss: 0.381640 Valid loss: 0.481488 Train acc: 0.827673 Valid acc: 0.783107\n",
      "Epoch: 121/200 Train loss: 0.380592 Valid loss: 0.481373 Train acc: 0.828250 Valid acc: 0.783294\n",
      "Epoch: 122/200 Train loss: 0.379558 Valid loss: 0.481265 Train acc: 0.828826 Valid acc: 0.783476\n",
      "Epoch: 123/200 Train loss: 0.378526 Valid loss: 0.481171 Train acc: 0.829432 Valid acc: 0.783639\n",
      "Epoch: 124/200 Train loss: 0.377502 Valid loss: 0.481084 Train acc: 0.830007 Valid acc: 0.783810\n",
      "Epoch: 125/200 Train loss: 0.376489 Valid loss: 0.481020 Train acc: 0.830565 Valid acc: 0.783968\n",
      "Epoch: 126/200 Train loss: 0.375455 Valid loss: 0.480967 Train acc: 0.831154 Valid acc: 0.784140\n",
      "Epoch: 127/200 Train loss: 0.374448 Valid loss: 0.480911 Train acc: 0.831716 Valid acc: 0.784313\n",
      "Epoch: 128/200 Train loss: 0.373437 Valid loss: 0.480854 Train acc: 0.832294 Valid acc: 0.784471\n",
      "Epoch: 129/200 Train loss: 0.372440 Valid loss: 0.480805 Train acc: 0.832872 Valid acc: 0.784623\n",
      "Epoch: 130/200 Train loss: 0.371438 Valid loss: 0.480759 Train acc: 0.833434 Valid acc: 0.784780\n",
      "Epoch: 131/200 Train loss: 0.370447 Valid loss: 0.480737 Train acc: 0.833995 Valid acc: 0.784926\n",
      "Epoch: 132/200 Train loss: 0.369453 Valid loss: 0.480714 Train acc: 0.834570 Valid acc: 0.785065\n",
      "Epoch: 133/200 Train loss: 0.368461 Valid loss: 0.480703 Train acc: 0.835132 Valid acc: 0.785193\n",
      "Epoch: 134/200 Train loss: 0.367482 Valid loss: 0.480691 Train acc: 0.835681 Valid acc: 0.785325\n",
      "Epoch: 135/200 Train loss: 0.366505 Valid loss: 0.480696 Train acc: 0.836236 Valid acc: 0.785442\n",
      "Epoch: 136/200 Train loss: 0.365522 Valid loss: 0.480701 Train acc: 0.836800 Valid acc: 0.785561\n",
      "Epoch: 137/200 Train loss: 0.364554 Valid loss: 0.480687 Train acc: 0.837332 Valid acc: 0.785691\n",
      "Epoch: 138/200 Train loss: 0.363576 Valid loss: 0.480702 Train acc: 0.837874 Valid acc: 0.785814\n",
      "Epoch: 139/200 Train loss: 0.362620 Valid loss: 0.480731 Train acc: 0.838411 Valid acc: 0.785933\n",
      "Epoch: 140/200 Train loss: 0.361661 Valid loss: 0.480754 Train acc: 0.838947 Valid acc: 0.786049\n",
      "Epoch: 141/200 Train loss: 0.360714 Valid loss: 0.480794 Train acc: 0.839470 Valid acc: 0.786157\n",
      "Epoch: 142/200 Train loss: 0.359767 Valid loss: 0.480848 Train acc: 0.839996 Valid acc: 0.786260\n",
      "Epoch: 143/200 Train loss: 0.358832 Valid loss: 0.480897 Train acc: 0.840523 Valid acc: 0.786372\n",
      "Epoch: 144/200 Train loss: 0.357893 Valid loss: 0.480964 Train acc: 0.841027 Valid acc: 0.786481\n",
      "Epoch: 145/200 Train loss: 0.356938 Valid loss: 0.481042 Train acc: 0.841546 Valid acc: 0.786590\n",
      "Epoch: 146/200 Train loss: 0.356007 Valid loss: 0.481117 Train acc: 0.842062 Valid acc: 0.786700\n",
      "Epoch: 147/200 Train loss: 0.355081 Valid loss: 0.481211 Train acc: 0.842582 Valid acc: 0.786804\n",
      "Epoch: 148/200 Train loss: 0.354133 Valid loss: 0.481296 Train acc: 0.843117 Valid acc: 0.786906\n",
      "Epoch: 149/200 Train loss: 0.353210 Valid loss: 0.481425 Train acc: 0.843619 Valid acc: 0.786991\n",
      "Epoch: 150/200 Train loss: 0.352279 Valid loss: 0.481518 Train acc: 0.844127 Valid acc: 0.787093\n",
      "Epoch: 151/200 Train loss: 0.351364 Valid loss: 0.481638 Train acc: 0.844620 Valid acc: 0.787190\n",
      "Epoch: 152/200 Train loss: 0.350437 Valid loss: 0.481766 Train acc: 0.845123 Valid acc: 0.787273\n",
      "Epoch: 153/200 Train loss: 0.349524 Valid loss: 0.481882 Train acc: 0.845616 Valid acc: 0.787350\n",
      "Epoch: 154/200 Train loss: 0.348611 Valid loss: 0.482001 Train acc: 0.846116 Valid acc: 0.787429\n",
      "Epoch: 155/200 Train loss: 0.347693 Valid loss: 0.482125 Train acc: 0.846633 Valid acc: 0.787514\n",
      "Epoch: 156/200 Train loss: 0.346782 Valid loss: 0.482263 Train acc: 0.847148 Valid acc: 0.787597\n",
      "Epoch: 157/200 Train loss: 0.345882 Valid loss: 0.482407 Train acc: 0.847647 Valid acc: 0.787673\n",
      "Epoch: 158/200 Train loss: 0.344978 Valid loss: 0.482549 Train acc: 0.848142 Valid acc: 0.787744\n",
      "Epoch: 159/200 Train loss: 0.344069 Valid loss: 0.482700 Train acc: 0.848629 Valid acc: 0.787813\n",
      "Epoch: 160/200 Train loss: 0.343168 Valid loss: 0.482881 Train acc: 0.849121 Valid acc: 0.787877\n",
      "Epoch: 161/200 Train loss: 0.342270 Valid loss: 0.483056 Train acc: 0.849606 Valid acc: 0.787944\n",
      "Epoch: 162/200 Train loss: 0.341380 Valid loss: 0.483237 Train acc: 0.850091 Valid acc: 0.788007\n",
      "Epoch: 163/200 Train loss: 0.340490 Valid loss: 0.483439 Train acc: 0.850577 Valid acc: 0.788056\n",
      "Epoch: 164/200 Train loss: 0.339589 Valid loss: 0.483627 Train acc: 0.851061 Valid acc: 0.788106\n",
      "Epoch: 165/200 Train loss: 0.338711 Valid loss: 0.483823 Train acc: 0.851546 Valid acc: 0.788152\n",
      "Epoch: 166/200 Train loss: 0.337817 Valid loss: 0.484015 Train acc: 0.852025 Valid acc: 0.788196\n",
      "Epoch: 167/200 Train loss: 0.336947 Valid loss: 0.484224 Train acc: 0.852486 Valid acc: 0.788244\n",
      "Epoch: 168/200 Train loss: 0.336058 Valid loss: 0.484427 Train acc: 0.852965 Valid acc: 0.788294\n",
      "Epoch: 169/200 Train loss: 0.335166 Valid loss: 0.484681 Train acc: 0.853433 Valid acc: 0.788336\n",
      "Epoch: 170/200 Train loss: 0.334287 Valid loss: 0.484927 Train acc: 0.853901 Valid acc: 0.788377\n",
      "Epoch: 171/200 Train loss: 0.333420 Valid loss: 0.485170 Train acc: 0.854359 Valid acc: 0.788410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172/200 Train loss: 0.332562 Valid loss: 0.485398 Train acc: 0.854809 Valid acc: 0.788445\n",
      "Epoch: 173/200 Train loss: 0.331700 Valid loss: 0.485656 Train acc: 0.855257 Valid acc: 0.788475\n",
      "Epoch: 174/200 Train loss: 0.330839 Valid loss: 0.485912 Train acc: 0.855717 Valid acc: 0.788511\n",
      "Epoch: 175/200 Train loss: 0.329981 Valid loss: 0.486152 Train acc: 0.856163 Valid acc: 0.788545\n",
      "Epoch: 176/200 Train loss: 0.329134 Valid loss: 0.486435 Train acc: 0.856618 Valid acc: 0.788577\n",
      "Epoch: 177/200 Train loss: 0.328287 Valid loss: 0.486720 Train acc: 0.857062 Valid acc: 0.788612\n",
      "Epoch: 178/200 Train loss: 0.327435 Valid loss: 0.486978 Train acc: 0.857517 Valid acc: 0.788651\n",
      "Epoch: 179/200 Train loss: 0.326596 Valid loss: 0.487251 Train acc: 0.857953 Valid acc: 0.788685\n",
      "Epoch: 180/200 Train loss: 0.325762 Valid loss: 0.487534 Train acc: 0.858396 Valid acc: 0.788715\n",
      "Epoch: 181/200 Train loss: 0.324928 Valid loss: 0.487804 Train acc: 0.858840 Valid acc: 0.788743\n",
      "Epoch: 182/200 Train loss: 0.324086 Valid loss: 0.488087 Train acc: 0.859286 Valid acc: 0.788772\n",
      "Epoch: 183/200 Train loss: 0.323255 Valid loss: 0.488397 Train acc: 0.859730 Valid acc: 0.788802\n",
      "Epoch: 184/200 Train loss: 0.322425 Valid loss: 0.488702 Train acc: 0.860182 Valid acc: 0.788828\n",
      "Epoch: 185/200 Train loss: 0.321606 Valid loss: 0.488975 Train acc: 0.860621 Valid acc: 0.788859\n",
      "Epoch: 186/200 Train loss: 0.320793 Valid loss: 0.489298 Train acc: 0.861044 Valid acc: 0.788884\n",
      "Epoch: 187/200 Train loss: 0.319978 Valid loss: 0.489581 Train acc: 0.861484 Valid acc: 0.788906\n",
      "Epoch: 188/200 Train loss: 0.319159 Valid loss: 0.489884 Train acc: 0.861917 Valid acc: 0.788931\n",
      "Epoch: 189/200 Train loss: 0.318354 Valid loss: 0.490220 Train acc: 0.862342 Valid acc: 0.788951\n",
      "Epoch: 190/200 Train loss: 0.317555 Valid loss: 0.490523 Train acc: 0.862769 Valid acc: 0.788978\n",
      "Epoch: 191/200 Train loss: 0.316762 Valid loss: 0.490854 Train acc: 0.863192 Valid acc: 0.788991\n",
      "Epoch: 192/200 Train loss: 0.315960 Valid loss: 0.491206 Train acc: 0.863613 Valid acc: 0.789000\n",
      "Epoch: 193/200 Train loss: 0.315172 Valid loss: 0.491499 Train acc: 0.864023 Valid acc: 0.789015\n",
      "Epoch: 194/200 Train loss: 0.314359 Valid loss: 0.491819 Train acc: 0.864451 Valid acc: 0.789027\n",
      "Epoch: 195/200 Train loss: 0.313559 Valid loss: 0.492170 Train acc: 0.864873 Valid acc: 0.789043\n",
      "Epoch: 196/200 Train loss: 0.312764 Valid loss: 0.492526 Train acc: 0.865283 Valid acc: 0.789059\n",
      "Epoch: 197/200 Train loss: 0.311981 Valid loss: 0.492854 Train acc: 0.865685 Valid acc: 0.789072\n",
      "Epoch: 198/200 Train loss: 0.311187 Valid loss: 0.493215 Train acc: 0.866103 Valid acc: 0.789081\n",
      "Epoch: 199/200 Train loss: 0.310398 Valid loss: 0.493588 Train acc: 0.866519 Valid acc: 0.789088\n",
      "Epoch: 200/200 Train loss: 0.309597 Valid loss: 0.493951 Train acc: 0.866936 Valid acc: 0.789099\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        #         for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "        for x, y in get_batches2(X_norm=X_train_norm, Y_labels=Y_train):\n",
    "            \n",
    "            ######################## Training\n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : keep_prob, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################## Validation\n",
    "            acc_batch = []\n",
    "            loss_batch = []    \n",
    "            # Loop over batches\n",
    "            #             for x, y in get_batches(X_valid_norm, Y_valid_onehot, batch_size):\n",
    "            for x, y in get_batches2(X_norm=X_valid_norm, Y_labels=Y_valid):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "                # Loss\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                acc_batch.append(acc)\n",
    "                loss_batch.append(loss)\n",
    "\n",
    "            # Store\n",
    "            valid_acc.append(np.mean(acc_batch))\n",
    "            valid_loss.append(np.mean(loss_batch))\n",
    "            \n",
    "        # Print info for every iter/epoch\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "              \"Train loss: {:6f}\".format(np.mean(train_loss)),\n",
    "              \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "              \"Train acc: {:6f}\".format(np.mean(train_acc)),\n",
    "              \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "                \n",
    "    saver.save(sess,\"checkpoints/dcnn-face-yalda-Copy2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd4VFX6wPHvyaSTThJagIQiHQKE\nEpqCSBEEURFQsYAiIiq6uy5WWHXVRVcsP7sIdtBFEEFEEZEiAgFC76GFGgIJNf38/jiTRtokTDLJ\n5P08zzyZe+fcO+/NwJsz556itNYIIYRwLi6ODkAIIYT9SXIXQggnJMldCCGckCR3IYRwQpLchRDC\nCUlyF0IIJyTJXQghnJAkdyGEcEKS3IUQwgm5OuqNg4ODdXh4uKPeXgghqqQNGzac1lqHlFTOYck9\nPDycmJgYR729EEJUSUqpQ7aUk2YZIYRwQpLchRDCCUlyF0IIJ+SwNnchRMVIT08nPj6elJQUR4ci\nSsHT05OwsDDc3NzKdLwkdyGcXHx8PL6+voSHh6OUcnQ4wgZaaxITE4mPjyciIqJM57CpWUYpNUAp\ntVsptU8pNbmQ16crpWKtjz1KqaQyRSOEsLuUlBRq1qwpib0KUUpRs2bNq/q2VWLNXSllAd4FbgDi\ngfVKqQVa6x3ZZbTWj+cp/wjQvswRCSHsThJ71XO1n5ktNffOwD6tdZzWOg2YDQwtpvwo4JuriqoY\n6w+e4dXFu5DlAYUQomi2JPd6wJE82/HWfQUopRoCEcCyIl4fp5SKUUrFJCQklDZWALbGJ/PBH/u5\n4+O1ZTpeCCGqA1uSe2HfDYqqNo8E/qe1zizsRa31R1rrKK11VEhIiaNnC1U3wAuANXGJZTpeCFHx\nLBYLkZGROY+DBw+Wy/ssX76cP//8s9THxcTE8Oijj5bpPX18fMp0XHmzpbdMPFA/z3YYcKyIsiOB\nh682qOK0ubCaT93e5v70v7NmfyLRjWuW59sJIezAy8uL2NjYcn+f5cuX4+PjQ7du3Qq8lpGRgatr\n4SkvKiqKqKio8g6vQtmS3NcDTZVSEcBRTAK/48pCSqlmQCCwxq4RXqGer4V6lliGZa5i1McufDc+\nmk7hQeX5lkI4jX/9uJ0dx87Z9Zwt6/ox5aZWpT7u4MGDjB49mosXLwLwf//3fzlJedq0aXzxxRe4\nuLgwcOBAXn31Vfbv38/DDz9MQkIC3t7efPzxxzRv3jzf+T744AMsFgtffvkl77zzDjNmzCAoKIhN\nmzbRoUMHRowYwaRJk7h8+TJeXl7MnDmTZs2asXz5cl5//XUWLlzI1KlTOXz4MHFxcRw+fJhJkybZ\nVKvXWvPkk0+yePFilFI8++yzjBgxguPHjzNixAjOnTtHRkYG77//Pt26dWPs2LHExMSglGLMmDE8\n/vjjJb5HaZSY3LXWGUqpicASwAJ8qrXerpR6AYjRWi+wFh0FzNblfaez5VDSa7Xj8RP/48fUaOLP\nXpLkLkQld/nyZSIjIwGIiIhg3rx5hIaG8uuvv+Lp6cnevXsZNWoUMTExLF68mPnz57N27Vq8vb05\nc+YMAOPGjeODDz6gadOmrF27lgkTJrBsWe7tvfDwcMaPH4+Pjw9///vfAZgxYwZ79uxh6dKlWCwW\nzp07x4oVK3B1dWXp0qU8/fTTzJ07t0C8u3bt4vfff+f8+fM0a9aMhx56qMTBRN9//z2xsbFs3ryZ\n06dP06lTJ3r16sXXX39N//79eeaZZ8jMzOTSpUvExsZy9OhRtm3bBkBSkv17j9s0iElr/RPw0xX7\nnr9ie6r9wiqGUrjdMIWwL29hlGUZj89xY1j7sAp5ayGqurLUsO2hsGaZ9PR0Jk6cSGxsLBaLhT17\n9gCwdOlS7rvvPry9vQEICgriwoUL/PnnnwwfPjzn+NTUVJvee/jw4VgsFgCSk5O555572Lt3L0op\n0tPTCz1m0KBBeHh44OHhQWhoKCdPniQsrPg8s2rVKkaNGoXFYqFWrVpce+21rF+/nk6dOjFmzBjS\n09O5+eabiYyMpFGjRsTFxfHII48waNAg+vXrZ9O1lEbVnFumcR+2ubdlous8vJEh1UJURdOnT6dW\nrVps3ryZmJgY0tLSANO8cWUf76ysLAICAoiNjc157Ny506b3qVGjRs7z5557jt69e7Nt2zZ+/PHH\nIgcJeXh45Dy3WCxkZGSU+D5FNVr06tWLFStWUK9ePUaPHs3nn39OYGAgmzdv5rrrruPdd9/l/vvv\nt+laSqNqJnelaHHXfwlR5xhr+YmZqw84OiIhRCklJydTp04dXFxc+OKLL8jMNJ3s+vXrx6effsql\nS5cAOHPmDH5+fkRERPDdd98BJpFu3ry5wDl9fX05f/58se9Zr57pyT1r1iy7Xk+vXr2YM2cOmZmZ\nJCQksGLFCjp37syhQ4cIDQ3lgQceYOzYsWzcuJHTp0+TlZXFrbfeyosvvsjGjRvtGgtU1eQOWBp0\nZmONnjzoupB3f1xDZpYMahKiKpkwYQKfffYZXbt2Zc+ePTk17AEDBjBkyBCioqKIjIzk9ddfB+Cr\nr75ixowZtGvXjlatWvHDDz8UOOdNN93EvHnziIyMZOXKlQVef/LJJ3nqqafo3r17zh8Texk2bBht\n27alXbt29OnTh2nTplG7dm2WL19OZGQk7du3Z+7cuTz22GMcPXqU6667jsjISO69915eeeUVu8YC\noBw10jMqKkpf7UpM0+f8xMQddzEn8zpch7zJyM4N7BSdEM5j586dtGjRwtFhiDIo7LNTSm3QWpfY\nb7PK1twBxt3cj821b2Wk5Xc+mbeYv2RgkxBCAFU8udfwcCXyrpe5hAeTXb/hz32nHR2SEMIJJSYm\n5hthm/1ITKy8FcoqP5+7q28I72UMZbLbbI6eXgs0c3RIQggnU7NmzQoZYWtPVbrmnm1t6HCO6SB6\nHHoPZLZIIYRwjuT+zYTeLA68i8apOzm/bbGjwxFCCIdziuTu6Wah6y2PciQrhMSFU6X2LoSo9pwi\nuQO0ahDC25nDCE/dzcVtCx0djhBCOJTTJHeAGp3u5GBWLVyWvyK1dyEqkYqaz720Zs2axcSJEwH4\n4IMP+PzzzwuUOXjwIK1bty7yHMuXL2fw4MHlFmNZVfneMnnd3rkR760fwrTEj0ne+Rv+Lfs6OiQh\nBBU3n/vVGD9+vKNDsCunSu5Na/nwQ2Z3/uk6m43fvMwNL0pyFyKfxZPhxFb7nrN2Gxj4aqkPs/d8\n7llZWTRq1IjY2FgCAgIAaNKkCatXr2bdunW89NJLpKWlUbNmTb766itq1aqVL56pU6fmTBe8YcMG\nxowZg7e3Nz169LD5ms6cOcOYMWOIi4vD29ubjz76iLZt2/LHH3/w2GOPAWbh6xUrVnDhwoUC87z3\n7Nmz1L/HojhVs4ybxYVU3Pk683qud9kIZ+IcHZIQgtz53CMjIxk2bBhAznzuGzduZM6cOTkLYuSd\nz33z5s08+eSTgJnP/Z133mHDhg28/vrrTJgwId97uLi4MHToUObNmwfA2rVrCQ8Pp1atWvTo0YO/\n/vqLTZs2MXLkSKZNm1ZsvPfddx9vv/02a9aUbu2hKVOm0L59e7Zs2cLLL7/M3XffDcDrr7/Ou+++\nS2xsLCtXrsTLyytnnvfsOeCz57u3F6equQN8/UAXJn18lvGWH8n88wPcBhf/IQpRrZShhm0PFTWf\n+4gRI3jhhRe47777mD17NiNGjAAgPj4+Z1WktLQ0IiIiiow1OTmZpKQkrr32WgBGjx7N4sW2dbFe\ntWpVzuIfffr0ITExkeTkZLp3784TTzzBnXfeyS233EJYWFih87zbk1PV3AG6NQ7mzr5dWJTVBZfN\nX0GKfZcUE0LYR3nM5x4dHc2+fftISEhg/vz53HLLLQA88sgjTJw4ka1bt/Lhhx8WOY97Ue9vq8Im\nYlRKMXnyZD755BMuX75M165d2bVrV6HzvNuT0yV3gMHt6jAzYwCW9AsQ+7WjwxFCFKI85nNXSjFs\n2DCeeOIJWrRoQc2aNXPeK3se988++6zYuAICAvD392fVqlWAmWrYVr169copv3z5coKDg/Hz82P/\n/v20adOGf/7zn0RFRbFr165C53m3J6dM7o2Ca3A2sC173Jqj130IWVmODkkIcYXymM8dTNPMl19+\nmdMkA+Zm6fDhw+nZsyfBwcElxjZz5kwefvhhoqOj8fLysvmapk6dSkxMDG3btmXy5Mk5f0jefPNN\nWrduTbt27fDy8mLgwIGFzvNuT1V6PvfivPPbXvb99ilvub8Hdy+ARteW23sJUZnJfO5VV7Wdz704\nvZuH8nNWZy6qGrDpS0eHI4QQFcppk3uLOn6k4s736dHoHQvgcpKjQxJCVGFLliwpMJ97drfOysjp\nukJms7gonhvckjmLrmN05lLY9j/oZP8VxoWoCq6mB4gw+vfvT//+/Svs/a62ydxpa+4AY7qH41qv\nPQcsEdI0I6otT09PEhMTrzpZiIqjtSYxMRFPT88yn8Npa+5gukW1bxjI16eu5Zljs+DkdqjVytFh\nCVGhwsLCiI+PJyEhwdGhiFLw9PQkLCyszMc7dXIHaFHbj1fSuvIPjy+I+/lDmt/ztqNDEqJCubm5\nFTsiUzgnm5pllFIDlFK7lVL7lFKTiyhzu1Jqh1Jqu1Kq0owcal7Hl7P4sSyrAyEHfoDMDEeHJIQQ\n5a7E5K6UsgDvAgOBlsAopVTLK8o0BZ4CumutWwGTyiHWMmka6gvA3Mye1CQJ9v/m4IiEEKL82VJz\n7wzs01rHaa3TgNnA0CvKPAC8q7U+C6C1PmXfMMvOy91CRHANfs+KJEn5Q6ztQ4mFEKKqsiW51wOO\n5NmOt+7L6xrgGqXUaqXUX0qpAfYK0B6WTOpFBq7EBvSF3Yvh0hlHhySEEOXKluReWOfYK/tUuQJN\ngeuAUcAnSqmAAidSapxSKkYpFVORd+7dXV1oXc+P3z1vgMw02Da3wt5bCCEcwZbkHg/Uz7MdBhwr\npMwPWut0rfUBYDcm2eejtf5Iax2ltY4KCQkpa8xlEujtzmcH/MgMaQWbv6nQ9xZCiIpmS3JfDzRV\nSkUopdyBkcCCK8rMB3oDKKWCMc00lWoZpBtamiW1NgUNgKMbIGG3gyMSQojyU2Jy11pnABOBJcBO\n4Fut9Xal1AtKqSHWYkuARKXUDuB34B9a68TyCrosRndtSA13Cz+pnqAsMs+7EMKpOe2Uv4WZ8NUG\nft+VwI7mn6JObIHHt4OLpUJjEEKIq1Htp/wtTPcmwVxOz2Rn7Zvg/HGI+93RIQkhqpuDqyHtYrm/\nTbVK7g2CzIK7N//qi/YMkKYZIUTFSj4Ks26EDcUv9WcP1Sq5tw0zvTPTcONSs2Gwa5HM8y6EKD+J\n++HbuyH1gtk+8pf52TC63N+6WiV3fy83RnVuAMD+ukMgIwW2z3NwVEIIp5SVBX++Azt+gHUfwg8P\nw3Hrot5Bjcv97atVcgcY16sRAD8m1IKQ5tLnXQhRdlmZpmv1lR1TDq2BFwIh2Tq4f8Mss6bE6rdM\nbz0P33IPrdol9zr+ZvL7j1cd5Hyz4XBkLZze5+CohBBV0sLH4eM+cGJL/v0xM8zPuD/Mz4t5eoZ7\nBUIFrIpV7ZK7p1tu18dn4lqCcpHauxCibPb8bH5unw+fD4XU87Dte1OjB8hKNz/T8/SO8QqskNCc\nfrGOwrSrH8DmI0nsvewLjfvA5tnQ+xlwqXZ/64QQZXExEbIycm+UrnrD/PxiGMSvB1evoo+toORe\nLbPZlJvMdPQ7j58jq90dcC4eDvzh4KiEEFXGa43grbb5a+RgEjtAxuWij5XkXn46NAikTT1/ALbU\n6AZeQbD2AwdHJYSoErK7T2eklO14Se7la/y1pivSzR9tRHcZb9rOTmxzcFRCiEoju908W0YqLHgU\nVv736s7r6X91x9uoWra5AwT7uOc8P93qHkL+fBtWTYfbZjgwKiFEpZCeAtNbQcd7IKQFBDWCOXea\naUvKysMPUs+Bxc1+cRaj2tbcI0Jq5Dw/eNEdou6D7d/DmUo1U7EQwl6ysuDI+oL7T++D96Lh9F6I\nj4EfJsKxjXDptKmlf38/fNKn7Im91TBw9YSAhmbbp1bZr6EUqm1yD/X1zLmxmnA+FaIngourGWQg\nhKj6LidBSnLu9pp3YEZfOPRn/nIrXoNTO+C7+2DOaNj0Baz9sPBzNuhW8vte9xQMeQfG/QFhnWHA\nq/DMCRj5FTTpC+3vKvs1lUK1Te4Ag9vWBeD0hVTwrQ2Rd5rJxM5dxVcvIUTl8Mn18N/mZs3kXYtg\n769m/7ljphYPcPYQZKaa5ye3wnnrInP7lxU8n3KBrg/lPi9KYAR0uBvqRsL9v5rcohQENoS75oJ3\nkH2urwTVOrkH1XDHRcFfcYmkZmRC98fMTZQ/33Z0aEKIsto218y6mLgP0i/BZ0Ng9h2QdMi8vvcX\nMzXA5tmmO2Nh80ulniu47/rnodG10O4OuP+3gq9bPMxPv7r2u5arUG1vqAJYXBThwTX4aesJarhv\n47Xh7aDt7RAzE3o8AT4Vu86rEKKUsrIgbhk0vt7UjrWG/43JX+bkVvMz6bD5uWWO+bngkYLna9of\nDq40fxQ8/XObdf6xH2oEm+fD3jc/3X0g7YJpS086BLd+ApfPQHgP+15jGVXrmjtALV8z18yPW6xf\nx3r+zfRfXfOOA6MSQthkyxz48lbTTr5jAewvpEZdlMy03Oc9noDnTsOd30KrW8y+Rr1zX89O7HmN\nWQL3/Gge1z8PzQdDx3srZN4YW1TrmjvAiE71WROXiLvF+ncuuCm0vgXWfQLdJ1VY+5gQohRSzsH8\nh8Dd2utty7emxl1Wja7L7aLYsBvEfgl120PXCbnvcaXarXOf9/xb2d+7nFT75H5z+3rEHDrDdzHx\nZGZpLC4Kev3DTAT009/h1hmV5i+xENVeZjrMHQsXEuBwnl4vR9aW7jyhLU0PmWaD4MbXwL9e7mvt\nRpnuio17V+k1lqt9swxA89p+pGZk0fjpn0jLyILQFtD7KXNjZtOXjg5PCJFt/+9m8YvDV3RnzNvE\nUixrRa3Lg6biNvDV/IkdzASCTftW6cQOktwBCPX1yHm+8fBZ86THExDeExY/mXsjRgjhWNnL1JVW\niyHm5/CZ0GW8qZ23uQ0CGtgvtkpGkjsQnCe5Hz5zyTxxscDN75uukX9Mc1BkQggAzh6En/4BB0rZ\nrt7hbvCrB8M+gEc2mtGiA/8Drh4lH1vFVfs2d4DGwT45z08m55npLaA+RI2BdR+Zn/U6OCA6IZxc\nZgbs+hF865i+5/3/DRcTIO2SaRqtGwlz8ozqzO56eKXgZnB6t3nefDCkXzYjRbOyTFNLzfJft7Qy\nkeQO+Hu7cfDVQbSZsoT//rqHGh6ujOkRYV687p+mjW/eg/DgCnArZhJ+IUTprfwvLH85d9viZipU\nRWk5xCw8DeBbF/pOMf8/63UA/zDT86X7o7nrmlbTRXgkuedxPjUDgBcW7shN7l6BcPN78MXNsHSq\n+UonhLh6p/eZxHtmf/79hSX2ZjdC7bbwx6vQdgTUCDEDjkKbm9d9apmui14BucdU815uktwL4eNx\nxa+lcW9zE2btB9D0BjP5jxCibI5vMSM5vxpedC8XF1fTPu4VCBZ36PeSuf/V4W7Tu6V2m/zlG/cu\n/DzVmE3fV5RSA5RSu5VS+5RSkwt5/V6lVIJSKtb6uN/+oZa/7k1qAnAhNYPpv+5BZ3+tA+g71fSN\n/W4MJOx2SHxCVGln4kwT5/cPmMWkC0vsN70NbW6Hoe+a4fw3vmba4JUCi2vBbouiSCpfAiusgFIW\nYA9wAxAPrAdGaa135ClzLxCltZ5o6xtHRUXpmJiYssRcblLSM3nj1z18tMLM6T73oWg6NswzQjXp\nMHzcB9y84YHfoUZNB0UqhINdTDSjODs9AO7ehZe5dCZ3WgDvmqYbY94peAEe22wqS16B8ONjZtbE\nSjLxVmWllNqgtY4qqZwtzTKdgX1a6zjriWcDQ4EdxR5VBXm6WWhZxy9ne9XexPzJPaABjJoNMwfC\nNyPh7vlFD00WwpltnAW/vWBuWvaYBFu+g42fQb2OZuKs45th2Yslnycw3DwAJqwpx4CrH1uSez3g\nSJ7teKBLIeVuVUr1wtTyH9daHymkTKVX298z53nc6QsFC4RFma+L394DP082Xa2EqC4OrDDzol9M\nMNsJu2Hr/8xqRWDmd1n9ZsHjrnvKLIhzJs50b/SrZ+ZxEuXGluRe2C3nK9tyfgS+0VqnKqXGA58B\nfQqcSKlxwDiABg0q58iwYJ/cwQ2X0jILL9RyqKmtrJoODbtDu5EVFJ0QDqK1GUj02U1m29vaJLn5\na/NQLnDDC/DLs/mP8/CHh1abMSMAddqahyh3trS5RwNTtdb9rdtPAWitXymivAU4o7Uudonvytjm\nDpCVpfnPkl18uuoA6Zma6SPaMax9WMGCmenwxTCzZNdtn0Krmys+WCHKy+q3IfkIBDUGV3czoOiX\nZ4ou/+BKk7SzsswAI/ca4B1sbpq6eRZ9nCg1e7a5rweaKqUigKPASOCOK96sjtY6e226IcDOUsZb\nabi4KJ4a2IIP/zA3Vf+9aCfXXhNKUA33/AUtbqb9/ctbzeIAlxKh01gHRCxEGWltmknyjtw8uNr0\nTPn1ucKPaTEEdi4wz3v+zcyeOvA/ubVxFxcIisgt7yKJ3VFK7Aqptc4AJgJLMEn7W631dqXUC0op\n62w8PKqU2q6U2gw8CtxbXgFXtNMX0ujw4q+Fv+jhY+7uN+kLi56Apf/KHRUnRGWWmQF/vQfvdDCD\n815vZhL1rBtNh4HCjP0VRnyRO84jeiI8utGM/RCVTonNMuWlsjbLZAufvCjfdoFukXllZsBPf4MN\ns6DDPTB4epWfLlQ4Ca3h5DYIbQW7Fpq28u3zYMd8M1T/2Kaij3VxNUvJjVkCx2Nz7y2lJJuHE8+o\nWJnZs1lGAP9ZvJtvx0cX/qLFFQa/adoYV75uehIMegP86lRskEJcKbsnS69/wIrX8r+W3eMlm7JA\nzyfMeA7fOuYYnWnWEs0e5g9m27PYW2qiEpDkXoRravmw52RuV8h1B8/Qf/oKljzeq/ADlILrnzNz\nXPw8GQ52MV0mr+lXQRGLau1iIqQkgc4yiXnLbFg5Hc7Fm9evTOxXunOudak5SQnOQj7JInz3YDdi\nDp1h7Ge5TUe7T55Ha40qbkKiLuOgyfXw3T3w9XDTbbLP8xDcpAKiFtXGpTPgGQDnj5tmlp0Lil5q\nzrcunD+Wf1+NEFNzv+UTqNUSarUq/5hFhZLkXgR/bzfaNwgssH/2+iOM7FS/+ARfszGM+QX+fNt0\nKdu50KyKfu0/wbdW+QUtnNe6j82/JQCfUDMCtNG1cPYQJO7NLRfSAsI6mkFCkXfCodXQbKDpfx7U\nCPYuNV0bez8LO38w0+dWg4UrqiO5oVoMrTXTl+7l7d/25tv/9qj2DGln4/wXF06ZlZw2zASLh5ln\nuvsk6fsrCpeVafqJBzWCfb/BkqehXpSZxwVMs9/F06Yt/EoT/jLr/wqnZusNVUnuNriy5wzA5IHN\nGX9tKVZ2Sdxv5uLYMd/0QOg01nQl8wm1Y6SiUktPgWMboUE0xH4NexabHikRvcDFDc6fMOMl1r4P\nrW4xw/zTzptj60XBvYtMpSDtErh6wpY55sZmUAScO2aaA4XTk+RuR2vjEvm/3/excu/pfPsPvjqo\n9Cc7sBJiZph20uw5q3s/bWpqwjkk7jczGyYdhsAISL8ECx6B/b+bZD14Oix8vOTz1GkHA6fB7sXW\nikBI+ccuKj1J7nZ2ITWD1lOW5Nu3dWo/fD3dynbC03shZqZprslIMUmgYTdTo6/b3g4Ri3KXvTYn\nmDZwDz+TyN/vZqaFTr9k9nkGQPLh/Mcqi2kz9/Q392QiekHnB0wbefdJcHK7qeG7uhd8X1GtSXIv\nB8//sI3P1+RfmPfrB7rQrXFw2U967rhJ8Kd2mDbW9EtQv6vpluYTaqZDbdyn2i8ZVuEunTE9UfL2\nIsnMgKVTzGfUbBDMHQO12pieUBtmFX6eOu1Mk0uLwRDS3EywteJ16POsSe5gujF6+ks3RGETSe7l\npO8bf7DvVG7/9wnXNebJAc2LOaIUUpJh4xcQ+5VJ9tla3WKS/ZG1pgdEeHf7vJ/ItfFzM+Cn5VCI\nvAM+HWBGZXZ5yCwkcWg1XDgJCbtyj3H1gqx0yMqARr2hbqSZArfLg7B/GTS5ASJ6Ou6ahFOS5F5O\nur+6jKNJl/Pt+3JsF3o0vYrae2EyUk3tcfPXsOwlMzglW70oCGwI9btA034Q0LDarvBeqKxM83B1\nh1VvmkR76wzY+p3pD953Kvz6PCQdMcn38BrTPu5WA9Iv5p7HxdUkbjA3wdMuQNcJprlk1yLo9XeT\n+M8fN8P75TMQFUCSeznp8OKvnLlYcO3H/S/fiMWlnJpOzh4y3d9Cm8P6GbD1W7iQABdOWAsos/BB\ng67Q+HqTfHxC8zflZKabmSwdKSvL3F8obFm2rCxTCz5/wsx5UtjcPGmXzLEXTsHRDWZuk1+eMzVq\nv3pmYI7ONO3V546atTjXvm+O9fCH1CuWePMKNH9EG3Yz34y6jIeDq8w6nwENTCL/tJ8pM245uHnZ\n9/chRBlIci8nv+44yeS5W0i8IsH3bRFK7+ahnDqXyqS+TYsf5GQviftNd7kLJ00zzqE/IfWcec07\n2EwS1bi3aUqI+wPa3AatbzU3c5ULBF9j/ghkpIJ3kFmMITPdrCzvH2b+oEDhvTQun4Uj6yGkmanR\nrv0AarU2zRpHN5okHtAQPP1MrfiP/5g/UhdOmHbozAyTqOt1NHGf3G79dqLNHOJKma6DIc3M3OAX\nTppmqfCe5lovJZo4vAJNT6MLpyDtojk+I9XU3DNTzaCejveaQTxthkPkKFjwKHQYDd0eM38MihvE\nk5Fqbn5Ke7ioJCS5l6PCes7ktf6ZvoT4OmDUX/plk1iPb4YTW0wtOO538Kltmh+2z8ttZiiJqxdk\nWJufarcxteKUZPOHIbQFnNiWvwmjJD61oWG0qWEf/gtqBMOxWDMfSq3W5luHh6+pHa95z7zuW8f8\nYUhJNgner66Zf9yvnhlZeSmwC3N9AAAcSUlEQVTRLNDsXy/3ffL+e05JMr1VXCwm2ctMncIJyKyQ\n5cjLrfgkcT4l3THJ3c3L3GzNe8M1JRncfU178I2vQcIe0+Tg5gnxMSZBegebdmP3Giahntxmknhg\nOFw+Y6aFvXwWLO4mqSbGmSHt7UbBceuUsVFjYd9S0xzSsLup8aYkm+PdfeCa/gUXE89OxFd+y+n2\naNl7B+U9zivP9BGS2EU1I8m9DEpqWz97Kb2CIrFB3qlZvQKhQZ61zYtaZKFhEVMbF6Zp39znbW8v\nXWxFJXDp9inEVZPb+2X0xu3tmDehGzPv61TgtZcW7WBtXKIDohJCCEOSexnd0iGM9g0C6d0slJsj\n808itulwEqNnrHNQZEIIIcndLt4c2Z5Rnevn2+fhJr9aIYTjSAaykyk3teKj0R1zts+nZPD12sOk\nZ2YVc5QQQpQPSe524ulmoV+r2vn2PT1vK02fWcygt1eSXJlusgohnJ4kdztrXtu3wL7tx85x+4dr\ncNSYAiFE9SPJ3c5+ntSLSX2bFti/++R5Ip76iXtnyo1WIUT5k+ReDiZc1yRf+3tey3cn0OXlpSRd\nKjg/jRBC2Isk93Lg7upCv1a1ee/ODlxTy6fA6yfPpfLjluP8FZfIh3/sd0CEQghnJyNUy9GNbeqg\nNTz89cYCrz03f1vO8wd6NsKlvGaUFEJUS1JzL2eD2tZh1T97F1vmzaV7GPT2SrYdTSbxQmoFRSaE\ncGY2JXel1ACl1G6l1D6l1ORiyt2mlNJKqRJnLKtOwgK9WffM9YVOVQDw9rJ9bD92jsHvrGLou6vZ\nn3Ch0HJCCGGrEpO7UsoCvAsMBFoCo5RSLQsp5ws8Cqy1d5DOINTXk97NQjnwyo05+wa3rVOgXPzZ\ny1z/3z84dS6lIsMTQjgZW9rcOwP7tNZxAEqp2cBQYMcV5V4EpgF/t2uETkYpxYtDW5F8OZ3RXcNZ\nuOV4oeVeWrSTzCzNxD5NaFHHr4KjFEJUdbYk93rAkTzb8UCXvAWUUu2B+lrrhUopSe4lGB0dDoDW\nGh8PVxrW9Gb7sXP5yizYfAyARVuPs+elgbi7yu0RIYTtbMkYhXXjyBlqqZRyAaYDfyvxREqNU0rF\nKKViEhISbI/SSSml2Dq1H0/f2KLYctc8u5gjZy5VUFRCCGdgS3KPB/JOeRgGHMuz7Qu0BpYrpQ4C\nXYEFhd1U1Vp/pLWO0lpHhYQUsi5nNaSUwtXaDbJ5bV8e7dOk0HI9p/3OpsNnKzI0IUQVZktyXw80\nVUpFKKXcgZHAguwXtdbJWutgrXW41joc+AsYorWumgukOkDniCCeHdSCOeOiGdC64E3WbHd9Iveq\nhRC2KTG5a60zgInAEmAn8K3WertS6gWl1JDyDrA6UEpxf89G+Hu7oa0tXq4uinfv6MCLN7fOKXcx\nLZPIF34hfPIiXlm8U/rECyGKpBw1U2FUVJSOiZHK/ZUupGbQesoSPrirIwNamymEwycvKvG4xY/1\nlF41QlQDSqkNWusSxxLJ9AOVjI+HKwdfHVToa3dHN+S3nac4mnS5wGufrzlIHX8vbulQj7BA73KO\nUghR2UlyrwJa1vFjx/Fz/GtIKyYPbM6hxEs0rOlNr2nLOW1tmvlmnemt+tPW4/w8qRcxB8/w6uJd\nxBw6y4FXbkQpmbtGiOpEknsV8PUDXTiUeAmlFN7urjnNL/93R3tGfvRXvrK7TpxnxIdrWHvgTM6+\ni2mZ+HjIRy1EdSIjY6qAAG932tUPKLC/a6OaOc87NgzMeZ43sQO0nrKEncdzB0nFHkni7k/XkZYh\n67sK4aykOlfFfftgNIu3Hef5wS1zJh8rzMC3VuLqovhhYnf+9m0s+xMucuD0RZoVsiygEKLqk+Re\nxXWOCKJzRBAArev5F1s2I0sz6O3c5L/2QCIHTl8otm+9EKJqkuTuZOY+1I2kS2m8sngX+04VP3Xw\n8z9sB6B9gwAmD2hOlzzNPEKIqk3a3J1Mx4aBXN+iFkufuNbmYzYdTmLER38xb1N8OUYmhKhIktyd\nWF1/T+oFeBHs425T+cfnbGbW6gMknDfdKy+kZvBdzBEcNdBNCFF2MkK1mpjw1QY8XC1MHxHJhkNn\nWXsgkWk/7y60bLCPO7PHRdP3jT8AWDKpF81q+6K1lv7yQjiYrSNUJblXU8t2nWTMrBju6x7OugNn\nCswnf6Ub29Tmp60nWPNUH+r4e1VQlEKIK8n0A6JYvZuF8sXYznRrHIzFOuVwemYWTZ9ZXGj5n7ae\nAGDfqQsE1XDH1cUl5zghROUjNXeRz9Gky3R/dZlNZR/vew2P9W1azhEJIfKSZhlRZhmZWXyy6gCj\nOjVg6o/bmbfpaLHlp49oh4tS9GtZm2fmbcXX05WnB7XAw9VSQRELUX1Ichd2s2T7CT5fc5DV+xJt\nPub5wS0JD/amW+NgPN0kyQthL9LmLuymf6va9G9Vm5+3HWdzfDJaQ8+mwdxZzMpQK/Ym8MLCBO7r\nHs6Um1pVYLRCCJDkLkphQOs6+aYqsLgoMrMK/+a3fLdZAH3m6oMMbls338RmQojyJ4OYRJk9NbB5\nvu0RUfULLXfr+3/y286TfLPucL79py+kcjkts9ziE6I6k5q7KLOxPSIY2yOCiKd+AuA/t7VlToxZ\nNKRb45r8uT+3jX7sZ+b+SkaW5mRyCnUCPHlm3jZa1PFj8WM9Kz54IZycJHdRZtmjVRsF12Bwu7o5\n+2v5efD1A10Z9t5qNh1OynfMc/O35dveefwcT/5vMz9vO8G5lAzeHBHJ2Utp3NstXEbDCnEVpLeM\nsKsTySl4e1jw83TL2ffSwh3EHDpL7JGkYo4saMJ1jXlyQPOSCwpRjUhvGeEQtf09C+x7dnBLAI4n\nX+bA6Yvc8XHRvWzyem/5fhrW9Ob2qPpSixeilCS5iwpTx9+r1PPS/HPuVprX9qOWnydBNdxxd5U+\nAELYQpplRIWLP3uJlPQsFsQeJe70RRZuOc7KJ3vTc9rvJR47vGMY025ri1KK7ceSUSha1vWrgKiF\nqBykWUZUWmGB3gA80a8ZWmteH94OTzcL7cL82RyfXOyx322Ix9vdwnODW+ZbMnDhIz24ppYvry7e\nxcQ+TQiqYdsc9kI4K/mOKxxKKZUzPcF347vx1f1dcl5rladG/tptbXOef7bmEE2umL3yh9ijLN15\nkk9XH+ClRTvKOWohKj9J7qLScHd1oX2DABqF1OC78dEserQnD/duzN/7XcONbYpfxPvjlQeY9edB\nAL7fWPxEZ0JUBza1uSulBgBvARbgE631q1e8Ph54GMgELgDjtNbFVp+kzV2U1oZDZ6nj78lPW4/z\n0qKdxZb9bExnpv28i26Na3JrxzCa1zbfAs5cTONiagb1g7wrImQh7M5us0IqpSzAHuAGIB5YD4zK\nm7yVUn5a63PW50OACVrrAcWdV5K7uBq/bD/BlAXbOZ6cYvMx/xrSipcW7SA9U3Pw1UHlGJ0Q5cfW\n5G5Ls0xnYJ/WOk5rnQbMBobmLZCd2K1qALKisihX/VrVZmSnBgBc1yzEpmOmLNhOeqb80xTVgy3J\nvR5wJM92vHVfPkqph5VS+4FpwKOFnUgpNU4pFaOUiklISChLvELkmNinCZuf78eLQ1vTp3lozv43\nR0TyxA3XFHvsyz/lNutorXFUl2Ahyostyb2woYEF/idord/VWjcG/gk8W9iJtNYfaa2jtNZRISG2\n1baEKIrFReHv7Ub9IG8+vbcT3z4YzajO9RkaWZdHry9++b+PVsTx1dpDnL2YRqd/LyXiqZ/4ZGVc\nBUUuRPmzJbnHA3nncg0DjhVTfjZw89UEJURZdI4I4pVb2uZMVbB1aj9CfD3ylZlyU8uc58/M20b7\nF3/l9IU0AF5atJNJszdxMTWDH2KPkp6ZxeW0TFLSZVpiUfXYMohpPdBUKRUBHAVGAnfkLaCUaqq1\n3mvdHATsRQgH8/V045dJvUi+nM51ry8H4J7ocP6KS2TJ9pOFHjM/9hjzY03dZdafB9l0OIlgH3di\nnr2hosIWwi5KTO5a6wyl1ERgCaYr5Kda6+1KqReAGK31AmCiUqovkA6cBe4pz6CFsFVgDXcCa7jT\nIMibYB93XFwUH442HQ1eXLiDGasOFHls9nTFpy+kcT4lnSwNH/6xn0Ft67DxcBJ3dG6AxUUmNBOV\nk8wtI6q1uIQLfBsTzwd/7KdBkDeBNdzZXMTUxC3q+LHzeG7HsHfv6MCgtsUPrhLC3uzZFVIIp9Uo\nxIcBrWsDcHd0Q+aOj6Zfy1qFls2b2AGytOZSWgZv/LonZ7lA6XUjKgupuQsB7Dl5nqahPiil0Fqz\nP+EiB05fZPG24yzccpy0jKwSzzHzvk7cN3M9M+/rRIvafry0aAdP9m9Og5oyGlbYj91GqJYXSe6i\nqtBas2zXKX7ZfpJGITXw9nAtsFwgQERwDQ6cvphvX+9mIXwwuiM7j58nsn5ARYUsnJgkdyHKSUZm\nVoFZKYtzd3RDPl9ziBX/6C21eHHVpM1diHLiasn9b3NL+wKDtQv4becpAG7/cA3Hki6XW1xC5CXJ\nXYgy+HJsF2r7efKvoa3w93IrtuxRa0I/cS6Ft5buZUt8EhsOneG5+dvYd+pCRYQrqiFplhHCDlIz\nMtlx7BxuFhfOpaTbvAh4tukj2jGsfVg5RSeciSyzJ0QF8nC10L5BIADJl9IBuLdbOPd0CyfE14PW\nU5YUe/zjczZzc2S9nKkThLhaUnMXohwcS7pMqK9HTvv8tzFH8PN0pUmoD33fWFHssd8+GE16ZhZN\nQ31IzciShUVEPlJzF8KB6gZ45du+Pap+gTKbnruB9i/+WmD/7R+uybc9e1xXdh0/x11dG+a7mStE\ncSS5C1HBXry5NWDmvbHFyI/+AmD1/kQ+vjuK48mX8fV0w8cj97/vieQUavq44ybJX1jJvwQhKtjo\nrg0Z3bUhAOHWfu8bnu2b83rfFqGFHvfrjpM8M28r0a8so/WUJXzx1yHGzFrPocSLdH3lN57/YXv5\nBy+qDGlzF8KBUtIz0Rq83C2ET14EwLqnr6fzy7+V6Xx3dGnAy8Pa2DNEUcnIICYhqgBPNwte7hYA\nPhzdkecGtyTUz5N1T1/PgondGd4xjLkPRdt8vq/XHi6vUEUVI23uQlQS/VvVznke6udJqJ8nrw0P\nKHSmSQ9XF1KLmMzs/s9iuLVDPSJCahDo7U6W1tTx9yIzS8v889WIJHchKjmlFDPuieKx2bGE+Hrw\n3fho0jKy6PbqskLLL915kqU7C19pava4rnRtVLM8wxWVhDTLCFEFXN+iFtv+1Z/f/34dwT4e1A3w\nYmLvJqU+z/LdCYRPXsTrS3ZzMTWDT1bGkXghtRwiFo4mN1SFqKK01qRnav7Yk0CzWr7UD/Ki7xt/\nsD/hYpHHBHq7cdY6grZxSA32J1ykQZA38x/uzuJtx+kcHkTTWr4VdQmiDGTKXyGqqU9XHeCFhTu4\nq2sDmoT48M26I+w+ed7m40N8PejfqhZTbmol/eYrIUnuQlRTWmvOXEyjpo9Hzr7sbpalMSKqPs8M\nboGfZ/GzXoqKJV0hhaimlFL5Entesc/fYPN55sQcoe3UXziXYppxth9L5qnvt5CRWfKSg8LxpLeM\nENXAjhf646IUnm4WBrWpQ+yRJI4mXeapgc1pE+Zf7BTFN7+7mrb1/JkfewyAjYeSePyGa+gUHoir\niwv+3lKzr4ykWUaIaiojMytnIrLZ6w4Tf/YyLgreXrbP5nNENQxk1pjOLNpyjNs61pd+9BVA2tyF\nEGXW6d9LSThvWxfJEF8PEs6nEurrwaf3duLU+RR6NwuVuenLiSR3IUSZnb2YxrmUdGr5efLCwh08\n2qcpb/22h2/WHbHp+LdGRjI0suT1ZUXpSXIXQtjd4HdWsu3ouRLL1QvwwtPNhVn3dcbHw5Usranp\n48HYWesZ0ak+/fJMtSBKx67JXSk1AHgLsACfaK1fveL1J4D7gQwgARijtT5U3DkluQtR9azed5pP\nVx2ghocr6w6c4cS5lGLLRzeqyYHTFzlxLoU+zUNZtusUAAdfHVQR4Tolu63EpJSyAO8CNwDxwHql\n1AKt9Y48xTYBUVrrS0qph4BpwIiyhS6EqKy6Nwmme5NgAJIupRF7JIl7Z64HwM2iSM/MX1lcE5eY\n8zw7sQMkX07n3OX0fEsIJl1KY+7Go4zpHi7t9XZgS1fIzsA+rXUcgFJqNjAUyEnuWuvf85T/C7jL\nnkEKISqfAG93rmtmFhbp3qQmX93fFbBtwFS7f/0CwBM3XMPZS2n8FXeGncdNc09kfX86NgwiNSOT\nPScu0CbMn8QLqfh5ucmI2VKwJbnXA/LeRYkHuhRTfiyw+GqCEkJUHX89dT0Befq6L36sJ5sOJzE8\nKoxdx8/zt+9imXFPJ3pO+73AsW/8uqfAvuypjKf8sJ3Z64+w5qk+RL+yjOubhzLj3k7ldyFOxpY/\ng4V9Pyq0oV4pdRcQBbxWxOvjlFIxSqmYhIQE26MUQlRatf098XSz5Gy3qOPHHV0a4GZxoU2YP788\nfi31g7x55RbbVoi64+O1HE68xOz1pk558pzpkvlbnmYdUTJbkns8kHfp9jDg2JWFlFJ9gWeAIVrr\nQjvIaq0/0lpHaa2jQkJCyhKvEKKKGtmpPp+P6ZyzPX1Eu3yLfOfV67XcWv7N767OeV5YB5AzF9N4\n+7e9ZGU5pudfZVVibxmllCuwB7geOAqsB+7QWm/PU6Y98D9ggNZ6ry1vLL1lhKieTp1PwUUpgn08\nSL6UzjvL9vLJqgM2H7/5+X45Ux5orblrxlpW70vk6/u70M16s9eZ2W3iMK11BjARWALsBL7VWm9X\nSr2glBpiLfYa4AN8p5SKVUotuIrYhRBOLNTXk2DrxGb+3m7cFhUGwMx7OzGuV6MSj7/+jeW88ctu\nHvwihgc+38DqfaZHzoSvN5KSnsk36w5LLR4ZxCSEqASy57nZfCSJoe+u5sFrGzG2RwSd//1bqc4T\n4O1G0qV0PrirA10iavLo7E08dG1jujUJ5s99pwkL9KZBTe+ST1SJyQhVIUSVtHrfaTpHBOFmceHP\nfaf5ccsxVuw5zdGkyzafIyK4BgdO565I9fOkngx4cyUAcS/fyJyYI9wcWQ8vd0tRp6i0JLkLIZzK\nsaTLOYuC398jAndXF95bvr/M5+vbIpSdx8/z+vB2RDeuOouGS3IXQjid48mX2X3ifM7gqb/iEvlq\n7WFGd21I8zq+rNmfyINfbCjVOesHeTGyUwPWHzzDhZQM/tG/GV0aVd5kL8ldCFEtDXhzBbtOnOfg\nq4NoM2UJ51Mzii1vcVFkXnEDdvy1jZk8sDlnLqbhalGVaqlBSe5CiGrpclomGVlZ+Hq6sWZ/Il+v\nO8yPmwsMzSmVabe2xdvDwpb4ZEZ0qk+orwe+1oSfnpnF1qPJdGgQaI/wSyTJXQghrAa/s5Javp60\nqOPHAz0bMWXBtpxlA8uihruFf/RvRoivJ/M2xbN05yl+nNiDNmH+doy6cHabFVIIIaq6hY/0zLfd\nKSKI+bHHuLNLA5rV9uX5H7YXcWThLqZlMvXHHfn27U+4QOyRs7QJCyCyfgCnL6QydcF2/j2sDf5e\nFd+sI8ldCFHtDO9Yn5T0LEZ3bYi7qwt3dWnI7PVHmLcpnvUHz/Lh6I74eLhy5ydFLxx+pQOnL/LW\nb2aA/rD29Zi36SgAkfUDuL9nyYOz7E2aZYQQIg+tNUop0jKyeHb+VqIaBqHR/HPuVga1qUNYkBcf\n/hFn8/la1fUjqmEgvp5u/L1/s6uOT9rchRDCjrKTfrZrnllMWmYW7q4upFmnKS7Ji0NbMaxDWJET\nptnCbnPLCCGEoMDqUN+M68I90Q3Z/eIA5j4UbdM5nvthO62nLOGzPw+WQ4T5SZu7EEKUQceGQXRs\nGJTzvE09f7YeTbbp2Jo+7uUZGiA1dyGEsIuZ93Xi6wdyF6m7sU1tnr6xOe0K6R4Z6utZ7vFIchdC\nCDsI9vGgW+Ng/jc+mvYNAnjj9kjG9WrMDxN7FCjr51X+jSbSLCOEEHYUFR7EvAnd8+373/hoPN0s\nrNibwPmUDK4J9S33OCS5CyFEOYsKN23zreuV/wjWbNIsI4QQTkiSuxBCOCFJ7kII4YQkuQshhBOS\n5C6EEE5IkrsQQjghSe5CCOGEJLkLIYQTctiUv0qpBOBQGQ8PBk7bMZyqQK65epBrrh6u5pobaq1D\nSirksOR+NZRSMbbMZ+xM5JqrB7nm6qEirlmaZYQQwglJchdCCCdUVZP7R44OwAHkmqsHuebqodyv\nuUq2uQshhCheVa25CyGEKEaVS+5KqQFKqd1KqX1KqcmOjsdelFL1lVK/K6V2KqW2K6Ues+4PUkr9\nqpTaa/0ZaN2vlFJvW38PW5RSHRx7BWWjlLIopTYppRZatyOUUmut1ztHKeVu3e9h3d5nfT3ckXGX\nlVIqQCn1P6XULutnHV0NPuPHrf+mtymlvlFKeTrj56yU+lQpdUoptS3PvlJ/tkqpe6zl9yql7ilr\nPFUquSulLMC7wECgJTBKKdXSsVHZTQbwN611C6Ar8LD12iYDv2mtmwK/WbfB/A6aWh/jgPcrPmS7\neAzYmWf7P8B06/WeBcZa948FzmqtmwDTreWqoreAn7XWzYF2mGt32s9YKVUPeBSI0lq3BizASJzz\nc54FDLhiX6k+W6VUEDAF6AJ0BqZk/0EoNa11lXkA0cCSPNtPAU85Oq5yutYfgBuA3UAd6746wG7r\n8w+BUXnK55SrKg8gzPoPvg+wEFCYgR2uV37ewBIg2vrc1VpOOfoaSnm9fsCBK+N28s+4HnAECLJ+\nbguB/s76OQPhwLayfrbAKODDPPvzlSvNo0rV3Mn9h5It3rrPqVi/irYH1gK1tNbHAaw/Q63FnOF3\n8SbwJJBl3a4JJGmtM6zbea8p53qtrydby1cljYAEYKa1KeoTpVQNnPgz1lofBV4HDgPHMZ/bBpz7\nc86rtJ+t3T7zqpbcVSH7nKq7j1LKB5gLTNJanyuuaCH7qszvQik1GDiltd6Qd3chRbUNr1UVrkAH\n4H2tdXvgIrlf0wtT5a/Z2qQwFIgA6gI1ME0SV3Kmz9kWRV2n3a6/qiX3eKB+nu0w4JiDYrE7pZQb\nJrF/pbX+3rr7pFKqjvX1OsAp6/6q/rvoDgxRSh0EZmOaZt4EApRS2Qu3572mnOu1vu4PnKnIgO0g\nHojXWq+1bv8Pk+yd9TMG6Asc0FonaK3Tge+Bbjj355xXaT9bu33mVS25rweaWu+0u2NuzCxwcEx2\noZRSwAxgp9b6jTwvLQCy75jfg2mLz95/t/Wue1cgOfvrX1WgtX5Kax2mtQ7HfI7LtNZ3Ar8Dt1mL\nXXm92b+H26zlq1SNTmt9AjiilGpm3XU9sAMn/YytDgNdlVLe1n/j2dfstJ/zFUr72S4B+imlAq3f\nevpZ95Weo29AlOGGxY3AHmA/8Iyj47HjdfXAfP3aAsRaHzdi2ht/A/ZafwZZyytMz6H9wFZMbwSH\nX0cZr/06YKH1eSNgHbAP+A7wsO73tG7vs77eyNFxl/FaI4EY6+c8Hwh09s8Y+BewC9gGfAF4OOPn\nDHyDua+QjqmBjy3LZwuMsV7/PuC+ssYjI1SFEMIJVbVmGSGEEDaQ5C6EEE5IkrsQQjghSe5CCOGE\nJLkLIYQTkuQuhBBOSJK7EEI4IUnuQgjhhP4fOnUQpjrH2/8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f05700bd128>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='Face train_loss')\n",
    "mplot.plot(valid_loss, label='Face valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n8EAS7kII4YEk3IUQwgP9PyD2fyG3tvaRAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f0544fb8fd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "mplot.plot(train_acc, label='Face train_acc')\n",
    "mplot.plot(valid_acc, label='Face valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dcnn-face-yalda-Copy2.ckpt\n",
      "Test loss: 0.338009 Test acc: 0.876786\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints/'))\n",
    "    \n",
    "    ################## Test\n",
    "    acc_batch = []\n",
    "    loss_batch = []    \n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(batch_size=100, X=X_test_norm, y=Y_test_onehot):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "        # Loss\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Store\n",
    "    test_acc.append(np.mean(acc_batch))\n",
    "    test_loss.append(np.mean(loss_batch))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print(\"Test loss: {:6f}\".format(np.mean(test_loss)),\n",
    "          \"Test acc: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
