{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18720, 205, 16) float64 (18720, 1) uint8\n",
      "0.833333333333 0.166666666667 0.0 0.0\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "BahramFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/BahramFace.mat')\n",
    "DJFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/DJFace.mat')\n",
    "NickFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/NickFace.mat')\n",
    "RoohiFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/RoohiFace.mat')\n",
    "SarahFace = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/SarahFace.mat')\n",
    "\n",
    "AllData = np.concatenate((BahramFace['Intensification_Data'],\n",
    "                            DJFace['Intensification_Data'],\n",
    "                            NickFace['Intensification_Data'],\n",
    "                            RoohiFace['Intensification_Data'],\n",
    "                            SarahFace['Intensification_Data']), axis=0)\n",
    "\n",
    "AllLabels = np.concatenate((BahramFace['Intensification_Label'],\n",
    "                            DJFace['Intensification_Label'],\n",
    "                            NickFace['Intensification_Label'],\n",
    "                            RoohiFace['Intensification_Label'],\n",
    "                            SarahFace['Intensification_Label']), axis=0)\n",
    "\n",
    "print(AllData.shape, AllData.dtype, AllLabels.shape, AllLabels.dtype)\n",
    "print(np.mean(AllLabels==0), np.mean(AllLabels==1), np.mean(AllLabels==2), np.mean(AllLabels==3))\n",
    "print((AllLabels +  1).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13104, 205, 16) (5616, 205, 16) (13104, 1) (5616, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "\n",
    "print(X_train_valid.shape, X_test.shape, Y_train_valid.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.835851648352 0.164148351648 0.0\n",
      "0.0 0.827457264957 0.172542735043 0.0\n",
      "(5616, 2) float64\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "X_train_valid_norm, X_test_norm = standardize(test=X_test, train=X_train_valid)\n",
    "\n",
    "# Onehot encoding/vectorizing the output data labels\n",
    "print(np.mean((Y_train_valid+1).reshape(-1)==0), np.mean((Y_train_valid+1).reshape(-1)==1),\n",
    "     np.mean((Y_train_valid+1).reshape(-1)==2), np.mean((Y_train_valid+1).reshape(-1)==3))\n",
    "\n",
    "print(np.mean((Y_test+1).reshape(-1)==0), np.mean((Y_test+1).reshape(-1)==1),\n",
    "     np.mean((Y_test+1).reshape(-1)==2), np.mean((Y_test+1).reshape(-1)==3))\n",
    "\n",
    "# Y_train_valid_onehot = one_hot(labels=(Y_train_valid+1).reshape(-1), n_class=2) \n",
    "# print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "Y_test_onehot = one_hot(labels=(Y_test+1).reshape(-1), n_class=2) \n",
    "print(Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "X_train_norm, X_valid_norm, Y_train, Y_valid = train_test_split(X_train_valid_norm, Y_train_valid, \n",
    "                                                                              test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches2(X_norm, Y_labels, kernel_size_ratio=1, strides_ratio=1):\n",
    "    # X normalized and Y NOT onehot encoded/vectorized\n",
    "    X, Y = X_norm, Y_labels\n",
    "    AllLabels = Y_labels # 100%\n",
    "\n",
    "    # non = 0 is 87%  AllLabelZero\n",
    "    # tgt = 1 is 13%  AllLabelOne\n",
    "    AllLabelZero = (AllLabels==0).reshape(-1) # 87%\n",
    "    AllLabelOne = (AllLabels==1).reshape(-1) # 13%\n",
    "\n",
    "    X_non, Y_non = X[AllLabelZero], Y[AllLabelZero] # 87%\n",
    "    X_tgt, Y_tgt = X[AllLabelOne], Y[AllLabelOne] # 13%\n",
    "#     print('X_non.shape, Y_non.shape', X_non.shape, Y_non.shape)\n",
    "#     print('X_tgt.shape, Y_tgt.shape', X_tgt.shape, Y_tgt.shape)\n",
    "\n",
    "    # Non-target batch size for get_batches from non-target data\n",
    "    batch_size = X_tgt.shape[0] # 13% -> tgt = 1 is 13%  AllLabelOne\n",
    "    assert X_tgt.shape[0] == Y_tgt.shape[0]\n",
    "#     print('batch_size', batch_size)\n",
    "    \n",
    "    # Convolvolutional minibatching technique\n",
    "    (inputs, filters, kernel_size, strides, padding) = (X_non, 1, \n",
    "                                                        int(batch_size//kernel_size_ratio), \n",
    "                                                        int(batch_size//strides_ratio), \n",
    "                                                        0)\n",
    "#     print('inputs.shape, filters, kernel_size, strides, padding', inputs.shape, filters, \n",
    "#           kernel_size, strides, padding)\n",
    "    n_batches = int((inputs.shape[0] - kernel_size + (2*padding))//strides  + 1) \n",
    "#     print('n_batches', n_batches)\n",
    "    \n",
    "    # Loop over target batches: start, stop, step\n",
    "    for i in range(0, n_batches, 1):\n",
    "        each_X_norm = np.concatenate((X_non[(i*strides):((i*strides)+kernel_size)], X_tgt), axis=0)\n",
    "        each_Y = np.concatenate((Y_non[(i*strides):((i*strides)+kernel_size)], Y_tgt), axis=0)\n",
    "        each_Y_onehot = one_hot(labels=(each_Y+1).reshape(-1), n_class=2)\n",
    "#         print('each_X_norm.shape, each_Y_onehot.shape', each_X_norm.shape, each_Y_onehot.shape)\n",
    "#         print('np.mean(each_Y==0), np.mean(each_Y==1)', np.mean(each_Y==0), np.mean(each_Y==1))\n",
    "        yield each_X_norm, each_Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_batches2 at 0x7fd972f25d58>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batches2(X_norm=X_valid_norm, Y_labels=Y_valid, kernel_size_ratio=1, strides_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object get_batches2 at 0x7fd96ece6ba0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_batches2(X_norm=X_train_norm, Y_labels=Y_train, kernel_size_ratio=1, strides_ratio=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len, n_channels 205 16\n",
      "n_classes [2]\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "# Input data\n",
    "# batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "# print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "print('seq_len, n_channels', seq_len, n_channels)\n",
    "\n",
    "# Output labels\n",
    "n_classes = Y_train_valid.max(axis=0)+1\n",
    "assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "print('n_classes', n_classes)\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.0001 #1e-4\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')\n",
    "print('inputs_.shape, labels_.shape', inputs_.shape, labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, conv1.shape, max_pool_1.shape (?, 205, 16) (?, 204, 32) (?, 102, 32)\n",
      "max_pool_1.shape, conv2.shape, max_pool_2.shape (?, 102, 32) (?, 102, 64) (?, 51, 64)\n",
      "max_pool_2.shape, conv3.shape, max_pool_3.shape (?, 51, 64) (?, 50, 128) (?, 25, 128)\n",
      "max_pool_3.shape, conv4.shape, max_pool_4.shape (?, 25, 128) (?, 24, 256) (?, 12, 256)\n",
      "max_pool_4.shape, flat.shape, logits.shape (?, 12, 256) (?, 3072) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n",
    "# (batch, 205, 16) --> (batch, 102, 32)\n",
    "# conv valid: (205-2+0)/1 + 1 = (203/1)+1 = 203 + 1=204\n",
    "# pool same: (204-2+0)/2 + 1 = (202/2)+1 = 101 + 1=102\n",
    "conv1 = tf.layers.conv1d(inputs=inputs_, filters=32, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_1 = tf.nn.dropout(max_pool_1, keep_prob=keep_prob_)\n",
    "print('inputs_.shape, conv1.shape, max_pool_1.shape', inputs_.shape, conv1.shape, max_pool_1.shape)\n",
    "\n",
    "# (batch, 102, 32) --> (batch, 51, 64)\n",
    "# conv same\n",
    "# pool same: (102-2+0)/2 + 1 = (100/2)+1 = 50 + 1=51\n",
    "conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=64, kernel_size=2, strides=1, padding='same', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_2 = tf.nn.dropout(max_pool_2, keep_prob=keep_prob_)\n",
    "print('max_pool_1.shape, conv2.shape, max_pool_2.shape', max_pool_1.shape, conv2.shape, max_pool_2.shape)\n",
    "\n",
    "# (batch, 51, 64) --> (batch, 25, 128)\n",
    "# conv valid: (51-2+0)/1 + 1 = (49/1)+1 = 49 + 1=50\n",
    "# pool same: (50-2+0)/2 + 1 = (48/2)+1 = 24 + 1=25\n",
    "conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=128, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_3 = tf.nn.dropout(max_pool_3, keep_prob=keep_prob_)\n",
    "print('max_pool_2.shape, conv3.shape, max_pool_3.shape', max_pool_2.shape, conv3.shape, max_pool_3.shape)\n",
    "\n",
    "# (batch, 25, 128) --> (batch, 12, 256)\n",
    "# conv valid: (25-2+0)/1 + 1 = (23/1)+1 = 23 + 1=24\n",
    "# pool same: (24-2+0)/2 + 1 = (22/2)+1 = 11 + 1=12\n",
    "conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=256, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_4 = tf.nn.dropout(max_pool_4, keep_prob=keep_prob_)\n",
    "print('max_pool_3.shape, conv4.shape, max_pool_4.shape', max_pool_3.shape, conv4.shape, max_pool_4.shape)\n",
    "\n",
    "# Flatten and add dropout + predicted output\n",
    "flat = tf.reshape(max_pool_4, (-1, 12*256))\n",
    "flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "logits = tf.layers.dense(flat, n_classes)\n",
    "probs = tf.nn.softmax(logits=logits)\n",
    "print('max_pool_4.shape, flat.shape, logits.shape', max_pool_4.shape, flat.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost, cost_ave: Tensor(\"Reshape_3:0\", shape=(?,), dtype=float32) Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "optimizer: name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_conv1d/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_2/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_3/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "correct_pred, correct_pred_ave: Tensor(\"Equal:0\", shape=(?,), dtype=bool) Tensor(\"Mean_1:0\", shape=(), dtype=float32)\n",
      "confusion Tensor(\"confusion_matrix/SparseTensorDenseAdd:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost_ave = tf.reduce_mean(input_tensor=cost)\n",
    "print('cost, cost_ave:', cost, cost_ave)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "print('optimizer:', optimizer)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(x=tf.argmax(input=probs, axis=1), y=tf.argmax(input=labels_, axis=1))\n",
    "correct_pred_ave = tf.reduce_mean(input_tensor=tf.cast(x=correct_pred, dtype=tf.float32))\n",
    "print('correct_pred, correct_pred_ave:', correct_pred, correct_pred_ave)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion = tf.confusion_matrix(predictions=tf.argmax(input=probs, axis=1), \n",
    "                                labels=tf.argmax(input=labels_, axis=1))\n",
    "print('confusion', confusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/300 Train loss: 0.699877 Valid loss: 0.689768 Train acc: 0.516127 Valid acc: 0.542006\n",
      "Epoch: 2/300 Train loss: 0.695889 Valid loss: 0.686440 Train acc: 0.524884 Valid acc: 0.571458\n",
      "Epoch: 3/300 Train loss: 0.691757 Valid loss: 0.683121 Train acc: 0.538180 Valid acc: 0.594974\n",
      "Epoch: 4/300 Train loss: 0.687840 Valid loss: 0.679855 Train acc: 0.550744 Valid acc: 0.613354\n",
      "Epoch: 5/300 Train loss: 0.683304 Valid loss: 0.676613 Train acc: 0.563834 Valid acc: 0.628069\n",
      "Epoch: 6/300 Train loss: 0.678765 Valid loss: 0.673222 Train acc: 0.576570 Valid acc: 0.639091\n",
      "Epoch: 7/300 Train loss: 0.674258 Valid loss: 0.669624 Train acc: 0.587697 Valid acc: 0.647013\n",
      "Epoch: 8/300 Train loss: 0.669667 Valid loss: 0.665829 Train acc: 0.598563 Valid acc: 0.654447\n",
      "Epoch: 9/300 Train loss: 0.664849 Valid loss: 0.661797 Train acc: 0.608908 Valid acc: 0.661041\n",
      "Epoch: 10/300 Train loss: 0.659687 Valid loss: 0.657481 Train acc: 0.618513 Valid acc: 0.666646\n",
      "Epoch: 11/300 Train loss: 0.654292 Valid loss: 0.652897 Train acc: 0.627778 Valid acc: 0.672035\n",
      "Epoch: 12/300 Train loss: 0.648531 Valid loss: 0.648068 Train acc: 0.636087 Valid acc: 0.676800\n",
      "Epoch: 13/300 Train loss: 0.642342 Valid loss: 0.643042 Train acc: 0.644146 Valid acc: 0.681423\n",
      "Epoch: 14/300 Train loss: 0.636290 Valid loss: 0.637835 Train acc: 0.651525 Valid acc: 0.685575\n",
      "Epoch: 15/300 Train loss: 0.629960 Valid loss: 0.632577 Train acc: 0.658374 Valid acc: 0.689419\n",
      "Epoch: 16/300 Train loss: 0.623731 Valid loss: 0.627282 Train acc: 0.664801 Valid acc: 0.693045\n",
      "Epoch: 17/300 Train loss: 0.617435 Valid loss: 0.622038 Train acc: 0.670542 Valid acc: 0.696576\n",
      "Epoch: 18/300 Train loss: 0.611195 Valid loss: 0.616887 Train acc: 0.676070 Valid acc: 0.699930\n",
      "Epoch: 19/300 Train loss: 0.605088 Valid loss: 0.611896 Train acc: 0.681184 Valid acc: 0.703008\n",
      "Epoch: 20/300 Train loss: 0.599115 Valid loss: 0.607096 Train acc: 0.686061 Valid acc: 0.706052\n",
      "Epoch: 21/300 Train loss: 0.593297 Valid loss: 0.602506 Train acc: 0.690778 Valid acc: 0.709016\n",
      "Epoch: 22/300 Train loss: 0.587621 Valid loss: 0.598103 Train acc: 0.695151 Valid acc: 0.711841\n",
      "Epoch: 23/300 Train loss: 0.582007 Valid loss: 0.593895 Train acc: 0.699471 Valid acc: 0.714582\n",
      "Epoch: 24/300 Train loss: 0.576666 Valid loss: 0.589851 Train acc: 0.703492 Valid acc: 0.717267\n",
      "Epoch: 25/300 Train loss: 0.571566 Valid loss: 0.585981 Train acc: 0.707212 Valid acc: 0.719848\n",
      "Epoch: 26/300 Train loss: 0.566539 Valid loss: 0.582280 Train acc: 0.710867 Valid acc: 0.722329\n",
      "Epoch: 27/300 Train loss: 0.561794 Valid loss: 0.578708 Train acc: 0.714215 Valid acc: 0.724742\n",
      "Epoch: 28/300 Train loss: 0.557186 Valid loss: 0.575310 Train acc: 0.717439 Valid acc: 0.727067\n",
      "Epoch: 29/300 Train loss: 0.552805 Valid loss: 0.572046 Train acc: 0.720496 Valid acc: 0.729284\n",
      "Epoch: 30/300 Train loss: 0.548445 Valid loss: 0.568892 Train acc: 0.723501 Valid acc: 0.731433\n",
      "Epoch: 31/300 Train loss: 0.544295 Valid loss: 0.565905 Train acc: 0.726363 Valid acc: 0.733474\n",
      "Epoch: 32/300 Train loss: 0.540275 Valid loss: 0.563030 Train acc: 0.729077 Valid acc: 0.735442\n",
      "Epoch: 33/300 Train loss: 0.536426 Valid loss: 0.560299 Train acc: 0.731737 Valid acc: 0.737322\n",
      "Epoch: 34/300 Train loss: 0.532649 Valid loss: 0.557666 Train acc: 0.734295 Valid acc: 0.739166\n",
      "Epoch: 35/300 Train loss: 0.528945 Valid loss: 0.555120 Train acc: 0.736863 Valid acc: 0.740920\n",
      "Epoch: 36/300 Train loss: 0.525435 Valid loss: 0.552717 Train acc: 0.739210 Valid acc: 0.742587\n",
      "Epoch: 37/300 Train loss: 0.522009 Valid loss: 0.550390 Train acc: 0.741464 Valid acc: 0.744141\n",
      "Epoch: 38/300 Train loss: 0.518655 Valid loss: 0.548168 Train acc: 0.743617 Valid acc: 0.745645\n",
      "Epoch: 39/300 Train loss: 0.515485 Valid loss: 0.546041 Train acc: 0.745712 Valid acc: 0.747093\n",
      "Epoch: 40/300 Train loss: 0.512421 Valid loss: 0.544005 Train acc: 0.747723 Valid acc: 0.748468\n",
      "Epoch: 41/300 Train loss: 0.509413 Valid loss: 0.542044 Train acc: 0.749730 Valid acc: 0.749816\n",
      "Epoch: 42/300 Train loss: 0.506464 Valid loss: 0.540160 Train acc: 0.751739 Valid acc: 0.751113\n",
      "Epoch: 43/300 Train loss: 0.503629 Valid loss: 0.538342 Train acc: 0.753568 Valid acc: 0.752369\n",
      "Epoch: 44/300 Train loss: 0.500860 Valid loss: 0.536581 Train acc: 0.755358 Valid acc: 0.753552\n",
      "Epoch: 45/300 Train loss: 0.498139 Valid loss: 0.534902 Train acc: 0.757157 Valid acc: 0.754688\n",
      "Epoch: 46/300 Train loss: 0.495496 Valid loss: 0.533249 Train acc: 0.758867 Valid acc: 0.755774\n",
      "Epoch: 47/300 Train loss: 0.492904 Valid loss: 0.531682 Train acc: 0.760511 Valid acc: 0.756832\n",
      "Epoch: 48/300 Train loss: 0.490388 Valid loss: 0.530177 Train acc: 0.762082 Valid acc: 0.757857\n",
      "Epoch: 49/300 Train loss: 0.487966 Valid loss: 0.528711 Train acc: 0.763586 Valid acc: 0.758876\n",
      "Epoch: 50/300 Train loss: 0.485612 Valid loss: 0.527328 Train acc: 0.765111 Valid acc: 0.759871\n",
      "Epoch: 51/300 Train loss: 0.483292 Valid loss: 0.525996 Train acc: 0.766539 Valid acc: 0.760841\n",
      "Epoch: 52/300 Train loss: 0.480969 Valid loss: 0.524699 Train acc: 0.767948 Valid acc: 0.761799\n",
      "Epoch: 53/300 Train loss: 0.478770 Valid loss: 0.523489 Train acc: 0.769319 Valid acc: 0.762728\n",
      "Epoch: 54/300 Train loss: 0.476631 Valid loss: 0.522289 Train acc: 0.770642 Valid acc: 0.763644\n",
      "Epoch: 55/300 Train loss: 0.474555 Valid loss: 0.521144 Train acc: 0.771903 Valid acc: 0.764563\n",
      "Epoch: 56/300 Train loss: 0.472456 Valid loss: 0.520033 Train acc: 0.773197 Valid acc: 0.765489\n",
      "Epoch: 57/300 Train loss: 0.470448 Valid loss: 0.518959 Train acc: 0.774415 Valid acc: 0.766393\n",
      "Epoch: 58/300 Train loss: 0.468412 Valid loss: 0.517944 Train acc: 0.775691 Valid acc: 0.767262\n",
      "Epoch: 59/300 Train loss: 0.466464 Valid loss: 0.516949 Train acc: 0.776891 Valid acc: 0.768097\n",
      "Epoch: 60/300 Train loss: 0.464558 Valid loss: 0.516003 Train acc: 0.778044 Valid acc: 0.768877\n",
      "Epoch: 61/300 Train loss: 0.462684 Valid loss: 0.515077 Train acc: 0.779152 Valid acc: 0.769642\n",
      "Epoch: 62/300 Train loss: 0.460828 Valid loss: 0.514183 Train acc: 0.780289 Valid acc: 0.770386\n",
      "Epoch: 63/300 Train loss: 0.459021 Valid loss: 0.513319 Train acc: 0.781361 Valid acc: 0.771117\n",
      "Epoch: 64/300 Train loss: 0.457204 Valid loss: 0.512502 Train acc: 0.782489 Valid acc: 0.771800\n",
      "Epoch: 65/300 Train loss: 0.455457 Valid loss: 0.511692 Train acc: 0.783494 Valid acc: 0.772472\n",
      "Epoch: 66/300 Train loss: 0.453726 Valid loss: 0.510908 Train acc: 0.784536 Valid acc: 0.773135\n",
      "Epoch: 67/300 Train loss: 0.452000 Valid loss: 0.510171 Train acc: 0.785565 Valid acc: 0.773784\n",
      "Epoch: 68/300 Train loss: 0.450312 Valid loss: 0.509437 Train acc: 0.786584 Valid acc: 0.774422\n",
      "Epoch: 69/300 Train loss: 0.448618 Valid loss: 0.508764 Train acc: 0.787597 Valid acc: 0.775021\n",
      "Epoch: 70/300 Train loss: 0.447011 Valid loss: 0.508086 Train acc: 0.788583 Valid acc: 0.775609\n",
      "Epoch: 71/300 Train loss: 0.445410 Valid loss: 0.507445 Train acc: 0.789523 Valid acc: 0.776178\n",
      "Epoch: 72/300 Train loss: 0.443822 Valid loss: 0.506816 Train acc: 0.790451 Valid acc: 0.776732\n",
      "Epoch: 73/300 Train loss: 0.442270 Valid loss: 0.506199 Train acc: 0.791366 Valid acc: 0.777268\n",
      "Epoch: 74/300 Train loss: 0.440708 Valid loss: 0.505610 Train acc: 0.792311 Valid acc: 0.777786\n",
      "Epoch: 75/300 Train loss: 0.439157 Valid loss: 0.505024 Train acc: 0.793240 Valid acc: 0.778301\n",
      "Epoch: 76/300 Train loss: 0.437643 Valid loss: 0.504475 Train acc: 0.794144 Valid acc: 0.778772\n",
      "Epoch: 77/300 Train loss: 0.436142 Valid loss: 0.503941 Train acc: 0.795054 Valid acc: 0.779249\n",
      "Epoch: 78/300 Train loss: 0.434689 Valid loss: 0.503424 Train acc: 0.795928 Valid acc: 0.779724\n",
      "Epoch: 79/300 Train loss: 0.433267 Valid loss: 0.502941 Train acc: 0.796769 Valid acc: 0.780171\n",
      "Epoch: 80/300 Train loss: 0.431833 Valid loss: 0.502459 Train acc: 0.797637 Valid acc: 0.780625\n",
      "Epoch: 81/300 Train loss: 0.430433 Valid loss: 0.502020 Train acc: 0.798495 Valid acc: 0.781071\n",
      "Epoch: 82/300 Train loss: 0.429044 Valid loss: 0.501610 Train acc: 0.799310 Valid acc: 0.781499\n",
      "Epoch: 83/300 Train loss: 0.427656 Valid loss: 0.501200 Train acc: 0.800120 Valid acc: 0.781918\n",
      "Epoch: 84/300 Train loss: 0.426296 Valid loss: 0.500833 Train acc: 0.800944 Valid acc: 0.782340\n",
      "Epoch: 85/300 Train loss: 0.424954 Valid loss: 0.500443 Train acc: 0.801739 Valid acc: 0.782754\n",
      "Epoch: 86/300 Train loss: 0.423633 Valid loss: 0.500108 Train acc: 0.802529 Valid acc: 0.783143\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/300 Train loss: 0.422314 Valid loss: 0.499750 Train acc: 0.803299 Valid acc: 0.783538\n",
      "Epoch: 88/300 Train loss: 0.421013 Valid loss: 0.499451 Train acc: 0.804066 Valid acc: 0.783921\n",
      "Epoch: 89/300 Train loss: 0.419706 Valid loss: 0.499127 Train acc: 0.804838 Valid acc: 0.784290\n",
      "Epoch: 90/300 Train loss: 0.418427 Valid loss: 0.498869 Train acc: 0.805603 Valid acc: 0.784658\n",
      "Epoch: 91/300 Train loss: 0.417162 Valid loss: 0.498578 Train acc: 0.806358 Valid acc: 0.785015\n",
      "Epoch: 92/300 Train loss: 0.415877 Valid loss: 0.498339 Train acc: 0.807104 Valid acc: 0.785375\n",
      "Epoch: 93/300 Train loss: 0.414639 Valid loss: 0.498087 Train acc: 0.807824 Valid acc: 0.785719\n",
      "Epoch: 94/300 Train loss: 0.413414 Valid loss: 0.497871 Train acc: 0.808533 Valid acc: 0.786059\n",
      "Epoch: 95/300 Train loss: 0.412209 Valid loss: 0.497649 Train acc: 0.809243 Valid acc: 0.786395\n",
      "Epoch: 96/300 Train loss: 0.410992 Valid loss: 0.497437 Train acc: 0.809964 Valid acc: 0.786737\n",
      "Epoch: 97/300 Train loss: 0.409795 Valid loss: 0.497251 Train acc: 0.810660 Valid acc: 0.787075\n",
      "Epoch: 98/300 Train loss: 0.408608 Valid loss: 0.497064 Train acc: 0.811352 Valid acc: 0.787420\n",
      "Epoch: 99/300 Train loss: 0.407420 Valid loss: 0.496898 Train acc: 0.812025 Valid acc: 0.787755\n",
      "Epoch: 100/300 Train loss: 0.406211 Valid loss: 0.496728 Train acc: 0.812731 Valid acc: 0.788096\n",
      "Epoch: 101/300 Train loss: 0.405048 Valid loss: 0.496566 Train acc: 0.813421 Valid acc: 0.788434\n",
      "Epoch: 102/300 Train loss: 0.403868 Valid loss: 0.496410 Train acc: 0.814126 Valid acc: 0.788761\n",
      "Epoch: 103/300 Train loss: 0.402713 Valid loss: 0.496295 Train acc: 0.814799 Valid acc: 0.789076\n",
      "Epoch: 104/300 Train loss: 0.401568 Valid loss: 0.496172 Train acc: 0.815464 Valid acc: 0.789383\n",
      "Epoch: 105/300 Train loss: 0.400429 Valid loss: 0.496048 Train acc: 0.816135 Valid acc: 0.789679\n",
      "Epoch: 106/300 Train loss: 0.399313 Valid loss: 0.495927 Train acc: 0.816780 Valid acc: 0.789961\n",
      "Epoch: 107/300 Train loss: 0.398170 Valid loss: 0.495832 Train acc: 0.817442 Valid acc: 0.790225\n",
      "Epoch: 108/300 Train loss: 0.397034 Valid loss: 0.495749 Train acc: 0.818098 Valid acc: 0.790489\n",
      "Epoch: 109/300 Train loss: 0.395905 Valid loss: 0.495667 Train acc: 0.818742 Valid acc: 0.790757\n",
      "Epoch: 110/300 Train loss: 0.394811 Valid loss: 0.495612 Train acc: 0.819373 Valid acc: 0.791015\n",
      "Epoch: 111/300 Train loss: 0.393710 Valid loss: 0.495559 Train acc: 0.820008 Valid acc: 0.791276\n",
      "Epoch: 112/300 Train loss: 0.392624 Valid loss: 0.495521 Train acc: 0.820627 Valid acc: 0.791537\n",
      "Epoch: 113/300 Train loss: 0.391521 Valid loss: 0.495515 Train acc: 0.821279 Valid acc: 0.791777\n",
      "Epoch: 114/300 Train loss: 0.390407 Valid loss: 0.495496 Train acc: 0.821912 Valid acc: 0.792015\n",
      "Epoch: 115/300 Train loss: 0.389351 Valid loss: 0.495497 Train acc: 0.822517 Valid acc: 0.792235\n",
      "Epoch: 116/300 Train loss: 0.388263 Valid loss: 0.495492 Train acc: 0.823146 Valid acc: 0.792468\n",
      "Epoch: 117/300 Train loss: 0.387185 Valid loss: 0.495513 Train acc: 0.823756 Valid acc: 0.792695\n",
      "Epoch: 118/300 Train loss: 0.386129 Valid loss: 0.495543 Train acc: 0.824355 Valid acc: 0.792917\n",
      "Epoch: 119/300 Train loss: 0.385085 Valid loss: 0.495571 Train acc: 0.824935 Valid acc: 0.793147\n",
      "Epoch: 120/300 Train loss: 0.384057 Valid loss: 0.495634 Train acc: 0.825530 Valid acc: 0.793351\n",
      "Epoch: 121/300 Train loss: 0.383031 Valid loss: 0.495676 Train acc: 0.826123 Valid acc: 0.793569\n",
      "Epoch: 122/300 Train loss: 0.381999 Valid loss: 0.495738 Train acc: 0.826723 Valid acc: 0.793767\n",
      "Epoch: 123/300 Train loss: 0.380976 Valid loss: 0.495804 Train acc: 0.827294 Valid acc: 0.793962\n",
      "Epoch: 124/300 Train loss: 0.379954 Valid loss: 0.495853 Train acc: 0.827874 Valid acc: 0.794185\n",
      "Epoch: 125/300 Train loss: 0.378931 Valid loss: 0.495951 Train acc: 0.828467 Valid acc: 0.794342\n",
      "Epoch: 126/300 Train loss: 0.377929 Valid loss: 0.496025 Train acc: 0.829012 Valid acc: 0.794533\n",
      "Epoch: 127/300 Train loss: 0.376912 Valid loss: 0.496121 Train acc: 0.829598 Valid acc: 0.794706\n",
      "Epoch: 128/300 Train loss: 0.375914 Valid loss: 0.496227 Train acc: 0.830157 Valid acc: 0.794866\n",
      "Epoch: 129/300 Train loss: 0.374908 Valid loss: 0.496314 Train acc: 0.830718 Valid acc: 0.795043\n",
      "Epoch: 130/300 Train loss: 0.373910 Valid loss: 0.496447 Train acc: 0.831297 Valid acc: 0.795178\n",
      "Epoch: 131/300 Train loss: 0.372905 Valid loss: 0.496567 Train acc: 0.831846 Valid acc: 0.795333\n",
      "Epoch: 132/300 Train loss: 0.371909 Valid loss: 0.496708 Train acc: 0.832412 Valid acc: 0.795464\n",
      "Epoch: 133/300 Train loss: 0.370957 Valid loss: 0.496885 Train acc: 0.832949 Valid acc: 0.795585\n",
      "Epoch: 134/300 Train loss: 0.369975 Valid loss: 0.497024 Train acc: 0.833509 Valid acc: 0.795722\n",
      "Epoch: 135/300 Train loss: 0.369004 Valid loss: 0.497233 Train acc: 0.834062 Valid acc: 0.795823\n",
      "Epoch: 136/300 Train loss: 0.368015 Valid loss: 0.497399 Train acc: 0.834615 Valid acc: 0.795937\n",
      "Epoch: 137/300 Train loss: 0.367044 Valid loss: 0.497604 Train acc: 0.835168 Valid acc: 0.796044\n",
      "Epoch: 138/300 Train loss: 0.366080 Valid loss: 0.497830 Train acc: 0.835703 Valid acc: 0.796158\n",
      "Epoch: 139/300 Train loss: 0.365119 Valid loss: 0.498025 Train acc: 0.836249 Valid acc: 0.796293\n",
      "Epoch: 140/300 Train loss: 0.364169 Valid loss: 0.498256 Train acc: 0.836778 Valid acc: 0.796393\n",
      "Epoch: 141/300 Train loss: 0.363218 Valid loss: 0.498450 Train acc: 0.837310 Valid acc: 0.796506\n",
      "Epoch: 142/300 Train loss: 0.362286 Valid loss: 0.498697 Train acc: 0.837815 Valid acc: 0.796609\n",
      "Epoch: 143/300 Train loss: 0.361340 Valid loss: 0.498916 Train acc: 0.838336 Valid acc: 0.796725\n",
      "Epoch: 144/300 Train loss: 0.360403 Valid loss: 0.499162 Train acc: 0.838873 Valid acc: 0.796820\n",
      "Epoch: 145/300 Train loss: 0.359461 Valid loss: 0.499426 Train acc: 0.839392 Valid acc: 0.796916\n",
      "Epoch: 146/300 Train loss: 0.358529 Valid loss: 0.499682 Train acc: 0.839915 Valid acc: 0.797018\n",
      "Epoch: 147/300 Train loss: 0.357603 Valid loss: 0.499949 Train acc: 0.840425 Valid acc: 0.797122\n",
      "Epoch: 148/300 Train loss: 0.356690 Valid loss: 0.500224 Train acc: 0.840930 Valid acc: 0.797227\n",
      "Epoch: 149/300 Train loss: 0.355747 Valid loss: 0.500512 Train acc: 0.841473 Valid acc: 0.797331\n",
      "Epoch: 150/300 Train loss: 0.354828 Valid loss: 0.500804 Train acc: 0.841983 Valid acc: 0.797433\n",
      "Epoch: 151/300 Train loss: 0.353916 Valid loss: 0.501115 Train acc: 0.842481 Valid acc: 0.797525\n",
      "Epoch: 152/300 Train loss: 0.352997 Valid loss: 0.501402 Train acc: 0.842985 Valid acc: 0.797625\n",
      "Epoch: 153/300 Train loss: 0.352088 Valid loss: 0.501718 Train acc: 0.843490 Valid acc: 0.797709\n",
      "Epoch: 154/300 Train loss: 0.351168 Valid loss: 0.502027 Train acc: 0.843994 Valid acc: 0.797798\n",
      "Epoch: 155/300 Train loss: 0.350272 Valid loss: 0.502324 Train acc: 0.844489 Valid acc: 0.797884\n",
      "Epoch: 156/300 Train loss: 0.349378 Valid loss: 0.502649 Train acc: 0.844989 Valid acc: 0.797966\n",
      "Epoch: 157/300 Train loss: 0.348480 Valid loss: 0.502962 Train acc: 0.845490 Valid acc: 0.798051\n",
      "Epoch: 158/300 Train loss: 0.347608 Valid loss: 0.503286 Train acc: 0.845967 Valid acc: 0.798132\n",
      "Epoch: 159/300 Train loss: 0.346722 Valid loss: 0.503605 Train acc: 0.846449 Valid acc: 0.798216\n",
      "Epoch: 160/300 Train loss: 0.345854 Valid loss: 0.503946 Train acc: 0.846921 Valid acc: 0.798292\n",
      "Epoch: 161/300 Train loss: 0.344969 Valid loss: 0.504301 Train acc: 0.847396 Valid acc: 0.798367\n",
      "Epoch: 162/300 Train loss: 0.344084 Valid loss: 0.504642 Train acc: 0.847879 Valid acc: 0.798448\n",
      "Epoch: 163/300 Train loss: 0.343218 Valid loss: 0.505004 Train acc: 0.848352 Valid acc: 0.798526\n",
      "Epoch: 164/300 Train loss: 0.342353 Valid loss: 0.505372 Train acc: 0.848820 Valid acc: 0.798605\n",
      "Epoch: 165/300 Train loss: 0.341491 Valid loss: 0.505721 Train acc: 0.849284 Valid acc: 0.798690\n",
      "Epoch: 166/300 Train loss: 0.340632 Valid loss: 0.506116 Train acc: 0.849747 Valid acc: 0.798765\n",
      "Epoch: 167/300 Train loss: 0.339779 Valid loss: 0.506507 Train acc: 0.850227 Valid acc: 0.798836\n",
      "Epoch: 168/300 Train loss: 0.338934 Valid loss: 0.506855 Train acc: 0.850682 Valid acc: 0.798920\n",
      "Epoch: 169/300 Train loss: 0.338091 Valid loss: 0.507254 Train acc: 0.851144 Valid acc: 0.798992\n",
      "Epoch: 170/300 Train loss: 0.337263 Valid loss: 0.507638 Train acc: 0.851605 Valid acc: 0.799072\n",
      "Epoch: 171/300 Train loss: 0.336403 Valid loss: 0.508034 Train acc: 0.852057 Valid acc: 0.799152\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172/300 Train loss: 0.335571 Valid loss: 0.508452 Train acc: 0.852514 Valid acc: 0.799220\n",
      "Epoch: 173/300 Train loss: 0.334733 Valid loss: 0.508836 Train acc: 0.852964 Valid acc: 0.799305\n",
      "Epoch: 174/300 Train loss: 0.333909 Valid loss: 0.509223 Train acc: 0.853419 Valid acc: 0.799381\n",
      "Epoch: 175/300 Train loss: 0.333080 Valid loss: 0.509654 Train acc: 0.853868 Valid acc: 0.799450\n",
      "Epoch: 176/300 Train loss: 0.332236 Valid loss: 0.510038 Train acc: 0.854322 Valid acc: 0.799530\n",
      "Epoch: 177/300 Train loss: 0.331418 Valid loss: 0.510479 Train acc: 0.854753 Valid acc: 0.799599\n",
      "Epoch: 178/300 Train loss: 0.330595 Valid loss: 0.510924 Train acc: 0.855188 Valid acc: 0.799668\n",
      "Epoch: 179/300 Train loss: 0.329765 Valid loss: 0.511361 Train acc: 0.855626 Valid acc: 0.799746\n",
      "Epoch: 180/300 Train loss: 0.328939 Valid loss: 0.511798 Train acc: 0.856072 Valid acc: 0.799826\n",
      "Epoch: 181/300 Train loss: 0.328123 Valid loss: 0.512248 Train acc: 0.856504 Valid acc: 0.799900\n",
      "Epoch: 182/300 Train loss: 0.327311 Valid loss: 0.512709 Train acc: 0.856931 Valid acc: 0.799963\n",
      "Epoch: 183/300 Train loss: 0.326504 Valid loss: 0.513157 Train acc: 0.857362 Valid acc: 0.800030\n",
      "Epoch: 184/300 Train loss: 0.325705 Valid loss: 0.513636 Train acc: 0.857797 Valid acc: 0.800082\n",
      "Epoch: 185/300 Train loss: 0.324902 Valid loss: 0.514112 Train acc: 0.858234 Valid acc: 0.800134\n",
      "Epoch: 186/300 Train loss: 0.324100 Valid loss: 0.514557 Train acc: 0.858669 Valid acc: 0.800199\n",
      "Epoch: 187/300 Train loss: 0.323299 Valid loss: 0.515050 Train acc: 0.859093 Valid acc: 0.800250\n",
      "Epoch: 188/300 Train loss: 0.322496 Valid loss: 0.515485 Train acc: 0.859521 Valid acc: 0.800311\n",
      "Epoch: 189/300 Train loss: 0.321669 Valid loss: 0.515949 Train acc: 0.859959 Valid acc: 0.800372\n",
      "Epoch: 190/300 Train loss: 0.320891 Valid loss: 0.516453 Train acc: 0.860374 Valid acc: 0.800430\n",
      "Epoch: 191/300 Train loss: 0.320106 Valid loss: 0.516920 Train acc: 0.860795 Valid acc: 0.800493\n",
      "Epoch: 192/300 Train loss: 0.319311 Valid loss: 0.517405 Train acc: 0.861198 Valid acc: 0.800548\n",
      "Epoch: 193/300 Train loss: 0.318540 Valid loss: 0.517881 Train acc: 0.861598 Valid acc: 0.800608\n",
      "Epoch: 194/300 Train loss: 0.317777 Valid loss: 0.518368 Train acc: 0.862011 Valid acc: 0.800667\n",
      "Epoch: 195/300 Train loss: 0.317004 Valid loss: 0.518853 Train acc: 0.862420 Valid acc: 0.800726\n",
      "Epoch: 196/300 Train loss: 0.316231 Valid loss: 0.519358 Train acc: 0.862832 Valid acc: 0.800774\n",
      "Epoch: 197/300 Train loss: 0.315450 Valid loss: 0.519880 Train acc: 0.863238 Valid acc: 0.800824\n",
      "Epoch: 198/300 Train loss: 0.314679 Valid loss: 0.520413 Train acc: 0.863645 Valid acc: 0.800874\n",
      "Epoch: 199/300 Train loss: 0.313931 Valid loss: 0.520947 Train acc: 0.864035 Valid acc: 0.800924\n",
      "Epoch: 200/300 Train loss: 0.313169 Valid loss: 0.521456 Train acc: 0.864439 Valid acc: 0.800981\n",
      "Epoch: 201/300 Train loss: 0.312408 Valid loss: 0.521976 Train acc: 0.864833 Valid acc: 0.801025\n",
      "Epoch: 202/300 Train loss: 0.311646 Valid loss: 0.522492 Train acc: 0.865227 Valid acc: 0.801066\n",
      "Epoch: 203/300 Train loss: 0.310899 Valid loss: 0.523042 Train acc: 0.865624 Valid acc: 0.801096\n",
      "Epoch: 204/300 Train loss: 0.310144 Valid loss: 0.523562 Train acc: 0.866023 Valid acc: 0.801141\n",
      "Epoch: 205/300 Train loss: 0.309403 Valid loss: 0.524125 Train acc: 0.866414 Valid acc: 0.801173\n",
      "Epoch: 206/300 Train loss: 0.308644 Valid loss: 0.524685 Train acc: 0.866805 Valid acc: 0.801210\n",
      "Epoch: 207/300 Train loss: 0.307911 Valid loss: 0.525234 Train acc: 0.867189 Valid acc: 0.801257\n",
      "Epoch: 208/300 Train loss: 0.307167 Valid loss: 0.525796 Train acc: 0.867574 Valid acc: 0.801297\n",
      "Epoch: 209/300 Train loss: 0.306433 Valid loss: 0.526344 Train acc: 0.867957 Valid acc: 0.801335\n",
      "Epoch: 210/300 Train loss: 0.305712 Valid loss: 0.526931 Train acc: 0.868345 Valid acc: 0.801361\n",
      "Epoch: 211/300 Train loss: 0.304971 Valid loss: 0.527479 Train acc: 0.868730 Valid acc: 0.801410\n",
      "Epoch: 212/300 Train loss: 0.304232 Valid loss: 0.528072 Train acc: 0.869112 Valid acc: 0.801444\n",
      "Epoch: 213/300 Train loss: 0.303508 Valid loss: 0.528652 Train acc: 0.869490 Valid acc: 0.801478\n",
      "Epoch: 214/300 Train loss: 0.302780 Valid loss: 0.529187 Train acc: 0.869876 Valid acc: 0.801527\n",
      "Epoch: 215/300 Train loss: 0.302065 Valid loss: 0.529782 Train acc: 0.870246 Valid acc: 0.801553\n",
      "Epoch: 216/300 Train loss: 0.301335 Valid loss: 0.530344 Train acc: 0.870613 Valid acc: 0.801586\n",
      "Epoch: 217/300 Train loss: 0.300625 Valid loss: 0.530901 Train acc: 0.870977 Valid acc: 0.801624\n",
      "Epoch: 218/300 Train loss: 0.299906 Valid loss: 0.531494 Train acc: 0.871345 Valid acc: 0.801653\n",
      "Epoch: 219/300 Train loss: 0.299201 Valid loss: 0.532084 Train acc: 0.871718 Valid acc: 0.801686\n",
      "Epoch: 220/300 Train loss: 0.298491 Valid loss: 0.532673 Train acc: 0.872079 Valid acc: 0.801719\n",
      "Epoch: 221/300 Train loss: 0.297789 Valid loss: 0.533280 Train acc: 0.872443 Valid acc: 0.801752\n",
      "Epoch: 222/300 Train loss: 0.297101 Valid loss: 0.533874 Train acc: 0.872788 Valid acc: 0.801787\n",
      "Epoch: 223/300 Train loss: 0.296421 Valid loss: 0.534438 Train acc: 0.873138 Valid acc: 0.801825\n",
      "Epoch: 224/300 Train loss: 0.295725 Valid loss: 0.535044 Train acc: 0.873490 Valid acc: 0.801852\n",
      "Epoch: 225/300 Train loss: 0.295048 Valid loss: 0.535645 Train acc: 0.873835 Valid acc: 0.801877\n",
      "Epoch: 226/300 Train loss: 0.294365 Valid loss: 0.536215 Train acc: 0.874186 Valid acc: 0.801913\n",
      "Epoch: 227/300 Train loss: 0.293669 Valid loss: 0.536828 Train acc: 0.874538 Valid acc: 0.801939\n",
      "Epoch: 228/300 Train loss: 0.292979 Valid loss: 0.537449 Train acc: 0.874894 Valid acc: 0.801975\n",
      "Epoch: 229/300 Train loss: 0.292296 Valid loss: 0.538065 Train acc: 0.875245 Valid acc: 0.802013\n",
      "Epoch: 230/300 Train loss: 0.291608 Valid loss: 0.538698 Train acc: 0.875599 Valid acc: 0.802044\n",
      "Epoch: 231/300 Train loss: 0.290914 Valid loss: 0.539317 Train acc: 0.875957 Valid acc: 0.802080\n",
      "Epoch: 232/300 Train loss: 0.290230 Valid loss: 0.539947 Train acc: 0.876313 Valid acc: 0.802110\n",
      "Epoch: 233/300 Train loss: 0.289550 Valid loss: 0.540581 Train acc: 0.876652 Valid acc: 0.802137\n",
      "Epoch: 234/300 Train loss: 0.288869 Valid loss: 0.541222 Train acc: 0.876990 Valid acc: 0.802153\n",
      "Epoch: 235/300 Train loss: 0.288206 Valid loss: 0.541857 Train acc: 0.877325 Valid acc: 0.802172\n",
      "Epoch: 236/300 Train loss: 0.287528 Valid loss: 0.542487 Train acc: 0.877670 Valid acc: 0.802193\n",
      "Epoch: 237/300 Train loss: 0.286867 Valid loss: 0.543130 Train acc: 0.878010 Valid acc: 0.802213\n",
      "Epoch: 238/300 Train loss: 0.286228 Valid loss: 0.543799 Train acc: 0.878328 Valid acc: 0.802231\n",
      "Epoch: 239/300 Train loss: 0.285569 Valid loss: 0.544423 Train acc: 0.878662 Valid acc: 0.802258\n",
      "Epoch: 240/300 Train loss: 0.284903 Valid loss: 0.545089 Train acc: 0.879004 Valid acc: 0.802276\n",
      "Epoch: 241/300 Train loss: 0.284242 Valid loss: 0.545706 Train acc: 0.879335 Valid acc: 0.802307\n",
      "Epoch: 242/300 Train loss: 0.283580 Valid loss: 0.546389 Train acc: 0.879673 Valid acc: 0.802321\n",
      "Epoch: 243/300 Train loss: 0.282922 Valid loss: 0.547019 Train acc: 0.880007 Valid acc: 0.802355\n",
      "Epoch: 244/300 Train loss: 0.282278 Valid loss: 0.547718 Train acc: 0.880332 Valid acc: 0.802368\n",
      "Epoch: 245/300 Train loss: 0.281625 Valid loss: 0.548387 Train acc: 0.880673 Valid acc: 0.802386\n",
      "Epoch: 246/300 Train loss: 0.280986 Valid loss: 0.549037 Train acc: 0.880993 Valid acc: 0.802406\n",
      "Epoch: 247/300 Train loss: 0.280341 Valid loss: 0.549719 Train acc: 0.881309 Valid acc: 0.802417\n",
      "Epoch: 248/300 Train loss: 0.279710 Valid loss: 0.550373 Train acc: 0.881622 Valid acc: 0.802437\n",
      "Epoch: 249/300 Train loss: 0.279065 Valid loss: 0.551023 Train acc: 0.881957 Valid acc: 0.802461\n",
      "Epoch: 250/300 Train loss: 0.278436 Valid loss: 0.551690 Train acc: 0.882270 Valid acc: 0.802474\n",
      "Epoch: 251/300 Train loss: 0.277805 Valid loss: 0.552368 Train acc: 0.882585 Valid acc: 0.802484\n",
      "Epoch: 252/300 Train loss: 0.277174 Valid loss: 0.553036 Train acc: 0.882898 Valid acc: 0.802500\n",
      "Epoch: 253/300 Train loss: 0.276553 Valid loss: 0.553701 Train acc: 0.883207 Valid acc: 0.802516\n",
      "Epoch: 254/300 Train loss: 0.275932 Valid loss: 0.554371 Train acc: 0.883520 Valid acc: 0.802529\n",
      "Epoch: 255/300 Train loss: 0.275302 Valid loss: 0.555060 Train acc: 0.883828 Valid acc: 0.802540\n",
      "Epoch: 256/300 Train loss: 0.274673 Valid loss: 0.555724 Train acc: 0.884140 Valid acc: 0.802566\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 257/300 Train loss: 0.274061 Valid loss: 0.556424 Train acc: 0.884447 Valid acc: 0.802568\n",
      "Epoch: 258/300 Train loss: 0.273442 Valid loss: 0.557092 Train acc: 0.884757 Valid acc: 0.802577\n",
      "Epoch: 259/300 Train loss: 0.272829 Valid loss: 0.557785 Train acc: 0.885062 Valid acc: 0.802585\n",
      "Epoch: 260/300 Train loss: 0.272205 Valid loss: 0.558476 Train acc: 0.885375 Valid acc: 0.802594\n",
      "Epoch: 261/300 Train loss: 0.271592 Valid loss: 0.559189 Train acc: 0.885683 Valid acc: 0.802594\n",
      "Epoch: 262/300 Train loss: 0.270987 Valid loss: 0.559863 Train acc: 0.885983 Valid acc: 0.802610\n",
      "Epoch: 263/300 Train loss: 0.270380 Valid loss: 0.560549 Train acc: 0.886282 Valid acc: 0.802621\n",
      "Epoch: 264/300 Train loss: 0.269778 Valid loss: 0.561298 Train acc: 0.886579 Valid acc: 0.802618\n",
      "Epoch: 265/300 Train loss: 0.269179 Valid loss: 0.562005 Train acc: 0.886874 Valid acc: 0.802622\n",
      "Epoch: 266/300 Train loss: 0.268572 Valid loss: 0.562688 Train acc: 0.887170 Valid acc: 0.802638\n",
      "Epoch: 267/300 Train loss: 0.267977 Valid loss: 0.563408 Train acc: 0.887463 Valid acc: 0.802641\n",
      "Epoch: 268/300 Train loss: 0.267384 Valid loss: 0.564120 Train acc: 0.887754 Valid acc: 0.802651\n",
      "Epoch: 269/300 Train loss: 0.266794 Valid loss: 0.564836 Train acc: 0.888049 Valid acc: 0.802657\n",
      "Epoch: 270/300 Train loss: 0.266208 Valid loss: 0.565536 Train acc: 0.888340 Valid acc: 0.802664\n",
      "Epoch: 271/300 Train loss: 0.265607 Valid loss: 0.566243 Train acc: 0.888638 Valid acc: 0.802668\n",
      "Epoch: 272/300 Train loss: 0.265020 Valid loss: 0.567017 Train acc: 0.888924 Valid acc: 0.802652\n",
      "Epoch: 273/300 Train loss: 0.264439 Valid loss: 0.567731 Train acc: 0.889209 Valid acc: 0.802665\n",
      "Epoch: 274/300 Train loss: 0.263862 Valid loss: 0.568488 Train acc: 0.889496 Valid acc: 0.802652\n",
      "Epoch: 275/300 Train loss: 0.263285 Valid loss: 0.569168 Train acc: 0.889789 Valid acc: 0.802664\n",
      "Epoch: 276/300 Train loss: 0.262715 Valid loss: 0.569880 Train acc: 0.890070 Valid acc: 0.802648\n",
      "Epoch: 277/300 Train loss: 0.262146 Valid loss: 0.570587 Train acc: 0.890352 Valid acc: 0.802637\n",
      "Epoch: 278/300 Train loss: 0.261568 Valid loss: 0.571231 Train acc: 0.890632 Valid acc: 0.802651\n",
      "Epoch: 279/300 Train loss: 0.260996 Valid loss: 0.572006 Train acc: 0.890913 Valid acc: 0.802633\n",
      "Epoch: 280/300 Train loss: 0.260437 Valid loss: 0.572704 Train acc: 0.891187 Valid acc: 0.802628\n",
      "Epoch: 281/300 Train loss: 0.259874 Valid loss: 0.573353 Train acc: 0.891465 Valid acc: 0.802630\n",
      "Epoch: 282/300 Train loss: 0.259311 Valid loss: 0.574106 Train acc: 0.891739 Valid acc: 0.802609\n",
      "Epoch: 283/300 Train loss: 0.258748 Valid loss: 0.574801 Train acc: 0.892020 Valid acc: 0.802604\n",
      "Epoch: 284/300 Train loss: 0.258189 Valid loss: 0.575517 Train acc: 0.892294 Valid acc: 0.802592\n",
      "Epoch: 285/300 Train loss: 0.257627 Valid loss: 0.576280 Train acc: 0.892572 Valid acc: 0.802572\n",
      "Epoch: 286/300 Train loss: 0.257074 Valid loss: 0.577015 Train acc: 0.892843 Valid acc: 0.802560\n",
      "Epoch: 287/300 Train loss: 0.256511 Valid loss: 0.577725 Train acc: 0.893120 Valid acc: 0.802562\n",
      "Epoch: 288/300 Train loss: 0.255951 Valid loss: 0.578484 Train acc: 0.893391 Valid acc: 0.802548\n",
      "Epoch: 289/300 Train loss: 0.255404 Valid loss: 0.579238 Train acc: 0.893659 Valid acc: 0.802538\n",
      "Epoch: 290/300 Train loss: 0.254853 Valid loss: 0.579955 Train acc: 0.893929 Valid acc: 0.802538\n",
      "Epoch: 291/300 Train loss: 0.254305 Valid loss: 0.580737 Train acc: 0.894194 Valid acc: 0.802524\n",
      "Epoch: 292/300 Train loss: 0.253764 Valid loss: 0.581484 Train acc: 0.894460 Valid acc: 0.802520\n",
      "Epoch: 293/300 Train loss: 0.253220 Valid loss: 0.582235 Train acc: 0.894728 Valid acc: 0.802516\n",
      "Epoch: 294/300 Train loss: 0.252676 Valid loss: 0.583021 Train acc: 0.894991 Valid acc: 0.802501\n",
      "Epoch: 295/300 Train loss: 0.252129 Valid loss: 0.583759 Train acc: 0.895252 Valid acc: 0.802498\n",
      "Epoch: 296/300 Train loss: 0.251597 Valid loss: 0.584523 Train acc: 0.895513 Valid acc: 0.802493\n",
      "Epoch: 297/300 Train loss: 0.251063 Valid loss: 0.585308 Train acc: 0.895770 Valid acc: 0.802482\n",
      "Epoch: 298/300 Train loss: 0.250532 Valid loss: 0.586043 Train acc: 0.896029 Valid acc: 0.802486\n",
      "Epoch: 299/300 Train loss: 0.249998 Valid loss: 0.586820 Train acc: 0.896286 Valid acc: 0.802477\n",
      "Epoch: 300/300 Train loss: 0.249471 Valid loss: 0.587602 Train acc: 0.896540 Valid acc: 0.802466\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "# hyperparameters\n",
    "epochs = 300 # num iterations for updating model\n",
    "kernel_size_ratios = 1 # conv size for conv minibatching \n",
    "strides_ratios = 1 # conv stride for conv minibatching\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    # Minibatching techniques tgt batch size: kernel_size_ratio\n",
    "    for k in range(0, kernel_size_ratios, 1):\n",
    "\n",
    "        # Minibatching techniques sampling: strides_ratio\n",
    "        for s in range(0, strides_ratios, 1):\n",
    "\n",
    "            # Loop over epochs\n",
    "            for e in range(0, epochs, 1):\n",
    "\n",
    "                # Loop over batches\n",
    "                for x, y in get_batches2(X_norm=X_train_norm, Y_labels=Y_train, \n",
    "                                         kernel_size_ratio=k+1,\n",
    "                                         strides_ratio=s+1):   \n",
    "\n",
    "                    ######################## Training\n",
    "                    # Feed dictionary\n",
    "                    feed = {inputs_ : x, labels_ : y, keep_prob_ : keep_prob, learning_rate_ : learning_rate}\n",
    "\n",
    "                    # Loss\n",
    "                    loss, _ , acc = sess.run([cost_ave, optimizer, correct_pred_ave], feed_dict = feed)\n",
    "                    train_acc.append(acc)\n",
    "                    train_loss.append(loss)\n",
    "\n",
    "                    ################## Validation\n",
    "                    acc_batch = []\n",
    "                    loss_batch = []    \n",
    "                    # Loop over batches\n",
    "                    for x, y in get_batches2(X_norm=X_valid_norm, Y_labels=Y_valid):\n",
    "\n",
    "                        # Feed dictionary\n",
    "                        feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "                        # Loss\n",
    "                        loss, acc = sess.run([cost_ave, correct_pred_ave], feed_dict = feed)\n",
    "                        acc_batch.append(acc)\n",
    "                        loss_batch.append(loss)\n",
    "\n",
    "                    # Store\n",
    "                    valid_acc.append(np.mean(acc_batch))\n",
    "                    valid_loss.append(np.mean(loss_batch))\n",
    "\n",
    "                # Print info for every iter/epoch\n",
    "                print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "#                       \"kernel_size_ratio: {}/{}\".format(k+1, kernel_size_ratios),\n",
    "#                       \"strides_ratio: {}/{}\".format(s+1, strides_ratios),\n",
    "                      \"Train loss: {:6f}\".format(np.mean(train_loss)),\n",
    "                      \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "                      \"Train acc: {:6f}\".format(np.mean(train_acc)),\n",
    "                      \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "                \n",
    "    saver.save(sess,\"checkpoints/dcnn-face.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8e04c26a0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='Face train_loss')\n",
    "mplot.plot(valid_loss, label='Face valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nuxBC1EOS3IUQoh6S5C6EEPXQ/wOqVV77wnu1ngAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd8bc668f60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "mplot.plot(train_acc, label='Face train_acc')\n",
    "mplot.plot(valid_acc, label='Face valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dcnn-face.ckpt\n"
     ]
    }
   ],
   "source": [
    "listcost_ave, listcorrect_pred_ave, listconfusion = [], [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints/'))\n",
    "    \n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(batch_size=100, X=X_test_norm, y=Y_test_onehot):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "        # Loss\n",
    "        arrcost_ave, arrcorrect_pred_ave, arrconfusion = sess.run([\n",
    "            cost_ave, correct_pred_ave, confusion], feed_dict = feed)\n",
    "        \n",
    "        listcost_ave.append(arrcost_ave) \n",
    "        listcorrect_pred_ave.append(arrcorrect_pred_ave)\n",
    "        listconfusion.append(arrconfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(56, 56, 56)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(listcorrect_pred_ave), len(listcost_ave), len(listconfusion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_ave_mean, correct_pred_ave_mean, confusion_mean.shape: 0.453767 0.865536 (2, 2)\n"
     ]
    }
   ],
   "source": [
    "cost_ave_mean = np.array(listcost_ave, dtype=arrcost_ave.dtype).mean(axis=0)\n",
    "correct_pred_ave_mean = np.array(listcorrect_pred_ave, dtype=arrcorrect_pred_ave.dtype).mean(axis=0)\n",
    "confusion_mean = np.array(listconfusion, dtype=arrconfusion.dtype).mean(axis=0)\n",
    "print('cost_ave_mean, correct_pred_ave_mean, confusion_mean.shape:', \n",
    "     cost_ave_mean, correct_pred_ave_mean, confusion_mean.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 74.21428571,   8.55357143],\n",
       "       [  4.89285714,  12.33928571]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accuracy or 1- loss\n",
    "accuracy = (confusion_mean[0, 0] + confusion_mean[1, 1])/ (confusion_mean[0, 0] + confusion_mean[0, 1] + \n",
    "                                                confusion_mean[1, 0] + confusion_mean[1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(correct_pred_ave_mean - accuracy): 2.17982700779e-08\n"
     ]
    }
   ],
   "source": [
    "print('(correct_pred_ave_mean - accuracy):', correct_pred_ave_mean - accuracy)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss or (1-acc): 0.134464285714\n"
     ]
    }
   ],
   "source": [
    "# accuracy or 1- loss\n",
    "loss = (confusion_mean[1, 0] + confusion_mean[0, 1])/ (confusion_mean[0, 0] + confusion_mean[0, 1] + \n",
    "                                                       confusion_mean[1, 0] + confusion_mean[1, 1])\n",
    "print('loss or (1-acc):', loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sensitivity: 0.938148984199\n"
     ]
    }
   ],
   "source": [
    "# sensitivity: TruePos rate\n",
    "# 1st col or true prediction condition\n",
    "sensitivity = confusion_mean[0, 0]/ (confusion_mean[0, 0] + \n",
    "                                     confusion_mean[1, 0])\n",
    "print('sensitivity:', sensitivity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "specificity: 0.590598290598\n"
     ]
    }
   ],
   "source": [
    "# specificity: TrueNeg rate\n",
    "# 2nd col or false prediction condition\n",
    "# (1st row, 2nd col)/ \n",
    "specificity = confusion_mean[1, 1]/ (confusion_mean[0, 1] + \n",
    "                                     confusion_mean[1, 1])\n",
    "print('specificity:', specificity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "precision: 0.89665587918\n"
     ]
    }
   ],
   "source": [
    "# precision: TP / (TP + FP)\n",
    "precision = confusion_mean[0, 0]/ (confusion_mean[0, 0] + confusion_mean[0, 1])\n",
    "print('precision:', precision)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total: 100.0\n"
     ]
    }
   ],
   "source": [
    "print('total:', (confusion_mean[0, 0] + confusion_mean[0, 1] + confusion_mean[1, 0] + confusion_mean[1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAARUAAAD8CAYAAABZ0jAcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fd87dfa9cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mplot.imshow(confusion_mean)\n",
    "mplot.show()\n",
    "mplot.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
