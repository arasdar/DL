{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"../../data/har-data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"../../data/har-data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train, \n",
    "                                                stratify = labels_train,\n",
    "                                                random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct inputs to LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(inputs_, [1,0,2]) # reshape into (seq_len, N, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_channels]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass, cost function and optimizer:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints') == False):\n",
    "    !mkdir checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.847266 Train acc: 0.103333\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.837416 Train acc: 0.121667\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.835993 Train acc: 0.116667\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.813084 Train acc: 0.160000\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.809562 Train acc: 0.151667\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.796237 Validation acc: 0.161111\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.797853 Train acc: 0.173333\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.800327 Train acc: 0.161667\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.766620 Train acc: 0.240000\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.766606 Train acc: 0.235000\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.744391 Train acc: 0.256667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.742686 Validation acc: 0.326667\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.748151 Train acc: 0.278333\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.731008 Train acc: 0.311667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.711746 Train acc: 0.313333\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.721588 Train acc: 0.296667\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.703976 Train acc: 0.348333\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.688772 Validation acc: 0.383333\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.684421 Train acc: 0.356667\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.702447 Train acc: 0.330000\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.677991 Train acc: 0.341667\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.632227 Train acc: 0.416667\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.655406 Train acc: 0.351667\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.631056 Validation acc: 0.428889\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.633909 Train acc: 0.385000\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.619319 Train acc: 0.385000\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.628367 Train acc: 0.386667\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.624659 Train acc: 0.393333\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.615118 Train acc: 0.376667\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.570167 Validation acc: 0.453333\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.602055 Train acc: 0.405000\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.584023 Train acc: 0.411667\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.532085 Train acc: 0.478333\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.555772 Train acc: 0.408333\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.527266 Train acc: 0.415000\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.507967 Validation acc: 0.467778\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.523703 Train acc: 0.416667\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.521440 Train acc: 0.420000\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.535577 Train acc: 0.418333\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.513901 Train acc: 0.420000\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.501778 Train acc: 0.435000\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.449998 Validation acc: 0.485556\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.518534 Train acc: 0.425000\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.431911 Train acc: 0.456667\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.444080 Train acc: 0.441667\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.422854 Train acc: 0.440000\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.431278 Train acc: 0.450000\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.398954 Validation acc: 0.503889\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.444867 Train acc: 0.430000\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.438376 Train acc: 0.438333\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.421006 Train acc: 0.451667\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.437390 Train acc: 0.410000\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.427173 Train acc: 0.458333\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.353169 Validation acc: 0.512222\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.362642 Train acc: 0.471667\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.358374 Train acc: 0.490000\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.334413 Train acc: 0.500000\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.336371 Train acc: 0.503333\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.376323 Train acc: 0.495000\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 1.308199 Validation acc: 0.529444\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.355148 Train acc: 0.463333\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.341646 Train acc: 0.515000\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.363108 Train acc: 0.473333\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.328793 Train acc: 0.521667\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.293986 Train acc: 0.523333\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 1.261251 Validation acc: 0.551111\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.279808 Train acc: 0.541667\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 1.246502 Train acc: 0.546667\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.270068 Train acc: 0.538333\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 1.296384 Train acc: 0.516667\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 1.293939 Train acc: 0.500000\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 1.211149 Validation acc: 0.578889\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 1.260306 Train acc: 0.550000\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 1.275067 Train acc: 0.528333\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 1.242535 Train acc: 0.578333\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 1.196354 Train acc: 0.561667\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 1.191989 Train acc: 0.563333\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 1.157320 Validation acc: 0.587778\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 1.174906 Train acc: 0.565000\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 1.178519 Train acc: 0.571667\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 1.194424 Train acc: 0.545000\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 1.205759 Train acc: 0.540000\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 1.164538 Train acc: 0.551667\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 1.099991 Validation acc: 0.591111\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 1.176610 Train acc: 0.565000\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 1.147282 Train acc: 0.580000\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 1.118525 Train acc: 0.578333\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 1.100332 Train acc: 0.598333\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 1.066583 Train acc: 0.620000\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 1.043916 Validation acc: 0.607222\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 1.092267 Train acc: 0.576667\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 1.131080 Train acc: 0.561667\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 1.116004 Train acc: 0.570000\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 1.064563 Train acc: 0.606667\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 1.076164 Train acc: 0.605000\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.988510 Validation acc: 0.634444\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 1.054192 Train acc: 0.621667\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 1.027979 Train acc: 0.631667\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 1.014740 Train acc: 0.631667\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.975789 Train acc: 0.650000\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 1.018189 Train acc: 0.600000\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.937002 Validation acc: 0.650556\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 1.026115 Train acc: 0.593333\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 1.038874 Train acc: 0.605000\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.964345 Train acc: 0.651667\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 1.009761 Train acc: 0.613333\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.974584 Train acc: 0.641667\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.891038 Validation acc: 0.660556\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.966942 Train acc: 0.633333\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.918384 Train acc: 0.661667\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.918784 Train acc: 0.635000\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.942323 Train acc: 0.631667\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.951407 Train acc: 0.660000\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.853031 Validation acc: 0.664444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.967682 Train acc: 0.628333\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.899454 Train acc: 0.696667\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.942367 Train acc: 0.645000\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.906175 Train acc: 0.670000\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.904765 Train acc: 0.681667\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.821274 Validation acc: 0.675000\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.851567 Train acc: 0.691667\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.870752 Train acc: 0.668333\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.885930 Train acc: 0.651667\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.906606 Train acc: 0.651667\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.894072 Train acc: 0.635000\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.793299 Validation acc: 0.681111\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.862010 Train acc: 0.666667\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.890967 Train acc: 0.670000\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.873157 Train acc: 0.663333\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.833435 Train acc: 0.686667\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.849401 Train acc: 0.655000\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.769438 Validation acc: 0.681111\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.812819 Train acc: 0.673333\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.852513 Train acc: 0.666667\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.849849 Train acc: 0.673333\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.868353 Train acc: 0.638333\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.813141 Train acc: 0.675000\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.747685 Validation acc: 0.686111\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.833983 Train acc: 0.683333\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.830702 Train acc: 0.666667\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.813925 Train acc: 0.680000\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.789673 Train acc: 0.670000\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.780384 Train acc: 0.696667\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.731061 Validation acc: 0.696667\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.820819 Train acc: 0.676667\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.831585 Train acc: 0.653333\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.838499 Train acc: 0.636667\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.762634 Train acc: 0.713333\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.807968 Train acc: 0.675000\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.713849 Validation acc: 0.700556\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.813995 Train acc: 0.676667\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.768576 Train acc: 0.706667\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.777350 Train acc: 0.703333\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.757123 Train acc: 0.676667\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.791932 Train acc: 0.696667\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.698085 Validation acc: 0.712222\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.759861 Train acc: 0.705000\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.823580 Train acc: 0.656667\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.750450 Train acc: 0.725000\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.813205 Train acc: 0.676667\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.771663 Train acc: 0.700000\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.680806 Validation acc: 0.735000\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.752177 Train acc: 0.721667\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.739701 Train acc: 0.716667\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.735493 Train acc: 0.706667\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.760728 Train acc: 0.708333\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.771347 Train acc: 0.676667\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.662719 Validation acc: 0.756111\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.776390 Train acc: 0.680000\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.704411 Train acc: 0.740000\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.764530 Train acc: 0.738333\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.727430 Train acc: 0.706667\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.707459 Train acc: 0.743333\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.642216 Validation acc: 0.768889\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.704581 Train acc: 0.740000\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.694170 Train acc: 0.731667\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.738631 Train acc: 0.731667\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.717162 Train acc: 0.721667\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.735154 Train acc: 0.725000\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.618269 Validation acc: 0.779444\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.696284 Train acc: 0.728333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.727802 Train acc: 0.715000\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.717316 Train acc: 0.740000\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.677345 Train acc: 0.763333\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.657872 Train acc: 0.773333\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.592209 Validation acc: 0.799444\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.654147 Train acc: 0.753333\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.664484 Train acc: 0.758333\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.677313 Train acc: 0.733333\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.691451 Train acc: 0.753333\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.645544 Train acc: 0.761667\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.568217 Validation acc: 0.802222\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.693639 Train acc: 0.740000\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.676719 Train acc: 0.761667\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.651421 Train acc: 0.775000\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.658050 Train acc: 0.753333\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.626036 Train acc: 0.768333\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.546702 Validation acc: 0.805000\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.641207 Train acc: 0.761667\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.658893 Train acc: 0.756667\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.664460 Train acc: 0.765000\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.579175 Train acc: 0.786667\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.626203 Train acc: 0.780000\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.530162 Validation acc: 0.806667\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.658673 Train acc: 0.773333\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.634941 Train acc: 0.778333\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.610396 Train acc: 0.765000\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.579504 Train acc: 0.773333\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.617802 Train acc: 0.781667\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.515220 Validation acc: 0.807778\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.604815 Train acc: 0.775000\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.590959 Train acc: 0.796667\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.571581 Train acc: 0.790000\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.613276 Train acc: 0.783333\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.623735 Train acc: 0.773333\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.501018 Validation acc: 0.805556\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.583712 Train acc: 0.773333\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.568233 Train acc: 0.790000\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.523431 Train acc: 0.805000\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.581531 Train acc: 0.771667\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.593666 Train acc: 0.756667\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.489582 Validation acc: 0.804444\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.599583 Train acc: 0.768333\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.538778 Train acc: 0.803333\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.601585 Train acc: 0.791667\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.589068 Train acc: 0.795000\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.548895 Train acc: 0.816667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.478959 Validation acc: 0.806667\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.543131 Train acc: 0.806667\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.532632 Train acc: 0.795000\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.566969 Train acc: 0.798333\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.558893 Train acc: 0.761667\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.572440 Train acc: 0.780000\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.468253 Validation acc: 0.806111\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.514854 Train acc: 0.835000\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.573419 Train acc: 0.795000\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.556118 Train acc: 0.798333\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.539551 Train acc: 0.811667\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.529055 Train acc: 0.821667\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.460305 Validation acc: 0.808333\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.505805 Train acc: 0.806667\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.545807 Train acc: 0.798333\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.564753 Train acc: 0.785000\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.559512 Train acc: 0.790000\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.502624 Train acc: 0.820000\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.447342 Validation acc: 0.810556\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.570472 Train acc: 0.776667\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.543629 Train acc: 0.803333\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.515736 Train acc: 0.810000\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.516788 Train acc: 0.806667\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.515688 Train acc: 0.801667\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.440223 Validation acc: 0.811111\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.546907 Train acc: 0.790000\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.523146 Train acc: 0.803333\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.544281 Train acc: 0.778333\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.486316 Train acc: 0.825000\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.571134 Train acc: 0.760000\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.433814 Validation acc: 0.812778\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.509638 Train acc: 0.823333\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.543489 Train acc: 0.803333\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.489506 Train acc: 0.843333\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.487028 Train acc: 0.805000\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.513190 Train acc: 0.790000\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.425044 Validation acc: 0.812222\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.510801 Train acc: 0.820000\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.524149 Train acc: 0.796667\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.472324 Train acc: 0.816667\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.548561 Train acc: 0.776667\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.510850 Train acc: 0.815000\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.417683 Validation acc: 0.815556\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.485327 Train acc: 0.820000\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.472179 Train acc: 0.816667\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.463703 Train acc: 0.810000\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.505711 Train acc: 0.796667\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.495766 Train acc: 0.813333\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.410063 Validation acc: 0.818889\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.525491 Train acc: 0.801667\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.447779 Train acc: 0.836667\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.537755 Train acc: 0.776667\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.518973 Train acc: 0.810000\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.480270 Train acc: 0.816667\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.407081 Validation acc: 0.817778\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.486106 Train acc: 0.800000\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.454380 Train acc: 0.826667\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.501697 Train acc: 0.816667\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.470388 Train acc: 0.810000\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.486635 Train acc: 0.810000\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.400616 Validation acc: 0.819444\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.457695 Train acc: 0.816667\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.529930 Train acc: 0.785000\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.485886 Train acc: 0.803333\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.468524 Train acc: 0.808333\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.464534 Train acc: 0.823333\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.396568 Validation acc: 0.820000\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.424949 Train acc: 0.826667\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.512925 Train acc: 0.813333\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.490708 Train acc: 0.805000\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.483489 Train acc: 0.803333\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.433765 Train acc: 0.850000\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.388134 Validation acc: 0.821667\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.512686 Train acc: 0.810000\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.491673 Train acc: 0.816667\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.456950 Train acc: 0.838333\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.447529 Train acc: 0.820000\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.441426 Train acc: 0.813333\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.385175 Validation acc: 0.822222\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.470802 Train acc: 0.805000\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.453026 Train acc: 0.808333\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.470589 Train acc: 0.830000\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.444642 Train acc: 0.821667\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.486622 Train acc: 0.791667\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.378752 Validation acc: 0.826111\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.482298 Train acc: 0.821667\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.440000 Train acc: 0.826667\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.446219 Train acc: 0.838333\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.437678 Train acc: 0.838333\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.454146 Train acc: 0.825000\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.374570 Validation acc: 0.827778\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.466471 Train acc: 0.790000\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.455261 Train acc: 0.828333\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.434453 Train acc: 0.836667\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.502166 Train acc: 0.810000\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.460765 Train acc: 0.815000\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.370580 Validation acc: 0.831111\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.422740 Train acc: 0.836667\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.451784 Train acc: 0.853333\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.409496 Train acc: 0.838333\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.434536 Train acc: 0.821667\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.457387 Train acc: 0.818333\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.363976 Validation acc: 0.835000\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.487405 Train acc: 0.791667\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.426827 Train acc: 0.830000\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.466070 Train acc: 0.823333\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.442883 Train acc: 0.836667\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.434489 Train acc: 0.821667\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.363972 Validation acc: 0.836111\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.430061 Train acc: 0.825000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.391348 Train acc: 0.831667\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.461262 Train acc: 0.795000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.441010 Train acc: 0.826667\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.481783 Train acc: 0.795000\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.357351 Validation acc: 0.836111\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.422833 Train acc: 0.835000\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.456751 Train acc: 0.821667\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.444896 Train acc: 0.825000\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.421713 Train acc: 0.835000\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.428455 Train acc: 0.840000\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.352202 Validation acc: 0.843889\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.391306 Train acc: 0.846667\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.433121 Train acc: 0.828333\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.446918 Train acc: 0.815000\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.438688 Train acc: 0.828333\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.395979 Train acc: 0.850000\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.347347 Validation acc: 0.844444\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.431340 Train acc: 0.846667\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.451049 Train acc: 0.810000\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.423523 Train acc: 0.848333\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.420335 Train acc: 0.846667\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.386765 Train acc: 0.851667\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.351502 Validation acc: 0.843889\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.439730 Train acc: 0.840000\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.416688 Train acc: 0.843333\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.422049 Train acc: 0.835000\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.394922 Train acc: 0.845000\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.433390 Train acc: 0.836667\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.346267 Validation acc: 0.852222\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.414863 Train acc: 0.835000\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.393902 Train acc: 0.848333\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.394242 Train acc: 0.846667\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.399057 Train acc: 0.848333\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.424515 Train acc: 0.845000\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.344756 Validation acc: 0.852222\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.427948 Train acc: 0.821667\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.405592 Train acc: 0.836667\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.382399 Train acc: 0.860000\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.447560 Train acc: 0.830000\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.427583 Train acc: 0.826667\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.336301 Validation acc: 0.855000\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.411693 Train acc: 0.838333\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.404727 Train acc: 0.848333\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.376952 Train acc: 0.868333\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.409355 Train acc: 0.848333\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.400547 Train acc: 0.830000\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.336493 Validation acc: 0.858889\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.411784 Train acc: 0.833333\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.375113 Train acc: 0.868333\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.420832 Train acc: 0.840000\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.409269 Train acc: 0.850000\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.408091 Train acc: 0.843333\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.330800 Validation acc: 0.861111\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.389106 Train acc: 0.866667\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.353712 Train acc: 0.855000\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.415176 Train acc: 0.833333\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.410828 Train acc: 0.855000\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.410227 Train acc: 0.850000\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.327397 Validation acc: 0.863889\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.381194 Train acc: 0.856667\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.444808 Train acc: 0.833333\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.427624 Train acc: 0.855000\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.393203 Train acc: 0.853333\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.369732 Train acc: 0.861667\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.320153 Validation acc: 0.865556\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.357579 Train acc: 0.866667\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.387983 Train acc: 0.873333\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.404127 Train acc: 0.868333\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.411379 Train acc: 0.841667\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.379392 Train acc: 0.856667\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.319265 Validation acc: 0.872222\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.407900 Train acc: 0.858333\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.385225 Train acc: 0.863333\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.389948 Train acc: 0.858333\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.368250 Train acc: 0.861667\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.339439 Train acc: 0.875000\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.310223 Validation acc: 0.875556\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.373456 Train acc: 0.875000\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.379055 Train acc: 0.858333\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.392920 Train acc: 0.861667\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.362744 Train acc: 0.880000\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.388203 Train acc: 0.876667\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.306972 Validation acc: 0.890000\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.415173 Train acc: 0.845000\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.360643 Train acc: 0.858333\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.366103 Train acc: 0.885000\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.329009 Train acc: 0.895000\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.370606 Train acc: 0.883333\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.296935 Validation acc: 0.891667\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.372578 Train acc: 0.865000\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.346226 Train acc: 0.885000\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.315404 Train acc: 0.910000\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.381837 Train acc: 0.880000\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.410697 Train acc: 0.855000\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.293707 Validation acc: 0.899444\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.355617 Train acc: 0.878333\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.354846 Train acc: 0.885000\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.338090 Train acc: 0.890000\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.363982 Train acc: 0.883333\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.352618 Train acc: 0.896667\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.285841 Validation acc: 0.909444\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.353878 Train acc: 0.888333\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.329254 Train acc: 0.910000\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.352287 Train acc: 0.895000\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.356453 Train acc: 0.883333\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.358050 Train acc: 0.888333\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.276139 Validation acc: 0.914444\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.324271 Train acc: 0.911667\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.313698 Train acc: 0.903333\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.331407 Train acc: 0.923333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.374840 Train acc: 0.893333\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.360467 Train acc: 0.891667\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.265312 Validation acc: 0.921111\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.291478 Train acc: 0.923333\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.378859 Train acc: 0.895000\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.328964 Train acc: 0.903333\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.321303 Train acc: 0.908333\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.335599 Train acc: 0.910000\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.258850 Validation acc: 0.924444\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.310507 Train acc: 0.906667\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.332957 Train acc: 0.923333\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.290689 Train acc: 0.930000\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.350594 Train acc: 0.908333\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.277100 Train acc: 0.931667\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.247292 Validation acc: 0.926111\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.359610 Train acc: 0.905000\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.316853 Train acc: 0.926667\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.280118 Train acc: 0.938333\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.293628 Train acc: 0.928333\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.276440 Train acc: 0.928333\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.243419 Validation acc: 0.927778\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.298542 Train acc: 0.908333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.329235 Train acc: 0.908333\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.314667 Train acc: 0.918333\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.292237 Train acc: 0.918333\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.334527 Train acc: 0.903333\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.233363 Validation acc: 0.928333\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.326050 Train acc: 0.906667\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.291475 Train acc: 0.925000\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.295812 Train acc: 0.926667\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.255702 Train acc: 0.925000\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.263441 Train acc: 0.930000\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.231449 Validation acc: 0.931667\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.311565 Train acc: 0.915000\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.311339 Train acc: 0.911667\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.270761 Train acc: 0.943333\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.333917 Train acc: 0.903333\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.305067 Train acc: 0.915000\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.227684 Validation acc: 0.931111\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.284772 Train acc: 0.926667\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.282834 Train acc: 0.925000\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.276966 Train acc: 0.918333\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.288092 Train acc: 0.930000\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.295411 Train acc: 0.928333\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.224107 Validation acc: 0.931667\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.297613 Train acc: 0.923333\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.255917 Train acc: 0.941667\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.351335 Train acc: 0.903333\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.305641 Train acc: 0.910000\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.289728 Train acc: 0.921667\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.222339 Validation acc: 0.932778\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.246563 Train acc: 0.945000\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.260313 Train acc: 0.928333\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.275461 Train acc: 0.938333\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.258110 Train acc: 0.943333\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.291146 Train acc: 0.915000\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.206012 Validation acc: 0.938889\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.236122 Train acc: 0.946667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.307338 Train acc: 0.913333\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.292672 Train acc: 0.940000\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.263223 Train acc: 0.935000\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.266615 Train acc: 0.928333\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.202525 Validation acc: 0.940556\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.260989 Train acc: 0.925000\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.247546 Train acc: 0.945000\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.267114 Train acc: 0.950000\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.284484 Train acc: 0.928333\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.226480 Train acc: 0.948333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.199658 Validation acc: 0.943889\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.297865 Train acc: 0.928333\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.271427 Train acc: 0.938333\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.267236 Train acc: 0.926667\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.241020 Train acc: 0.943333\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.236552 Train acc: 0.940000\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.191931 Validation acc: 0.945000\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.262916 Train acc: 0.943333\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.249056 Train acc: 0.940000\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.272354 Train acc: 0.936667\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.237337 Train acc: 0.938333\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.287428 Train acc: 0.916667\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.190282 Validation acc: 0.942778\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.280341 Train acc: 0.943333\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.250972 Train acc: 0.933333\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.228124 Train acc: 0.951667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.224950 Train acc: 0.946667\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.249609 Train acc: 0.948333\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.185385 Validation acc: 0.946111\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.278638 Train acc: 0.931667\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.274634 Train acc: 0.935000\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.206282 Train acc: 0.960000\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.289035 Train acc: 0.921667\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.268234 Train acc: 0.935000\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.180093 Validation acc: 0.946667\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.277734 Train acc: 0.930000\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.228836 Train acc: 0.945000\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.234694 Train acc: 0.941667\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.246522 Train acc: 0.941667\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.249116 Train acc: 0.940000\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.173860 Validation acc: 0.950000\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.243400 Train acc: 0.938333\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.206658 Train acc: 0.965000\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.259304 Train acc: 0.938333\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.264750 Train acc: 0.936667\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.253667 Train acc: 0.925000\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.169228 Validation acc: 0.951111\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.241817 Train acc: 0.935000\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.201772 Train acc: 0.963333\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.222869 Train acc: 0.951667\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.257376 Train acc: 0.941667\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.264451 Train acc: 0.946667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.166826 Validation acc: 0.951111\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.200442 Train acc: 0.960000\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.261164 Train acc: 0.918333\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.240039 Train acc: 0.950000\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.233210 Train acc: 0.935000\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.237820 Train acc: 0.941667\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.167731 Validation acc: 0.952222\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.220885 Train acc: 0.953333\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.248073 Train acc: 0.948333\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.212736 Train acc: 0.958333\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.235305 Train acc: 0.938333\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.191851 Train acc: 0.961667\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.161218 Validation acc: 0.953889\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.255642 Train acc: 0.930000\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.218709 Train acc: 0.953333\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.245990 Train acc: 0.946667\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.197619 Train acc: 0.953333\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.213612 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.162873 Validation acc: 0.950556\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.220036 Train acc: 0.953333\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.234201 Train acc: 0.955000\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.247495 Train acc: 0.945000\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.197604 Train acc: 0.966667\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.254719 Train acc: 0.946667\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.152582 Validation acc: 0.954444\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.227248 Train acc: 0.950000\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.235035 Train acc: 0.946667\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.210395 Train acc: 0.956667\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.218426 Train acc: 0.950000\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.222057 Train acc: 0.955000\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.153807 Validation acc: 0.953333\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.203512 Train acc: 0.950000\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.248125 Train acc: 0.936667\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.178196 Train acc: 0.970000\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.239264 Train acc: 0.941667\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.229430 Train acc: 0.955000\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.151602 Validation acc: 0.953889\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.211251 Train acc: 0.950000\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.201542 Train acc: 0.961667\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.208751 Train acc: 0.951667\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.218922 Train acc: 0.956667\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.202645 Train acc: 0.963333\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.147310 Validation acc: 0.955555\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.225556 Train acc: 0.940000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.175257 Train acc: 0.961667\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.263288 Train acc: 0.936667\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.223906 Train acc: 0.955000\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.210673 Train acc: 0.941667\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.146293 Validation acc: 0.956667\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.211397 Train acc: 0.948333\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.197515 Train acc: 0.951667\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.205218 Train acc: 0.958333\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.218881 Train acc: 0.958333\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.221308 Train acc: 0.946667\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.150572 Validation acc: 0.954444\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.196305 Train acc: 0.966667\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.257735 Train acc: 0.936667\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.214500 Train acc: 0.956667\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.207555 Train acc: 0.935000\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.197712 Train acc: 0.943333\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.148875 Validation acc: 0.953333\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.200769 Train acc: 0.945000\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.207711 Train acc: 0.955000\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.206972 Train acc: 0.961667\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.206587 Train acc: 0.951667\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.161883 Train acc: 0.970000\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.147561 Validation acc: 0.952222\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.266056 Train acc: 0.931667\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.231546 Train acc: 0.945000\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.204976 Train acc: 0.953333\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.206851 Train acc: 0.958333\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.181379 Train acc: 0.960000\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.143399 Validation acc: 0.952778\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.197094 Train acc: 0.958333\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.187758 Train acc: 0.953333\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.208522 Train acc: 0.955000\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.163595 Train acc: 0.965000\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.244882 Train acc: 0.936667\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.143292 Validation acc: 0.953333\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.212619 Train acc: 0.946667\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.190918 Train acc: 0.948333\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.207487 Train acc: 0.955000\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.169977 Train acc: 0.950000\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.218075 Train acc: 0.951667\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.140293 Validation acc: 0.953889\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.186854 Train acc: 0.960000\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.205769 Train acc: 0.945000\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.184220 Train acc: 0.971667\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.229834 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.225625 Train acc: 0.946667\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.140565 Validation acc: 0.953333\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.201706 Train acc: 0.946667\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.187568 Train acc: 0.948333\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.177658 Train acc: 0.950000\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.187939 Train acc: 0.970000\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.208229 Train acc: 0.955000\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.138562 Validation acc: 0.953333\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.224688 Train acc: 0.943333\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.176347 Train acc: 0.963333\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.231367 Train acc: 0.930000\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.204357 Train acc: 0.961667\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.171143 Train acc: 0.950000\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.137724 Validation acc: 0.955000\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.173579 Train acc: 0.961667\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.152944 Train acc: 0.966667\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.193038 Train acc: 0.958333\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.188773 Train acc: 0.956667\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.191554 Train acc: 0.951667\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.135461 Validation acc: 0.956667\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.168102 Train acc: 0.971667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.236813 Train acc: 0.936667\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.193566 Train acc: 0.956667\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.188792 Train acc: 0.943333\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.203523 Train acc: 0.956667\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.139508 Validation acc: 0.954444\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.159730 Train acc: 0.955000\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.186635 Train acc: 0.961667\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.185369 Train acc: 0.960000\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.207473 Train acc: 0.941667\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.144561 Train acc: 0.968333\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.135679 Validation acc: 0.955000\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.221882 Train acc: 0.951667\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.204534 Train acc: 0.953333\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.196333 Train acc: 0.958333\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.167254 Train acc: 0.960000\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.173936 Train acc: 0.965000\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.134779 Validation acc: 0.953889\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.199276 Train acc: 0.953333\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.177722 Train acc: 0.960000\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.193734 Train acc: 0.945000\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.164633 Train acc: 0.965000\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.220033 Train acc: 0.940000\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.133393 Validation acc: 0.955555\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.220194 Train acc: 0.943333\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.192353 Train acc: 0.943333\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.177385 Train acc: 0.958333\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.166636 Train acc: 0.960000\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.167791 Train acc: 0.973333\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.131933 Validation acc: 0.957222\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.201331 Train acc: 0.963333\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.177177 Train acc: 0.955000\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.154268 Train acc: 0.975000\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.243661 Train acc: 0.938333\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.208263 Train acc: 0.948333\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.132337 Validation acc: 0.956111\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.209361 Train acc: 0.951667\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.163197 Train acc: 0.958333\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.167633 Train acc: 0.956667\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.180592 Train acc: 0.966667\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.172549 Train acc: 0.968333\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.131829 Validation acc: 0.955000\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.179631 Train acc: 0.960000\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.154448 Train acc: 0.961667\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.219639 Train acc: 0.935000\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.181527 Train acc: 0.963333\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.172095 Train acc: 0.966667\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.130824 Validation acc: 0.956667\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.187721 Train acc: 0.960000\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.152960 Train acc: 0.965000\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.191221 Train acc: 0.963333\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.171411 Train acc: 0.961667\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.182403 Train acc: 0.951667\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.130056 Validation acc: 0.956667\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.148373 Train acc: 0.968333\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.211081 Train acc: 0.948333\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.191735 Train acc: 0.958333\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.173487 Train acc: 0.956667\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.181000 Train acc: 0.953333\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.135532 Validation acc: 0.953889\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.171474 Train acc: 0.956667\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.155212 Train acc: 0.973333\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.164093 Train acc: 0.965000\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.207540 Train acc: 0.945000\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.143403 Train acc: 0.965000\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.130353 Validation acc: 0.953889\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.232976 Train acc: 0.940000\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.186305 Train acc: 0.965000\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.178575 Train acc: 0.956667\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.161111 Train acc: 0.958333\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.162283 Train acc: 0.970000\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.132959 Validation acc: 0.956667\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.196313 Train acc: 0.956667\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.166928 Train acc: 0.961667\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.202006 Train acc: 0.945000\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.134745 Train acc: 0.975000\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.226239 Train acc: 0.936667\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.127738 Validation acc: 0.956667\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.183315 Train acc: 0.955000\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.183925 Train acc: 0.956667\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.174105 Train acc: 0.961667\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.166203 Train acc: 0.958333\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.166615 Train acc: 0.961667\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.127387 Validation acc: 0.956111\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.172328 Train acc: 0.970000\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.179938 Train acc: 0.953333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.139747 Train acc: 0.971667\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.200741 Train acc: 0.943333\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.191006 Train acc: 0.953333\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.124849 Validation acc: 0.957222\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.173330 Train acc: 0.956667\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.158680 Train acc: 0.963333\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.157233 Train acc: 0.950000\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.166435 Train acc: 0.963333\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.159112 Train acc: 0.968333\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.125346 Validation acc: 0.956667\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.184328 Train acc: 0.950000\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.171508 Train acc: 0.960000\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.189355 Train acc: 0.941667\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.185806 Train acc: 0.960000\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.164907 Train acc: 0.958333\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.125944 Validation acc: 0.955555\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.154413 Train acc: 0.961667\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.149253 Train acc: 0.961667\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.157755 Train acc: 0.963333\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.162009 Train acc: 0.970000\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.182626 Train acc: 0.950000\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.125304 Validation acc: 0.957222\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.140848 Train acc: 0.975000\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.194809 Train acc: 0.948333\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.180925 Train acc: 0.958333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.161787 Train acc: 0.956667\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.166519 Train acc: 0.965000\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.127412 Validation acc: 0.956667\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.133151 Train acc: 0.968333\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.188345 Train acc: 0.970000\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.179469 Train acc: 0.960000\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.199520 Train acc: 0.935000\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.154146 Train acc: 0.963333\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.138872 Validation acc: 0.955555\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.194336 Train acc: 0.945000\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.177953 Train acc: 0.948333\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.165172 Train acc: 0.963333\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.169019 Train acc: 0.955000\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.156086 Train acc: 0.955000\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.120517 Validation acc: 0.956111\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.142815 Train acc: 0.970000\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.149067 Train acc: 0.963333\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.169133 Train acc: 0.960000\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.137244 Train acc: 0.970000\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.190528 Train acc: 0.950000\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.121674 Validation acc: 0.957222\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.170529 Train acc: 0.956667\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.155436 Train acc: 0.956667\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.154172 Train acc: 0.955000\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.137420 Train acc: 0.963333\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.152085 Train acc: 0.968333\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.119546 Validation acc: 0.958333\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.147677 Train acc: 0.963333\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.181976 Train acc: 0.943333\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.138362 Train acc: 0.978333\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.209864 Train acc: 0.940000\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.222999 Train acc: 0.935000\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.144006 Validation acc: 0.949444\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.175987 Train acc: 0.940000\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.188406 Train acc: 0.950000\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.151393 Train acc: 0.961667\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.166979 Train acc: 0.965000\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.164886 Train acc: 0.968333\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.126748 Validation acc: 0.956111\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.185217 Train acc: 0.945000\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.146802 Train acc: 0.970000\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.198714 Train acc: 0.941667\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.166849 Train acc: 0.963333\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.156227 Train acc: 0.960000\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.124785 Validation acc: 0.956667\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.144681 Train acc: 0.968333\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.134576 Train acc: 0.970000\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.155883 Train acc: 0.960000\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.145543 Train acc: 0.965000\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.171637 Train acc: 0.955000\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.125077 Validation acc: 0.956667\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.131209 Train acc: 0.978333\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.194341 Train acc: 0.943333\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.171842 Train acc: 0.956667\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.158883 Train acc: 0.958333\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.133374 Train acc: 0.975000\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.123566 Validation acc: 0.955555\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.142018 Train acc: 0.970000\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.173855 Train acc: 0.966667\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.179367 Train acc: 0.965000\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.171425 Train acc: 0.943333\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.135905 Train acc: 0.976667\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.119689 Validation acc: 0.957222\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.181329 Train acc: 0.948333\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.169090 Train acc: 0.960000\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.178601 Train acc: 0.955000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.156898 Train acc: 0.960000\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.164598 Train acc: 0.953333\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.124797 Validation acc: 0.956667\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.160777 Train acc: 0.966667\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.148127 Train acc: 0.975000\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.172597 Train acc: 0.956667\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.121818 Train acc: 0.970000\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.203490 Train acc: 0.946667\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.119934 Validation acc: 0.957778\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.171735 Train acc: 0.960000\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.154797 Train acc: 0.953333\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.167739 Train acc: 0.963333\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.142259 Train acc: 0.960000\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.167911 Train acc: 0.963333\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.117903 Validation acc: 0.958889\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.168578 Train acc: 0.965000\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.181924 Train acc: 0.950000\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.125151 Train acc: 0.973333\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.199028 Train acc: 0.940000\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.206482 Train acc: 0.946667\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.121911 Validation acc: 0.955555\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.177574 Train acc: 0.955000\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.140663 Train acc: 0.966667\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.135574 Train acc: 0.966667\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.142867 Train acc: 0.968333\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.149102 Train acc: 0.971667\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.117099 Validation acc: 0.958333\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.176495 Train acc: 0.956667\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.140907 Train acc: 0.970000\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.198264 Train acc: 0.950000\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.172490 Train acc: 0.941667\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.149203 Train acc: 0.960000\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.122350 Validation acc: 0.955555\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.152646 Train acc: 0.960000\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.127982 Train acc: 0.968333\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.154078 Train acc: 0.965000\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.163245 Train acc: 0.963333\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.168151 Train acc: 0.951667\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.125670 Validation acc: 0.954444\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.120286 Train acc: 0.975000\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.188982 Train acc: 0.938333\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.163609 Train acc: 0.958333\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.183049 Train acc: 0.950000\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.139964 Train acc: 0.973333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.125077 Validation acc: 0.956667\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.138551 Train acc: 0.960000\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.156349 Train acc: 0.961667\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.151385 Train acc: 0.961667\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.168740 Train acc: 0.948333\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.108639 Train acc: 0.981667\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.118249 Validation acc: 0.958333\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.192986 Train acc: 0.941667\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.149777 Train acc: 0.960000\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.142111 Train acc: 0.965000\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.154659 Train acc: 0.963333\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.140313 Train acc: 0.963333\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.121139 Validation acc: 0.955000\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.176870 Train acc: 0.953333\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.137538 Train acc: 0.961667\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.168591 Train acc: 0.951667\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.128912 Train acc: 0.970000\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.164324 Train acc: 0.958333\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.122000 Validation acc: 0.953333\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.151375 Train acc: 0.958333\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.172934 Train acc: 0.960000\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.146006 Train acc: 0.960000\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.153327 Train acc: 0.948333\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.141534 Train acc: 0.971667\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.118223 Validation acc: 0.955556\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.152059 Train acc: 0.961667\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.159760 Train acc: 0.955000\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.111560 Train acc: 0.978333\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.166981 Train acc: 0.948333\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.166324 Train acc: 0.958333\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.114210 Validation acc: 0.958889\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.148254 Train acc: 0.958333\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.142325 Train acc: 0.961667\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.138423 Train acc: 0.961667\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.146524 Train acc: 0.966667\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.144126 Train acc: 0.966667\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.115214 Validation acc: 0.957778\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.154367 Train acc: 0.950000\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.122923 Train acc: 0.971667\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.179120 Train acc: 0.946667\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.159671 Train acc: 0.966667\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.164726 Train acc: 0.953333\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.116578 Validation acc: 0.958333\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.140281 Train acc: 0.966667\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.127123 Train acc: 0.965000\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.142792 Train acc: 0.975000\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.152851 Train acc: 0.971667\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.187299 Train acc: 0.943333\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.119014 Validation acc: 0.957222\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.129750 Train acc: 0.971667\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.159236 Train acc: 0.955000\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.159710 Train acc: 0.961667\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.142754 Train acc: 0.963333\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.133671 Train acc: 0.970000\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.116323 Validation acc: 0.957222\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.141737 Train acc: 0.966667\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.134851 Train acc: 0.970000\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.149042 Train acc: 0.958333\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.162356 Train acc: 0.958333\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.125451 Train acc: 0.980000\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.117098 Validation acc: 0.956667\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.159834 Train acc: 0.951667\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.170941 Train acc: 0.963333\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.140063 Train acc: 0.956667\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.140341 Train acc: 0.966667\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.138743 Train acc: 0.963333\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.115968 Validation acc: 0.956111\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.128539 Train acc: 0.971667\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.134660 Train acc: 0.975000\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.143032 Train acc: 0.961667\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.123921 Train acc: 0.976667\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.167936 Train acc: 0.945000\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.115310 Validation acc: 0.957222\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.160139 Train acc: 0.950000\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.131917 Train acc: 0.958333\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.151323 Train acc: 0.956667\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.143071 Train acc: 0.953333\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.141293 Train acc: 0.973333\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.115821 Validation acc: 0.957778\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.138231 Train acc: 0.965000\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.193998 Train acc: 0.945000\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.134574 Train acc: 0.968333\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.202178 Train acc: 0.940000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.155409 Train acc: 0.961667\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.117201 Validation acc: 0.955000\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.139790 Train acc: 0.956667\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.143776 Train acc: 0.960000\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.123244 Train acc: 0.961667\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.127425 Train acc: 0.965000\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.137160 Train acc: 0.971667\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.113181 Validation acc: 0.957222\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.162160 Train acc: 0.950000\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.119051 Train acc: 0.976667\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.177861 Train acc: 0.948333\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.163561 Train acc: 0.958333\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.139188 Train acc: 0.960000\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.113853 Validation acc: 0.958333\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.141964 Train acc: 0.958333\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.120040 Train acc: 0.970000\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.151649 Train acc: 0.968333\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.123143 Train acc: 0.965000\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.146509 Train acc: 0.960000\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.115422 Validation acc: 0.956667\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.113217 Train acc: 0.975000\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.173685 Train acc: 0.943333\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.152403 Train acc: 0.961667\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.153771 Train acc: 0.955000\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.131857 Train acc: 0.966667\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.111589 Validation acc: 0.957778\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.130007 Train acc: 0.963333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.139574 Train acc: 0.968333\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.140845 Train acc: 0.971667\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.154078 Train acc: 0.955000\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.103763 Train acc: 0.975000\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.114910 Validation acc: 0.957222\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.177987 Train acc: 0.951667\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.132762 Train acc: 0.970000\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.138813 Train acc: 0.963333\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.141381 Train acc: 0.960000\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.126855 Train acc: 0.963333\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.114304 Validation acc: 0.956667\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.115830 Train acc: 0.976667\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.135692 Train acc: 0.961667\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.165331 Train acc: 0.950000\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.101436 Train acc: 0.981667\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.174979 Train acc: 0.950000\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.116157 Validation acc: 0.956111\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.154152 Train acc: 0.958333\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.129135 Train acc: 0.961667\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.139373 Train acc: 0.966667\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.113269 Train acc: 0.968333\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.141167 Train acc: 0.966667\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.115969 Validation acc: 0.957222\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.149041 Train acc: 0.961667\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.165505 Train acc: 0.948333\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.108622 Train acc: 0.978333\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.144275 Train acc: 0.960000\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.149080 Train acc: 0.960000\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.114350 Validation acc: 0.957778\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.145239 Train acc: 0.958333\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.126972 Train acc: 0.968333\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.120158 Train acc: 0.965000\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.137012 Train acc: 0.960000\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.132250 Train acc: 0.970000\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.112844 Validation acc: 0.958889\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.154101 Train acc: 0.956667\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.112238 Train acc: 0.975000\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.171228 Train acc: 0.943333\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.171819 Train acc: 0.963333\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.133583 Train acc: 0.955000\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.112654 Validation acc: 0.957222\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.152420 Train acc: 0.963333\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.130337 Train acc: 0.965000\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.139027 Train acc: 0.971667\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.122529 Train acc: 0.971667\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.144257 Train acc: 0.961667\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.113572 Validation acc: 0.955556\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.097770 Train acc: 0.978333\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.161608 Train acc: 0.953333\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.155215 Train acc: 0.955000\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.133685 Train acc: 0.966667\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.135432 Train acc: 0.963333\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.112137 Validation acc: 0.957778\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.128831 Train acc: 0.963333\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.138349 Train acc: 0.966667\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.146863 Train acc: 0.961667\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.159633 Train acc: 0.956667\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.121915 Train acc: 0.975000\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.114657 Validation acc: 0.957222\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.149273 Train acc: 0.950000\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.158356 Train acc: 0.965000\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.127614 Train acc: 0.958333\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.123396 Train acc: 0.961667\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.118572 Train acc: 0.968333\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.114554 Validation acc: 0.956667\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.117115 Train acc: 0.971667\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.132484 Train acc: 0.961667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.162844 Train acc: 0.951667\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.110452 Train acc: 0.978333\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.162162 Train acc: 0.941667\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.115168 Validation acc: 0.956111\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.146424 Train acc: 0.961667\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.135307 Train acc: 0.955000\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.122975 Train acc: 0.970000\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.122171 Train acc: 0.966667\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.130585 Train acc: 0.971667\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.114447 Validation acc: 0.956667\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.137249 Train acc: 0.973333\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.145745 Train acc: 0.961667\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.097705 Train acc: 0.978333\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.141973 Train acc: 0.953333\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.147612 Train acc: 0.951667\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.112493 Validation acc: 0.958333\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.130953 Train acc: 0.960000\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.113695 Train acc: 0.973333\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.108805 Train acc: 0.968333\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.126755 Train acc: 0.971667\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.120615 Train acc: 0.963333\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.112301 Validation acc: 0.958333\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.131032 Train acc: 0.958333\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.100497 Train acc: 0.975000\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.158203 Train acc: 0.945000\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.139147 Train acc: 0.963333\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.120695 Train acc: 0.961667\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.114572 Validation acc: 0.956667\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.116874 Train acc: 0.968333\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.125483 Train acc: 0.963333\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.140221 Train acc: 0.971667\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.128405 Train acc: 0.973333\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.157514 Train acc: 0.951667\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.114467 Validation acc: 0.958889\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.104443 Train acc: 0.978333\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.143034 Train acc: 0.948333\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.132031 Train acc: 0.960000\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.121468 Train acc: 0.968333\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.131398 Train acc: 0.966667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.116174 Validation acc: 0.955555\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.115113 Train acc: 0.970000\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.121828 Train acc: 0.971667\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.131867 Train acc: 0.973333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.169250 Train acc: 0.951667\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.107883 Train acc: 0.978333\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.113450 Validation acc: 0.956667\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.153083 Train acc: 0.955000\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.146733 Train acc: 0.958333\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.141497 Train acc: 0.968333\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.134365 Train acc: 0.963333\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.120043 Train acc: 0.960000\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.110491 Validation acc: 0.957222\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.123814 Train acc: 0.973333\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.127805 Train acc: 0.975000\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.128355 Train acc: 0.965000\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.105753 Train acc: 0.976667\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.163056 Train acc: 0.953333\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.110757 Validation acc: 0.957778\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.156525 Train acc: 0.955000\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.133427 Train acc: 0.956667\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.127379 Train acc: 0.961667\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.123157 Train acc: 0.963333\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.130633 Train acc: 0.968333\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.112891 Validation acc: 0.957222\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.106718 Train acc: 0.976667\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.125771 Train acc: 0.966667\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.099950 Train acc: 0.976667\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.133249 Train acc: 0.956667\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.140150 Train acc: 0.963333\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.114381 Validation acc: 0.957778\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.130552 Train acc: 0.961667\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.115249 Train acc: 0.971667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.116056 Train acc: 0.963333\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.130641 Train acc: 0.970000\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.124405 Train acc: 0.968333\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.116464 Validation acc: 0.957778\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.128773 Train acc: 0.958333\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.111151 Train acc: 0.978333\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.158588 Train acc: 0.948333\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.139798 Train acc: 0.963333\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.126756 Train acc: 0.963333\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.115232 Validation acc: 0.957778\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.113516 Train acc: 0.970000\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.111365 Train acc: 0.966667\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.132299 Train acc: 0.971667\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.118380 Train acc: 0.971667\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.154666 Train acc: 0.951667\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.114183 Validation acc: 0.957222\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.086559 Train acc: 0.981667\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.152535 Train acc: 0.956667\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.146872 Train acc: 0.966667\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.114883 Train acc: 0.961667\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.136418 Train acc: 0.970000\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.115356 Validation acc: 0.957778\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.115888 Train acc: 0.961667\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.131398 Train acc: 0.968333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.125871 Train acc: 0.968333\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.147475 Train acc: 0.956667\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.105900 Train acc: 0.976667\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.112996 Validation acc: 0.958333\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.152637 Train acc: 0.945000\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.146493 Train acc: 0.960000\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.113746 Train acc: 0.968333\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.114396 Train acc: 0.973333\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.123877 Train acc: 0.965000\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.112255 Validation acc: 0.959444\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.123537 Train acc: 0.970000\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.134819 Train acc: 0.966667\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.168532 Train acc: 0.946667\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.114108 Train acc: 0.963333\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.152091 Train acc: 0.953333\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.122668 Validation acc: 0.953333\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.166329 Train acc: 0.953333\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.129125 Train acc: 0.956667\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.135750 Train acc: 0.958333\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.120357 Train acc: 0.950000\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.134736 Train acc: 0.960000\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.111954 Validation acc: 0.957778\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.119062 Train acc: 0.963333\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.174010 Train acc: 0.941667\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.094148 Train acc: 0.975000\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.159923 Train acc: 0.955000\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.153532 Train acc: 0.960000\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.111903 Validation acc: 0.958889\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.130343 Train acc: 0.950000\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.106884 Train acc: 0.973333\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.107569 Train acc: 0.963333\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.122050 Train acc: 0.973333\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.115487 Train acc: 0.968333\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.115538 Validation acc: 0.956667\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.137420 Train acc: 0.966667\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.103426 Train acc: 0.975000\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.147452 Train acc: 0.948333\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.133013 Train acc: 0.961667\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.116219 Train acc: 0.965000\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.115119 Validation acc: 0.957778\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.122555 Train acc: 0.963333\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.107895 Train acc: 0.970000\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.107921 Train acc: 0.975000\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.116701 Train acc: 0.961667\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.139561 Train acc: 0.955000\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.113591 Validation acc: 0.958333\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.091745 Train acc: 0.976667\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.136291 Train acc: 0.943333\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.133679 Train acc: 0.958333\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.123532 Train acc: 0.961667\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.131942 Train acc: 0.965000\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.112191 Validation acc: 0.957222\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.112393 Train acc: 0.970000\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.127760 Train acc: 0.965000\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.123531 Train acc: 0.976667\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.140663 Train acc: 0.961667\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.088720 Train acc: 0.978333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.114350 Validation acc: 0.957222\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.131810 Train acc: 0.961667\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.129228 Train acc: 0.965000\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.128764 Train acc: 0.955000\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.131099 Train acc: 0.965000\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.108506 Train acc: 0.973333\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.114440 Validation acc: 0.957222\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.132949 Train acc: 0.970000\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.112007 Train acc: 0.976667\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.124027 Train acc: 0.961667\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.102384 Train acc: 0.978333\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.144875 Train acc: 0.955000\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.106697 Validation acc: 0.959444\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.131401 Train acc: 0.970000\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.127796 Train acc: 0.956667\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.108843 Train acc: 0.965000\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.100256 Train acc: 0.966667\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.118131 Train acc: 0.968333\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.110225 Validation acc: 0.959444\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.115161 Train acc: 0.968333\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.138670 Train acc: 0.963333\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.107102 Train acc: 0.981667\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.147008 Train acc: 0.955000\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.130860 Train acc: 0.960000\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.108946 Validation acc: 0.957778\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.136555 Train acc: 0.961667\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.123590 Train acc: 0.963333\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.107633 Train acc: 0.975000\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.117938 Train acc: 0.976667\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.124505 Train acc: 0.963333\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.110421 Validation acc: 0.957778\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.135545 Train acc: 0.963333\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.094986 Train acc: 0.980000\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.148830 Train acc: 0.950000\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.156133 Train acc: 0.955000\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.154146 Train acc: 0.955000\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.110298 Validation acc: 0.959444\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.122120 Train acc: 0.966667\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.105016 Train acc: 0.968333\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.126697 Train acc: 0.968333\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.123697 Train acc: 0.973333\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.125173 Train acc: 0.961667\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.108418 Validation acc: 0.958333\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.110299 Train acc: 0.970000\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.146447 Train acc: 0.955000\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.139143 Train acc: 0.958333\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.145070 Train acc: 0.955000\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.116380 Train acc: 0.968333\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.110626 Validation acc: 0.957222\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.095172 Train acc: 0.970000\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.117717 Train acc: 0.968333\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.103521 Train acc: 0.970000\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.118528 Train acc: 0.956667\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.088601 Train acc: 0.981667\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.109216 Validation acc: 0.958889\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.158396 Train acc: 0.953333\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.139181 Train acc: 0.965000\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.117866 Train acc: 0.963333\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.111361 Train acc: 0.965000\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.096562 Train acc: 0.968333\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.107662 Validation acc: 0.958333\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.128704 Train acc: 0.971667\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.113187 Train acc: 0.971667\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.143726 Train acc: 0.958333\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.093137 Train acc: 0.980000\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.133123 Train acc: 0.958333\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.108552 Validation acc: 0.958333\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.144858 Train acc: 0.958333\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.136666 Train acc: 0.953333\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.120515 Train acc: 0.970000\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.098974 Train acc: 0.966667\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.131592 Train acc: 0.970000\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.110169 Validation acc: 0.957222\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.120253 Train acc: 0.966667\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.144978 Train acc: 0.958333\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.100273 Train acc: 0.975000\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.152447 Train acc: 0.955000\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.134291 Train acc: 0.961667\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.111369 Validation acc: 0.958333\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.116259 Train acc: 0.966667\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.126321 Train acc: 0.961667\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.100799 Train acc: 0.966667\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.138286 Train acc: 0.970000\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.120764 Train acc: 0.966667\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.109118 Validation acc: 0.957778\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.126595 Train acc: 0.963333\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.087970 Train acc: 0.968333\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.153140 Train acc: 0.960000\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.132643 Train acc: 0.960000\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.118640 Train acc: 0.965000\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.110609 Validation acc: 0.957222\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.118720 Train acc: 0.970000\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.092679 Train acc: 0.971667\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.122732 Train acc: 0.966667\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.110382 Train acc: 0.973333\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.131222 Train acc: 0.958333\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.111741 Validation acc: 0.957222\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.095832 Train acc: 0.975000\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.141170 Train acc: 0.950000\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.144058 Train acc: 0.956667\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.148309 Train acc: 0.950000\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.109150 Train acc: 0.970000\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.109612 Validation acc: 0.958333\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.097719 Train acc: 0.966667\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.126758 Train acc: 0.973333\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.097269 Train acc: 0.971667\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.128317 Train acc: 0.963333\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.087031 Train acc: 0.978333\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.108926 Validation acc: 0.957778\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.141166 Train acc: 0.958333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.144728 Train acc: 0.961667\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.130321 Train acc: 0.951667\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.112089 Train acc: 0.970000\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.094394 Train acc: 0.973333\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.106404 Validation acc: 0.957778\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.127580 Train acc: 0.970000\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.134842 Train acc: 0.966667\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.142790 Train acc: 0.946667\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.108339 Train acc: 0.980000\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.153462 Train acc: 0.950000\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.114463 Validation acc: 0.956111\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.130297 Train acc: 0.963333\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.147740 Train acc: 0.948333\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.124271 Train acc: 0.970000\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.106656 Train acc: 0.973333\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.121251 Train acc: 0.976667\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.115992 Validation acc: 0.955555\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.125980 Train acc: 0.966667\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.123893 Train acc: 0.965000\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.100753 Train acc: 0.973333\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.127512 Train acc: 0.956667\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.138605 Train acc: 0.956667\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.110443 Validation acc: 0.957222\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.122360 Train acc: 0.963333\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.135757 Train acc: 0.963333\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.104987 Train acc: 0.963333\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.128047 Train acc: 0.973333\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.107380 Train acc: 0.975000\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.111792 Validation acc: 0.957222\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.112794 Train acc: 0.970000\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.080778 Train acc: 0.981667\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.152872 Train acc: 0.953333\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.138424 Train acc: 0.958333\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.124576 Train acc: 0.963333\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.111056 Validation acc: 0.958333\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.109203 Train acc: 0.966667\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.104539 Train acc: 0.960000\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.129096 Train acc: 0.971667\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.120003 Train acc: 0.970000\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.135379 Train acc: 0.956667\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.115252 Validation acc: 0.956667\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.102817 Train acc: 0.975000\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.154145 Train acc: 0.948333\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.143835 Train acc: 0.956667\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.115861 Train acc: 0.960000\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.119541 Train acc: 0.966667\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.111419 Validation acc: 0.957222\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.098369 Train acc: 0.971667\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.111750 Train acc: 0.971667\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.111188 Train acc: 0.968333\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.131289 Train acc: 0.958333\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.083026 Train acc: 0.976667\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.107894 Validation acc: 0.958333\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.137737 Train acc: 0.950000\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.128015 Train acc: 0.968333\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.134928 Train acc: 0.955000\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.102129 Train acc: 0.970000\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.093118 Train acc: 0.971667\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.108742 Validation acc: 0.958333\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.117101 Train acc: 0.970000\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.112945 Train acc: 0.968333\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.126102 Train acc: 0.968333\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.088270 Train acc: 0.971667\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.145006 Train acc: 0.956667\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.111063 Validation acc: 0.957778\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.128625 Train acc: 0.960000\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.121129 Train acc: 0.960000\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.115783 Train acc: 0.961667\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.109045 Train acc: 0.968333\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.114842 Train acc: 0.973333\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.112614 Validation acc: 0.957778\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.101980 Train acc: 0.975000\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.130352 Train acc: 0.963333\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.083242 Train acc: 0.981667\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.137056 Train acc: 0.950000\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.125254 Train acc: 0.970000\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.112582 Validation acc: 0.957222\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.111345 Train acc: 0.961667\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.135940 Train acc: 0.956667\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.110951 Train acc: 0.961667\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.120557 Train acc: 0.976667\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.101181 Train acc: 0.975000\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.115382 Validation acc: 0.958333\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.122459 Train acc: 0.968333\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.080476 Train acc: 0.983333\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.150361 Train acc: 0.948333\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.141781 Train acc: 0.961667\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.107430 Train acc: 0.966667\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.116016 Validation acc: 0.957222\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.101004 Train acc: 0.971667\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.106022 Train acc: 0.966667\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.105158 Train acc: 0.973333\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.105269 Train acc: 0.966667\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.114582 Train acc: 0.963333\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.116688 Validation acc: 0.956667\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.091566 Train acc: 0.971667\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.136764 Train acc: 0.958333\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.116646 Train acc: 0.963333\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.118591 Train acc: 0.961667\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.103869 Train acc: 0.975000\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.116689 Validation acc: 0.956667\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.096604 Train acc: 0.975000\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.102714 Train acc: 0.980000\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.116126 Train acc: 0.971667\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.122383 Train acc: 0.961667\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.089416 Train acc: 0.976667\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.117923 Validation acc: 0.957222\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.133606 Train acc: 0.955000\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.121167 Train acc: 0.961667\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.104088 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.115506 Train acc: 0.970000\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.098713 Train acc: 0.971667\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.116038 Validation acc: 0.957778\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.115310 Train acc: 0.968333\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.126989 Train acc: 0.973333\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.106171 Train acc: 0.966667\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.081475 Train acc: 0.976667\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.134140 Train acc: 0.953333\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.114911 Validation acc: 0.957222\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.121487 Train acc: 0.963333\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.141635 Train acc: 0.956667\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.095408 Train acc: 0.973333\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.109781 Train acc: 0.963333\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.123125 Train acc: 0.970000\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.114901 Validation acc: 0.957778\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.110095 Train acc: 0.973333\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.123595 Train acc: 0.958333\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.085682 Train acc: 0.976667\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.136543 Train acc: 0.956667\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.110610 Train acc: 0.966667\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.110800 Validation acc: 0.958333\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.125870 Train acc: 0.960000\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.102305 Train acc: 0.963333\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.094106 Train acc: 0.975000\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.115911 Train acc: 0.975000\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.112668 Train acc: 0.971667\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.115278 Validation acc: 0.958333\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.117400 Train acc: 0.961667\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.086947 Train acc: 0.978333\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.134904 Train acc: 0.956667\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.110981 Train acc: 0.968333\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.105096 Train acc: 0.968333\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.115031 Validation acc: 0.957222\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.111788 Train acc: 0.965000\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.085298 Train acc: 0.975000\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.117002 Train acc: 0.968333\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.109430 Train acc: 0.978333\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.122033 Train acc: 0.965000\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.116404 Validation acc: 0.957222\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.085321 Train acc: 0.981667\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.133971 Train acc: 0.955000\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.133537 Train acc: 0.963333\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.115286 Train acc: 0.963333\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.114390 Train acc: 0.961667\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.116812 Validation acc: 0.956111\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.093246 Train acc: 0.970000\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.126376 Train acc: 0.971667\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.109253 Train acc: 0.971667\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.132806 Train acc: 0.958333\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.086637 Train acc: 0.973333\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.108197 Validation acc: 0.959444\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.140170 Train acc: 0.950000\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.139429 Train acc: 0.960000\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.115405 Train acc: 0.960000\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.111999 Train acc: 0.966667\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.096270 Train acc: 0.971667\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.111383 Validation acc: 0.959444\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.116710 Train acc: 0.973333\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.102378 Train acc: 0.976667\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.138746 Train acc: 0.955000\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.077615 Train acc: 0.978333\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.132570 Train acc: 0.951667\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.118612 Validation acc: 0.956111\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.127258 Train acc: 0.966667\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.118164 Train acc: 0.965000\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.104967 Train acc: 0.968333\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.090246 Train acc: 0.973333\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.102051 Train acc: 0.975000\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.115732 Validation acc: 0.957222\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.102404 Train acc: 0.966667\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.117794 Train acc: 0.968333\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.075226 Train acc: 0.981667\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.144074 Train acc: 0.958333\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.132910 Train acc: 0.961667\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.113578 Validation acc: 0.958333\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.109732 Train acc: 0.970000\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.098030 Train acc: 0.968333\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.090403 Train acc: 0.975000\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.117077 Train acc: 0.973333\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.098694 Train acc: 0.978333\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.117013 Validation acc: 0.957778\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.131100 Train acc: 0.960000\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.073505 Train acc: 0.980000\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.133465 Train acc: 0.958333\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.133392 Train acc: 0.965000\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.112707 Train acc: 0.958333\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.107343 Validation acc: 0.960556\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.102526 Train acc: 0.970000\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.099613 Train acc: 0.966667\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.138095 Train acc: 0.965000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.101413 Train acc: 0.975000\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.124748 Train acc: 0.956667\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.109241 Validation acc: 0.956111\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.088421 Train acc: 0.985000\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.134923 Train acc: 0.953333\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.120538 Train acc: 0.968333\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.113810 Train acc: 0.960000\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.122940 Train acc: 0.958333\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.112596 Validation acc: 0.956667\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.099046 Train acc: 0.968333\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.109791 Train acc: 0.975000\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.106361 Train acc: 0.973333\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.104407 Train acc: 0.966667\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.087247 Train acc: 0.978333\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.112170 Validation acc: 0.957778\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.133002 Train acc: 0.956667\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.129583 Train acc: 0.965000\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.118929 Train acc: 0.963333\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.090976 Train acc: 0.966667\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.096363 Train acc: 0.966667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.109958 Validation acc: 0.957778\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.098958 Train acc: 0.976667\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.106209 Train acc: 0.978333\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.134670 Train acc: 0.956667\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.082931 Train acc: 0.978333\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.126123 Train acc: 0.956667\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.111334 Validation acc: 0.957778\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.131579 Train acc: 0.960000\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.115124 Train acc: 0.961667\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.118770 Train acc: 0.963333\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.084985 Train acc: 0.973333\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.110475 Train acc: 0.971667\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.113131 Validation acc: 0.957222\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.103123 Train acc: 0.976667\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.123167 Train acc: 0.960000\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.076587 Train acc: 0.981667\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.133401 Train acc: 0.953333\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.112387 Train acc: 0.968333\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.116176 Validation acc: 0.958333\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.122634 Train acc: 0.965000\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.098648 Train acc: 0.963333\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.090696 Train acc: 0.973333\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.109105 Train acc: 0.968333\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.101788 Train acc: 0.973333\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.116652 Validation acc: 0.958889\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.134306 Train acc: 0.955000\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.090941 Train acc: 0.980000\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.134987 Train acc: 0.960000\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.125271 Train acc: 0.963333\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.118060 Train acc: 0.960000\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.116846 Validation acc: 0.958333\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.105712 Train acc: 0.968333\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.102953 Train acc: 0.963333\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.121777 Train acc: 0.963333\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.107867 Train acc: 0.970000\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.147552 Train acc: 0.958333\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.115645 Validation acc: 0.956667\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.085986 Train acc: 0.985000\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.135962 Train acc: 0.955000\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.118575 Train acc: 0.965000\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.122079 Train acc: 0.955000\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.088291 Train acc: 0.976667\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.117067 Validation acc: 0.957778\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.085560 Train acc: 0.970000\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.114172 Train acc: 0.970000\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.109415 Train acc: 0.965000\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.113344 Train acc: 0.968333\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.090012 Train acc: 0.978333\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.117734 Validation acc: 0.955555\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.135954 Train acc: 0.953333\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.125923 Train acc: 0.966667\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.115405 Train acc: 0.960000\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.106440 Train acc: 0.966667\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.094438 Train acc: 0.968333\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.116645 Validation acc: 0.957222\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.104716 Train acc: 0.976667\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.117960 Train acc: 0.966667\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.118779 Train acc: 0.968333\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.080957 Train acc: 0.978333\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.140696 Train acc: 0.948333\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.117327 Validation acc: 0.955555\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.113913 Train acc: 0.968333\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.120324 Train acc: 0.958333\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.103117 Train acc: 0.958333\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.072989 Train acc: 0.976667\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.099452 Train acc: 0.963333\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.117786 Validation acc: 0.955000\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.103049 Train acc: 0.970000\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.121592 Train acc: 0.958333\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.088771 Train acc: 0.971667\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.137508 Train acc: 0.951667\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.120178 Train acc: 0.963333\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.114227 Validation acc: 0.956667\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.106296 Train acc: 0.970000\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.113933 Train acc: 0.973333\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.095807 Train acc: 0.971667\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.098393 Train acc: 0.970000\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.110466 Train acc: 0.975000\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.117925 Validation acc: 0.956667\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.125748 Train acc: 0.955000\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.074974 Train acc: 0.978333\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.143596 Train acc: 0.946667\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.110359 Train acc: 0.965000\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.122851 Train acc: 0.963333\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.117388 Validation acc: 0.956667\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.093400 Train acc: 0.970000\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.089618 Train acc: 0.970000\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.104825 Train acc: 0.980000\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.095532 Train acc: 0.971667\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.138505 Train acc: 0.960000\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.118425 Validation acc: 0.953889\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.083000 Train acc: 0.976667\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.151953 Train acc: 0.945000\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.111534 Train acc: 0.963333\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.118223 Train acc: 0.963333\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.110480 Train acc: 0.958333\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.109166 Validation acc: 0.957222\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.097362 Train acc: 0.973333\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.114330 Train acc: 0.971667\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.098958 Train acc: 0.973333\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.114410 Train acc: 0.961667\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.089822 Train acc: 0.975000\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.115651 Validation acc: 0.958889\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.123163 Train acc: 0.963333\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.124159 Train acc: 0.958333\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.108476 Train acc: 0.963333\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.095136 Train acc: 0.966667\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.087832 Train acc: 0.971667\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.116922 Validation acc: 0.956667\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.110134 Train acc: 0.971667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.099026 Train acc: 0.971667\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.135662 Train acc: 0.953333\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.080124 Train acc: 0.978333\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.144548 Train acc: 0.953333\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.108847 Validation acc: 0.960000\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.110658 Train acc: 0.968333\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.105153 Train acc: 0.965000\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.109994 Train acc: 0.963333\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.076008 Train acc: 0.980000\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.115107 Train acc: 0.970000\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.117221 Validation acc: 0.956667\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.111522 Train acc: 0.973333\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.106629 Train acc: 0.970000\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.083472 Train acc: 0.981667\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.136770 Train acc: 0.963333\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.134379 Train acc: 0.960000\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.117167 Validation acc: 0.956667\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.106848 Train acc: 0.960000\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.107785 Train acc: 0.966667\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.086693 Train acc: 0.975000\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.121698 Train acc: 0.976667\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.104605 Train acc: 0.973333\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.117351 Validation acc: 0.956667\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.139065 Train acc: 0.951667\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.073591 Train acc: 0.981667\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.133921 Train acc: 0.961667\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.110888 Train acc: 0.965000\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.107647 Train acc: 0.966667\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.109041 Validation acc: 0.959444\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.110410 Train acc: 0.963333\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.093816 Train acc: 0.970000\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.103444 Train acc: 0.975000\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.093203 Train acc: 0.973333\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.128266 Train acc: 0.958333\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.108531 Validation acc: 0.958889\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.072497 Train acc: 0.980000\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.152827 Train acc: 0.955000\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.127782 Train acc: 0.970000\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.115326 Train acc: 0.956667\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.091563 Train acc: 0.966667\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.114763 Validation acc: 0.957222\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.079608 Train acc: 0.971667\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.109892 Train acc: 0.975000\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.110568 Train acc: 0.975000\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.125019 Train acc: 0.951667\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.072740 Train acc: 0.985000\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.113480 Validation acc: 0.958333\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.137815 Train acc: 0.953333\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.125018 Train acc: 0.958333\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.127798 Train acc: 0.956667\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.122758 Train acc: 0.951667\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.098648 Train acc: 0.963333\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.110952 Validation acc: 0.960555\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.120605 Train acc: 0.975000\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.118620 Train acc: 0.965000\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.122348 Train acc: 0.963333\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.078179 Train acc: 0.976667\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.153257 Train acc: 0.940000\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.115488 Validation acc: 0.956111\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.118866 Train acc: 0.966667\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.113955 Train acc: 0.955000\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.101441 Train acc: 0.968333\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.086761 Train acc: 0.973333\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.098222 Train acc: 0.976667\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.114658 Validation acc: 0.957222\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.092772 Train acc: 0.971667\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.122172 Train acc: 0.965000\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.078579 Train acc: 0.981667\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.148732 Train acc: 0.956667\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.112010 Train acc: 0.968333\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.112020 Validation acc: 0.957222\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.091270 Train acc: 0.966667\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.098887 Train acc: 0.963333\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.090711 Train acc: 0.973333\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.142144 Train acc: 0.971667\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.102913 Train acc: 0.971667\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.112896 Validation acc: 0.955000\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.132708 Train acc: 0.955000\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.082293 Train acc: 0.971667\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.133385 Train acc: 0.963333\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.109938 Train acc: 0.968333\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.116560 Train acc: 0.960000\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.108842 Validation acc: 0.958889\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.105836 Train acc: 0.966667\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.079224 Train acc: 0.978333\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.112963 Train acc: 0.971667\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.102452 Train acc: 0.971667\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.116452 Train acc: 0.961667\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.108730 Validation acc: 0.958889\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.080388 Train acc: 0.978333\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.139756 Train acc: 0.951667\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.126385 Train acc: 0.963333\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.092712 Train acc: 0.965000\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.095111 Train acc: 0.963333\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.113407 Validation acc: 0.957778\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.082579 Train acc: 0.973333\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.114233 Train acc: 0.975000\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.088261 Train acc: 0.973333\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.118163 Train acc: 0.955000\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.079220 Train acc: 0.981667\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.112662 Validation acc: 0.958333\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.120464 Train acc: 0.955000\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.111021 Train acc: 0.966667\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.108847 Train acc: 0.965000\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.115839 Train acc: 0.961667\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.090114 Train acc: 0.971667\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.113597 Validation acc: 0.958333\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.107709 Train acc: 0.978333\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.110689 Train acc: 0.973333\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.118197 Train acc: 0.963333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.080547 Train acc: 0.973333\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.140783 Train acc: 0.953333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.114804 Validation acc: 0.957778\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.110343 Train acc: 0.973333\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.110312 Train acc: 0.963333\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.103949 Train acc: 0.971667\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.094364 Train acc: 0.958333\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.105961 Train acc: 0.973333\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.112975 Validation acc: 0.957222\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.100038 Train acc: 0.973333\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.139501 Train acc: 0.955000\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.073744 Train acc: 0.981667\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.138117 Train acc: 0.955000\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.123991 Train acc: 0.968333\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.111362 Validation acc: 0.959444\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.132514 Train acc: 0.953333\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.111933 Train acc: 0.968333\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.086119 Train acc: 0.970000\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.107558 Train acc: 0.968333\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.114859 Train acc: 0.970000\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.109987 Validation acc: 0.958333\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.121670 Train acc: 0.961667\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.075032 Train acc: 0.981667\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.127362 Train acc: 0.955000\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.121810 Train acc: 0.963333\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.112701 Train acc: 0.953333\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.112108 Validation acc: 0.958333\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.101722 Train acc: 0.965000\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.081123 Train acc: 0.971667\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.112122 Train acc: 0.971667\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.110638 Train acc: 0.975000\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.124193 Train acc: 0.963333\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.111982 Validation acc: 0.958333\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.081029 Train acc: 0.976667\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.121919 Train acc: 0.960000\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.126687 Train acc: 0.965000\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.100344 Train acc: 0.970000\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.103461 Train acc: 0.960000\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.113865 Validation acc: 0.955000\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.084046 Train acc: 0.970000\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.116384 Train acc: 0.973333\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.106305 Train acc: 0.973333\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.124622 Train acc: 0.960000\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.065964 Train acc: 0.983333\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.112659 Validation acc: 0.957222\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.133138 Train acc: 0.955000\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.108499 Train acc: 0.970000\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.119496 Train acc: 0.961667\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.095823 Train acc: 0.963333\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.089497 Train acc: 0.973333\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.106462 Validation acc: 0.960000\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.110489 Train acc: 0.975000\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.094578 Train acc: 0.973333\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.110631 Train acc: 0.966667\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.072766 Train acc: 0.978333\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.140256 Train acc: 0.951667\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.109376 Validation acc: 0.956667\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.101233 Train acc: 0.971667\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.094459 Train acc: 0.973333\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.113428 Train acc: 0.970000\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.093336 Train acc: 0.970000\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.098084 Train acc: 0.978333\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.109880 Validation acc: 0.957778\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.095130 Train acc: 0.971667\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.106850 Train acc: 0.965000\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.066364 Train acc: 0.981667\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.131701 Train acc: 0.955000\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.112744 Train acc: 0.963333\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.107230 Validation acc: 0.959444\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.105745 Train acc: 0.966667\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.095794 Train acc: 0.965000\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.083467 Train acc: 0.970000\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.106021 Train acc: 0.970000\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.098299 Train acc: 0.971667\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.106630 Validation acc: 0.960000\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.119410 Train acc: 0.963333\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.075675 Train acc: 0.981667\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.127868 Train acc: 0.960000\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.106013 Train acc: 0.961667\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.104826 Train acc: 0.970000\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.107991 Validation acc: 0.958889\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.106450 Train acc: 0.966667\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.077304 Train acc: 0.971667\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.108626 Train acc: 0.966667\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.112982 Train acc: 0.980000\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.122687 Train acc: 0.961667\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.112418 Validation acc: 0.956111\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.081354 Train acc: 0.980000\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.129130 Train acc: 0.955000\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.125840 Train acc: 0.960000\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.109487 Train acc: 0.956667\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.105308 Train acc: 0.970000\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.106181 Validation acc: 0.957778\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.079444 Train acc: 0.975000\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.115058 Train acc: 0.971667\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.115204 Train acc: 0.970000\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.106668 Train acc: 0.968333\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.071211 Train acc: 0.981667\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.109661 Validation acc: 0.957778\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.135922 Train acc: 0.951667\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.142501 Train acc: 0.950000\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.118954 Train acc: 0.956667\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.113016 Train acc: 0.953333\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.091847 Train acc: 0.970000\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.115048 Validation acc: 0.955556\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.116504 Train acc: 0.963333\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.100659 Train acc: 0.978333\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.133551 Train acc: 0.958333\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.079298 Train acc: 0.978333\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.134913 Train acc: 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.110326 Validation acc: 0.957222\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.121809 Train acc: 0.958333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.097851 Train acc: 0.963333\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.097426 Train acc: 0.961667\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.075158 Train acc: 0.978333\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.103043 Train acc: 0.973333\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.108186 Validation acc: 0.958333\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.089801 Train acc: 0.973333\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.114144 Train acc: 0.961667\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.078641 Train acc: 0.978333\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.113805 Train acc: 0.965000\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.119305 Train acc: 0.956667\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.107142 Validation acc: 0.958333\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.107506 Train acc: 0.963333\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.107103 Train acc: 0.965000\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.077991 Train acc: 0.975000\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.106233 Train acc: 0.973333\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.107855 Train acc: 0.970000\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.107103 Validation acc: 0.959444\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.105781 Train acc: 0.970000\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.083767 Train acc: 0.971667\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.162288 Train acc: 0.940000\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.145593 Train acc: 0.960000\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.133121 Train acc: 0.963333\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.104180 Validation acc: 0.957778\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.105158 Train acc: 0.961667\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.093905 Train acc: 0.968333\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.105370 Train acc: 0.973333\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.096181 Train acc: 0.973333\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.114642 Train acc: 0.965000\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.106800 Validation acc: 0.957222\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.083044 Train acc: 0.971667\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.129403 Train acc: 0.955000\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.099711 Train acc: 0.968333\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.112840 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.099086 Train acc: 0.968333\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.107173 Validation acc: 0.958889\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.085241 Train acc: 0.968333\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.094655 Train acc: 0.973333\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.090283 Train acc: 0.976667\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.114865 Train acc: 0.963333\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.076028 Train acc: 0.980000\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.106040 Validation acc: 0.958889\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.132724 Train acc: 0.945000\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.112666 Train acc: 0.965000\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.111840 Train acc: 0.960000\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.101259 Train acc: 0.966667\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.083399 Train acc: 0.971667\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.109715 Validation acc: 0.957778\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.108948 Train acc: 0.965000\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.091676 Train acc: 0.976667\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.117894 Train acc: 0.958333\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.063349 Train acc: 0.985000\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.122261 Train acc: 0.955000\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.109128 Validation acc: 0.956667\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.097766 Train acc: 0.971667\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.108615 Train acc: 0.966667\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.091796 Train acc: 0.973333\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.086527 Train acc: 0.971667\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.090104 Train acc: 0.975000\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.109808 Validation acc: 0.957778\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.089549 Train acc: 0.968333\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.115597 Train acc: 0.963333\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.075778 Train acc: 0.980000\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.124175 Train acc: 0.950000\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.104754 Train acc: 0.968333\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.116958 Validation acc: 0.957778\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.092324 Train acc: 0.966667\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.095923 Train acc: 0.963333\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.084761 Train acc: 0.970000\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.098703 Train acc: 0.975000\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.094461 Train acc: 0.971667\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.116625 Validation acc: 0.957222\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.130914 Train acc: 0.955000\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.078240 Train acc: 0.981667\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.143436 Train acc: 0.946667\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.120840 Train acc: 0.965000\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.098013 Train acc: 0.968333\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.112775 Validation acc: 0.958333\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.090868 Train acc: 0.966667\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.077286 Train acc: 0.973333\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.099439 Train acc: 0.970000\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.095629 Train acc: 0.973333\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.107037 Train acc: 0.965000\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.116726 Validation acc: 0.958333\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.076529 Train acc: 0.981667\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.135127 Train acc: 0.956667\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.113477 Train acc: 0.968333\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.098177 Train acc: 0.968333\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.102234 Train acc: 0.968333\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.108933 Validation acc: 0.958333\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.082561 Train acc: 0.971667\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.106688 Train acc: 0.973333\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.092283 Train acc: 0.975000\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.107292 Train acc: 0.963333\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.080270 Train acc: 0.978333\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.109631 Validation acc: 0.957222\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.095903 Train acc: 0.965000\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.118861 Train acc: 0.963333\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.093414 Train acc: 0.968333\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.105113 Train acc: 0.966667\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.078986 Train acc: 0.975000\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.108997 Validation acc: 0.958333\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.108976 Train acc: 0.975000\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.098481 Train acc: 0.978333\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.117900 Train acc: 0.963333\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.079752 Train acc: 0.981667\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.112554 Train acc: 0.958333\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.114987 Validation acc: 0.956111\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.119659 Train acc: 0.966667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.106522 Train acc: 0.965000\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.091879 Train acc: 0.971667\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.087938 Train acc: 0.966667\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.102484 Train acc: 0.971667\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.106857 Validation acc: 0.960000\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.097596 Train acc: 0.970000\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.140733 Train acc: 0.953333\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.075315 Train acc: 0.981667\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.127621 Train acc: 0.960000\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.113094 Train acc: 0.968333\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.105786 Validation acc: 0.961111\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.117161 Train acc: 0.966667\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.086715 Train acc: 0.973333\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.079051 Train acc: 0.973333\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.090549 Train acc: 0.978333\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.093673 Train acc: 0.970000\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.107999 Validation acc: 0.957222\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.113027 Train acc: 0.958333\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.072074 Train acc: 0.981667\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.122797 Train acc: 0.958333\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.106699 Train acc: 0.963333\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.120033 Train acc: 0.956667\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.113302 Validation acc: 0.957778\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.097487 Train acc: 0.966667\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.072994 Train acc: 0.981667\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.111003 Train acc: 0.975000\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.093571 Train acc: 0.970000\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.101669 Train acc: 0.965000\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.112266 Validation acc: 0.956667\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.061327 Train acc: 0.985000\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.119789 Train acc: 0.960000\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.118261 Train acc: 0.971667\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.086609 Train acc: 0.971667\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.098582 Train acc: 0.965000\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.110152 Validation acc: 0.958333\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.070389 Train acc: 0.980000\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.105802 Train acc: 0.971667\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.084384 Train acc: 0.971667\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.119435 Train acc: 0.966667\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.076255 Train acc: 0.978333\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.119176 Validation acc: 0.957222\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.137527 Train acc: 0.951667\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.103855 Train acc: 0.975000\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.127710 Train acc: 0.953333\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.103177 Train acc: 0.965000\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.092356 Train acc: 0.968333\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.111807 Validation acc: 0.958333\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.101856 Train acc: 0.978333\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.090152 Train acc: 0.973333\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.118212 Train acc: 0.961667\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.068961 Train acc: 0.978333\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.137817 Train acc: 0.946667\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.115393 Validation acc: 0.954444\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.128347 Train acc: 0.961667\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.099427 Train acc: 0.966667\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.094015 Train acc: 0.965000\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.077737 Train acc: 0.973333\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.109032 Train acc: 0.976667\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.112666 Validation acc: 0.957778\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.086567 Train acc: 0.976667\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.113131 Train acc: 0.955000\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.064492 Train acc: 0.985000\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.125623 Train acc: 0.963333\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.108310 Train acc: 0.965000\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.105745 Validation acc: 0.960000\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.092627 Train acc: 0.966667\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.095264 Train acc: 0.965000\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.078964 Train acc: 0.975000\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.094094 Train acc: 0.976667\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.097613 Train acc: 0.973333\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.103725 Validation acc: 0.958889\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.112967 Train acc: 0.965000\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.076258 Train acc: 0.976667\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.119016 Train acc: 0.963333\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.117941 Train acc: 0.963333\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.085966 Train acc: 0.975000\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.113701 Validation acc: 0.958333\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.098674 Train acc: 0.968333\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.072081 Train acc: 0.976667\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.089554 Train acc: 0.973333\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.094465 Train acc: 0.973333\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.113550 Train acc: 0.963333\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.114547 Validation acc: 0.959444\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.074127 Train acc: 0.983333\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.125355 Train acc: 0.953333\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.126594 Train acc: 0.966667\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.091330 Train acc: 0.966667\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.096850 Train acc: 0.973333\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.107688 Validation acc: 0.960000\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.088014 Train acc: 0.968333\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.104285 Train acc: 0.976667\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.098907 Train acc: 0.968333\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.108916 Train acc: 0.968333\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.075329 Train acc: 0.978333\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.109311 Validation acc: 0.958333\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.124855 Train acc: 0.955000\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.111301 Train acc: 0.966667\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.101448 Train acc: 0.960000\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.090883 Train acc: 0.968333\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.082469 Train acc: 0.970000\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.108912 Validation acc: 0.958333\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.112364 Train acc: 0.971667\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.106628 Train acc: 0.968333\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.123122 Train acc: 0.965000\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.063529 Train acc: 0.978333\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.133940 Train acc: 0.953333\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.108007 Validation acc: 0.960556\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.112311 Train acc: 0.965000\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.100550 Train acc: 0.965000\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.087097 Train acc: 0.971667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.078261 Train acc: 0.970000\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.119227 Train acc: 0.961667\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.108460 Validation acc: 0.958333\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.081248 Train acc: 0.971667\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.101114 Train acc: 0.963333\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.079321 Train acc: 0.980000\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.129351 Train acc: 0.956667\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.101454 Train acc: 0.968333\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.106993 Validation acc: 0.957222\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.089833 Train acc: 0.970000\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.083679 Train acc: 0.968333\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.079962 Train acc: 0.973333\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.082398 Train acc: 0.978333\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.095822 Train acc: 0.975000\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.108399 Validation acc: 0.959444\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.117344 Train acc: 0.960000\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.065509 Train acc: 0.978333\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.116247 Train acc: 0.956667\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.102996 Train acc: 0.971667\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.085106 Train acc: 0.970000\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.108229 Validation acc: 0.960000\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.091983 Train acc: 0.976667\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.067081 Train acc: 0.986667\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.093378 Train acc: 0.973333\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.089254 Train acc: 0.973333\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.103495 Train acc: 0.968333\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.108984 Validation acc: 0.957222\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.059737 Train acc: 0.981667\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.116982 Train acc: 0.948333\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.094199 Train acc: 0.971667\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.086821 Train acc: 0.973333\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.108698 Train acc: 0.960000\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.113775 Validation acc: 0.957222\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.068765 Train acc: 0.978333\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.100012 Train acc: 0.975000\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.100827 Train acc: 0.975000\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.089375 Train acc: 0.970000\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.062670 Train acc: 0.985000\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.113945 Validation acc: 0.957778\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.139540 Train acc: 0.958333\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.105002 Train acc: 0.971667\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.097402 Train acc: 0.965000\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.100841 Train acc: 0.965000\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.066662 Train acc: 0.980000\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.113042 Validation acc: 0.956667\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.092105 Train acc: 0.980000\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.090920 Train acc: 0.975000\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.109873 Train acc: 0.960000\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.075398 Train acc: 0.976667\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.114168 Train acc: 0.963333\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.109110 Validation acc: 0.959444\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.099102 Train acc: 0.970000\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.087411 Train acc: 0.973333\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.096105 Train acc: 0.966667\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.074342 Train acc: 0.976667\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.093334 Train acc: 0.980000\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.108150 Validation acc: 0.960000\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.089782 Train acc: 0.971667\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.128936 Train acc: 0.963333\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.072124 Train acc: 0.980000\n",
      "Epoch: 999/1000 Iteration: 8995 Train loss: 0.129827 Train acc: 0.951667\n",
      "Epoch: 999/1000 Iteration: 9000 Train loss: 0.100995 Train acc: 0.961667\n",
      "Epoch: 999/1000 Iteration: 9000 Validation loss: 0.109193 Validation acc: 0.959444\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints/har-lstm.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26a16b0a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f27e5d7d6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/har-lstm.ckpt\n",
      "Test accuracy: 0.861667\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints'))\n",
    "    test_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1,\n",
    "                initial_state: test_state}\n",
    "        \n",
    "        batch_acc, test_state = sess.run([accuracy, final_state], feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
