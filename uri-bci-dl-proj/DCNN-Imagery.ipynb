{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input data\n",
    "\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "new_imagery = spio.loadmat(file_name='../data/bci_EEG_data-new/new_imagery.mat')\n",
    "new_imagery_data = new_imagery['new_imagery']\n",
    "print(new_imagery_data.shape, new_imagery_data.dtype)\n",
    "\n",
    "new_imagery_data_transposed = new_imagery_data.transpose(2, 0, 1)\n",
    "print(new_imagery_data_transposed.shape)\n",
    "\n",
    "# Deviding the input data into train and validation\n",
    "# For creating the training and testing set, 30% percent of each subject is considered as test and\n",
    "# 70% of each subject is conidered as training.\n",
    "length = int(new_imagery_data_transposed.shape[0] * 0.30)\n",
    "# length\n",
    "\n",
    "train_data_all = new_imagery_data_transposed[:-length]\n",
    "test_data = new_imagery_data_transposed[-length:]\n",
    "\n",
    "print(new_imagery_data_transposed.shape, new_imagery_data_transposed.dtype, \n",
    " train_data_all.shape, train_data_all.dtype, \n",
    " test_data.shape, test_data.dtype)\n",
    "\n",
    "# 30% of the total training data is validation,\n",
    "# 70% of the total training data is training\n",
    "# This is applied to every single subject data.\n",
    "length2 = int(train_data_all.shape[0] * 0.30)\n",
    "# length2\n",
    "\n",
    "train_data = train_data_all[:-length2]\n",
    "valid_data = train_data_all[-length2:]\n",
    "\n",
    "print(train_data_all.shape, train_data_all.dtype, \n",
    " train_data.shape, train_data.dtype, \n",
    " valid_data.shape, valid_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_imagery_label = spio.loadmat(file_name='../data/bci_EEG_data-new/new_imagery_label.mat')\n",
    "# print(new_imagery_label.keys())\n",
    "new_imagery_label_all = new_imagery_label['new_imagery_label']\n",
    "print(new_imagery_label_all.shape, new_imagery_label_all.dtype)\n",
    "print(new_imagery_label_all.max(axis=0)+1)\n",
    "\n",
    "label_train_all = new_imagery_label_all[:-length]\n",
    "label_test = new_imagery_label_all[-length:]\n",
    "\n",
    "print(new_imagery_label_all.shape, new_imagery_label_all.dtype,\n",
    " label_test.shape, label_test.dtype, \n",
    " label_train_all.shape, label_train_all.dtype)\n",
    "\n",
    "label_train = label_train_all[:-length2]\n",
    "label_valid = label_train_all[-length2:]\n",
    "print(label_train.shape, label_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Normalizing input data\n",
    "# def normalize(inputs, inputs_all):\n",
    "#     return (inputs - inputs_all.mean(axis=0)[None,:,:]) / inputs_all.std(axis=0)[None,:,:]\n",
    "# Yalda suggested this normalization.\n",
    "def normalize(inputs):\n",
    "    return (inputs - inputs.mean(axis=0)[None,:,:]) / inputs.std(axis=0)[None,:,:]\n",
    "\n",
    "# onehot vectorizing output labels\n",
    "def one_hot(labels, n_class):\n",
    "    \"\"\" One-hot encoding \"\"\"\n",
    "    expansion = np.eye(n_class)\n",
    "    y = expansion[:, labels-1].T\n",
    "    assert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "    return y\n",
    "\n",
    "# get minibatches for learning\n",
    "def get_batches(X, y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]\n",
    "\n",
    "# Standardize/normalize train and test\n",
    "# X_train_norm_all = normalize(inputs=FacesDataTrain, inputs_all=FacesDataAll)\n",
    "X_train_norm = normalize(inputs=train_data)\n",
    "X_valid_norm = normalize(inputs=valid_data)\n",
    "X_test_norm = normalize(inputs=test_data)\n",
    "\n",
    "print(X_train_norm.shape, X_train_norm.dtype, \n",
    "X_valid_norm.shape, X_valid_norm.dtype,\n",
    "X_test_norm.shape, X_test_norm.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "# Input data\n",
    "batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "\n",
    "# Output labels\n",
    "n_classes = int(new_imagery_label_all.max(axis=0) + 1)\n",
    "print('n_classes', n_classes)\n",
    "\n",
    "# Tweekable parameters\n",
    "learning_rate = 0.001 #1e-3\n",
    "epochs = 100 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train = np.array(label_train, dtype=int).reshape(-1)\n",
    "Y_valid = np.array(label_valid, dtype=int).reshape(-1)\n",
    "Y_test = np.array(label_test, dtype=int).reshape(-1)\n",
    "\n",
    "Y_train_onehot = one_hot(labels=Y_train, n_class=n_classes)\n",
    "Y_valid_onehot = one_hot(labels=Y_valid, n_class=n_classes)\n",
    "Y_test_onehot = one_hot(labels=Y_test, n_class=n_classes)\n",
    "\n",
    "print(Y_train_onehot.shape, Y_valid_onehot.shape, Y_test_onehot.shape, \n",
    " X_train_norm.shape, X_valid_norm.shape, X_test_norm.shape)\n",
    "\n",
    "print(Y_train_onehot.dtype, Y_valid_onehot.dtype, Y_test_onehot.dtype,\n",
    " X_train_norm.dtype, X_valid_norm.dtype, X_test_norm.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPUs or CPU\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "#  No graphs is needed on tensorflow\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')# Construct the LSTM inputs and LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Forward pass: Convolutional Layers, FC Layer, and Output layer\n",
    "# batch_size, seq_len, n_channels: 6, 3584, 13\n",
    "# (batch, 3584, 13) --> (batch, 1790, 26)\n",
    "# (3584 - 6 + 0)/2 + 1 = (3578/2)+1= 1789 +1 = 1790\n",
    "# 2/6 with strides/kernel_size is \n",
    "# 33.333% non-overlap/diff region and \n",
    "# 66.666% overlapping window/ common region\n",
    "in_conv = inputs_\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=26, kernel_size=6, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(in_conv.shape, out_conv.shape)\n",
    "\n",
    "# To reduce the size for memory efficiency & equivariancy/invariency/ minicolumns\n",
    "# (batch, 1790, 26) --> (batch, 446, 26)\n",
    "# (1790 - 10 + 0)/4 + 1 = (1780/4)+1= 445 +1 = 446\n",
    "# 4/10 with strides/kernel_size is \n",
    "# 40% non-overlap/diff region and \n",
    "# 60% overlapping window/ common region\n",
    "in_pool = out_conv\n",
    "out_pool = tf.layers.max_pooling1d(inputs=in_pool, pool_size=10, strides=4, padding='valid')\n",
    "print(in_pool.shape, out_pool.shape)\n",
    "\n",
    "# (batch, 446, 26) --> (batch, 221, 52)\n",
    "# (446 - 6 + 0)/2 + 1 = (440/2)+1= 220+1= 221\n",
    "# 2/6 with strides/kernel_size is \n",
    "# 33.33% non-overlap/diff region and \n",
    "# 66.66% overlapping window/ common region\n",
    "in_conv = out_pool\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=52, kernel_size=6, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(in_conv.shape, out_conv.shape)\n",
    "\n",
    "# To reduce the size for memory efficiency & equivariancy/invariency/ minicolumns\n",
    "# (batch, 221, 52) --> (batch, 43, 52)\n",
    "# (221 - 11 + 0)/5 + 1 = (210/5)+1= 42 +1 = 43\n",
    "# 5/11 with strides/kernel_size is \n",
    "# ~45.5% non-overlap/diff region and \n",
    "# ~64.5% overlapping window/ common region\n",
    "in_pool = out_conv\n",
    "out_pool = tf.layers.max_pooling1d(inputs=in_pool, pool_size=11, strides=5, padding='valid')\n",
    "print(in_pool.shape, out_pool.shape)\n",
    "\n",
    "# (batch, 43, 52) --> (batch, 43*52) --> (batch, 43*52*2)\n",
    "in_fc = tf.reshape(tensor=out_pool, shape=(-1, 43*52))\n",
    "out_fc = tf.layers.dense(inputs=in_fc, units=43*52*2)\n",
    "out_fc = tf.layers.batch_normalization(inputs=out_fc)\n",
    "out_fc = tf.nn.relu(features=out_fc)\n",
    "out_fc = tf.nn.dropout(x=out_fc, keep_prob=keep_prob_)\n",
    "print(out_pool.shape, in_fc.shape, out_fc.shape)\n",
    "\n",
    "# (batch, 43*52*2) --> (batch, 4) \n",
    "logits = tf.layers.dense(inputs=out_fc, units=n_classes)\n",
    "print(out_fc.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 0.825126 Valid loss: 6.321150 Train acc: 0.389474 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 4.102737 Valid loss: 6.099168 Train acc: 0.842105 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 4.101676 Valid loss: 5.375078 Train acc: 0.831579 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 2.860102 Valid loss: 4.581524 Train acc: 0.831579 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 1.722166 Valid loss: 3.881145 Train acc: 0.831579 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 0.932480 Valid loss: 3.323048 Train acc: 0.831579 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 0.492617 Valid loss: 2.916594 Train acc: 0.831579 Valid acc: 0.833468\n",
      "Epoch: 1/10 Train loss: 0.470911 Valid loss: 2.626531 Train acc: 0.831579 Valid acc: 0.833502\n",
      "Epoch: 1/10 Train loss: 0.561634 Valid loss: 2.408175 Train acc: 0.831579 Valid acc: 0.829450\n",
      "Epoch: 1/10 Train loss: 0.617193 Valid loss: 2.234608 Train acc: 0.821053 Valid acc: 0.821161\n",
      "Epoch: 1/10 Train loss: 0.629621 Valid loss: 2.091463 Train acc: 0.789474 Valid acc: 0.822329\n",
      "Epoch: 1/10 Train loss: 0.636655 Valid loss: 1.970569 Train acc: 0.842105 Valid acc: 0.823302\n",
      "Epoch: 1/10 Train loss: 0.626448 Valid loss: 1.866723 Train acc: 0.821053 Valid acc: 0.824084\n",
      "Epoch: 1/10 Train loss: 0.626479 Valid loss: 1.776345 Train acc: 0.831579 Valid acc: 0.824754\n",
      "Epoch: 1/10 Train loss: 0.605410 Valid loss: 1.696797 Train acc: 0.842105 Valid acc: 0.825335\n",
      "Epoch: 1/10 Train loss: 0.600842 Valid loss: 1.626118 Train acc: 0.810526 Valid acc: 0.825844\n",
      "Epoch: 1/10 Train loss: 0.574554 Valid loss: 1.562759 Train acc: 0.831579 Valid acc: 0.826292\n",
      "Epoch: 1/10 Train loss: 0.553722 Valid loss: 1.505506 Train acc: 0.842105 Valid acc: 0.826691\n",
      "Epoch: 1/10 Train loss: 0.522630 Valid loss: 1.453417 Train acc: 0.831579 Valid acc: 0.827048\n",
      "Epoch: 1/10 Train loss: 0.485462 Valid loss: 1.405758 Train acc: 0.842105 Valid acc: 0.827369\n",
      "Epoch: 1/10 Train loss: 0.527093 Valid loss: 1.362056 Train acc: 0.810526 Valid acc: 0.827659\n",
      "Epoch: 1/10 Train loss: 0.423366 Valid loss: 1.321901 Train acc: 0.852632 Valid acc: 0.827923\n",
      "Epoch: 1/10 Train loss: 0.500179 Valid loss: 1.284956 Train acc: 0.821053 Valid acc: 0.828164\n",
      "Epoch: 1/10 Train loss: 0.441113 Valid loss: 1.250857 Train acc: 0.842105 Valid acc: 0.828385\n",
      "Epoch: 1/10 Train loss: 0.455957 Valid loss: 1.219361 Train acc: 0.831579 Valid acc: 0.828589\n",
      "Epoch: 1/10 Train loss: 0.479981 Valid loss: 1.190213 Train acc: 0.831579 Valid acc: 0.828776\n",
      "Epoch: 1/10 Train loss: 0.549923 Valid loss: 1.163225 Train acc: 0.842105 Valid acc: 0.828950\n",
      "Epoch: 1/10 Train loss: 0.513013 Valid loss: 1.138187 Train acc: 0.831579 Valid acc: 0.829112\n",
      "Epoch: 1/10 Train loss: 0.467795 Valid loss: 1.114900 Train acc: 0.821053 Valid acc: 0.829262\n",
      "Epoch: 1/10 Train loss: 0.434296 Valid loss: 1.093186 Train acc: 0.842105 Valid acc: 0.829402\n",
      "Epoch: 1/10 Train loss: 0.455064 Valid loss: 1.072910 Train acc: 0.842105 Valid acc: 0.829533\n",
      "Epoch: 1/10 Train loss: 0.439639 Valid loss: 1.053934 Train acc: 0.831579 Valid acc: 0.829656\n",
      "Epoch: 1/10 Train loss: 0.451702 Valid loss: 1.036137 Train acc: 0.821053 Valid acc: 0.829772\n",
      "Epoch: 1/10 Train loss: 0.443919 Valid loss: 1.019411 Train acc: 0.842105 Valid acc: 0.829880\n",
      "Epoch: 1/10 Train loss: 0.465908 Valid loss: 1.003648 Train acc: 0.831579 Valid acc: 0.829983\n",
      "Epoch: 1/10 Train loss: 0.428016 Valid loss: 0.988751 Train acc: 0.831579 Valid acc: 0.830080\n",
      "Epoch: 1/10 Train loss: 0.416534 Valid loss: 0.974639 Train acc: 0.842105 Valid acc: 0.830171\n",
      "Epoch: 1/10 Train loss: 0.469137 Valid loss: 0.961255 Train acc: 0.821053 Valid acc: 0.830258\n",
      "Epoch: 1/10 Train loss: 0.424372 Valid loss: 0.948538 Train acc: 0.831579 Valid acc: 0.830340\n",
      "Epoch: 1/10 Train loss: 0.429859 Valid loss: 0.936417 Train acc: 0.852632 Valid acc: 0.830418\n",
      "Epoch: 1/10 Train loss: 0.502854 Valid loss: 0.924841 Train acc: 0.810526 Valid acc: 0.830493\n",
      "Epoch: 1/10 Train loss: 0.448893 Valid loss: 0.913754 Train acc: 0.842105 Valid acc: 0.830564\n",
      "Epoch: 1/10 Train loss: 0.461065 Valid loss: 0.903120 Train acc: 0.831579 Valid acc: 0.830631\n",
      "Epoch: 1/10 Train loss: 0.454193 Valid loss: 0.892910 Train acc: 0.821053 Valid acc: 0.830696\n",
      "Epoch: 1/10 Train loss: 0.434925 Valid loss: 0.883097 Train acc: 0.852632 Valid acc: 0.830757\n",
      "Epoch: 1/10 Train loss: 0.447596 Valid loss: 0.873668 Train acc: 0.831579 Valid acc: 0.830816\n",
      "Epoch: 1/10 Train loss: 0.445251 Valid loss: 0.864610 Train acc: 0.831579 Valid acc: 0.830873\n",
      "Epoch: 1/10 Train loss: 0.456451 Valid loss: 0.855907 Train acc: 0.831579 Valid acc: 0.830927\n",
      "Epoch: 1/10 Train loss: 0.417870 Valid loss: 0.847542 Train acc: 0.842105 Valid acc: 0.830979\n",
      "Epoch: 1/10 Train loss: 0.463663 Valid loss: 0.839497 Train acc: 0.821053 Valid acc: 0.831029\n",
      "Epoch: 1/10 Train loss: 0.414927 Valid loss: 0.831756 Train acc: 0.842105 Valid acc: 0.831076\n",
      "Epoch: 1/10 Train loss: 0.478997 Valid loss: 0.824293 Train acc: 0.831579 Valid acc: 0.831122\n",
      "Epoch: 1/10 Train loss: 0.424515 Valid loss: 0.817093 Train acc: 0.842105 Valid acc: 0.831167\n",
      "Epoch: 1/10 Train loss: 0.483541 Valid loss: 0.810135 Train acc: 0.821053 Valid acc: 0.831209\n",
      "Epoch: 1/10 Train loss: 0.439975 Valid loss: 0.803408 Train acc: 0.842105 Valid acc: 0.831250\n",
      "Epoch: 1/10 Train loss: 0.471382 Valid loss: 0.796903 Train acc: 0.821053 Valid acc: 0.831290\n",
      "Epoch: 1/10 Train loss: 0.456898 Valid loss: 0.790609 Train acc: 0.831579 Valid acc: 0.831328\n",
      "Epoch: 1/10 Train loss: 0.415467 Valid loss: 0.784516 Train acc: 0.842105 Valid acc: 0.831365\n",
      "Epoch: 1/10 Train loss: 0.466251 Valid loss: 0.778617 Train acc: 0.831579 Valid acc: 0.831401\n",
      "Epoch: 1/10 Train loss: 0.436757 Valid loss: 0.772904 Train acc: 0.831579 Valid acc: 0.831435\n",
      "Epoch: 1/10 Train loss: 0.416079 Valid loss: 0.767362 Train acc: 0.831579 Valid acc: 0.831469\n",
      "Epoch: 1/10 Train loss: 0.397909 Valid loss: 0.761976 Train acc: 0.842105 Valid acc: 0.831501\n",
      "Epoch: 1/10 Train loss: 0.435623 Valid loss: 0.756736 Train acc: 0.821053 Valid acc: 0.831532\n",
      "Epoch: 1/10 Train loss: 0.452224 Valid loss: 0.751634 Train acc: 0.842105 Valid acc: 0.831562\n",
      "Epoch: 1/10 Train loss: 0.480327 Valid loss: 0.746669 Train acc: 0.831579 Valid acc: 0.831592\n",
      "Epoch: 1/10 Train loss: 0.455003 Valid loss: 0.741838 Train acc: 0.842105 Valid acc: 0.831620\n",
      "Epoch: 1/10 Train loss: 0.483168 Valid loss: 0.737137 Train acc: 0.831579 Valid acc: 0.831648\n",
      "Epoch: 1/10 Train loss: 0.466538 Valid loss: 0.732567 Train acc: 0.831579 Valid acc: 0.831674\n",
      "Epoch: 1/10 Train loss: 0.456566 Valid loss: 0.728125 Train acc: 0.831579 Valid acc: 0.831700\n",
      "Epoch: 1/10 Train loss: 0.435038 Valid loss: 0.723802 Train acc: 0.831579 Valid acc: 0.831726\n",
      "Epoch: 1/10 Train loss: 0.431991 Valid loss: 0.719593 Train acc: 0.831579 Valid acc: 0.831750\n",
      "Epoch: 1/10 Train loss: 0.414525 Valid loss: 0.715493 Train acc: 0.831579 Valid acc: 0.831774\n",
      "Epoch: 1/10 Train loss: 0.532214 Valid loss: 0.711493 Train acc: 0.831579 Valid acc: 0.831797\n",
      "Epoch: 1/10 Train loss: 0.412940 Valid loss: 0.707587 Train acc: 0.831579 Valid acc: 0.831820\n",
      "Epoch: 1/10 Train loss: 0.495910 Valid loss: 0.703768 Train acc: 0.831579 Valid acc: 0.831842\n",
      "Epoch: 1/10 Train loss: 0.434986 Valid loss: 0.700031 Train acc: 0.842105 Valid acc: 0.831863\n",
      "Epoch: 1/10 Train loss: 0.418378 Valid loss: 0.696375 Train acc: 0.831579 Valid acc: 0.831884\n",
      "Epoch: 1/10 Train loss: 0.396826 Valid loss: 0.692796 Train acc: 0.842105 Valid acc: 0.831904\n",
      "Epoch: 1/10 Train loss: 0.460104 Valid loss: 0.689291 Train acc: 0.810526 Valid acc: 0.831924\n",
      "Epoch: 1/10 Train loss: 0.405127 Valid loss: 0.685858 Train acc: 0.852632 Valid acc: 0.831944\n",
      "Epoch: 1/10 Train loss: 0.450011 Valid loss: 0.682484 Train acc: 0.831579 Valid acc: 0.831962\n",
      "Epoch: 1/10 Train loss: 0.430990 Valid loss: 0.679163 Train acc: 0.831579 Valid acc: 0.831981\n",
      "Epoch: 1/10 Train loss: 0.417408 Valid loss: 0.675899 Train acc: 0.831579 Valid acc: 0.831999\n",
      "Epoch: 1/10 Train loss: 0.438033 Valid loss: 0.672710 Train acc: 0.831579 Valid acc: 0.832016\n",
      "Epoch: 1/10 Train loss: 0.424410 Valid loss: 0.669627 Train acc: 0.831579 Valid acc: 0.832033\n",
      "Epoch: 1/10 Train loss: 0.406794 Valid loss: 0.666666 Train acc: 0.831579 Valid acc: 0.832050\n",
      "Epoch: 1/10 Train loss: 0.413071 Valid loss: 0.663832 Train acc: 0.831579 Valid acc: 0.832066\n",
      "Epoch: 1/10 Train loss: 2.272379 Valid loss: 0.661343 Train acc: 0.831579 Valid acc: 0.832088\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 0.953453 Valid loss: 0.659336 Train acc: 0.831579 Valid acc: 0.832125\n",
      "Epoch: 1/10 Train loss: 0.612580 Valid loss: 0.657804 Train acc: 0.842105 Valid acc: 0.832218\n",
      "Epoch: 1/10 Train loss: 0.462744 Valid loss: 0.656621 Train acc: 0.821053 Valid acc: 0.832350\n",
      "Epoch: 1/10 Train loss: 0.497360 Valid loss: 0.655668 Train acc: 0.831579 Valid acc: 0.832503\n",
      "Epoch: 1/10 Train loss: 0.518475 Valid loss: 0.654856 Train acc: 0.831579 Valid acc: 0.832667\n",
      "Epoch: 1/10 Train loss: 0.502389 Valid loss: 0.654109 Train acc: 0.873684 Valid acc: 0.832814\n",
      "Epoch: 1/10 Train loss: 0.534019 Valid loss: 0.653377 Train acc: 0.821053 Valid acc: 0.832957\n",
      "Epoch: 1/10 Train loss: 0.526161 Valid loss: 0.652617 Train acc: 0.852632 Valid acc: 0.833064\n",
      "Epoch: 1/10 Train loss: 0.526416 Valid loss: 0.651797 Train acc: 0.842105 Valid acc: 0.833132\n",
      "Epoch: 1/10 Train loss: 0.506791 Valid loss: 0.650889 Train acc: 0.831579 Valid acc: 0.833182\n",
      "Epoch: 1/10 Train loss: 0.490948 Valid loss: 0.649868 Train acc: 0.842105 Valid acc: 0.833204\n",
      "Epoch: 1/10 Train loss: 0.463369 Valid loss: 0.648709 Train acc: 0.831579 Valid acc: 0.833215\n",
      "Epoch: 2/10 Train loss: 0.494951 Valid loss: 0.647395 Train acc: 0.831579 Valid acc: 0.833225\n",
      "Epoch: 2/10 Train loss: 0.466302 Valid loss: 0.645910 Train acc: 0.842105 Valid acc: 0.833228\n",
      "Epoch: 2/10 Train loss: 0.471546 Valid loss: 0.644253 Train acc: 0.831579 Valid acc: 0.833230\n",
      "Epoch: 2/10 Train loss: 0.420893 Valid loss: 0.642427 Train acc: 0.831579 Valid acc: 0.833232\n",
      "Epoch: 2/10 Train loss: 0.386443 Valid loss: 0.640450 Train acc: 0.831579 Valid acc: 0.833234\n",
      "Epoch: 2/10 Train loss: 0.429185 Valid loss: 0.638360 Train acc: 0.831579 Valid acc: 0.833237\n",
      "Epoch: 2/10 Train loss: 0.442010 Valid loss: 0.636204 Train acc: 0.831579 Valid acc: 0.833239\n",
      "Epoch: 2/10 Train loss: 0.379357 Valid loss: 0.634026 Train acc: 0.831579 Valid acc: 0.833241\n",
      "Epoch: 2/10 Train loss: 0.367925 Valid loss: 0.631867 Train acc: 0.831579 Valid acc: 0.833243\n",
      "Epoch: 2/10 Train loss: 0.383352 Valid loss: 0.629758 Train acc: 0.842105 Valid acc: 0.833245\n",
      "Epoch: 2/10 Train loss: 0.410187 Valid loss: 0.627706 Train acc: 0.831579 Valid acc: 0.833247\n",
      "Epoch: 2/10 Train loss: 0.393492 Valid loss: 0.625702 Train acc: 0.831579 Valid acc: 0.833249\n",
      "Epoch: 2/10 Train loss: 0.354206 Valid loss: 0.623731 Train acc: 0.842105 Valid acc: 0.833251\n",
      "Epoch: 2/10 Train loss: 0.461299 Valid loss: 0.621771 Train acc: 0.831579 Valid acc: 0.833253\n",
      "Epoch: 2/10 Train loss: 0.338708 Valid loss: 0.619811 Train acc: 0.842105 Valid acc: 0.833255\n",
      "Epoch: 2/10 Train loss: 0.446691 Valid loss: 0.617840 Train acc: 0.810526 Valid acc: 0.833257\n",
      "Epoch: 2/10 Train loss: 0.453178 Valid loss: 0.615868 Train acc: 0.831579 Valid acc: 0.833263\n",
      "Epoch: 2/10 Train loss: 0.350044 Valid loss: 0.613910 Train acc: 0.842105 Valid acc: 0.833269\n",
      "Epoch: 2/10 Train loss: 0.328312 Valid loss: 0.611981 Train acc: 0.831579 Valid acc: 0.833278\n",
      "Epoch: 2/10 Train loss: 0.272302 Valid loss: 0.610093 Train acc: 0.842105 Valid acc: 0.833288\n",
      "Epoch: 2/10 Train loss: 0.539945 Valid loss: 0.608276 Train acc: 0.800000 Valid acc: 0.833303\n",
      "Epoch: 2/10 Train loss: 0.346731 Valid loss: 0.606559 Train acc: 0.863158 Valid acc: 0.833347\n",
      "Epoch: 2/10 Train loss: 0.431519 Valid loss: 0.604978 Train acc: 0.810526 Valid acc: 0.833418\n",
      "Epoch: 2/10 Train loss: 0.356508 Valid loss: 0.603532 Train acc: 0.852632 Valid acc: 0.833503\n",
      "Epoch: 2/10 Train loss: 0.327787 Valid loss: 0.602217 Train acc: 0.821053 Valid acc: 0.833617\n",
      "Epoch: 2/10 Train loss: 0.446044 Valid loss: 0.601022 Train acc: 0.821053 Valid acc: 0.833758\n",
      "Epoch: 2/10 Train loss: 0.363949 Valid loss: 0.599939 Train acc: 0.831579 Valid acc: 0.833928\n",
      "Epoch: 2/10 Train loss: 0.454544 Valid loss: 0.598955 Train acc: 0.842105 Valid acc: 0.834090\n",
      "Epoch: 2/10 Train loss: 0.357338 Valid loss: 0.598032 Train acc: 0.894737 Valid acc: 0.834247\n",
      "Epoch: 2/10 Train loss: 0.385090 Valid loss: 0.597133 Train acc: 0.852632 Valid acc: 0.834394\n",
      "Epoch: 2/10 Train loss: 0.337499 Valid loss: 0.596227 Train acc: 0.884211 Valid acc: 0.834538\n",
      "Epoch: 2/10 Train loss: 0.348183 Valid loss: 0.595295 Train acc: 0.926316 Valid acc: 0.834691\n",
      "Epoch: 2/10 Train loss: 0.369463 Valid loss: 0.594319 Train acc: 0.884211 Valid acc: 0.834818\n",
      "Epoch: 2/10 Train loss: 0.368040 Valid loss: 0.593292 Train acc: 0.894737 Valid acc: 0.834927\n",
      "Epoch: 2/10 Train loss: 0.365708 Valid loss: 0.592208 Train acc: 0.873684 Valid acc: 0.835018\n",
      "Epoch: 2/10 Train loss: 0.277901 Valid loss: 0.591055 Train acc: 0.894737 Valid acc: 0.835104\n",
      "Epoch: 2/10 Train loss: 0.330171 Valid loss: 0.589841 Train acc: 0.884211 Valid acc: 0.835178\n",
      "Epoch: 2/10 Train loss: 0.371670 Valid loss: 0.588576 Train acc: 0.863158 Valid acc: 0.835250\n",
      "Epoch: 2/10 Train loss: 0.301442 Valid loss: 0.587273 Train acc: 0.873684 Valid acc: 0.835331\n",
      "Epoch: 2/10 Train loss: 0.413851 Valid loss: 0.585942 Train acc: 0.842105 Valid acc: 0.835408\n",
      "Epoch: 2/10 Train loss: 0.464823 Valid loss: 0.584597 Train acc: 0.789474 Valid acc: 0.835492\n",
      "Epoch: 2/10 Train loss: 0.411444 Valid loss: 0.583244 Train acc: 0.831579 Valid acc: 0.835576\n",
      "Epoch: 2/10 Train loss: 0.436403 Valid loss: 0.581893 Train acc: 0.831579 Valid acc: 0.835662\n",
      "Epoch: 2/10 Train loss: 0.367704 Valid loss: 0.580547 Train acc: 0.831579 Valid acc: 0.835751\n",
      "Epoch: 2/10 Train loss: 0.475286 Valid loss: 0.579212 Train acc: 0.852632 Valid acc: 0.835844\n",
      "Epoch: 2/10 Train loss: 0.494946 Valid loss: 0.577904 Train acc: 0.831579 Valid acc: 0.835942\n",
      "Epoch: 2/10 Train loss: 0.439775 Valid loss: 0.576626 Train acc: 0.831579 Valid acc: 0.836044\n",
      "Epoch: 2/10 Train loss: 0.344636 Valid loss: 0.575381 Train acc: 0.852632 Valid acc: 0.836153\n",
      "Epoch: 2/10 Train loss: 0.317631 Valid loss: 0.574162 Train acc: 0.863158 Valid acc: 0.836265\n",
      "Epoch: 2/10 Train loss: 0.390518 Valid loss: 0.572974 Train acc: 0.831579 Valid acc: 0.836385\n",
      "Epoch: 2/10 Train loss: 0.339786 Valid loss: 0.571808 Train acc: 0.863158 Valid acc: 0.836518\n",
      "Epoch: 2/10 Train loss: 0.391960 Valid loss: 0.570668 Train acc: 0.831579 Valid acc: 0.836659\n",
      "Epoch: 2/10 Train loss: 0.424175 Valid loss: 0.569557 Train acc: 0.810526 Valid acc: 0.836803\n",
      "Epoch: 2/10 Train loss: 0.345980 Valid loss: 0.568470 Train acc: 0.842105 Valid acc: 0.836958\n",
      "Epoch: 2/10 Train loss: 0.415458 Valid loss: 0.567408 Train acc: 0.831579 Valid acc: 0.837110\n",
      "Epoch: 2/10 Train loss: 0.495692 Valid loss: 0.566379 Train acc: 0.810526 Valid acc: 0.837268\n",
      "Epoch: 2/10 Train loss: 0.392850 Valid loss: 0.565376 Train acc: 0.842105 Valid acc: 0.837424\n",
      "Epoch: 2/10 Train loss: 0.332914 Valid loss: 0.564386 Train acc: 0.863158 Valid acc: 0.837573\n",
      "Epoch: 2/10 Train loss: 0.491468 Valid loss: 0.563422 Train acc: 0.800000 Valid acc: 0.837716\n",
      "Epoch: 2/10 Train loss: 0.366214 Valid loss: 0.562471 Train acc: 0.863158 Valid acc: 0.837846\n",
      "Epoch: 2/10 Train loss: 0.347965 Valid loss: 0.561524 Train acc: 0.852632 Valid acc: 0.837986\n",
      "Epoch: 2/10 Train loss: 0.321155 Valid loss: 0.560569 Train acc: 0.852632 Valid acc: 0.838125\n",
      "Epoch: 2/10 Train loss: 0.370571 Valid loss: 0.559602 Train acc: 0.821053 Valid acc: 0.838257\n",
      "Epoch: 2/10 Train loss: 0.474678 Valid loss: 0.558629 Train acc: 0.831579 Valid acc: 0.838386\n",
      "Epoch: 2/10 Train loss: 0.581180 Valid loss: 0.557668 Train acc: 0.831579 Valid acc: 0.838499\n",
      "Epoch: 2/10 Train loss: 0.499461 Valid loss: 0.556725 Train acc: 0.842105 Valid acc: 0.838605\n",
      "Epoch: 2/10 Train loss: 0.480007 Valid loss: 0.555804 Train acc: 0.821053 Valid acc: 0.838695\n",
      "Epoch: 2/10 Train loss: 0.517161 Valid loss: 0.554917 Train acc: 0.821053 Valid acc: 0.838764\n",
      "Epoch: 2/10 Train loss: 0.529055 Valid loss: 0.554066 Train acc: 0.821053 Valid acc: 0.838814\n",
      "Epoch: 2/10 Train loss: 0.380677 Valid loss: 0.553243 Train acc: 0.842105 Valid acc: 0.838849\n",
      "Epoch: 2/10 Train loss: 0.385425 Valid loss: 0.552442 Train acc: 0.831579 Valid acc: 0.838875\n",
      "Epoch: 2/10 Train loss: 0.365874 Valid loss: 0.551657 Train acc: 0.831579 Valid acc: 0.838887\n",
      "Epoch: 2/10 Train loss: 0.444542 Valid loss: 0.550890 Train acc: 0.831579 Valid acc: 0.838893\n",
      "Epoch: 2/10 Train loss: 0.365840 Valid loss: 0.550135 Train acc: 0.831579 Valid acc: 0.838898\n",
      "Epoch: 2/10 Train loss: 0.418466 Valid loss: 0.549388 Train acc: 0.831579 Valid acc: 0.838902\n",
      "Epoch: 2/10 Train loss: 0.364859 Valid loss: 0.548640 Train acc: 0.842105 Valid acc: 0.838906\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 Train loss: 0.403026 Valid loss: 0.547887 Train acc: 0.831579 Valid acc: 0.838906\n",
      "Epoch: 2/10 Train loss: 0.355610 Valid loss: 0.547124 Train acc: 0.842105 Valid acc: 0.838901\n",
      "Epoch: 2/10 Train loss: 0.421498 Valid loss: 0.546351 Train acc: 0.810526 Valid acc: 0.838897\n",
      "Epoch: 2/10 Train loss: 0.361830 Valid loss: 0.545561 Train acc: 0.852632 Valid acc: 0.838889\n",
      "Epoch: 2/10 Train loss: 0.395953 Valid loss: 0.544760 Train acc: 0.831579 Valid acc: 0.838881\n",
      "Epoch: 2/10 Train loss: 0.364935 Valid loss: 0.543951 Train acc: 0.831579 Valid acc: 0.838878\n",
      "Epoch: 2/10 Train loss: 0.320782 Valid loss: 0.543135 Train acc: 0.831579 Valid acc: 0.838883\n",
      "Epoch: 2/10 Train loss: 0.346359 Valid loss: 0.542317 Train acc: 0.831579 Valid acc: 0.838889\n",
      "Epoch: 2/10 Train loss: 0.336717 Valid loss: 0.541496 Train acc: 0.831579 Valid acc: 0.838906\n",
      "Epoch: 2/10 Train loss: 0.353726 Valid loss: 0.540674 Train acc: 0.831579 Valid acc: 0.838929\n",
      "Epoch: 2/10 Train loss: 0.357590 Valid loss: 0.539852 Train acc: 0.831579 Valid acc: 0.838965\n",
      "Epoch: 2/10 Train loss: 1.348416 Valid loss: 0.539093 Train acc: 0.842105 Valid acc: 0.839022\n",
      "Epoch: 2/10 Train loss: 0.589041 Valid loss: 0.538419 Train acc: 0.831579 Valid acc: 0.839102\n",
      "Epoch: 2/10 Train loss: 0.369144 Valid loss: 0.537823 Train acc: 0.842105 Valid acc: 0.839202\n",
      "Epoch: 2/10 Train loss: 0.317602 Valid loss: 0.537286 Train acc: 0.842105 Valid acc: 0.839319\n",
      "Epoch: 2/10 Train loss: 0.363591 Valid loss: 0.536793 Train acc: 0.852632 Valid acc: 0.839448\n",
      "Epoch: 2/10 Train loss: 0.372416 Valid loss: 0.536323 Train acc: 0.863158 Valid acc: 0.839591\n",
      "Epoch: 2/10 Train loss: 0.323335 Valid loss: 0.535857 Train acc: 0.873684 Valid acc: 0.839737\n",
      "Epoch: 2/10 Train loss: 0.382556 Valid loss: 0.535380 Train acc: 0.842105 Valid acc: 0.839871\n",
      "Epoch: 2/10 Train loss: 0.325096 Valid loss: 0.534873 Train acc: 0.905263 Valid acc: 0.840011\n",
      "Epoch: 2/10 Train loss: 0.422600 Valid loss: 0.534332 Train acc: 0.842105 Valid acc: 0.840152\n",
      "Epoch: 2/10 Train loss: 0.379247 Valid loss: 0.533750 Train acc: 0.831579 Valid acc: 0.840287\n",
      "Epoch: 2/10 Train loss: 0.335708 Valid loss: 0.533116 Train acc: 0.873684 Valid acc: 0.840425\n",
      "Epoch: 2/10 Train loss: 0.285666 Valid loss: 0.532425 Train acc: 0.863158 Valid acc: 0.840563\n",
      "Epoch: 3/10 Train loss: 0.306355 Valid loss: 0.531674 Train acc: 0.863158 Valid acc: 0.840694\n",
      "Epoch: 3/10 Train loss: 0.337155 Valid loss: 0.530867 Train acc: 0.863158 Valid acc: 0.840824\n",
      "Epoch: 3/10 Train loss: 0.409451 Valid loss: 0.530019 Train acc: 0.852632 Valid acc: 0.840951\n",
      "Epoch: 3/10 Train loss: 0.304890 Valid loss: 0.529136 Train acc: 0.831579 Valid acc: 0.841071\n",
      "Epoch: 3/10 Train loss: 0.300775 Valid loss: 0.528229 Train acc: 0.873684 Valid acc: 0.841190\n",
      "Epoch: 3/10 Train loss: 0.361607 Valid loss: 0.527310 Train acc: 0.863158 Valid acc: 0.841309\n",
      "Epoch: 3/10 Train loss: 0.386788 Valid loss: 0.526386 Train acc: 0.831579 Valid acc: 0.841426\n",
      "Epoch: 3/10 Train loss: 0.307519 Valid loss: 0.525461 Train acc: 0.852632 Valid acc: 0.841549\n",
      "Epoch: 3/10 Train loss: 0.239054 Valid loss: 0.524536 Train acc: 0.894737 Valid acc: 0.841679\n",
      "Epoch: 3/10 Train loss: 0.293257 Valid loss: 0.523613 Train acc: 0.873684 Valid acc: 0.841810\n",
      "Epoch: 3/10 Train loss: 0.332376 Valid loss: 0.522692 Train acc: 0.926316 Valid acc: 0.841958\n",
      "Epoch: 3/10 Train loss: 0.312373 Valid loss: 0.521775 Train acc: 0.873684 Valid acc: 0.842104\n",
      "Epoch: 3/10 Train loss: 0.240760 Valid loss: 0.520868 Train acc: 0.884211 Valid acc: 0.842238\n",
      "Epoch: 3/10 Train loss: 0.423614 Valid loss: 0.519975 Train acc: 0.800000 Valid acc: 0.842351\n",
      "Epoch: 3/10 Train loss: 0.286737 Valid loss: 0.519107 Train acc: 0.873684 Valid acc: 0.842454\n",
      "Epoch: 3/10 Train loss: 0.293993 Valid loss: 0.518268 Train acc: 0.842105 Valid acc: 0.842529\n",
      "Epoch: 3/10 Train loss: 0.455533 Valid loss: 0.517463 Train acc: 0.810526 Valid acc: 0.842589\n",
      "Epoch: 3/10 Train loss: 0.276796 Valid loss: 0.516682 Train acc: 0.894737 Valid acc: 0.842639\n",
      "Epoch: 3/10 Train loss: 0.270920 Valid loss: 0.515912 Train acc: 0.873684 Valid acc: 0.842692\n",
      "Epoch: 3/10 Train loss: 0.195088 Valid loss: 0.515135 Train acc: 0.915790 Valid acc: 0.842749\n",
      "Epoch: 3/10 Train loss: 0.540146 Valid loss: 0.514352 Train acc: 0.810526 Valid acc: 0.842821\n",
      "Epoch: 3/10 Train loss: 0.224277 Valid loss: 0.513554 Train acc: 0.894737 Valid acc: 0.842913\n",
      "Epoch: 3/10 Train loss: 0.343761 Valid loss: 0.512753 Train acc: 0.863158 Valid acc: 0.843034\n",
      "Epoch: 3/10 Train loss: 0.371970 Valid loss: 0.511956 Train acc: 0.842105 Valid acc: 0.843160\n",
      "Epoch: 3/10 Train loss: 0.245607 Valid loss: 0.511172 Train acc: 0.894737 Valid acc: 0.843294\n",
      "Epoch: 3/10 Train loss: 0.380285 Valid loss: 0.510409 Train acc: 0.852632 Valid acc: 0.843435\n",
      "Epoch: 3/10 Train loss: 0.317116 Valid loss: 0.509679 Train acc: 0.863158 Valid acc: 0.843569\n",
      "Epoch: 3/10 Train loss: 0.458285 Valid loss: 0.508996 Train acc: 0.863158 Valid acc: 0.843695\n",
      "Epoch: 3/10 Train loss: 0.239736 Valid loss: 0.508358 Train acc: 0.936842 Valid acc: 0.843811\n",
      "Epoch: 3/10 Train loss: 0.293641 Valid loss: 0.507756 Train acc: 0.873684 Valid acc: 0.843916\n",
      "Epoch: 3/10 Train loss: 0.262711 Valid loss: 0.507184 Train acc: 0.884211 Valid acc: 0.844016\n",
      "Epoch: 3/10 Train loss: 0.186071 Valid loss: 0.506634 Train acc: 0.915790 Valid acc: 0.844108\n",
      "Epoch: 3/10 Train loss: 0.160571 Valid loss: 0.506099 Train acc: 0.957895 Valid acc: 0.844182\n",
      "Epoch: 3/10 Train loss: 0.224974 Valid loss: 0.505571 Train acc: 0.905263 Valid acc: 0.844251\n",
      "Epoch: 3/10 Train loss: 0.324215 Valid loss: 0.505049 Train acc: 0.894737 Valid acc: 0.844312\n",
      "Epoch: 3/10 Train loss: 0.207109 Valid loss: 0.504529 Train acc: 0.947369 Valid acc: 0.844366\n",
      "Epoch: 3/10 Train loss: 0.165959 Valid loss: 0.504009 Train acc: 0.936842 Valid acc: 0.844423\n",
      "Epoch: 3/10 Train loss: 0.209015 Valid loss: 0.503487 Train acc: 0.936842 Valid acc: 0.844471\n",
      "Epoch: 3/10 Train loss: 0.243863 Valid loss: 0.502965 Train acc: 0.926316 Valid acc: 0.844519\n",
      "Epoch: 3/10 Train loss: 0.455698 Valid loss: 0.502445 Train acc: 0.810526 Valid acc: 0.844565\n",
      "Epoch: 3/10 Train loss: 0.506527 Valid loss: 0.501933 Train acc: 0.800000 Valid acc: 0.844611\n",
      "Epoch: 3/10 Train loss: 0.411734 Valid loss: 0.501429 Train acc: 0.810526 Valid acc: 0.844658\n",
      "Epoch: 3/10 Train loss: 0.424334 Valid loss: 0.500936 Train acc: 0.842105 Valid acc: 0.844712\n",
      "Epoch: 3/10 Train loss: 0.379014 Valid loss: 0.500457 Train acc: 0.831579 Valid acc: 0.844769\n",
      "Epoch: 3/10 Train loss: 0.414050 Valid loss: 0.499991 Train acc: 0.842105 Valid acc: 0.844832\n",
      "Epoch: 3/10 Train loss: 0.505724 Valid loss: 0.499543 Train acc: 0.800000 Valid acc: 0.844899\n",
      "Epoch: 3/10 Train loss: 0.359731 Valid loss: 0.499114 Train acc: 0.831579 Valid acc: 0.844968\n",
      "Epoch: 3/10 Train loss: 0.271381 Valid loss: 0.498697 Train acc: 0.905263 Valid acc: 0.845039\n",
      "Epoch: 3/10 Train loss: 0.332052 Valid loss: 0.498289 Train acc: 0.852632 Valid acc: 0.845114\n",
      "Epoch: 3/10 Train loss: 0.397223 Valid loss: 0.497890 Train acc: 0.842105 Valid acc: 0.845191\n",
      "Epoch: 3/10 Train loss: 0.302582 Valid loss: 0.497493 Train acc: 0.852632 Valid acc: 0.845260\n",
      "Epoch: 3/10 Train loss: 0.389231 Valid loss: 0.497097 Train acc: 0.852632 Valid acc: 0.845329\n",
      "Epoch: 3/10 Train loss: 0.408076 Valid loss: 0.496702 Train acc: 0.821053 Valid acc: 0.845400\n",
      "Epoch: 3/10 Train loss: 0.346249 Valid loss: 0.496303 Train acc: 0.863158 Valid acc: 0.845469\n",
      "Epoch: 3/10 Train loss: 0.413504 Valid loss: 0.495902 Train acc: 0.842105 Valid acc: 0.845542\n",
      "Epoch: 3/10 Train loss: 0.443480 Valid loss: 0.495506 Train acc: 0.821053 Valid acc: 0.845618\n",
      "Epoch: 3/10 Train loss: 0.420260 Valid loss: 0.495114 Train acc: 0.810526 Valid acc: 0.845693\n",
      "Epoch: 3/10 Train loss: 0.335354 Valid loss: 0.494722 Train acc: 0.831579 Valid acc: 0.845769\n",
      "Epoch: 3/10 Train loss: 0.440493 Valid loss: 0.494338 Train acc: 0.810526 Valid acc: 0.845839\n",
      "Epoch: 3/10 Train loss: 0.347447 Valid loss: 0.493959 Train acc: 0.842105 Valid acc: 0.845908\n",
      "Epoch: 3/10 Train loss: 0.371263 Valid loss: 0.493585 Train acc: 0.852632 Valid acc: 0.845978\n",
      "Epoch: 3/10 Train loss: 0.269771 Valid loss: 0.493207 Train acc: 0.884211 Valid acc: 0.846053\n",
      "Epoch: 3/10 Train loss: 0.326350 Valid loss: 0.492823 Train acc: 0.821053 Valid acc: 0.846133\n",
      "Epoch: 3/10 Train loss: 0.519680 Valid loss: 0.492442 Train acc: 0.810526 Valid acc: 0.846218\n",
      "Epoch: 3/10 Train loss: 0.528477 Valid loss: 0.492076 Train acc: 0.821053 Valid acc: 0.846298\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Train loss: 0.586790 Valid loss: 0.491734 Train acc: 0.800000 Valid acc: 0.846373\n",
      "Epoch: 3/10 Train loss: 0.481316 Valid loss: 0.491421 Train acc: 0.800000 Valid acc: 0.846438\n",
      "Epoch: 3/10 Train loss: 0.495185 Valid loss: 0.491138 Train acc: 0.800000 Valid acc: 0.846496\n",
      "Epoch: 3/10 Train loss: 0.510167 Valid loss: 0.490888 Train acc: 0.821053 Valid acc: 0.846544\n",
      "Epoch: 3/10 Train loss: 0.349739 Valid loss: 0.490659 Train acc: 0.842105 Valid acc: 0.846588\n",
      "Epoch: 3/10 Train loss: 0.419065 Valid loss: 0.490445 Train acc: 0.810526 Valid acc: 0.846618\n",
      "Epoch: 3/10 Train loss: 0.403237 Valid loss: 0.490241 Train acc: 0.831579 Valid acc: 0.846642\n",
      "Epoch: 3/10 Train loss: 0.442487 Valid loss: 0.490046 Train acc: 0.831579 Valid acc: 0.846659\n",
      "Epoch: 3/10 Train loss: 0.372593 Valid loss: 0.489856 Train acc: 0.831579 Valid acc: 0.846669\n",
      "Epoch: 3/10 Train loss: 0.377354 Valid loss: 0.489662 Train acc: 0.831579 Valid acc: 0.846670\n",
      "Epoch: 3/10 Train loss: 0.332066 Valid loss: 0.489457 Train acc: 0.863158 Valid acc: 0.846670\n",
      "Epoch: 3/10 Train loss: 0.369357 Valid loss: 0.489235 Train acc: 0.831579 Valid acc: 0.846669\n",
      "Epoch: 3/10 Train loss: 0.369759 Valid loss: 0.488991 Train acc: 0.842105 Valid acc: 0.846666\n",
      "Epoch: 3/10 Train loss: 0.395532 Valid loss: 0.488724 Train acc: 0.821053 Valid acc: 0.846662\n",
      "Epoch: 3/10 Train loss: 0.341697 Valid loss: 0.488431 Train acc: 0.852632 Valid acc: 0.846656\n",
      "Epoch: 3/10 Train loss: 0.346326 Valid loss: 0.488116 Train acc: 0.831579 Valid acc: 0.846649\n",
      "Epoch: 3/10 Train loss: 0.352353 Valid loss: 0.487781 Train acc: 0.831579 Valid acc: 0.846641\n",
      "Epoch: 3/10 Train loss: 0.383236 Valid loss: 0.487436 Train acc: 0.842105 Valid acc: 0.846639\n",
      "Epoch: 3/10 Train loss: 0.366744 Valid loss: 0.487088 Train acc: 0.831579 Valid acc: 0.846650\n",
      "Epoch: 3/10 Train loss: 0.335456 Valid loss: 0.486738 Train acc: 0.831579 Valid acc: 0.846667\n",
      "Epoch: 3/10 Train loss: 0.300362 Valid loss: 0.486388 Train acc: 0.852632 Valid acc: 0.846699\n",
      "Epoch: 3/10 Train loss: 0.306340 Valid loss: 0.486040 Train acc: 0.821053 Valid acc: 0.846747\n",
      "Epoch: 3/10 Train loss: 0.692275 Valid loss: 0.485716 Train acc: 0.842105 Valid acc: 0.846816\n",
      "Epoch: 3/10 Train loss: 0.296153 Valid loss: 0.485418 Train acc: 0.852632 Valid acc: 0.846902\n",
      "Epoch: 3/10 Train loss: 0.321664 Valid loss: 0.485144 Train acc: 0.863158 Valid acc: 0.846995\n",
      "Epoch: 3/10 Train loss: 0.266977 Valid loss: 0.484884 Train acc: 0.894737 Valid acc: 0.847111\n",
      "Epoch: 3/10 Train loss: 0.306150 Valid loss: 0.484630 Train acc: 0.873684 Valid acc: 0.847215\n",
      "Epoch: 3/10 Train loss: 0.336472 Valid loss: 0.484370 Train acc: 0.873684 Valid acc: 0.847304\n",
      "Epoch: 3/10 Train loss: 0.266265 Valid loss: 0.484090 Train acc: 0.905263 Valid acc: 0.847381\n",
      "Epoch: 3/10 Train loss: 0.314889 Valid loss: 0.483779 Train acc: 0.894737 Valid acc: 0.847450\n",
      "Epoch: 3/10 Train loss: 0.278262 Valid loss: 0.483429 Train acc: 0.905263 Valid acc: 0.847521\n",
      "Epoch: 3/10 Train loss: 0.389552 Valid loss: 0.483039 Train acc: 0.852632 Valid acc: 0.847600\n",
      "Epoch: 3/10 Train loss: 0.290774 Valid loss: 0.482611 Train acc: 0.936842 Valid acc: 0.847686\n",
      "Epoch: 3/10 Train loss: 0.260991 Valid loss: 0.482150 Train acc: 0.894737 Valid acc: 0.847776\n",
      "Epoch: 3/10 Train loss: 0.206764 Valid loss: 0.481658 Train acc: 0.926316 Valid acc: 0.847866\n",
      "Epoch: 4/10 Train loss: 0.261402 Valid loss: 0.481141 Train acc: 0.894737 Valid acc: 0.847955\n",
      "Epoch: 4/10 Train loss: 0.254547 Valid loss: 0.480602 Train acc: 0.884211 Valid acc: 0.848045\n",
      "Epoch: 4/10 Train loss: 0.424741 Valid loss: 0.480052 Train acc: 0.821053 Valid acc: 0.848131\n",
      "Epoch: 4/10 Train loss: 0.283310 Valid loss: 0.479495 Train acc: 0.894737 Valid acc: 0.848216\n",
      "Epoch: 4/10 Train loss: 0.217268 Valid loss: 0.478932 Train acc: 0.894737 Valid acc: 0.848303\n",
      "Epoch: 4/10 Train loss: 0.413876 Valid loss: 0.478370 Train acc: 0.842105 Valid acc: 0.848392\n",
      "Epoch: 4/10 Train loss: 0.421287 Valid loss: 0.477813 Train acc: 0.852632 Valid acc: 0.848476\n",
      "Epoch: 4/10 Train loss: 0.315969 Valid loss: 0.477262 Train acc: 0.842105 Valid acc: 0.848559\n",
      "Epoch: 4/10 Train loss: 0.220667 Valid loss: 0.476715 Train acc: 0.905263 Valid acc: 0.848638\n",
      "Epoch: 4/10 Train loss: 0.272728 Valid loss: 0.476175 Train acc: 0.884211 Valid acc: 0.848716\n",
      "Epoch: 4/10 Train loss: 0.332740 Valid loss: 0.475643 Train acc: 0.915790 Valid acc: 0.848792\n",
      "Epoch: 4/10 Train loss: 0.305259 Valid loss: 0.475119 Train acc: 0.873684 Valid acc: 0.848862\n",
      "Epoch: 4/10 Train loss: 0.197109 Valid loss: 0.474604 Train acc: 0.905263 Valid acc: 0.848919\n",
      "Epoch: 4/10 Train loss: 0.369934 Valid loss: 0.474104 Train acc: 0.831579 Valid acc: 0.848967\n",
      "Epoch: 4/10 Train loss: 0.208514 Valid loss: 0.473615 Train acc: 0.947368 Valid acc: 0.849014\n",
      "Epoch: 4/10 Train loss: 0.219045 Valid loss: 0.473139 Train acc: 0.905263 Valid acc: 0.849057\n",
      "Epoch: 4/10 Train loss: 0.362402 Valid loss: 0.472677 Train acc: 0.831579 Valid acc: 0.849095\n",
      "Epoch: 4/10 Train loss: 0.242549 Valid loss: 0.472223 Train acc: 0.915789 Valid acc: 0.849136\n",
      "Epoch: 4/10 Train loss: 0.205294 Valid loss: 0.471767 Train acc: 0.894737 Valid acc: 0.849176\n",
      "Epoch: 4/10 Train loss: 0.224854 Valid loss: 0.471285 Train acc: 0.905263 Valid acc: 0.849229\n",
      "Epoch: 4/10 Train loss: 0.539338 Valid loss: 0.470774 Train acc: 0.831579 Valid acc: 0.849305\n",
      "Epoch: 4/10 Train loss: 0.160241 Valid loss: 0.470239 Train acc: 0.936842 Valid acc: 0.849405\n",
      "Epoch: 4/10 Train loss: 0.311193 Valid loss: 0.469696 Train acc: 0.873684 Valid acc: 0.849522\n",
      "Epoch: 4/10 Train loss: 0.378087 Valid loss: 0.469153 Train acc: 0.842105 Valid acc: 0.849635\n",
      "Epoch: 4/10 Train loss: 0.147820 Valid loss: 0.468618 Train acc: 0.936842 Valid acc: 0.849748\n",
      "Epoch: 4/10 Train loss: 0.271580 Valid loss: 0.468096 Train acc: 0.915789 Valid acc: 0.849857\n",
      "Epoch: 4/10 Train loss: 0.204345 Valid loss: 0.467594 Train acc: 0.905263 Valid acc: 0.849965\n",
      "Epoch: 4/10 Train loss: 0.453581 Valid loss: 0.467123 Train acc: 0.894737 Valid acc: 0.850061\n",
      "Epoch: 4/10 Train loss: 0.209146 Valid loss: 0.466687 Train acc: 0.936842 Valid acc: 0.850146\n",
      "Epoch: 4/10 Train loss: 0.229032 Valid loss: 0.466281 Train acc: 0.915790 Valid acc: 0.850217\n",
      "Epoch: 4/10 Train loss: 0.117751 Valid loss: 0.465898 Train acc: 0.957895 Valid acc: 0.850278\n",
      "Epoch: 4/10 Train loss: 0.167343 Valid loss: 0.465530 Train acc: 0.936842 Valid acc: 0.850338\n",
      "Epoch: 4/10 Train loss: 0.095502 Valid loss: 0.465170 Train acc: 0.968421 Valid acc: 0.850388\n",
      "Epoch: 4/10 Train loss: 0.157995 Valid loss: 0.464815 Train acc: 0.905263 Valid acc: 0.850433\n",
      "Epoch: 4/10 Train loss: 0.194312 Valid loss: 0.464463 Train acc: 0.926316 Valid acc: 0.850477\n",
      "Epoch: 4/10 Train loss: 0.153081 Valid loss: 0.464116 Train acc: 0.989474 Valid acc: 0.850517\n",
      "Epoch: 4/10 Train loss: 0.122832 Valid loss: 0.463773 Train acc: 0.936842 Valid acc: 0.850553\n",
      "Epoch: 4/10 Train loss: 0.206036 Valid loss: 0.463435 Train acc: 0.947369 Valid acc: 0.850582\n",
      "Epoch: 4/10 Train loss: 0.163887 Valid loss: 0.463104 Train acc: 0.947369 Valid acc: 0.850611\n",
      "Epoch: 4/10 Train loss: 0.442932 Valid loss: 0.462782 Train acc: 0.842105 Valid acc: 0.850637\n",
      "Epoch: 4/10 Train loss: 0.478237 Valid loss: 0.462476 Train acc: 0.821053 Valid acc: 0.850660\n",
      "Epoch: 4/10 Train loss: 0.395981 Valid loss: 0.462186 Train acc: 0.842105 Valid acc: 0.850681\n",
      "Epoch: 4/10 Train loss: 0.465817 Valid loss: 0.461916 Train acc: 0.810526 Valid acc: 0.850705\n",
      "Epoch: 4/10 Train loss: 0.364973 Valid loss: 0.461666 Train acc: 0.831579 Valid acc: 0.850730\n",
      "Epoch: 4/10 Train loss: 0.389422 Valid loss: 0.461437 Train acc: 0.873684 Valid acc: 0.850755\n",
      "Epoch: 4/10 Train loss: 0.443931 Valid loss: 0.461228 Train acc: 0.789474 Valid acc: 0.850781\n",
      "Epoch: 4/10 Train loss: 0.366768 Valid loss: 0.461036 Train acc: 0.821053 Valid acc: 0.850807\n",
      "Epoch: 4/10 Train loss: 0.269598 Valid loss: 0.460855 Train acc: 0.894737 Valid acc: 0.850833\n",
      "Epoch: 4/10 Train loss: 0.309230 Valid loss: 0.460678 Train acc: 0.852632 Valid acc: 0.850861\n",
      "Epoch: 4/10 Train loss: 0.405031 Valid loss: 0.460505 Train acc: 0.821053 Valid acc: 0.850890\n",
      "Epoch: 4/10 Train loss: 0.314889 Valid loss: 0.460327 Train acc: 0.884211 Valid acc: 0.850925\n",
      "Epoch: 4/10 Train loss: 0.419754 Valid loss: 0.460144 Train acc: 0.831579 Valid acc: 0.850959\n",
      "Epoch: 4/10 Train loss: 0.422960 Valid loss: 0.459952 Train acc: 0.831579 Valid acc: 0.850992\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 Train loss: 0.315235 Valid loss: 0.459750 Train acc: 0.873684 Valid acc: 0.851027\n",
      "Epoch: 4/10 Train loss: 0.417262 Valid loss: 0.459536 Train acc: 0.810526 Valid acc: 0.851065\n",
      "Epoch: 4/10 Train loss: 0.410094 Valid loss: 0.459316 Train acc: 0.842105 Valid acc: 0.851106\n",
      "Epoch: 4/10 Train loss: 0.379292 Valid loss: 0.459090 Train acc: 0.810526 Valid acc: 0.851146\n",
      "Epoch: 4/10 Train loss: 0.341425 Valid loss: 0.458856 Train acc: 0.842105 Valid acc: 0.851189\n",
      "Epoch: 4/10 Train loss: 0.421616 Valid loss: 0.458623 Train acc: 0.810526 Valid acc: 0.851235\n",
      "Epoch: 4/10 Train loss: 0.324791 Valid loss: 0.458385 Train acc: 0.852632 Valid acc: 0.851284\n",
      "Epoch: 4/10 Train loss: 0.338179 Valid loss: 0.458144 Train acc: 0.852632 Valid acc: 0.851338\n",
      "Epoch: 4/10 Train loss: 0.259403 Valid loss: 0.457893 Train acc: 0.873684 Valid acc: 0.851394\n",
      "Epoch: 4/10 Train loss: 0.331915 Valid loss: 0.457635 Train acc: 0.831579 Valid acc: 0.851453\n",
      "Epoch: 4/10 Train loss: 0.602940 Valid loss: 0.457381 Train acc: 0.789474 Valid acc: 0.851511\n",
      "Epoch: 4/10 Train loss: 0.521121 Valid loss: 0.457139 Train acc: 0.800000 Valid acc: 0.851571\n",
      "Epoch: 4/10 Train loss: 0.553111 Valid loss: 0.456915 Train acc: 0.800000 Valid acc: 0.851633\n",
      "Epoch: 4/10 Train loss: 0.513688 Valid loss: 0.456714 Train acc: 0.800000 Valid acc: 0.851693\n",
      "Epoch: 4/10 Train loss: 0.497511 Valid loss: 0.456539 Train acc: 0.821053 Valid acc: 0.851750\n",
      "Epoch: 4/10 Train loss: 0.554576 Valid loss: 0.456393 Train acc: 0.800000 Valid acc: 0.851800\n",
      "Epoch: 4/10 Train loss: 0.352527 Valid loss: 0.456269 Train acc: 0.852632 Valid acc: 0.851842\n",
      "Epoch: 4/10 Train loss: 0.473147 Valid loss: 0.456162 Train acc: 0.778947 Valid acc: 0.851880\n",
      "Epoch: 4/10 Train loss: 0.450172 Valid loss: 0.456067 Train acc: 0.852632 Valid acc: 0.851911\n",
      "Epoch: 4/10 Train loss: 0.412952 Valid loss: 0.455983 Train acc: 0.831579 Valid acc: 0.851937\n",
      "Epoch: 4/10 Train loss: 0.388764 Valid loss: 0.455904 Train acc: 0.821053 Valid acc: 0.851958\n",
      "Epoch: 4/10 Train loss: 0.377711 Valid loss: 0.455825 Train acc: 0.831579 Valid acc: 0.851979\n",
      "Epoch: 4/10 Train loss: 0.369529 Valid loss: 0.455743 Train acc: 0.852632 Valid acc: 0.851997\n",
      "Epoch: 4/10 Train loss: 0.382322 Valid loss: 0.455651 Train acc: 0.831579 Valid acc: 0.852014\n",
      "Epoch: 4/10 Train loss: 0.362538 Valid loss: 0.455545 Train acc: 0.842105 Valid acc: 0.852023\n",
      "Epoch: 4/10 Train loss: 0.402968 Valid loss: 0.455423 Train acc: 0.821053 Valid acc: 0.852028\n",
      "Epoch: 4/10 Train loss: 0.327082 Valid loss: 0.455284 Train acc: 0.852632 Valid acc: 0.852031\n",
      "Epoch: 4/10 Train loss: 0.355165 Valid loss: 0.455128 Train acc: 0.831579 Valid acc: 0.852035\n",
      "Epoch: 4/10 Train loss: 0.325739 Valid loss: 0.454956 Train acc: 0.831579 Valid acc: 0.852040\n",
      "Epoch: 4/10 Train loss: 0.296914 Valid loss: 0.454768 Train acc: 0.852632 Valid acc: 0.852049\n",
      "Epoch: 4/10 Train loss: 0.337230 Valid loss: 0.454567 Train acc: 0.852632 Valid acc: 0.852063\n",
      "Epoch: 4/10 Train loss: 0.318952 Valid loss: 0.454356 Train acc: 0.831579 Valid acc: 0.852082\n",
      "Epoch: 4/10 Train loss: 0.326196 Valid loss: 0.454136 Train acc: 0.831579 Valid acc: 0.852108\n",
      "Epoch: 4/10 Train loss: 0.334110 Valid loss: 0.453909 Train acc: 0.842105 Valid acc: 0.852148\n",
      "Epoch: 4/10 Train loss: 0.505602 Valid loss: 0.453688 Train acc: 0.842105 Valid acc: 0.852193\n",
      "Epoch: 4/10 Train loss: 0.369586 Valid loss: 0.453481 Train acc: 0.831579 Valid acc: 0.852247\n",
      "Epoch: 4/10 Train loss: 0.401947 Valid loss: 0.453289 Train acc: 0.852632 Valid acc: 0.852312\n",
      "Epoch: 4/10 Train loss: 0.270078 Valid loss: 0.453107 Train acc: 0.915790 Valid acc: 0.852380\n",
      "Epoch: 4/10 Train loss: 0.291069 Valid loss: 0.452929 Train acc: 0.873684 Valid acc: 0.852447\n",
      "Epoch: 4/10 Train loss: 0.344741 Valid loss: 0.452750 Train acc: 0.884211 Valid acc: 0.852510\n",
      "Epoch: 4/10 Train loss: 0.241875 Valid loss: 0.452562 Train acc: 0.926316 Valid acc: 0.852571\n",
      "Epoch: 4/10 Train loss: 0.277056 Valid loss: 0.452361 Train acc: 0.873684 Valid acc: 0.852630\n",
      "Epoch: 4/10 Train loss: 0.222614 Valid loss: 0.452146 Train acc: 0.947369 Valid acc: 0.852685\n",
      "Epoch: 4/10 Train loss: 0.364055 Valid loss: 0.451913 Train acc: 0.831579 Valid acc: 0.852740\n",
      "Epoch: 4/10 Train loss: 0.271213 Valid loss: 0.451663 Train acc: 0.915789 Valid acc: 0.852792\n",
      "Epoch: 4/10 Train loss: 0.243777 Valid loss: 0.451396 Train acc: 0.936842 Valid acc: 0.852841\n",
      "Epoch: 4/10 Train loss: 0.194740 Valid loss: 0.451111 Train acc: 0.947369 Valid acc: 0.852891\n",
      "Epoch: 5/10 Train loss: 0.247365 Valid loss: 0.450810 Train acc: 0.873684 Valid acc: 0.852944\n",
      "Epoch: 5/10 Train loss: 0.293080 Valid loss: 0.450493 Train acc: 0.863158 Valid acc: 0.852999\n",
      "Epoch: 5/10 Train loss: 0.361697 Valid loss: 0.450163 Train acc: 0.852632 Valid acc: 0.853052\n",
      "Epoch: 5/10 Train loss: 0.253097 Valid loss: 0.449824 Train acc: 0.894737 Valid acc: 0.853103\n",
      "Epoch: 5/10 Train loss: 0.238796 Valid loss: 0.449478 Train acc: 0.894737 Valid acc: 0.853154\n",
      "Epoch: 5/10 Train loss: 0.314576 Valid loss: 0.449128 Train acc: 0.905263 Valid acc: 0.853206\n",
      "Epoch: 5/10 Train loss: 0.467229 Valid loss: 0.448779 Train acc: 0.810526 Valid acc: 0.853264\n",
      "Epoch: 5/10 Train loss: 0.265904 Valid loss: 0.448430 Train acc: 0.905263 Valid acc: 0.853320\n",
      "Epoch: 5/10 Train loss: 0.198958 Valid loss: 0.448083 Train acc: 0.926316 Valid acc: 0.853370\n",
      "Epoch: 5/10 Train loss: 0.286387 Valid loss: 0.447738 Train acc: 0.863158 Valid acc: 0.853417\n",
      "Epoch: 5/10 Train loss: 0.256237 Valid loss: 0.447398 Train acc: 0.947369 Valid acc: 0.853461\n",
      "Epoch: 5/10 Train loss: 0.365681 Valid loss: 0.447066 Train acc: 0.873684 Valid acc: 0.853500\n",
      "Epoch: 5/10 Train loss: 0.211890 Valid loss: 0.446748 Train acc: 0.884211 Valid acc: 0.853532\n",
      "Epoch: 5/10 Train loss: 0.351539 Valid loss: 0.446446 Train acc: 0.852632 Valid acc: 0.853551\n",
      "Epoch: 5/10 Train loss: 0.197691 Valid loss: 0.446160 Train acc: 0.905263 Valid acc: 0.853565\n",
      "Epoch: 5/10 Train loss: 0.236337 Valid loss: 0.445893 Train acc: 0.894737 Valid acc: 0.853561\n",
      "Epoch: 5/10 Train loss: 0.435099 Valid loss: 0.445642 Train acc: 0.842105 Valid acc: 0.853553\n",
      "Epoch: 5/10 Train loss: 0.255384 Valid loss: 0.445386 Train acc: 0.873684 Valid acc: 0.853548\n",
      "Epoch: 5/10 Train loss: 0.256655 Valid loss: 0.445112 Train acc: 0.873684 Valid acc: 0.853553\n",
      "Epoch: 5/10 Train loss: 0.286065 Valid loss: 0.444800 Train acc: 0.884211 Valid acc: 0.853580\n",
      "Epoch: 5/10 Train loss: 0.462245 Valid loss: 0.444461 Train acc: 0.873684 Valid acc: 0.853638\n",
      "Epoch: 5/10 Train loss: 0.134216 Valid loss: 0.444104 Train acc: 0.926316 Valid acc: 0.853710\n",
      "Epoch: 5/10 Train loss: 0.345957 Valid loss: 0.443743 Train acc: 0.873684 Valid acc: 0.853785\n",
      "Epoch: 5/10 Train loss: 0.304407 Valid loss: 0.443387 Train acc: 0.884211 Valid acc: 0.853866\n",
      "Epoch: 5/10 Train loss: 0.128564 Valid loss: 0.443040 Train acc: 0.936842 Valid acc: 0.853942\n",
      "Epoch: 5/10 Train loss: 0.263084 Valid loss: 0.442703 Train acc: 0.936842 Valid acc: 0.854012\n",
      "Epoch: 5/10 Train loss: 0.240936 Valid loss: 0.442379 Train acc: 0.926316 Valid acc: 0.854075\n",
      "Epoch: 5/10 Train loss: 0.384995 Valid loss: 0.442073 Train acc: 0.873684 Valid acc: 0.854127\n",
      "Epoch: 5/10 Train loss: 0.158969 Valid loss: 0.441787 Train acc: 0.947369 Valid acc: 0.854175\n",
      "Epoch: 5/10 Train loss: 0.314137 Valid loss: 0.441520 Train acc: 0.894737 Valid acc: 0.854215\n",
      "Epoch: 5/10 Train loss: 0.102040 Valid loss: 0.441271 Train acc: 0.957895 Valid acc: 0.854247\n",
      "Epoch: 5/10 Train loss: 0.115080 Valid loss: 0.441035 Train acc: 0.968421 Valid acc: 0.854274\n",
      "Epoch: 5/10 Train loss: 0.075364 Valid loss: 0.440808 Train acc: 0.989474 Valid acc: 0.854293\n",
      "Epoch: 5/10 Train loss: 0.168359 Valid loss: 0.440588 Train acc: 0.936842 Valid acc: 0.854310\n",
      "Epoch: 5/10 Train loss: 0.238009 Valid loss: 0.440371 Train acc: 0.926316 Valid acc: 0.854324\n",
      "Epoch: 5/10 Train loss: 0.117020 Valid loss: 0.440159 Train acc: 0.968421 Valid acc: 0.854337\n",
      "Epoch: 5/10 Train loss: 0.083589 Valid loss: 0.439950 Train acc: 0.978947 Valid acc: 0.854350\n",
      "Epoch: 5/10 Train loss: 0.125013 Valid loss: 0.439744 Train acc: 0.936842 Valid acc: 0.854358\n",
      "Epoch: 5/10 Train loss: 0.101250 Valid loss: 0.439541 Train acc: 0.968421 Valid acc: 0.854364\n",
      "Epoch: 5/10 Train loss: 0.414496 Valid loss: 0.439340 Train acc: 0.852632 Valid acc: 0.854371\n",
      "Epoch: 5/10 Train loss: 0.519139 Valid loss: 0.439144 Train acc: 0.821053 Valid acc: 0.854376\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 Train loss: 0.328371 Valid loss: 0.438954 Train acc: 0.873684 Valid acc: 0.854382\n",
      "Epoch: 5/10 Train loss: 0.423176 Valid loss: 0.438771 Train acc: 0.821053 Valid acc: 0.854387\n",
      "Epoch: 5/10 Train loss: 0.366760 Valid loss: 0.438599 Train acc: 0.831579 Valid acc: 0.854391\n",
      "Epoch: 5/10 Train loss: 0.389498 Valid loss: 0.438444 Train acc: 0.842105 Valid acc: 0.854396\n",
      "Epoch: 5/10 Train loss: 0.435119 Valid loss: 0.438304 Train acc: 0.842105 Valid acc: 0.854401\n",
      "Epoch: 5/10 Train loss: 0.349757 Valid loss: 0.438178 Train acc: 0.821053 Valid acc: 0.854410\n",
      "Epoch: 5/10 Train loss: 0.222946 Valid loss: 0.438063 Train acc: 0.936842 Valid acc: 0.854421\n",
      "Epoch: 5/10 Train loss: 0.298878 Valid loss: 0.437958 Train acc: 0.884211 Valid acc: 0.854432\n",
      "Epoch: 5/10 Train loss: 0.373685 Valid loss: 0.437861 Train acc: 0.852632 Valid acc: 0.854446\n",
      "Epoch: 5/10 Train loss: 0.307083 Valid loss: 0.437767 Train acc: 0.863158 Valid acc: 0.854462\n",
      "Epoch: 5/10 Train loss: 0.382284 Valid loss: 0.437675 Train acc: 0.852632 Valid acc: 0.854481\n",
      "Epoch: 5/10 Train loss: 0.416495 Valid loss: 0.437581 Train acc: 0.821053 Valid acc: 0.854504\n",
      "Epoch: 5/10 Train loss: 0.343677 Valid loss: 0.437484 Train acc: 0.873684 Valid acc: 0.854531\n",
      "Epoch: 5/10 Train loss: 0.395220 Valid loss: 0.437382 Train acc: 0.810526 Valid acc: 0.854557\n",
      "Epoch: 5/10 Train loss: 0.441391 Valid loss: 0.437279 Train acc: 0.821053 Valid acc: 0.854584\n",
      "Epoch: 5/10 Train loss: 0.373498 Valid loss: 0.437172 Train acc: 0.831579 Valid acc: 0.854612\n",
      "Epoch: 5/10 Train loss: 0.313923 Valid loss: 0.437059 Train acc: 0.863158 Valid acc: 0.854646\n",
      "Epoch: 5/10 Train loss: 0.466504 Valid loss: 0.436943 Train acc: 0.810526 Valid acc: 0.854682\n",
      "Epoch: 5/10 Train loss: 0.326917 Valid loss: 0.436823 Train acc: 0.873684 Valid acc: 0.854722\n",
      "Epoch: 5/10 Train loss: 0.364178 Valid loss: 0.436701 Train acc: 0.863158 Valid acc: 0.854763\n",
      "Epoch: 5/10 Train loss: 0.278199 Valid loss: 0.436571 Train acc: 0.863158 Valid acc: 0.854813\n",
      "Epoch: 5/10 Train loss: 0.337446 Valid loss: 0.436435 Train acc: 0.842105 Valid acc: 0.854861\n",
      "Epoch: 5/10 Train loss: 0.524792 Valid loss: 0.436297 Train acc: 0.810526 Valid acc: 0.854911\n",
      "Epoch: 5/10 Train loss: 0.509754 Valid loss: 0.436162 Train acc: 0.789474 Valid acc: 0.854958\n",
      "Epoch: 5/10 Train loss: 0.606904 Valid loss: 0.436036 Train acc: 0.789474 Valid acc: 0.855001\n",
      "Epoch: 5/10 Train loss: 0.505791 Valid loss: 0.435921 Train acc: 0.810526 Valid acc: 0.855039\n",
      "Epoch: 5/10 Train loss: 0.481205 Valid loss: 0.435820 Train acc: 0.821053 Valid acc: 0.855076\n",
      "Epoch: 5/10 Train loss: 0.540057 Valid loss: 0.435734 Train acc: 0.831579 Valid acc: 0.855106\n",
      "Epoch: 5/10 Train loss: 0.358554 Valid loss: 0.435661 Train acc: 0.842105 Valid acc: 0.855136\n",
      "Epoch: 5/10 Train loss: 0.442482 Valid loss: 0.435601 Train acc: 0.810526 Valid acc: 0.855165\n",
      "Epoch: 5/10 Train loss: 0.410969 Valid loss: 0.435551 Train acc: 0.831579 Valid acc: 0.855188\n",
      "Epoch: 5/10 Train loss: 0.357983 Valid loss: 0.435509 Train acc: 0.831579 Valid acc: 0.855205\n",
      "Epoch: 5/10 Train loss: 0.365901 Valid loss: 0.435474 Train acc: 0.852632 Valid acc: 0.855220\n",
      "Epoch: 5/10 Train loss: 0.365382 Valid loss: 0.435441 Train acc: 0.821053 Valid acc: 0.855236\n",
      "Epoch: 5/10 Train loss: 0.357054 Valid loss: 0.435407 Train acc: 0.852632 Valid acc: 0.855251\n",
      "Epoch: 5/10 Train loss: 0.384394 Valid loss: 0.435369 Train acc: 0.831579 Valid acc: 0.855264\n",
      "Epoch: 5/10 Train loss: 0.368244 Valid loss: 0.435326 Train acc: 0.842105 Valid acc: 0.855277\n",
      "Epoch: 5/10 Train loss: 0.402407 Valid loss: 0.435275 Train acc: 0.821053 Valid acc: 0.855290\n",
      "Epoch: 5/10 Train loss: 0.337767 Valid loss: 0.435214 Train acc: 0.852632 Valid acc: 0.855303\n",
      "Epoch: 5/10 Train loss: 0.343733 Valid loss: 0.435141 Train acc: 0.831579 Valid acc: 0.855318\n",
      "Epoch: 5/10 Train loss: 0.306063 Valid loss: 0.435056 Train acc: 0.842105 Valid acc: 0.855334\n",
      "Epoch: 5/10 Train loss: 0.322445 Valid loss: 0.434958 Train acc: 0.842105 Valid acc: 0.855353\n",
      "Epoch: 5/10 Train loss: 0.327348 Valid loss: 0.434848 Train acc: 0.831579 Valid acc: 0.855373\n",
      "Epoch: 5/10 Train loss: 0.307035 Valid loss: 0.434726 Train acc: 0.852632 Valid acc: 0.855396\n",
      "Epoch: 5/10 Train loss: 0.300687 Valid loss: 0.434593 Train acc: 0.873684 Valid acc: 0.855424\n",
      "Epoch: 5/10 Train loss: 0.312865 Valid loss: 0.434449 Train acc: 0.852632 Valid acc: 0.855453\n",
      "Epoch: 5/10 Train loss: 0.303909 Valid loss: 0.434299 Train acc: 0.863158 Valid acc: 0.855493\n",
      "Epoch: 5/10 Train loss: 0.382413 Valid loss: 0.434150 Train acc: 0.873684 Valid acc: 0.855532\n",
      "Epoch: 5/10 Train loss: 0.392517 Valid loss: 0.434004 Train acc: 0.852632 Valid acc: 0.855576\n",
      "Epoch: 5/10 Train loss: 0.266899 Valid loss: 0.433859 Train acc: 0.894737 Valid acc: 0.855625\n",
      "Epoch: 5/10 Train loss: 0.286093 Valid loss: 0.433717 Train acc: 0.894737 Valid acc: 0.855681\n",
      "Epoch: 5/10 Train loss: 0.277910 Valid loss: 0.433574 Train acc: 0.884211 Valid acc: 0.855740\n",
      "Epoch: 5/10 Train loss: 0.225654 Valid loss: 0.433429 Train acc: 0.936842 Valid acc: 0.855796\n",
      "Epoch: 5/10 Train loss: 0.298915 Valid loss: 0.433278 Train acc: 0.905263 Valid acc: 0.855851\n",
      "Epoch: 5/10 Train loss: 0.255044 Valid loss: 0.433119 Train acc: 0.884211 Valid acc: 0.855906\n",
      "Epoch: 5/10 Train loss: 0.354179 Valid loss: 0.432950 Train acc: 0.873684 Valid acc: 0.855957\n",
      "Epoch: 5/10 Train loss: 0.254611 Valid loss: 0.432772 Train acc: 0.884211 Valid acc: 0.856006\n",
      "Epoch: 5/10 Train loss: 0.283349 Valid loss: 0.432583 Train acc: 0.873684 Valid acc: 0.856054\n",
      "Epoch: 5/10 Train loss: 0.239038 Valid loss: 0.432380 Train acc: 0.915789 Valid acc: 0.856105\n",
      "Epoch: 6/10 Train loss: 0.239956 Valid loss: 0.432165 Train acc: 0.936842 Valid acc: 0.856152\n",
      "Epoch: 6/10 Train loss: 0.225956 Valid loss: 0.431935 Train acc: 0.905263 Valid acc: 0.856197\n",
      "Epoch: 6/10 Train loss: 0.375077 Valid loss: 0.431696 Train acc: 0.852632 Valid acc: 0.856242\n",
      "Epoch: 6/10 Train loss: 0.258156 Valid loss: 0.431447 Train acc: 0.915789 Valid acc: 0.856289\n",
      "Epoch: 6/10 Train loss: 0.212192 Valid loss: 0.431191 Train acc: 0.894737 Valid acc: 0.856337\n",
      "Epoch: 6/10 Train loss: 0.292184 Valid loss: 0.430928 Train acc: 0.894737 Valid acc: 0.856385\n",
      "Epoch: 6/10 Train loss: 0.389555 Valid loss: 0.430663 Train acc: 0.852632 Valid acc: 0.856433\n",
      "Epoch: 6/10 Train loss: 0.255963 Valid loss: 0.430396 Train acc: 0.915789 Valid acc: 0.856479\n",
      "Epoch: 6/10 Train loss: 0.178738 Valid loss: 0.430127 Train acc: 0.968421 Valid acc: 0.856523\n",
      "Epoch: 6/10 Train loss: 0.231426 Valid loss: 0.429857 Train acc: 0.905263 Valid acc: 0.856564\n",
      "Epoch: 6/10 Train loss: 0.283076 Valid loss: 0.429587 Train acc: 0.936842 Valid acc: 0.856604\n",
      "Epoch: 6/10 Train loss: 0.273345 Valid loss: 0.429318 Train acc: 0.894737 Valid acc: 0.856644\n",
      "Epoch: 6/10 Train loss: 0.240985 Valid loss: 0.429054 Train acc: 0.905263 Valid acc: 0.856679\n",
      "Epoch: 6/10 Train loss: 0.414292 Valid loss: 0.428798 Train acc: 0.842105 Valid acc: 0.856707\n",
      "Epoch: 6/10 Train loss: 0.201707 Valid loss: 0.428554 Train acc: 0.905263 Valid acc: 0.856732\n",
      "Epoch: 6/10 Train loss: 0.250453 Valid loss: 0.428324 Train acc: 0.863158 Valid acc: 0.856751\n",
      "Epoch: 6/10 Train loss: 0.372727 Valid loss: 0.428105 Train acc: 0.873684 Valid acc: 0.856761\n",
      "Epoch: 6/10 Train loss: 0.258535 Valid loss: 0.427891 Train acc: 0.905263 Valid acc: 0.856766\n",
      "Epoch: 6/10 Train loss: 0.193500 Valid loss: 0.427671 Train acc: 0.926316 Valid acc: 0.856775\n",
      "Epoch: 6/10 Train loss: 0.331007 Valid loss: 0.427422 Train acc: 0.894737 Valid acc: 0.856802\n",
      "Epoch: 6/10 Train loss: 0.385071 Valid loss: 0.427151 Train acc: 0.863158 Valid acc: 0.856850\n",
      "Epoch: 6/10 Train loss: 0.146576 Valid loss: 0.426865 Train acc: 0.936842 Valid acc: 0.856915\n",
      "Epoch: 6/10 Train loss: 0.192977 Valid loss: 0.426571 Train acc: 0.905263 Valid acc: 0.856981\n",
      "Epoch: 6/10 Train loss: 0.223510 Valid loss: 0.426276 Train acc: 0.905263 Valid acc: 0.857048\n",
      "Epoch: 6/10 Train loss: 0.112535 Valid loss: 0.425987 Train acc: 0.968421 Valid acc: 0.857112\n",
      "Epoch: 6/10 Train loss: 0.205880 Valid loss: 0.425705 Train acc: 0.915789 Valid acc: 0.857172\n",
      "Epoch: 6/10 Train loss: 0.241516 Valid loss: 0.425429 Train acc: 0.936842 Valid acc: 0.857227\n",
      "Epoch: 6/10 Train loss: 0.431188 Valid loss: 0.425159 Train acc: 0.894737 Valid acc: 0.857275\n",
      "Epoch: 6/10 Train loss: 0.312804 Valid loss: 0.424900 Train acc: 0.915789 Valid acc: 0.857323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 Train loss: 0.203688 Valid loss: 0.424652 Train acc: 0.915790 Valid acc: 0.857366\n",
      "Epoch: 6/10 Train loss: 0.080997 Valid loss: 0.424420 Train acc: 0.989474 Valid acc: 0.857407\n",
      "Epoch: 6/10 Train loss: 0.154180 Valid loss: 0.424200 Train acc: 0.947369 Valid acc: 0.857440\n",
      "Epoch: 6/10 Train loss: 0.077385 Valid loss: 0.423991 Train acc: 0.968421 Valid acc: 0.857468\n",
      "Epoch: 6/10 Train loss: 0.196666 Valid loss: 0.423790 Train acc: 0.947369 Valid acc: 0.857493\n",
      "Epoch: 6/10 Train loss: 0.176937 Valid loss: 0.423594 Train acc: 0.936842 Valid acc: 0.857516\n",
      "Epoch: 6/10 Train loss: 0.124680 Valid loss: 0.423402 Train acc: 0.947369 Valid acc: 0.857540\n",
      "Epoch: 6/10 Train loss: 0.121585 Valid loss: 0.423212 Train acc: 0.968421 Valid acc: 0.857560\n",
      "Epoch: 6/10 Train loss: 0.097635 Valid loss: 0.423023 Train acc: 0.968421 Valid acc: 0.857578\n",
      "Epoch: 6/10 Train loss: 0.143584 Valid loss: 0.422836 Train acc: 0.947369 Valid acc: 0.857594\n",
      "Epoch: 6/10 Train loss: 0.393614 Valid loss: 0.422651 Train acc: 0.821053 Valid acc: 0.857610\n",
      "Epoch: 6/10 Train loss: 0.438986 Valid loss: 0.422472 Train acc: 0.831579 Valid acc: 0.857624\n",
      "Epoch: 6/10 Train loss: 0.296433 Valid loss: 0.422299 Train acc: 0.863158 Valid acc: 0.857639\n",
      "Epoch: 6/10 Train loss: 0.380711 Valid loss: 0.422133 Train acc: 0.842105 Valid acc: 0.857653\n",
      "Epoch: 6/10 Train loss: 0.340403 Valid loss: 0.421975 Train acc: 0.831579 Valid acc: 0.857671\n",
      "Epoch: 6/10 Train loss: 0.384152 Valid loss: 0.421827 Train acc: 0.873684 Valid acc: 0.857691\n",
      "Epoch: 6/10 Train loss: 0.430658 Valid loss: 0.421689 Train acc: 0.831579 Valid acc: 0.857711\n",
      "Epoch: 6/10 Train loss: 0.355638 Valid loss: 0.421563 Train acc: 0.842105 Valid acc: 0.857732\n",
      "Epoch: 6/10 Train loss: 0.257098 Valid loss: 0.421445 Train acc: 0.894737 Valid acc: 0.857751\n",
      "Epoch: 6/10 Train loss: 0.294080 Valid loss: 0.421336 Train acc: 0.873684 Valid acc: 0.857770\n",
      "Epoch: 6/10 Train loss: 0.368553 Valid loss: 0.421235 Train acc: 0.842105 Valid acc: 0.857792\n",
      "Epoch: 6/10 Train loss: 0.281349 Valid loss: 0.421139 Train acc: 0.884211 Valid acc: 0.857815\n",
      "Epoch: 6/10 Train loss: 0.401092 Valid loss: 0.421047 Train acc: 0.852632 Valid acc: 0.857839\n",
      "Epoch: 6/10 Train loss: 0.419655 Valid loss: 0.420959 Train acc: 0.821053 Valid acc: 0.857865\n",
      "Epoch: 6/10 Train loss: 0.321284 Valid loss: 0.420871 Train acc: 0.873684 Valid acc: 0.857890\n",
      "Epoch: 6/10 Train loss: 0.354536 Valid loss: 0.420782 Train acc: 0.852632 Valid acc: 0.857919\n",
      "Epoch: 6/10 Train loss: 0.424855 Valid loss: 0.420692 Train acc: 0.842105 Valid acc: 0.857947\n",
      "Epoch: 6/10 Train loss: 0.401117 Valid loss: 0.420601 Train acc: 0.821053 Valid acc: 0.857977\n",
      "Epoch: 6/10 Train loss: 0.324443 Valid loss: 0.420505 Train acc: 0.852632 Valid acc: 0.858010\n",
      "Epoch: 6/10 Train loss: 0.419664 Valid loss: 0.420407 Train acc: 0.789474 Valid acc: 0.858045\n",
      "Epoch: 6/10 Train loss: 0.284242 Valid loss: 0.420302 Train acc: 0.873684 Valid acc: 0.858078\n",
      "Epoch: 6/10 Train loss: 0.337403 Valid loss: 0.420192 Train acc: 0.884211 Valid acc: 0.858112\n",
      "Epoch: 6/10 Train loss: 0.236973 Valid loss: 0.420073 Train acc: 0.905263 Valid acc: 0.858147\n",
      "Epoch: 6/10 Train loss: 0.372539 Valid loss: 0.419947 Train acc: 0.821053 Valid acc: 0.858184\n",
      "Epoch: 6/10 Train loss: 0.551302 Valid loss: 0.419818 Train acc: 0.810526 Valid acc: 0.858220\n",
      "Epoch: 6/10 Train loss: 0.591522 Valid loss: 0.419691 Train acc: 0.821053 Valid acc: 0.858253\n",
      "Epoch: 6/10 Train loss: 0.603285 Valid loss: 0.419572 Train acc: 0.789474 Valid acc: 0.858283\n",
      "Epoch: 6/10 Train loss: 0.543894 Valid loss: 0.419461 Train acc: 0.778947 Valid acc: 0.858311\n",
      "Epoch: 6/10 Train loss: 0.463522 Valid loss: 0.419361 Train acc: 0.821053 Valid acc: 0.858337\n",
      "Epoch: 6/10 Train loss: 0.509439 Valid loss: 0.419273 Train acc: 0.821053 Valid acc: 0.858361\n",
      "Epoch: 6/10 Train loss: 0.331978 Valid loss: 0.419196 Train acc: 0.842105 Valid acc: 0.858386\n",
      "Epoch: 6/10 Train loss: 0.426056 Valid loss: 0.419127 Train acc: 0.800000 Valid acc: 0.858406\n",
      "Epoch: 6/10 Train loss: 0.389198 Valid loss: 0.419065 Train acc: 0.831579 Valid acc: 0.858423\n",
      "Epoch: 6/10 Train loss: 0.366442 Valid loss: 0.419009 Train acc: 0.831579 Valid acc: 0.858440\n",
      "Epoch: 6/10 Train loss: 0.358536 Valid loss: 0.418957 Train acc: 0.852632 Valid acc: 0.858457\n",
      "Epoch: 6/10 Train loss: 0.340253 Valid loss: 0.418908 Train acc: 0.831579 Valid acc: 0.858473\n",
      "Epoch: 6/10 Train loss: 0.343533 Valid loss: 0.418857 Train acc: 0.863158 Valid acc: 0.858488\n",
      "Epoch: 6/10 Train loss: 0.382213 Valid loss: 0.418804 Train acc: 0.831579 Valid acc: 0.858502\n",
      "Epoch: 6/10 Train loss: 0.345536 Valid loss: 0.418745 Train acc: 0.852632 Valid acc: 0.858515\n",
      "Epoch: 6/10 Train loss: 0.378383 Valid loss: 0.418680 Train acc: 0.810526 Valid acc: 0.858530\n",
      "Epoch: 6/10 Train loss: 0.318212 Valid loss: 0.418608 Train acc: 0.852632 Valid acc: 0.858544\n",
      "Epoch: 6/10 Train loss: 0.320851 Valid loss: 0.418528 Train acc: 0.831579 Valid acc: 0.858560\n",
      "Epoch: 6/10 Train loss: 0.345606 Valid loss: 0.418440 Train acc: 0.852632 Valid acc: 0.858578\n",
      "Epoch: 6/10 Train loss: 0.326050 Valid loss: 0.418343 Train acc: 0.842105 Valid acc: 0.858598\n",
      "Epoch: 6/10 Train loss: 0.318113 Valid loss: 0.418238 Train acc: 0.842105 Valid acc: 0.858621\n",
      "Epoch: 6/10 Train loss: 0.294182 Valid loss: 0.418126 Train acc: 0.852632 Valid acc: 0.858647\n",
      "Epoch: 6/10 Train loss: 0.294785 Valid loss: 0.418005 Train acc: 0.873684 Valid acc: 0.858674\n",
      "Epoch: 6/10 Train loss: 0.256311 Valid loss: 0.417877 Train acc: 0.873684 Valid acc: 0.858705\n",
      "Epoch: 6/10 Train loss: 0.414177 Valid loss: 0.417747 Train acc: 0.905263 Valid acc: 0.858741\n",
      "Epoch: 6/10 Train loss: 0.328331 Valid loss: 0.417616 Train acc: 0.852632 Valid acc: 0.858778\n",
      "Epoch: 6/10 Train loss: 0.383064 Valid loss: 0.417485 Train acc: 0.821053 Valid acc: 0.858821\n",
      "Epoch: 6/10 Train loss: 0.272806 Valid loss: 0.417352 Train acc: 0.905263 Valid acc: 0.858863\n",
      "Epoch: 6/10 Train loss: 0.254092 Valid loss: 0.417217 Train acc: 0.894737 Valid acc: 0.858910\n",
      "Epoch: 6/10 Train loss: 0.300390 Valid loss: 0.417078 Train acc: 0.894737 Valid acc: 0.858959\n",
      "Epoch: 6/10 Train loss: 0.221654 Valid loss: 0.416935 Train acc: 0.926316 Valid acc: 0.859005\n",
      "Epoch: 6/10 Train loss: 0.289413 Valid loss: 0.416787 Train acc: 0.936842 Valid acc: 0.859054\n",
      "Epoch: 6/10 Train loss: 0.228890 Valid loss: 0.416632 Train acc: 0.905263 Valid acc: 0.859098\n",
      "Epoch: 6/10 Train loss: 0.315770 Valid loss: 0.416471 Train acc: 0.905263 Valid acc: 0.859137\n",
      "Epoch: 6/10 Train loss: 0.227137 Valid loss: 0.416303 Train acc: 0.926316 Valid acc: 0.859173\n",
      "Epoch: 6/10 Train loss: 0.271346 Valid loss: 0.416128 Train acc: 0.873684 Valid acc: 0.859206\n",
      "Epoch: 6/10 Train loss: 0.201217 Valid loss: 0.415948 Train acc: 0.915789 Valid acc: 0.859237\n",
      "Epoch: 7/10 Train loss: 0.248512 Valid loss: 0.415762 Train acc: 0.894737 Valid acc: 0.859265\n",
      "Epoch: 7/10 Train loss: 0.261612 Valid loss: 0.415572 Train acc: 0.915789 Valid acc: 0.859294\n",
      "Epoch: 7/10 Train loss: 0.395839 Valid loss: 0.415379 Train acc: 0.842105 Valid acc: 0.859321\n",
      "Epoch: 7/10 Train loss: 0.301172 Valid loss: 0.415186 Train acc: 0.863158 Valid acc: 0.859349\n",
      "Epoch: 7/10 Train loss: 0.247264 Valid loss: 0.414993 Train acc: 0.894737 Valid acc: 0.859374\n",
      "Epoch: 7/10 Train loss: 0.333513 Valid loss: 0.414801 Train acc: 0.905263 Valid acc: 0.859399\n",
      "Epoch: 7/10 Train loss: 0.395376 Valid loss: 0.414612 Train acc: 0.852632 Valid acc: 0.859422\n",
      "Epoch: 7/10 Train loss: 0.257122 Valid loss: 0.414424 Train acc: 0.905263 Valid acc: 0.859442\n",
      "Epoch: 7/10 Train loss: 0.191286 Valid loss: 0.414237 Train acc: 0.947369 Valid acc: 0.859464\n",
      "Epoch: 7/10 Train loss: 0.222691 Valid loss: 0.414048 Train acc: 0.905263 Valid acc: 0.859486\n",
      "Epoch: 7/10 Train loss: 0.271587 Valid loss: 0.413857 Train acc: 0.915790 Valid acc: 0.859509\n",
      "Epoch: 7/10 Train loss: 0.274732 Valid loss: 0.413666 Train acc: 0.926316 Valid acc: 0.859532\n",
      "Epoch: 7/10 Train loss: 0.307616 Valid loss: 0.413476 Train acc: 0.894737 Valid acc: 0.859551\n",
      "Epoch: 7/10 Train loss: 0.348946 Valid loss: 0.413291 Train acc: 0.842105 Valid acc: 0.859569\n",
      "Epoch: 7/10 Train loss: 0.216508 Valid loss: 0.413110 Train acc: 0.936842 Valid acc: 0.859584\n",
      "Epoch: 7/10 Train loss: 0.200000 Valid loss: 0.412935 Train acc: 0.926316 Valid acc: 0.859598\n",
      "Epoch: 7/10 Train loss: 0.392953 Valid loss: 0.412764 Train acc: 0.831579 Valid acc: 0.859609\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 Train loss: 0.253211 Valid loss: 0.412591 Train acc: 0.894737 Valid acc: 0.859620\n",
      "Epoch: 7/10 Train loss: 0.183862 Valid loss: 0.412414 Train acc: 0.905263 Valid acc: 0.859633\n",
      "Epoch: 7/10 Train loss: 0.172122 Valid loss: 0.412222 Train acc: 0.936842 Valid acc: 0.859655\n",
      "Epoch: 7/10 Train loss: 0.220074 Valid loss: 0.412014 Train acc: 0.905263 Valid acc: 0.859690\n",
      "Epoch: 7/10 Train loss: 0.072989 Valid loss: 0.411796 Train acc: 0.978947 Valid acc: 0.859734\n",
      "Epoch: 7/10 Train loss: 0.159673 Valid loss: 0.411577 Train acc: 0.905263 Valid acc: 0.859780\n",
      "Epoch: 7/10 Train loss: 0.230281 Valid loss: 0.411363 Train acc: 0.915790 Valid acc: 0.859823\n",
      "Epoch: 7/10 Train loss: 0.126621 Valid loss: 0.411164 Train acc: 0.936842 Valid acc: 0.859857\n",
      "Epoch: 7/10 Train loss: 0.178587 Valid loss: 0.410982 Train acc: 0.936842 Valid acc: 0.859880\n",
      "Epoch: 7/10 Train loss: 0.080349 Valid loss: 0.410815 Train acc: 0.947369 Valid acc: 0.859898\n",
      "Epoch: 7/10 Train loss: 0.491219 Valid loss: 0.410649 Train acc: 0.894737 Valid acc: 0.859914\n",
      "Epoch: 7/10 Train loss: 0.261095 Valid loss: 0.410478 Train acc: 0.926316 Valid acc: 0.859929\n",
      "Epoch: 7/10 Train loss: 0.239858 Valid loss: 0.410306 Train acc: 0.915789 Valid acc: 0.859946\n",
      "Epoch: 7/10 Train loss: 0.122690 Valid loss: 0.410132 Train acc: 0.957895 Valid acc: 0.859964\n",
      "Epoch: 7/10 Train loss: 0.102598 Valid loss: 0.409961 Train acc: 0.947369 Valid acc: 0.859980\n",
      "Epoch: 7/10 Train loss: 0.068534 Valid loss: 0.409795 Train acc: 0.978947 Valid acc: 0.859995\n",
      "Epoch: 7/10 Train loss: 0.188425 Valid loss: 0.409635 Train acc: 0.936842 Valid acc: 0.860006\n",
      "Epoch: 7/10 Train loss: 0.189702 Valid loss: 0.409482 Train acc: 0.926316 Valid acc: 0.860018\n",
      "Epoch: 7/10 Train loss: 0.111967 Valid loss: 0.409335 Train acc: 0.968421 Valid acc: 0.860028\n",
      "Epoch: 7/10 Train loss: 0.104879 Valid loss: 0.409195 Train acc: 0.968421 Valid acc: 0.860036\n",
      "Epoch: 7/10 Train loss: 0.122266 Valid loss: 0.409058 Train acc: 0.947368 Valid acc: 0.860043\n",
      "Epoch: 7/10 Train loss: 0.159827 Valid loss: 0.408924 Train acc: 0.947369 Valid acc: 0.860049\n",
      "Epoch: 7/10 Train loss: 0.393461 Valid loss: 0.408791 Train acc: 0.821053 Valid acc: 0.860054\n",
      "Epoch: 7/10 Train loss: 0.487219 Valid loss: 0.408662 Train acc: 0.821053 Valid acc: 0.860059\n",
      "Epoch: 7/10 Train loss: 0.309913 Valid loss: 0.408536 Train acc: 0.863158 Valid acc: 0.860065\n",
      "Epoch: 7/10 Train loss: 0.370389 Valid loss: 0.408415 Train acc: 0.821053 Valid acc: 0.860069\n",
      "Epoch: 7/10 Train loss: 0.346759 Valid loss: 0.408301 Train acc: 0.821053 Valid acc: 0.860072\n",
      "Epoch: 7/10 Train loss: 0.378245 Valid loss: 0.408193 Train acc: 0.842105 Valid acc: 0.860077\n",
      "Epoch: 7/10 Train loss: 0.379824 Valid loss: 0.408091 Train acc: 0.810526 Valid acc: 0.860084\n",
      "Epoch: 7/10 Train loss: 0.363522 Valid loss: 0.407996 Train acc: 0.842105 Valid acc: 0.860096\n",
      "Epoch: 7/10 Train loss: 0.257389 Valid loss: 0.407907 Train acc: 0.915789 Valid acc: 0.860109\n",
      "Epoch: 7/10 Train loss: 0.257587 Valid loss: 0.407824 Train acc: 0.873684 Valid acc: 0.860127\n",
      "Epoch: 7/10 Train loss: 0.409187 Valid loss: 0.407744 Train acc: 0.831579 Valid acc: 0.860145\n",
      "Epoch: 7/10 Train loss: 0.294843 Valid loss: 0.407667 Train acc: 0.873684 Valid acc: 0.860165\n",
      "Epoch: 7/10 Train loss: 0.353317 Valid loss: 0.407590 Train acc: 0.873684 Valid acc: 0.860187\n",
      "Epoch: 7/10 Train loss: 0.407719 Valid loss: 0.407513 Train acc: 0.810526 Valid acc: 0.860211\n",
      "Epoch: 7/10 Train loss: 0.319046 Valid loss: 0.407435 Train acc: 0.894737 Valid acc: 0.860237\n",
      "Epoch: 7/10 Train loss: 0.343379 Valid loss: 0.407353 Train acc: 0.863158 Valid acc: 0.860262\n",
      "Epoch: 7/10 Train loss: 0.401840 Valid loss: 0.407270 Train acc: 0.821053 Valid acc: 0.860290\n",
      "Epoch: 7/10 Train loss: 0.351016 Valid loss: 0.407183 Train acc: 0.831579 Valid acc: 0.860319\n",
      "Epoch: 7/10 Train loss: 0.306122 Valid loss: 0.407091 Train acc: 0.905263 Valid acc: 0.860348\n",
      "Epoch: 7/10 Train loss: 0.361041 Valid loss: 0.406995 Train acc: 0.863158 Valid acc: 0.860378\n",
      "Epoch: 7/10 Train loss: 0.297612 Valid loss: 0.406893 Train acc: 0.852632 Valid acc: 0.860408\n",
      "Epoch: 7/10 Train loss: 0.294964 Valid loss: 0.406786 Train acc: 0.873684 Valid acc: 0.860437\n",
      "Epoch: 7/10 Train loss: 0.244375 Valid loss: 0.406672 Train acc: 0.905263 Valid acc: 0.860467\n",
      "Epoch: 7/10 Train loss: 0.317514 Valid loss: 0.406553 Train acc: 0.905263 Valid acc: 0.860496\n",
      "Epoch: 7/10 Train loss: 0.605232 Valid loss: 0.406435 Train acc: 0.800000 Valid acc: 0.860527\n",
      "Epoch: 7/10 Train loss: 0.568724 Valid loss: 0.406322 Train acc: 0.768421 Valid acc: 0.860558\n",
      "Epoch: 7/10 Train loss: 0.669784 Valid loss: 0.406218 Train acc: 0.778947 Valid acc: 0.860587\n",
      "Epoch: 7/10 Train loss: 0.499991 Valid loss: 0.406126 Train acc: 0.810526 Valid acc: 0.860616\n",
      "Epoch: 7/10 Train loss: 0.497666 Valid loss: 0.406048 Train acc: 0.789474 Valid acc: 0.860644\n",
      "Epoch: 7/10 Train loss: 0.559664 Valid loss: 0.405987 Train acc: 0.789474 Valid acc: 0.860671\n",
      "Epoch: 7/10 Train loss: 0.329684 Valid loss: 0.405938 Train acc: 0.831579 Valid acc: 0.860694\n",
      "Epoch: 7/10 Train loss: 0.388515 Valid loss: 0.405898 Train acc: 0.842105 Valid acc: 0.860716\n",
      "Epoch: 7/10 Train loss: 0.360241 Valid loss: 0.405865 Train acc: 0.863158 Valid acc: 0.860734\n",
      "Epoch: 7/10 Train loss: 0.360742 Valid loss: 0.405836 Train acc: 0.842105 Valid acc: 0.860749\n",
      "Epoch: 7/10 Train loss: 0.367412 Valid loss: 0.405811 Train acc: 0.863158 Valid acc: 0.860764\n",
      "Epoch: 7/10 Train loss: 0.335377 Valid loss: 0.405785 Train acc: 0.863158 Valid acc: 0.860778\n",
      "Epoch: 7/10 Train loss: 0.320861 Valid loss: 0.405757 Train acc: 0.863158 Valid acc: 0.860791\n",
      "Epoch: 7/10 Train loss: 0.377319 Valid loss: 0.405725 Train acc: 0.842105 Valid acc: 0.860803\n",
      "Epoch: 7/10 Train loss: 0.344506 Valid loss: 0.405687 Train acc: 0.852632 Valid acc: 0.860816\n",
      "Epoch: 7/10 Train loss: 0.377595 Valid loss: 0.405643 Train acc: 0.810526 Valid acc: 0.860828\n",
      "Epoch: 7/10 Train loss: 0.300154 Valid loss: 0.405592 Train acc: 0.863158 Valid acc: 0.860840\n",
      "Epoch: 7/10 Train loss: 0.311488 Valid loss: 0.405532 Train acc: 0.852632 Valid acc: 0.860853\n",
      "Epoch: 7/10 Train loss: 0.300703 Valid loss: 0.405465 Train acc: 0.842105 Valid acc: 0.860865\n",
      "Epoch: 7/10 Train loss: 0.315138 Valid loss: 0.405389 Train acc: 0.863158 Valid acc: 0.860880\n",
      "Epoch: 7/10 Train loss: 0.329601 Valid loss: 0.405307 Train acc: 0.863158 Valid acc: 0.860895\n",
      "Epoch: 7/10 Train loss: 0.277535 Valid loss: 0.405219 Train acc: 0.863158 Valid acc: 0.860912\n",
      "Epoch: 7/10 Train loss: 0.325804 Valid loss: 0.405126 Train acc: 0.852632 Valid acc: 0.860931\n",
      "Epoch: 7/10 Train loss: 0.308139 Valid loss: 0.405028 Train acc: 0.863158 Valid acc: 0.860956\n",
      "Epoch: 7/10 Train loss: 0.225887 Valid loss: 0.404926 Train acc: 0.915789 Valid acc: 0.860982\n",
      "Epoch: 7/10 Train loss: 0.298276 Valid loss: 0.404823 Train acc: 0.863158 Valid acc: 0.861009\n",
      "Epoch: 7/10 Train loss: 0.283071 Valid loss: 0.404719 Train acc: 0.905263 Valid acc: 0.861041\n",
      "Epoch: 7/10 Train loss: 0.208681 Valid loss: 0.404612 Train acc: 0.926316 Valid acc: 0.861075\n",
      "Epoch: 7/10 Train loss: 0.263481 Valid loss: 0.404503 Train acc: 0.905263 Valid acc: 0.861110\n",
      "Epoch: 7/10 Train loss: 0.280595 Valid loss: 0.404391 Train acc: 0.873684 Valid acc: 0.861145\n",
      "Epoch: 7/10 Train loss: 0.186497 Valid loss: 0.404275 Train acc: 0.926316 Valid acc: 0.861181\n",
      "Epoch: 7/10 Train loss: 0.251709 Valid loss: 0.404156 Train acc: 0.915790 Valid acc: 0.861215\n",
      "Epoch: 7/10 Train loss: 0.202375 Valid loss: 0.404031 Train acc: 0.926316 Valid acc: 0.861246\n",
      "Epoch: 7/10 Train loss: 0.350205 Valid loss: 0.403901 Train acc: 0.863158 Valid acc: 0.861281\n",
      "Epoch: 7/10 Train loss: 0.221855 Valid loss: 0.403765 Train acc: 0.905263 Valid acc: 0.861315\n",
      "Epoch: 7/10 Train loss: 0.265234 Valid loss: 0.403624 Train acc: 0.884211 Valid acc: 0.861348\n",
      "Epoch: 7/10 Train loss: 0.170775 Valid loss: 0.403478 Train acc: 0.915789 Valid acc: 0.861380\n",
      "Epoch: 8/10 Train loss: 0.235596 Valid loss: 0.403326 Train acc: 0.863158 Valid acc: 0.861411\n",
      "Epoch: 8/10 Train loss: 0.293604 Valid loss: 0.403169 Train acc: 0.863158 Valid acc: 0.861442\n",
      "Epoch: 8/10 Train loss: 0.357901 Valid loss: 0.403009 Train acc: 0.863158 Valid acc: 0.861473\n",
      "Epoch: 8/10 Train loss: 0.290446 Valid loss: 0.402849 Train acc: 0.873684 Valid acc: 0.861502\n",
      "Epoch: 8/10 Train loss: 0.198038 Valid loss: 0.402687 Train acc: 0.915789 Valid acc: 0.861531\n",
      "Epoch: 8/10 Train loss: 0.327237 Valid loss: 0.402524 Train acc: 0.905263 Valid acc: 0.861558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Train loss: 0.372214 Valid loss: 0.402364 Train acc: 0.831579 Valid acc: 0.861583\n",
      "Epoch: 8/10 Train loss: 0.264061 Valid loss: 0.402207 Train acc: 0.915789 Valid acc: 0.861607\n",
      "Epoch: 8/10 Train loss: 0.179267 Valid loss: 0.402053 Train acc: 0.947369 Valid acc: 0.861629\n",
      "Epoch: 8/10 Train loss: 0.209518 Valid loss: 0.401901 Train acc: 0.926316 Valid acc: 0.861645\n",
      "Epoch: 8/10 Train loss: 0.303186 Valid loss: 0.401753 Train acc: 0.947368 Valid acc: 0.861659\n",
      "Epoch: 8/10 Train loss: 0.296938 Valid loss: 0.401607 Train acc: 0.894737 Valid acc: 0.861675\n",
      "Epoch: 8/10 Train loss: 0.229850 Valid loss: 0.401464 Train acc: 0.915790 Valid acc: 0.861690\n",
      "Epoch: 8/10 Train loss: 0.349608 Valid loss: 0.401325 Train acc: 0.852632 Valid acc: 0.861703\n",
      "Epoch: 8/10 Train loss: 0.229779 Valid loss: 0.401190 Train acc: 0.905263 Valid acc: 0.861713\n",
      "Epoch: 8/10 Train loss: 0.174967 Valid loss: 0.401061 Train acc: 0.936842 Valid acc: 0.861720\n",
      "Epoch: 8/10 Train loss: 0.395123 Valid loss: 0.400936 Train acc: 0.852632 Valid acc: 0.861726\n",
      "Epoch: 8/10 Train loss: 0.275744 Valid loss: 0.400810 Train acc: 0.915789 Valid acc: 0.861733\n",
      "Epoch: 8/10 Train loss: 0.169626 Valid loss: 0.400681 Train acc: 0.936842 Valid acc: 0.861742\n",
      "Epoch: 8/10 Train loss: 0.300504 Valid loss: 0.400531 Train acc: 0.884211 Valid acc: 0.861764\n",
      "Epoch: 8/10 Train loss: 0.354827 Valid loss: 0.400362 Train acc: 0.884211 Valid acc: 0.861794\n",
      "Epoch: 8/10 Train loss: 0.159780 Valid loss: 0.400179 Train acc: 0.936842 Valid acc: 0.861833\n",
      "Epoch: 8/10 Train loss: 0.289438 Valid loss: 0.399995 Train acc: 0.884211 Valid acc: 0.861876\n",
      "Epoch: 8/10 Train loss: 0.203046 Valid loss: 0.399816 Train acc: 0.915789 Valid acc: 0.861916\n",
      "Epoch: 8/10 Train loss: 0.130746 Valid loss: 0.399648 Train acc: 0.947369 Valid acc: 0.861948\n",
      "Epoch: 8/10 Train loss: 0.230531 Valid loss: 0.399490 Train acc: 0.926316 Valid acc: 0.861972\n",
      "Epoch: 8/10 Train loss: 0.136936 Valid loss: 0.399336 Train acc: 0.947369 Valid acc: 0.861990\n",
      "Epoch: 8/10 Train loss: 0.404309 Valid loss: 0.399187 Train acc: 0.926316 Valid acc: 0.862009\n",
      "Epoch: 8/10 Train loss: 0.209972 Valid loss: 0.399040 Train acc: 0.936842 Valid acc: 0.862026\n",
      "Epoch: 8/10 Train loss: 0.227390 Valid loss: 0.398898 Train acc: 0.915789 Valid acc: 0.862041\n",
      "Epoch: 8/10 Train loss: 0.107248 Valid loss: 0.398761 Train acc: 0.957895 Valid acc: 0.862056\n",
      "Epoch: 8/10 Train loss: 0.163938 Valid loss: 0.398631 Train acc: 0.915790 Valid acc: 0.862070\n",
      "Epoch: 8/10 Train loss: 0.078261 Valid loss: 0.398508 Train acc: 0.978947 Valid acc: 0.862083\n",
      "Epoch: 8/10 Train loss: 0.170467 Valid loss: 0.398390 Train acc: 0.926316 Valid acc: 0.862095\n",
      "Epoch: 8/10 Train loss: 0.227426 Valid loss: 0.398279 Train acc: 0.926316 Valid acc: 0.862106\n",
      "Epoch: 8/10 Train loss: 0.127150 Valid loss: 0.398172 Train acc: 0.989474 Valid acc: 0.862114\n",
      "Epoch: 8/10 Train loss: 0.094280 Valid loss: 0.398070 Train acc: 0.989474 Valid acc: 0.862121\n",
      "Epoch: 8/10 Train loss: 0.189885 Valid loss: 0.397971 Train acc: 0.936842 Valid acc: 0.862125\n",
      "Epoch: 8/10 Train loss: 0.171142 Valid loss: 0.397874 Train acc: 0.936842 Valid acc: 0.862128\n",
      "Epoch: 8/10 Train loss: 0.343691 Valid loss: 0.397780 Train acc: 0.852632 Valid acc: 0.862130\n",
      "Epoch: 8/10 Train loss: 0.383355 Valid loss: 0.397689 Train acc: 0.821053 Valid acc: 0.862132\n",
      "Epoch: 8/10 Train loss: 0.302637 Valid loss: 0.397600 Train acc: 0.852632 Valid acc: 0.862133\n",
      "Epoch: 8/10 Train loss: 0.374381 Valid loss: 0.397515 Train acc: 0.831579 Valid acc: 0.862135\n",
      "Epoch: 8/10 Train loss: 0.372837 Valid loss: 0.397435 Train acc: 0.842105 Valid acc: 0.862139\n",
      "Epoch: 8/10 Train loss: 0.344947 Valid loss: 0.397359 Train acc: 0.842105 Valid acc: 0.862145\n",
      "Epoch: 8/10 Train loss: 0.404228 Valid loss: 0.397289 Train acc: 0.842105 Valid acc: 0.862154\n",
      "Epoch: 8/10 Train loss: 0.327784 Valid loss: 0.397224 Train acc: 0.852632 Valid acc: 0.862163\n",
      "Epoch: 8/10 Train loss: 0.231701 Valid loss: 0.397163 Train acc: 0.894737 Valid acc: 0.862173\n",
      "Epoch: 8/10 Train loss: 0.272534 Valid loss: 0.397104 Train acc: 0.873684 Valid acc: 0.862183\n",
      "Epoch: 8/10 Train loss: 0.375393 Valid loss: 0.397048 Train acc: 0.831579 Valid acc: 0.862193\n",
      "Epoch: 8/10 Train loss: 0.273077 Valid loss: 0.396991 Train acc: 0.905263 Valid acc: 0.862206\n",
      "Epoch: 8/10 Train loss: 0.367893 Valid loss: 0.396933 Train acc: 0.863158 Valid acc: 0.862220\n",
      "Epoch: 8/10 Train loss: 0.415174 Valid loss: 0.396873 Train acc: 0.821053 Valid acc: 0.862237\n",
      "Epoch: 8/10 Train loss: 0.303987 Valid loss: 0.396811 Train acc: 0.894737 Valid acc: 0.862256\n",
      "Epoch: 8/10 Train loss: 0.341838 Valid loss: 0.396746 Train acc: 0.842105 Valid acc: 0.862277\n",
      "Epoch: 8/10 Train loss: 0.386444 Valid loss: 0.396678 Train acc: 0.831579 Valid acc: 0.862298\n",
      "Epoch: 8/10 Train loss: 0.345762 Valid loss: 0.396607 Train acc: 0.831579 Valid acc: 0.862322\n",
      "Epoch: 8/10 Train loss: 0.298496 Valid loss: 0.396533 Train acc: 0.873684 Valid acc: 0.862348\n",
      "Epoch: 8/10 Train loss: 0.410696 Valid loss: 0.396456 Train acc: 0.810526 Valid acc: 0.862374\n",
      "Epoch: 8/10 Train loss: 0.277382 Valid loss: 0.396375 Train acc: 0.894737 Valid acc: 0.862400\n",
      "Epoch: 8/10 Train loss: 0.267284 Valid loss: 0.396291 Train acc: 0.905263 Valid acc: 0.862428\n",
      "Epoch: 8/10 Train loss: 0.216540 Valid loss: 0.396202 Train acc: 0.915789 Valid acc: 0.862455\n",
      "Epoch: 8/10 Train loss: 0.323695 Valid loss: 0.396108 Train acc: 0.873684 Valid acc: 0.862482\n",
      "Epoch: 8/10 Train loss: 0.520472 Valid loss: 0.396013 Train acc: 0.789474 Valid acc: 0.862510\n",
      "Epoch: 8/10 Train loss: 0.652843 Valid loss: 0.395920 Train acc: 0.747369 Valid acc: 0.862537\n",
      "Epoch: 8/10 Train loss: 0.640234 Valid loss: 0.395832 Train acc: 0.810526 Valid acc: 0.862565\n",
      "Epoch: 8/10 Train loss: 0.565906 Valid loss: 0.395750 Train acc: 0.768421 Valid acc: 0.862591\n",
      "Epoch: 8/10 Train loss: 0.506272 Valid loss: 0.395676 Train acc: 0.789474 Valid acc: 0.862614\n",
      "Epoch: 8/10 Train loss: 0.533875 Valid loss: 0.395612 Train acc: 0.810526 Valid acc: 0.862634\n",
      "Epoch: 8/10 Train loss: 0.285076 Valid loss: 0.395557 Train acc: 0.873684 Valid acc: 0.862654\n",
      "Epoch: 8/10 Train loss: 0.452851 Valid loss: 0.395508 Train acc: 0.821053 Valid acc: 0.862668\n",
      "Epoch: 8/10 Train loss: 0.358607 Valid loss: 0.395465 Train acc: 0.842105 Valid acc: 0.862680\n",
      "Epoch: 8/10 Train loss: 0.355874 Valid loss: 0.395426 Train acc: 0.852632 Valid acc: 0.862689\n",
      "Epoch: 8/10 Train loss: 0.352193 Valid loss: 0.395391 Train acc: 0.831579 Valid acc: 0.862699\n",
      "Epoch: 8/10 Train loss: 0.355901 Valid loss: 0.395359 Train acc: 0.842105 Valid acc: 0.862707\n",
      "Epoch: 8/10 Train loss: 0.345075 Valid loss: 0.395327 Train acc: 0.852632 Valid acc: 0.862713\n",
      "Epoch: 8/10 Train loss: 0.351046 Valid loss: 0.395296 Train acc: 0.831579 Valid acc: 0.862719\n",
      "Epoch: 8/10 Train loss: 0.313863 Valid loss: 0.395264 Train acc: 0.863158 Valid acc: 0.862723\n",
      "Epoch: 8/10 Train loss: 0.358640 Valid loss: 0.395230 Train acc: 0.831579 Valid acc: 0.862727\n",
      "Epoch: 8/10 Train loss: 0.305346 Valid loss: 0.395193 Train acc: 0.852632 Valid acc: 0.862732\n",
      "Epoch: 8/10 Train loss: 0.300652 Valid loss: 0.395152 Train acc: 0.884211 Valid acc: 0.862739\n",
      "Epoch: 8/10 Train loss: 0.292297 Valid loss: 0.395107 Train acc: 0.873684 Valid acc: 0.862745\n",
      "Epoch: 8/10 Train loss: 0.356244 Valid loss: 0.395057 Train acc: 0.852632 Valid acc: 0.862754\n",
      "Epoch: 8/10 Train loss: 0.295872 Valid loss: 0.395002 Train acc: 0.884211 Valid acc: 0.862766\n",
      "Epoch: 8/10 Train loss: 0.328461 Valid loss: 0.394941 Train acc: 0.842105 Valid acc: 0.862777\n",
      "Epoch: 8/10 Train loss: 0.283794 Valid loss: 0.394874 Train acc: 0.873684 Valid acc: 0.862791\n",
      "Epoch: 8/10 Train loss: 0.293237 Valid loss: 0.394801 Train acc: 0.831579 Valid acc: 0.862806\n",
      "Epoch: 8/10 Train loss: 0.236497 Valid loss: 0.394722 Train acc: 0.915789 Valid acc: 0.862824\n",
      "Epoch: 8/10 Train loss: 0.521963 Valid loss: 0.394636 Train acc: 0.778947 Valid acc: 0.862844\n",
      "Epoch: 8/10 Train loss: 0.338805 Valid loss: 0.394544 Train acc: 0.863158 Valid acc: 0.862868\n",
      "Epoch: 8/10 Train loss: 0.229860 Valid loss: 0.394446 Train acc: 0.915789 Valid acc: 0.862893\n",
      "Epoch: 8/10 Train loss: 0.246027 Valid loss: 0.394340 Train acc: 0.863158 Valid acc: 0.862921\n",
      "Epoch: 8/10 Train loss: 0.281219 Valid loss: 0.394230 Train acc: 0.884211 Valid acc: 0.862950\n",
      "Epoch: 8/10 Train loss: 0.201149 Valid loss: 0.394114 Train acc: 0.936842 Valid acc: 0.862981\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Train loss: 0.220329 Valid loss: 0.393993 Train acc: 0.905263 Valid acc: 0.863013\n",
      "Epoch: 8/10 Train loss: 0.185609 Valid loss: 0.393868 Train acc: 0.936842 Valid acc: 0.863050\n",
      "Epoch: 8/10 Train loss: 0.352239 Valid loss: 0.393740 Train acc: 0.863158 Valid acc: 0.863087\n",
      "Epoch: 8/10 Train loss: 0.231781 Valid loss: 0.393612 Train acc: 0.915789 Valid acc: 0.863123\n",
      "Epoch: 8/10 Train loss: 0.257912 Valid loss: 0.393485 Train acc: 0.894737 Valid acc: 0.863156\n",
      "Epoch: 8/10 Train loss: 0.161874 Valid loss: 0.393357 Train acc: 0.947369 Valid acc: 0.863186\n",
      "Epoch: 9/10 Train loss: 0.198898 Valid loss: 0.393228 Train acc: 0.936842 Valid acc: 0.863214\n",
      "Epoch: 9/10 Train loss: 0.235024 Valid loss: 0.393098 Train acc: 0.863158 Valid acc: 0.863240\n",
      "Epoch: 9/10 Train loss: 0.421336 Valid loss: 0.392966 Train acc: 0.831579 Valid acc: 0.863264\n",
      "Epoch: 9/10 Train loss: 0.243823 Valid loss: 0.392832 Train acc: 0.926316 Valid acc: 0.863286\n",
      "Epoch: 9/10 Train loss: 0.177845 Valid loss: 0.392697 Train acc: 0.968421 Valid acc: 0.863308\n",
      "Epoch: 9/10 Train loss: 0.341582 Valid loss: 0.392560 Train acc: 0.863158 Valid acc: 0.863329\n",
      "Epoch: 9/10 Train loss: 0.376514 Valid loss: 0.392424 Train acc: 0.831579 Valid acc: 0.863351\n",
      "Epoch: 9/10 Train loss: 0.272864 Valid loss: 0.392288 Train acc: 0.863158 Valid acc: 0.863374\n",
      "Epoch: 9/10 Train loss: 0.196054 Valid loss: 0.392152 Train acc: 0.926316 Valid acc: 0.863397\n",
      "Epoch: 9/10 Train loss: 0.191294 Valid loss: 0.392014 Train acc: 0.915790 Valid acc: 0.863420\n",
      "Epoch: 9/10 Train loss: 0.231419 Valid loss: 0.391876 Train acc: 0.947368 Valid acc: 0.863442\n",
      "Epoch: 9/10 Train loss: 0.292588 Valid loss: 0.391739 Train acc: 0.915789 Valid acc: 0.863467\n",
      "Epoch: 9/10 Train loss: 0.213855 Valid loss: 0.391604 Train acc: 0.905263 Valid acc: 0.863492\n",
      "Epoch: 9/10 Train loss: 0.339228 Valid loss: 0.391472 Train acc: 0.884211 Valid acc: 0.863514\n",
      "Epoch: 9/10 Train loss: 0.195605 Valid loss: 0.391344 Train acc: 0.926316 Valid acc: 0.863533\n",
      "Epoch: 9/10 Train loss: 0.235105 Valid loss: 0.391219 Train acc: 0.915789 Valid acc: 0.863547\n",
      "Epoch: 9/10 Train loss: 0.396890 Valid loss: 0.391101 Train acc: 0.863158 Valid acc: 0.863556\n",
      "Epoch: 9/10 Train loss: 0.269226 Valid loss: 0.390985 Train acc: 0.936842 Valid acc: 0.863562\n",
      "Epoch: 9/10 Train loss: 0.160640 Valid loss: 0.390867 Train acc: 0.936842 Valid acc: 0.863572\n",
      "Epoch: 9/10 Train loss: 0.165692 Valid loss: 0.390740 Train acc: 0.915789 Valid acc: 0.863589\n",
      "Epoch: 9/10 Train loss: 0.372866 Valid loss: 0.390600 Train acc: 0.873684 Valid acc: 0.863614\n",
      "Epoch: 9/10 Train loss: 0.100135 Valid loss: 0.390450 Train acc: 0.968421 Valid acc: 0.863647\n",
      "Epoch: 9/10 Train loss: 0.242903 Valid loss: 0.390294 Train acc: 0.915789 Valid acc: 0.863680\n",
      "Epoch: 9/10 Train loss: 0.233549 Valid loss: 0.390137 Train acc: 0.905263 Valid acc: 0.863716\n",
      "Epoch: 9/10 Train loss: 0.087543 Valid loss: 0.389984 Train acc: 0.968421 Valid acc: 0.863753\n",
      "Epoch: 9/10 Train loss: 0.245418 Valid loss: 0.389836 Train acc: 0.926316 Valid acc: 0.863784\n",
      "Epoch: 9/10 Train loss: 0.101284 Valid loss: 0.389693 Train acc: 0.968421 Valid acc: 0.863809\n",
      "Epoch: 9/10 Train loss: 0.326514 Valid loss: 0.389555 Train acc: 0.905263 Valid acc: 0.863832\n",
      "Epoch: 9/10 Train loss: 0.169000 Valid loss: 0.389421 Train acc: 0.947368 Valid acc: 0.863851\n",
      "Epoch: 9/10 Train loss: 0.199929 Valid loss: 0.389292 Train acc: 0.894737 Valid acc: 0.863868\n",
      "Epoch: 9/10 Train loss: 0.089980 Valid loss: 0.389166 Train acc: 0.968421 Valid acc: 0.863882\n",
      "Epoch: 9/10 Train loss: 0.092555 Valid loss: 0.389045 Train acc: 0.957895 Valid acc: 0.863893\n",
      "Epoch: 9/10 Train loss: 0.043249 Valid loss: 0.388929 Train acc: 0.989474 Valid acc: 0.863904\n",
      "Epoch: 9/10 Train loss: 0.118258 Valid loss: 0.388816 Train acc: 0.978947 Valid acc: 0.863911\n",
      "Epoch: 9/10 Train loss: 0.204469 Valid loss: 0.388708 Train acc: 0.926316 Valid acc: 0.863920\n",
      "Epoch: 9/10 Train loss: 0.093379 Valid loss: 0.388604 Train acc: 0.978947 Valid acc: 0.863927\n",
      "Epoch: 9/10 Train loss: 0.092962 Valid loss: 0.388503 Train acc: 0.978947 Valid acc: 0.863932\n",
      "Epoch: 9/10 Train loss: 0.067121 Valid loss: 0.388406 Train acc: 0.978947 Valid acc: 0.863935\n",
      "Epoch: 9/10 Train loss: 0.120544 Valid loss: 0.388311 Train acc: 0.936842 Valid acc: 0.863936\n",
      "Epoch: 9/10 Train loss: 0.464408 Valid loss: 0.388218 Train acc: 0.852632 Valid acc: 0.863937\n",
      "Epoch: 9/10 Train loss: 0.444525 Valid loss: 0.388128 Train acc: 0.842105 Valid acc: 0.863937\n",
      "Epoch: 9/10 Train loss: 0.306243 Valid loss: 0.388039 Train acc: 0.852632 Valid acc: 0.863937\n",
      "Epoch: 9/10 Train loss: 0.373524 Valid loss: 0.387955 Train acc: 0.831579 Valid acc: 0.863937\n",
      "Epoch: 9/10 Train loss: 0.352390 Valid loss: 0.387875 Train acc: 0.831579 Valid acc: 0.863942\n",
      "Epoch: 9/10 Train loss: 0.390101 Valid loss: 0.387803 Train acc: 0.842105 Valid acc: 0.863949\n",
      "Epoch: 9/10 Train loss: 0.377589 Valid loss: 0.387737 Train acc: 0.852632 Valid acc: 0.863958\n",
      "Epoch: 9/10 Train loss: 0.324656 Valid loss: 0.387680 Train acc: 0.852632 Valid acc: 0.863967\n",
      "Epoch: 9/10 Train loss: 0.257439 Valid loss: 0.387629 Train acc: 0.915790 Valid acc: 0.863979\n",
      "Epoch: 9/10 Train loss: 0.249853 Valid loss: 0.387581 Train acc: 0.894737 Valid acc: 0.863988\n",
      "Epoch: 9/10 Train loss: 0.361736 Valid loss: 0.387534 Train acc: 0.852632 Valid acc: 0.863999\n",
      "Epoch: 9/10 Train loss: 0.239255 Valid loss: 0.387485 Train acc: 0.915789 Valid acc: 0.864014\n",
      "Epoch: 9/10 Train loss: 0.334637 Valid loss: 0.387431 Train acc: 0.863158 Valid acc: 0.864030\n",
      "Epoch: 9/10 Train loss: 0.372514 Valid loss: 0.387373 Train acc: 0.810526 Valid acc: 0.864047\n",
      "Epoch: 9/10 Train loss: 0.317859 Valid loss: 0.387308 Train acc: 0.894737 Valid acc: 0.864066\n",
      "Epoch: 9/10 Train loss: 0.341858 Valid loss: 0.387238 Train acc: 0.863158 Valid acc: 0.864085\n",
      "Epoch: 9/10 Train loss: 0.401163 Valid loss: 0.387164 Train acc: 0.842105 Valid acc: 0.864105\n",
      "Epoch: 9/10 Train loss: 0.306243 Valid loss: 0.387086 Train acc: 0.884211 Valid acc: 0.864129\n",
      "Epoch: 9/10 Train loss: 0.245560 Valid loss: 0.387004 Train acc: 0.905263 Valid acc: 0.864153\n",
      "Epoch: 9/10 Train loss: 0.394658 Valid loss: 0.386919 Train acc: 0.821053 Valid acc: 0.864176\n",
      "Epoch: 9/10 Train loss: 0.256171 Valid loss: 0.386830 Train acc: 0.863158 Valid acc: 0.864201\n",
      "Epoch: 9/10 Train loss: 0.247067 Valid loss: 0.386739 Train acc: 0.884211 Valid acc: 0.864223\n",
      "Epoch: 9/10 Train loss: 0.170230 Valid loss: 0.386645 Train acc: 0.947369 Valid acc: 0.864245\n",
      "Epoch: 9/10 Train loss: 0.320242 Valid loss: 0.386550 Train acc: 0.863158 Valid acc: 0.864267\n",
      "Epoch: 9/10 Train loss: 0.549668 Valid loss: 0.386455 Train acc: 0.810526 Valid acc: 0.864288\n",
      "Epoch: 9/10 Train loss: 0.581690 Valid loss: 0.386364 Train acc: 0.768421 Valid acc: 0.864309\n",
      "Epoch: 9/10 Train loss: 0.740204 Valid loss: 0.386278 Train acc: 0.757895 Valid acc: 0.864329\n",
      "Epoch: 9/10 Train loss: 0.536776 Valid loss: 0.386201 Train acc: 0.778947 Valid acc: 0.864348\n",
      "Epoch: 9/10 Train loss: 0.500612 Valid loss: 0.386132 Train acc: 0.768421 Valid acc: 0.864366\n",
      "Epoch: 9/10 Train loss: 0.550872 Valid loss: 0.386075 Train acc: 0.789474 Valid acc: 0.864381\n",
      "Epoch: 9/10 Train loss: 0.356025 Valid loss: 0.386026 Train acc: 0.863158 Valid acc: 0.864396\n",
      "Epoch: 9/10 Train loss: 0.369659 Valid loss: 0.385984 Train acc: 0.842105 Valid acc: 0.864411\n",
      "Epoch: 9/10 Train loss: 0.366926 Valid loss: 0.385947 Train acc: 0.842105 Valid acc: 0.864423\n",
      "Epoch: 9/10 Train loss: 0.350283 Valid loss: 0.385914 Train acc: 0.852632 Valid acc: 0.864435\n",
      "Epoch: 9/10 Train loss: 0.344249 Valid loss: 0.385885 Train acc: 0.852632 Valid acc: 0.864447\n",
      "Epoch: 9/10 Train loss: 0.337059 Valid loss: 0.385857 Train acc: 0.873684 Valid acc: 0.864458\n",
      "Epoch: 9/10 Train loss: 0.335632 Valid loss: 0.385830 Train acc: 0.873684 Valid acc: 0.864471\n",
      "Epoch: 9/10 Train loss: 0.385145 Valid loss: 0.385801 Train acc: 0.831579 Valid acc: 0.864485\n",
      "Epoch: 9/10 Train loss: 0.321878 Valid loss: 0.385769 Train acc: 0.852632 Valid acc: 0.864499\n",
      "Epoch: 9/10 Train loss: 0.350160 Valid loss: 0.385735 Train acc: 0.842105 Valid acc: 0.864513\n",
      "Epoch: 9/10 Train loss: 0.278409 Valid loss: 0.385697 Train acc: 0.873684 Valid acc: 0.864527\n",
      "Epoch: 9/10 Train loss: 0.297182 Valid loss: 0.385654 Train acc: 0.873684 Valid acc: 0.864540\n",
      "Epoch: 9/10 Train loss: 0.291937 Valid loss: 0.385606 Train acc: 0.884211 Valid acc: 0.864553\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 Train loss: 0.314154 Valid loss: 0.385552 Train acc: 0.842105 Valid acc: 0.864565\n",
      "Epoch: 9/10 Train loss: 0.323276 Valid loss: 0.385494 Train acc: 0.842105 Valid acc: 0.864577\n",
      "Epoch: 9/10 Train loss: 0.310979 Valid loss: 0.385431 Train acc: 0.842105 Valid acc: 0.864590\n",
      "Epoch: 9/10 Train loss: 0.264994 Valid loss: 0.385363 Train acc: 0.894737 Valid acc: 0.864603\n",
      "Epoch: 9/10 Train loss: 0.265040 Valid loss: 0.385292 Train acc: 0.852632 Valid acc: 0.864617\n",
      "Epoch: 9/10 Train loss: 0.353294 Valid loss: 0.385220 Train acc: 0.884211 Valid acc: 0.864632\n",
      "Epoch: 9/10 Train loss: 0.323959 Valid loss: 0.385147 Train acc: 0.842105 Valid acc: 0.864648\n",
      "Epoch: 9/10 Train loss: 0.503060 Valid loss: 0.385075 Train acc: 0.852632 Valid acc: 0.864665\n",
      "Epoch: 9/10 Train loss: 0.251446 Valid loss: 0.385002 Train acc: 0.905263 Valid acc: 0.864681\n",
      "Epoch: 9/10 Train loss: 0.223067 Valid loss: 0.384930 Train acc: 0.894737 Valid acc: 0.864698\n",
      "Epoch: 9/10 Train loss: 0.344108 Valid loss: 0.384858 Train acc: 0.884211 Valid acc: 0.864714\n",
      "Epoch: 9/10 Train loss: 0.241422 Valid loss: 0.384787 Train acc: 0.905263 Valid acc: 0.864728\n",
      "Epoch: 9/10 Train loss: 0.290317 Valid loss: 0.384717 Train acc: 0.873684 Valid acc: 0.864742\n",
      "Epoch: 9/10 Train loss: 0.193322 Valid loss: 0.384649 Train acc: 0.926316 Valid acc: 0.864754\n",
      "Epoch: 9/10 Train loss: 0.280256 Valid loss: 0.384581 Train acc: 0.915789 Valid acc: 0.864764\n",
      "Epoch: 9/10 Train loss: 0.245967 Valid loss: 0.384515 Train acc: 0.926316 Valid acc: 0.864774\n",
      "Epoch: 9/10 Train loss: 0.230803 Valid loss: 0.384450 Train acc: 0.915790 Valid acc: 0.864782\n",
      "Epoch: 9/10 Train loss: 0.193487 Valid loss: 0.384385 Train acc: 0.926316 Valid acc: 0.864787\n",
      "Epoch: 10/10 Train loss: 0.213892 Valid loss: 0.384320 Train acc: 0.936842 Valid acc: 0.864794\n",
      "Epoch: 10/10 Train loss: 0.254902 Valid loss: 0.384253 Train acc: 0.884211 Valid acc: 0.864800\n",
      "Epoch: 10/10 Train loss: 0.359090 Valid loss: 0.384188 Train acc: 0.873684 Valid acc: 0.864806\n",
      "Epoch: 10/10 Train loss: 0.249850 Valid loss: 0.384122 Train acc: 0.926316 Valid acc: 0.864808\n",
      "Epoch: 10/10 Train loss: 0.234896 Valid loss: 0.384056 Train acc: 0.884211 Valid acc: 0.864808\n",
      "Epoch: 10/10 Train loss: 0.303466 Valid loss: 0.383990 Train acc: 0.905263 Valid acc: 0.864808\n",
      "Epoch: 10/10 Train loss: 0.320870 Valid loss: 0.383926 Train acc: 0.863158 Valid acc: 0.864805\n",
      "Epoch: 10/10 Train loss: 0.237002 Valid loss: 0.383864 Train acc: 0.926316 Valid acc: 0.864799\n",
      "Epoch: 10/10 Train loss: 0.181460 Valid loss: 0.383803 Train acc: 0.936842 Valid acc: 0.864792\n",
      "Epoch: 10/10 Train loss: 0.250932 Valid loss: 0.383742 Train acc: 0.873684 Valid acc: 0.864783\n",
      "Epoch: 10/10 Train loss: 0.214970 Valid loss: 0.383681 Train acc: 0.926316 Valid acc: 0.864773\n",
      "Epoch: 10/10 Train loss: 0.283553 Valid loss: 0.383622 Train acc: 0.936842 Valid acc: 0.864763\n",
      "Epoch: 10/10 Train loss: 0.213586 Valid loss: 0.383565 Train acc: 0.926316 Valid acc: 0.864750\n",
      "Epoch: 10/10 Train loss: 0.374027 Valid loss: 0.383512 Train acc: 0.852632 Valid acc: 0.864736\n",
      "Epoch: 10/10 Train loss: 0.179029 Valid loss: 0.383463 Train acc: 0.947368 Valid acc: 0.864720\n",
      "Epoch: 10/10 Train loss: 0.181951 Valid loss: 0.383420 Train acc: 0.936842 Valid acc: 0.864700\n",
      "Epoch: 10/10 Train loss: 0.323821 Valid loss: 0.383382 Train acc: 0.863158 Valid acc: 0.864676\n",
      "Epoch: 10/10 Train loss: 0.227563 Valid loss: 0.383348 Train acc: 0.915789 Valid acc: 0.864652\n",
      "Epoch: 10/10 Train loss: 0.229648 Valid loss: 0.383305 Train acc: 0.905263 Valid acc: 0.864631\n",
      "Epoch: 10/10 Train loss: 0.263433 Valid loss: 0.383241 Train acc: 0.905263 Valid acc: 0.864622\n",
      "Epoch: 10/10 Train loss: 0.234994 Valid loss: 0.383157 Train acc: 0.926316 Valid acc: 0.864630\n",
      "Epoch: 10/10 Train loss: 0.088363 Valid loss: 0.383062 Train acc: 0.947369 Valid acc: 0.864647\n",
      "Epoch: 10/10 Train loss: 0.273412 Valid loss: 0.382964 Train acc: 0.884211 Valid acc: 0.864666\n",
      "Epoch: 10/10 Train loss: 0.245739 Valid loss: 0.382873 Train acc: 0.905263 Valid acc: 0.864682\n",
      "Epoch: 10/10 Train loss: 0.096768 Valid loss: 0.382793 Train acc: 0.968421 Valid acc: 0.864696\n",
      "Epoch: 10/10 Train loss: 0.091055 Valid loss: 0.382726 Train acc: 0.978947 Valid acc: 0.864706\n",
      "Epoch: 10/10 Train loss: 0.077626 Valid loss: 0.382666 Train acc: 0.957895 Valid acc: 0.864713\n",
      "Epoch: 10/10 Train loss: 0.369282 Valid loss: 0.382606 Train acc: 0.894737 Valid acc: 0.864717\n",
      "Epoch: 10/10 Train loss: 0.141417 Valid loss: 0.382543 Train acc: 0.936842 Valid acc: 0.864719\n",
      "Epoch: 10/10 Train loss: 0.186862 Valid loss: 0.382475 Train acc: 0.915789 Valid acc: 0.864723\n",
      "Epoch: 10/10 Train loss: 0.055462 Valid loss: 0.382406 Train acc: 0.978947 Valid acc: 0.864727\n",
      "Epoch: 10/10 Train loss: 0.185170 Valid loss: 0.382338 Train acc: 0.936842 Valid acc: 0.864729\n",
      "Epoch: 10/10 Train loss: 0.040610 Valid loss: 0.382271 Train acc: 0.989474 Valid acc: 0.864732\n",
      "Epoch: 10/10 Train loss: 0.093338 Valid loss: 0.382208 Train acc: 0.968421 Valid acc: 0.864733\n",
      "Epoch: 10/10 Train loss: 0.176956 Valid loss: 0.382147 Train acc: 0.936842 Valid acc: 0.864735\n",
      "Epoch: 10/10 Train loss: 0.190692 Valid loss: 0.382088 Train acc: 0.957895 Valid acc: 0.864734\n",
      "Epoch: 10/10 Train loss: 0.101444 Valid loss: 0.382033 Train acc: 0.957895 Valid acc: 0.864733\n",
      "Epoch: 10/10 Train loss: 0.143153 Valid loss: 0.381982 Train acc: 0.957895 Valid acc: 0.864729\n",
      "Epoch: 10/10 Train loss: 0.126754 Valid loss: 0.381935 Train acc: 0.947368 Valid acc: 0.864724\n",
      "Epoch: 10/10 Train loss: 0.405568 Valid loss: 0.381889 Train acc: 0.842105 Valid acc: 0.864718\n",
      "Epoch: 10/10 Train loss: 0.462163 Valid loss: 0.381846 Train acc: 0.831579 Valid acc: 0.864709\n",
      "Epoch: 10/10 Train loss: 0.269577 Valid loss: 0.381803 Train acc: 0.852632 Valid acc: 0.864699\n",
      "Epoch: 10/10 Train loss: 0.364928 Valid loss: 0.381764 Train acc: 0.852632 Valid acc: 0.864689\n",
      "Epoch: 10/10 Train loss: 0.350449 Valid loss: 0.381731 Train acc: 0.842105 Valid acc: 0.864679\n",
      "Epoch: 10/10 Train loss: 0.362415 Valid loss: 0.381703 Train acc: 0.852632 Valid acc: 0.864670\n",
      "Epoch: 10/10 Train loss: 0.374484 Valid loss: 0.381680 Train acc: 0.884211 Valid acc: 0.864659\n",
      "Epoch: 10/10 Train loss: 0.340733 Valid loss: 0.381662 Train acc: 0.884211 Valid acc: 0.864652\n",
      "Epoch: 10/10 Train loss: 0.215751 Valid loss: 0.381648 Train acc: 0.915789 Valid acc: 0.864646\n",
      "Epoch: 10/10 Train loss: 0.264615 Valid loss: 0.381636 Train acc: 0.884211 Valid acc: 0.864639\n",
      "Epoch: 10/10 Train loss: 0.303084 Valid loss: 0.381624 Train acc: 0.863158 Valid acc: 0.864632\n",
      "Epoch: 10/10 Train loss: 0.244313 Valid loss: 0.381610 Train acc: 0.905263 Valid acc: 0.864630\n",
      "Epoch: 10/10 Train loss: 0.307613 Valid loss: 0.381591 Train acc: 0.873684 Valid acc: 0.864629\n",
      "Epoch: 10/10 Train loss: 0.425384 Valid loss: 0.381568 Train acc: 0.821053 Valid acc: 0.864630\n",
      "Epoch: 10/10 Train loss: 0.297552 Valid loss: 0.381540 Train acc: 0.894737 Valid acc: 0.864632\n",
      "Epoch: 10/10 Train loss: 0.312954 Valid loss: 0.381506 Train acc: 0.863158 Valid acc: 0.864636\n",
      "Epoch: 10/10 Train loss: 0.421136 Valid loss: 0.381470 Train acc: 0.810526 Valid acc: 0.864642\n",
      "Epoch: 10/10 Train loss: 0.329619 Valid loss: 0.381429 Train acc: 0.842105 Valid acc: 0.864650\n",
      "Epoch: 10/10 Train loss: 0.284527 Valid loss: 0.381385 Train acc: 0.905263 Valid acc: 0.864658\n",
      "Epoch: 10/10 Train loss: 0.343813 Valid loss: 0.381337 Train acc: 0.873684 Valid acc: 0.864666\n",
      "Epoch: 10/10 Train loss: 0.280308 Valid loss: 0.381287 Train acc: 0.884211 Valid acc: 0.864675\n",
      "Epoch: 10/10 Train loss: 0.257594 Valid loss: 0.381234 Train acc: 0.884211 Valid acc: 0.864682\n",
      "Epoch: 10/10 Train loss: 0.209554 Valid loss: 0.381179 Train acc: 0.926316 Valid acc: 0.864692\n",
      "Epoch: 10/10 Train loss: 0.325805 Valid loss: 0.381123 Train acc: 0.873684 Valid acc: 0.864701\n",
      "Epoch: 10/10 Train loss: 0.572546 Valid loss: 0.381068 Train acc: 0.800000 Valid acc: 0.864710\n",
      "Epoch: 10/10 Train loss: 0.574764 Valid loss: 0.381016 Train acc: 0.778947 Valid acc: 0.864720\n",
      "Epoch: 10/10 Train loss: 0.652988 Valid loss: 0.380970 Train acc: 0.726316 Valid acc: 0.864727\n",
      "Epoch: 10/10 Train loss: 0.573308 Valid loss: 0.380929 Train acc: 0.757895 Valid acc: 0.864734\n",
      "Epoch: 10/10 Train loss: 0.500469 Valid loss: 0.380896 Train acc: 0.810526 Valid acc: 0.864739\n",
      "Epoch: 10/10 Train loss: 0.591782 Valid loss: 0.380871 Train acc: 0.768421 Valid acc: 0.864743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 Train loss: 0.329989 Valid loss: 0.380853 Train acc: 0.873684 Valid acc: 0.864747\n",
      "Epoch: 10/10 Train loss: 0.405674 Valid loss: 0.380843 Train acc: 0.800000 Valid acc: 0.864751\n",
      "Epoch: 10/10 Train loss: 0.397168 Valid loss: 0.380838 Train acc: 0.863158 Valid acc: 0.864755\n",
      "Epoch: 10/10 Train loss: 0.355114 Valid loss: 0.380836 Train acc: 0.873684 Valid acc: 0.864760\n",
      "Epoch: 10/10 Train loss: 0.332290 Valid loss: 0.380836 Train acc: 0.831579 Valid acc: 0.864763\n",
      "Epoch: 10/10 Train loss: 0.341266 Valid loss: 0.380837 Train acc: 0.894737 Valid acc: 0.864765\n",
      "Epoch: 10/10 Train loss: 0.307356 Valid loss: 0.380836 Train acc: 0.894737 Valid acc: 0.864768\n",
      "Epoch: 10/10 Train loss: 0.354623 Valid loss: 0.380832 Train acc: 0.863158 Valid acc: 0.864771\n",
      "Epoch: 10/10 Train loss: 0.305683 Valid loss: 0.380825 Train acc: 0.863158 Valid acc: 0.864772\n",
      "Epoch: 10/10 Train loss: 0.345538 Valid loss: 0.380814 Train acc: 0.852632 Valid acc: 0.864772\n",
      "Epoch: 10/10 Train loss: 0.304256 Valid loss: 0.380800 Train acc: 0.884211 Valid acc: 0.864773\n",
      "Epoch: 10/10 Train loss: 0.316062 Valid loss: 0.380780 Train acc: 0.873684 Valid acc: 0.864773\n",
      "Epoch: 10/10 Train loss: 0.285591 Valid loss: 0.380756 Train acc: 0.894737 Valid acc: 0.864774\n",
      "Epoch: 10/10 Train loss: 0.267401 Valid loss: 0.380727 Train acc: 0.884211 Valid acc: 0.864775\n",
      "Epoch: 10/10 Train loss: 0.271049 Valid loss: 0.380693 Train acc: 0.884211 Valid acc: 0.864776\n",
      "Epoch: 10/10 Train loss: 0.303917 Valid loss: 0.380655 Train acc: 0.863158 Valid acc: 0.864777\n",
      "Epoch: 10/10 Train loss: 0.241553 Valid loss: 0.380611 Train acc: 0.926316 Valid acc: 0.864780\n",
      "Epoch: 10/10 Train loss: 0.283100 Valid loss: 0.380564 Train acc: 0.863158 Valid acc: 0.864784\n",
      "Epoch: 10/10 Train loss: 0.603268 Valid loss: 0.380517 Train acc: 0.863158 Valid acc: 0.864788\n",
      "Epoch: 10/10 Train loss: 0.614876 Valid loss: 0.380470 Train acc: 0.831579 Valid acc: 0.864795\n",
      "Epoch: 10/10 Train loss: 0.595906 Valid loss: 0.380423 Train acc: 0.831579 Valid acc: 0.864804\n",
      "Epoch: 10/10 Train loss: 0.219447 Valid loss: 0.380375 Train acc: 0.926316 Valid acc: 0.864814\n",
      "Epoch: 10/10 Train loss: 0.247685 Valid loss: 0.380328 Train acc: 0.884211 Valid acc: 0.864824\n",
      "Epoch: 10/10 Train loss: 0.338075 Valid loss: 0.380280 Train acc: 0.884211 Valid acc: 0.864835\n",
      "Epoch: 10/10 Train loss: 0.212475 Valid loss: 0.380233 Train acc: 0.926316 Valid acc: 0.864849\n",
      "Epoch: 10/10 Train loss: 0.266987 Valid loss: 0.380184 Train acc: 0.894737 Valid acc: 0.864863\n",
      "Epoch: 10/10 Train loss: 0.215711 Valid loss: 0.380134 Train acc: 0.915790 Valid acc: 0.864878\n",
      "Epoch: 10/10 Train loss: 0.290386 Valid loss: 0.380080 Train acc: 0.894737 Valid acc: 0.864892\n",
      "Epoch: 10/10 Train loss: 0.240135 Valid loss: 0.380024 Train acc: 0.905263 Valid acc: 0.864905\n",
      "Epoch: 10/10 Train loss: 0.239024 Valid loss: 0.379964 Train acc: 0.915789 Valid acc: 0.864919\n",
      "Epoch: 10/10 Train loss: 0.211911 Valid loss: 0.379900 Train acc: 0.905263 Valid acc: 0.864931\n",
      "Epoch: 10/10 Test loss: 0.328912 Test acc: 0.871805\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "# Plotting the acc and loss curve\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initalize session global variables just in the case they are initialized.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "       \n",
    "        # Loop over batches\n",
    "        for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_:x, labels_:y, keep_prob_: keep_prob, learning_rate_:learning_rate}\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################################ Validation\n",
    "            # Initialize \n",
    "            loss_v_batch, acc_v_batch = [], []\n",
    "\n",
    "            # Loop over batches\n",
    "            for x_v, y_v in get_batches(X_valid_norm, Y_valid_onehot, batch_size):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_:x_v, labels_:y_v, keep_prob_: 1.0}\n",
    "                loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                \n",
    "                acc_v_batch.append(acc_v)\n",
    "                loss_v_batch.append(loss_v)\n",
    "                \n",
    "            valid_acc.append(np.mean(acc_v_batch))\n",
    "            valid_loss.append(np.mean(loss_v_batch))\n",
    "            \n",
    "            # Print info\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Train loss: {:6f}\".format(loss),\n",
    "                  \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "                  \"Train acc: {:6f}\".format(acc),\n",
    "                  \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "            \n",
    "    ################################ Test\n",
    "    # Initialize \n",
    "    acc_batch, loss_batch = [], []\n",
    "\n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(X_test_norm, Y_test_onehot, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_:x, labels_:y, keep_prob_:1.0}\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print info\n",
    "    print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "          \"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIYSoZyS4hRCinpHgFkKIeub/AQfxXcux9AMQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff84c4ede80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nPmTF3RhjfMiKuzHG+JAVd2OM8aH/AZSnQrCamJw4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7ff7f40adfd0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
