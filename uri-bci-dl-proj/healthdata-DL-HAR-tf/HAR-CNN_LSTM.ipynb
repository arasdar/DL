{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HAR CNN + LSTM training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "import os\n",
    "from utils.utilities import *\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train, labels_train, list_ch_train = read_data(data_path=\"./data/\", split=\"train\") # train\n",
    "X_test, labels_test, list_ch_test = read_data(data_path=\"./data/\", split=\"test\") # test\n",
    "\n",
    "assert list_ch_train == list_ch_test, \"Mistmatch in channels!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Standardize\n",
    "X_train, X_test = standardize(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train/Validation Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_tr, X_vld, lab_tr, lab_vld = train_test_split(X_train, labels_train,\n",
    "                                                stratify = labels_train, random_state = 123)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One-hot encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_tr = one_hot(lab_tr)\n",
    "y_vld = one_hot(lab_vld)\n",
    "y_test = one_hot(labels_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lstm_size = 27         # 3 times the amount of channels\n",
    "lstm_layers = 2        # Number of layers\n",
    "batch_size = 600       # Batch size\n",
    "seq_len = 128          # Number of steps\n",
    "learning_rate = 0.0001  # Learning rate (default is 0.001)\n",
    "epochs = 1000\n",
    "\n",
    "# Fixed\n",
    "n_classes = 6\n",
    "n_channels = 9"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construct the graph\n",
    "Placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "graph = tf.Graph()\n",
    "\n",
    "# Construct placeholders\n",
    "with graph.as_default():\n",
    "    inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs')\n",
    "    labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels')\n",
    "    keep_prob_ = tf.placeholder(tf.float32, name = 'keep')\n",
    "    learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build Convolutional Layer(s)\n",
    "\n",
    "Questions: \n",
    "* Should we use a different activation? Like tf.nn.tanh?\n",
    "* Should we use pooling? average or max?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convolutional layers\n",
    "with graph.as_default():\n",
    "    # (batch, 128, 9) --> (batch, 128, 18)\n",
    "    conv1 = tf.layers.conv1d(inputs=inputs_, filters=18, kernel_size=2, strides=1, \n",
    "                             padding='same', activation = tf.nn.relu)\n",
    "    n_ch = n_channels *2\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, pass to LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    # Construct the LSTM inputs and LSTM cells\n",
    "    lstm_in = tf.transpose(conv1, [1,0,2]) # reshape into (seq_len, batch, channels)\n",
    "    lstm_in = tf.reshape(lstm_in, [-1, n_ch]) # Now (seq_len*N, n_channels)\n",
    "    \n",
    "    # To cells\n",
    "    lstm_in = tf.layers.dense(lstm_in, lstm_size, activation=None) # or tf.nn.relu, tf.nn.sigmoid, tf.nn.tanh?\n",
    "    \n",
    "    # Open up the tensor into a list of seq_len pieces\n",
    "    lstm_in = tf.split(lstm_in, seq_len, 0)\n",
    "    \n",
    "    # Add LSTM layers\n",
    "    lstm = tf.contrib.rnn.BasicLSTMCell(lstm_size)\n",
    "    drop = tf.contrib.rnn.DropoutWrapper(lstm, output_keep_prob=keep_prob_)\n",
    "    cell = tf.contrib.rnn.MultiRNNCell([drop] * lstm_layers)\n",
    "    initial_state = cell.zero_state(batch_size, tf.float32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define forward pass and cost function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with graph.as_default():\n",
    "    outputs, final_state = tf.contrib.rnn.static_rnn(cell, lstm_in, dtype=tf.float32,\n",
    "                                                     initial_state = initial_state)\n",
    "    \n",
    "    # We only need the last output tensor to pass into a classifier\n",
    "    logits = tf.layers.dense(outputs[-1], n_classes, name='logits')\n",
    "    \n",
    "    # Cost function and optimizer\n",
    "    cost = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_))\n",
    "    #optimizer = tf.train.AdamOptimizer(learning_rate_).minimize(cost) # No grad clipping\n",
    "    \n",
    "    # Grad clipping\n",
    "    train_op = tf.train.AdamOptimizer(learning_rate_)\n",
    "\n",
    "    gradients = train_op.compute_gradients(cost)\n",
    "    capped_gradients = [(tf.clip_by_value(grad, -1., 1.), var) for grad, var in gradients]\n",
    "    optimizer = train_op.apply_gradients(capped_gradients)\n",
    "    \n",
    "    # Accuracy\n",
    "    correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if (os.path.exists('checkpoints-crnn') == False):\n",
    "    !mkdir checkpoints-crnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0/1000 Iteration: 5 Train loss: 1.820212 Train acc: 0.195000\n",
      "Epoch: 1/1000 Iteration: 10 Train loss: 1.805851 Train acc: 0.198333\n",
      "Epoch: 1/1000 Iteration: 15 Train loss: 1.787565 Train acc: 0.220000\n",
      "Epoch: 2/1000 Iteration: 20 Train loss: 1.789301 Train acc: 0.200000\n",
      "Epoch: 2/1000 Iteration: 25 Train loss: 1.772577 Train acc: 0.225000\n",
      "Epoch: 2/1000 Iteration: 25 Validation loss: 1.754684 Validation acc: 0.312778\n",
      "Epoch: 3/1000 Iteration: 30 Train loss: 1.757486 Train acc: 0.245000\n",
      "Epoch: 3/1000 Iteration: 35 Train loss: 1.747905 Train acc: 0.275000\n",
      "Epoch: 4/1000 Iteration: 40 Train loss: 1.728050 Train acc: 0.278333\n",
      "Epoch: 4/1000 Iteration: 45 Train loss: 1.727108 Train acc: 0.285000\n",
      "Epoch: 5/1000 Iteration: 50 Train loss: 1.706027 Train acc: 0.306667\n",
      "Epoch: 5/1000 Iteration: 50 Validation loss: 1.693114 Validation acc: 0.416667\n",
      "Epoch: 6/1000 Iteration: 55 Train loss: 1.696254 Train acc: 0.356667\n",
      "Epoch: 6/1000 Iteration: 60 Train loss: 1.683182 Train acc: 0.356667\n",
      "Epoch: 7/1000 Iteration: 65 Train loss: 1.671199 Train acc: 0.366667\n",
      "Epoch: 7/1000 Iteration: 70 Train loss: 1.668917 Train acc: 0.363333\n",
      "Epoch: 8/1000 Iteration: 75 Train loss: 1.660387 Train acc: 0.350000\n",
      "Epoch: 8/1000 Iteration: 75 Validation loss: 1.625782 Validation acc: 0.468889\n",
      "Epoch: 8/1000 Iteration: 80 Train loss: 1.646031 Train acc: 0.378333\n",
      "Epoch: 9/1000 Iteration: 85 Train loss: 1.639138 Train acc: 0.405000\n",
      "Epoch: 9/1000 Iteration: 90 Train loss: 1.629824 Train acc: 0.411667\n",
      "Epoch: 10/1000 Iteration: 95 Train loss: 1.576027 Train acc: 0.461667\n",
      "Epoch: 11/1000 Iteration: 100 Train loss: 1.570262 Train acc: 0.446667\n",
      "Epoch: 11/1000 Iteration: 100 Validation loss: 1.551610 Validation acc: 0.505556\n",
      "Epoch: 11/1000 Iteration: 105 Train loss: 1.561274 Train acc: 0.453333\n",
      "Epoch: 12/1000 Iteration: 110 Train loss: 1.552974 Train acc: 0.458333\n",
      "Epoch: 12/1000 Iteration: 115 Train loss: 1.552384 Train acc: 0.446667\n",
      "Epoch: 13/1000 Iteration: 120 Train loss: 1.542372 Train acc: 0.433333\n",
      "Epoch: 13/1000 Iteration: 125 Train loss: 1.521307 Train acc: 0.470000\n",
      "Epoch: 13/1000 Iteration: 125 Validation loss: 1.467162 Validation acc: 0.526111\n",
      "Epoch: 14/1000 Iteration: 130 Train loss: 1.502767 Train acc: 0.470000\n",
      "Epoch: 14/1000 Iteration: 135 Train loss: 1.481720 Train acc: 0.510000\n",
      "Epoch: 15/1000 Iteration: 140 Train loss: 1.435971 Train acc: 0.545000\n",
      "Epoch: 16/1000 Iteration: 145 Train loss: 1.432786 Train acc: 0.500000\n",
      "Epoch: 16/1000 Iteration: 150 Train loss: 1.410829 Train acc: 0.506667\n",
      "Epoch: 16/1000 Iteration: 150 Validation loss: 1.367979 Validation acc: 0.543889\n",
      "Epoch: 17/1000 Iteration: 155 Train loss: 1.391085 Train acc: 0.521667\n",
      "Epoch: 17/1000 Iteration: 160 Train loss: 1.404801 Train acc: 0.511667\n",
      "Epoch: 18/1000 Iteration: 165 Train loss: 1.400702 Train acc: 0.505000\n",
      "Epoch: 18/1000 Iteration: 170 Train loss: 1.354328 Train acc: 0.543333\n",
      "Epoch: 19/1000 Iteration: 175 Train loss: 1.355788 Train acc: 0.530000\n",
      "Epoch: 19/1000 Iteration: 175 Validation loss: 1.261552 Validation acc: 0.531667\n",
      "Epoch: 19/1000 Iteration: 180 Train loss: 1.302319 Train acc: 0.546667\n",
      "Epoch: 20/1000 Iteration: 185 Train loss: 1.273763 Train acc: 0.556667\n",
      "Epoch: 21/1000 Iteration: 190 Train loss: 1.284515 Train acc: 0.548333\n",
      "Epoch: 21/1000 Iteration: 195 Train loss: 1.258723 Train acc: 0.556667\n",
      "Epoch: 22/1000 Iteration: 200 Train loss: 1.238381 Train acc: 0.573333\n",
      "Epoch: 22/1000 Iteration: 200 Validation loss: 1.173573 Validation acc: 0.528333\n",
      "Epoch: 22/1000 Iteration: 205 Train loss: 1.261911 Train acc: 0.520000\n",
      "Epoch: 23/1000 Iteration: 210 Train loss: 1.214848 Train acc: 0.575000\n",
      "Epoch: 23/1000 Iteration: 215 Train loss: 1.208578 Train acc: 0.558333\n",
      "Epoch: 24/1000 Iteration: 220 Train loss: 1.212722 Train acc: 0.563333\n",
      "Epoch: 24/1000 Iteration: 225 Train loss: 1.182609 Train acc: 0.563333\n",
      "Epoch: 24/1000 Iteration: 225 Validation loss: 1.104376 Validation acc: 0.534444\n",
      "Epoch: 25/1000 Iteration: 230 Train loss: 1.128649 Train acc: 0.575000\n",
      "Epoch: 26/1000 Iteration: 235 Train loss: 1.132126 Train acc: 0.578333\n",
      "Epoch: 26/1000 Iteration: 240 Train loss: 1.132119 Train acc: 0.561667\n",
      "Epoch: 27/1000 Iteration: 245 Train loss: 1.138613 Train acc: 0.536667\n",
      "Epoch: 27/1000 Iteration: 250 Train loss: 1.165615 Train acc: 0.536667\n",
      "Epoch: 27/1000 Iteration: 250 Validation loss: 1.046322 Validation acc: 0.592778\n",
      "Epoch: 28/1000 Iteration: 255 Train loss: 1.131782 Train acc: 0.530000\n",
      "Epoch: 28/1000 Iteration: 260 Train loss: 1.117442 Train acc: 0.561667\n",
      "Epoch: 29/1000 Iteration: 265 Train loss: 1.103960 Train acc: 0.565000\n",
      "Epoch: 29/1000 Iteration: 270 Train loss: 1.105988 Train acc: 0.565000\n",
      "Epoch: 30/1000 Iteration: 275 Train loss: 1.048057 Train acc: 0.598333\n",
      "Epoch: 30/1000 Iteration: 275 Validation loss: 0.997726 Validation acc: 0.668333\n",
      "Epoch: 31/1000 Iteration: 280 Train loss: 1.064882 Train acc: 0.588333\n",
      "Epoch: 31/1000 Iteration: 285 Train loss: 1.035514 Train acc: 0.591667\n",
      "Epoch: 32/1000 Iteration: 290 Train loss: 1.068756 Train acc: 0.571667\n",
      "Epoch: 32/1000 Iteration: 295 Train loss: 1.071036 Train acc: 0.541667\n",
      "Epoch: 33/1000 Iteration: 300 Train loss: 1.076805 Train acc: 0.541667\n",
      "Epoch: 33/1000 Iteration: 300 Validation loss: 0.954297 Validation acc: 0.658333\n",
      "Epoch: 33/1000 Iteration: 305 Train loss: 1.048160 Train acc: 0.585000\n",
      "Epoch: 34/1000 Iteration: 310 Train loss: 1.036134 Train acc: 0.578333\n",
      "Epoch: 34/1000 Iteration: 315 Train loss: 1.047778 Train acc: 0.566667\n",
      "Epoch: 35/1000 Iteration: 320 Train loss: 0.989761 Train acc: 0.615000\n",
      "Epoch: 36/1000 Iteration: 325 Train loss: 1.011162 Train acc: 0.596667\n",
      "Epoch: 36/1000 Iteration: 325 Validation loss: 0.914251 Validation acc: 0.657222\n",
      "Epoch: 36/1000 Iteration: 330 Train loss: 0.959467 Train acc: 0.615000\n",
      "Epoch: 37/1000 Iteration: 335 Train loss: 0.990215 Train acc: 0.585000\n",
      "Epoch: 37/1000 Iteration: 340 Train loss: 1.018476 Train acc: 0.581667\n",
      "Epoch: 38/1000 Iteration: 345 Train loss: 0.998264 Train acc: 0.593333\n",
      "Epoch: 38/1000 Iteration: 350 Train loss: 0.983000 Train acc: 0.595000\n",
      "Epoch: 38/1000 Iteration: 350 Validation loss: 0.878340 Validation acc: 0.666111\n",
      "Epoch: 39/1000 Iteration: 355 Train loss: 0.965855 Train acc: 0.605000\n",
      "Epoch: 39/1000 Iteration: 360 Train loss: 0.961078 Train acc: 0.606667\n",
      "Epoch: 40/1000 Iteration: 365 Train loss: 0.892743 Train acc: 0.666667\n",
      "Epoch: 41/1000 Iteration: 370 Train loss: 0.942833 Train acc: 0.618333\n",
      "Epoch: 41/1000 Iteration: 375 Train loss: 0.908581 Train acc: 0.665000\n",
      "Epoch: 41/1000 Iteration: 375 Validation loss: 0.842050 Validation acc: 0.698889\n",
      "Epoch: 42/1000 Iteration: 380 Train loss: 0.918071 Train acc: 0.630000\n",
      "Epoch: 42/1000 Iteration: 385 Train loss: 0.937245 Train acc: 0.633333\n",
      "Epoch: 43/1000 Iteration: 390 Train loss: 0.915478 Train acc: 0.645000\n",
      "Epoch: 43/1000 Iteration: 395 Train loss: 0.915649 Train acc: 0.630000\n",
      "Epoch: 44/1000 Iteration: 400 Train loss: 0.926855 Train acc: 0.628333\n",
      "Epoch: 44/1000 Iteration: 400 Validation loss: 0.804678 Validation acc: 0.723333\n",
      "Epoch: 44/1000 Iteration: 405 Train loss: 0.909865 Train acc: 0.646667\n",
      "Epoch: 45/1000 Iteration: 410 Train loss: 0.845671 Train acc: 0.686667\n",
      "Epoch: 46/1000 Iteration: 415 Train loss: 0.860009 Train acc: 0.688333\n",
      "Epoch: 46/1000 Iteration: 420 Train loss: 0.861219 Train acc: 0.678333\n",
      "Epoch: 47/1000 Iteration: 425 Train loss: 0.849474 Train acc: 0.683333\n",
      "Epoch: 47/1000 Iteration: 425 Validation loss: 0.761483 Validation acc: 0.756111\n",
      "Epoch: 47/1000 Iteration: 430 Train loss: 0.872034 Train acc: 0.673333\n",
      "Epoch: 48/1000 Iteration: 435 Train loss: 0.858176 Train acc: 0.670000\n",
      "Epoch: 48/1000 Iteration: 440 Train loss: 0.836961 Train acc: 0.701667\n",
      "Epoch: 49/1000 Iteration: 445 Train loss: 0.818676 Train acc: 0.718333\n",
      "Epoch: 49/1000 Iteration: 450 Train loss: 0.844604 Train acc: 0.718333\n",
      "Epoch: 49/1000 Iteration: 450 Validation loss: 0.713230 Validation acc: 0.802222\n",
      "Epoch: 50/1000 Iteration: 455 Train loss: 0.780784 Train acc: 0.726667\n",
      "Epoch: 51/1000 Iteration: 460 Train loss: 0.761725 Train acc: 0.760000\n",
      "Epoch: 51/1000 Iteration: 465 Train loss: 0.772808 Train acc: 0.738333\n",
      "Epoch: 52/1000 Iteration: 470 Train loss: 0.774510 Train acc: 0.755000\n",
      "Epoch: 52/1000 Iteration: 475 Train loss: 0.754581 Train acc: 0.756667\n",
      "Epoch: 52/1000 Iteration: 475 Validation loss: 0.663676 Validation acc: 0.842778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 53/1000 Iteration: 480 Train loss: 0.768577 Train acc: 0.725000\n",
      "Epoch: 53/1000 Iteration: 485 Train loss: 0.745624 Train acc: 0.785000\n",
      "Epoch: 54/1000 Iteration: 490 Train loss: 0.752024 Train acc: 0.755000\n",
      "Epoch: 54/1000 Iteration: 495 Train loss: 0.755776 Train acc: 0.751667\n",
      "Epoch: 55/1000 Iteration: 500 Train loss: 0.707066 Train acc: 0.788333\n",
      "Epoch: 55/1000 Iteration: 500 Validation loss: 0.613790 Validation acc: 0.886111\n",
      "Epoch: 56/1000 Iteration: 505 Train loss: 0.691065 Train acc: 0.805000\n",
      "Epoch: 56/1000 Iteration: 510 Train loss: 0.707045 Train acc: 0.780000\n",
      "Epoch: 57/1000 Iteration: 515 Train loss: 0.707216 Train acc: 0.803333\n",
      "Epoch: 57/1000 Iteration: 520 Train loss: 0.674143 Train acc: 0.818333\n",
      "Epoch: 58/1000 Iteration: 525 Train loss: 0.672850 Train acc: 0.805000\n",
      "Epoch: 58/1000 Iteration: 525 Validation loss: 0.572206 Validation acc: 0.896667\n",
      "Epoch: 58/1000 Iteration: 530 Train loss: 0.659299 Train acc: 0.816667\n",
      "Epoch: 59/1000 Iteration: 535 Train loss: 0.671344 Train acc: 0.805000\n",
      "Epoch: 59/1000 Iteration: 540 Train loss: 0.660667 Train acc: 0.825000\n",
      "Epoch: 60/1000 Iteration: 545 Train loss: 0.634700 Train acc: 0.831667\n",
      "Epoch: 61/1000 Iteration: 550 Train loss: 0.647096 Train acc: 0.833333\n",
      "Epoch: 61/1000 Iteration: 550 Validation loss: 0.531695 Validation acc: 0.908333\n",
      "Epoch: 61/1000 Iteration: 555 Train loss: 0.626607 Train acc: 0.838333\n",
      "Epoch: 62/1000 Iteration: 560 Train loss: 0.629467 Train acc: 0.838333\n",
      "Epoch: 62/1000 Iteration: 565 Train loss: 0.625077 Train acc: 0.841667\n",
      "Epoch: 63/1000 Iteration: 570 Train loss: 0.626885 Train acc: 0.820000\n",
      "Epoch: 63/1000 Iteration: 575 Train loss: 0.618672 Train acc: 0.848333\n",
      "Epoch: 63/1000 Iteration: 575 Validation loss: 0.494005 Validation acc: 0.912222\n",
      "Epoch: 64/1000 Iteration: 580 Train loss: 0.624322 Train acc: 0.826667\n",
      "Epoch: 64/1000 Iteration: 585 Train loss: 0.620157 Train acc: 0.841667\n",
      "Epoch: 65/1000 Iteration: 590 Train loss: 0.593919 Train acc: 0.840000\n",
      "Epoch: 66/1000 Iteration: 595 Train loss: 0.570569 Train acc: 0.871667\n",
      "Epoch: 66/1000 Iteration: 600 Train loss: 0.583756 Train acc: 0.875000\n",
      "Epoch: 66/1000 Iteration: 600 Validation loss: 0.457806 Validation acc: 0.916667\n",
      "Epoch: 67/1000 Iteration: 605 Train loss: 0.553844 Train acc: 0.866667\n",
      "Epoch: 67/1000 Iteration: 610 Train loss: 0.567562 Train acc: 0.851667\n",
      "Epoch: 68/1000 Iteration: 615 Train loss: 0.577566 Train acc: 0.858333\n",
      "Epoch: 68/1000 Iteration: 620 Train loss: 0.533720 Train acc: 0.890000\n",
      "Epoch: 69/1000 Iteration: 625 Train loss: 0.549141 Train acc: 0.866667\n",
      "Epoch: 69/1000 Iteration: 625 Validation loss: 0.427360 Validation acc: 0.917222\n",
      "Epoch: 69/1000 Iteration: 630 Train loss: 0.555760 Train acc: 0.870000\n",
      "Epoch: 70/1000 Iteration: 635 Train loss: 0.525708 Train acc: 0.878333\n",
      "Epoch: 71/1000 Iteration: 640 Train loss: 0.498287 Train acc: 0.885000\n",
      "Epoch: 71/1000 Iteration: 645 Train loss: 0.519877 Train acc: 0.883333\n",
      "Epoch: 72/1000 Iteration: 650 Train loss: 0.513738 Train acc: 0.885000\n",
      "Epoch: 72/1000 Iteration: 650 Validation loss: 0.390467 Validation acc: 0.921667\n",
      "Epoch: 72/1000 Iteration: 655 Train loss: 0.502942 Train acc: 0.891667\n",
      "Epoch: 73/1000 Iteration: 660 Train loss: 0.523676 Train acc: 0.870000\n",
      "Epoch: 73/1000 Iteration: 665 Train loss: 0.472353 Train acc: 0.915000\n",
      "Epoch: 74/1000 Iteration: 670 Train loss: 0.491722 Train acc: 0.893333\n",
      "Epoch: 74/1000 Iteration: 675 Train loss: 0.499967 Train acc: 0.886667\n",
      "Epoch: 74/1000 Iteration: 675 Validation loss: 0.365445 Validation acc: 0.926111\n",
      "Epoch: 75/1000 Iteration: 680 Train loss: 0.463890 Train acc: 0.915000\n",
      "Epoch: 76/1000 Iteration: 685 Train loss: 0.462258 Train acc: 0.893333\n",
      "Epoch: 76/1000 Iteration: 690 Train loss: 0.456712 Train acc: 0.908333\n",
      "Epoch: 77/1000 Iteration: 695 Train loss: 0.465844 Train acc: 0.901667\n",
      "Epoch: 77/1000 Iteration: 700 Train loss: 0.454331 Train acc: 0.903333\n",
      "Epoch: 77/1000 Iteration: 700 Validation loss: 0.341513 Validation acc: 0.931667\n",
      "Epoch: 78/1000 Iteration: 705 Train loss: 0.481226 Train acc: 0.880000\n",
      "Epoch: 78/1000 Iteration: 710 Train loss: 0.451573 Train acc: 0.923333\n",
      "Epoch: 79/1000 Iteration: 715 Train loss: 0.469532 Train acc: 0.875000\n",
      "Epoch: 79/1000 Iteration: 720 Train loss: 0.461190 Train acc: 0.906667\n",
      "Epoch: 80/1000 Iteration: 725 Train loss: 0.417088 Train acc: 0.911667\n",
      "Epoch: 80/1000 Iteration: 725 Validation loss: 0.318569 Validation acc: 0.937778\n",
      "Epoch: 81/1000 Iteration: 730 Train loss: 0.437454 Train acc: 0.900000\n",
      "Epoch: 81/1000 Iteration: 735 Train loss: 0.419800 Train acc: 0.918333\n",
      "Epoch: 82/1000 Iteration: 740 Train loss: 0.448013 Train acc: 0.925000\n",
      "Epoch: 82/1000 Iteration: 745 Train loss: 0.416128 Train acc: 0.913333\n",
      "Epoch: 83/1000 Iteration: 750 Train loss: 0.446910 Train acc: 0.898333\n",
      "Epoch: 83/1000 Iteration: 750 Validation loss: 0.296019 Validation acc: 0.945000\n",
      "Epoch: 83/1000 Iteration: 755 Train loss: 0.370932 Train acc: 0.933333\n",
      "Epoch: 84/1000 Iteration: 760 Train loss: 0.398077 Train acc: 0.920000\n",
      "Epoch: 84/1000 Iteration: 765 Train loss: 0.420091 Train acc: 0.920000\n",
      "Epoch: 85/1000 Iteration: 770 Train loss: 0.416952 Train acc: 0.915000\n",
      "Epoch: 86/1000 Iteration: 775 Train loss: 0.395478 Train acc: 0.928333\n",
      "Epoch: 86/1000 Iteration: 775 Validation loss: 0.281908 Validation acc: 0.944444\n",
      "Epoch: 86/1000 Iteration: 780 Train loss: 0.366090 Train acc: 0.930000\n",
      "Epoch: 87/1000 Iteration: 785 Train loss: 0.404105 Train acc: 0.926667\n",
      "Epoch: 87/1000 Iteration: 790 Train loss: 0.396109 Train acc: 0.923333\n",
      "Epoch: 88/1000 Iteration: 795 Train loss: 0.394330 Train acc: 0.926667\n",
      "Epoch: 88/1000 Iteration: 800 Train loss: 0.349179 Train acc: 0.938333\n",
      "Epoch: 88/1000 Iteration: 800 Validation loss: 0.272345 Validation acc: 0.942222\n",
      "Epoch: 89/1000 Iteration: 805 Train loss: 0.394974 Train acc: 0.918333\n",
      "Epoch: 89/1000 Iteration: 810 Train loss: 0.395758 Train acc: 0.918333\n",
      "Epoch: 90/1000 Iteration: 815 Train loss: 0.369320 Train acc: 0.931667\n",
      "Epoch: 91/1000 Iteration: 820 Train loss: 0.361788 Train acc: 0.930000\n",
      "Epoch: 91/1000 Iteration: 825 Train loss: 0.359028 Train acc: 0.935000\n",
      "Epoch: 91/1000 Iteration: 825 Validation loss: 0.263151 Validation acc: 0.942778\n",
      "Epoch: 92/1000 Iteration: 830 Train loss: 0.387985 Train acc: 0.923333\n",
      "Epoch: 92/1000 Iteration: 835 Train loss: 0.355321 Train acc: 0.936667\n",
      "Epoch: 93/1000 Iteration: 840 Train loss: 0.356032 Train acc: 0.931667\n",
      "Epoch: 93/1000 Iteration: 845 Train loss: 0.346631 Train acc: 0.943333\n",
      "Epoch: 94/1000 Iteration: 850 Train loss: 0.381398 Train acc: 0.903333\n",
      "Epoch: 94/1000 Iteration: 850 Validation loss: 0.250363 Validation acc: 0.945000\n",
      "Epoch: 94/1000 Iteration: 855 Train loss: 0.386899 Train acc: 0.923333\n",
      "Epoch: 95/1000 Iteration: 860 Train loss: 0.352185 Train acc: 0.926667\n",
      "Epoch: 96/1000 Iteration: 865 Train loss: 0.342758 Train acc: 0.931667\n",
      "Epoch: 96/1000 Iteration: 870 Train loss: 0.340096 Train acc: 0.943333\n",
      "Epoch: 97/1000 Iteration: 875 Train loss: 0.327834 Train acc: 0.936667\n",
      "Epoch: 97/1000 Iteration: 875 Validation loss: 0.245215 Validation acc: 0.942222\n",
      "Epoch: 97/1000 Iteration: 880 Train loss: 0.352514 Train acc: 0.931667\n",
      "Epoch: 98/1000 Iteration: 885 Train loss: 0.343540 Train acc: 0.938333\n",
      "Epoch: 98/1000 Iteration: 890 Train loss: 0.309792 Train acc: 0.946667\n",
      "Epoch: 99/1000 Iteration: 895 Train loss: 0.334616 Train acc: 0.925000\n",
      "Epoch: 99/1000 Iteration: 900 Train loss: 0.370038 Train acc: 0.926667\n",
      "Epoch: 99/1000 Iteration: 900 Validation loss: 0.227541 Validation acc: 0.948889\n",
      "Epoch: 100/1000 Iteration: 905 Train loss: 0.335870 Train acc: 0.935000\n",
      "Epoch: 101/1000 Iteration: 910 Train loss: 0.333571 Train acc: 0.935000\n",
      "Epoch: 101/1000 Iteration: 915 Train loss: 0.322774 Train acc: 0.935000\n",
      "Epoch: 102/1000 Iteration: 920 Train loss: 0.323263 Train acc: 0.940000\n",
      "Epoch: 102/1000 Iteration: 925 Train loss: 0.322601 Train acc: 0.943333\n",
      "Epoch: 102/1000 Iteration: 925 Validation loss: 0.228599 Validation acc: 0.945556\n",
      "Epoch: 103/1000 Iteration: 930 Train loss: 0.329826 Train acc: 0.920000\n",
      "Epoch: 103/1000 Iteration: 935 Train loss: 0.320247 Train acc: 0.943333\n",
      "Epoch: 104/1000 Iteration: 940 Train loss: 0.336372 Train acc: 0.926667\n",
      "Epoch: 104/1000 Iteration: 945 Train loss: 0.350489 Train acc: 0.928333\n",
      "Epoch: 105/1000 Iteration: 950 Train loss: 0.297166 Train acc: 0.945000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 105/1000 Iteration: 950 Validation loss: 0.217218 Validation acc: 0.948333\n",
      "Epoch: 106/1000 Iteration: 955 Train loss: 0.317807 Train acc: 0.931667\n",
      "Epoch: 106/1000 Iteration: 960 Train loss: 0.314952 Train acc: 0.936667\n",
      "Epoch: 107/1000 Iteration: 965 Train loss: 0.311310 Train acc: 0.946667\n",
      "Epoch: 107/1000 Iteration: 970 Train loss: 0.306601 Train acc: 0.931667\n",
      "Epoch: 108/1000 Iteration: 975 Train loss: 0.328082 Train acc: 0.933333\n",
      "Epoch: 108/1000 Iteration: 975 Validation loss: 0.214680 Validation acc: 0.946667\n",
      "Epoch: 108/1000 Iteration: 980 Train loss: 0.283785 Train acc: 0.951667\n",
      "Epoch: 109/1000 Iteration: 985 Train loss: 0.306368 Train acc: 0.921667\n",
      "Epoch: 109/1000 Iteration: 990 Train loss: 0.333584 Train acc: 0.928333\n",
      "Epoch: 110/1000 Iteration: 995 Train loss: 0.287255 Train acc: 0.941667\n",
      "Epoch: 111/1000 Iteration: 1000 Train loss: 0.286897 Train acc: 0.940000\n",
      "Epoch: 111/1000 Iteration: 1000 Validation loss: 0.207233 Validation acc: 0.949444\n",
      "Epoch: 111/1000 Iteration: 1005 Train loss: 0.304303 Train acc: 0.943333\n",
      "Epoch: 112/1000 Iteration: 1010 Train loss: 0.277391 Train acc: 0.951667\n",
      "Epoch: 112/1000 Iteration: 1015 Train loss: 0.294088 Train acc: 0.938333\n",
      "Epoch: 113/1000 Iteration: 1020 Train loss: 0.308975 Train acc: 0.928333\n",
      "Epoch: 113/1000 Iteration: 1025 Train loss: 0.280700 Train acc: 0.956667\n",
      "Epoch: 113/1000 Iteration: 1025 Validation loss: 0.204008 Validation acc: 0.948333\n",
      "Epoch: 114/1000 Iteration: 1030 Train loss: 0.333321 Train acc: 0.911667\n",
      "Epoch: 114/1000 Iteration: 1035 Train loss: 0.318396 Train acc: 0.938333\n",
      "Epoch: 115/1000 Iteration: 1040 Train loss: 0.290775 Train acc: 0.933333\n",
      "Epoch: 116/1000 Iteration: 1045 Train loss: 0.264472 Train acc: 0.955000\n",
      "Epoch: 116/1000 Iteration: 1050 Train loss: 0.281456 Train acc: 0.935000\n",
      "Epoch: 116/1000 Iteration: 1050 Validation loss: 0.197915 Validation acc: 0.950556\n",
      "Epoch: 117/1000 Iteration: 1055 Train loss: 0.291294 Train acc: 0.941667\n",
      "Epoch: 117/1000 Iteration: 1060 Train loss: 0.296111 Train acc: 0.941667\n",
      "Epoch: 118/1000 Iteration: 1065 Train loss: 0.285375 Train acc: 0.933333\n",
      "Epoch: 118/1000 Iteration: 1070 Train loss: 0.259376 Train acc: 0.948333\n",
      "Epoch: 119/1000 Iteration: 1075 Train loss: 0.307363 Train acc: 0.931667\n",
      "Epoch: 119/1000 Iteration: 1075 Validation loss: 0.194875 Validation acc: 0.949444\n",
      "Epoch: 119/1000 Iteration: 1080 Train loss: 0.289660 Train acc: 0.931667\n",
      "Epoch: 120/1000 Iteration: 1085 Train loss: 0.274450 Train acc: 0.945000\n",
      "Epoch: 121/1000 Iteration: 1090 Train loss: 0.280442 Train acc: 0.936667\n",
      "Epoch: 121/1000 Iteration: 1095 Train loss: 0.272522 Train acc: 0.948333\n",
      "Epoch: 122/1000 Iteration: 1100 Train loss: 0.268024 Train acc: 0.951667\n",
      "Epoch: 122/1000 Iteration: 1100 Validation loss: 0.190929 Validation acc: 0.948889\n",
      "Epoch: 122/1000 Iteration: 1105 Train loss: 0.283575 Train acc: 0.933333\n",
      "Epoch: 123/1000 Iteration: 1110 Train loss: 0.302664 Train acc: 0.938333\n",
      "Epoch: 123/1000 Iteration: 1115 Train loss: 0.247037 Train acc: 0.950000\n",
      "Epoch: 124/1000 Iteration: 1120 Train loss: 0.308783 Train acc: 0.918333\n",
      "Epoch: 124/1000 Iteration: 1125 Train loss: 0.308321 Train acc: 0.926667\n",
      "Epoch: 124/1000 Iteration: 1125 Validation loss: 0.191539 Validation acc: 0.947778\n",
      "Epoch: 125/1000 Iteration: 1130 Train loss: 0.275798 Train acc: 0.935000\n",
      "Epoch: 126/1000 Iteration: 1135 Train loss: 0.273580 Train acc: 0.950000\n",
      "Epoch: 126/1000 Iteration: 1140 Train loss: 0.253066 Train acc: 0.953333\n",
      "Epoch: 127/1000 Iteration: 1145 Train loss: 0.252817 Train acc: 0.948333\n",
      "Epoch: 127/1000 Iteration: 1150 Train loss: 0.281197 Train acc: 0.928333\n",
      "Epoch: 127/1000 Iteration: 1150 Validation loss: 0.191597 Validation acc: 0.947222\n",
      "Epoch: 128/1000 Iteration: 1155 Train loss: 0.296268 Train acc: 0.935000\n",
      "Epoch: 128/1000 Iteration: 1160 Train loss: 0.242197 Train acc: 0.956667\n",
      "Epoch: 129/1000 Iteration: 1165 Train loss: 0.279572 Train acc: 0.928333\n",
      "Epoch: 129/1000 Iteration: 1170 Train loss: 0.272244 Train acc: 0.945000\n",
      "Epoch: 130/1000 Iteration: 1175 Train loss: 0.259797 Train acc: 0.943333\n",
      "Epoch: 130/1000 Iteration: 1175 Validation loss: 0.191429 Validation acc: 0.943333\n",
      "Epoch: 131/1000 Iteration: 1180 Train loss: 0.241661 Train acc: 0.945000\n",
      "Epoch: 131/1000 Iteration: 1185 Train loss: 0.238227 Train acc: 0.948333\n",
      "Epoch: 132/1000 Iteration: 1190 Train loss: 0.262739 Train acc: 0.948333\n",
      "Epoch: 132/1000 Iteration: 1195 Train loss: 0.264290 Train acc: 0.948333\n",
      "Epoch: 133/1000 Iteration: 1200 Train loss: 0.273512 Train acc: 0.938333\n",
      "Epoch: 133/1000 Iteration: 1200 Validation loss: 0.180875 Validation acc: 0.950556\n",
      "Epoch: 133/1000 Iteration: 1205 Train loss: 0.240217 Train acc: 0.951667\n",
      "Epoch: 134/1000 Iteration: 1210 Train loss: 0.274664 Train acc: 0.930000\n",
      "Epoch: 134/1000 Iteration: 1215 Train loss: 0.282306 Train acc: 0.935000\n",
      "Epoch: 135/1000 Iteration: 1220 Train loss: 0.255610 Train acc: 0.940000\n",
      "Epoch: 136/1000 Iteration: 1225 Train loss: 0.243851 Train acc: 0.951667\n",
      "Epoch: 136/1000 Iteration: 1225 Validation loss: 0.179403 Validation acc: 0.946111\n",
      "Epoch: 136/1000 Iteration: 1230 Train loss: 0.236240 Train acc: 0.948333\n",
      "Epoch: 137/1000 Iteration: 1235 Train loss: 0.249857 Train acc: 0.951667\n",
      "Epoch: 137/1000 Iteration: 1240 Train loss: 0.259936 Train acc: 0.943333\n",
      "Epoch: 138/1000 Iteration: 1245 Train loss: 0.249959 Train acc: 0.941667\n",
      "Epoch: 138/1000 Iteration: 1250 Train loss: 0.221977 Train acc: 0.960000\n",
      "Epoch: 138/1000 Iteration: 1250 Validation loss: 0.175833 Validation acc: 0.950556\n",
      "Epoch: 139/1000 Iteration: 1255 Train loss: 0.276570 Train acc: 0.935000\n",
      "Epoch: 139/1000 Iteration: 1260 Train loss: 0.259050 Train acc: 0.938333\n",
      "Epoch: 140/1000 Iteration: 1265 Train loss: 0.256118 Train acc: 0.936667\n",
      "Epoch: 141/1000 Iteration: 1270 Train loss: 0.234208 Train acc: 0.951667\n",
      "Epoch: 141/1000 Iteration: 1275 Train loss: 0.242837 Train acc: 0.950000\n",
      "Epoch: 141/1000 Iteration: 1275 Validation loss: 0.175499 Validation acc: 0.949444\n",
      "Epoch: 142/1000 Iteration: 1280 Train loss: 0.239604 Train acc: 0.951667\n",
      "Epoch: 142/1000 Iteration: 1285 Train loss: 0.230764 Train acc: 0.943333\n",
      "Epoch: 143/1000 Iteration: 1290 Train loss: 0.262349 Train acc: 0.931667\n",
      "Epoch: 143/1000 Iteration: 1295 Train loss: 0.220135 Train acc: 0.951667\n",
      "Epoch: 144/1000 Iteration: 1300 Train loss: 0.280491 Train acc: 0.928333\n",
      "Epoch: 144/1000 Iteration: 1300 Validation loss: 0.170648 Validation acc: 0.950000\n",
      "Epoch: 144/1000 Iteration: 1305 Train loss: 0.265868 Train acc: 0.936667\n",
      "Epoch: 145/1000 Iteration: 1310 Train loss: 0.251369 Train acc: 0.940000\n",
      "Epoch: 146/1000 Iteration: 1315 Train loss: 0.229570 Train acc: 0.953333\n",
      "Epoch: 146/1000 Iteration: 1320 Train loss: 0.209682 Train acc: 0.955000\n",
      "Epoch: 147/1000 Iteration: 1325 Train loss: 0.239097 Train acc: 0.955000\n",
      "Epoch: 147/1000 Iteration: 1325 Validation loss: 0.169312 Validation acc: 0.948889\n",
      "Epoch: 147/1000 Iteration: 1330 Train loss: 0.244748 Train acc: 0.941667\n",
      "Epoch: 148/1000 Iteration: 1335 Train loss: 0.258838 Train acc: 0.930000\n",
      "Epoch: 148/1000 Iteration: 1340 Train loss: 0.219836 Train acc: 0.956667\n",
      "Epoch: 149/1000 Iteration: 1345 Train loss: 0.252080 Train acc: 0.931667\n",
      "Epoch: 149/1000 Iteration: 1350 Train loss: 0.247682 Train acc: 0.941667\n",
      "Epoch: 149/1000 Iteration: 1350 Validation loss: 0.169551 Validation acc: 0.948333\n",
      "Epoch: 150/1000 Iteration: 1355 Train loss: 0.244063 Train acc: 0.941667\n",
      "Epoch: 151/1000 Iteration: 1360 Train loss: 0.209403 Train acc: 0.951667\n",
      "Epoch: 151/1000 Iteration: 1365 Train loss: 0.214271 Train acc: 0.950000\n",
      "Epoch: 152/1000 Iteration: 1370 Train loss: 0.210746 Train acc: 0.958333\n",
      "Epoch: 152/1000 Iteration: 1375 Train loss: 0.233201 Train acc: 0.941667\n",
      "Epoch: 152/1000 Iteration: 1375 Validation loss: 0.169178 Validation acc: 0.949444\n",
      "Epoch: 153/1000 Iteration: 1380 Train loss: 0.244373 Train acc: 0.940000\n",
      "Epoch: 153/1000 Iteration: 1385 Train loss: 0.196835 Train acc: 0.968333\n",
      "Epoch: 154/1000 Iteration: 1390 Train loss: 0.257481 Train acc: 0.921667\n",
      "Epoch: 154/1000 Iteration: 1395 Train loss: 0.258657 Train acc: 0.938333\n",
      "Epoch: 155/1000 Iteration: 1400 Train loss: 0.243750 Train acc: 0.940000\n",
      "Epoch: 155/1000 Iteration: 1400 Validation loss: 0.171904 Validation acc: 0.947222\n",
      "Epoch: 156/1000 Iteration: 1405 Train loss: 0.221727 Train acc: 0.948333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 156/1000 Iteration: 1410 Train loss: 0.204086 Train acc: 0.956667\n",
      "Epoch: 157/1000 Iteration: 1415 Train loss: 0.231255 Train acc: 0.955000\n",
      "Epoch: 157/1000 Iteration: 1420 Train loss: 0.219523 Train acc: 0.943333\n",
      "Epoch: 158/1000 Iteration: 1425 Train loss: 0.269358 Train acc: 0.941667\n",
      "Epoch: 158/1000 Iteration: 1425 Validation loss: 0.163675 Validation acc: 0.951111\n",
      "Epoch: 158/1000 Iteration: 1430 Train loss: 0.207451 Train acc: 0.960000\n",
      "Epoch: 159/1000 Iteration: 1435 Train loss: 0.255504 Train acc: 0.935000\n",
      "Epoch: 159/1000 Iteration: 1440 Train loss: 0.236518 Train acc: 0.935000\n",
      "Epoch: 160/1000 Iteration: 1445 Train loss: 0.240639 Train acc: 0.943333\n",
      "Epoch: 161/1000 Iteration: 1450 Train loss: 0.218593 Train acc: 0.948333\n",
      "Epoch: 161/1000 Iteration: 1450 Validation loss: 0.165448 Validation acc: 0.948889\n",
      "Epoch: 161/1000 Iteration: 1455 Train loss: 0.217246 Train acc: 0.955000\n",
      "Epoch: 162/1000 Iteration: 1460 Train loss: 0.218003 Train acc: 0.955000\n",
      "Epoch: 162/1000 Iteration: 1465 Train loss: 0.215494 Train acc: 0.951667\n",
      "Epoch: 163/1000 Iteration: 1470 Train loss: 0.242315 Train acc: 0.936667\n",
      "Epoch: 163/1000 Iteration: 1475 Train loss: 0.202637 Train acc: 0.963333\n",
      "Epoch: 163/1000 Iteration: 1475 Validation loss: 0.163488 Validation acc: 0.949444\n",
      "Epoch: 164/1000 Iteration: 1480 Train loss: 0.243916 Train acc: 0.933333\n",
      "Epoch: 164/1000 Iteration: 1485 Train loss: 0.246624 Train acc: 0.943333\n",
      "Epoch: 165/1000 Iteration: 1490 Train loss: 0.234459 Train acc: 0.946667\n",
      "Epoch: 166/1000 Iteration: 1495 Train loss: 0.214647 Train acc: 0.953333\n",
      "Epoch: 166/1000 Iteration: 1500 Train loss: 0.203515 Train acc: 0.955000\n",
      "Epoch: 166/1000 Iteration: 1500 Validation loss: 0.160396 Validation acc: 0.948333\n",
      "Epoch: 167/1000 Iteration: 1505 Train loss: 0.213215 Train acc: 0.948333\n",
      "Epoch: 167/1000 Iteration: 1510 Train loss: 0.222713 Train acc: 0.946667\n",
      "Epoch: 168/1000 Iteration: 1515 Train loss: 0.231222 Train acc: 0.943333\n",
      "Epoch: 168/1000 Iteration: 1520 Train loss: 0.204423 Train acc: 0.956667\n",
      "Epoch: 169/1000 Iteration: 1525 Train loss: 0.240026 Train acc: 0.931667\n",
      "Epoch: 169/1000 Iteration: 1525 Validation loss: 0.164421 Validation acc: 0.945000\n",
      "Epoch: 169/1000 Iteration: 1530 Train loss: 0.239339 Train acc: 0.938333\n",
      "Epoch: 170/1000 Iteration: 1535 Train loss: 0.224219 Train acc: 0.938333\n",
      "Epoch: 171/1000 Iteration: 1540 Train loss: 0.198665 Train acc: 0.948333\n",
      "Epoch: 171/1000 Iteration: 1545 Train loss: 0.204551 Train acc: 0.948333\n",
      "Epoch: 172/1000 Iteration: 1550 Train loss: 0.218086 Train acc: 0.951667\n",
      "Epoch: 172/1000 Iteration: 1550 Validation loss: 0.156310 Validation acc: 0.949444\n",
      "Epoch: 172/1000 Iteration: 1555 Train loss: 0.212449 Train acc: 0.948333\n",
      "Epoch: 173/1000 Iteration: 1560 Train loss: 0.228206 Train acc: 0.930000\n",
      "Epoch: 173/1000 Iteration: 1565 Train loss: 0.194171 Train acc: 0.955000\n",
      "Epoch: 174/1000 Iteration: 1570 Train loss: 0.249178 Train acc: 0.933333\n",
      "Epoch: 174/1000 Iteration: 1575 Train loss: 0.233045 Train acc: 0.948333\n",
      "Epoch: 174/1000 Iteration: 1575 Validation loss: 0.152048 Validation acc: 0.951111\n",
      "Epoch: 175/1000 Iteration: 1580 Train loss: 0.210872 Train acc: 0.945000\n",
      "Epoch: 176/1000 Iteration: 1585 Train loss: 0.216358 Train acc: 0.950000\n",
      "Epoch: 176/1000 Iteration: 1590 Train loss: 0.195122 Train acc: 0.953333\n",
      "Epoch: 177/1000 Iteration: 1595 Train loss: 0.207686 Train acc: 0.943333\n",
      "Epoch: 177/1000 Iteration: 1600 Train loss: 0.205970 Train acc: 0.946667\n",
      "Epoch: 177/1000 Iteration: 1600 Validation loss: 0.154286 Validation acc: 0.949444\n",
      "Epoch: 178/1000 Iteration: 1605 Train loss: 0.237893 Train acc: 0.938333\n",
      "Epoch: 178/1000 Iteration: 1610 Train loss: 0.195231 Train acc: 0.955000\n",
      "Epoch: 179/1000 Iteration: 1615 Train loss: 0.228592 Train acc: 0.928333\n",
      "Epoch: 179/1000 Iteration: 1620 Train loss: 0.217856 Train acc: 0.946667\n",
      "Epoch: 180/1000 Iteration: 1625 Train loss: 0.208837 Train acc: 0.946667\n",
      "Epoch: 180/1000 Iteration: 1625 Validation loss: 0.156571 Validation acc: 0.947778\n",
      "Epoch: 181/1000 Iteration: 1630 Train loss: 0.208957 Train acc: 0.946667\n",
      "Epoch: 181/1000 Iteration: 1635 Train loss: 0.205516 Train acc: 0.960000\n",
      "Epoch: 182/1000 Iteration: 1640 Train loss: 0.218884 Train acc: 0.945000\n",
      "Epoch: 182/1000 Iteration: 1645 Train loss: 0.207151 Train acc: 0.946667\n",
      "Epoch: 183/1000 Iteration: 1650 Train loss: 0.223756 Train acc: 0.930000\n",
      "Epoch: 183/1000 Iteration: 1650 Validation loss: 0.155137 Validation acc: 0.949444\n",
      "Epoch: 183/1000 Iteration: 1655 Train loss: 0.187476 Train acc: 0.956667\n",
      "Epoch: 184/1000 Iteration: 1660 Train loss: 0.218689 Train acc: 0.935000\n",
      "Epoch: 184/1000 Iteration: 1665 Train loss: 0.243364 Train acc: 0.935000\n",
      "Epoch: 185/1000 Iteration: 1670 Train loss: 0.206087 Train acc: 0.951667\n",
      "Epoch: 186/1000 Iteration: 1675 Train loss: 0.200626 Train acc: 0.950000\n",
      "Epoch: 186/1000 Iteration: 1675 Validation loss: 0.152835 Validation acc: 0.948333\n",
      "Epoch: 186/1000 Iteration: 1680 Train loss: 0.182150 Train acc: 0.960000\n",
      "Epoch: 187/1000 Iteration: 1685 Train loss: 0.206124 Train acc: 0.953333\n",
      "Epoch: 187/1000 Iteration: 1690 Train loss: 0.192162 Train acc: 0.951667\n",
      "Epoch: 188/1000 Iteration: 1695 Train loss: 0.206088 Train acc: 0.946667\n",
      "Epoch: 188/1000 Iteration: 1700 Train loss: 0.177490 Train acc: 0.963333\n",
      "Epoch: 188/1000 Iteration: 1700 Validation loss: 0.151211 Validation acc: 0.949444\n",
      "Epoch: 189/1000 Iteration: 1705 Train loss: 0.220576 Train acc: 0.935000\n",
      "Epoch: 189/1000 Iteration: 1710 Train loss: 0.210408 Train acc: 0.946667\n",
      "Epoch: 190/1000 Iteration: 1715 Train loss: 0.204844 Train acc: 0.943333\n",
      "Epoch: 191/1000 Iteration: 1720 Train loss: 0.186354 Train acc: 0.956667\n",
      "Epoch: 191/1000 Iteration: 1725 Train loss: 0.188462 Train acc: 0.960000\n",
      "Epoch: 191/1000 Iteration: 1725 Validation loss: 0.151010 Validation acc: 0.949444\n",
      "Epoch: 192/1000 Iteration: 1730 Train loss: 0.205683 Train acc: 0.958333\n",
      "Epoch: 192/1000 Iteration: 1735 Train loss: 0.177542 Train acc: 0.958333\n",
      "Epoch: 193/1000 Iteration: 1740 Train loss: 0.213396 Train acc: 0.940000\n",
      "Epoch: 193/1000 Iteration: 1745 Train loss: 0.173793 Train acc: 0.953333\n",
      "Epoch: 194/1000 Iteration: 1750 Train loss: 0.226612 Train acc: 0.930000\n",
      "Epoch: 194/1000 Iteration: 1750 Validation loss: 0.153519 Validation acc: 0.947222\n",
      "Epoch: 194/1000 Iteration: 1755 Train loss: 0.213253 Train acc: 0.938333\n",
      "Epoch: 195/1000 Iteration: 1760 Train loss: 0.192868 Train acc: 0.958333\n",
      "Epoch: 196/1000 Iteration: 1765 Train loss: 0.191552 Train acc: 0.951667\n",
      "Epoch: 196/1000 Iteration: 1770 Train loss: 0.185194 Train acc: 0.951667\n",
      "Epoch: 197/1000 Iteration: 1775 Train loss: 0.199231 Train acc: 0.955000\n",
      "Epoch: 197/1000 Iteration: 1775 Validation loss: 0.146025 Validation acc: 0.951111\n",
      "Epoch: 197/1000 Iteration: 1780 Train loss: 0.201354 Train acc: 0.950000\n",
      "Epoch: 198/1000 Iteration: 1785 Train loss: 0.207678 Train acc: 0.945000\n",
      "Epoch: 198/1000 Iteration: 1790 Train loss: 0.175315 Train acc: 0.965000\n",
      "Epoch: 199/1000 Iteration: 1795 Train loss: 0.220536 Train acc: 0.940000\n",
      "Epoch: 199/1000 Iteration: 1800 Train loss: 0.201061 Train acc: 0.953333\n",
      "Epoch: 199/1000 Iteration: 1800 Validation loss: 0.150319 Validation acc: 0.950000\n",
      "Epoch: 200/1000 Iteration: 1805 Train loss: 0.179451 Train acc: 0.953333\n",
      "Epoch: 201/1000 Iteration: 1810 Train loss: 0.179692 Train acc: 0.955000\n",
      "Epoch: 201/1000 Iteration: 1815 Train loss: 0.186726 Train acc: 0.946667\n",
      "Epoch: 202/1000 Iteration: 1820 Train loss: 0.198548 Train acc: 0.946667\n",
      "Epoch: 202/1000 Iteration: 1825 Train loss: 0.186257 Train acc: 0.950000\n",
      "Epoch: 202/1000 Iteration: 1825 Validation loss: 0.148332 Validation acc: 0.948333\n",
      "Epoch: 203/1000 Iteration: 1830 Train loss: 0.202877 Train acc: 0.945000\n",
      "Epoch: 203/1000 Iteration: 1835 Train loss: 0.172834 Train acc: 0.958333\n",
      "Epoch: 204/1000 Iteration: 1840 Train loss: 0.232319 Train acc: 0.935000\n",
      "Epoch: 204/1000 Iteration: 1845 Train loss: 0.205575 Train acc: 0.941667\n",
      "Epoch: 205/1000 Iteration: 1850 Train loss: 0.227506 Train acc: 0.940000\n",
      "Epoch: 205/1000 Iteration: 1850 Validation loss: 0.150597 Validation acc: 0.947778\n",
      "Epoch: 206/1000 Iteration: 1855 Train loss: 0.197829 Train acc: 0.956667\n",
      "Epoch: 206/1000 Iteration: 1860 Train loss: 0.175428 Train acc: 0.958333\n",
      "Epoch: 207/1000 Iteration: 1865 Train loss: 0.206175 Train acc: 0.955000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 207/1000 Iteration: 1870 Train loss: 0.197786 Train acc: 0.950000\n",
      "Epoch: 208/1000 Iteration: 1875 Train loss: 0.199966 Train acc: 0.948333\n",
      "Epoch: 208/1000 Iteration: 1875 Validation loss: 0.146860 Validation acc: 0.948889\n",
      "Epoch: 208/1000 Iteration: 1880 Train loss: 0.157128 Train acc: 0.965000\n",
      "Epoch: 209/1000 Iteration: 1885 Train loss: 0.198424 Train acc: 0.943333\n",
      "Epoch: 209/1000 Iteration: 1890 Train loss: 0.200021 Train acc: 0.946667\n",
      "Epoch: 210/1000 Iteration: 1895 Train loss: 0.209143 Train acc: 0.945000\n",
      "Epoch: 211/1000 Iteration: 1900 Train loss: 0.172867 Train acc: 0.950000\n",
      "Epoch: 211/1000 Iteration: 1900 Validation loss: 0.144628 Validation acc: 0.950556\n",
      "Epoch: 211/1000 Iteration: 1905 Train loss: 0.183694 Train acc: 0.946667\n",
      "Epoch: 212/1000 Iteration: 1910 Train loss: 0.186347 Train acc: 0.948333\n",
      "Epoch: 212/1000 Iteration: 1915 Train loss: 0.179692 Train acc: 0.950000\n",
      "Epoch: 213/1000 Iteration: 1920 Train loss: 0.194528 Train acc: 0.950000\n",
      "Epoch: 213/1000 Iteration: 1925 Train loss: 0.160486 Train acc: 0.970000\n",
      "Epoch: 213/1000 Iteration: 1925 Validation loss: 0.142528 Validation acc: 0.948333\n",
      "Epoch: 214/1000 Iteration: 1930 Train loss: 0.208387 Train acc: 0.941667\n",
      "Epoch: 214/1000 Iteration: 1935 Train loss: 0.220336 Train acc: 0.945000\n",
      "Epoch: 215/1000 Iteration: 1940 Train loss: 0.199966 Train acc: 0.940000\n",
      "Epoch: 216/1000 Iteration: 1945 Train loss: 0.171220 Train acc: 0.960000\n",
      "Epoch: 216/1000 Iteration: 1950 Train loss: 0.161315 Train acc: 0.960000\n",
      "Epoch: 216/1000 Iteration: 1950 Validation loss: 0.139880 Validation acc: 0.949444\n",
      "Epoch: 217/1000 Iteration: 1955 Train loss: 0.187220 Train acc: 0.953333\n",
      "Epoch: 217/1000 Iteration: 1960 Train loss: 0.177481 Train acc: 0.963333\n",
      "Epoch: 218/1000 Iteration: 1965 Train loss: 0.206291 Train acc: 0.945000\n",
      "Epoch: 218/1000 Iteration: 1970 Train loss: 0.163703 Train acc: 0.971667\n",
      "Epoch: 219/1000 Iteration: 1975 Train loss: 0.196462 Train acc: 0.938333\n",
      "Epoch: 219/1000 Iteration: 1975 Validation loss: 0.149535 Validation acc: 0.948889\n",
      "Epoch: 219/1000 Iteration: 1980 Train loss: 0.195625 Train acc: 0.951667\n",
      "Epoch: 220/1000 Iteration: 1985 Train loss: 0.189669 Train acc: 0.951667\n",
      "Epoch: 221/1000 Iteration: 1990 Train loss: 0.170286 Train acc: 0.951667\n",
      "Epoch: 221/1000 Iteration: 1995 Train loss: 0.162775 Train acc: 0.951667\n",
      "Epoch: 222/1000 Iteration: 2000 Train loss: 0.174824 Train acc: 0.958333\n",
      "Epoch: 222/1000 Iteration: 2000 Validation loss: 0.137597 Validation acc: 0.952222\n",
      "Epoch: 222/1000 Iteration: 2005 Train loss: 0.170955 Train acc: 0.953333\n",
      "Epoch: 223/1000 Iteration: 2010 Train loss: 0.190163 Train acc: 0.945000\n",
      "Epoch: 223/1000 Iteration: 2015 Train loss: 0.145137 Train acc: 0.968333\n",
      "Epoch: 224/1000 Iteration: 2020 Train loss: 0.189015 Train acc: 0.938333\n",
      "Epoch: 224/1000 Iteration: 2025 Train loss: 0.200620 Train acc: 0.951667\n",
      "Epoch: 224/1000 Iteration: 2025 Validation loss: 0.139340 Validation acc: 0.950556\n",
      "Epoch: 225/1000 Iteration: 2030 Train loss: 0.195619 Train acc: 0.946667\n",
      "Epoch: 226/1000 Iteration: 2035 Train loss: 0.157695 Train acc: 0.956667\n",
      "Epoch: 226/1000 Iteration: 2040 Train loss: 0.166778 Train acc: 0.955000\n",
      "Epoch: 227/1000 Iteration: 2045 Train loss: 0.182845 Train acc: 0.948333\n",
      "Epoch: 227/1000 Iteration: 2050 Train loss: 0.182282 Train acc: 0.951667\n",
      "Epoch: 227/1000 Iteration: 2050 Validation loss: 0.137733 Validation acc: 0.950000\n",
      "Epoch: 228/1000 Iteration: 2055 Train loss: 0.199747 Train acc: 0.938333\n",
      "Epoch: 228/1000 Iteration: 2060 Train loss: 0.147705 Train acc: 0.973333\n",
      "Epoch: 229/1000 Iteration: 2065 Train loss: 0.206388 Train acc: 0.930000\n",
      "Epoch: 229/1000 Iteration: 2070 Train loss: 0.217729 Train acc: 0.941667\n",
      "Epoch: 230/1000 Iteration: 2075 Train loss: 0.186574 Train acc: 0.945000\n",
      "Epoch: 230/1000 Iteration: 2075 Validation loss: 0.137772 Validation acc: 0.950000\n",
      "Epoch: 231/1000 Iteration: 2080 Train loss: 0.156023 Train acc: 0.961667\n",
      "Epoch: 231/1000 Iteration: 2085 Train loss: 0.162638 Train acc: 0.953333\n",
      "Epoch: 232/1000 Iteration: 2090 Train loss: 0.164345 Train acc: 0.953333\n",
      "Epoch: 232/1000 Iteration: 2095 Train loss: 0.176673 Train acc: 0.950000\n",
      "Epoch: 233/1000 Iteration: 2100 Train loss: 0.195268 Train acc: 0.941667\n",
      "Epoch: 233/1000 Iteration: 2100 Validation loss: 0.136495 Validation acc: 0.951111\n",
      "Epoch: 233/1000 Iteration: 2105 Train loss: 0.177841 Train acc: 0.946667\n",
      "Epoch: 234/1000 Iteration: 2110 Train loss: 0.225447 Train acc: 0.935000\n",
      "Epoch: 234/1000 Iteration: 2115 Train loss: 0.184712 Train acc: 0.948333\n",
      "Epoch: 235/1000 Iteration: 2120 Train loss: 0.185358 Train acc: 0.940000\n",
      "Epoch: 236/1000 Iteration: 2125 Train loss: 0.168097 Train acc: 0.955000\n",
      "Epoch: 236/1000 Iteration: 2125 Validation loss: 0.141096 Validation acc: 0.947222\n",
      "Epoch: 236/1000 Iteration: 2130 Train loss: 0.177184 Train acc: 0.951667\n",
      "Epoch: 237/1000 Iteration: 2135 Train loss: 0.166845 Train acc: 0.956667\n",
      "Epoch: 237/1000 Iteration: 2140 Train loss: 0.170260 Train acc: 0.960000\n",
      "Epoch: 238/1000 Iteration: 2145 Train loss: 0.185277 Train acc: 0.946667\n",
      "Epoch: 238/1000 Iteration: 2150 Train loss: 0.155241 Train acc: 0.968333\n",
      "Epoch: 238/1000 Iteration: 2150 Validation loss: 0.139233 Validation acc: 0.950556\n",
      "Epoch: 239/1000 Iteration: 2155 Train loss: 0.210757 Train acc: 0.930000\n",
      "Epoch: 239/1000 Iteration: 2160 Train loss: 0.198295 Train acc: 0.950000\n",
      "Epoch: 240/1000 Iteration: 2165 Train loss: 0.183125 Train acc: 0.953333\n",
      "Epoch: 241/1000 Iteration: 2170 Train loss: 0.167532 Train acc: 0.950000\n",
      "Epoch: 241/1000 Iteration: 2175 Train loss: 0.168538 Train acc: 0.953333\n",
      "Epoch: 241/1000 Iteration: 2175 Validation loss: 0.138195 Validation acc: 0.948889\n",
      "Epoch: 242/1000 Iteration: 2180 Train loss: 0.191288 Train acc: 0.955000\n",
      "Epoch: 242/1000 Iteration: 2185 Train loss: 0.176511 Train acc: 0.953333\n",
      "Epoch: 243/1000 Iteration: 2190 Train loss: 0.203561 Train acc: 0.938333\n",
      "Epoch: 243/1000 Iteration: 2195 Train loss: 0.139829 Train acc: 0.971667\n",
      "Epoch: 244/1000 Iteration: 2200 Train loss: 0.201083 Train acc: 0.938333\n",
      "Epoch: 244/1000 Iteration: 2200 Validation loss: 0.136111 Validation acc: 0.951667\n",
      "Epoch: 244/1000 Iteration: 2205 Train loss: 0.195940 Train acc: 0.955000\n",
      "Epoch: 245/1000 Iteration: 2210 Train loss: 0.173467 Train acc: 0.955000\n",
      "Epoch: 246/1000 Iteration: 2215 Train loss: 0.151271 Train acc: 0.961667\n",
      "Epoch: 246/1000 Iteration: 2220 Train loss: 0.155663 Train acc: 0.965000\n",
      "Epoch: 247/1000 Iteration: 2225 Train loss: 0.180449 Train acc: 0.948333\n",
      "Epoch: 247/1000 Iteration: 2225 Validation loss: 0.135910 Validation acc: 0.951111\n",
      "Epoch: 247/1000 Iteration: 2230 Train loss: 0.168597 Train acc: 0.953333\n",
      "Epoch: 248/1000 Iteration: 2235 Train loss: 0.202218 Train acc: 0.940000\n",
      "Epoch: 248/1000 Iteration: 2240 Train loss: 0.143939 Train acc: 0.968333\n",
      "Epoch: 249/1000 Iteration: 2245 Train loss: 0.196037 Train acc: 0.938333\n",
      "Epoch: 249/1000 Iteration: 2250 Train loss: 0.198136 Train acc: 0.946667\n",
      "Epoch: 249/1000 Iteration: 2250 Validation loss: 0.138315 Validation acc: 0.950556\n",
      "Epoch: 250/1000 Iteration: 2255 Train loss: 0.181122 Train acc: 0.950000\n",
      "Epoch: 251/1000 Iteration: 2260 Train loss: 0.151056 Train acc: 0.961667\n",
      "Epoch: 251/1000 Iteration: 2265 Train loss: 0.162024 Train acc: 0.956667\n",
      "Epoch: 252/1000 Iteration: 2270 Train loss: 0.165282 Train acc: 0.955000\n",
      "Epoch: 252/1000 Iteration: 2275 Train loss: 0.160369 Train acc: 0.963333\n",
      "Epoch: 252/1000 Iteration: 2275 Validation loss: 0.136255 Validation acc: 0.952778\n",
      "Epoch: 253/1000 Iteration: 2280 Train loss: 0.186121 Train acc: 0.951667\n",
      "Epoch: 253/1000 Iteration: 2285 Train loss: 0.133513 Train acc: 0.963333\n",
      "Epoch: 254/1000 Iteration: 2290 Train loss: 0.182964 Train acc: 0.941667\n",
      "Epoch: 254/1000 Iteration: 2295 Train loss: 0.176389 Train acc: 0.956667\n",
      "Epoch: 255/1000 Iteration: 2300 Train loss: 0.179434 Train acc: 0.948333\n",
      "Epoch: 255/1000 Iteration: 2300 Validation loss: 0.135779 Validation acc: 0.952222\n",
      "Epoch: 256/1000 Iteration: 2305 Train loss: 0.153295 Train acc: 0.960000\n",
      "Epoch: 256/1000 Iteration: 2310 Train loss: 0.158406 Train acc: 0.960000\n",
      "Epoch: 257/1000 Iteration: 2315 Train loss: 0.157333 Train acc: 0.961667\n",
      "Epoch: 257/1000 Iteration: 2320 Train loss: 0.165680 Train acc: 0.961667\n",
      "Epoch: 258/1000 Iteration: 2325 Train loss: 0.192793 Train acc: 0.940000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 258/1000 Iteration: 2325 Validation loss: 0.134385 Validation acc: 0.952222\n",
      "Epoch: 258/1000 Iteration: 2330 Train loss: 0.134420 Train acc: 0.968333\n",
      "Epoch: 259/1000 Iteration: 2335 Train loss: 0.187994 Train acc: 0.941667\n",
      "Epoch: 259/1000 Iteration: 2340 Train loss: 0.168133 Train acc: 0.951667\n",
      "Epoch: 260/1000 Iteration: 2345 Train loss: 0.165429 Train acc: 0.955000\n",
      "Epoch: 261/1000 Iteration: 2350 Train loss: 0.156287 Train acc: 0.960000\n",
      "Epoch: 261/1000 Iteration: 2350 Validation loss: 0.132014 Validation acc: 0.953333\n",
      "Epoch: 261/1000 Iteration: 2355 Train loss: 0.159275 Train acc: 0.950000\n",
      "Epoch: 262/1000 Iteration: 2360 Train loss: 0.178466 Train acc: 0.951667\n",
      "Epoch: 262/1000 Iteration: 2365 Train loss: 0.155750 Train acc: 0.961667\n",
      "Epoch: 263/1000 Iteration: 2370 Train loss: 0.186840 Train acc: 0.946667\n",
      "Epoch: 263/1000 Iteration: 2375 Train loss: 0.134874 Train acc: 0.965000\n",
      "Epoch: 263/1000 Iteration: 2375 Validation loss: 0.130111 Validation acc: 0.952778\n",
      "Epoch: 264/1000 Iteration: 2380 Train loss: 0.183684 Train acc: 0.941667\n",
      "Epoch: 264/1000 Iteration: 2385 Train loss: 0.166306 Train acc: 0.948333\n",
      "Epoch: 265/1000 Iteration: 2390 Train loss: 0.186488 Train acc: 0.943333\n",
      "Epoch: 266/1000 Iteration: 2395 Train loss: 0.155289 Train acc: 0.956667\n",
      "Epoch: 266/1000 Iteration: 2400 Train loss: 0.138421 Train acc: 0.961667\n",
      "Epoch: 266/1000 Iteration: 2400 Validation loss: 0.125878 Validation acc: 0.952778\n",
      "Epoch: 267/1000 Iteration: 2405 Train loss: 0.162307 Train acc: 0.963333\n",
      "Epoch: 267/1000 Iteration: 2410 Train loss: 0.177164 Train acc: 0.953333\n",
      "Epoch: 268/1000 Iteration: 2415 Train loss: 0.198366 Train acc: 0.940000\n",
      "Epoch: 268/1000 Iteration: 2420 Train loss: 0.143270 Train acc: 0.963333\n",
      "Epoch: 269/1000 Iteration: 2425 Train loss: 0.182583 Train acc: 0.943333\n",
      "Epoch: 269/1000 Iteration: 2425 Validation loss: 0.138080 Validation acc: 0.948333\n",
      "Epoch: 269/1000 Iteration: 2430 Train loss: 0.184133 Train acc: 0.946667\n",
      "Epoch: 270/1000 Iteration: 2435 Train loss: 0.172469 Train acc: 0.950000\n",
      "Epoch: 271/1000 Iteration: 2440 Train loss: 0.153855 Train acc: 0.958333\n",
      "Epoch: 271/1000 Iteration: 2445 Train loss: 0.156883 Train acc: 0.956667\n",
      "Epoch: 272/1000 Iteration: 2450 Train loss: 0.160722 Train acc: 0.961667\n",
      "Epoch: 272/1000 Iteration: 2450 Validation loss: 0.129763 Validation acc: 0.951667\n",
      "Epoch: 272/1000 Iteration: 2455 Train loss: 0.177205 Train acc: 0.950000\n",
      "Epoch: 273/1000 Iteration: 2460 Train loss: 0.192606 Train acc: 0.938333\n",
      "Epoch: 273/1000 Iteration: 2465 Train loss: 0.151918 Train acc: 0.961667\n",
      "Epoch: 274/1000 Iteration: 2470 Train loss: 0.180368 Train acc: 0.938333\n",
      "Epoch: 274/1000 Iteration: 2475 Train loss: 0.191262 Train acc: 0.946667\n",
      "Epoch: 274/1000 Iteration: 2475 Validation loss: 0.125296 Validation acc: 0.955000\n",
      "Epoch: 275/1000 Iteration: 2480 Train loss: 0.160682 Train acc: 0.961667\n",
      "Epoch: 276/1000 Iteration: 2485 Train loss: 0.152749 Train acc: 0.955000\n",
      "Epoch: 276/1000 Iteration: 2490 Train loss: 0.150801 Train acc: 0.958333\n",
      "Epoch: 277/1000 Iteration: 2495 Train loss: 0.158580 Train acc: 0.960000\n",
      "Epoch: 277/1000 Iteration: 2500 Train loss: 0.167853 Train acc: 0.951667\n",
      "Epoch: 277/1000 Iteration: 2500 Validation loss: 0.128049 Validation acc: 0.950556\n",
      "Epoch: 278/1000 Iteration: 2505 Train loss: 0.169081 Train acc: 0.945000\n",
      "Epoch: 278/1000 Iteration: 2510 Train loss: 0.135300 Train acc: 0.963333\n",
      "Epoch: 279/1000 Iteration: 2515 Train loss: 0.168790 Train acc: 0.941667\n",
      "Epoch: 279/1000 Iteration: 2520 Train loss: 0.173313 Train acc: 0.945000\n",
      "Epoch: 280/1000 Iteration: 2525 Train loss: 0.166313 Train acc: 0.956667\n",
      "Epoch: 280/1000 Iteration: 2525 Validation loss: 0.127956 Validation acc: 0.953333\n",
      "Epoch: 281/1000 Iteration: 2530 Train loss: 0.150087 Train acc: 0.955000\n",
      "Epoch: 281/1000 Iteration: 2535 Train loss: 0.152102 Train acc: 0.965000\n",
      "Epoch: 282/1000 Iteration: 2540 Train loss: 0.175625 Train acc: 0.958333\n",
      "Epoch: 282/1000 Iteration: 2545 Train loss: 0.160114 Train acc: 0.946667\n",
      "Epoch: 283/1000 Iteration: 2550 Train loss: 0.171593 Train acc: 0.938333\n",
      "Epoch: 283/1000 Iteration: 2550 Validation loss: 0.126594 Validation acc: 0.953889\n",
      "Epoch: 283/1000 Iteration: 2555 Train loss: 0.132563 Train acc: 0.971667\n",
      "Epoch: 284/1000 Iteration: 2560 Train loss: 0.179169 Train acc: 0.940000\n",
      "Epoch: 284/1000 Iteration: 2565 Train loss: 0.170675 Train acc: 0.950000\n",
      "Epoch: 285/1000 Iteration: 2570 Train loss: 0.160008 Train acc: 0.956667\n",
      "Epoch: 286/1000 Iteration: 2575 Train loss: 0.168378 Train acc: 0.948333\n",
      "Epoch: 286/1000 Iteration: 2575 Validation loss: 0.126778 Validation acc: 0.953333\n",
      "Epoch: 286/1000 Iteration: 2580 Train loss: 0.155263 Train acc: 0.960000\n",
      "Epoch: 287/1000 Iteration: 2585 Train loss: 0.152398 Train acc: 0.966667\n",
      "Epoch: 287/1000 Iteration: 2590 Train loss: 0.153020 Train acc: 0.958333\n",
      "Epoch: 288/1000 Iteration: 2595 Train loss: 0.182530 Train acc: 0.950000\n",
      "Epoch: 288/1000 Iteration: 2600 Train loss: 0.127171 Train acc: 0.966667\n",
      "Epoch: 288/1000 Iteration: 2600 Validation loss: 0.125390 Validation acc: 0.953333\n",
      "Epoch: 289/1000 Iteration: 2605 Train loss: 0.186486 Train acc: 0.943333\n",
      "Epoch: 289/1000 Iteration: 2610 Train loss: 0.168159 Train acc: 0.958333\n",
      "Epoch: 290/1000 Iteration: 2615 Train loss: 0.161332 Train acc: 0.953333\n",
      "Epoch: 291/1000 Iteration: 2620 Train loss: 0.144209 Train acc: 0.968333\n",
      "Epoch: 291/1000 Iteration: 2625 Train loss: 0.140745 Train acc: 0.960000\n",
      "Epoch: 291/1000 Iteration: 2625 Validation loss: 0.128901 Validation acc: 0.955000\n",
      "Epoch: 292/1000 Iteration: 2630 Train loss: 0.175032 Train acc: 0.951667\n",
      "Epoch: 292/1000 Iteration: 2635 Train loss: 0.169626 Train acc: 0.948333\n",
      "Epoch: 293/1000 Iteration: 2640 Train loss: 0.170492 Train acc: 0.945000\n",
      "Epoch: 293/1000 Iteration: 2645 Train loss: 0.135299 Train acc: 0.965000\n",
      "Epoch: 294/1000 Iteration: 2650 Train loss: 0.188177 Train acc: 0.930000\n",
      "Epoch: 294/1000 Iteration: 2650 Validation loss: 0.126333 Validation acc: 0.952222\n",
      "Epoch: 294/1000 Iteration: 2655 Train loss: 0.158218 Train acc: 0.956667\n",
      "Epoch: 295/1000 Iteration: 2660 Train loss: 0.165179 Train acc: 0.953333\n",
      "Epoch: 296/1000 Iteration: 2665 Train loss: 0.149429 Train acc: 0.955000\n",
      "Epoch: 296/1000 Iteration: 2670 Train loss: 0.150099 Train acc: 0.955000\n",
      "Epoch: 297/1000 Iteration: 2675 Train loss: 0.147152 Train acc: 0.955000\n",
      "Epoch: 297/1000 Iteration: 2675 Validation loss: 0.124756 Validation acc: 0.953333\n",
      "Epoch: 297/1000 Iteration: 2680 Train loss: 0.146786 Train acc: 0.958333\n",
      "Epoch: 298/1000 Iteration: 2685 Train loss: 0.171660 Train acc: 0.940000\n",
      "Epoch: 298/1000 Iteration: 2690 Train loss: 0.133560 Train acc: 0.960000\n",
      "Epoch: 299/1000 Iteration: 2695 Train loss: 0.182659 Train acc: 0.940000\n",
      "Epoch: 299/1000 Iteration: 2700 Train loss: 0.179263 Train acc: 0.946667\n",
      "Epoch: 299/1000 Iteration: 2700 Validation loss: 0.123943 Validation acc: 0.952778\n",
      "Epoch: 300/1000 Iteration: 2705 Train loss: 0.148099 Train acc: 0.956667\n",
      "Epoch: 301/1000 Iteration: 2710 Train loss: 0.147026 Train acc: 0.961667\n",
      "Epoch: 301/1000 Iteration: 2715 Train loss: 0.150154 Train acc: 0.963333\n",
      "Epoch: 302/1000 Iteration: 2720 Train loss: 0.156359 Train acc: 0.956667\n",
      "Epoch: 302/1000 Iteration: 2725 Train loss: 0.159909 Train acc: 0.955000\n",
      "Epoch: 302/1000 Iteration: 2725 Validation loss: 0.127298 Validation acc: 0.951111\n",
      "Epoch: 303/1000 Iteration: 2730 Train loss: 0.155892 Train acc: 0.951667\n",
      "Epoch: 303/1000 Iteration: 2735 Train loss: 0.124800 Train acc: 0.971667\n",
      "Epoch: 304/1000 Iteration: 2740 Train loss: 0.189317 Train acc: 0.940000\n",
      "Epoch: 304/1000 Iteration: 2745 Train loss: 0.189201 Train acc: 0.951667\n",
      "Epoch: 305/1000 Iteration: 2750 Train loss: 0.163847 Train acc: 0.950000\n",
      "Epoch: 305/1000 Iteration: 2750 Validation loss: 0.128595 Validation acc: 0.951667\n",
      "Epoch: 306/1000 Iteration: 2755 Train loss: 0.133023 Train acc: 0.965000\n",
      "Epoch: 306/1000 Iteration: 2760 Train loss: 0.154005 Train acc: 0.956667\n",
      "Epoch: 307/1000 Iteration: 2765 Train loss: 0.158679 Train acc: 0.953333\n",
      "Epoch: 307/1000 Iteration: 2770 Train loss: 0.146771 Train acc: 0.958333\n",
      "Epoch: 308/1000 Iteration: 2775 Train loss: 0.166464 Train acc: 0.941667\n",
      "Epoch: 308/1000 Iteration: 2775 Validation loss: 0.126014 Validation acc: 0.951111\n",
      "Epoch: 308/1000 Iteration: 2780 Train loss: 0.129067 Train acc: 0.963333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 309/1000 Iteration: 2785 Train loss: 0.167397 Train acc: 0.940000\n",
      "Epoch: 309/1000 Iteration: 2790 Train loss: 0.161878 Train acc: 0.960000\n",
      "Epoch: 310/1000 Iteration: 2795 Train loss: 0.155608 Train acc: 0.956667\n",
      "Epoch: 311/1000 Iteration: 2800 Train loss: 0.141170 Train acc: 0.960000\n",
      "Epoch: 311/1000 Iteration: 2800 Validation loss: 0.128967 Validation acc: 0.950556\n",
      "Epoch: 311/1000 Iteration: 2805 Train loss: 0.141619 Train acc: 0.960000\n",
      "Epoch: 312/1000 Iteration: 2810 Train loss: 0.168120 Train acc: 0.960000\n",
      "Epoch: 312/1000 Iteration: 2815 Train loss: 0.149489 Train acc: 0.961667\n",
      "Epoch: 313/1000 Iteration: 2820 Train loss: 0.169936 Train acc: 0.950000\n",
      "Epoch: 313/1000 Iteration: 2825 Train loss: 0.133147 Train acc: 0.963333\n",
      "Epoch: 313/1000 Iteration: 2825 Validation loss: 0.127184 Validation acc: 0.950556\n",
      "Epoch: 314/1000 Iteration: 2830 Train loss: 0.178640 Train acc: 0.936667\n",
      "Epoch: 314/1000 Iteration: 2835 Train loss: 0.160075 Train acc: 0.950000\n",
      "Epoch: 315/1000 Iteration: 2840 Train loss: 0.145429 Train acc: 0.951667\n",
      "Epoch: 316/1000 Iteration: 2845 Train loss: 0.149296 Train acc: 0.948333\n",
      "Epoch: 316/1000 Iteration: 2850 Train loss: 0.145507 Train acc: 0.950000\n",
      "Epoch: 316/1000 Iteration: 2850 Validation loss: 0.130327 Validation acc: 0.952222\n",
      "Epoch: 317/1000 Iteration: 2855 Train loss: 0.147484 Train acc: 0.956667\n",
      "Epoch: 317/1000 Iteration: 2860 Train loss: 0.142875 Train acc: 0.960000\n",
      "Epoch: 318/1000 Iteration: 2865 Train loss: 0.160133 Train acc: 0.956667\n",
      "Epoch: 318/1000 Iteration: 2870 Train loss: 0.123311 Train acc: 0.966667\n",
      "Epoch: 319/1000 Iteration: 2875 Train loss: 0.172714 Train acc: 0.945000\n",
      "Epoch: 319/1000 Iteration: 2875 Validation loss: 0.126868 Validation acc: 0.950000\n",
      "Epoch: 319/1000 Iteration: 2880 Train loss: 0.168051 Train acc: 0.953333\n",
      "Epoch: 320/1000 Iteration: 2885 Train loss: 0.137452 Train acc: 0.955000\n",
      "Epoch: 321/1000 Iteration: 2890 Train loss: 0.136756 Train acc: 0.948333\n",
      "Epoch: 321/1000 Iteration: 2895 Train loss: 0.135878 Train acc: 0.963333\n",
      "Epoch: 322/1000 Iteration: 2900 Train loss: 0.155115 Train acc: 0.956667\n",
      "Epoch: 322/1000 Iteration: 2900 Validation loss: 0.128695 Validation acc: 0.949444\n",
      "Epoch: 322/1000 Iteration: 2905 Train loss: 0.163703 Train acc: 0.960000\n",
      "Epoch: 323/1000 Iteration: 2910 Train loss: 0.168794 Train acc: 0.941667\n",
      "Epoch: 323/1000 Iteration: 2915 Train loss: 0.120370 Train acc: 0.968333\n",
      "Epoch: 324/1000 Iteration: 2920 Train loss: 0.182683 Train acc: 0.933333\n",
      "Epoch: 324/1000 Iteration: 2925 Train loss: 0.160597 Train acc: 0.941667\n",
      "Epoch: 324/1000 Iteration: 2925 Validation loss: 0.124092 Validation acc: 0.953889\n",
      "Epoch: 325/1000 Iteration: 2930 Train loss: 0.138712 Train acc: 0.956667\n",
      "Epoch: 326/1000 Iteration: 2935 Train loss: 0.130105 Train acc: 0.960000\n",
      "Epoch: 326/1000 Iteration: 2940 Train loss: 0.135110 Train acc: 0.955000\n",
      "Epoch: 327/1000 Iteration: 2945 Train loss: 0.154526 Train acc: 0.955000\n",
      "Epoch: 327/1000 Iteration: 2950 Train loss: 0.154219 Train acc: 0.958333\n",
      "Epoch: 327/1000 Iteration: 2950 Validation loss: 0.127172 Validation acc: 0.950000\n",
      "Epoch: 328/1000 Iteration: 2955 Train loss: 0.166855 Train acc: 0.940000\n",
      "Epoch: 328/1000 Iteration: 2960 Train loss: 0.115404 Train acc: 0.966667\n",
      "Epoch: 329/1000 Iteration: 2965 Train loss: 0.168792 Train acc: 0.936667\n",
      "Epoch: 329/1000 Iteration: 2970 Train loss: 0.169850 Train acc: 0.953333\n",
      "Epoch: 330/1000 Iteration: 2975 Train loss: 0.156928 Train acc: 0.948333\n",
      "Epoch: 330/1000 Iteration: 2975 Validation loss: 0.128926 Validation acc: 0.950000\n",
      "Epoch: 331/1000 Iteration: 2980 Train loss: 0.123453 Train acc: 0.965000\n",
      "Epoch: 331/1000 Iteration: 2985 Train loss: 0.127966 Train acc: 0.955000\n",
      "Epoch: 332/1000 Iteration: 2990 Train loss: 0.157098 Train acc: 0.956667\n",
      "Epoch: 332/1000 Iteration: 2995 Train loss: 0.140949 Train acc: 0.960000\n",
      "Epoch: 333/1000 Iteration: 3000 Train loss: 0.162175 Train acc: 0.951667\n",
      "Epoch: 333/1000 Iteration: 3000 Validation loss: 0.125913 Validation acc: 0.951111\n",
      "Epoch: 333/1000 Iteration: 3005 Train loss: 0.114912 Train acc: 0.976667\n",
      "Epoch: 334/1000 Iteration: 3010 Train loss: 0.175052 Train acc: 0.935000\n",
      "Epoch: 334/1000 Iteration: 3015 Train loss: 0.163500 Train acc: 0.951667\n",
      "Epoch: 335/1000 Iteration: 3020 Train loss: 0.139011 Train acc: 0.961667\n",
      "Epoch: 336/1000 Iteration: 3025 Train loss: 0.124413 Train acc: 0.961667\n",
      "Epoch: 336/1000 Iteration: 3025 Validation loss: 0.123386 Validation acc: 0.953889\n",
      "Epoch: 336/1000 Iteration: 3030 Train loss: 0.127680 Train acc: 0.965000\n",
      "Epoch: 337/1000 Iteration: 3035 Train loss: 0.156838 Train acc: 0.953333\n",
      "Epoch: 337/1000 Iteration: 3040 Train loss: 0.150282 Train acc: 0.958333\n",
      "Epoch: 338/1000 Iteration: 3045 Train loss: 0.164273 Train acc: 0.951667\n",
      "Epoch: 338/1000 Iteration: 3050 Train loss: 0.115584 Train acc: 0.970000\n",
      "Epoch: 338/1000 Iteration: 3050 Validation loss: 0.127072 Validation acc: 0.950000\n",
      "Epoch: 339/1000 Iteration: 3055 Train loss: 0.166781 Train acc: 0.938333\n",
      "Epoch: 339/1000 Iteration: 3060 Train loss: 0.139163 Train acc: 0.956667\n",
      "Epoch: 340/1000 Iteration: 3065 Train loss: 0.138054 Train acc: 0.963333\n",
      "Epoch: 341/1000 Iteration: 3070 Train loss: 0.134512 Train acc: 0.955000\n",
      "Epoch: 341/1000 Iteration: 3075 Train loss: 0.129283 Train acc: 0.951667\n",
      "Epoch: 341/1000 Iteration: 3075 Validation loss: 0.121526 Validation acc: 0.951667\n",
      "Epoch: 342/1000 Iteration: 3080 Train loss: 0.139749 Train acc: 0.965000\n",
      "Epoch: 342/1000 Iteration: 3085 Train loss: 0.144640 Train acc: 0.951667\n",
      "Epoch: 343/1000 Iteration: 3090 Train loss: 0.159130 Train acc: 0.943333\n",
      "Epoch: 343/1000 Iteration: 3095 Train loss: 0.121433 Train acc: 0.968333\n",
      "Epoch: 344/1000 Iteration: 3100 Train loss: 0.163786 Train acc: 0.945000\n",
      "Epoch: 344/1000 Iteration: 3100 Validation loss: 0.122819 Validation acc: 0.951111\n",
      "Epoch: 344/1000 Iteration: 3105 Train loss: 0.148548 Train acc: 0.953333\n",
      "Epoch: 345/1000 Iteration: 3110 Train loss: 0.128205 Train acc: 0.963333\n",
      "Epoch: 346/1000 Iteration: 3115 Train loss: 0.138731 Train acc: 0.956667\n",
      "Epoch: 346/1000 Iteration: 3120 Train loss: 0.120678 Train acc: 0.963333\n",
      "Epoch: 347/1000 Iteration: 3125 Train loss: 0.145338 Train acc: 0.958333\n",
      "Epoch: 347/1000 Iteration: 3125 Validation loss: 0.122804 Validation acc: 0.953333\n",
      "Epoch: 347/1000 Iteration: 3130 Train loss: 0.142202 Train acc: 0.961667\n",
      "Epoch: 348/1000 Iteration: 3135 Train loss: 0.169627 Train acc: 0.943333\n",
      "Epoch: 348/1000 Iteration: 3140 Train loss: 0.114548 Train acc: 0.971667\n",
      "Epoch: 349/1000 Iteration: 3145 Train loss: 0.164336 Train acc: 0.955000\n",
      "Epoch: 349/1000 Iteration: 3150 Train loss: 0.150199 Train acc: 0.951667\n",
      "Epoch: 349/1000 Iteration: 3150 Validation loss: 0.125511 Validation acc: 0.952222\n",
      "Epoch: 350/1000 Iteration: 3155 Train loss: 0.142762 Train acc: 0.951667\n",
      "Epoch: 351/1000 Iteration: 3160 Train loss: 0.142811 Train acc: 0.955000\n",
      "Epoch: 351/1000 Iteration: 3165 Train loss: 0.139265 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3170 Train loss: 0.136873 Train acc: 0.960000\n",
      "Epoch: 352/1000 Iteration: 3175 Train loss: 0.138331 Train acc: 0.950000\n",
      "Epoch: 352/1000 Iteration: 3175 Validation loss: 0.120616 Validation acc: 0.950000\n",
      "Epoch: 353/1000 Iteration: 3180 Train loss: 0.154673 Train acc: 0.945000\n",
      "Epoch: 353/1000 Iteration: 3185 Train loss: 0.112839 Train acc: 0.970000\n",
      "Epoch: 354/1000 Iteration: 3190 Train loss: 0.168188 Train acc: 0.938333\n",
      "Epoch: 354/1000 Iteration: 3195 Train loss: 0.154441 Train acc: 0.951667\n",
      "Epoch: 355/1000 Iteration: 3200 Train loss: 0.151207 Train acc: 0.950000\n",
      "Epoch: 355/1000 Iteration: 3200 Validation loss: 0.123535 Validation acc: 0.953333\n",
      "Epoch: 356/1000 Iteration: 3205 Train loss: 0.122175 Train acc: 0.960000\n",
      "Epoch: 356/1000 Iteration: 3210 Train loss: 0.132411 Train acc: 0.965000\n",
      "Epoch: 357/1000 Iteration: 3215 Train loss: 0.138181 Train acc: 0.965000\n",
      "Epoch: 357/1000 Iteration: 3220 Train loss: 0.139465 Train acc: 0.953333\n",
      "Epoch: 358/1000 Iteration: 3225 Train loss: 0.159596 Train acc: 0.946667\n",
      "Epoch: 358/1000 Iteration: 3225 Validation loss: 0.122523 Validation acc: 0.953889\n",
      "Epoch: 358/1000 Iteration: 3230 Train loss: 0.124107 Train acc: 0.963333\n",
      "Epoch: 359/1000 Iteration: 3235 Train loss: 0.184537 Train acc: 0.936667\n",
      "Epoch: 359/1000 Iteration: 3240 Train loss: 0.158465 Train acc: 0.945000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 360/1000 Iteration: 3245 Train loss: 0.164533 Train acc: 0.950000\n",
      "Epoch: 361/1000 Iteration: 3250 Train loss: 0.149411 Train acc: 0.951667\n",
      "Epoch: 361/1000 Iteration: 3250 Validation loss: 0.118006 Validation acc: 0.953889\n",
      "Epoch: 361/1000 Iteration: 3255 Train loss: 0.122313 Train acc: 0.968333\n",
      "Epoch: 362/1000 Iteration: 3260 Train loss: 0.129605 Train acc: 0.961667\n",
      "Epoch: 362/1000 Iteration: 3265 Train loss: 0.130428 Train acc: 0.958333\n",
      "Epoch: 363/1000 Iteration: 3270 Train loss: 0.164642 Train acc: 0.941667\n",
      "Epoch: 363/1000 Iteration: 3275 Train loss: 0.116813 Train acc: 0.963333\n",
      "Epoch: 363/1000 Iteration: 3275 Validation loss: 0.125584 Validation acc: 0.952778\n",
      "Epoch: 364/1000 Iteration: 3280 Train loss: 0.163791 Train acc: 0.946667\n",
      "Epoch: 364/1000 Iteration: 3285 Train loss: 0.148525 Train acc: 0.955000\n",
      "Epoch: 365/1000 Iteration: 3290 Train loss: 0.141962 Train acc: 0.951667\n",
      "Epoch: 366/1000 Iteration: 3295 Train loss: 0.147576 Train acc: 0.948333\n",
      "Epoch: 366/1000 Iteration: 3300 Train loss: 0.120913 Train acc: 0.965000\n",
      "Epoch: 366/1000 Iteration: 3300 Validation loss: 0.119987 Validation acc: 0.954444\n",
      "Epoch: 367/1000 Iteration: 3305 Train loss: 0.139095 Train acc: 0.958333\n",
      "Epoch: 367/1000 Iteration: 3310 Train loss: 0.139679 Train acc: 0.958333\n",
      "Epoch: 368/1000 Iteration: 3315 Train loss: 0.136639 Train acc: 0.955000\n",
      "Epoch: 368/1000 Iteration: 3320 Train loss: 0.115881 Train acc: 0.966667\n",
      "Epoch: 369/1000 Iteration: 3325 Train loss: 0.162611 Train acc: 0.926667\n",
      "Epoch: 369/1000 Iteration: 3325 Validation loss: 0.118295 Validation acc: 0.953889\n",
      "Epoch: 369/1000 Iteration: 3330 Train loss: 0.152625 Train acc: 0.950000\n",
      "Epoch: 370/1000 Iteration: 3335 Train loss: 0.154528 Train acc: 0.945000\n",
      "Epoch: 371/1000 Iteration: 3340 Train loss: 0.123485 Train acc: 0.961667\n",
      "Epoch: 371/1000 Iteration: 3345 Train loss: 0.130189 Train acc: 0.958333\n",
      "Epoch: 372/1000 Iteration: 3350 Train loss: 0.139572 Train acc: 0.960000\n",
      "Epoch: 372/1000 Iteration: 3350 Validation loss: 0.120142 Validation acc: 0.954444\n",
      "Epoch: 372/1000 Iteration: 3355 Train loss: 0.138564 Train acc: 0.955000\n",
      "Epoch: 373/1000 Iteration: 3360 Train loss: 0.146342 Train acc: 0.950000\n",
      "Epoch: 373/1000 Iteration: 3365 Train loss: 0.123465 Train acc: 0.960000\n",
      "Epoch: 374/1000 Iteration: 3370 Train loss: 0.164034 Train acc: 0.945000\n",
      "Epoch: 374/1000 Iteration: 3375 Train loss: 0.158490 Train acc: 0.951667\n",
      "Epoch: 374/1000 Iteration: 3375 Validation loss: 0.121803 Validation acc: 0.953333\n",
      "Epoch: 375/1000 Iteration: 3380 Train loss: 0.131212 Train acc: 0.965000\n",
      "Epoch: 376/1000 Iteration: 3385 Train loss: 0.136300 Train acc: 0.958333\n",
      "Epoch: 376/1000 Iteration: 3390 Train loss: 0.128823 Train acc: 0.958333\n",
      "Epoch: 377/1000 Iteration: 3395 Train loss: 0.137526 Train acc: 0.960000\n",
      "Epoch: 377/1000 Iteration: 3400 Train loss: 0.139298 Train acc: 0.961667\n",
      "Epoch: 377/1000 Iteration: 3400 Validation loss: 0.120513 Validation acc: 0.953333\n",
      "Epoch: 378/1000 Iteration: 3405 Train loss: 0.152164 Train acc: 0.941667\n",
      "Epoch: 378/1000 Iteration: 3410 Train loss: 0.111357 Train acc: 0.973333\n",
      "Epoch: 379/1000 Iteration: 3415 Train loss: 0.163666 Train acc: 0.940000\n",
      "Epoch: 379/1000 Iteration: 3420 Train loss: 0.149607 Train acc: 0.953333\n",
      "Epoch: 380/1000 Iteration: 3425 Train loss: 0.136512 Train acc: 0.953333\n",
      "Epoch: 380/1000 Iteration: 3425 Validation loss: 0.120346 Validation acc: 0.952222\n",
      "Epoch: 381/1000 Iteration: 3430 Train loss: 0.134564 Train acc: 0.960000\n",
      "Epoch: 381/1000 Iteration: 3435 Train loss: 0.125468 Train acc: 0.958333\n",
      "Epoch: 382/1000 Iteration: 3440 Train loss: 0.153195 Train acc: 0.961667\n",
      "Epoch: 382/1000 Iteration: 3445 Train loss: 0.132635 Train acc: 0.950000\n",
      "Epoch: 383/1000 Iteration: 3450 Train loss: 0.149081 Train acc: 0.953333\n",
      "Epoch: 383/1000 Iteration: 3450 Validation loss: 0.120184 Validation acc: 0.950556\n",
      "Epoch: 383/1000 Iteration: 3455 Train loss: 0.123795 Train acc: 0.965000\n",
      "Epoch: 384/1000 Iteration: 3460 Train loss: 0.153422 Train acc: 0.958333\n",
      "Epoch: 384/1000 Iteration: 3465 Train loss: 0.131731 Train acc: 0.950000\n",
      "Epoch: 385/1000 Iteration: 3470 Train loss: 0.138869 Train acc: 0.955000\n",
      "Epoch: 386/1000 Iteration: 3475 Train loss: 0.126854 Train acc: 0.963333\n",
      "Epoch: 386/1000 Iteration: 3475 Validation loss: 0.120400 Validation acc: 0.952778\n",
      "Epoch: 386/1000 Iteration: 3480 Train loss: 0.123151 Train acc: 0.963333\n",
      "Epoch: 387/1000 Iteration: 3485 Train loss: 0.142947 Train acc: 0.956667\n",
      "Epoch: 387/1000 Iteration: 3490 Train loss: 0.133078 Train acc: 0.958333\n",
      "Epoch: 388/1000 Iteration: 3495 Train loss: 0.144207 Train acc: 0.946667\n",
      "Epoch: 388/1000 Iteration: 3500 Train loss: 0.099896 Train acc: 0.973333\n",
      "Epoch: 388/1000 Iteration: 3500 Validation loss: 0.120191 Validation acc: 0.953333\n",
      "Epoch: 389/1000 Iteration: 3505 Train loss: 0.158767 Train acc: 0.940000\n",
      "Epoch: 389/1000 Iteration: 3510 Train loss: 0.152149 Train acc: 0.948333\n",
      "Epoch: 390/1000 Iteration: 3515 Train loss: 0.140598 Train acc: 0.950000\n",
      "Epoch: 391/1000 Iteration: 3520 Train loss: 0.132016 Train acc: 0.960000\n",
      "Epoch: 391/1000 Iteration: 3525 Train loss: 0.130233 Train acc: 0.960000\n",
      "Epoch: 391/1000 Iteration: 3525 Validation loss: 0.117729 Validation acc: 0.951667\n",
      "Epoch: 392/1000 Iteration: 3530 Train loss: 0.132867 Train acc: 0.956667\n",
      "Epoch: 392/1000 Iteration: 3535 Train loss: 0.114261 Train acc: 0.968333\n",
      "Epoch: 393/1000 Iteration: 3540 Train loss: 0.149501 Train acc: 0.943333\n",
      "Epoch: 393/1000 Iteration: 3545 Train loss: 0.111324 Train acc: 0.968333\n",
      "Epoch: 394/1000 Iteration: 3550 Train loss: 0.157993 Train acc: 0.941667\n",
      "Epoch: 394/1000 Iteration: 3550 Validation loss: 0.117454 Validation acc: 0.951111\n",
      "Epoch: 394/1000 Iteration: 3555 Train loss: 0.140933 Train acc: 0.948333\n",
      "Epoch: 395/1000 Iteration: 3560 Train loss: 0.133781 Train acc: 0.953333\n",
      "Epoch: 396/1000 Iteration: 3565 Train loss: 0.126286 Train acc: 0.963333\n",
      "Epoch: 396/1000 Iteration: 3570 Train loss: 0.114103 Train acc: 0.960000\n",
      "Epoch: 397/1000 Iteration: 3575 Train loss: 0.140340 Train acc: 0.958333\n",
      "Epoch: 397/1000 Iteration: 3575 Validation loss: 0.116500 Validation acc: 0.952778\n",
      "Epoch: 397/1000 Iteration: 3580 Train loss: 0.137250 Train acc: 0.960000\n",
      "Epoch: 398/1000 Iteration: 3585 Train loss: 0.149438 Train acc: 0.945000\n",
      "Epoch: 398/1000 Iteration: 3590 Train loss: 0.110304 Train acc: 0.966667\n",
      "Epoch: 399/1000 Iteration: 3595 Train loss: 0.170539 Train acc: 0.931667\n",
      "Epoch: 399/1000 Iteration: 3600 Train loss: 0.151346 Train acc: 0.956667\n",
      "Epoch: 399/1000 Iteration: 3600 Validation loss: 0.125912 Validation acc: 0.950556\n",
      "Epoch: 400/1000 Iteration: 3605 Train loss: 0.124427 Train acc: 0.961667\n",
      "Epoch: 401/1000 Iteration: 3610 Train loss: 0.125528 Train acc: 0.966667\n",
      "Epoch: 401/1000 Iteration: 3615 Train loss: 0.120214 Train acc: 0.960000\n",
      "Epoch: 402/1000 Iteration: 3620 Train loss: 0.128956 Train acc: 0.963333\n",
      "Epoch: 402/1000 Iteration: 3625 Train loss: 0.133041 Train acc: 0.953333\n",
      "Epoch: 402/1000 Iteration: 3625 Validation loss: 0.121950 Validation acc: 0.952222\n",
      "Epoch: 403/1000 Iteration: 3630 Train loss: 0.157693 Train acc: 0.935000\n",
      "Epoch: 403/1000 Iteration: 3635 Train loss: 0.097086 Train acc: 0.973333\n",
      "Epoch: 404/1000 Iteration: 3640 Train loss: 0.161844 Train acc: 0.946667\n",
      "Epoch: 404/1000 Iteration: 3645 Train loss: 0.141995 Train acc: 0.948333\n",
      "Epoch: 405/1000 Iteration: 3650 Train loss: 0.120215 Train acc: 0.956667\n",
      "Epoch: 405/1000 Iteration: 3650 Validation loss: 0.119235 Validation acc: 0.950556\n",
      "Epoch: 406/1000 Iteration: 3655 Train loss: 0.130835 Train acc: 0.961667\n",
      "Epoch: 406/1000 Iteration: 3660 Train loss: 0.113373 Train acc: 0.966667\n",
      "Epoch: 407/1000 Iteration: 3665 Train loss: 0.122654 Train acc: 0.961667\n",
      "Epoch: 407/1000 Iteration: 3670 Train loss: 0.126016 Train acc: 0.958333\n",
      "Epoch: 408/1000 Iteration: 3675 Train loss: 0.152294 Train acc: 0.941667\n",
      "Epoch: 408/1000 Iteration: 3675 Validation loss: 0.120293 Validation acc: 0.952778\n",
      "Epoch: 408/1000 Iteration: 3680 Train loss: 0.108055 Train acc: 0.965000\n",
      "Epoch: 409/1000 Iteration: 3685 Train loss: 0.156204 Train acc: 0.955000\n",
      "Epoch: 409/1000 Iteration: 3690 Train loss: 0.139694 Train acc: 0.945000\n",
      "Epoch: 410/1000 Iteration: 3695 Train loss: 0.129078 Train acc: 0.965000\n",
      "Epoch: 411/1000 Iteration: 3700 Train loss: 0.122940 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 411/1000 Iteration: 3700 Validation loss: 0.121412 Validation acc: 0.949444\n",
      "Epoch: 411/1000 Iteration: 3705 Train loss: 0.116845 Train acc: 0.963333\n",
      "Epoch: 412/1000 Iteration: 3710 Train loss: 0.132652 Train acc: 0.956667\n",
      "Epoch: 412/1000 Iteration: 3715 Train loss: 0.134806 Train acc: 0.958333\n",
      "Epoch: 413/1000 Iteration: 3720 Train loss: 0.143913 Train acc: 0.960000\n",
      "Epoch: 413/1000 Iteration: 3725 Train loss: 0.112489 Train acc: 0.968333\n",
      "Epoch: 413/1000 Iteration: 3725 Validation loss: 0.123230 Validation acc: 0.948889\n",
      "Epoch: 414/1000 Iteration: 3730 Train loss: 0.149369 Train acc: 0.938333\n",
      "Epoch: 414/1000 Iteration: 3735 Train loss: 0.131158 Train acc: 0.956667\n",
      "Epoch: 415/1000 Iteration: 3740 Train loss: 0.147286 Train acc: 0.950000\n",
      "Epoch: 416/1000 Iteration: 3745 Train loss: 0.121184 Train acc: 0.963333\n",
      "Epoch: 416/1000 Iteration: 3750 Train loss: 0.104681 Train acc: 0.968333\n",
      "Epoch: 416/1000 Iteration: 3750 Validation loss: 0.126035 Validation acc: 0.947778\n",
      "Epoch: 417/1000 Iteration: 3755 Train loss: 0.128219 Train acc: 0.960000\n",
      "Epoch: 417/1000 Iteration: 3760 Train loss: 0.118928 Train acc: 0.953333\n",
      "Epoch: 418/1000 Iteration: 3765 Train loss: 0.128223 Train acc: 0.955000\n",
      "Epoch: 418/1000 Iteration: 3770 Train loss: 0.105642 Train acc: 0.975000\n",
      "Epoch: 419/1000 Iteration: 3775 Train loss: 0.152994 Train acc: 0.941667\n",
      "Epoch: 419/1000 Iteration: 3775 Validation loss: 0.118794 Validation acc: 0.950556\n",
      "Epoch: 419/1000 Iteration: 3780 Train loss: 0.135299 Train acc: 0.951667\n",
      "Epoch: 420/1000 Iteration: 3785 Train loss: 0.125848 Train acc: 0.966667\n",
      "Epoch: 421/1000 Iteration: 3790 Train loss: 0.125788 Train acc: 0.958333\n",
      "Epoch: 421/1000 Iteration: 3795 Train loss: 0.115827 Train acc: 0.958333\n",
      "Epoch: 422/1000 Iteration: 3800 Train loss: 0.139757 Train acc: 0.966667\n",
      "Epoch: 422/1000 Iteration: 3800 Validation loss: 0.117289 Validation acc: 0.953333\n",
      "Epoch: 422/1000 Iteration: 3805 Train loss: 0.115897 Train acc: 0.961667\n",
      "Epoch: 423/1000 Iteration: 3810 Train loss: 0.151420 Train acc: 0.945000\n",
      "Epoch: 423/1000 Iteration: 3815 Train loss: 0.105853 Train acc: 0.968333\n",
      "Epoch: 424/1000 Iteration: 3820 Train loss: 0.158592 Train acc: 0.943333\n",
      "Epoch: 424/1000 Iteration: 3825 Train loss: 0.122158 Train acc: 0.955000\n",
      "Epoch: 424/1000 Iteration: 3825 Validation loss: 0.117566 Validation acc: 0.951667\n",
      "Epoch: 425/1000 Iteration: 3830 Train loss: 0.133023 Train acc: 0.953333\n",
      "Epoch: 426/1000 Iteration: 3835 Train loss: 0.135874 Train acc: 0.960000\n",
      "Epoch: 426/1000 Iteration: 3840 Train loss: 0.126028 Train acc: 0.951667\n",
      "Epoch: 427/1000 Iteration: 3845 Train loss: 0.125327 Train acc: 0.965000\n",
      "Epoch: 427/1000 Iteration: 3850 Train loss: 0.129686 Train acc: 0.955000\n",
      "Epoch: 427/1000 Iteration: 3850 Validation loss: 0.120654 Validation acc: 0.950556\n",
      "Epoch: 428/1000 Iteration: 3855 Train loss: 0.142525 Train acc: 0.951667\n",
      "Epoch: 428/1000 Iteration: 3860 Train loss: 0.103005 Train acc: 0.973333\n",
      "Epoch: 429/1000 Iteration: 3865 Train loss: 0.144769 Train acc: 0.941667\n",
      "Epoch: 429/1000 Iteration: 3870 Train loss: 0.131925 Train acc: 0.955000\n",
      "Epoch: 430/1000 Iteration: 3875 Train loss: 0.124383 Train acc: 0.958333\n",
      "Epoch: 430/1000 Iteration: 3875 Validation loss: 0.117575 Validation acc: 0.951667\n",
      "Epoch: 431/1000 Iteration: 3880 Train loss: 0.127693 Train acc: 0.958333\n",
      "Epoch: 431/1000 Iteration: 3885 Train loss: 0.106398 Train acc: 0.963333\n",
      "Epoch: 432/1000 Iteration: 3890 Train loss: 0.138463 Train acc: 0.958333\n",
      "Epoch: 432/1000 Iteration: 3895 Train loss: 0.149044 Train acc: 0.948333\n",
      "Epoch: 433/1000 Iteration: 3900 Train loss: 0.150088 Train acc: 0.945000\n",
      "Epoch: 433/1000 Iteration: 3900 Validation loss: 0.116489 Validation acc: 0.952778\n",
      "Epoch: 433/1000 Iteration: 3905 Train loss: 0.118132 Train acc: 0.956667\n",
      "Epoch: 434/1000 Iteration: 3910 Train loss: 0.142625 Train acc: 0.951667\n",
      "Epoch: 434/1000 Iteration: 3915 Train loss: 0.129665 Train acc: 0.958333\n",
      "Epoch: 435/1000 Iteration: 3920 Train loss: 0.130856 Train acc: 0.958333\n",
      "Epoch: 436/1000 Iteration: 3925 Train loss: 0.122608 Train acc: 0.960000\n",
      "Epoch: 436/1000 Iteration: 3925 Validation loss: 0.117896 Validation acc: 0.951111\n",
      "Epoch: 436/1000 Iteration: 3930 Train loss: 0.115155 Train acc: 0.960000\n",
      "Epoch: 437/1000 Iteration: 3935 Train loss: 0.137660 Train acc: 0.960000\n",
      "Epoch: 437/1000 Iteration: 3940 Train loss: 0.128960 Train acc: 0.961667\n",
      "Epoch: 438/1000 Iteration: 3945 Train loss: 0.149133 Train acc: 0.943333\n",
      "Epoch: 438/1000 Iteration: 3950 Train loss: 0.099359 Train acc: 0.970000\n",
      "Epoch: 438/1000 Iteration: 3950 Validation loss: 0.117427 Validation acc: 0.951667\n",
      "Epoch: 439/1000 Iteration: 3955 Train loss: 0.152149 Train acc: 0.950000\n",
      "Epoch: 439/1000 Iteration: 3960 Train loss: 0.141566 Train acc: 0.956667\n",
      "Epoch: 440/1000 Iteration: 3965 Train loss: 0.124703 Train acc: 0.953333\n",
      "Epoch: 441/1000 Iteration: 3970 Train loss: 0.122117 Train acc: 0.963333\n",
      "Epoch: 441/1000 Iteration: 3975 Train loss: 0.110475 Train acc: 0.958333\n",
      "Epoch: 441/1000 Iteration: 3975 Validation loss: 0.124475 Validation acc: 0.947778\n",
      "Epoch: 442/1000 Iteration: 3980 Train loss: 0.140497 Train acc: 0.958333\n",
      "Epoch: 442/1000 Iteration: 3985 Train loss: 0.124566 Train acc: 0.963333\n",
      "Epoch: 443/1000 Iteration: 3990 Train loss: 0.156577 Train acc: 0.941667\n",
      "Epoch: 443/1000 Iteration: 3995 Train loss: 0.101051 Train acc: 0.978333\n",
      "Epoch: 444/1000 Iteration: 4000 Train loss: 0.131786 Train acc: 0.945000\n",
      "Epoch: 444/1000 Iteration: 4000 Validation loss: 0.126982 Validation acc: 0.947778\n",
      "Epoch: 444/1000 Iteration: 4005 Train loss: 0.156357 Train acc: 0.941667\n",
      "Epoch: 445/1000 Iteration: 4010 Train loss: 0.128580 Train acc: 0.963333\n",
      "Epoch: 446/1000 Iteration: 4015 Train loss: 0.134602 Train acc: 0.961667\n",
      "Epoch: 446/1000 Iteration: 4020 Train loss: 0.118684 Train acc: 0.950000\n",
      "Epoch: 447/1000 Iteration: 4025 Train loss: 0.131263 Train acc: 0.956667\n",
      "Epoch: 447/1000 Iteration: 4025 Validation loss: 0.117054 Validation acc: 0.951667\n",
      "Epoch: 447/1000 Iteration: 4030 Train loss: 0.127781 Train acc: 0.958333\n",
      "Epoch: 448/1000 Iteration: 4035 Train loss: 0.144332 Train acc: 0.955000\n",
      "Epoch: 448/1000 Iteration: 4040 Train loss: 0.097718 Train acc: 0.976667\n",
      "Epoch: 449/1000 Iteration: 4045 Train loss: 0.131743 Train acc: 0.945000\n",
      "Epoch: 449/1000 Iteration: 4050 Train loss: 0.131200 Train acc: 0.956667\n",
      "Epoch: 449/1000 Iteration: 4050 Validation loss: 0.114851 Validation acc: 0.954444\n",
      "Epoch: 450/1000 Iteration: 4055 Train loss: 0.131336 Train acc: 0.960000\n",
      "Epoch: 451/1000 Iteration: 4060 Train loss: 0.133451 Train acc: 0.956667\n",
      "Epoch: 451/1000 Iteration: 4065 Train loss: 0.111005 Train acc: 0.965000\n",
      "Epoch: 452/1000 Iteration: 4070 Train loss: 0.134807 Train acc: 0.963333\n",
      "Epoch: 452/1000 Iteration: 4075 Train loss: 0.122337 Train acc: 0.955000\n",
      "Epoch: 452/1000 Iteration: 4075 Validation loss: 0.118996 Validation acc: 0.951111\n",
      "Epoch: 453/1000 Iteration: 4080 Train loss: 0.110186 Train acc: 0.966667\n",
      "Epoch: 453/1000 Iteration: 4085 Train loss: 0.089861 Train acc: 0.973333\n",
      "Epoch: 454/1000 Iteration: 4090 Train loss: 0.155091 Train acc: 0.935000\n",
      "Epoch: 454/1000 Iteration: 4095 Train loss: 0.139368 Train acc: 0.953333\n",
      "Epoch: 455/1000 Iteration: 4100 Train loss: 0.125032 Train acc: 0.961667\n",
      "Epoch: 455/1000 Iteration: 4100 Validation loss: 0.120084 Validation acc: 0.952222\n",
      "Epoch: 456/1000 Iteration: 4105 Train loss: 0.122029 Train acc: 0.956667\n",
      "Epoch: 456/1000 Iteration: 4110 Train loss: 0.107941 Train acc: 0.965000\n",
      "Epoch: 457/1000 Iteration: 4115 Train loss: 0.127979 Train acc: 0.966667\n",
      "Epoch: 457/1000 Iteration: 4120 Train loss: 0.125499 Train acc: 0.953333\n",
      "Epoch: 458/1000 Iteration: 4125 Train loss: 0.145485 Train acc: 0.948333\n",
      "Epoch: 458/1000 Iteration: 4125 Validation loss: 0.113719 Validation acc: 0.949444\n",
      "Epoch: 458/1000 Iteration: 4130 Train loss: 0.095238 Train acc: 0.970000\n",
      "Epoch: 459/1000 Iteration: 4135 Train loss: 0.166309 Train acc: 0.940000\n",
      "Epoch: 459/1000 Iteration: 4140 Train loss: 0.142200 Train acc: 0.953333\n",
      "Epoch: 460/1000 Iteration: 4145 Train loss: 0.124347 Train acc: 0.958333\n",
      "Epoch: 461/1000 Iteration: 4150 Train loss: 0.105166 Train acc: 0.960000\n",
      "Epoch: 461/1000 Iteration: 4150 Validation loss: 0.118578 Validation acc: 0.952222\n",
      "Epoch: 461/1000 Iteration: 4155 Train loss: 0.106797 Train acc: 0.960000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 462/1000 Iteration: 4160 Train loss: 0.128983 Train acc: 0.966667\n",
      "Epoch: 462/1000 Iteration: 4165 Train loss: 0.104550 Train acc: 0.963333\n",
      "Epoch: 463/1000 Iteration: 4170 Train loss: 0.147706 Train acc: 0.943333\n",
      "Epoch: 463/1000 Iteration: 4175 Train loss: 0.093288 Train acc: 0.971667\n",
      "Epoch: 463/1000 Iteration: 4175 Validation loss: 0.122556 Validation acc: 0.949444\n",
      "Epoch: 464/1000 Iteration: 4180 Train loss: 0.145085 Train acc: 0.941667\n",
      "Epoch: 464/1000 Iteration: 4185 Train loss: 0.126479 Train acc: 0.961667\n",
      "Epoch: 465/1000 Iteration: 4190 Train loss: 0.127999 Train acc: 0.946667\n",
      "Epoch: 466/1000 Iteration: 4195 Train loss: 0.104542 Train acc: 0.966667\n",
      "Epoch: 466/1000 Iteration: 4200 Train loss: 0.102666 Train acc: 0.971667\n",
      "Epoch: 466/1000 Iteration: 4200 Validation loss: 0.117835 Validation acc: 0.951111\n",
      "Epoch: 467/1000 Iteration: 4205 Train loss: 0.123412 Train acc: 0.961667\n",
      "Epoch: 467/1000 Iteration: 4210 Train loss: 0.131168 Train acc: 0.953333\n",
      "Epoch: 468/1000 Iteration: 4215 Train loss: 0.121706 Train acc: 0.961667\n",
      "Epoch: 468/1000 Iteration: 4220 Train loss: 0.101693 Train acc: 0.968333\n",
      "Epoch: 469/1000 Iteration: 4225 Train loss: 0.153782 Train acc: 0.945000\n",
      "Epoch: 469/1000 Iteration: 4225 Validation loss: 0.121283 Validation acc: 0.951111\n",
      "Epoch: 469/1000 Iteration: 4230 Train loss: 0.131291 Train acc: 0.955000\n",
      "Epoch: 470/1000 Iteration: 4235 Train loss: 0.110119 Train acc: 0.960000\n",
      "Epoch: 471/1000 Iteration: 4240 Train loss: 0.117816 Train acc: 0.966667\n",
      "Epoch: 471/1000 Iteration: 4245 Train loss: 0.104881 Train acc: 0.956667\n",
      "Epoch: 472/1000 Iteration: 4250 Train loss: 0.117074 Train acc: 0.958333\n",
      "Epoch: 472/1000 Iteration: 4250 Validation loss: 0.120228 Validation acc: 0.948333\n",
      "Epoch: 472/1000 Iteration: 4255 Train loss: 0.106929 Train acc: 0.966667\n",
      "Epoch: 473/1000 Iteration: 4260 Train loss: 0.141606 Train acc: 0.948333\n",
      "Epoch: 473/1000 Iteration: 4265 Train loss: 0.098924 Train acc: 0.965000\n",
      "Epoch: 474/1000 Iteration: 4270 Train loss: 0.136239 Train acc: 0.938333\n",
      "Epoch: 474/1000 Iteration: 4275 Train loss: 0.125028 Train acc: 0.955000\n",
      "Epoch: 474/1000 Iteration: 4275 Validation loss: 0.117478 Validation acc: 0.948889\n",
      "Epoch: 475/1000 Iteration: 4280 Train loss: 0.121104 Train acc: 0.955000\n",
      "Epoch: 476/1000 Iteration: 4285 Train loss: 0.126213 Train acc: 0.958333\n",
      "Epoch: 476/1000 Iteration: 4290 Train loss: 0.109346 Train acc: 0.966667\n",
      "Epoch: 477/1000 Iteration: 4295 Train loss: 0.121240 Train acc: 0.961667\n",
      "Epoch: 477/1000 Iteration: 4300 Train loss: 0.123363 Train acc: 0.953333\n",
      "Epoch: 477/1000 Iteration: 4300 Validation loss: 0.114238 Validation acc: 0.950556\n",
      "Epoch: 478/1000 Iteration: 4305 Train loss: 0.148125 Train acc: 0.945000\n",
      "Epoch: 478/1000 Iteration: 4310 Train loss: 0.092468 Train acc: 0.973333\n",
      "Epoch: 479/1000 Iteration: 4315 Train loss: 0.131460 Train acc: 0.941667\n",
      "Epoch: 479/1000 Iteration: 4320 Train loss: 0.136366 Train acc: 0.951667\n",
      "Epoch: 480/1000 Iteration: 4325 Train loss: 0.122502 Train acc: 0.961667\n",
      "Epoch: 480/1000 Iteration: 4325 Validation loss: 0.119121 Validation acc: 0.951111\n",
      "Epoch: 481/1000 Iteration: 4330 Train loss: 0.116115 Train acc: 0.965000\n",
      "Epoch: 481/1000 Iteration: 4335 Train loss: 0.098681 Train acc: 0.971667\n",
      "Epoch: 482/1000 Iteration: 4340 Train loss: 0.118395 Train acc: 0.960000\n",
      "Epoch: 482/1000 Iteration: 4345 Train loss: 0.122284 Train acc: 0.960000\n",
      "Epoch: 483/1000 Iteration: 4350 Train loss: 0.124262 Train acc: 0.961667\n",
      "Epoch: 483/1000 Iteration: 4350 Validation loss: 0.114339 Validation acc: 0.951667\n",
      "Epoch: 483/1000 Iteration: 4355 Train loss: 0.092134 Train acc: 0.983333\n",
      "Epoch: 484/1000 Iteration: 4360 Train loss: 0.148103 Train acc: 0.940000\n",
      "Epoch: 484/1000 Iteration: 4365 Train loss: 0.112722 Train acc: 0.965000\n",
      "Epoch: 485/1000 Iteration: 4370 Train loss: 0.116442 Train acc: 0.963333\n",
      "Epoch: 486/1000 Iteration: 4375 Train loss: 0.104281 Train acc: 0.970000\n",
      "Epoch: 486/1000 Iteration: 4375 Validation loss: 0.116828 Validation acc: 0.950556\n",
      "Epoch: 486/1000 Iteration: 4380 Train loss: 0.105100 Train acc: 0.968333\n",
      "Epoch: 487/1000 Iteration: 4385 Train loss: 0.128702 Train acc: 0.963333\n",
      "Epoch: 487/1000 Iteration: 4390 Train loss: 0.116810 Train acc: 0.970000\n",
      "Epoch: 488/1000 Iteration: 4395 Train loss: 0.123557 Train acc: 0.953333\n",
      "Epoch: 488/1000 Iteration: 4400 Train loss: 0.089696 Train acc: 0.970000\n",
      "Epoch: 488/1000 Iteration: 4400 Validation loss: 0.117019 Validation acc: 0.951667\n",
      "Epoch: 489/1000 Iteration: 4405 Train loss: 0.140545 Train acc: 0.946667\n",
      "Epoch: 489/1000 Iteration: 4410 Train loss: 0.126695 Train acc: 0.960000\n",
      "Epoch: 490/1000 Iteration: 4415 Train loss: 0.122588 Train acc: 0.958333\n",
      "Epoch: 491/1000 Iteration: 4420 Train loss: 0.109265 Train acc: 0.956667\n",
      "Epoch: 491/1000 Iteration: 4425 Train loss: 0.101725 Train acc: 0.961667\n",
      "Epoch: 491/1000 Iteration: 4425 Validation loss: 0.116478 Validation acc: 0.952222\n",
      "Epoch: 492/1000 Iteration: 4430 Train loss: 0.118386 Train acc: 0.960000\n",
      "Epoch: 492/1000 Iteration: 4435 Train loss: 0.105125 Train acc: 0.966667\n",
      "Epoch: 493/1000 Iteration: 4440 Train loss: 0.135220 Train acc: 0.948333\n",
      "Epoch: 493/1000 Iteration: 4445 Train loss: 0.090779 Train acc: 0.965000\n",
      "Epoch: 494/1000 Iteration: 4450 Train loss: 0.137884 Train acc: 0.940000\n",
      "Epoch: 494/1000 Iteration: 4450 Validation loss: 0.118568 Validation acc: 0.950000\n",
      "Epoch: 494/1000 Iteration: 4455 Train loss: 0.116604 Train acc: 0.965000\n",
      "Epoch: 495/1000 Iteration: 4460 Train loss: 0.164567 Train acc: 0.950000\n",
      "Epoch: 496/1000 Iteration: 4465 Train loss: 0.142069 Train acc: 0.956667\n",
      "Epoch: 496/1000 Iteration: 4470 Train loss: 0.107046 Train acc: 0.963333\n",
      "Epoch: 497/1000 Iteration: 4475 Train loss: 0.131191 Train acc: 0.960000\n",
      "Epoch: 497/1000 Iteration: 4475 Validation loss: 0.117128 Validation acc: 0.950556\n",
      "Epoch: 497/1000 Iteration: 4480 Train loss: 0.107056 Train acc: 0.968333\n",
      "Epoch: 498/1000 Iteration: 4485 Train loss: 0.147955 Train acc: 0.941667\n",
      "Epoch: 498/1000 Iteration: 4490 Train loss: 0.100285 Train acc: 0.966667\n",
      "Epoch: 499/1000 Iteration: 4495 Train loss: 0.166831 Train acc: 0.921667\n",
      "Epoch: 499/1000 Iteration: 4500 Train loss: 0.132215 Train acc: 0.955000\n",
      "Epoch: 499/1000 Iteration: 4500 Validation loss: 0.125302 Validation acc: 0.948889\n",
      "Epoch: 500/1000 Iteration: 4505 Train loss: 0.117393 Train acc: 0.965000\n",
      "Epoch: 501/1000 Iteration: 4510 Train loss: 0.124188 Train acc: 0.960000\n",
      "Epoch: 501/1000 Iteration: 4515 Train loss: 0.100866 Train acc: 0.971667\n",
      "Epoch: 502/1000 Iteration: 4520 Train loss: 0.118199 Train acc: 0.966667\n",
      "Epoch: 502/1000 Iteration: 4525 Train loss: 0.119582 Train acc: 0.961667\n",
      "Epoch: 502/1000 Iteration: 4525 Validation loss: 0.116117 Validation acc: 0.951111\n",
      "Epoch: 503/1000 Iteration: 4530 Train loss: 0.126035 Train acc: 0.946667\n",
      "Epoch: 503/1000 Iteration: 4535 Train loss: 0.102560 Train acc: 0.973333\n",
      "Epoch: 504/1000 Iteration: 4540 Train loss: 0.140360 Train acc: 0.933333\n",
      "Epoch: 504/1000 Iteration: 4545 Train loss: 0.138308 Train acc: 0.943333\n",
      "Epoch: 505/1000 Iteration: 4550 Train loss: 0.128779 Train acc: 0.953333\n",
      "Epoch: 505/1000 Iteration: 4550 Validation loss: 0.117312 Validation acc: 0.951111\n",
      "Epoch: 506/1000 Iteration: 4555 Train loss: 0.116018 Train acc: 0.955000\n",
      "Epoch: 506/1000 Iteration: 4560 Train loss: 0.114763 Train acc: 0.958333\n",
      "Epoch: 507/1000 Iteration: 4565 Train loss: 0.111989 Train acc: 0.955000\n",
      "Epoch: 507/1000 Iteration: 4570 Train loss: 0.111872 Train acc: 0.953333\n",
      "Epoch: 508/1000 Iteration: 4575 Train loss: 0.130212 Train acc: 0.950000\n",
      "Epoch: 508/1000 Iteration: 4575 Validation loss: 0.117115 Validation acc: 0.951111\n",
      "Epoch: 508/1000 Iteration: 4580 Train loss: 0.094137 Train acc: 0.973333\n",
      "Epoch: 509/1000 Iteration: 4585 Train loss: 0.133814 Train acc: 0.938333\n",
      "Epoch: 509/1000 Iteration: 4590 Train loss: 0.117352 Train acc: 0.958333\n",
      "Epoch: 510/1000 Iteration: 4595 Train loss: 0.107879 Train acc: 0.966667\n",
      "Epoch: 511/1000 Iteration: 4600 Train loss: 0.124255 Train acc: 0.961667\n",
      "Epoch: 511/1000 Iteration: 4600 Validation loss: 0.118060 Validation acc: 0.950556\n",
      "Epoch: 511/1000 Iteration: 4605 Train loss: 0.103993 Train acc: 0.965000\n",
      "Epoch: 512/1000 Iteration: 4610 Train loss: 0.124607 Train acc: 0.963333\n",
      "Epoch: 512/1000 Iteration: 4615 Train loss: 0.122893 Train acc: 0.953333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 513/1000 Iteration: 4620 Train loss: 0.112094 Train acc: 0.956667\n",
      "Epoch: 513/1000 Iteration: 4625 Train loss: 0.096716 Train acc: 0.973333\n",
      "Epoch: 513/1000 Iteration: 4625 Validation loss: 0.117847 Validation acc: 0.950556\n",
      "Epoch: 514/1000 Iteration: 4630 Train loss: 0.137651 Train acc: 0.941667\n",
      "Epoch: 514/1000 Iteration: 4635 Train loss: 0.125612 Train acc: 0.960000\n",
      "Epoch: 515/1000 Iteration: 4640 Train loss: 0.117233 Train acc: 0.961667\n",
      "Epoch: 516/1000 Iteration: 4645 Train loss: 0.124202 Train acc: 0.958333\n",
      "Epoch: 516/1000 Iteration: 4650 Train loss: 0.099058 Train acc: 0.963333\n",
      "Epoch: 516/1000 Iteration: 4650 Validation loss: 0.120664 Validation acc: 0.950000\n",
      "Epoch: 517/1000 Iteration: 4655 Train loss: 0.110109 Train acc: 0.966667\n",
      "Epoch: 517/1000 Iteration: 4660 Train loss: 0.110542 Train acc: 0.960000\n",
      "Epoch: 518/1000 Iteration: 4665 Train loss: 0.123788 Train acc: 0.951667\n",
      "Epoch: 518/1000 Iteration: 4670 Train loss: 0.085948 Train acc: 0.980000\n",
      "Epoch: 519/1000 Iteration: 4675 Train loss: 0.129251 Train acc: 0.950000\n",
      "Epoch: 519/1000 Iteration: 4675 Validation loss: 0.116704 Validation acc: 0.950556\n",
      "Epoch: 519/1000 Iteration: 4680 Train loss: 0.118938 Train acc: 0.955000\n",
      "Epoch: 520/1000 Iteration: 4685 Train loss: 0.135318 Train acc: 0.958333\n",
      "Epoch: 521/1000 Iteration: 4690 Train loss: 0.110451 Train acc: 0.961667\n",
      "Epoch: 521/1000 Iteration: 4695 Train loss: 0.110033 Train acc: 0.961667\n",
      "Epoch: 522/1000 Iteration: 4700 Train loss: 0.121124 Train acc: 0.960000\n",
      "Epoch: 522/1000 Iteration: 4700 Validation loss: 0.113730 Validation acc: 0.953889\n",
      "Epoch: 522/1000 Iteration: 4705 Train loss: 0.105277 Train acc: 0.966667\n",
      "Epoch: 523/1000 Iteration: 4710 Train loss: 0.145346 Train acc: 0.945000\n",
      "Epoch: 523/1000 Iteration: 4715 Train loss: 0.080746 Train acc: 0.978333\n",
      "Epoch: 524/1000 Iteration: 4720 Train loss: 0.140914 Train acc: 0.945000\n",
      "Epoch: 524/1000 Iteration: 4725 Train loss: 0.139400 Train acc: 0.946667\n",
      "Epoch: 524/1000 Iteration: 4725 Validation loss: 0.131248 Validation acc: 0.948889\n",
      "Epoch: 525/1000 Iteration: 4730 Train loss: 0.122092 Train acc: 0.958333\n",
      "Epoch: 526/1000 Iteration: 4735 Train loss: 0.105628 Train acc: 0.961667\n",
      "Epoch: 526/1000 Iteration: 4740 Train loss: 0.110819 Train acc: 0.960000\n",
      "Epoch: 527/1000 Iteration: 4745 Train loss: 0.102738 Train acc: 0.963333\n",
      "Epoch: 527/1000 Iteration: 4750 Train loss: 0.117899 Train acc: 0.955000\n",
      "Epoch: 527/1000 Iteration: 4750 Validation loss: 0.116020 Validation acc: 0.955000\n",
      "Epoch: 528/1000 Iteration: 4755 Train loss: 0.123415 Train acc: 0.953333\n",
      "Epoch: 528/1000 Iteration: 4760 Train loss: 0.100566 Train acc: 0.970000\n",
      "Epoch: 529/1000 Iteration: 4765 Train loss: 0.137655 Train acc: 0.945000\n",
      "Epoch: 529/1000 Iteration: 4770 Train loss: 0.138799 Train acc: 0.948333\n",
      "Epoch: 530/1000 Iteration: 4775 Train loss: 0.115156 Train acc: 0.960000\n",
      "Epoch: 530/1000 Iteration: 4775 Validation loss: 0.124614 Validation acc: 0.950556\n",
      "Epoch: 531/1000 Iteration: 4780 Train loss: 0.117215 Train acc: 0.961667\n",
      "Epoch: 531/1000 Iteration: 4785 Train loss: 0.094626 Train acc: 0.961667\n",
      "Epoch: 532/1000 Iteration: 4790 Train loss: 0.106275 Train acc: 0.963333\n",
      "Epoch: 532/1000 Iteration: 4795 Train loss: 0.112459 Train acc: 0.958333\n",
      "Epoch: 533/1000 Iteration: 4800 Train loss: 0.130273 Train acc: 0.951667\n",
      "Epoch: 533/1000 Iteration: 4800 Validation loss: 0.115778 Validation acc: 0.951667\n",
      "Epoch: 533/1000 Iteration: 4805 Train loss: 0.100522 Train acc: 0.963333\n",
      "Epoch: 534/1000 Iteration: 4810 Train loss: 0.130497 Train acc: 0.953333\n",
      "Epoch: 534/1000 Iteration: 4815 Train loss: 0.136730 Train acc: 0.955000\n",
      "Epoch: 535/1000 Iteration: 4820 Train loss: 0.129370 Train acc: 0.951667\n",
      "Epoch: 536/1000 Iteration: 4825 Train loss: 0.112459 Train acc: 0.971667\n",
      "Epoch: 536/1000 Iteration: 4825 Validation loss: 0.108123 Validation acc: 0.952778\n",
      "Epoch: 536/1000 Iteration: 4830 Train loss: 0.108206 Train acc: 0.961667\n",
      "Epoch: 537/1000 Iteration: 4835 Train loss: 0.118999 Train acc: 0.963333\n",
      "Epoch: 537/1000 Iteration: 4840 Train loss: 0.105136 Train acc: 0.973333\n",
      "Epoch: 538/1000 Iteration: 4845 Train loss: 0.116036 Train acc: 0.956667\n",
      "Epoch: 538/1000 Iteration: 4850 Train loss: 0.082503 Train acc: 0.975000\n",
      "Epoch: 538/1000 Iteration: 4850 Validation loss: 0.114857 Validation acc: 0.953889\n",
      "Epoch: 539/1000 Iteration: 4855 Train loss: 0.141051 Train acc: 0.941667\n",
      "Epoch: 539/1000 Iteration: 4860 Train loss: 0.122814 Train acc: 0.951667\n",
      "Epoch: 540/1000 Iteration: 4865 Train loss: 0.121352 Train acc: 0.955000\n",
      "Epoch: 541/1000 Iteration: 4870 Train loss: 0.104731 Train acc: 0.968333\n",
      "Epoch: 541/1000 Iteration: 4875 Train loss: 0.102705 Train acc: 0.966667\n",
      "Epoch: 541/1000 Iteration: 4875 Validation loss: 0.121910 Validation acc: 0.951111\n",
      "Epoch: 542/1000 Iteration: 4880 Train loss: 0.125008 Train acc: 0.960000\n",
      "Epoch: 542/1000 Iteration: 4885 Train loss: 0.108795 Train acc: 0.958333\n",
      "Epoch: 543/1000 Iteration: 4890 Train loss: 0.110604 Train acc: 0.960000\n",
      "Epoch: 543/1000 Iteration: 4895 Train loss: 0.094970 Train acc: 0.968333\n",
      "Epoch: 544/1000 Iteration: 4900 Train loss: 0.142064 Train acc: 0.945000\n",
      "Epoch: 544/1000 Iteration: 4900 Validation loss: 0.114219 Validation acc: 0.954444\n",
      "Epoch: 544/1000 Iteration: 4905 Train loss: 0.113626 Train acc: 0.948333\n",
      "Epoch: 545/1000 Iteration: 4910 Train loss: 0.109926 Train acc: 0.961667\n",
      "Epoch: 546/1000 Iteration: 4915 Train loss: 0.114047 Train acc: 0.951667\n",
      "Epoch: 546/1000 Iteration: 4920 Train loss: 0.104244 Train acc: 0.960000\n",
      "Epoch: 547/1000 Iteration: 4925 Train loss: 0.110261 Train acc: 0.968333\n",
      "Epoch: 547/1000 Iteration: 4925 Validation loss: 0.114451 Validation acc: 0.953889\n",
      "Epoch: 547/1000 Iteration: 4930 Train loss: 0.112207 Train acc: 0.960000\n",
      "Epoch: 548/1000 Iteration: 4935 Train loss: 0.124391 Train acc: 0.950000\n",
      "Epoch: 548/1000 Iteration: 4940 Train loss: 0.081202 Train acc: 0.970000\n",
      "Epoch: 549/1000 Iteration: 4945 Train loss: 0.137013 Train acc: 0.941667\n",
      "Epoch: 549/1000 Iteration: 4950 Train loss: 0.118559 Train acc: 0.953333\n",
      "Epoch: 549/1000 Iteration: 4950 Validation loss: 0.116383 Validation acc: 0.952222\n",
      "Epoch: 550/1000 Iteration: 4955 Train loss: 0.113241 Train acc: 0.961667\n",
      "Epoch: 551/1000 Iteration: 4960 Train loss: 0.121558 Train acc: 0.960000\n",
      "Epoch: 551/1000 Iteration: 4965 Train loss: 0.108367 Train acc: 0.955000\n",
      "Epoch: 552/1000 Iteration: 4970 Train loss: 0.125862 Train acc: 0.960000\n",
      "Epoch: 552/1000 Iteration: 4975 Train loss: 0.110287 Train acc: 0.965000\n",
      "Epoch: 552/1000 Iteration: 4975 Validation loss: 0.116388 Validation acc: 0.953333\n",
      "Epoch: 553/1000 Iteration: 4980 Train loss: 0.113681 Train acc: 0.956667\n",
      "Epoch: 553/1000 Iteration: 4985 Train loss: 0.092965 Train acc: 0.975000\n",
      "Epoch: 554/1000 Iteration: 4990 Train loss: 0.144397 Train acc: 0.938333\n",
      "Epoch: 554/1000 Iteration: 4995 Train loss: 0.120749 Train acc: 0.943333\n",
      "Epoch: 555/1000 Iteration: 5000 Train loss: 0.123816 Train acc: 0.956667\n",
      "Epoch: 555/1000 Iteration: 5000 Validation loss: 0.119835 Validation acc: 0.952222\n",
      "Epoch: 556/1000 Iteration: 5005 Train loss: 0.108772 Train acc: 0.958333\n",
      "Epoch: 556/1000 Iteration: 5010 Train loss: 0.101153 Train acc: 0.965000\n",
      "Epoch: 557/1000 Iteration: 5015 Train loss: 0.113428 Train acc: 0.958333\n",
      "Epoch: 557/1000 Iteration: 5020 Train loss: 0.108133 Train acc: 0.951667\n",
      "Epoch: 558/1000 Iteration: 5025 Train loss: 0.110560 Train acc: 0.960000\n",
      "Epoch: 558/1000 Iteration: 5025 Validation loss: 0.114796 Validation acc: 0.954444\n",
      "Epoch: 558/1000 Iteration: 5030 Train loss: 0.096547 Train acc: 0.975000\n",
      "Epoch: 559/1000 Iteration: 5035 Train loss: 0.143499 Train acc: 0.941667\n",
      "Epoch: 559/1000 Iteration: 5040 Train loss: 0.124997 Train acc: 0.956667\n",
      "Epoch: 560/1000 Iteration: 5045 Train loss: 0.110228 Train acc: 0.961667\n",
      "Epoch: 561/1000 Iteration: 5050 Train loss: 0.102653 Train acc: 0.963333\n",
      "Epoch: 561/1000 Iteration: 5050 Validation loss: 0.114322 Validation acc: 0.953333\n",
      "Epoch: 561/1000 Iteration: 5055 Train loss: 0.093329 Train acc: 0.968333\n",
      "Epoch: 562/1000 Iteration: 5060 Train loss: 0.107077 Train acc: 0.963333\n",
      "Epoch: 562/1000 Iteration: 5065 Train loss: 0.101229 Train acc: 0.963333\n",
      "Epoch: 563/1000 Iteration: 5070 Train loss: 0.119830 Train acc: 0.960000\n",
      "Epoch: 563/1000 Iteration: 5075 Train loss: 0.086446 Train acc: 0.976667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 563/1000 Iteration: 5075 Validation loss: 0.116831 Validation acc: 0.952778\n",
      "Epoch: 564/1000 Iteration: 5080 Train loss: 0.120283 Train acc: 0.950000\n",
      "Epoch: 564/1000 Iteration: 5085 Train loss: 0.116989 Train acc: 0.955000\n",
      "Epoch: 565/1000 Iteration: 5090 Train loss: 0.113915 Train acc: 0.960000\n",
      "Epoch: 566/1000 Iteration: 5095 Train loss: 0.102989 Train acc: 0.963333\n",
      "Epoch: 566/1000 Iteration: 5100 Train loss: 0.102677 Train acc: 0.958333\n",
      "Epoch: 566/1000 Iteration: 5100 Validation loss: 0.113398 Validation acc: 0.955556\n",
      "Epoch: 567/1000 Iteration: 5105 Train loss: 0.105734 Train acc: 0.970000\n",
      "Epoch: 567/1000 Iteration: 5110 Train loss: 0.102299 Train acc: 0.963333\n",
      "Epoch: 568/1000 Iteration: 5115 Train loss: 0.115731 Train acc: 0.960000\n",
      "Epoch: 568/1000 Iteration: 5120 Train loss: 0.090239 Train acc: 0.970000\n",
      "Epoch: 569/1000 Iteration: 5125 Train loss: 0.131144 Train acc: 0.940000\n",
      "Epoch: 569/1000 Iteration: 5125 Validation loss: 0.113820 Validation acc: 0.955000\n",
      "Epoch: 569/1000 Iteration: 5130 Train loss: 0.115165 Train acc: 0.958333\n",
      "Epoch: 570/1000 Iteration: 5135 Train loss: 0.122407 Train acc: 0.943333\n",
      "Epoch: 571/1000 Iteration: 5140 Train loss: 0.105429 Train acc: 0.958333\n",
      "Epoch: 571/1000 Iteration: 5145 Train loss: 0.090183 Train acc: 0.973333\n",
      "Epoch: 572/1000 Iteration: 5150 Train loss: 0.099984 Train acc: 0.970000\n",
      "Epoch: 572/1000 Iteration: 5150 Validation loss: 0.120466 Validation acc: 0.953333\n",
      "Epoch: 572/1000 Iteration: 5155 Train loss: 0.102159 Train acc: 0.968333\n",
      "Epoch: 573/1000 Iteration: 5160 Train loss: 0.117742 Train acc: 0.955000\n",
      "Epoch: 573/1000 Iteration: 5165 Train loss: 0.084716 Train acc: 0.975000\n",
      "Epoch: 574/1000 Iteration: 5170 Train loss: 0.125896 Train acc: 0.938333\n",
      "Epoch: 574/1000 Iteration: 5175 Train loss: 0.133105 Train acc: 0.953333\n",
      "Epoch: 574/1000 Iteration: 5175 Validation loss: 0.116301 Validation acc: 0.955556\n",
      "Epoch: 575/1000 Iteration: 5180 Train loss: 0.118441 Train acc: 0.953333\n",
      "Epoch: 576/1000 Iteration: 5185 Train loss: 0.101731 Train acc: 0.960000\n",
      "Epoch: 576/1000 Iteration: 5190 Train loss: 0.088017 Train acc: 0.965000\n",
      "Epoch: 577/1000 Iteration: 5195 Train loss: 0.113371 Train acc: 0.963333\n",
      "Epoch: 577/1000 Iteration: 5200 Train loss: 0.099116 Train acc: 0.963333\n",
      "Epoch: 577/1000 Iteration: 5200 Validation loss: 0.114614 Validation acc: 0.953889\n",
      "Epoch: 578/1000 Iteration: 5205 Train loss: 0.111602 Train acc: 0.960000\n",
      "Epoch: 578/1000 Iteration: 5210 Train loss: 0.074550 Train acc: 0.973333\n",
      "Epoch: 579/1000 Iteration: 5215 Train loss: 0.122335 Train acc: 0.946667\n",
      "Epoch: 579/1000 Iteration: 5220 Train loss: 0.108335 Train acc: 0.958333\n",
      "Epoch: 580/1000 Iteration: 5225 Train loss: 0.130713 Train acc: 0.956667\n",
      "Epoch: 580/1000 Iteration: 5225 Validation loss: 0.121269 Validation acc: 0.955555\n",
      "Epoch: 581/1000 Iteration: 5230 Train loss: 0.106542 Train acc: 0.958333\n",
      "Epoch: 581/1000 Iteration: 5235 Train loss: 0.111454 Train acc: 0.951667\n",
      "Epoch: 582/1000 Iteration: 5240 Train loss: 0.117435 Train acc: 0.961667\n",
      "Epoch: 582/1000 Iteration: 5245 Train loss: 0.113291 Train acc: 0.955000\n",
      "Epoch: 583/1000 Iteration: 5250 Train loss: 0.111859 Train acc: 0.956667\n",
      "Epoch: 583/1000 Iteration: 5250 Validation loss: 0.120550 Validation acc: 0.953889\n",
      "Epoch: 583/1000 Iteration: 5255 Train loss: 0.099122 Train acc: 0.968333\n",
      "Epoch: 584/1000 Iteration: 5260 Train loss: 0.127530 Train acc: 0.948333\n",
      "Epoch: 584/1000 Iteration: 5265 Train loss: 0.125708 Train acc: 0.958333\n",
      "Epoch: 585/1000 Iteration: 5270 Train loss: 0.116740 Train acc: 0.958333\n",
      "Epoch: 586/1000 Iteration: 5275 Train loss: 0.097095 Train acc: 0.965000\n",
      "Epoch: 586/1000 Iteration: 5275 Validation loss: 0.113759 Validation acc: 0.956111\n",
      "Epoch: 586/1000 Iteration: 5280 Train loss: 0.093918 Train acc: 0.966667\n",
      "Epoch: 587/1000 Iteration: 5285 Train loss: 0.104562 Train acc: 0.958333\n",
      "Epoch: 587/1000 Iteration: 5290 Train loss: 0.106633 Train acc: 0.963333\n",
      "Epoch: 588/1000 Iteration: 5295 Train loss: 0.121252 Train acc: 0.955000\n",
      "Epoch: 588/1000 Iteration: 5300 Train loss: 0.083643 Train acc: 0.971667\n",
      "Epoch: 588/1000 Iteration: 5300 Validation loss: 0.111446 Validation acc: 0.957778\n",
      "Epoch: 589/1000 Iteration: 5305 Train loss: 0.134187 Train acc: 0.943333\n",
      "Epoch: 589/1000 Iteration: 5310 Train loss: 0.107836 Train acc: 0.956667\n",
      "Epoch: 590/1000 Iteration: 5315 Train loss: 0.114002 Train acc: 0.951667\n",
      "Epoch: 591/1000 Iteration: 5320 Train loss: 0.101556 Train acc: 0.951667\n",
      "Epoch: 591/1000 Iteration: 5325 Train loss: 0.083030 Train acc: 0.971667\n",
      "Epoch: 591/1000 Iteration: 5325 Validation loss: 0.130491 Validation acc: 0.951667\n",
      "Epoch: 592/1000 Iteration: 5330 Train loss: 0.098303 Train acc: 0.958333\n",
      "Epoch: 592/1000 Iteration: 5335 Train loss: 0.105851 Train acc: 0.961667\n",
      "Epoch: 593/1000 Iteration: 5340 Train loss: 0.102711 Train acc: 0.956667\n",
      "Epoch: 593/1000 Iteration: 5345 Train loss: 0.081871 Train acc: 0.968333\n",
      "Epoch: 594/1000 Iteration: 5350 Train loss: 0.124193 Train acc: 0.950000\n",
      "Epoch: 594/1000 Iteration: 5350 Validation loss: 0.112950 Validation acc: 0.957778\n",
      "Epoch: 594/1000 Iteration: 5355 Train loss: 0.119892 Train acc: 0.960000\n",
      "Epoch: 595/1000 Iteration: 5360 Train loss: 0.111499 Train acc: 0.965000\n",
      "Epoch: 596/1000 Iteration: 5365 Train loss: 0.108346 Train acc: 0.960000\n",
      "Epoch: 596/1000 Iteration: 5370 Train loss: 0.093977 Train acc: 0.973333\n",
      "Epoch: 597/1000 Iteration: 5375 Train loss: 0.105607 Train acc: 0.968333\n",
      "Epoch: 597/1000 Iteration: 5375 Validation loss: 0.116463 Validation acc: 0.953889\n",
      "Epoch: 597/1000 Iteration: 5380 Train loss: 0.098556 Train acc: 0.968333\n",
      "Epoch: 598/1000 Iteration: 5385 Train loss: 0.104878 Train acc: 0.955000\n",
      "Epoch: 598/1000 Iteration: 5390 Train loss: 0.084781 Train acc: 0.968333\n",
      "Epoch: 599/1000 Iteration: 5395 Train loss: 0.125693 Train acc: 0.948333\n",
      "Epoch: 599/1000 Iteration: 5400 Train loss: 0.117824 Train acc: 0.956667\n",
      "Epoch: 599/1000 Iteration: 5400 Validation loss: 0.114427 Validation acc: 0.955000\n",
      "Epoch: 600/1000 Iteration: 5405 Train loss: 0.118872 Train acc: 0.956667\n",
      "Epoch: 601/1000 Iteration: 5410 Train loss: 0.106060 Train acc: 0.961667\n",
      "Epoch: 601/1000 Iteration: 5415 Train loss: 0.093475 Train acc: 0.970000\n",
      "Epoch: 602/1000 Iteration: 5420 Train loss: 0.089520 Train acc: 0.968333\n",
      "Epoch: 602/1000 Iteration: 5425 Train loss: 0.103447 Train acc: 0.958333\n",
      "Epoch: 602/1000 Iteration: 5425 Validation loss: 0.114341 Validation acc: 0.955000\n",
      "Epoch: 603/1000 Iteration: 5430 Train loss: 0.103575 Train acc: 0.966667\n",
      "Epoch: 603/1000 Iteration: 5435 Train loss: 0.087072 Train acc: 0.973333\n",
      "Epoch: 604/1000 Iteration: 5440 Train loss: 0.119976 Train acc: 0.946667\n",
      "Epoch: 604/1000 Iteration: 5445 Train loss: 0.128183 Train acc: 0.953333\n",
      "Epoch: 605/1000 Iteration: 5450 Train loss: 0.108857 Train acc: 0.965000\n",
      "Epoch: 605/1000 Iteration: 5450 Validation loss: 0.114041 Validation acc: 0.955556\n",
      "Epoch: 606/1000 Iteration: 5455 Train loss: 0.103001 Train acc: 0.960000\n",
      "Epoch: 606/1000 Iteration: 5460 Train loss: 0.095765 Train acc: 0.970000\n",
      "Epoch: 607/1000 Iteration: 5465 Train loss: 0.101464 Train acc: 0.963333\n",
      "Epoch: 607/1000 Iteration: 5470 Train loss: 0.102914 Train acc: 0.961667\n",
      "Epoch: 608/1000 Iteration: 5475 Train loss: 0.113417 Train acc: 0.955000\n",
      "Epoch: 608/1000 Iteration: 5475 Validation loss: 0.112756 Validation acc: 0.957222\n",
      "Epoch: 608/1000 Iteration: 5480 Train loss: 0.088261 Train acc: 0.971667\n",
      "Epoch: 609/1000 Iteration: 5485 Train loss: 0.129130 Train acc: 0.940000\n",
      "Epoch: 609/1000 Iteration: 5490 Train loss: 0.109320 Train acc: 0.950000\n",
      "Epoch: 610/1000 Iteration: 5495 Train loss: 0.101280 Train acc: 0.965000\n",
      "Epoch: 611/1000 Iteration: 5500 Train loss: 0.103427 Train acc: 0.961667\n",
      "Epoch: 611/1000 Iteration: 5500 Validation loss: 0.113789 Validation acc: 0.953333\n",
      "Epoch: 611/1000 Iteration: 5505 Train loss: 0.093108 Train acc: 0.963333\n",
      "Epoch: 612/1000 Iteration: 5510 Train loss: 0.093453 Train acc: 0.968333\n",
      "Epoch: 612/1000 Iteration: 5515 Train loss: 0.097001 Train acc: 0.966667\n",
      "Epoch: 613/1000 Iteration: 5520 Train loss: 0.099033 Train acc: 0.960000\n",
      "Epoch: 613/1000 Iteration: 5525 Train loss: 0.075206 Train acc: 0.978333\n",
      "Epoch: 613/1000 Iteration: 5525 Validation loss: 0.119238 Validation acc: 0.956667\n",
      "Epoch: 614/1000 Iteration: 5530 Train loss: 0.130019 Train acc: 0.940000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 614/1000 Iteration: 5535 Train loss: 0.112897 Train acc: 0.966667\n",
      "Epoch: 615/1000 Iteration: 5540 Train loss: 0.115583 Train acc: 0.956667\n",
      "Epoch: 616/1000 Iteration: 5545 Train loss: 0.095688 Train acc: 0.965000\n",
      "Epoch: 616/1000 Iteration: 5550 Train loss: 0.086895 Train acc: 0.965000\n",
      "Epoch: 616/1000 Iteration: 5550 Validation loss: 0.120002 Validation acc: 0.953889\n",
      "Epoch: 617/1000 Iteration: 5555 Train loss: 0.104053 Train acc: 0.965000\n",
      "Epoch: 617/1000 Iteration: 5560 Train loss: 0.100446 Train acc: 0.965000\n",
      "Epoch: 618/1000 Iteration: 5565 Train loss: 0.104783 Train acc: 0.965000\n",
      "Epoch: 618/1000 Iteration: 5570 Train loss: 0.086430 Train acc: 0.973333\n",
      "Epoch: 619/1000 Iteration: 5575 Train loss: 0.129626 Train acc: 0.948333\n",
      "Epoch: 619/1000 Iteration: 5575 Validation loss: 0.124931 Validation acc: 0.955000\n",
      "Epoch: 619/1000 Iteration: 5580 Train loss: 0.117681 Train acc: 0.966667\n",
      "Epoch: 620/1000 Iteration: 5585 Train loss: 0.120537 Train acc: 0.961667\n",
      "Epoch: 621/1000 Iteration: 5590 Train loss: 0.100614 Train acc: 0.956667\n",
      "Epoch: 621/1000 Iteration: 5595 Train loss: 0.095738 Train acc: 0.958333\n",
      "Epoch: 622/1000 Iteration: 5600 Train loss: 0.092183 Train acc: 0.965000\n",
      "Epoch: 622/1000 Iteration: 5600 Validation loss: 0.123514 Validation acc: 0.955556\n",
      "Epoch: 622/1000 Iteration: 5605 Train loss: 0.099773 Train acc: 0.970000\n",
      "Epoch: 623/1000 Iteration: 5610 Train loss: 0.117633 Train acc: 0.951667\n",
      "Epoch: 623/1000 Iteration: 5615 Train loss: 0.089339 Train acc: 0.968333\n",
      "Epoch: 624/1000 Iteration: 5620 Train loss: 0.140974 Train acc: 0.945000\n",
      "Epoch: 624/1000 Iteration: 5625 Train loss: 0.119506 Train acc: 0.961667\n",
      "Epoch: 624/1000 Iteration: 5625 Validation loss: 0.112618 Validation acc: 0.956111\n",
      "Epoch: 625/1000 Iteration: 5630 Train loss: 0.099164 Train acc: 0.960000\n",
      "Epoch: 626/1000 Iteration: 5635 Train loss: 0.092983 Train acc: 0.966667\n",
      "Epoch: 626/1000 Iteration: 5640 Train loss: 0.083829 Train acc: 0.968333\n",
      "Epoch: 627/1000 Iteration: 5645 Train loss: 0.091561 Train acc: 0.971667\n",
      "Epoch: 627/1000 Iteration: 5650 Train loss: 0.104153 Train acc: 0.965000\n",
      "Epoch: 627/1000 Iteration: 5650 Validation loss: 0.122447 Validation acc: 0.956111\n",
      "Epoch: 628/1000 Iteration: 5655 Train loss: 0.111024 Train acc: 0.951667\n",
      "Epoch: 628/1000 Iteration: 5660 Train loss: 0.077862 Train acc: 0.976667\n",
      "Epoch: 629/1000 Iteration: 5665 Train loss: 0.139620 Train acc: 0.950000\n",
      "Epoch: 629/1000 Iteration: 5670 Train loss: 0.132474 Train acc: 0.945000\n",
      "Epoch: 630/1000 Iteration: 5675 Train loss: 0.117926 Train acc: 0.958333\n",
      "Epoch: 630/1000 Iteration: 5675 Validation loss: 0.123978 Validation acc: 0.953333\n",
      "Epoch: 631/1000 Iteration: 5680 Train loss: 0.093813 Train acc: 0.966667\n",
      "Epoch: 631/1000 Iteration: 5685 Train loss: 0.088858 Train acc: 0.965000\n",
      "Epoch: 632/1000 Iteration: 5690 Train loss: 0.102369 Train acc: 0.965000\n",
      "Epoch: 632/1000 Iteration: 5695 Train loss: 0.108321 Train acc: 0.960000\n",
      "Epoch: 633/1000 Iteration: 5700 Train loss: 0.105076 Train acc: 0.960000\n",
      "Epoch: 633/1000 Iteration: 5700 Validation loss: 0.114052 Validation acc: 0.955556\n",
      "Epoch: 633/1000 Iteration: 5705 Train loss: 0.077443 Train acc: 0.971667\n",
      "Epoch: 634/1000 Iteration: 5710 Train loss: 0.119521 Train acc: 0.946667\n",
      "Epoch: 634/1000 Iteration: 5715 Train loss: 0.108961 Train acc: 0.958333\n",
      "Epoch: 635/1000 Iteration: 5720 Train loss: 0.116750 Train acc: 0.956667\n",
      "Epoch: 636/1000 Iteration: 5725 Train loss: 0.097537 Train acc: 0.956667\n",
      "Epoch: 636/1000 Iteration: 5725 Validation loss: 0.110280 Validation acc: 0.958889\n",
      "Epoch: 636/1000 Iteration: 5730 Train loss: 0.092114 Train acc: 0.961667\n",
      "Epoch: 637/1000 Iteration: 5735 Train loss: 0.100864 Train acc: 0.963333\n",
      "Epoch: 637/1000 Iteration: 5740 Train loss: 0.100819 Train acc: 0.968333\n",
      "Epoch: 638/1000 Iteration: 5745 Train loss: 0.103245 Train acc: 0.958333\n",
      "Epoch: 638/1000 Iteration: 5750 Train loss: 0.070724 Train acc: 0.980000\n",
      "Epoch: 638/1000 Iteration: 5750 Validation loss: 0.115862 Validation acc: 0.957222\n",
      "Epoch: 639/1000 Iteration: 5755 Train loss: 0.130820 Train acc: 0.943333\n",
      "Epoch: 639/1000 Iteration: 5760 Train loss: 0.124385 Train acc: 0.956667\n",
      "Epoch: 640/1000 Iteration: 5765 Train loss: 0.101184 Train acc: 0.961667\n",
      "Epoch: 641/1000 Iteration: 5770 Train loss: 0.097976 Train acc: 0.961667\n",
      "Epoch: 641/1000 Iteration: 5775 Train loss: 0.090429 Train acc: 0.965000\n",
      "Epoch: 641/1000 Iteration: 5775 Validation loss: 0.113897 Validation acc: 0.955000\n",
      "Epoch: 642/1000 Iteration: 5780 Train loss: 0.091587 Train acc: 0.971667\n",
      "Epoch: 642/1000 Iteration: 5785 Train loss: 0.105924 Train acc: 0.963333\n",
      "Epoch: 643/1000 Iteration: 5790 Train loss: 0.113841 Train acc: 0.953333\n",
      "Epoch: 643/1000 Iteration: 5795 Train loss: 0.087442 Train acc: 0.966667\n",
      "Epoch: 644/1000 Iteration: 5800 Train loss: 0.117945 Train acc: 0.946667\n",
      "Epoch: 644/1000 Iteration: 5800 Validation loss: 0.146173 Validation acc: 0.950000\n",
      "Epoch: 644/1000 Iteration: 5805 Train loss: 0.129919 Train acc: 0.960000\n",
      "Epoch: 645/1000 Iteration: 5810 Train loss: 0.110251 Train acc: 0.963333\n",
      "Epoch: 646/1000 Iteration: 5815 Train loss: 0.094259 Train acc: 0.950000\n",
      "Epoch: 646/1000 Iteration: 5820 Train loss: 0.088030 Train acc: 0.970000\n",
      "Epoch: 647/1000 Iteration: 5825 Train loss: 0.091379 Train acc: 0.973333\n",
      "Epoch: 647/1000 Iteration: 5825 Validation loss: 0.130251 Validation acc: 0.956667\n",
      "Epoch: 647/1000 Iteration: 5830 Train loss: 0.105617 Train acc: 0.963333\n",
      "Epoch: 648/1000 Iteration: 5835 Train loss: 0.109013 Train acc: 0.961667\n",
      "Epoch: 648/1000 Iteration: 5840 Train loss: 0.083710 Train acc: 0.975000\n",
      "Epoch: 649/1000 Iteration: 5845 Train loss: 0.122987 Train acc: 0.951667\n",
      "Epoch: 649/1000 Iteration: 5850 Train loss: 0.091938 Train acc: 0.963333\n",
      "Epoch: 649/1000 Iteration: 5850 Validation loss: 0.108503 Validation acc: 0.956667\n",
      "Epoch: 650/1000 Iteration: 5855 Train loss: 0.103249 Train acc: 0.953333\n",
      "Epoch: 651/1000 Iteration: 5860 Train loss: 0.104929 Train acc: 0.956667\n",
      "Epoch: 651/1000 Iteration: 5865 Train loss: 0.093163 Train acc: 0.961667\n",
      "Epoch: 652/1000 Iteration: 5870 Train loss: 0.103256 Train acc: 0.958333\n",
      "Epoch: 652/1000 Iteration: 5875 Train loss: 0.103577 Train acc: 0.961667\n",
      "Epoch: 652/1000 Iteration: 5875 Validation loss: 0.105070 Validation acc: 0.958889\n",
      "Epoch: 653/1000 Iteration: 5880 Train loss: 0.109944 Train acc: 0.955000\n",
      "Epoch: 653/1000 Iteration: 5885 Train loss: 0.074153 Train acc: 0.980000\n",
      "Epoch: 654/1000 Iteration: 5890 Train loss: 0.113747 Train acc: 0.955000\n",
      "Epoch: 654/1000 Iteration: 5895 Train loss: 0.108486 Train acc: 0.953333\n",
      "Epoch: 655/1000 Iteration: 5900 Train loss: 0.115885 Train acc: 0.960000\n",
      "Epoch: 655/1000 Iteration: 5900 Validation loss: 0.111177 Validation acc: 0.956667\n",
      "Epoch: 656/1000 Iteration: 5905 Train loss: 0.083231 Train acc: 0.958333\n",
      "Epoch: 656/1000 Iteration: 5910 Train loss: 0.097017 Train acc: 0.961667\n",
      "Epoch: 657/1000 Iteration: 5915 Train loss: 0.096508 Train acc: 0.970000\n",
      "Epoch: 657/1000 Iteration: 5920 Train loss: 0.101397 Train acc: 0.966667\n",
      "Epoch: 658/1000 Iteration: 5925 Train loss: 0.114547 Train acc: 0.951667\n",
      "Epoch: 658/1000 Iteration: 5925 Validation loss: 0.107243 Validation acc: 0.959445\n",
      "Epoch: 658/1000 Iteration: 5930 Train loss: 0.075805 Train acc: 0.966667\n",
      "Epoch: 659/1000 Iteration: 5935 Train loss: 0.115018 Train acc: 0.950000\n",
      "Epoch: 659/1000 Iteration: 5940 Train loss: 0.134214 Train acc: 0.948333\n",
      "Epoch: 660/1000 Iteration: 5945 Train loss: 0.111406 Train acc: 0.951667\n",
      "Epoch: 661/1000 Iteration: 5950 Train loss: 0.095212 Train acc: 0.960000\n",
      "Epoch: 661/1000 Iteration: 5950 Validation loss: 0.117606 Validation acc: 0.957778\n",
      "Epoch: 661/1000 Iteration: 5955 Train loss: 0.084446 Train acc: 0.968333\n",
      "Epoch: 662/1000 Iteration: 5960 Train loss: 0.099220 Train acc: 0.961667\n",
      "Epoch: 662/1000 Iteration: 5965 Train loss: 0.096120 Train acc: 0.961667\n",
      "Epoch: 663/1000 Iteration: 5970 Train loss: 0.105692 Train acc: 0.961667\n",
      "Epoch: 663/1000 Iteration: 5975 Train loss: 0.074731 Train acc: 0.981667\n",
      "Epoch: 663/1000 Iteration: 5975 Validation loss: 0.110376 Validation acc: 0.956667\n",
      "Epoch: 664/1000 Iteration: 5980 Train loss: 0.132937 Train acc: 0.945000\n",
      "Epoch: 664/1000 Iteration: 5985 Train loss: 0.121654 Train acc: 0.963333\n",
      "Epoch: 665/1000 Iteration: 5990 Train loss: 0.103675 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 666/1000 Iteration: 5995 Train loss: 0.081213 Train acc: 0.971667\n",
      "Epoch: 666/1000 Iteration: 6000 Train loss: 0.084006 Train acc: 0.966667\n",
      "Epoch: 666/1000 Iteration: 6000 Validation loss: 0.108578 Validation acc: 0.960000\n",
      "Epoch: 667/1000 Iteration: 6005 Train loss: 0.086543 Train acc: 0.970000\n",
      "Epoch: 667/1000 Iteration: 6010 Train loss: 0.096347 Train acc: 0.965000\n",
      "Epoch: 668/1000 Iteration: 6015 Train loss: 0.102849 Train acc: 0.956667\n",
      "Epoch: 668/1000 Iteration: 6020 Train loss: 0.079594 Train acc: 0.973333\n",
      "Epoch: 669/1000 Iteration: 6025 Train loss: 0.133371 Train acc: 0.943333\n",
      "Epoch: 669/1000 Iteration: 6025 Validation loss: 0.114568 Validation acc: 0.958889\n",
      "Epoch: 669/1000 Iteration: 6030 Train loss: 0.135411 Train acc: 0.950000\n",
      "Epoch: 670/1000 Iteration: 6035 Train loss: 0.101681 Train acc: 0.955000\n",
      "Epoch: 671/1000 Iteration: 6040 Train loss: 0.092827 Train acc: 0.960000\n",
      "Epoch: 671/1000 Iteration: 6045 Train loss: 0.091804 Train acc: 0.958333\n",
      "Epoch: 672/1000 Iteration: 6050 Train loss: 0.091446 Train acc: 0.965000\n",
      "Epoch: 672/1000 Iteration: 6050 Validation loss: 0.114539 Validation acc: 0.956667\n",
      "Epoch: 672/1000 Iteration: 6055 Train loss: 0.102849 Train acc: 0.955000\n",
      "Epoch: 673/1000 Iteration: 6060 Train loss: 0.103981 Train acc: 0.953333\n",
      "Epoch: 673/1000 Iteration: 6065 Train loss: 0.079740 Train acc: 0.966667\n",
      "Epoch: 674/1000 Iteration: 6070 Train loss: 0.123601 Train acc: 0.943333\n",
      "Epoch: 674/1000 Iteration: 6075 Train loss: 0.099549 Train acc: 0.961667\n",
      "Epoch: 674/1000 Iteration: 6075 Validation loss: 0.110667 Validation acc: 0.956667\n",
      "Epoch: 675/1000 Iteration: 6080 Train loss: 0.109547 Train acc: 0.951667\n",
      "Epoch: 676/1000 Iteration: 6085 Train loss: 0.085850 Train acc: 0.965000\n",
      "Epoch: 676/1000 Iteration: 6090 Train loss: 0.078996 Train acc: 0.973333\n",
      "Epoch: 677/1000 Iteration: 6095 Train loss: 0.098909 Train acc: 0.965000\n",
      "Epoch: 677/1000 Iteration: 6100 Train loss: 0.095568 Train acc: 0.963333\n",
      "Epoch: 677/1000 Iteration: 6100 Validation loss: 0.116906 Validation acc: 0.956111\n",
      "Epoch: 678/1000 Iteration: 6105 Train loss: 0.104946 Train acc: 0.956667\n",
      "Epoch: 678/1000 Iteration: 6110 Train loss: 0.078515 Train acc: 0.973333\n",
      "Epoch: 679/1000 Iteration: 6115 Train loss: 0.123492 Train acc: 0.943333\n",
      "Epoch: 679/1000 Iteration: 6120 Train loss: 0.102027 Train acc: 0.956667\n",
      "Epoch: 680/1000 Iteration: 6125 Train loss: 0.109722 Train acc: 0.960000\n",
      "Epoch: 680/1000 Iteration: 6125 Validation loss: 0.116315 Validation acc: 0.955556\n",
      "Epoch: 681/1000 Iteration: 6130 Train loss: 0.099489 Train acc: 0.956667\n",
      "Epoch: 681/1000 Iteration: 6135 Train loss: 0.083768 Train acc: 0.973333\n",
      "Epoch: 682/1000 Iteration: 6140 Train loss: 0.086228 Train acc: 0.970000\n",
      "Epoch: 682/1000 Iteration: 6145 Train loss: 0.092955 Train acc: 0.960000\n",
      "Epoch: 683/1000 Iteration: 6150 Train loss: 0.100265 Train acc: 0.968333\n",
      "Epoch: 683/1000 Iteration: 6150 Validation loss: 0.117391 Validation acc: 0.953889\n",
      "Epoch: 683/1000 Iteration: 6155 Train loss: 0.088453 Train acc: 0.968333\n",
      "Epoch: 684/1000 Iteration: 6160 Train loss: 0.132100 Train acc: 0.946667\n",
      "Epoch: 684/1000 Iteration: 6165 Train loss: 0.117061 Train acc: 0.953333\n",
      "Epoch: 685/1000 Iteration: 6170 Train loss: 0.111902 Train acc: 0.965000\n",
      "Epoch: 686/1000 Iteration: 6175 Train loss: 0.091408 Train acc: 0.960000\n",
      "Epoch: 686/1000 Iteration: 6175 Validation loss: 0.105080 Validation acc: 0.960556\n",
      "Epoch: 686/1000 Iteration: 6180 Train loss: 0.081890 Train acc: 0.963333\n",
      "Epoch: 687/1000 Iteration: 6185 Train loss: 0.102842 Train acc: 0.965000\n",
      "Epoch: 687/1000 Iteration: 6190 Train loss: 0.094952 Train acc: 0.970000\n",
      "Epoch: 688/1000 Iteration: 6195 Train loss: 0.108921 Train acc: 0.956667\n",
      "Epoch: 688/1000 Iteration: 6200 Train loss: 0.075621 Train acc: 0.976667\n",
      "Epoch: 688/1000 Iteration: 6200 Validation loss: 0.112603 Validation acc: 0.960000\n",
      "Epoch: 689/1000 Iteration: 6205 Train loss: 0.134515 Train acc: 0.946667\n",
      "Epoch: 689/1000 Iteration: 6210 Train loss: 0.103489 Train acc: 0.968333\n",
      "Epoch: 690/1000 Iteration: 6215 Train loss: 0.099106 Train acc: 0.955000\n",
      "Epoch: 691/1000 Iteration: 6220 Train loss: 0.088501 Train acc: 0.958333\n",
      "Epoch: 691/1000 Iteration: 6225 Train loss: 0.101613 Train acc: 0.956667\n",
      "Epoch: 691/1000 Iteration: 6225 Validation loss: 0.116478 Validation acc: 0.955000\n",
      "Epoch: 692/1000 Iteration: 6230 Train loss: 0.096870 Train acc: 0.966667\n",
      "Epoch: 692/1000 Iteration: 6235 Train loss: 0.097659 Train acc: 0.963333\n",
      "Epoch: 693/1000 Iteration: 6240 Train loss: 0.108236 Train acc: 0.961667\n",
      "Epoch: 693/1000 Iteration: 6245 Train loss: 0.071837 Train acc: 0.973333\n",
      "Epoch: 694/1000 Iteration: 6250 Train loss: 0.124797 Train acc: 0.945000\n",
      "Epoch: 694/1000 Iteration: 6250 Validation loss: 0.109888 Validation acc: 0.958333\n",
      "Epoch: 694/1000 Iteration: 6255 Train loss: 0.107553 Train acc: 0.955000\n",
      "Epoch: 695/1000 Iteration: 6260 Train loss: 0.110663 Train acc: 0.965000\n",
      "Epoch: 696/1000 Iteration: 6265 Train loss: 0.088303 Train acc: 0.963333\n",
      "Epoch: 696/1000 Iteration: 6270 Train loss: 0.081708 Train acc: 0.966667\n",
      "Epoch: 697/1000 Iteration: 6275 Train loss: 0.099613 Train acc: 0.963333\n",
      "Epoch: 697/1000 Iteration: 6275 Validation loss: 0.111977 Validation acc: 0.957222\n",
      "Epoch: 697/1000 Iteration: 6280 Train loss: 0.102502 Train acc: 0.951667\n",
      "Epoch: 698/1000 Iteration: 6285 Train loss: 0.131060 Train acc: 0.948333\n",
      "Epoch: 698/1000 Iteration: 6290 Train loss: 0.073832 Train acc: 0.975000\n",
      "Epoch: 699/1000 Iteration: 6295 Train loss: 0.125455 Train acc: 0.951667\n",
      "Epoch: 699/1000 Iteration: 6300 Train loss: 0.119720 Train acc: 0.958333\n",
      "Epoch: 699/1000 Iteration: 6300 Validation loss: 0.109959 Validation acc: 0.957778\n",
      "Epoch: 700/1000 Iteration: 6305 Train loss: 0.096664 Train acc: 0.961667\n",
      "Epoch: 701/1000 Iteration: 6310 Train loss: 0.095948 Train acc: 0.958333\n",
      "Epoch: 701/1000 Iteration: 6315 Train loss: 0.091307 Train acc: 0.961667\n",
      "Epoch: 702/1000 Iteration: 6320 Train loss: 0.081492 Train acc: 0.973333\n",
      "Epoch: 702/1000 Iteration: 6325 Train loss: 0.091037 Train acc: 0.965000\n",
      "Epoch: 702/1000 Iteration: 6325 Validation loss: 0.112590 Validation acc: 0.957222\n",
      "Epoch: 703/1000 Iteration: 6330 Train loss: 0.105945 Train acc: 0.961667\n",
      "Epoch: 703/1000 Iteration: 6335 Train loss: 0.073368 Train acc: 0.978333\n",
      "Epoch: 704/1000 Iteration: 6340 Train loss: 0.119451 Train acc: 0.946667\n",
      "Epoch: 704/1000 Iteration: 6345 Train loss: 0.110464 Train acc: 0.955000\n",
      "Epoch: 705/1000 Iteration: 6350 Train loss: 0.098657 Train acc: 0.960000\n",
      "Epoch: 705/1000 Iteration: 6350 Validation loss: 0.111183 Validation acc: 0.957222\n",
      "Epoch: 706/1000 Iteration: 6355 Train loss: 0.093557 Train acc: 0.960000\n",
      "Epoch: 706/1000 Iteration: 6360 Train loss: 0.081718 Train acc: 0.975000\n",
      "Epoch: 707/1000 Iteration: 6365 Train loss: 0.093740 Train acc: 0.965000\n",
      "Epoch: 707/1000 Iteration: 6370 Train loss: 0.078820 Train acc: 0.973333\n",
      "Epoch: 708/1000 Iteration: 6375 Train loss: 0.096411 Train acc: 0.958333\n",
      "Epoch: 708/1000 Iteration: 6375 Validation loss: 0.119357 Validation acc: 0.957222\n",
      "Epoch: 708/1000 Iteration: 6380 Train loss: 0.070011 Train acc: 0.971667\n",
      "Epoch: 709/1000 Iteration: 6385 Train loss: 0.127102 Train acc: 0.948333\n",
      "Epoch: 709/1000 Iteration: 6390 Train loss: 0.109796 Train acc: 0.953333\n",
      "Epoch: 710/1000 Iteration: 6395 Train loss: 0.090461 Train acc: 0.968333\n",
      "Epoch: 711/1000 Iteration: 6400 Train loss: 0.090145 Train acc: 0.956667\n",
      "Epoch: 711/1000 Iteration: 6400 Validation loss: 0.108611 Validation acc: 0.957778\n",
      "Epoch: 711/1000 Iteration: 6405 Train loss: 0.089027 Train acc: 0.961667\n",
      "Epoch: 712/1000 Iteration: 6410 Train loss: 0.095927 Train acc: 0.951667\n",
      "Epoch: 712/1000 Iteration: 6415 Train loss: 0.090796 Train acc: 0.965000\n",
      "Epoch: 713/1000 Iteration: 6420 Train loss: 0.103682 Train acc: 0.953333\n",
      "Epoch: 713/1000 Iteration: 6425 Train loss: 0.076566 Train acc: 0.970000\n",
      "Epoch: 713/1000 Iteration: 6425 Validation loss: 0.110736 Validation acc: 0.957778\n",
      "Epoch: 714/1000 Iteration: 6430 Train loss: 0.129029 Train acc: 0.936667\n",
      "Epoch: 714/1000 Iteration: 6435 Train loss: 0.101987 Train acc: 0.955000\n",
      "Epoch: 715/1000 Iteration: 6440 Train loss: 0.094942 Train acc: 0.961667\n",
      "Epoch: 716/1000 Iteration: 6445 Train loss: 0.084169 Train acc: 0.963333\n",
      "Epoch: 716/1000 Iteration: 6450 Train loss: 0.092732 Train acc: 0.956667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 716/1000 Iteration: 6450 Validation loss: 0.113165 Validation acc: 0.958333\n",
      "Epoch: 717/1000 Iteration: 6455 Train loss: 0.088498 Train acc: 0.965000\n",
      "Epoch: 717/1000 Iteration: 6460 Train loss: 0.099988 Train acc: 0.965000\n",
      "Epoch: 718/1000 Iteration: 6465 Train loss: 0.101518 Train acc: 0.961667\n",
      "Epoch: 718/1000 Iteration: 6470 Train loss: 0.071354 Train acc: 0.978333\n",
      "Epoch: 719/1000 Iteration: 6475 Train loss: 0.130004 Train acc: 0.946667\n",
      "Epoch: 719/1000 Iteration: 6475 Validation loss: 0.110276 Validation acc: 0.958333\n",
      "Epoch: 719/1000 Iteration: 6480 Train loss: 0.097900 Train acc: 0.955000\n",
      "Epoch: 720/1000 Iteration: 6485 Train loss: 0.094481 Train acc: 0.956667\n",
      "Epoch: 721/1000 Iteration: 6490 Train loss: 0.091923 Train acc: 0.958333\n",
      "Epoch: 721/1000 Iteration: 6495 Train loss: 0.082260 Train acc: 0.976667\n",
      "Epoch: 722/1000 Iteration: 6500 Train loss: 0.084116 Train acc: 0.966667\n",
      "Epoch: 722/1000 Iteration: 6500 Validation loss: 0.119591 Validation acc: 0.954444\n",
      "Epoch: 722/1000 Iteration: 6505 Train loss: 0.086094 Train acc: 0.966667\n",
      "Epoch: 723/1000 Iteration: 6510 Train loss: 0.107499 Train acc: 0.953333\n",
      "Epoch: 723/1000 Iteration: 6515 Train loss: 0.085298 Train acc: 0.971667\n",
      "Epoch: 724/1000 Iteration: 6520 Train loss: 0.119454 Train acc: 0.953333\n",
      "Epoch: 724/1000 Iteration: 6525 Train loss: 0.104879 Train acc: 0.960000\n",
      "Epoch: 724/1000 Iteration: 6525 Validation loss: 0.123696 Validation acc: 0.955556\n",
      "Epoch: 725/1000 Iteration: 6530 Train loss: 0.105284 Train acc: 0.951667\n",
      "Epoch: 726/1000 Iteration: 6535 Train loss: 0.080870 Train acc: 0.960000\n",
      "Epoch: 726/1000 Iteration: 6540 Train loss: 0.086228 Train acc: 0.963333\n",
      "Epoch: 727/1000 Iteration: 6545 Train loss: 0.090530 Train acc: 0.960000\n",
      "Epoch: 727/1000 Iteration: 6550 Train loss: 0.082709 Train acc: 0.966667\n",
      "Epoch: 727/1000 Iteration: 6550 Validation loss: 0.119099 Validation acc: 0.957222\n",
      "Epoch: 728/1000 Iteration: 6555 Train loss: 0.106048 Train acc: 0.956667\n",
      "Epoch: 728/1000 Iteration: 6560 Train loss: 0.069344 Train acc: 0.971667\n",
      "Epoch: 729/1000 Iteration: 6565 Train loss: 0.121496 Train acc: 0.950000\n",
      "Epoch: 729/1000 Iteration: 6570 Train loss: 0.102221 Train acc: 0.950000\n",
      "Epoch: 730/1000 Iteration: 6575 Train loss: 0.097333 Train acc: 0.958333\n",
      "Epoch: 730/1000 Iteration: 6575 Validation loss: 0.120016 Validation acc: 0.954444\n",
      "Epoch: 731/1000 Iteration: 6580 Train loss: 0.089531 Train acc: 0.965000\n",
      "Epoch: 731/1000 Iteration: 6585 Train loss: 0.088170 Train acc: 0.960000\n",
      "Epoch: 732/1000 Iteration: 6590 Train loss: 0.086087 Train acc: 0.961667\n",
      "Epoch: 732/1000 Iteration: 6595 Train loss: 0.088934 Train acc: 0.970000\n",
      "Epoch: 733/1000 Iteration: 6600 Train loss: 0.105086 Train acc: 0.960000\n",
      "Epoch: 733/1000 Iteration: 6600 Validation loss: 0.125019 Validation acc: 0.955000\n",
      "Epoch: 733/1000 Iteration: 6605 Train loss: 0.076052 Train acc: 0.973333\n",
      "Epoch: 734/1000 Iteration: 6610 Train loss: 0.102485 Train acc: 0.960000\n",
      "Epoch: 734/1000 Iteration: 6615 Train loss: 0.116477 Train acc: 0.951667\n",
      "Epoch: 735/1000 Iteration: 6620 Train loss: 0.100996 Train acc: 0.961667\n",
      "Epoch: 736/1000 Iteration: 6625 Train loss: 0.087093 Train acc: 0.966667\n",
      "Epoch: 736/1000 Iteration: 6625 Validation loss: 0.115314 Validation acc: 0.956111\n",
      "Epoch: 736/1000 Iteration: 6630 Train loss: 0.077821 Train acc: 0.976667\n",
      "Epoch: 737/1000 Iteration: 6635 Train loss: 0.090774 Train acc: 0.963333\n",
      "Epoch: 737/1000 Iteration: 6640 Train loss: 0.077340 Train acc: 0.968333\n",
      "Epoch: 738/1000 Iteration: 6645 Train loss: 0.104113 Train acc: 0.968333\n",
      "Epoch: 738/1000 Iteration: 6650 Train loss: 0.067655 Train acc: 0.978333\n",
      "Epoch: 738/1000 Iteration: 6650 Validation loss: 0.118797 Validation acc: 0.957222\n",
      "Epoch: 739/1000 Iteration: 6655 Train loss: 0.116525 Train acc: 0.950000\n",
      "Epoch: 739/1000 Iteration: 6660 Train loss: 0.106774 Train acc: 0.958333\n",
      "Epoch: 740/1000 Iteration: 6665 Train loss: 0.098866 Train acc: 0.960000\n",
      "Epoch: 741/1000 Iteration: 6670 Train loss: 0.093772 Train acc: 0.956667\n",
      "Epoch: 741/1000 Iteration: 6675 Train loss: 0.078010 Train acc: 0.968333\n",
      "Epoch: 741/1000 Iteration: 6675 Validation loss: 0.113906 Validation acc: 0.956111\n",
      "Epoch: 742/1000 Iteration: 6680 Train loss: 0.089419 Train acc: 0.963333\n",
      "Epoch: 742/1000 Iteration: 6685 Train loss: 0.078032 Train acc: 0.975000\n",
      "Epoch: 743/1000 Iteration: 6690 Train loss: 0.092234 Train acc: 0.968333\n",
      "Epoch: 743/1000 Iteration: 6695 Train loss: 0.073605 Train acc: 0.975000\n",
      "Epoch: 744/1000 Iteration: 6700 Train loss: 0.122688 Train acc: 0.948333\n",
      "Epoch: 744/1000 Iteration: 6700 Validation loss: 0.108424 Validation acc: 0.958889\n",
      "Epoch: 744/1000 Iteration: 6705 Train loss: 0.106993 Train acc: 0.951667\n",
      "Epoch: 745/1000 Iteration: 6710 Train loss: 0.107211 Train acc: 0.956667\n",
      "Epoch: 746/1000 Iteration: 6715 Train loss: 0.086670 Train acc: 0.960000\n",
      "Epoch: 746/1000 Iteration: 6720 Train loss: 0.090969 Train acc: 0.955000\n",
      "Epoch: 747/1000 Iteration: 6725 Train loss: 0.073167 Train acc: 0.970000\n",
      "Epoch: 747/1000 Iteration: 6725 Validation loss: 0.117800 Validation acc: 0.957222\n",
      "Epoch: 747/1000 Iteration: 6730 Train loss: 0.076684 Train acc: 0.963333\n",
      "Epoch: 748/1000 Iteration: 6735 Train loss: 0.095499 Train acc: 0.966667\n",
      "Epoch: 748/1000 Iteration: 6740 Train loss: 0.067631 Train acc: 0.983333\n",
      "Epoch: 749/1000 Iteration: 6745 Train loss: 0.129265 Train acc: 0.943333\n",
      "Epoch: 749/1000 Iteration: 6750 Train loss: 0.113322 Train acc: 0.946667\n",
      "Epoch: 749/1000 Iteration: 6750 Validation loss: 0.116061 Validation acc: 0.954444\n",
      "Epoch: 750/1000 Iteration: 6755 Train loss: 0.103893 Train acc: 0.960000\n",
      "Epoch: 751/1000 Iteration: 6760 Train loss: 0.083624 Train acc: 0.965000\n",
      "Epoch: 751/1000 Iteration: 6765 Train loss: 0.086141 Train acc: 0.961667\n",
      "Epoch: 752/1000 Iteration: 6770 Train loss: 0.093660 Train acc: 0.966667\n",
      "Epoch: 752/1000 Iteration: 6775 Train loss: 0.077755 Train acc: 0.971667\n",
      "Epoch: 752/1000 Iteration: 6775 Validation loss: 0.118721 Validation acc: 0.958333\n",
      "Epoch: 753/1000 Iteration: 6780 Train loss: 0.099224 Train acc: 0.958333\n",
      "Epoch: 753/1000 Iteration: 6785 Train loss: 0.071894 Train acc: 0.970000\n",
      "Epoch: 754/1000 Iteration: 6790 Train loss: 0.117425 Train acc: 0.955000\n",
      "Epoch: 754/1000 Iteration: 6795 Train loss: 0.096818 Train acc: 0.963333\n",
      "Epoch: 755/1000 Iteration: 6800 Train loss: 0.090758 Train acc: 0.960000\n",
      "Epoch: 755/1000 Iteration: 6800 Validation loss: 0.122027 Validation acc: 0.956667\n",
      "Epoch: 756/1000 Iteration: 6805 Train loss: 0.078477 Train acc: 0.970000\n",
      "Epoch: 756/1000 Iteration: 6810 Train loss: 0.076458 Train acc: 0.971667\n",
      "Epoch: 757/1000 Iteration: 6815 Train loss: 0.082694 Train acc: 0.966667\n",
      "Epoch: 757/1000 Iteration: 6820 Train loss: 0.083762 Train acc: 0.966667\n",
      "Epoch: 758/1000 Iteration: 6825 Train loss: 0.097736 Train acc: 0.960000\n",
      "Epoch: 758/1000 Iteration: 6825 Validation loss: 0.126043 Validation acc: 0.956667\n",
      "Epoch: 758/1000 Iteration: 6830 Train loss: 0.055765 Train acc: 0.978333\n",
      "Epoch: 759/1000 Iteration: 6835 Train loss: 0.121764 Train acc: 0.948333\n",
      "Epoch: 759/1000 Iteration: 6840 Train loss: 0.109118 Train acc: 0.958333\n",
      "Epoch: 760/1000 Iteration: 6845 Train loss: 0.092661 Train acc: 0.960000\n",
      "Epoch: 761/1000 Iteration: 6850 Train loss: 0.098372 Train acc: 0.963333\n",
      "Epoch: 761/1000 Iteration: 6850 Validation loss: 0.116323 Validation acc: 0.956111\n",
      "Epoch: 761/1000 Iteration: 6855 Train loss: 0.078339 Train acc: 0.968333\n",
      "Epoch: 762/1000 Iteration: 6860 Train loss: 0.084162 Train acc: 0.976667\n",
      "Epoch: 762/1000 Iteration: 6865 Train loss: 0.091266 Train acc: 0.958333\n",
      "Epoch: 763/1000 Iteration: 6870 Train loss: 0.094661 Train acc: 0.968333\n",
      "Epoch: 763/1000 Iteration: 6875 Train loss: 0.067444 Train acc: 0.980000\n",
      "Epoch: 763/1000 Iteration: 6875 Validation loss: 0.118279 Validation acc: 0.956111\n",
      "Epoch: 764/1000 Iteration: 6880 Train loss: 0.121131 Train acc: 0.946667\n",
      "Epoch: 764/1000 Iteration: 6885 Train loss: 0.118901 Train acc: 0.953333\n",
      "Epoch: 765/1000 Iteration: 6890 Train loss: 0.084360 Train acc: 0.966667\n",
      "Epoch: 766/1000 Iteration: 6895 Train loss: 0.087948 Train acc: 0.960000\n",
      "Epoch: 766/1000 Iteration: 6900 Train loss: 0.078822 Train acc: 0.963333\n",
      "Epoch: 766/1000 Iteration: 6900 Validation loss: 0.119074 Validation acc: 0.957222\n",
      "Epoch: 767/1000 Iteration: 6905 Train loss: 0.083687 Train acc: 0.971667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 767/1000 Iteration: 6910 Train loss: 0.084775 Train acc: 0.965000\n",
      "Epoch: 768/1000 Iteration: 6915 Train loss: 0.092616 Train acc: 0.970000\n",
      "Epoch: 768/1000 Iteration: 6920 Train loss: 0.057126 Train acc: 0.983333\n",
      "Epoch: 769/1000 Iteration: 6925 Train loss: 0.114678 Train acc: 0.946667\n",
      "Epoch: 769/1000 Iteration: 6925 Validation loss: 0.098142 Validation acc: 0.958333\n",
      "Epoch: 769/1000 Iteration: 6930 Train loss: 0.118588 Train acc: 0.956667\n",
      "Epoch: 770/1000 Iteration: 6935 Train loss: 0.101219 Train acc: 0.961667\n",
      "Epoch: 771/1000 Iteration: 6940 Train loss: 0.099497 Train acc: 0.956667\n",
      "Epoch: 771/1000 Iteration: 6945 Train loss: 0.079034 Train acc: 0.973333\n",
      "Epoch: 772/1000 Iteration: 6950 Train loss: 0.077570 Train acc: 0.970000\n",
      "Epoch: 772/1000 Iteration: 6950 Validation loss: 0.115715 Validation acc: 0.955000\n",
      "Epoch: 772/1000 Iteration: 6955 Train loss: 0.080634 Train acc: 0.971667\n",
      "Epoch: 773/1000 Iteration: 6960 Train loss: 0.107047 Train acc: 0.956667\n",
      "Epoch: 773/1000 Iteration: 6965 Train loss: 0.078085 Train acc: 0.968333\n",
      "Epoch: 774/1000 Iteration: 6970 Train loss: 0.118598 Train acc: 0.945000\n",
      "Epoch: 774/1000 Iteration: 6975 Train loss: 0.108430 Train acc: 0.951667\n",
      "Epoch: 774/1000 Iteration: 6975 Validation loss: 0.110871 Validation acc: 0.957222\n",
      "Epoch: 775/1000 Iteration: 6980 Train loss: 0.090306 Train acc: 0.960000\n",
      "Epoch: 776/1000 Iteration: 6985 Train loss: 0.103835 Train acc: 0.953333\n",
      "Epoch: 776/1000 Iteration: 6990 Train loss: 0.077445 Train acc: 0.973333\n",
      "Epoch: 777/1000 Iteration: 6995 Train loss: 0.089200 Train acc: 0.970000\n",
      "Epoch: 777/1000 Iteration: 7000 Train loss: 0.065749 Train acc: 0.971667\n",
      "Epoch: 777/1000 Iteration: 7000 Validation loss: 0.111805 Validation acc: 0.957778\n",
      "Epoch: 778/1000 Iteration: 7005 Train loss: 0.100435 Train acc: 0.955000\n",
      "Epoch: 778/1000 Iteration: 7010 Train loss: 0.060021 Train acc: 0.978333\n",
      "Epoch: 779/1000 Iteration: 7015 Train loss: 0.120272 Train acc: 0.946667\n",
      "Epoch: 779/1000 Iteration: 7020 Train loss: 0.107016 Train acc: 0.956667\n",
      "Epoch: 780/1000 Iteration: 7025 Train loss: 0.102272 Train acc: 0.963333\n",
      "Epoch: 780/1000 Iteration: 7025 Validation loss: 0.112043 Validation acc: 0.957222\n",
      "Epoch: 781/1000 Iteration: 7030 Train loss: 0.089589 Train acc: 0.965000\n",
      "Epoch: 781/1000 Iteration: 7035 Train loss: 0.077884 Train acc: 0.970000\n",
      "Epoch: 782/1000 Iteration: 7040 Train loss: 0.092158 Train acc: 0.966667\n",
      "Epoch: 782/1000 Iteration: 7045 Train loss: 0.084468 Train acc: 0.966667\n",
      "Epoch: 783/1000 Iteration: 7050 Train loss: 0.104320 Train acc: 0.955000\n",
      "Epoch: 783/1000 Iteration: 7050 Validation loss: 0.110998 Validation acc: 0.955000\n",
      "Epoch: 783/1000 Iteration: 7055 Train loss: 0.061853 Train acc: 0.981667\n",
      "Epoch: 784/1000 Iteration: 7060 Train loss: 0.098862 Train acc: 0.960000\n",
      "Epoch: 784/1000 Iteration: 7065 Train loss: 0.108767 Train acc: 0.950000\n",
      "Epoch: 785/1000 Iteration: 7070 Train loss: 0.115264 Train acc: 0.951667\n",
      "Epoch: 786/1000 Iteration: 7075 Train loss: 0.085093 Train acc: 0.965000\n",
      "Epoch: 786/1000 Iteration: 7075 Validation loss: 0.111071 Validation acc: 0.957778\n",
      "Epoch: 786/1000 Iteration: 7080 Train loss: 0.086438 Train acc: 0.960000\n",
      "Epoch: 787/1000 Iteration: 7085 Train loss: 0.080606 Train acc: 0.970000\n",
      "Epoch: 787/1000 Iteration: 7090 Train loss: 0.076686 Train acc: 0.971667\n",
      "Epoch: 788/1000 Iteration: 7095 Train loss: 0.105208 Train acc: 0.953333\n",
      "Epoch: 788/1000 Iteration: 7100 Train loss: 0.066125 Train acc: 0.970000\n",
      "Epoch: 788/1000 Iteration: 7100 Validation loss: 0.118996 Validation acc: 0.957222\n",
      "Epoch: 789/1000 Iteration: 7105 Train loss: 0.127412 Train acc: 0.945000\n",
      "Epoch: 789/1000 Iteration: 7110 Train loss: 0.091205 Train acc: 0.968333\n",
      "Epoch: 790/1000 Iteration: 7115 Train loss: 0.103044 Train acc: 0.961667\n",
      "Epoch: 791/1000 Iteration: 7120 Train loss: 0.082090 Train acc: 0.965000\n",
      "Epoch: 791/1000 Iteration: 7125 Train loss: 0.079864 Train acc: 0.963333\n",
      "Epoch: 791/1000 Iteration: 7125 Validation loss: 0.121593 Validation acc: 0.954444\n",
      "Epoch: 792/1000 Iteration: 7130 Train loss: 0.080541 Train acc: 0.976667\n",
      "Epoch: 792/1000 Iteration: 7135 Train loss: 0.084954 Train acc: 0.961667\n",
      "Epoch: 793/1000 Iteration: 7140 Train loss: 0.096193 Train acc: 0.956667\n",
      "Epoch: 793/1000 Iteration: 7145 Train loss: 0.060286 Train acc: 0.978333\n",
      "Epoch: 794/1000 Iteration: 7150 Train loss: 0.121297 Train acc: 0.950000\n",
      "Epoch: 794/1000 Iteration: 7150 Validation loss: 0.112429 Validation acc: 0.957222\n",
      "Epoch: 794/1000 Iteration: 7155 Train loss: 0.101927 Train acc: 0.955000\n",
      "Epoch: 795/1000 Iteration: 7160 Train loss: 0.091918 Train acc: 0.963333\n",
      "Epoch: 796/1000 Iteration: 7165 Train loss: 0.073531 Train acc: 0.968333\n",
      "Epoch: 796/1000 Iteration: 7170 Train loss: 0.083351 Train acc: 0.956667\n",
      "Epoch: 797/1000 Iteration: 7175 Train loss: 0.089894 Train acc: 0.961667\n",
      "Epoch: 797/1000 Iteration: 7175 Validation loss: 0.140768 Validation acc: 0.953333\n",
      "Epoch: 797/1000 Iteration: 7180 Train loss: 0.075520 Train acc: 0.966667\n",
      "Epoch: 798/1000 Iteration: 7185 Train loss: 0.102815 Train acc: 0.961667\n",
      "Epoch: 798/1000 Iteration: 7190 Train loss: 0.063313 Train acc: 0.973333\n",
      "Epoch: 799/1000 Iteration: 7195 Train loss: 0.125929 Train acc: 0.943333\n",
      "Epoch: 799/1000 Iteration: 7200 Train loss: 0.106653 Train acc: 0.955000\n",
      "Epoch: 799/1000 Iteration: 7200 Validation loss: 0.121475 Validation acc: 0.956111\n",
      "Epoch: 800/1000 Iteration: 7205 Train loss: 0.094986 Train acc: 0.963333\n",
      "Epoch: 801/1000 Iteration: 7210 Train loss: 0.080453 Train acc: 0.963333\n",
      "Epoch: 801/1000 Iteration: 7215 Train loss: 0.078506 Train acc: 0.975000\n",
      "Epoch: 802/1000 Iteration: 7220 Train loss: 0.086521 Train acc: 0.968333\n",
      "Epoch: 802/1000 Iteration: 7225 Train loss: 0.091649 Train acc: 0.965000\n",
      "Epoch: 802/1000 Iteration: 7225 Validation loss: 0.121023 Validation acc: 0.955000\n",
      "Epoch: 803/1000 Iteration: 7230 Train loss: 0.089356 Train acc: 0.955000\n",
      "Epoch: 803/1000 Iteration: 7235 Train loss: 0.067529 Train acc: 0.970000\n",
      "Epoch: 804/1000 Iteration: 7240 Train loss: 0.120214 Train acc: 0.946667\n",
      "Epoch: 804/1000 Iteration: 7245 Train loss: 0.095006 Train acc: 0.950000\n",
      "Epoch: 805/1000 Iteration: 7250 Train loss: 0.107856 Train acc: 0.951667\n",
      "Epoch: 805/1000 Iteration: 7250 Validation loss: 0.120177 Validation acc: 0.957222\n",
      "Epoch: 806/1000 Iteration: 7255 Train loss: 0.086501 Train acc: 0.961667\n",
      "Epoch: 806/1000 Iteration: 7260 Train loss: 0.073798 Train acc: 0.971667\n",
      "Epoch: 807/1000 Iteration: 7265 Train loss: 0.070388 Train acc: 0.973333\n",
      "Epoch: 807/1000 Iteration: 7270 Train loss: 0.076520 Train acc: 0.966667\n",
      "Epoch: 808/1000 Iteration: 7275 Train loss: 0.096485 Train acc: 0.945000\n",
      "Epoch: 808/1000 Iteration: 7275 Validation loss: 0.112876 Validation acc: 0.957778\n",
      "Epoch: 808/1000 Iteration: 7280 Train loss: 0.065568 Train acc: 0.983333\n",
      "Epoch: 809/1000 Iteration: 7285 Train loss: 0.114118 Train acc: 0.948333\n",
      "Epoch: 809/1000 Iteration: 7290 Train loss: 0.102750 Train acc: 0.955000\n",
      "Epoch: 810/1000 Iteration: 7295 Train loss: 0.109870 Train acc: 0.951667\n",
      "Epoch: 811/1000 Iteration: 7300 Train loss: 0.101229 Train acc: 0.951667\n",
      "Epoch: 811/1000 Iteration: 7300 Validation loss: 0.117616 Validation acc: 0.957778\n",
      "Epoch: 811/1000 Iteration: 7305 Train loss: 0.076082 Train acc: 0.968333\n",
      "Epoch: 812/1000 Iteration: 7310 Train loss: 0.082917 Train acc: 0.966667\n",
      "Epoch: 812/1000 Iteration: 7315 Train loss: 0.076163 Train acc: 0.963333\n",
      "Epoch: 813/1000 Iteration: 7320 Train loss: 0.091212 Train acc: 0.956667\n",
      "Epoch: 813/1000 Iteration: 7325 Train loss: 0.056655 Train acc: 0.981667\n",
      "Epoch: 813/1000 Iteration: 7325 Validation loss: 0.123264 Validation acc: 0.955000\n",
      "Epoch: 814/1000 Iteration: 7330 Train loss: 0.115732 Train acc: 0.946667\n",
      "Epoch: 814/1000 Iteration: 7335 Train loss: 0.097858 Train acc: 0.961667\n",
      "Epoch: 815/1000 Iteration: 7340 Train loss: 0.092614 Train acc: 0.970000\n",
      "Epoch: 816/1000 Iteration: 7345 Train loss: 0.078871 Train acc: 0.965000\n",
      "Epoch: 816/1000 Iteration: 7350 Train loss: 0.072825 Train acc: 0.970000\n",
      "Epoch: 816/1000 Iteration: 7350 Validation loss: 0.108534 Validation acc: 0.956111\n",
      "Epoch: 817/1000 Iteration: 7355 Train loss: 0.078679 Train acc: 0.968333\n",
      "Epoch: 817/1000 Iteration: 7360 Train loss: 0.076708 Train acc: 0.973333\n",
      "Epoch: 818/1000 Iteration: 7365 Train loss: 0.093824 Train acc: 0.965000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 818/1000 Iteration: 7370 Train loss: 0.060287 Train acc: 0.971667\n",
      "Epoch: 819/1000 Iteration: 7375 Train loss: 0.116481 Train acc: 0.948333\n",
      "Epoch: 819/1000 Iteration: 7375 Validation loss: 0.124852 Validation acc: 0.953333\n",
      "Epoch: 819/1000 Iteration: 7380 Train loss: 0.102283 Train acc: 0.950000\n",
      "Epoch: 820/1000 Iteration: 7385 Train loss: 0.101016 Train acc: 0.955000\n",
      "Epoch: 821/1000 Iteration: 7390 Train loss: 0.091874 Train acc: 0.961667\n",
      "Epoch: 821/1000 Iteration: 7395 Train loss: 0.083319 Train acc: 0.966667\n",
      "Epoch: 822/1000 Iteration: 7400 Train loss: 0.068861 Train acc: 0.970000\n",
      "Epoch: 822/1000 Iteration: 7400 Validation loss: 0.110278 Validation acc: 0.955556\n",
      "Epoch: 822/1000 Iteration: 7405 Train loss: 0.075533 Train acc: 0.975000\n",
      "Epoch: 823/1000 Iteration: 7410 Train loss: 0.094021 Train acc: 0.956667\n",
      "Epoch: 823/1000 Iteration: 7415 Train loss: 0.062279 Train acc: 0.980000\n",
      "Epoch: 824/1000 Iteration: 7420 Train loss: 0.107585 Train acc: 0.946667\n",
      "Epoch: 824/1000 Iteration: 7425 Train loss: 0.096391 Train acc: 0.965000\n",
      "Epoch: 824/1000 Iteration: 7425 Validation loss: 0.108971 Validation acc: 0.954444\n",
      "Epoch: 825/1000 Iteration: 7430 Train loss: 0.091324 Train acc: 0.958333\n",
      "Epoch: 826/1000 Iteration: 7435 Train loss: 0.084441 Train acc: 0.963333\n",
      "Epoch: 826/1000 Iteration: 7440 Train loss: 0.076530 Train acc: 0.965000\n",
      "Epoch: 827/1000 Iteration: 7445 Train loss: 0.089550 Train acc: 0.963333\n",
      "Epoch: 827/1000 Iteration: 7450 Train loss: 0.074309 Train acc: 0.973333\n",
      "Epoch: 827/1000 Iteration: 7450 Validation loss: 0.127051 Validation acc: 0.953889\n",
      "Epoch: 828/1000 Iteration: 7455 Train loss: 0.092052 Train acc: 0.968333\n",
      "Epoch: 828/1000 Iteration: 7460 Train loss: 0.056512 Train acc: 0.978333\n",
      "Epoch: 829/1000 Iteration: 7465 Train loss: 0.112511 Train acc: 0.956667\n",
      "Epoch: 829/1000 Iteration: 7470 Train loss: 0.103873 Train acc: 0.951667\n",
      "Epoch: 830/1000 Iteration: 7475 Train loss: 0.090937 Train acc: 0.961667\n",
      "Epoch: 830/1000 Iteration: 7475 Validation loss: 0.113105 Validation acc: 0.955556\n",
      "Epoch: 831/1000 Iteration: 7480 Train loss: 0.081932 Train acc: 0.961667\n",
      "Epoch: 831/1000 Iteration: 7485 Train loss: 0.074952 Train acc: 0.971667\n",
      "Epoch: 832/1000 Iteration: 7490 Train loss: 0.069501 Train acc: 0.970000\n",
      "Epoch: 832/1000 Iteration: 7495 Train loss: 0.068242 Train acc: 0.975000\n",
      "Epoch: 833/1000 Iteration: 7500 Train loss: 0.084930 Train acc: 0.961667\n",
      "Epoch: 833/1000 Iteration: 7500 Validation loss: 0.124430 Validation acc: 0.954444\n",
      "Epoch: 833/1000 Iteration: 7505 Train loss: 0.060934 Train acc: 0.980000\n",
      "Epoch: 834/1000 Iteration: 7510 Train loss: 0.120045 Train acc: 0.950000\n",
      "Epoch: 834/1000 Iteration: 7515 Train loss: 0.090499 Train acc: 0.966667\n",
      "Epoch: 835/1000 Iteration: 7520 Train loss: 0.100772 Train acc: 0.956667\n",
      "Epoch: 836/1000 Iteration: 7525 Train loss: 0.092261 Train acc: 0.956667\n",
      "Epoch: 836/1000 Iteration: 7525 Validation loss: 0.114364 Validation acc: 0.956667\n",
      "Epoch: 836/1000 Iteration: 7530 Train loss: 0.072600 Train acc: 0.968333\n",
      "Epoch: 837/1000 Iteration: 7535 Train loss: 0.095912 Train acc: 0.965000\n",
      "Epoch: 837/1000 Iteration: 7540 Train loss: 0.074229 Train acc: 0.968333\n",
      "Epoch: 838/1000 Iteration: 7545 Train loss: 0.092668 Train acc: 0.960000\n",
      "Epoch: 838/1000 Iteration: 7550 Train loss: 0.054426 Train acc: 0.981667\n",
      "Epoch: 838/1000 Iteration: 7550 Validation loss: 0.126533 Validation acc: 0.955000\n",
      "Epoch: 839/1000 Iteration: 7555 Train loss: 0.113522 Train acc: 0.953333\n",
      "Epoch: 839/1000 Iteration: 7560 Train loss: 0.106698 Train acc: 0.953333\n",
      "Epoch: 840/1000 Iteration: 7565 Train loss: 0.106023 Train acc: 0.951667\n",
      "Epoch: 841/1000 Iteration: 7570 Train loss: 0.087835 Train acc: 0.961667\n",
      "Epoch: 841/1000 Iteration: 7575 Train loss: 0.072753 Train acc: 0.971667\n",
      "Epoch: 841/1000 Iteration: 7575 Validation loss: 0.113148 Validation acc: 0.956667\n",
      "Epoch: 842/1000 Iteration: 7580 Train loss: 0.075767 Train acc: 0.971667\n",
      "Epoch: 842/1000 Iteration: 7585 Train loss: 0.067792 Train acc: 0.973333\n",
      "Epoch: 843/1000 Iteration: 7590 Train loss: 0.084435 Train acc: 0.963333\n",
      "Epoch: 843/1000 Iteration: 7595 Train loss: 0.057513 Train acc: 0.980000\n",
      "Epoch: 844/1000 Iteration: 7600 Train loss: 0.104151 Train acc: 0.961667\n",
      "Epoch: 844/1000 Iteration: 7600 Validation loss: 0.119931 Validation acc: 0.955000\n",
      "Epoch: 844/1000 Iteration: 7605 Train loss: 0.106002 Train acc: 0.963333\n",
      "Epoch: 845/1000 Iteration: 7610 Train loss: 0.098856 Train acc: 0.960000\n",
      "Epoch: 846/1000 Iteration: 7615 Train loss: 0.080184 Train acc: 0.963333\n",
      "Epoch: 846/1000 Iteration: 7620 Train loss: 0.069414 Train acc: 0.968333\n",
      "Epoch: 847/1000 Iteration: 7625 Train loss: 0.082417 Train acc: 0.961667\n",
      "Epoch: 847/1000 Iteration: 7625 Validation loss: 0.112269 Validation acc: 0.956667\n",
      "Epoch: 847/1000 Iteration: 7630 Train loss: 0.070268 Train acc: 0.973333\n",
      "Epoch: 848/1000 Iteration: 7635 Train loss: 0.083632 Train acc: 0.958333\n",
      "Epoch: 848/1000 Iteration: 7640 Train loss: 0.054397 Train acc: 0.973333\n",
      "Epoch: 849/1000 Iteration: 7645 Train loss: 0.104378 Train acc: 0.951667\n",
      "Epoch: 849/1000 Iteration: 7650 Train loss: 0.089210 Train acc: 0.948333\n",
      "Epoch: 849/1000 Iteration: 7650 Validation loss: 0.113415 Validation acc: 0.956667\n",
      "Epoch: 850/1000 Iteration: 7655 Train loss: 0.100493 Train acc: 0.960000\n",
      "Epoch: 851/1000 Iteration: 7660 Train loss: 0.073579 Train acc: 0.963333\n",
      "Epoch: 851/1000 Iteration: 7665 Train loss: 0.076129 Train acc: 0.966667\n",
      "Epoch: 852/1000 Iteration: 7670 Train loss: 0.082224 Train acc: 0.966667\n",
      "Epoch: 852/1000 Iteration: 7675 Train loss: 0.078594 Train acc: 0.968333\n",
      "Epoch: 852/1000 Iteration: 7675 Validation loss: 0.130813 Validation acc: 0.952778\n",
      "Epoch: 853/1000 Iteration: 7680 Train loss: 0.084262 Train acc: 0.965000\n",
      "Epoch: 853/1000 Iteration: 7685 Train loss: 0.058900 Train acc: 0.981667\n",
      "Epoch: 854/1000 Iteration: 7690 Train loss: 0.113802 Train acc: 0.943333\n",
      "Epoch: 854/1000 Iteration: 7695 Train loss: 0.099658 Train acc: 0.966667\n",
      "Epoch: 855/1000 Iteration: 7700 Train loss: 0.094985 Train acc: 0.956667\n",
      "Epoch: 855/1000 Iteration: 7700 Validation loss: 0.126976 Validation acc: 0.953889\n",
      "Epoch: 856/1000 Iteration: 7705 Train loss: 0.080514 Train acc: 0.965000\n",
      "Epoch: 856/1000 Iteration: 7710 Train loss: 0.071477 Train acc: 0.966667\n",
      "Epoch: 857/1000 Iteration: 7715 Train loss: 0.079274 Train acc: 0.961667\n",
      "Epoch: 857/1000 Iteration: 7720 Train loss: 0.066099 Train acc: 0.968333\n",
      "Epoch: 858/1000 Iteration: 7725 Train loss: 0.084903 Train acc: 0.958333\n",
      "Epoch: 858/1000 Iteration: 7725 Validation loss: 0.119451 Validation acc: 0.954444\n",
      "Epoch: 858/1000 Iteration: 7730 Train loss: 0.061179 Train acc: 0.975000\n",
      "Epoch: 859/1000 Iteration: 7735 Train loss: 0.112248 Train acc: 0.958333\n",
      "Epoch: 859/1000 Iteration: 7740 Train loss: 0.107841 Train acc: 0.956667\n",
      "Epoch: 860/1000 Iteration: 7745 Train loss: 0.099155 Train acc: 0.956667\n",
      "Epoch: 861/1000 Iteration: 7750 Train loss: 0.083732 Train acc: 0.965000\n",
      "Epoch: 861/1000 Iteration: 7750 Validation loss: 0.119169 Validation acc: 0.955000\n",
      "Epoch: 861/1000 Iteration: 7755 Train loss: 0.070691 Train acc: 0.970000\n",
      "Epoch: 862/1000 Iteration: 7760 Train loss: 0.067890 Train acc: 0.980000\n",
      "Epoch: 862/1000 Iteration: 7765 Train loss: 0.063779 Train acc: 0.975000\n",
      "Epoch: 863/1000 Iteration: 7770 Train loss: 0.082540 Train acc: 0.961667\n",
      "Epoch: 863/1000 Iteration: 7775 Train loss: 0.049944 Train acc: 0.980000\n",
      "Epoch: 863/1000 Iteration: 7775 Validation loss: 0.112653 Validation acc: 0.956111\n",
      "Epoch: 864/1000 Iteration: 7780 Train loss: 0.112315 Train acc: 0.951667\n",
      "Epoch: 864/1000 Iteration: 7785 Train loss: 0.101172 Train acc: 0.963333\n",
      "Epoch: 865/1000 Iteration: 7790 Train loss: 0.083627 Train acc: 0.961667\n",
      "Epoch: 866/1000 Iteration: 7795 Train loss: 0.084397 Train acc: 0.966667\n",
      "Epoch: 866/1000 Iteration: 7800 Train loss: 0.070153 Train acc: 0.970000\n",
      "Epoch: 866/1000 Iteration: 7800 Validation loss: 0.112718 Validation acc: 0.956667\n",
      "Epoch: 867/1000 Iteration: 7805 Train loss: 0.076739 Train acc: 0.970000\n",
      "Epoch: 867/1000 Iteration: 7810 Train loss: 0.074006 Train acc: 0.968333\n",
      "Epoch: 868/1000 Iteration: 7815 Train loss: 0.091478 Train acc: 0.951667\n",
      "Epoch: 868/1000 Iteration: 7820 Train loss: 0.075424 Train acc: 0.973333\n",
      "Epoch: 869/1000 Iteration: 7825 Train loss: 0.150805 Train acc: 0.936667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 869/1000 Iteration: 7825 Validation loss: 0.113664 Validation acc: 0.956667\n",
      "Epoch: 869/1000 Iteration: 7830 Train loss: 0.089674 Train acc: 0.963333\n",
      "Epoch: 870/1000 Iteration: 7835 Train loss: 0.093603 Train acc: 0.956667\n",
      "Epoch: 871/1000 Iteration: 7840 Train loss: 0.076516 Train acc: 0.960000\n",
      "Epoch: 871/1000 Iteration: 7845 Train loss: 0.075038 Train acc: 0.970000\n",
      "Epoch: 872/1000 Iteration: 7850 Train loss: 0.079109 Train acc: 0.968333\n",
      "Epoch: 872/1000 Iteration: 7850 Validation loss: 0.118567 Validation acc: 0.955000\n",
      "Epoch: 872/1000 Iteration: 7855 Train loss: 0.082628 Train acc: 0.963333\n",
      "Epoch: 873/1000 Iteration: 7860 Train loss: 0.097598 Train acc: 0.951667\n",
      "Epoch: 873/1000 Iteration: 7865 Train loss: 0.060202 Train acc: 0.978333\n",
      "Epoch: 874/1000 Iteration: 7870 Train loss: 0.119674 Train acc: 0.946667\n",
      "Epoch: 874/1000 Iteration: 7875 Train loss: 0.095713 Train acc: 0.956667\n",
      "Epoch: 874/1000 Iteration: 7875 Validation loss: 0.126005 Validation acc: 0.956111\n",
      "Epoch: 875/1000 Iteration: 7880 Train loss: 0.101850 Train acc: 0.960000\n",
      "Epoch: 876/1000 Iteration: 7885 Train loss: 0.084268 Train acc: 0.961667\n",
      "Epoch: 876/1000 Iteration: 7890 Train loss: 0.068929 Train acc: 0.971667\n",
      "Epoch: 877/1000 Iteration: 7895 Train loss: 0.084846 Train acc: 0.970000\n",
      "Epoch: 877/1000 Iteration: 7900 Train loss: 0.069763 Train acc: 0.968333\n",
      "Epoch: 877/1000 Iteration: 7900 Validation loss: 0.115065 Validation acc: 0.956111\n",
      "Epoch: 878/1000 Iteration: 7905 Train loss: 0.090587 Train acc: 0.960000\n",
      "Epoch: 878/1000 Iteration: 7910 Train loss: 0.063441 Train acc: 0.976667\n",
      "Epoch: 879/1000 Iteration: 7915 Train loss: 0.120966 Train acc: 0.955000\n",
      "Epoch: 879/1000 Iteration: 7920 Train loss: 0.097333 Train acc: 0.950000\n",
      "Epoch: 880/1000 Iteration: 7925 Train loss: 0.085066 Train acc: 0.965000\n",
      "Epoch: 880/1000 Iteration: 7925 Validation loss: 0.111109 Validation acc: 0.955556\n",
      "Epoch: 881/1000 Iteration: 7930 Train loss: 0.083079 Train acc: 0.965000\n",
      "Epoch: 881/1000 Iteration: 7935 Train loss: 0.072618 Train acc: 0.975000\n",
      "Epoch: 882/1000 Iteration: 7940 Train loss: 0.084461 Train acc: 0.965000\n",
      "Epoch: 882/1000 Iteration: 7945 Train loss: 0.071160 Train acc: 0.973333\n",
      "Epoch: 883/1000 Iteration: 7950 Train loss: 0.085404 Train acc: 0.961667\n",
      "Epoch: 883/1000 Iteration: 7950 Validation loss: 0.126022 Validation acc: 0.955555\n",
      "Epoch: 883/1000 Iteration: 7955 Train loss: 0.061887 Train acc: 0.980000\n",
      "Epoch: 884/1000 Iteration: 7960 Train loss: 0.115967 Train acc: 0.953333\n",
      "Epoch: 884/1000 Iteration: 7965 Train loss: 0.091187 Train acc: 0.956667\n",
      "Epoch: 885/1000 Iteration: 7970 Train loss: 0.100415 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Train loss: 0.091470 Train acc: 0.960000\n",
      "Epoch: 886/1000 Iteration: 7975 Validation loss: 0.119444 Validation acc: 0.956111\n",
      "Epoch: 886/1000 Iteration: 7980 Train loss: 0.071952 Train acc: 0.966667\n",
      "Epoch: 887/1000 Iteration: 7985 Train loss: 0.069490 Train acc: 0.970000\n",
      "Epoch: 887/1000 Iteration: 7990 Train loss: 0.065615 Train acc: 0.975000\n",
      "Epoch: 888/1000 Iteration: 7995 Train loss: 0.091215 Train acc: 0.960000\n",
      "Epoch: 888/1000 Iteration: 8000 Train loss: 0.055011 Train acc: 0.980000\n",
      "Epoch: 888/1000 Iteration: 8000 Validation loss: 0.110863 Validation acc: 0.956111\n",
      "Epoch: 889/1000 Iteration: 8005 Train loss: 0.104040 Train acc: 0.958333\n",
      "Epoch: 889/1000 Iteration: 8010 Train loss: 0.093118 Train acc: 0.960000\n",
      "Epoch: 890/1000 Iteration: 8015 Train loss: 0.100892 Train acc: 0.951667\n",
      "Epoch: 891/1000 Iteration: 8020 Train loss: 0.076019 Train acc: 0.965000\n",
      "Epoch: 891/1000 Iteration: 8025 Train loss: 0.066071 Train acc: 0.971667\n",
      "Epoch: 891/1000 Iteration: 8025 Validation loss: 0.125293 Validation acc: 0.956111\n",
      "Epoch: 892/1000 Iteration: 8030 Train loss: 0.077128 Train acc: 0.971667\n",
      "Epoch: 892/1000 Iteration: 8035 Train loss: 0.066481 Train acc: 0.976667\n",
      "Epoch: 893/1000 Iteration: 8040 Train loss: 0.073633 Train acc: 0.965000\n",
      "Epoch: 893/1000 Iteration: 8045 Train loss: 0.046253 Train acc: 0.986667\n",
      "Epoch: 894/1000 Iteration: 8050 Train loss: 0.103884 Train acc: 0.951667\n",
      "Epoch: 894/1000 Iteration: 8050 Validation loss: 0.113193 Validation acc: 0.955556\n",
      "Epoch: 894/1000 Iteration: 8055 Train loss: 0.082814 Train acc: 0.965000\n",
      "Epoch: 895/1000 Iteration: 8060 Train loss: 0.082192 Train acc: 0.960000\n",
      "Epoch: 896/1000 Iteration: 8065 Train loss: 0.073941 Train acc: 0.973333\n",
      "Epoch: 896/1000 Iteration: 8070 Train loss: 0.062769 Train acc: 0.970000\n",
      "Epoch: 897/1000 Iteration: 8075 Train loss: 0.076162 Train acc: 0.963333\n",
      "Epoch: 897/1000 Iteration: 8075 Validation loss: 0.121688 Validation acc: 0.954444\n",
      "Epoch: 897/1000 Iteration: 8080 Train loss: 0.078390 Train acc: 0.968333\n",
      "Epoch: 898/1000 Iteration: 8085 Train loss: 0.075700 Train acc: 0.961667\n",
      "Epoch: 898/1000 Iteration: 8090 Train loss: 0.050154 Train acc: 0.986667\n",
      "Epoch: 899/1000 Iteration: 8095 Train loss: 0.108218 Train acc: 0.953333\n",
      "Epoch: 899/1000 Iteration: 8100 Train loss: 0.096142 Train acc: 0.960000\n",
      "Epoch: 899/1000 Iteration: 8100 Validation loss: 0.117091 Validation acc: 0.955000\n",
      "Epoch: 900/1000 Iteration: 8105 Train loss: 0.090470 Train acc: 0.963333\n",
      "Epoch: 901/1000 Iteration: 8110 Train loss: 0.092151 Train acc: 0.960000\n",
      "Epoch: 901/1000 Iteration: 8115 Train loss: 0.068282 Train acc: 0.965000\n",
      "Epoch: 902/1000 Iteration: 8120 Train loss: 0.074688 Train acc: 0.968333\n",
      "Epoch: 902/1000 Iteration: 8125 Train loss: 0.069853 Train acc: 0.973333\n",
      "Epoch: 902/1000 Iteration: 8125 Validation loss: 0.115929 Validation acc: 0.955000\n",
      "Epoch: 903/1000 Iteration: 8130 Train loss: 0.093505 Train acc: 0.958333\n",
      "Epoch: 903/1000 Iteration: 8135 Train loss: 0.060227 Train acc: 0.978333\n",
      "Epoch: 904/1000 Iteration: 8140 Train loss: 0.102732 Train acc: 0.953333\n",
      "Epoch: 904/1000 Iteration: 8145 Train loss: 0.098879 Train acc: 0.958333\n",
      "Epoch: 905/1000 Iteration: 8150 Train loss: 0.086535 Train acc: 0.968333\n",
      "Epoch: 905/1000 Iteration: 8150 Validation loss: 0.121746 Validation acc: 0.955556\n",
      "Epoch: 906/1000 Iteration: 8155 Train loss: 0.080519 Train acc: 0.968333\n",
      "Epoch: 906/1000 Iteration: 8160 Train loss: 0.063240 Train acc: 0.971667\n",
      "Epoch: 907/1000 Iteration: 8165 Train loss: 0.081862 Train acc: 0.971667\n",
      "Epoch: 907/1000 Iteration: 8170 Train loss: 0.075093 Train acc: 0.968333\n",
      "Epoch: 908/1000 Iteration: 8175 Train loss: 0.083224 Train acc: 0.963333\n",
      "Epoch: 908/1000 Iteration: 8175 Validation loss: 0.113678 Validation acc: 0.955000\n",
      "Epoch: 908/1000 Iteration: 8180 Train loss: 0.056884 Train acc: 0.975000\n",
      "Epoch: 909/1000 Iteration: 8185 Train loss: 0.097629 Train acc: 0.948333\n",
      "Epoch: 909/1000 Iteration: 8190 Train loss: 0.082364 Train acc: 0.965000\n",
      "Epoch: 910/1000 Iteration: 8195 Train loss: 0.090955 Train acc: 0.963333\n",
      "Epoch: 911/1000 Iteration: 8200 Train loss: 0.083180 Train acc: 0.961667\n",
      "Epoch: 911/1000 Iteration: 8200 Validation loss: 0.112460 Validation acc: 0.956667\n",
      "Epoch: 911/1000 Iteration: 8205 Train loss: 0.074569 Train acc: 0.970000\n",
      "Epoch: 912/1000 Iteration: 8210 Train loss: 0.066416 Train acc: 0.970000\n",
      "Epoch: 912/1000 Iteration: 8215 Train loss: 0.068951 Train acc: 0.975000\n",
      "Epoch: 913/1000 Iteration: 8220 Train loss: 0.095814 Train acc: 0.955000\n",
      "Epoch: 913/1000 Iteration: 8225 Train loss: 0.061294 Train acc: 0.978333\n",
      "Epoch: 913/1000 Iteration: 8225 Validation loss: 0.113171 Validation acc: 0.956111\n",
      "Epoch: 914/1000 Iteration: 8230 Train loss: 0.107672 Train acc: 0.953333\n",
      "Epoch: 914/1000 Iteration: 8235 Train loss: 0.089125 Train acc: 0.961667\n",
      "Epoch: 915/1000 Iteration: 8240 Train loss: 0.073534 Train acc: 0.960000\n",
      "Epoch: 916/1000 Iteration: 8245 Train loss: 0.075810 Train acc: 0.960000\n",
      "Epoch: 916/1000 Iteration: 8250 Train loss: 0.088618 Train acc: 0.960000\n",
      "Epoch: 916/1000 Iteration: 8250 Validation loss: 0.114647 Validation acc: 0.956667\n",
      "Epoch: 917/1000 Iteration: 8255 Train loss: 0.067619 Train acc: 0.968333\n",
      "Epoch: 917/1000 Iteration: 8260 Train loss: 0.064563 Train acc: 0.981667\n",
      "Epoch: 918/1000 Iteration: 8265 Train loss: 0.082270 Train acc: 0.955000\n",
      "Epoch: 918/1000 Iteration: 8270 Train loss: 0.051529 Train acc: 0.981667\n",
      "Epoch: 919/1000 Iteration: 8275 Train loss: 0.105380 Train acc: 0.955000\n",
      "Epoch: 919/1000 Iteration: 8275 Validation loss: 0.111424 Validation acc: 0.956111\n",
      "Epoch: 919/1000 Iteration: 8280 Train loss: 0.094010 Train acc: 0.958333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 920/1000 Iteration: 8285 Train loss: 0.089890 Train acc: 0.965000\n",
      "Epoch: 921/1000 Iteration: 8290 Train loss: 0.077087 Train acc: 0.973333\n",
      "Epoch: 921/1000 Iteration: 8295 Train loss: 0.074221 Train acc: 0.966667\n",
      "Epoch: 922/1000 Iteration: 8300 Train loss: 0.076144 Train acc: 0.971667\n",
      "Epoch: 922/1000 Iteration: 8300 Validation loss: 0.118856 Validation acc: 0.955000\n",
      "Epoch: 922/1000 Iteration: 8305 Train loss: 0.071350 Train acc: 0.973333\n",
      "Epoch: 923/1000 Iteration: 8310 Train loss: 0.079495 Train acc: 0.966667\n",
      "Epoch: 923/1000 Iteration: 8315 Train loss: 0.054167 Train acc: 0.980000\n",
      "Epoch: 924/1000 Iteration: 8320 Train loss: 0.102846 Train acc: 0.951667\n",
      "Epoch: 924/1000 Iteration: 8325 Train loss: 0.093860 Train acc: 0.956667\n",
      "Epoch: 924/1000 Iteration: 8325 Validation loss: 0.119332 Validation acc: 0.955556\n",
      "Epoch: 925/1000 Iteration: 8330 Train loss: 0.084806 Train acc: 0.965000\n",
      "Epoch: 926/1000 Iteration: 8335 Train loss: 0.074225 Train acc: 0.968333\n",
      "Epoch: 926/1000 Iteration: 8340 Train loss: 0.069638 Train acc: 0.966667\n",
      "Epoch: 927/1000 Iteration: 8345 Train loss: 0.082801 Train acc: 0.968333\n",
      "Epoch: 927/1000 Iteration: 8350 Train loss: 0.069029 Train acc: 0.970000\n",
      "Epoch: 927/1000 Iteration: 8350 Validation loss: 0.114599 Validation acc: 0.955000\n",
      "Epoch: 928/1000 Iteration: 8355 Train loss: 0.081629 Train acc: 0.955000\n",
      "Epoch: 928/1000 Iteration: 8360 Train loss: 0.056961 Train acc: 0.976667\n",
      "Epoch: 929/1000 Iteration: 8365 Train loss: 0.110066 Train acc: 0.951667\n",
      "Epoch: 929/1000 Iteration: 8370 Train loss: 0.089859 Train acc: 0.963333\n",
      "Epoch: 930/1000 Iteration: 8375 Train loss: 0.085872 Train acc: 0.966667\n",
      "Epoch: 930/1000 Iteration: 8375 Validation loss: 0.109580 Validation acc: 0.958333\n",
      "Epoch: 931/1000 Iteration: 8380 Train loss: 0.079114 Train acc: 0.968333\n",
      "Epoch: 931/1000 Iteration: 8385 Train loss: 0.076046 Train acc: 0.965000\n",
      "Epoch: 932/1000 Iteration: 8390 Train loss: 0.063723 Train acc: 0.975000\n",
      "Epoch: 932/1000 Iteration: 8395 Train loss: 0.063777 Train acc: 0.966667\n",
      "Epoch: 933/1000 Iteration: 8400 Train loss: 0.087971 Train acc: 0.958333\n",
      "Epoch: 933/1000 Iteration: 8400 Validation loss: 0.106297 Validation acc: 0.957778\n",
      "Epoch: 933/1000 Iteration: 8405 Train loss: 0.050951 Train acc: 0.975000\n",
      "Epoch: 934/1000 Iteration: 8410 Train loss: 0.112699 Train acc: 0.950000\n",
      "Epoch: 934/1000 Iteration: 8415 Train loss: 0.096863 Train acc: 0.956667\n",
      "Epoch: 935/1000 Iteration: 8420 Train loss: 0.087591 Train acc: 0.965000\n",
      "Epoch: 936/1000 Iteration: 8425 Train loss: 0.083591 Train acc: 0.960000\n",
      "Epoch: 936/1000 Iteration: 8425 Validation loss: 0.120053 Validation acc: 0.954444\n",
      "Epoch: 936/1000 Iteration: 8430 Train loss: 0.073366 Train acc: 0.968333\n",
      "Epoch: 937/1000 Iteration: 8435 Train loss: 0.067171 Train acc: 0.970000\n",
      "Epoch: 937/1000 Iteration: 8440 Train loss: 0.060774 Train acc: 0.978333\n",
      "Epoch: 938/1000 Iteration: 8445 Train loss: 0.082884 Train acc: 0.965000\n",
      "Epoch: 938/1000 Iteration: 8450 Train loss: 0.053192 Train acc: 0.980000\n",
      "Epoch: 938/1000 Iteration: 8450 Validation loss: 0.124909 Validation acc: 0.952222\n",
      "Epoch: 939/1000 Iteration: 8455 Train loss: 0.102004 Train acc: 0.955000\n",
      "Epoch: 939/1000 Iteration: 8460 Train loss: 0.084191 Train acc: 0.965000\n",
      "Epoch: 940/1000 Iteration: 8465 Train loss: 0.080937 Train acc: 0.970000\n",
      "Epoch: 941/1000 Iteration: 8470 Train loss: 0.083869 Train acc: 0.961667\n",
      "Epoch: 941/1000 Iteration: 8475 Train loss: 0.065961 Train acc: 0.975000\n",
      "Epoch: 941/1000 Iteration: 8475 Validation loss: 0.115512 Validation acc: 0.953889\n",
      "Epoch: 942/1000 Iteration: 8480 Train loss: 0.075895 Train acc: 0.968333\n",
      "Epoch: 942/1000 Iteration: 8485 Train loss: 0.058675 Train acc: 0.983333\n",
      "Epoch: 943/1000 Iteration: 8490 Train loss: 0.071856 Train acc: 0.968333\n",
      "Epoch: 943/1000 Iteration: 8495 Train loss: 0.053053 Train acc: 0.978333\n",
      "Epoch: 944/1000 Iteration: 8500 Train loss: 0.111609 Train acc: 0.953333\n",
      "Epoch: 944/1000 Iteration: 8500 Validation loss: 0.113251 Validation acc: 0.957222\n",
      "Epoch: 944/1000 Iteration: 8505 Train loss: 0.100967 Train acc: 0.960000\n",
      "Epoch: 945/1000 Iteration: 8510 Train loss: 0.077566 Train acc: 0.960000\n",
      "Epoch: 946/1000 Iteration: 8515 Train loss: 0.078678 Train acc: 0.963333\n",
      "Epoch: 946/1000 Iteration: 8520 Train loss: 0.067952 Train acc: 0.970000\n",
      "Epoch: 947/1000 Iteration: 8525 Train loss: 0.072860 Train acc: 0.970000\n",
      "Epoch: 947/1000 Iteration: 8525 Validation loss: 0.119033 Validation acc: 0.955556\n",
      "Epoch: 947/1000 Iteration: 8530 Train loss: 0.075820 Train acc: 0.970000\n",
      "Epoch: 948/1000 Iteration: 8535 Train loss: 0.082051 Train acc: 0.958333\n",
      "Epoch: 948/1000 Iteration: 8540 Train loss: 0.051981 Train acc: 0.981667\n",
      "Epoch: 949/1000 Iteration: 8545 Train loss: 0.105914 Train acc: 0.958333\n",
      "Epoch: 949/1000 Iteration: 8550 Train loss: 0.096909 Train acc: 0.958333\n",
      "Epoch: 949/1000 Iteration: 8550 Validation loss: 0.117139 Validation acc: 0.955000\n",
      "Epoch: 950/1000 Iteration: 8555 Train loss: 0.089701 Train acc: 0.958333\n",
      "Epoch: 951/1000 Iteration: 8560 Train loss: 0.077757 Train acc: 0.960000\n",
      "Epoch: 951/1000 Iteration: 8565 Train loss: 0.065516 Train acc: 0.976667\n",
      "Epoch: 952/1000 Iteration: 8570 Train loss: 0.083407 Train acc: 0.980000\n",
      "Epoch: 952/1000 Iteration: 8575 Train loss: 0.085362 Train acc: 0.970000\n",
      "Epoch: 952/1000 Iteration: 8575 Validation loss: 0.110722 Validation acc: 0.957222\n",
      "Epoch: 953/1000 Iteration: 8580 Train loss: 0.091889 Train acc: 0.960000\n",
      "Epoch: 953/1000 Iteration: 8585 Train loss: 0.057602 Train acc: 0.976667\n",
      "Epoch: 954/1000 Iteration: 8590 Train loss: 0.093363 Train acc: 0.965000\n",
      "Epoch: 954/1000 Iteration: 8595 Train loss: 0.093010 Train acc: 0.966667\n",
      "Epoch: 955/1000 Iteration: 8600 Train loss: 0.082522 Train acc: 0.968333\n",
      "Epoch: 955/1000 Iteration: 8600 Validation loss: 0.109771 Validation acc: 0.956667\n",
      "Epoch: 956/1000 Iteration: 8605 Train loss: 0.076737 Train acc: 0.965000\n",
      "Epoch: 956/1000 Iteration: 8610 Train loss: 0.069999 Train acc: 0.963333\n",
      "Epoch: 957/1000 Iteration: 8615 Train loss: 0.073090 Train acc: 0.968333\n",
      "Epoch: 957/1000 Iteration: 8620 Train loss: 0.062072 Train acc: 0.973333\n",
      "Epoch: 958/1000 Iteration: 8625 Train loss: 0.081131 Train acc: 0.961667\n",
      "Epoch: 958/1000 Iteration: 8625 Validation loss: 0.114551 Validation acc: 0.955556\n",
      "Epoch: 958/1000 Iteration: 8630 Train loss: 0.058577 Train acc: 0.973333\n",
      "Epoch: 959/1000 Iteration: 8635 Train loss: 0.103975 Train acc: 0.946667\n",
      "Epoch: 959/1000 Iteration: 8640 Train loss: 0.091709 Train acc: 0.963333\n",
      "Epoch: 960/1000 Iteration: 8645 Train loss: 0.084483 Train acc: 0.961667\n",
      "Epoch: 961/1000 Iteration: 8650 Train loss: 0.084053 Train acc: 0.965000\n",
      "Epoch: 961/1000 Iteration: 8650 Validation loss: 0.118386 Validation acc: 0.956667\n",
      "Epoch: 961/1000 Iteration: 8655 Train loss: 0.076767 Train acc: 0.960000\n",
      "Epoch: 962/1000 Iteration: 8660 Train loss: 0.072290 Train acc: 0.971667\n",
      "Epoch: 962/1000 Iteration: 8665 Train loss: 0.067917 Train acc: 0.970000\n",
      "Epoch: 963/1000 Iteration: 8670 Train loss: 0.087891 Train acc: 0.956667\n",
      "Epoch: 963/1000 Iteration: 8675 Train loss: 0.049017 Train acc: 0.975000\n",
      "Epoch: 963/1000 Iteration: 8675 Validation loss: 0.119821 Validation acc: 0.954444\n",
      "Epoch: 964/1000 Iteration: 8680 Train loss: 0.109656 Train acc: 0.948333\n",
      "Epoch: 964/1000 Iteration: 8685 Train loss: 0.092287 Train acc: 0.956667\n",
      "Epoch: 965/1000 Iteration: 8690 Train loss: 0.070900 Train acc: 0.963333\n",
      "Epoch: 966/1000 Iteration: 8695 Train loss: 0.074555 Train acc: 0.973333\n",
      "Epoch: 966/1000 Iteration: 8700 Train loss: 0.072339 Train acc: 0.971667\n",
      "Epoch: 966/1000 Iteration: 8700 Validation loss: 0.117037 Validation acc: 0.955556\n",
      "Epoch: 967/1000 Iteration: 8705 Train loss: 0.077836 Train acc: 0.965000\n",
      "Epoch: 967/1000 Iteration: 8710 Train loss: 0.060208 Train acc: 0.973333\n",
      "Epoch: 968/1000 Iteration: 8715 Train loss: 0.094147 Train acc: 0.961667\n",
      "Epoch: 968/1000 Iteration: 8720 Train loss: 0.068814 Train acc: 0.975000\n",
      "Epoch: 969/1000 Iteration: 8725 Train loss: 0.111729 Train acc: 0.951667\n",
      "Epoch: 969/1000 Iteration: 8725 Validation loss: 0.124171 Validation acc: 0.956667\n",
      "Epoch: 969/1000 Iteration: 8730 Train loss: 0.113222 Train acc: 0.956667\n",
      "Epoch: 970/1000 Iteration: 8735 Train loss: 0.084236 Train acc: 0.966667\n",
      "Epoch: 971/1000 Iteration: 8740 Train loss: 0.074158 Train acc: 0.961667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 971/1000 Iteration: 8745 Train loss: 0.076027 Train acc: 0.970000\n",
      "Epoch: 972/1000 Iteration: 8750 Train loss: 0.066652 Train acc: 0.973333\n",
      "Epoch: 972/1000 Iteration: 8750 Validation loss: 0.120647 Validation acc: 0.958333\n",
      "Epoch: 972/1000 Iteration: 8755 Train loss: 0.064651 Train acc: 0.975000\n",
      "Epoch: 973/1000 Iteration: 8760 Train loss: 0.079711 Train acc: 0.966667\n",
      "Epoch: 973/1000 Iteration: 8765 Train loss: 0.053569 Train acc: 0.980000\n",
      "Epoch: 974/1000 Iteration: 8770 Train loss: 0.113256 Train acc: 0.948333\n",
      "Epoch: 974/1000 Iteration: 8775 Train loss: 0.088584 Train acc: 0.961667\n",
      "Epoch: 974/1000 Iteration: 8775 Validation loss: 0.119525 Validation acc: 0.956667\n",
      "Epoch: 975/1000 Iteration: 8780 Train loss: 0.090378 Train acc: 0.961667\n",
      "Epoch: 976/1000 Iteration: 8785 Train loss: 0.069613 Train acc: 0.971667\n",
      "Epoch: 976/1000 Iteration: 8790 Train loss: 0.059444 Train acc: 0.978333\n",
      "Epoch: 977/1000 Iteration: 8795 Train loss: 0.076061 Train acc: 0.966667\n",
      "Epoch: 977/1000 Iteration: 8800 Train loss: 0.071752 Train acc: 0.970000\n",
      "Epoch: 977/1000 Iteration: 8800 Validation loss: 0.111530 Validation acc: 0.957778\n",
      "Epoch: 978/1000 Iteration: 8805 Train loss: 0.088944 Train acc: 0.956667\n",
      "Epoch: 978/1000 Iteration: 8810 Train loss: 0.049862 Train acc: 0.976667\n",
      "Epoch: 979/1000 Iteration: 8815 Train loss: 0.109460 Train acc: 0.950000\n",
      "Epoch: 979/1000 Iteration: 8820 Train loss: 0.088095 Train acc: 0.963333\n",
      "Epoch: 980/1000 Iteration: 8825 Train loss: 0.079504 Train acc: 0.963333\n",
      "Epoch: 980/1000 Iteration: 8825 Validation loss: 0.097018 Validation acc: 0.953333\n",
      "Epoch: 981/1000 Iteration: 8830 Train loss: 0.070606 Train acc: 0.965000\n",
      "Epoch: 981/1000 Iteration: 8835 Train loss: 0.068107 Train acc: 0.971667\n",
      "Epoch: 982/1000 Iteration: 8840 Train loss: 0.080157 Train acc: 0.973333\n",
      "Epoch: 982/1000 Iteration: 8845 Train loss: 0.059500 Train acc: 0.975000\n",
      "Epoch: 983/1000 Iteration: 8850 Train loss: 0.077928 Train acc: 0.961667\n",
      "Epoch: 983/1000 Iteration: 8850 Validation loss: 0.109884 Validation acc: 0.957778\n",
      "Epoch: 983/1000 Iteration: 8855 Train loss: 0.047328 Train acc: 0.983333\n",
      "Epoch: 984/1000 Iteration: 8860 Train loss: 0.123671 Train acc: 0.946667\n",
      "Epoch: 984/1000 Iteration: 8865 Train loss: 0.090566 Train acc: 0.956667\n",
      "Epoch: 985/1000 Iteration: 8870 Train loss: 0.076829 Train acc: 0.971667\n",
      "Epoch: 986/1000 Iteration: 8875 Train loss: 0.073582 Train acc: 0.966667\n",
      "Epoch: 986/1000 Iteration: 8875 Validation loss: 0.121004 Validation acc: 0.956667\n",
      "Epoch: 986/1000 Iteration: 8880 Train loss: 0.067996 Train acc: 0.970000\n",
      "Epoch: 987/1000 Iteration: 8885 Train loss: 0.073644 Train acc: 0.970000\n",
      "Epoch: 987/1000 Iteration: 8890 Train loss: 0.066204 Train acc: 0.970000\n",
      "Epoch: 988/1000 Iteration: 8895 Train loss: 0.077444 Train acc: 0.958333\n",
      "Epoch: 988/1000 Iteration: 8900 Train loss: 0.047243 Train acc: 0.986667\n",
      "Epoch: 988/1000 Iteration: 8900 Validation loss: 0.107780 Validation acc: 0.957222\n",
      "Epoch: 989/1000 Iteration: 8905 Train loss: 0.091299 Train acc: 0.961667\n",
      "Epoch: 989/1000 Iteration: 8910 Train loss: 0.100508 Train acc: 0.956667\n",
      "Epoch: 990/1000 Iteration: 8915 Train loss: 0.077976 Train acc: 0.966667\n",
      "Epoch: 991/1000 Iteration: 8920 Train loss: 0.066196 Train acc: 0.976667\n",
      "Epoch: 991/1000 Iteration: 8925 Train loss: 0.065296 Train acc: 0.965000\n",
      "Epoch: 991/1000 Iteration: 8925 Validation loss: 0.115705 Validation acc: 0.956667\n",
      "Epoch: 992/1000 Iteration: 8930 Train loss: 0.068280 Train acc: 0.973333\n",
      "Epoch: 992/1000 Iteration: 8935 Train loss: 0.062614 Train acc: 0.971667\n",
      "Epoch: 993/1000 Iteration: 8940 Train loss: 0.072751 Train acc: 0.971667\n",
      "Epoch: 993/1000 Iteration: 8945 Train loss: 0.052150 Train acc: 0.976667\n",
      "Epoch: 994/1000 Iteration: 8950 Train loss: 0.103501 Train acc: 0.948333\n",
      "Epoch: 994/1000 Iteration: 8950 Validation loss: 0.127568 Validation acc: 0.955000\n",
      "Epoch: 994/1000 Iteration: 8955 Train loss: 0.093660 Train acc: 0.965000\n",
      "Epoch: 995/1000 Iteration: 8960 Train loss: 0.086334 Train acc: 0.960000\n",
      "Epoch: 996/1000 Iteration: 8965 Train loss: 0.090621 Train acc: 0.960000\n",
      "Epoch: 996/1000 Iteration: 8970 Train loss: 0.070725 Train acc: 0.971667\n",
      "Epoch: 997/1000 Iteration: 8975 Train loss: 0.065386 Train acc: 0.978333\n",
      "Epoch: 997/1000 Iteration: 8975 Validation loss: 0.123023 Validation acc: 0.956667\n",
      "Epoch: 997/1000 Iteration: 8980 Train loss: 0.072501 Train acc: 0.973333\n",
      "Epoch: 998/1000 Iteration: 8985 Train loss: 0.076436 Train acc: 0.960000\n",
      "Epoch: 998/1000 Iteration: 8990 Train loss: 0.051834 Train acc: 0.983333\n"
     ]
    }
   ],
   "source": [
    "validation_acc = []\n",
    "validation_loss = []\n",
    "\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "with graph.as_default():\n",
    "    saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    iteration = 1\n",
    "    \n",
    "    for e in range(epochs):\n",
    "        # Initialize \n",
    "        state = sess.run(initial_state)\n",
    "        \n",
    "        # Loop over batches\n",
    "        for x,y in get_batches(X_tr, y_tr, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : 0.5, \n",
    "                    initial_state : state, learning_rate_ : learning_rate}\n",
    "            \n",
    "            loss, _ , state, acc = sess.run([cost, optimizer, final_state, accuracy], \n",
    "                                             feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            # Print at each 5 iters\n",
    "            if (iteration % 5 == 0):\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Train loss: {:6f}\".format(loss),\n",
    "                      \"Train acc: {:.6f}\".format(acc))\n",
    "            \n",
    "            # Compute validation loss at every 25 iterations\n",
    "            if (iteration%25 == 0):\n",
    "                \n",
    "                # Initiate for validation set\n",
    "                val_state = sess.run(cell.zero_state(batch_size, tf.float32))\n",
    "                \n",
    "                val_acc_ = []\n",
    "                val_loss_ = []\n",
    "                for x_v, y_v in get_batches(X_vld, y_vld, batch_size):\n",
    "                    # Feed\n",
    "                    feed = {inputs_ : x_v, labels_ : y_v, keep_prob_ : 1.0, initial_state : val_state}\n",
    "                    \n",
    "                    # Loss\n",
    "                    loss_v, state_v, acc_v = sess.run([cost, final_state, accuracy], feed_dict = feed)\n",
    "                    \n",
    "                    val_acc_.append(acc_v)\n",
    "                    val_loss_.append(loss_v)\n",
    "                \n",
    "                # Print info\n",
    "                print(\"Epoch: {}/{}\".format(e, epochs),\n",
    "                      \"Iteration: {:d}\".format(iteration),\n",
    "                      \"Validation loss: {:6f}\".format(np.mean(val_loss_)),\n",
    "                      \"Validation acc: {:.6f}\".format(np.mean(val_acc_)))\n",
    "                \n",
    "                # Store\n",
    "                validation_acc.append(np.mean(val_acc_))\n",
    "                validation_loss.append(np.mean(val_loss_))\n",
    "            \n",
    "            # Iterate \n",
    "            iteration += 1\n",
    "    \n",
    "    saver.save(sess,\"checkpoints-crnn/har.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYwAAAF3CAYAAAC2bHyQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2983a8e278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot training and test loss\n",
    "t = np.arange(iteration-1)\n",
    "\n",
    "plt.figure(figsize = (6,6))\n",
    "plt.plot(t, np.array(train_loss), 'r-', t[t % 25 == 0], np.array(validation_loss), 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Loss\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAF3CAYAAABKeVdaAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSgoiIpLy/wPZfIJjHXqNXAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2983a8e390>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot Accuracies\n",
    "plt.figure(figsize = (6,6))\n",
    "\n",
    "plt.plot(t, np.array(train_acc), 'r-', t[t % 25 == 0], validation_acc, 'b*')\n",
    "plt.xlabel(\"iteration\")\n",
    "plt.ylabel(\"Accuray\")\n",
    "plt.legend(['train', 'validation'], loc='upper right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.892917\n"
     ]
    }
   ],
   "source": [
    "test_acc = []\n",
    "\n",
    "with tf.Session(graph=graph) as sess:\n",
    "    # Restore\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints-crnn'))\n",
    "    \n",
    "    for x_t, y_t in get_batches(X_test, y_test, batch_size):\n",
    "        feed = {inputs_: x_t,\n",
    "                labels_: y_t,\n",
    "                keep_prob_: 1}\n",
    "        \n",
    "        batch_acc = sess.run(accuracy, feed_dict=feed)\n",
    "        test_acc.append(batch_acc)\n",
    "    print(\"Test accuracy: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
