{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6480, 192, 64) (6480,) float64 float64\n",
      "(4536, 192, 64) (1944, 192, 64)\n",
      "(3176, 192, 64) (1360, 192, 64)\n",
      "(3176, 192, 64) float64 (1360, 192, 64) float64 (1944, 192, 64) float64\n",
      "(6480,) (4536,) (1944,)\n",
      "(3176,) (1360,)\n",
      "(3176,) int64 (1944,) int64 (1360,) int64\n",
      "(3176, 2) (1360, 2) (1944, 2) (3176, 192, 64) (1360, 192, 64) (1944, 192, 64)\n",
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "X = spio.loadmat(file_name='../data/bci-sample-data/x.mat')\n",
    "Y = spio.loadmat(file_name='../data/bci-sample-data/y.mat')\n",
    "\n",
    "Data = X['Intensification_Data']\n",
    "SType = Y['Intensification_SType'].mean(axis=1)\n",
    "\n",
    "print(Data.shape, SType.shape, Data.dtype, SType.dtype)\n",
    "\n",
    "# 30 % total data test\n",
    "# 70 % total data train+valid\n",
    "length = int(Data.shape[0] * 0.30)\n",
    "# length\n",
    "\n",
    "TrainDataAll = Data[:-length]\n",
    "TestData = Data[-length:]\n",
    "\n",
    "print(TrainDataAll.shape, TestData.shape)\n",
    "\n",
    "# 30% total train data is valid\n",
    "# 70% total trainALl is training\n",
    "length2 = int(TrainDataAll.shape[0] * 0.30)\n",
    "# length2\n",
    "\n",
    "TrainData = TrainDataAll[:-length2]\n",
    "ValidData = TrainDataAll[-length2:]\n",
    "\n",
    "print(TrainData.shape, ValidData.shape)\n",
    "\n",
    "# Normalizing input data\n",
    "def normalize(inputs):\n",
    "    return (inputs - inputs.mean(axis=0)[None,:,:]) / inputs.std(axis=0)[None,:,:]\n",
    "\n",
    "# onehot vectorizing output labels\n",
    "def one_hot(labels, n_class):\n",
    "    \"\"\" One-hot encoding \"\"\"\n",
    "    expansion = np.eye(n_class)\n",
    "    y = expansion[:, labels-1].T\n",
    "    assert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "    return y\n",
    "\n",
    "# get minibatches for learning\n",
    "def get_batches(X, y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]\n",
    "\n",
    "# Standardize/normalize train and test\n",
    "X_train_norm = normalize(inputs=TrainData)\n",
    "X_valid_norm = normalize(inputs=ValidData)\n",
    "X_test_norm = normalize(inputs=TestData)\n",
    "\n",
    "print(X_train_norm.shape, X_train_norm.dtype, \n",
    "X_valid_norm.shape, X_valid_norm.dtype,\n",
    "X_test_norm.shape, X_test_norm.dtype)\n",
    "\n",
    "LabelsAll = SType[:]\n",
    "TrainLabelsAll = SType[:-length]\n",
    "TestLabels = SType[-length:]\n",
    "\n",
    "print(LabelsAll.shape, TrainLabelsAll.shape, TestLabels.shape)\n",
    "\n",
    "TrainLabels = TrainLabelsAll[:-length2]\n",
    "ValidLabels = TrainLabelsAll[-length2:]\n",
    "\n",
    "print(TrainLabels.shape, ValidLabels.shape)\n",
    "\n",
    "Y_train = np.array(TrainLabels, dtype=int)\n",
    "Y_valid = np.array(ValidLabels, dtype=int)\n",
    "Y_test = np.array(TestLabels, dtype=int)\n",
    "\n",
    "print(Y_train.shape, Y_train.dtype, \n",
    "Y_test.shape, Y_test.dtype,\n",
    "Y_valid.shape, Y_valid.dtype)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "# CNN hyper parameters\n",
    "# Input data\n",
    "batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "\n",
    "# Output labels\n",
    "n_classes = int(LabelsAll.max() + 1)\n",
    "\n",
    "# Tweekable parameters\n",
    "learning_rate = 0.001 #1e-3\n",
    "epochs = 10 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out\n",
    "\n",
    "Y_train_onehot = one_hot(labels=Y_train, n_class=n_classes)\n",
    "Y_valid_onehot = one_hot(labels=Y_valid, n_class=n_classes)\n",
    "Y_test_onehot = one_hot(labels=Y_test, n_class=n_classes)\n",
    "\n",
    "print(Y_train_onehot.shape, Y_valid_onehot.shape, Y_test_onehot.shape,\n",
    " X_train_norm.shape, X_valid_norm.shape, X_test_norm.shape)\n",
    "\n",
    "# GPUs availability or CPU\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "#  No graphs is needed on tensorflow\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 94, 128)\n",
      "(?, 45, 256)\n",
      "(?, 11520) (?, 23040)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Convolutional Layers, FC Layer, and Output layer\n",
    "# (batch, 192, 64) --> (batch, 94, 128)\n",
    "# (192 - 6 + 0)/2 + 1 = (186/2)+1= 93+1= 94\n",
    "# (2/6)==(1/3) with strides/kernel_size is 33.333% non-overlap/diff region and \n",
    "# 66.666% overlapping window/ common region\n",
    "in_conv = inputs_\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=128, kernel_size=6, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(out_conv.shape)\n",
    "\n",
    "# (batch, 94, 128) --> (batch, 45, 256)\n",
    "# (94 - 6 + 0)/2 + 1 = (88/2)+1= 44+1= 45\n",
    "# (2/6)==(1/3) with strides/kernel_size is 33.333% non-overlap/diff region and \n",
    "# 66.666% overlapping window/ common region\n",
    "in_conv = out_conv\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=256, kernel_size=6, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(out_conv.shape)\n",
    "\n",
    "# (batch, 45, 256) --> (batch, 45*256) --> (batch, 45*256*2)\n",
    "in_fc = tf.reshape(tensor=out_conv, shape=(-1, 45*256))\n",
    "out_fc = tf.layers.dense(inputs=in_fc, units=45*256*2)\n",
    "out_fc = tf.layers.batch_normalization(inputs=out_fc)\n",
    "out_fc = tf.nn.relu(features=out_fc)\n",
    "out_fc = tf.nn.dropout(x=out_fc, keep_prob=keep_prob_)\n",
    "print(in_fc.shape, out_fc.shape)\n",
    "\n",
    "# (batch, 49*64*2) --> (batch, 2) \n",
    "logits = tf.layers.dense(inputs=out_fc, units=n_classes)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 1.212925 Valid loss: 39.670612 Train acc: 0.419355 Valid acc: 0.833458\n",
      "Epoch: 1/10 Train loss: 97.321121 Valid loss: 32.678665 Train acc: 0.806452 Valid acc: 0.833458\n",
      "Epoch: 1/10 Train loss: 58.111832 Valid loss: 25.682856 Train acc: 0.806452 Valid acc: 0.833458\n",
      "Epoch: 1/10 Train loss: 15.701215 Valid loss: 20.349094 Train acc: 0.870968 Valid acc: 0.833458\n",
      "Epoch: 1/10 Train loss: 10.034811 Valid loss: 16.515396 Train acc: 0.806452 Valid acc: 0.833458\n",
      "Epoch: 1/10 Train loss: 2.706568 Valid loss: 13.877476 Train acc: 0.870968 Valid acc: 0.788197\n",
      "Epoch: 1/10 Train loss: 1.271901 Valid loss: 12.119920 Train acc: 0.806452 Valid acc: 0.701104\n",
      "Epoch: 1/10 Train loss: 0.850224 Valid loss: 10.802660 Train acc: 0.516129 Valid acc: 0.634752\n",
      "Epoch: 1/10 Train loss: 1.954910 Valid loss: 9.740643 Train acc: 0.161290 Valid acc: 0.583062\n",
      "Epoch: 1/10 Train loss: 2.923816 Valid loss: 8.853546 Train acc: 0.161290 Valid acc: 0.543436\n",
      "Epoch: 1/10 Train loss: 0.994185 Valid loss: 8.113614 Train acc: 0.225806 Valid acc: 0.522471\n",
      "Epoch: 1/10 Train loss: 0.727563 Valid loss: 7.491720 Train acc: 0.580645 Valid acc: 0.546449\n",
      "Epoch: 1/10 Train loss: 0.494152 Valid loss: 6.963494 Train acc: 0.838710 Valid acc: 0.568469\n",
      "Epoch: 1/10 Train loss: 0.583247 Valid loss: 6.510262 Train acc: 0.806452 Valid acc: 0.587397\n",
      "Epoch: 1/10 Train loss: 0.377030 Valid loss: 6.117144 Train acc: 0.870968 Valid acc: 0.603801\n",
      "Epoch: 1/10 Train loss: 0.517446 Valid loss: 5.772867 Train acc: 0.806452 Valid acc: 0.618155\n",
      "Epoch: 1/10 Train loss: 0.468555 Valid loss: 5.468952 Train acc: 0.838710 Valid acc: 0.630819\n",
      "Epoch: 1/10 Train loss: 0.545566 Valid loss: 5.198510 Train acc: 0.838710 Valid acc: 0.642077\n",
      "Epoch: 1/10 Train loss: 0.491420 Valid loss: 4.955949 Train acc: 0.838710 Valid acc: 0.652150\n",
      "Epoch: 1/10 Train loss: 0.503072 Valid loss: 4.736830 Train acc: 0.806452 Valid acc: 0.661215\n",
      "Epoch: 1/10 Train loss: 0.415322 Valid loss: 4.537701 Train acc: 0.838710 Valid acc: 0.669417\n",
      "Epoch: 1/10 Train loss: 0.452120 Valid loss: 4.356446 Train acc: 0.838710 Valid acc: 0.676874\n",
      "Epoch: 1/10 Train loss: 0.445115 Valid loss: 4.191397 Train acc: 0.838710 Valid acc: 0.683682\n",
      "Epoch: 1/10 Train loss: 0.539469 Valid loss: 4.040350 Train acc: 0.838710 Valid acc: 0.689922\n",
      "Epoch: 1/10 Train loss: 0.459690 Valid loss: 3.901821 Train acc: 0.870968 Valid acc: 0.695664\n",
      "Epoch: 1/10 Train loss: 0.625900 Valid loss: 3.774760 Train acc: 0.806452 Valid acc: 0.700964\n",
      "Epoch: 1/10 Train loss: 0.461997 Valid loss: 3.657198 Train acc: 0.838710 Valid acc: 0.705871\n",
      "Epoch: 1/10 Train loss: 0.505838 Valid loss: 3.548008 Train acc: 0.806452 Valid acc: 0.710427\n",
      "Epoch: 1/10 Train loss: 0.455530 Valid loss: 3.446232 Train acc: 0.838710 Valid acc: 0.714670\n",
      "Epoch: 1/10 Train loss: 0.440954 Valid loss: 3.351050 Train acc: 0.838710 Valid acc: 0.718630\n",
      "Epoch: 1/10 Train loss: 0.460216 Valid loss: 3.261757 Train acc: 0.838710 Valid acc: 0.722334\n",
      "Epoch: 1/10 Train loss: 0.546911 Valid loss: 3.177739 Train acc: 0.870968 Valid acc: 0.725806\n",
      "Epoch: 1/10 Train loss: 0.520658 Valid loss: 3.098549 Train acc: 0.806452 Valid acc: 0.729069\n",
      "Epoch: 1/10 Train loss: 0.452996 Valid loss: 3.023706 Train acc: 0.838710 Valid acc: 0.732139\n",
      "Epoch: 1/10 Train loss: 0.685693 Valid loss: 2.952907 Train acc: 0.806452 Valid acc: 0.735034\n",
      "Epoch: 1/10 Train loss: 0.465771 Valid loss: 2.886001 Train acc: 0.838710 Valid acc: 0.737768\n",
      "Epoch: 1/10 Train loss: 0.499587 Valid loss: 2.822681 Train acc: 0.838710 Valid acc: 0.740354\n",
      "Epoch: 1/10 Train loss: 0.444560 Valid loss: 2.762701 Train acc: 0.838710 Valid acc: 0.742804\n",
      "Epoch: 1/10 Train loss: 0.745530 Valid loss: 2.705924 Train acc: 0.806452 Valid acc: 0.745129\n",
      "Epoch: 1/10 Train loss: 0.432328 Valid loss: 2.652133 Train acc: 0.838710 Valid acc: 0.747337\n",
      "Epoch: 1/10 Train loss: 0.449743 Valid loss: 2.601044 Train acc: 0.838710 Valid acc: 0.749437\n",
      "Epoch: 1/10 Train loss: 0.479279 Valid loss: 2.552425 Train acc: 0.806452 Valid acc: 0.751438\n",
      "Epoch: 1/10 Train loss: 0.489141 Valid loss: 2.506051 Train acc: 0.870968 Valid acc: 0.753345\n",
      "Epoch: 1/10 Train loss: 0.514766 Valid loss: 2.461735 Train acc: 0.806452 Valid acc: 0.755166\n",
      "Epoch: 1/10 Train loss: 0.491214 Valid loss: 2.419299 Train acc: 0.870968 Valid acc: 0.756906\n",
      "Epoch: 1/10 Train loss: 0.537884 Valid loss: 2.378587 Train acc: 0.806452 Valid acc: 0.758570\n",
      "Epoch: 1/10 Train loss: 0.537737 Valid loss: 2.339434 Train acc: 0.806452 Valid acc: 0.760163\n",
      "Epoch: 1/10 Train loss: 0.374612 Valid loss: 2.301669 Train acc: 0.870968 Valid acc: 0.761690\n",
      "Epoch: 1/10 Train loss: 0.658181 Valid loss: 2.265384 Train acc: 0.838710 Valid acc: 0.763155\n",
      "Epoch: 1/10 Train loss: 0.460316 Valid loss: 2.230500 Train acc: 0.838710 Valid acc: 0.764561\n",
      "Epoch: 1/10 Train loss: 0.490704 Valid loss: 2.196930 Train acc: 0.806452 Valid acc: 0.765912\n",
      "Epoch: 1/10 Train loss: 0.497349 Valid loss: 2.164582 Train acc: 0.838710 Valid acc: 0.767211\n",
      "Epoch: 1/10 Train loss: 0.707429 Valid loss: 2.133447 Train acc: 0.838710 Valid acc: 0.768461\n",
      "Epoch: 1/10 Train loss: 0.621040 Valid loss: 2.103510 Train acc: 0.838710 Valid acc: 0.769665\n",
      "Epoch: 1/10 Train loss: 0.437075 Valid loss: 2.074684 Train acc: 0.838710 Valid acc: 0.770824\n",
      "Epoch: 1/10 Train loss: 0.465267 Valid loss: 2.046876 Train acc: 0.838710 Valid acc: 0.771943\n",
      "Epoch: 1/10 Train loss: 0.521125 Valid loss: 2.020011 Train acc: 0.806452 Valid acc: 0.773022\n",
      "Epoch: 1/10 Train loss: 0.470456 Valid loss: 1.994006 Train acc: 0.838710 Valid acc: 0.774064\n",
      "Epoch: 1/10 Train loss: 0.444251 Valid loss: 1.968868 Train acc: 0.838710 Valid acc: 0.775071\n",
      "Epoch: 1/10 Train loss: 0.487463 Valid loss: 1.944531 Train acc: 0.838710 Valid acc: 0.776044\n",
      "Epoch: 1/10 Train loss: 0.582158 Valid loss: 1.920973 Train acc: 0.806452 Valid acc: 0.776985\n",
      "Epoch: 1/10 Train loss: 0.462941 Valid loss: 1.898126 Train acc: 0.870968 Valid acc: 0.777896\n",
      "Epoch: 1/10 Train loss: 0.502370 Valid loss: 1.875939 Train acc: 0.806452 Valid acc: 0.778778\n",
      "Epoch: 1/10 Train loss: 0.438034 Valid loss: 1.854361 Train acc: 0.870968 Valid acc: 0.779632\n",
      "Epoch: 1/10 Train loss: 0.478537 Valid loss: 1.833361 Train acc: 0.806452 Valid acc: 0.780460\n",
      "Epoch: 1/10 Train loss: 0.475590 Valid loss: 1.812914 Train acc: 0.838710 Valid acc: 0.781263\n",
      "Epoch: 1/10 Train loss: 0.498281 Valid loss: 1.793031 Train acc: 0.806452 Valid acc: 0.782043\n",
      "Epoch: 1/10 Train loss: 0.415838 Valid loss: 1.773718 Train acc: 0.870968 Valid acc: 0.782799\n",
      "Epoch: 1/10 Train loss: 0.463692 Valid loss: 1.754979 Train acc: 0.838710 Valid acc: 0.783533\n",
      "Epoch: 1/10 Train loss: 0.588963 Valid loss: 1.736715 Train acc: 0.806452 Valid acc: 0.784246\n",
      "Epoch: 1/10 Train loss: 0.621077 Valid loss: 1.718960 Train acc: 0.838710 Valid acc: 0.784939\n",
      "Epoch: 1/10 Train loss: 0.404858 Valid loss: 1.701716 Train acc: 0.838710 Valid acc: 0.785613\n",
      "Epoch: 1/10 Train loss: 0.425908 Valid loss: 1.684967 Train acc: 0.838710 Valid acc: 0.786268\n",
      "Epoch: 1/10 Train loss: 0.506524 Valid loss: 1.668705 Train acc: 0.806452 Valid acc: 0.786906\n",
      "Epoch: 1/10 Train loss: 0.427438 Valid loss: 1.652900 Train acc: 0.870968 Valid acc: 0.787527\n",
      "Epoch: 1/10 Train loss: 0.429858 Valid loss: 1.637523 Train acc: 0.838710 Valid acc: 0.788131\n",
      "Epoch: 1/10 Train loss: 0.494342 Valid loss: 1.622554 Train acc: 0.806452 Valid acc: 0.788720\n",
      "Epoch: 1/10 Train loss: 0.457050 Valid loss: 1.607965 Train acc: 0.838710 Valid acc: 0.789293\n",
      "Epoch: 1/10 Train loss: 0.517018 Valid loss: 1.593734 Train acc: 0.806452 Valid acc: 0.789852\n",
      "Epoch: 1/10 Train loss: 0.420994 Valid loss: 1.579832 Train acc: 0.870968 Valid acc: 0.790398\n",
      "Epoch: 1/10 Train loss: 0.443690 Valid loss: 1.566239 Train acc: 0.838710 Valid acc: 0.790929\n",
      "Epoch: 1/10 Train loss: 0.707383 Valid loss: 1.552984 Train acc: 0.806452 Valid acc: 0.791448\n",
      "Epoch: 1/10 Train loss: 0.450180 Valid loss: 1.540048 Train acc: 0.838710 Valid acc: 0.791954\n",
      "Epoch: 1/10 Train loss: 0.460432 Valid loss: 1.527413 Train acc: 0.838710 Valid acc: 0.792448\n",
      "Epoch: 1/10 Train loss: 0.466653 Valid loss: 1.515060 Train acc: 0.838710 Valid acc: 0.792931\n",
      "Epoch: 1/10 Train loss: 0.439285 Valid loss: 1.502974 Train acc: 0.838710 Valid acc: 0.793402\n",
      "Epoch: 1/10 Train loss: 0.471283 Valid loss: 1.491145 Train acc: 0.806452 Valid acc: 0.793862\n",
      "Epoch: 1/10 Train loss: 0.519778 Valid loss: 1.479574 Train acc: 0.806452 Valid acc: 0.794312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 0.379939 Valid loss: 1.468244 Train acc: 0.870968 Valid acc: 0.794752\n",
      "Epoch: 1/10 Train loss: 0.425338 Valid loss: 1.457146 Train acc: 0.838710 Valid acc: 0.795182\n",
      "Epoch: 1/10 Train loss: 0.514423 Valid loss: 1.446270 Train acc: 0.838710 Valid acc: 0.795603\n",
      "Epoch: 1/10 Train loss: 0.489231 Valid loss: 1.435620 Train acc: 0.838710 Valid acc: 0.796014\n",
      "Epoch: 1/10 Train loss: 0.492489 Valid loss: 1.425187 Train acc: 0.806452 Valid acc: 0.796417\n",
      "Epoch: 1/10 Train loss: 0.435183 Valid loss: 1.414961 Train acc: 0.870968 Valid acc: 0.796811\n",
      "Epoch: 1/10 Train loss: 0.479688 Valid loss: 1.404938 Train acc: 0.806452 Valid acc: 0.797197\n",
      "Epoch: 1/10 Train loss: 0.440341 Valid loss: 1.395110 Train acc: 0.838710 Valid acc: 0.797574\n",
      "Epoch: 1/10 Train loss: 0.477896 Valid loss: 1.385480 Train acc: 0.838710 Valid acc: 0.797944\n",
      "Epoch: 1/10 Train loss: 0.470655 Valid loss: 1.376048 Train acc: 0.838710 Valid acc: 0.798307\n",
      "Epoch: 1/10 Train loss: 0.513425 Valid loss: 1.366810 Train acc: 0.806452 Valid acc: 0.798662\n",
      "Epoch: 1/10 Train loss: 0.410370 Valid loss: 1.357759 Train acc: 0.838710 Valid acc: 0.799010\n",
      "Epoch: 1/10 Train loss: 0.452241 Valid loss: 1.348888 Train acc: 0.838710 Valid acc: 0.799351\n",
      "Epoch: 1/10 Train loss: 0.418318 Valid loss: 1.340189 Train acc: 0.838710 Valid acc: 0.799685\n",
      "Epoch: 2/10 Train loss: 1.144692 Valid loss: 1.331686 Train acc: 0.870968 Valid acc: 0.800013\n",
      "Epoch: 2/10 Train loss: 0.765911 Valid loss: 1.323399 Train acc: 0.806452 Valid acc: 0.800335\n",
      "Epoch: 2/10 Train loss: 0.550915 Valid loss: 1.315331 Train acc: 0.806452 Valid acc: 0.800650\n",
      "Epoch: 2/10 Train loss: 0.481962 Valid loss: 1.307459 Train acc: 0.870968 Valid acc: 0.800960\n",
      "Epoch: 2/10 Train loss: 0.487312 Valid loss: 1.299764 Train acc: 0.806452 Valid acc: 0.801263\n",
      "Epoch: 2/10 Train loss: 0.441835 Valid loss: 1.292216 Train acc: 0.870968 Valid acc: 0.801561\n",
      "Epoch: 2/10 Train loss: 0.531842 Valid loss: 1.284802 Train acc: 0.806452 Valid acc: 0.801854\n",
      "Epoch: 2/10 Train loss: 0.532880 Valid loss: 1.277501 Train acc: 0.806452 Valid acc: 0.802141\n",
      "Epoch: 2/10 Train loss: 0.510892 Valid loss: 1.270296 Train acc: 0.806452 Valid acc: 0.802423\n",
      "Epoch: 2/10 Train loss: 0.510987 Valid loss: 1.263173 Train acc: 0.838710 Valid acc: 0.802701\n",
      "Epoch: 2/10 Train loss: 0.403798 Valid loss: 1.256119 Train acc: 0.870968 Valid acc: 0.802973\n",
      "Epoch: 2/10 Train loss: 0.477758 Valid loss: 1.249137 Train acc: 0.806452 Valid acc: 0.803240\n",
      "Epoch: 2/10 Train loss: 0.475937 Valid loss: 1.242257 Train acc: 0.838710 Valid acc: 0.803503\n",
      "Epoch: 2/10 Train loss: 0.581876 Valid loss: 1.235519 Train acc: 0.806452 Valid acc: 0.803761\n",
      "Epoch: 2/10 Train loss: 0.377985 Valid loss: 1.228954 Train acc: 0.870968 Valid acc: 0.804015\n",
      "Epoch: 2/10 Train loss: 0.482091 Valid loss: 1.222598 Train acc: 0.806452 Valid acc: 0.804265\n",
      "Epoch: 2/10 Train loss: 0.593620 Valid loss: 1.216224 Train acc: 0.838710 Valid acc: 0.804510\n",
      "Epoch: 2/10 Train loss: 0.510428 Valid loss: 1.209881 Train acc: 0.838710 Valid acc: 0.804751\n",
      "Epoch: 2/10 Train loss: 0.416523 Valid loss: 1.203619 Train acc: 0.838710 Valid acc: 0.804988\n",
      "Epoch: 2/10 Train loss: 0.510694 Valid loss: 1.197460 Train acc: 0.806452 Valid acc: 0.805222\n",
      "Epoch: 2/10 Train loss: 0.481862 Valid loss: 1.191407 Train acc: 0.838710 Valid acc: 0.805451\n",
      "Epoch: 2/10 Train loss: 0.441449 Valid loss: 1.185454 Train acc: 0.838710 Valid acc: 0.805677\n",
      "Epoch: 2/10 Train loss: 0.476056 Valid loss: 1.179596 Train acc: 0.838710 Valid acc: 0.805899\n",
      "Epoch: 2/10 Train loss: 0.437906 Valid loss: 1.173832 Train acc: 0.838710 Valid acc: 0.806118\n",
      "Epoch: 2/10 Train loss: 0.394637 Valid loss: 1.168156 Train acc: 0.870968 Valid acc: 0.806333\n",
      "Epoch: 2/10 Train loss: 0.478807 Valid loss: 1.162567 Train acc: 0.806452 Valid acc: 0.806545\n",
      "Epoch: 2/10 Train loss: 0.450521 Valid loss: 1.157063 Train acc: 0.838710 Valid acc: 0.806754\n",
      "Epoch: 2/10 Train loss: 0.507469 Valid loss: 1.151643 Train acc: 0.806452 Valid acc: 0.806959\n",
      "Epoch: 2/10 Train loss: 0.472848 Valid loss: 1.146305 Train acc: 0.838710 Valid acc: 0.807162\n",
      "Epoch: 2/10 Train loss: 0.434525 Valid loss: 1.141047 Train acc: 0.838710 Valid acc: 0.807361\n",
      "Epoch: 2/10 Train loss: 0.435824 Valid loss: 1.135868 Train acc: 0.838710 Valid acc: 0.807557\n",
      "Epoch: 2/10 Train loss: 0.390731 Valid loss: 1.130766 Train acc: 0.870968 Valid acc: 0.807750\n",
      "Epoch: 2/10 Train loss: 0.480914 Valid loss: 1.125741 Train acc: 0.806452 Valid acc: 0.807941\n",
      "Epoch: 2/10 Train loss: 0.436833 Valid loss: 1.120792 Train acc: 0.838710 Valid acc: 0.808128\n",
      "Epoch: 2/10 Train loss: 0.506052 Valid loss: 1.115918 Train acc: 0.806452 Valid acc: 0.808313\n",
      "Epoch: 2/10 Train loss: 0.456841 Valid loss: 1.111117 Train acc: 0.838710 Valid acc: 0.808496\n",
      "Epoch: 2/10 Train loss: 0.434671 Valid loss: 1.106385 Train acc: 0.838710 Valid acc: 0.808675\n",
      "Epoch: 2/10 Train loss: 0.426060 Valid loss: 1.101721 Train acc: 0.838710 Valid acc: 0.808852\n",
      "Epoch: 2/10 Train loss: 0.544976 Valid loss: 1.097119 Train acc: 0.806452 Valid acc: 0.809027\n",
      "Epoch: 2/10 Train loss: 0.411734 Valid loss: 1.092581 Train acc: 0.838710 Valid acc: 0.809199\n",
      "Epoch: 2/10 Train loss: 0.426061 Valid loss: 1.088107 Train acc: 0.838710 Valid acc: 0.809368\n",
      "Epoch: 2/10 Train loss: 0.496874 Valid loss: 1.083696 Train acc: 0.806452 Valid acc: 0.809536\n",
      "Epoch: 2/10 Train loss: 0.429766 Valid loss: 1.079346 Train acc: 0.870968 Valid acc: 0.809701\n",
      "Epoch: 2/10 Train loss: 0.524380 Valid loss: 1.075055 Train acc: 0.806452 Valid acc: 0.809863\n",
      "Epoch: 2/10 Train loss: 0.383758 Valid loss: 1.070822 Train acc: 0.870968 Valid acc: 0.810024\n",
      "Epoch: 2/10 Train loss: 0.487794 Valid loss: 1.066647 Train acc: 0.806452 Valid acc: 0.810182\n",
      "Epoch: 2/10 Train loss: 0.501563 Valid loss: 1.062528 Train acc: 0.806452 Valid acc: 0.810338\n",
      "Epoch: 2/10 Train loss: 0.381925 Valid loss: 1.058463 Train acc: 0.870968 Valid acc: 0.810493\n",
      "Epoch: 2/10 Train loss: 0.480364 Valid loss: 1.054454 Train acc: 0.838710 Valid acc: 0.810645\n",
      "Epoch: 2/10 Train loss: 0.427237 Valid loss: 1.050500 Train acc: 0.838710 Valid acc: 0.810795\n",
      "Epoch: 2/10 Train loss: 0.484688 Valid loss: 1.046598 Train acc: 0.806452 Valid acc: 0.810943\n",
      "Epoch: 2/10 Train loss: 0.441953 Valid loss: 1.042747 Train acc: 0.838710 Valid acc: 0.811089\n",
      "Epoch: 2/10 Train loss: 0.404443 Valid loss: 1.038945 Train acc: 0.838710 Valid acc: 0.811233\n",
      "Epoch: 2/10 Train loss: 0.421008 Valid loss: 1.035193 Train acc: 0.838710 Valid acc: 0.811376\n",
      "Epoch: 2/10 Train loss: 0.445796 Valid loss: 1.031489 Train acc: 0.838710 Valid acc: 0.811517\n",
      "Epoch: 2/10 Train loss: 0.434504 Valid loss: 1.027832 Train acc: 0.838710 Valid acc: 0.811655\n",
      "Epoch: 2/10 Train loss: 0.488963 Valid loss: 1.024225 Train acc: 0.806452 Valid acc: 0.811793\n",
      "Epoch: 2/10 Train loss: 0.432444 Valid loss: 1.020664 Train acc: 0.838710 Valid acc: 0.811928\n",
      "Epoch: 2/10 Train loss: 0.436128 Valid loss: 1.017159 Train acc: 0.838710 Valid acc: 0.812062\n",
      "Epoch: 2/10 Train loss: 0.439605 Valid loss: 1.013713 Train acc: 0.838710 Valid acc: 0.812194\n",
      "Epoch: 2/10 Train loss: 0.516029 Valid loss: 1.010332 Train acc: 0.806452 Valid acc: 0.812324\n",
      "Epoch: 2/10 Train loss: 0.360292 Valid loss: 1.007018 Train acc: 0.870968 Valid acc: 0.812453\n",
      "Epoch: 2/10 Train loss: 0.514830 Valid loss: 1.003759 Train acc: 0.806452 Valid acc: 0.812580\n",
      "Epoch: 2/10 Train loss: 0.399073 Valid loss: 1.000552 Train acc: 0.870968 Valid acc: 0.812706\n",
      "Epoch: 2/10 Train loss: 0.495970 Valid loss: 0.997369 Train acc: 0.806452 Valid acc: 0.812830\n",
      "Epoch: 2/10 Train loss: 0.437055 Valid loss: 0.994215 Train acc: 0.838710 Valid acc: 0.812953\n",
      "Epoch: 2/10 Train loss: 0.519907 Valid loss: 0.991091 Train acc: 0.806452 Valid acc: 0.813075\n",
      "Epoch: 2/10 Train loss: 0.408633 Valid loss: 0.987996 Train acc: 0.870968 Valid acc: 0.813194\n",
      "Epoch: 2/10 Train loss: 0.447013 Valid loss: 0.984932 Train acc: 0.838710 Valid acc: 0.813313\n",
      "Epoch: 2/10 Train loss: 0.615367 Valid loss: 0.981862 Train acc: 0.806452 Valid acc: 0.813430\n",
      "Epoch: 2/10 Train loss: 0.456356 Valid loss: 0.978812 Train acc: 0.838710 Valid acc: 0.813546\n",
      "Epoch: 2/10 Train loss: 0.464017 Valid loss: 0.975797 Train acc: 0.838710 Valid acc: 0.813660\n",
      "Epoch: 2/10 Train loss: 0.448626 Valid loss: 0.972817 Train acc: 0.838710 Valid acc: 0.813773\n",
      "Epoch: 2/10 Train loss: 0.469863 Valid loss: 0.969873 Train acc: 0.806452 Valid acc: 0.813885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 Train loss: 0.408402 Valid loss: 0.966962 Train acc: 0.870968 Valid acc: 0.813996\n",
      "Epoch: 2/10 Train loss: 0.435837 Valid loss: 0.964082 Train acc: 0.838710 Valid acc: 0.814105\n",
      "Epoch: 2/10 Train loss: 0.532720 Valid loss: 0.961238 Train acc: 0.806452 Valid acc: 0.814213\n",
      "Epoch: 2/10 Train loss: 0.428958 Valid loss: 0.958428 Train acc: 0.838710 Valid acc: 0.814320\n",
      "Epoch: 2/10 Train loss: 0.482428 Valid loss: 0.955650 Train acc: 0.806452 Valid acc: 0.814426\n",
      "Epoch: 2/10 Train loss: 0.398194 Valid loss: 0.952901 Train acc: 0.870968 Valid acc: 0.814530\n",
      "Epoch: 2/10 Train loss: 0.427921 Valid loss: 0.950180 Train acc: 0.838710 Valid acc: 0.814634\n",
      "Epoch: 2/10 Train loss: 0.551352 Valid loss: 0.947490 Train acc: 0.806452 Valid acc: 0.814736\n",
      "Epoch: 2/10 Train loss: 0.413438 Valid loss: 0.944833 Train acc: 0.838710 Valid acc: 0.814837\n",
      "Epoch: 2/10 Train loss: 0.459278 Valid loss: 0.942210 Train acc: 0.838710 Valid acc: 0.814938\n",
      "Epoch: 2/10 Train loss: 0.452321 Valid loss: 0.939615 Train acc: 0.838710 Valid acc: 0.815037\n",
      "Epoch: 2/10 Train loss: 0.450140 Valid loss: 0.937042 Train acc: 0.838710 Valid acc: 0.815135\n",
      "Epoch: 2/10 Train loss: 0.491865 Valid loss: 0.934493 Train acc: 0.806452 Valid acc: 0.815232\n",
      "Epoch: 2/10 Train loss: 0.490728 Valid loss: 0.931971 Train acc: 0.806452 Valid acc: 0.815327\n",
      "Epoch: 2/10 Train loss: 0.393274 Valid loss: 0.929473 Train acc: 0.870968 Valid acc: 0.815422\n",
      "Epoch: 2/10 Train loss: 0.461986 Valid loss: 0.927001 Train acc: 0.838710 Valid acc: 0.815516\n",
      "Epoch: 2/10 Train loss: 0.454428 Valid loss: 0.924552 Train acc: 0.838710 Valid acc: 0.815609\n",
      "Epoch: 2/10 Train loss: 0.397607 Valid loss: 0.922127 Train acc: 0.838710 Valid acc: 0.815701\n",
      "Epoch: 2/10 Train loss: 0.512528 Valid loss: 0.919725 Train acc: 0.806452 Valid acc: 0.815792\n",
      "Epoch: 2/10 Train loss: 0.382265 Valid loss: 0.917345 Train acc: 0.870968 Valid acc: 0.815882\n",
      "Epoch: 2/10 Train loss: 0.512887 Valid loss: 0.914986 Train acc: 0.806452 Valid acc: 0.815972\n",
      "Epoch: 2/10 Train loss: 0.448928 Valid loss: 0.912649 Train acc: 0.838710 Valid acc: 0.816060\n",
      "Epoch: 2/10 Train loss: 0.469425 Valid loss: 0.910334 Train acc: 0.838710 Valid acc: 0.816147\n",
      "Epoch: 2/10 Train loss: 0.390473 Valid loss: 0.908039 Train acc: 0.838710 Valid acc: 0.816234\n",
      "Epoch: 2/10 Train loss: 0.492715 Valid loss: 0.905767 Train acc: 0.806452 Valid acc: 0.816320\n",
      "Epoch: 2/10 Train loss: 0.469630 Valid loss: 0.903515 Train acc: 0.838710 Valid acc: 0.816405\n",
      "Epoch: 2/10 Train loss: 0.447690 Valid loss: 0.901285 Train acc: 0.838710 Valid acc: 0.816489\n",
      "Epoch: 2/10 Train loss: 0.413308 Valid loss: 0.899079 Train acc: 0.838710 Valid acc: 0.816572\n",
      "Epoch: 3/10 Train loss: 0.399269 Valid loss: 0.896901 Train acc: 0.870968 Valid acc: 0.816654\n",
      "Epoch: 3/10 Train loss: 0.500237 Valid loss: 0.894760 Train acc: 0.806452 Valid acc: 0.816736\n",
      "Epoch: 3/10 Train loss: 0.463628 Valid loss: 0.892671 Train acc: 0.806452 Valid acc: 0.816816\n",
      "Epoch: 3/10 Train loss: 0.424187 Valid loss: 0.890683 Train acc: 0.870968 Valid acc: 0.816896\n",
      "Epoch: 3/10 Train loss: 0.424762 Valid loss: 0.888821 Train acc: 0.806452 Valid acc: 0.816976\n",
      "Epoch: 3/10 Train loss: 0.327303 Valid loss: 0.887350 Train acc: 0.870968 Valid acc: 0.817054\n",
      "Epoch: 3/10 Train loss: 0.854907 Valid loss: 0.885447 Train acc: 0.806452 Valid acc: 0.817132\n",
      "Epoch: 3/10 Train loss: 0.502734 Valid loss: 0.883470 Train acc: 0.806452 Valid acc: 0.817209\n",
      "Epoch: 3/10 Train loss: 0.413591 Valid loss: 0.881517 Train acc: 0.838710 Valid acc: 0.817285\n",
      "Epoch: 3/10 Train loss: 0.467856 Valid loss: 0.879601 Train acc: 0.838710 Valid acc: 0.817361\n",
      "Epoch: 3/10 Train loss: 0.413406 Valid loss: 0.877717 Train acc: 0.870968 Valid acc: 0.817436\n",
      "Epoch: 3/10 Train loss: 0.490416 Valid loss: 0.875856 Train acc: 0.806452 Valid acc: 0.817510\n",
      "Epoch: 3/10 Train loss: 0.446841 Valid loss: 0.874009 Train acc: 0.838710 Valid acc: 0.817583\n",
      "Epoch: 3/10 Train loss: 0.546918 Valid loss: 0.872170 Train acc: 0.774194 Valid acc: 0.817656\n",
      "Epoch: 3/10 Train loss: 0.472038 Valid loss: 0.870340 Train acc: 0.838710 Valid acc: 0.817728\n",
      "Epoch: 3/10 Train loss: 0.508251 Valid loss: 0.868517 Train acc: 0.806452 Valid acc: 0.817800\n",
      "Epoch: 3/10 Train loss: 0.439804 Valid loss: 0.866696 Train acc: 0.838710 Valid acc: 0.817871\n",
      "Epoch: 3/10 Train loss: 0.426308 Valid loss: 0.864875 Train acc: 0.838710 Valid acc: 0.817941\n",
      "Epoch: 3/10 Train loss: 0.425057 Valid loss: 0.863057 Train acc: 0.838710 Valid acc: 0.818010\n",
      "Epoch: 3/10 Train loss: 0.430377 Valid loss: 0.861260 Train acc: 0.806452 Valid acc: 0.818079\n",
      "Epoch: 3/10 Train loss: 0.444224 Valid loss: 0.859509 Train acc: 0.838710 Valid acc: 0.818148\n",
      "Epoch: 3/10 Train loss: 0.449638 Valid loss: 0.857864 Train acc: 0.838710 Valid acc: 0.818215\n",
      "Epoch: 3/10 Train loss: 0.583915 Valid loss: 0.856198 Train acc: 0.838710 Valid acc: 0.818283\n",
      "Epoch: 3/10 Train loss: 0.545321 Valid loss: 0.854474 Train acc: 0.838710 Valid acc: 0.818349\n",
      "Epoch: 3/10 Train loss: 0.398749 Valid loss: 0.852760 Train acc: 0.870968 Valid acc: 0.818415\n",
      "Epoch: 3/10 Train loss: 0.553569 Valid loss: 0.851058 Train acc: 0.806452 Valid acc: 0.818481\n",
      "Epoch: 3/10 Train loss: 0.435486 Valid loss: 0.849371 Train acc: 0.838710 Valid acc: 0.818545\n",
      "Epoch: 3/10 Train loss: 0.512370 Valid loss: 0.847677 Train acc: 0.806452 Valid acc: 0.818610\n",
      "Epoch: 3/10 Train loss: 0.427244 Valid loss: 0.845989 Train acc: 0.838710 Valid acc: 0.818673\n",
      "Epoch: 3/10 Train loss: 0.438515 Valid loss: 0.844313 Train acc: 0.838710 Valid acc: 0.818737\n",
      "Epoch: 3/10 Train loss: 0.451245 Valid loss: 0.842651 Train acc: 0.838710 Valid acc: 0.818799\n",
      "Epoch: 3/10 Train loss: 0.396165 Valid loss: 0.841001 Train acc: 0.870968 Valid acc: 0.818861\n",
      "Epoch: 3/10 Train loss: 0.468969 Valid loss: 0.839365 Train acc: 0.806452 Valid acc: 0.818923\n",
      "Epoch: 3/10 Train loss: 0.426007 Valid loss: 0.837741 Train acc: 0.838710 Valid acc: 0.818984\n",
      "Epoch: 3/10 Train loss: 0.486616 Valid loss: 0.836131 Train acc: 0.806452 Valid acc: 0.819045\n",
      "Epoch: 3/10 Train loss: 0.440314 Valid loss: 0.834531 Train acc: 0.838710 Valid acc: 0.819105\n",
      "Epoch: 3/10 Train loss: 0.443454 Valid loss: 0.832943 Train acc: 0.838710 Valid acc: 0.819164\n",
      "Epoch: 3/10 Train loss: 0.440898 Valid loss: 0.831367 Train acc: 0.838710 Valid acc: 0.819223\n",
      "Epoch: 3/10 Train loss: 0.492578 Valid loss: 0.829802 Train acc: 0.806452 Valid acc: 0.819282\n",
      "Epoch: 3/10 Train loss: 0.460119 Valid loss: 0.828249 Train acc: 0.838710 Valid acc: 0.819340\n",
      "Epoch: 3/10 Train loss: 0.433983 Valid loss: 0.826707 Train acc: 0.838710 Valid acc: 0.819398\n",
      "Epoch: 3/10 Train loss: 0.489763 Valid loss: 0.825178 Train acc: 0.806452 Valid acc: 0.819455\n",
      "Epoch: 3/10 Train loss: 0.385125 Valid loss: 0.823661 Train acc: 0.870968 Valid acc: 0.819511\n",
      "Epoch: 3/10 Train loss: 0.496613 Valid loss: 0.822157 Train acc: 0.806452 Valid acc: 0.819568\n",
      "Epoch: 3/10 Train loss: 0.407612 Valid loss: 0.820664 Train acc: 0.870968 Valid acc: 0.819624\n",
      "Epoch: 3/10 Train loss: 0.484354 Valid loss: 0.819183 Train acc: 0.806452 Valid acc: 0.819679\n",
      "Epoch: 3/10 Train loss: 0.482914 Valid loss: 0.817715 Train acc: 0.806452 Valid acc: 0.819734\n",
      "Epoch: 3/10 Train loss: 0.386421 Valid loss: 0.816258 Train acc: 0.870968 Valid acc: 0.819788\n",
      "Epoch: 3/10 Train loss: 0.451583 Valid loss: 0.814812 Train acc: 0.838710 Valid acc: 0.819842\n",
      "Epoch: 3/10 Train loss: 0.429479 Valid loss: 0.813378 Train acc: 0.838710 Valid acc: 0.819896\n",
      "Epoch: 3/10 Train loss: 0.479180 Valid loss: 0.811954 Train acc: 0.806452 Valid acc: 0.819949\n",
      "Epoch: 3/10 Train loss: 0.448066 Valid loss: 0.810541 Train acc: 0.838710 Valid acc: 0.820002\n",
      "Epoch: 3/10 Train loss: 0.489703 Valid loss: 0.809139 Train acc: 0.838710 Valid acc: 0.820054\n",
      "Epoch: 3/10 Train loss: 0.415887 Valid loss: 0.807748 Train acc: 0.838710 Valid acc: 0.820106\n",
      "Epoch: 3/10 Train loss: 0.449682 Valid loss: 0.806368 Train acc: 0.838710 Valid acc: 0.820158\n",
      "Epoch: 3/10 Train loss: 0.441005 Valid loss: 0.804999 Train acc: 0.838710 Valid acc: 0.820209\n",
      "Epoch: 3/10 Train loss: 0.496495 Valid loss: 0.803640 Train acc: 0.806452 Valid acc: 0.820260\n",
      "Epoch: 3/10 Train loss: 0.453497 Valid loss: 0.802292 Train acc: 0.838710 Valid acc: 0.820310\n",
      "Epoch: 3/10 Train loss: 0.423864 Valid loss: 0.800955 Train acc: 0.838710 Valid acc: 0.820360\n",
      "Epoch: 3/10 Train loss: 0.426192 Valid loss: 0.799627 Train acc: 0.838710 Valid acc: 0.820410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Train loss: 0.523467 Valid loss: 0.798309 Train acc: 0.806452 Valid acc: 0.820459\n",
      "Epoch: 3/10 Train loss: 0.402340 Valid loss: 0.797004 Train acc: 0.870968 Valid acc: 0.820508\n",
      "Epoch: 3/10 Train loss: 0.460357 Valid loss: 0.795712 Train acc: 0.806452 Valid acc: 0.820556\n",
      "Epoch: 3/10 Train loss: 0.382069 Valid loss: 0.794433 Train acc: 0.870968 Valid acc: 0.820604\n",
      "Epoch: 3/10 Train loss: 0.489432 Valid loss: 0.793161 Train acc: 0.806452 Valid acc: 0.820652\n",
      "Epoch: 3/10 Train loss: 0.445129 Valid loss: 0.791900 Train acc: 0.838710 Valid acc: 0.820700\n",
      "Epoch: 3/10 Train loss: 0.497755 Valid loss: 0.790649 Train acc: 0.806452 Valid acc: 0.820747\n",
      "Epoch: 3/10 Train loss: 0.408595 Valid loss: 0.789405 Train acc: 0.870968 Valid acc: 0.820793\n",
      "Epoch: 3/10 Train loss: 0.438680 Valid loss: 0.788169 Train acc: 0.838710 Valid acc: 0.820840\n",
      "Epoch: 3/10 Train loss: 0.551217 Valid loss: 0.786943 Train acc: 0.806452 Valid acc: 0.820886\n",
      "Epoch: 3/10 Train loss: 0.442425 Valid loss: 0.785727 Train acc: 0.838710 Valid acc: 0.820932\n",
      "Epoch: 3/10 Train loss: 0.435107 Valid loss: 0.784520 Train acc: 0.838710 Valid acc: 0.820977\n",
      "Epoch: 3/10 Train loss: 0.446086 Valid loss: 0.783322 Train acc: 0.838710 Valid acc: 0.821022\n",
      "Epoch: 3/10 Train loss: 0.492722 Valid loss: 0.782133 Train acc: 0.806452 Valid acc: 0.821067\n",
      "Epoch: 3/10 Train loss: 0.398683 Valid loss: 0.780951 Train acc: 0.870968 Valid acc: 0.821111\n",
      "Epoch: 3/10 Train loss: 0.441222 Valid loss: 0.779777 Train acc: 0.838710 Valid acc: 0.821155\n",
      "Epoch: 3/10 Train loss: 0.484017 Valid loss: 0.778610 Train acc: 0.806452 Valid acc: 0.821199\n",
      "Epoch: 3/10 Train loss: 0.453933 Valid loss: 0.777450 Train acc: 0.838710 Valid acc: 0.821243\n",
      "Epoch: 3/10 Train loss: 0.492152 Valid loss: 0.776298 Train acc: 0.806452 Valid acc: 0.821286\n",
      "Epoch: 3/10 Train loss: 0.392396 Valid loss: 0.775154 Train acc: 0.870968 Valid acc: 0.821329\n",
      "Epoch: 3/10 Train loss: 0.444859 Valid loss: 0.774017 Train acc: 0.838710 Valid acc: 0.821371\n",
      "Epoch: 3/10 Train loss: 0.506806 Valid loss: 0.772887 Train acc: 0.806452 Valid acc: 0.821413\n",
      "Epoch: 3/10 Train loss: 0.430670 Valid loss: 0.771765 Train acc: 0.838710 Valid acc: 0.821455\n",
      "Epoch: 3/10 Train loss: 0.457209 Valid loss: 0.770651 Train acc: 0.838710 Valid acc: 0.821497\n",
      "Epoch: 3/10 Train loss: 0.462971 Valid loss: 0.769544 Train acc: 0.838710 Valid acc: 0.821538\n",
      "Epoch: 3/10 Train loss: 0.448604 Valid loss: 0.768444 Train acc: 0.838710 Valid acc: 0.821580\n",
      "Epoch: 3/10 Train loss: 0.482213 Valid loss: 0.767352 Train acc: 0.806452 Valid acc: 0.821620\n",
      "Epoch: 3/10 Train loss: 0.541504 Valid loss: 0.766268 Train acc: 0.806452 Valid acc: 0.821661\n",
      "Epoch: 3/10 Train loss: 0.393278 Valid loss: 0.765191 Train acc: 0.870968 Valid acc: 0.821701\n",
      "Epoch: 3/10 Train loss: 0.439536 Valid loss: 0.764122 Train acc: 0.838710 Valid acc: 0.821741\n",
      "Epoch: 3/10 Train loss: 0.429275 Valid loss: 0.763059 Train acc: 0.838710 Valid acc: 0.821781\n",
      "Epoch: 3/10 Train loss: 0.433700 Valid loss: 0.762005 Train acc: 0.838710 Valid acc: 0.821820\n",
      "Epoch: 3/10 Train loss: 0.484925 Valid loss: 0.760957 Train acc: 0.806452 Valid acc: 0.821859\n",
      "Epoch: 3/10 Train loss: 0.388618 Valid loss: 0.759916 Train acc: 0.870968 Valid acc: 0.821898\n",
      "Epoch: 3/10 Train loss: 0.483170 Valid loss: 0.758883 Train acc: 0.806452 Valid acc: 0.821937\n",
      "Epoch: 3/10 Train loss: 0.436968 Valid loss: 0.757857 Train acc: 0.838710 Valid acc: 0.821976\n",
      "Epoch: 3/10 Train loss: 0.448366 Valid loss: 0.756837 Train acc: 0.838710 Valid acc: 0.822014\n",
      "Epoch: 3/10 Train loss: 0.441134 Valid loss: 0.755825 Train acc: 0.838710 Valid acc: 0.822052\n",
      "Epoch: 3/10 Train loss: 0.527803 Valid loss: 0.754820 Train acc: 0.806452 Valid acc: 0.822089\n",
      "Epoch: 3/10 Train loss: 0.462557 Valid loss: 0.753824 Train acc: 0.838710 Valid acc: 0.822127\n",
      "Epoch: 3/10 Train loss: 0.435751 Valid loss: 0.752836 Train acc: 0.838710 Valid acc: 0.822164\n",
      "Epoch: 3/10 Train loss: 0.439568 Valid loss: 0.751855 Train acc: 0.838710 Valid acc: 0.822201\n",
      "Epoch: 4/10 Train loss: 0.670355 Valid loss: 0.750877 Train acc: 0.870968 Valid acc: 0.822237\n",
      "Epoch: 4/10 Train loss: 0.604253 Valid loss: 0.749909 Train acc: 0.774194 Valid acc: 0.822274\n",
      "Epoch: 4/10 Train loss: 0.504248 Valid loss: 0.748952 Train acc: 0.806452 Valid acc: 0.822310\n",
      "Epoch: 4/10 Train loss: 0.471123 Valid loss: 0.748005 Train acc: 0.870968 Valid acc: 0.822346\n",
      "Epoch: 4/10 Train loss: 0.472755 Valid loss: 0.747067 Train acc: 0.806452 Valid acc: 0.822382\n",
      "Epoch: 4/10 Train loss: 0.400573 Valid loss: 0.746137 Train acc: 0.870968 Valid acc: 0.822417\n",
      "Epoch: 4/10 Train loss: 0.470223 Valid loss: 0.745215 Train acc: 0.806452 Valid acc: 0.822452\n",
      "Epoch: 4/10 Train loss: 0.502855 Valid loss: 0.744299 Train acc: 0.806452 Valid acc: 0.822487\n",
      "Epoch: 4/10 Train loss: 0.431341 Valid loss: 0.743391 Train acc: 0.838710 Valid acc: 0.822522\n",
      "Epoch: 4/10 Train loss: 0.465281 Valid loss: 0.742488 Train acc: 0.838710 Valid acc: 0.822557\n",
      "Epoch: 4/10 Train loss: 0.385384 Valid loss: 0.741587 Train acc: 0.870968 Valid acc: 0.822591\n",
      "Epoch: 4/10 Train loss: 0.513968 Valid loss: 0.740691 Train acc: 0.806452 Valid acc: 0.822625\n",
      "Epoch: 4/10 Train loss: 0.436674 Valid loss: 0.739799 Train acc: 0.838710 Valid acc: 0.822659\n",
      "Epoch: 4/10 Train loss: 0.547767 Valid loss: 0.738912 Train acc: 0.806452 Valid acc: 0.822693\n",
      "Epoch: 4/10 Train loss: 0.386665 Valid loss: 0.738028 Train acc: 0.870968 Valid acc: 0.822727\n",
      "Epoch: 4/10 Train loss: 0.532415 Valid loss: 0.737148 Train acc: 0.806452 Valid acc: 0.822760\n",
      "Epoch: 4/10 Train loss: 0.456366 Valid loss: 0.736272 Train acc: 0.838710 Valid acc: 0.822793\n",
      "Epoch: 4/10 Train loss: 0.411439 Valid loss: 0.735401 Train acc: 0.838710 Valid acc: 0.822826\n",
      "Epoch: 4/10 Train loss: 0.437381 Valid loss: 0.734533 Train acc: 0.838710 Valid acc: 0.822859\n",
      "Epoch: 4/10 Train loss: 0.488413 Valid loss: 0.733671 Train acc: 0.806452 Valid acc: 0.822891\n",
      "Epoch: 4/10 Train loss: 0.427016 Valid loss: 0.732813 Train acc: 0.838710 Valid acc: 0.822924\n",
      "Epoch: 4/10 Train loss: 0.436485 Valid loss: 0.731959 Train acc: 0.838710 Valid acc: 0.822956\n",
      "Epoch: 4/10 Train loss: 0.444710 Valid loss: 0.731109 Train acc: 0.838710 Valid acc: 0.822988\n",
      "Epoch: 4/10 Train loss: 0.449870 Valid loss: 0.730263 Train acc: 0.838710 Valid acc: 0.823019\n",
      "Epoch: 4/10 Train loss: 0.396209 Valid loss: 0.729419 Train acc: 0.870968 Valid acc: 0.823051\n",
      "Epoch: 4/10 Train loss: 0.483007 Valid loss: 0.728579 Train acc: 0.806452 Valid acc: 0.823082\n",
      "Epoch: 4/10 Train loss: 0.446523 Valid loss: 0.727748 Train acc: 0.838710 Valid acc: 0.823113\n",
      "Epoch: 4/10 Train loss: 0.494579 Valid loss: 0.726961 Train acc: 0.806452 Valid acc: 0.823144\n",
      "Epoch: 4/10 Train loss: 0.436650 Valid loss: 0.726374 Train acc: 0.838710 Valid acc: 0.823175\n",
      "Epoch: 4/10 Train loss: 0.519173 Valid loss: 0.725682 Train acc: 0.838710 Valid acc: 0.823206\n",
      "Epoch: 4/10 Train loss: 0.417832 Valid loss: 0.724919 Train acc: 0.838710 Valid acc: 0.823236\n",
      "Epoch: 4/10 Train loss: 0.348604 Valid loss: 0.724160 Train acc: 0.870968 Valid acc: 0.823266\n",
      "Epoch: 4/10 Train loss: 0.772763 Valid loss: 0.723355 Train acc: 0.806452 Valid acc: 0.823296\n",
      "Epoch: 4/10 Train loss: 0.479349 Valid loss: 0.722558 Train acc: 0.838710 Valid acc: 0.823326\n",
      "Epoch: 4/10 Train loss: 0.529445 Valid loss: 0.721771 Train acc: 0.806452 Valid acc: 0.823356\n",
      "Epoch: 4/10 Train loss: 0.447716 Valid loss: 0.720994 Train acc: 0.838710 Valid acc: 0.823386\n",
      "Epoch: 4/10 Train loss: 0.445863 Valid loss: 0.720227 Train acc: 0.838710 Valid acc: 0.823415\n",
      "Epoch: 4/10 Train loss: 0.454170 Valid loss: 0.719466 Train acc: 0.838710 Valid acc: 0.823444\n",
      "Epoch: 4/10 Train loss: 0.493653 Valid loss: 0.718711 Train acc: 0.806452 Valid acc: 0.823473\n",
      "Epoch: 4/10 Train loss: 0.457488 Valid loss: 0.717959 Train acc: 0.838710 Valid acc: 0.823502\n",
      "Epoch: 4/10 Train loss: 0.453267 Valid loss: 0.717210 Train acc: 0.838710 Valid acc: 0.823531\n",
      "Epoch: 4/10 Train loss: 0.499518 Valid loss: 0.716462 Train acc: 0.806452 Valid acc: 0.823559\n",
      "Epoch: 4/10 Train loss: 0.399722 Valid loss: 0.715715 Train acc: 0.870968 Valid acc: 0.823588\n",
      "Epoch: 4/10 Train loss: 0.468394 Valid loss: 0.714969 Train acc: 0.806452 Valid acc: 0.823616\n",
      "Epoch: 4/10 Train loss: 0.397668 Valid loss: 0.714224 Train acc: 0.870968 Valid acc: 0.823644\n",
      "Epoch: 4/10 Train loss: 0.479912 Valid loss: 0.713480 Train acc: 0.806452 Valid acc: 0.823672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 Train loss: 0.497813 Valid loss: 0.712740 Train acc: 0.806452 Valid acc: 0.823700\n",
      "Epoch: 4/10 Train loss: 0.392981 Valid loss: 0.712002 Train acc: 0.870968 Valid acc: 0.823727\n",
      "Epoch: 4/10 Train loss: 0.438799 Valid loss: 0.711269 Train acc: 0.838710 Valid acc: 0.823754\n",
      "Epoch: 4/10 Train loss: 0.456947 Valid loss: 0.710540 Train acc: 0.838710 Valid acc: 0.823782\n",
      "Epoch: 4/10 Train loss: 0.500642 Valid loss: 0.709816 Train acc: 0.806452 Valid acc: 0.823809\n",
      "Epoch: 4/10 Train loss: 0.433959 Valid loss: 0.709096 Train acc: 0.838710 Valid acc: 0.823836\n",
      "Epoch: 4/10 Train loss: 0.458844 Valid loss: 0.708381 Train acc: 0.838710 Valid acc: 0.823863\n",
      "Epoch: 4/10 Train loss: 0.416661 Valid loss: 0.707668 Train acc: 0.838710 Valid acc: 0.823889\n",
      "Epoch: 4/10 Train loss: 0.443694 Valid loss: 0.706958 Train acc: 0.838710 Valid acc: 0.823916\n",
      "Epoch: 4/10 Train loss: 0.423060 Valid loss: 0.706252 Train acc: 0.838710 Valid acc: 0.823942\n",
      "Epoch: 4/10 Train loss: 0.499187 Valid loss: 0.705548 Train acc: 0.806452 Valid acc: 0.823968\n",
      "Epoch: 4/10 Train loss: 0.455035 Valid loss: 0.704848 Train acc: 0.838710 Valid acc: 0.823994\n",
      "Epoch: 4/10 Train loss: 0.448304 Valid loss: 0.704152 Train acc: 0.838710 Valid acc: 0.824020\n",
      "Epoch: 4/10 Train loss: 0.434363 Valid loss: 0.703460 Train acc: 0.838710 Valid acc: 0.824046\n",
      "Epoch: 4/10 Train loss: 0.497229 Valid loss: 0.702772 Train acc: 0.806452 Valid acc: 0.824072\n",
      "Epoch: 4/10 Train loss: 0.381555 Valid loss: 0.702087 Train acc: 0.870968 Valid acc: 0.824097\n",
      "Epoch: 4/10 Train loss: 0.477366 Valid loss: 0.701408 Train acc: 0.806452 Valid acc: 0.824123\n",
      "Epoch: 4/10 Train loss: 0.394149 Valid loss: 0.700732 Train acc: 0.870968 Valid acc: 0.824148\n",
      "Epoch: 4/10 Train loss: 0.503205 Valid loss: 0.700061 Train acc: 0.806452 Valid acc: 0.824173\n",
      "Epoch: 4/10 Train loss: 0.444793 Valid loss: 0.699394 Train acc: 0.838710 Valid acc: 0.824198\n",
      "Epoch: 4/10 Train loss: 0.492189 Valid loss: 0.698731 Train acc: 0.806452 Valid acc: 0.824223\n",
      "Epoch: 4/10 Train loss: 0.398135 Valid loss: 0.698071 Train acc: 0.870968 Valid acc: 0.824247\n",
      "Epoch: 4/10 Train loss: 0.444198 Valid loss: 0.697415 Train acc: 0.838710 Valid acc: 0.824272\n",
      "Epoch: 4/10 Train loss: 0.516326 Valid loss: 0.696760 Train acc: 0.806452 Valid acc: 0.824296\n",
      "Epoch: 4/10 Train loss: 0.439410 Valid loss: 0.696108 Train acc: 0.838710 Valid acc: 0.824321\n",
      "Epoch: 4/10 Train loss: 0.426210 Valid loss: 0.695459 Train acc: 0.838710 Valid acc: 0.824345\n",
      "Epoch: 4/10 Train loss: 0.455433 Valid loss: 0.694813 Train acc: 0.838710 Valid acc: 0.824369\n",
      "Epoch: 4/10 Train loss: 0.483689 Valid loss: 0.694170 Train acc: 0.806452 Valid acc: 0.824393\n",
      "Epoch: 4/10 Train loss: 0.401131 Valid loss: 0.693531 Train acc: 0.870968 Valid acc: 0.824417\n",
      "Epoch: 4/10 Train loss: 0.448697 Valid loss: 0.692895 Train acc: 0.838710 Valid acc: 0.824440\n",
      "Epoch: 4/10 Train loss: 0.529387 Valid loss: 0.692262 Train acc: 0.806452 Valid acc: 0.824464\n",
      "Epoch: 4/10 Train loss: 0.439465 Valid loss: 0.691635 Train acc: 0.838710 Valid acc: 0.824487\n",
      "Epoch: 4/10 Train loss: 0.521306 Valid loss: 0.691009 Train acc: 0.806452 Valid acc: 0.824511\n",
      "Epoch: 4/10 Train loss: 0.384762 Valid loss: 0.690385 Train acc: 0.870968 Valid acc: 0.824534\n",
      "Epoch: 4/10 Train loss: 0.438962 Valid loss: 0.689765 Train acc: 0.838710 Valid acc: 0.824557\n",
      "Epoch: 4/10 Train loss: 0.460637 Valid loss: 0.689149 Train acc: 0.806452 Valid acc: 0.824580\n",
      "Epoch: 4/10 Train loss: 0.473594 Valid loss: 0.688535 Train acc: 0.838710 Valid acc: 0.824603\n",
      "Epoch: 4/10 Train loss: 0.418128 Valid loss: 0.687926 Train acc: 0.838710 Valid acc: 0.824625\n",
      "Epoch: 4/10 Train loss: 0.456374 Valid loss: 0.687320 Train acc: 0.838710 Valid acc: 0.824648\n",
      "Epoch: 4/10 Train loss: 0.454130 Valid loss: 0.686718 Train acc: 0.838710 Valid acc: 0.824670\n",
      "Epoch: 4/10 Train loss: 0.510266 Valid loss: 0.686121 Train acc: 0.806452 Valid acc: 0.824693\n",
      "Epoch: 4/10 Train loss: 0.497080 Valid loss: 0.685528 Train acc: 0.806452 Valid acc: 0.824715\n",
      "Epoch: 4/10 Train loss: 0.399405 Valid loss: 0.684939 Train acc: 0.870968 Valid acc: 0.824737\n",
      "Epoch: 4/10 Train loss: 0.439885 Valid loss: 0.684353 Train acc: 0.838710 Valid acc: 0.824759\n",
      "Epoch: 4/10 Train loss: 0.450631 Valid loss: 0.683769 Train acc: 0.838710 Valid acc: 0.824781\n",
      "Epoch: 4/10 Train loss: 0.433222 Valid loss: 0.683187 Train acc: 0.838710 Valid acc: 0.824803\n",
      "Epoch: 4/10 Train loss: 0.497853 Valid loss: 0.682607 Train acc: 0.806452 Valid acc: 0.824825\n",
      "Epoch: 4/10 Train loss: 0.383861 Valid loss: 0.682029 Train acc: 0.870968 Valid acc: 0.824846\n",
      "Epoch: 4/10 Train loss: 0.487086 Valid loss: 0.681453 Train acc: 0.806452 Valid acc: 0.824868\n",
      "Epoch: 4/10 Train loss: 0.444373 Valid loss: 0.680879 Train acc: 0.838710 Valid acc: 0.824889\n",
      "Epoch: 4/10 Train loss: 0.463006 Valid loss: 0.680307 Train acc: 0.838710 Valid acc: 0.824910\n",
      "Epoch: 4/10 Train loss: 0.430127 Valid loss: 0.679737 Train acc: 0.838710 Valid acc: 0.824931\n",
      "Epoch: 4/10 Train loss: 0.489083 Valid loss: 0.679171 Train acc: 0.806452 Valid acc: 0.824952\n",
      "Epoch: 4/10 Train loss: 0.443868 Valid loss: 0.678607 Train acc: 0.838710 Valid acc: 0.824973\n",
      "Epoch: 4/10 Train loss: 0.446838 Valid loss: 0.678045 Train acc: 0.838710 Valid acc: 0.824994\n",
      "Epoch: 4/10 Train loss: 0.436380 Valid loss: 0.677487 Train acc: 0.838710 Valid acc: 0.825015\n",
      "Epoch: 5/10 Train loss: 0.419297 Valid loss: 0.676932 Train acc: 0.870968 Valid acc: 0.825036\n",
      "Epoch: 5/10 Train loss: 0.458897 Valid loss: 0.676380 Train acc: 0.806452 Valid acc: 0.825056\n",
      "Epoch: 5/10 Train loss: 0.577636 Valid loss: 0.675831 Train acc: 0.806452 Valid acc: 0.825077\n",
      "Epoch: 5/10 Train loss: 0.361564 Valid loss: 0.675283 Train acc: 0.870968 Valid acc: 0.825097\n",
      "Epoch: 5/10 Train loss: 0.478030 Valid loss: 0.674739 Train acc: 0.806452 Valid acc: 0.825117\n",
      "Epoch: 5/10 Train loss: 0.383097 Valid loss: 0.674197 Train acc: 0.870968 Valid acc: 0.825137\n",
      "Epoch: 5/10 Train loss: 0.504908 Valid loss: 0.673658 Train acc: 0.806452 Valid acc: 0.825157\n",
      "Epoch: 5/10 Train loss: 0.590643 Valid loss: 0.673125 Train acc: 0.806452 Valid acc: 0.825177\n",
      "Epoch: 5/10 Train loss: 0.485847 Valid loss: 0.672600 Train acc: 0.838710 Valid acc: 0.825197\n",
      "Epoch: 5/10 Train loss: 0.432639 Valid loss: 0.672087 Train acc: 0.838710 Valid acc: 0.825217\n",
      "Epoch: 5/10 Train loss: 0.384567 Valid loss: 0.671583 Train acc: 0.870968 Valid acc: 0.825237\n",
      "Epoch: 5/10 Train loss: 0.479900 Valid loss: 0.671088 Train acc: 0.806452 Valid acc: 0.825256\n",
      "Epoch: 5/10 Train loss: 0.423090 Valid loss: 0.670599 Train acc: 0.838710 Valid acc: 0.825276\n",
      "Epoch: 5/10 Train loss: 0.531108 Valid loss: 0.670117 Train acc: 0.806452 Valid acc: 0.825295\n",
      "Epoch: 5/10 Train loss: 0.413848 Valid loss: 0.669635 Train acc: 0.903226 Valid acc: 0.825314\n",
      "Epoch: 5/10 Train loss: 0.492975 Valid loss: 0.669153 Train acc: 0.806452 Valid acc: 0.825334\n",
      "Epoch: 5/10 Train loss: 0.511505 Valid loss: 0.668669 Train acc: 0.838710 Valid acc: 0.825353\n",
      "Epoch: 5/10 Train loss: 0.477971 Valid loss: 0.668184 Train acc: 0.838710 Valid acc: 0.825372\n",
      "Epoch: 5/10 Train loss: 0.457367 Valid loss: 0.667695 Train acc: 0.838710 Valid acc: 0.825391\n",
      "Epoch: 5/10 Train loss: 0.479146 Valid loss: 0.667203 Train acc: 0.806452 Valid acc: 0.825410\n",
      "Epoch: 5/10 Train loss: 0.446585 Valid loss: 0.666709 Train acc: 0.838710 Valid acc: 0.825428\n",
      "Epoch: 5/10 Train loss: 0.431816 Valid loss: 0.666213 Train acc: 0.838710 Valid acc: 0.825447\n",
      "Epoch: 5/10 Train loss: 0.448046 Valid loss: 0.665716 Train acc: 0.838710 Valid acc: 0.825466\n",
      "Epoch: 5/10 Train loss: 0.454988 Valid loss: 0.665220 Train acc: 0.838710 Valid acc: 0.825484\n",
      "Epoch: 5/10 Train loss: 0.385236 Valid loss: 0.664727 Train acc: 0.870968 Valid acc: 0.825502\n",
      "Epoch: 5/10 Train loss: 0.498724 Valid loss: 0.664236 Train acc: 0.806452 Valid acc: 0.825521\n",
      "Epoch: 5/10 Train loss: 0.443972 Valid loss: 0.663750 Train acc: 0.838710 Valid acc: 0.825539\n",
      "Epoch: 5/10 Train loss: 0.518248 Valid loss: 0.663267 Train acc: 0.806452 Valid acc: 0.825557\n",
      "Epoch: 5/10 Train loss: 0.440027 Valid loss: 0.662786 Train acc: 0.838710 Valid acc: 0.825575\n",
      "Epoch: 5/10 Train loss: 0.438719 Valid loss: 0.662307 Train acc: 0.838710 Valid acc: 0.825593\n",
      "Epoch: 5/10 Train loss: 0.441594 Valid loss: 0.661829 Train acc: 0.838710 Valid acc: 0.825611\n",
      "Epoch: 5/10 Train loss: 0.382342 Valid loss: 0.661353 Train acc: 0.870968 Valid acc: 0.825629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 Train loss: 0.502698 Valid loss: 0.660878 Train acc: 0.806452 Valid acc: 0.825647\n",
      "Epoch: 5/10 Train loss: 0.440675 Valid loss: 0.660405 Train acc: 0.838710 Valid acc: 0.825664\n",
      "Epoch: 5/10 Train loss: 0.511639 Valid loss: 0.659932 Train acc: 0.806452 Valid acc: 0.825682\n",
      "Epoch: 5/10 Train loss: 0.455806 Valid loss: 0.659462 Train acc: 0.838710 Valid acc: 0.825700\n",
      "Epoch: 5/10 Train loss: 0.440735 Valid loss: 0.658993 Train acc: 0.838710 Valid acc: 0.825717\n",
      "Epoch: 5/10 Train loss: 0.447409 Valid loss: 0.658525 Train acc: 0.838710 Valid acc: 0.825734\n",
      "Epoch: 5/10 Train loss: 0.481726 Valid loss: 0.658060 Train acc: 0.806452 Valid acc: 0.825752\n",
      "Epoch: 5/10 Train loss: 0.450823 Valid loss: 0.657597 Train acc: 0.838710 Valid acc: 0.825769\n",
      "Epoch: 5/10 Train loss: 0.440196 Valid loss: 0.657137 Train acc: 0.838710 Valid acc: 0.825786\n",
      "Epoch: 5/10 Train loss: 0.493860 Valid loss: 0.656679 Train acc: 0.806452 Valid acc: 0.825803\n",
      "Epoch: 5/10 Train loss: 0.397039 Valid loss: 0.656224 Train acc: 0.870968 Valid acc: 0.825820\n",
      "Epoch: 5/10 Train loss: 0.488026 Valid loss: 0.655772 Train acc: 0.806452 Valid acc: 0.825837\n",
      "Epoch: 5/10 Train loss: 0.386787 Valid loss: 0.655322 Train acc: 0.870968 Valid acc: 0.825854\n",
      "Epoch: 5/10 Train loss: 0.503482 Valid loss: 0.654875 Train acc: 0.806452 Valid acc: 0.825870\n",
      "Epoch: 5/10 Train loss: 0.490451 Valid loss: 0.654430 Train acc: 0.806452 Valid acc: 0.825887\n",
      "Epoch: 5/10 Train loss: 0.397017 Valid loss: 0.653987 Train acc: 0.870968 Valid acc: 0.825904\n",
      "Epoch: 5/10 Train loss: 0.453915 Valid loss: 0.653545 Train acc: 0.838710 Valid acc: 0.825920\n",
      "Epoch: 5/10 Train loss: 0.440093 Valid loss: 0.653105 Train acc: 0.838710 Valid acc: 0.825937\n",
      "Epoch: 5/10 Train loss: 0.492935 Valid loss: 0.652666 Train acc: 0.806452 Valid acc: 0.825953\n",
      "Epoch: 5/10 Train loss: 0.446957 Valid loss: 0.652229 Train acc: 0.838710 Valid acc: 0.825969\n",
      "Epoch: 5/10 Train loss: 0.629162 Valid loss: 0.651793 Train acc: 0.806452 Valid acc: 0.825986\n",
      "Epoch: 5/10 Train loss: 0.438586 Valid loss: 0.651358 Train acc: 0.838710 Valid acc: 0.826002\n",
      "Epoch: 5/10 Train loss: 0.447939 Valid loss: 0.650924 Train acc: 0.838710 Valid acc: 0.826018\n",
      "Epoch: 5/10 Train loss: 0.444703 Valid loss: 0.650492 Train acc: 0.838710 Valid acc: 0.826034\n",
      "Epoch: 5/10 Train loss: 0.486973 Valid loss: 0.650061 Train acc: 0.806452 Valid acc: 0.826050\n",
      "Epoch: 5/10 Train loss: 0.421044 Valid loss: 0.649632 Train acc: 0.838710 Valid acc: 0.826066\n",
      "Epoch: 5/10 Train loss: 0.440903 Valid loss: 0.649206 Train acc: 0.838710 Valid acc: 0.826082\n",
      "Epoch: 5/10 Train loss: 0.452135 Valid loss: 0.648785 Train acc: 0.838710 Valid acc: 0.826097\n",
      "Epoch: 5/10 Train loss: 0.493346 Valid loss: 0.648380 Train acc: 0.806452 Valid acc: 0.826113\n",
      "Epoch: 5/10 Train loss: 0.376378 Valid loss: 0.648043 Train acc: 0.870968 Valid acc: 0.826129\n",
      "Epoch: 5/10 Train loss: 0.519299 Valid loss: 0.647772 Train acc: 0.806452 Valid acc: 0.826144\n",
      "Epoch: 5/10 Train loss: 0.385502 Valid loss: 0.647573 Train acc: 0.870968 Valid acc: 0.826160\n",
      "Epoch: 5/10 Train loss: 0.531788 Valid loss: 0.647314 Train acc: 0.806452 Valid acc: 0.826175\n",
      "Epoch: 5/10 Train loss: 0.439463 Valid loss: 0.647029 Train acc: 0.838710 Valid acc: 0.826191\n",
      "Epoch: 5/10 Train loss: 0.513924 Valid loss: 0.646702 Train acc: 0.806452 Valid acc: 0.826206\n",
      "Epoch: 5/10 Train loss: 0.406646 Valid loss: 0.646334 Train acc: 0.870968 Valid acc: 0.826221\n",
      "Epoch: 5/10 Train loss: 0.449845 Valid loss: 0.645944 Train acc: 0.838710 Valid acc: 0.826236\n",
      "Epoch: 5/10 Train loss: 0.561838 Valid loss: 0.645536 Train acc: 0.806452 Valid acc: 0.826251\n",
      "Epoch: 5/10 Train loss: 0.480373 Valid loss: 0.645132 Train acc: 0.838710 Valid acc: 0.826266\n",
      "Epoch: 5/10 Train loss: 0.402476 Valid loss: 0.644731 Train acc: 0.838710 Valid acc: 0.826281\n",
      "Epoch: 5/10 Train loss: 0.442158 Valid loss: 0.644333 Train acc: 0.838710 Valid acc: 0.826296\n",
      "Epoch: 5/10 Train loss: 0.500204 Valid loss: 0.643938 Train acc: 0.806452 Valid acc: 0.826311\n",
      "Epoch: 5/10 Train loss: 0.391944 Valid loss: 0.643544 Train acc: 0.870968 Valid acc: 0.826326\n",
      "Epoch: 5/10 Train loss: 0.439156 Valid loss: 0.643152 Train acc: 0.838710 Valid acc: 0.826341\n",
      "Epoch: 5/10 Train loss: 0.560152 Valid loss: 0.642761 Train acc: 0.806452 Valid acc: 0.826355\n",
      "Epoch: 5/10 Train loss: 0.438045 Valid loss: 0.642373 Train acc: 0.838710 Valid acc: 0.826370\n",
      "Epoch: 5/10 Train loss: 0.491376 Valid loss: 0.641985 Train acc: 0.806452 Valid acc: 0.826385\n",
      "Epoch: 5/10 Train loss: 0.362921 Valid loss: 0.641599 Train acc: 0.870968 Valid acc: 0.826399\n",
      "Epoch: 5/10 Train loss: 0.449846 Valid loss: 0.641213 Train acc: 0.838710 Valid acc: 0.826414\n",
      "Epoch: 5/10 Train loss: 0.590390 Valid loss: 0.640830 Train acc: 0.806452 Valid acc: 0.826428\n",
      "Epoch: 5/10 Train loss: 0.426613 Valid loss: 0.640448 Train acc: 0.838710 Valid acc: 0.826442\n",
      "Epoch: 5/10 Train loss: 0.455694 Valid loss: 0.640070 Train acc: 0.838710 Valid acc: 0.826457\n",
      "Epoch: 5/10 Train loss: 0.467682 Valid loss: 0.639694 Train acc: 0.838710 Valid acc: 0.826471\n",
      "Epoch: 5/10 Train loss: 0.469189 Valid loss: 0.639320 Train acc: 0.838710 Valid acc: 0.826485\n",
      "Epoch: 5/10 Train loss: 0.493384 Valid loss: 0.638949 Train acc: 0.806452 Valid acc: 0.826499\n",
      "Epoch: 5/10 Train loss: 0.479159 Valid loss: 0.638580 Train acc: 0.806452 Valid acc: 0.826513\n",
      "Epoch: 5/10 Train loss: 0.372148 Valid loss: 0.638211 Train acc: 0.870968 Valid acc: 0.826527\n",
      "Epoch: 5/10 Train loss: 0.446059 Valid loss: 0.637842 Train acc: 0.838710 Valid acc: 0.826541\n",
      "Epoch: 5/10 Train loss: 0.452368 Valid loss: 0.637472 Train acc: 0.838710 Valid acc: 0.826555\n",
      "Epoch: 5/10 Train loss: 0.436033 Valid loss: 0.637101 Train acc: 0.838710 Valid acc: 0.826569\n",
      "Epoch: 5/10 Train loss: 0.494767 Valid loss: 0.636730 Train acc: 0.806452 Valid acc: 0.826582\n",
      "Epoch: 5/10 Train loss: 0.392999 Valid loss: 0.636359 Train acc: 0.870968 Valid acc: 0.826596\n",
      "Epoch: 5/10 Train loss: 0.474260 Valid loss: 0.635989 Train acc: 0.806452 Valid acc: 0.826610\n",
      "Epoch: 5/10 Train loss: 0.432066 Valid loss: 0.635621 Train acc: 0.838710 Valid acc: 0.826623\n",
      "Epoch: 5/10 Train loss: 0.401523 Valid loss: 0.635255 Train acc: 0.838710 Valid acc: 0.826637\n",
      "Epoch: 5/10 Train loss: 0.446899 Valid loss: 0.634892 Train acc: 0.838710 Valid acc: 0.826650\n",
      "Epoch: 5/10 Train loss: 0.514837 Valid loss: 0.634531 Train acc: 0.774194 Valid acc: 0.826664\n",
      "Epoch: 5/10 Train loss: 0.496913 Valid loss: 0.634173 Train acc: 0.806452 Valid acc: 0.826677\n",
      "Epoch: 5/10 Train loss: 0.469114 Valid loss: 0.633818 Train acc: 0.838710 Valid acc: 0.826690\n",
      "Epoch: 5/10 Train loss: 0.428633 Valid loss: 0.633466 Train acc: 0.838710 Valid acc: 0.826704\n",
      "Epoch: 6/10 Train loss: 0.417076 Valid loss: 0.633117 Train acc: 0.870968 Valid acc: 0.826717\n",
      "Epoch: 6/10 Train loss: 0.506779 Valid loss: 0.632769 Train acc: 0.806452 Valid acc: 0.826730\n",
      "Epoch: 6/10 Train loss: 0.512672 Valid loss: 0.632421 Train acc: 0.806452 Valid acc: 0.826743\n",
      "Epoch: 6/10 Train loss: 0.409735 Valid loss: 0.632074 Train acc: 0.870968 Valid acc: 0.826756\n",
      "Epoch: 6/10 Train loss: 0.505337 Valid loss: 0.631726 Train acc: 0.806452 Valid acc: 0.826769\n",
      "Epoch: 6/10 Train loss: 0.411734 Valid loss: 0.631378 Train acc: 0.870968 Valid acc: 0.826782\n",
      "Epoch: 6/10 Train loss: 0.556208 Valid loss: 0.631031 Train acc: 0.806452 Valid acc: 0.826795\n",
      "Epoch: 6/10 Train loss: 0.491829 Valid loss: 0.630683 Train acc: 0.806452 Valid acc: 0.826808\n",
      "Epoch: 6/10 Train loss: 0.453476 Valid loss: 0.630336 Train acc: 0.838710 Valid acc: 0.826821\n",
      "Epoch: 6/10 Train loss: 0.521456 Valid loss: 0.629990 Train acc: 0.806452 Valid acc: 0.826834\n",
      "Epoch: 6/10 Train loss: 0.372096 Valid loss: 0.629646 Train acc: 0.870968 Valid acc: 0.826846\n",
      "Epoch: 6/10 Train loss: 0.508669 Valid loss: 0.629305 Train acc: 0.806452 Valid acc: 0.826859\n",
      "Epoch: 6/10 Train loss: 0.433813 Valid loss: 0.628965 Train acc: 0.838710 Valid acc: 0.826872\n",
      "Epoch: 6/10 Train loss: 0.485230 Valid loss: 0.628630 Train acc: 0.806452 Valid acc: 0.826884\n",
      "Epoch: 6/10 Train loss: 0.380283 Valid loss: 0.628296 Train acc: 0.870968 Valid acc: 0.826897\n",
      "Epoch: 6/10 Train loss: 0.515325 Valid loss: 0.627964 Train acc: 0.806452 Valid acc: 0.826909\n",
      "Epoch: 6/10 Train loss: 0.460745 Valid loss: 0.627638 Train acc: 0.838710 Valid acc: 0.826922\n",
      "Epoch: 6/10 Train loss: 0.401968 Valid loss: 0.627325 Train acc: 0.838710 Valid acc: 0.826934\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 Train loss: 0.419088 Valid loss: 0.627129 Train acc: 0.838710 Valid acc: 0.826946\n",
      "Epoch: 6/10 Train loss: 0.598323 Valid loss: 0.626812 Train acc: 0.806452 Valid acc: 0.826959\n",
      "Epoch: 6/10 Train loss: 0.418838 Valid loss: 0.626500 Train acc: 0.838710 Valid acc: 0.826971\n",
      "Epoch: 6/10 Train loss: 0.422338 Valid loss: 0.626193 Train acc: 0.838710 Valid acc: 0.826983\n",
      "Epoch: 6/10 Train loss: 0.504905 Valid loss: 0.625887 Train acc: 0.838710 Valid acc: 0.826995\n",
      "Epoch: 6/10 Train loss: 0.474866 Valid loss: 0.625582 Train acc: 0.838710 Valid acc: 0.827007\n",
      "Epoch: 6/10 Train loss: 0.411960 Valid loss: 0.625274 Train acc: 0.870968 Valid acc: 0.827019\n",
      "Epoch: 6/10 Train loss: 0.492204 Valid loss: 0.624963 Train acc: 0.806452 Valid acc: 0.827031\n",
      "Epoch: 6/10 Train loss: 0.450179 Valid loss: 0.624651 Train acc: 0.838710 Valid acc: 0.827043\n",
      "Epoch: 6/10 Train loss: 0.488330 Valid loss: 0.624336 Train acc: 0.806452 Valid acc: 0.827055\n",
      "Epoch: 6/10 Train loss: 0.436199 Valid loss: 0.624019 Train acc: 0.838710 Valid acc: 0.827067\n",
      "Epoch: 6/10 Train loss: 0.420032 Valid loss: 0.623702 Train acc: 0.838710 Valid acc: 0.827079\n",
      "Epoch: 6/10 Train loss: 0.445835 Valid loss: 0.623384 Train acc: 0.838710 Valid acc: 0.827091\n",
      "Epoch: 6/10 Train loss: 0.388138 Valid loss: 0.623069 Train acc: 0.870968 Valid acc: 0.827102\n",
      "Epoch: 6/10 Train loss: 0.511667 Valid loss: 0.622760 Train acc: 0.806452 Valid acc: 0.827114\n",
      "Epoch: 6/10 Train loss: 0.560593 Valid loss: 0.622452 Train acc: 0.838710 Valid acc: 0.827126\n",
      "Epoch: 6/10 Train loss: 0.465018 Valid loss: 0.622148 Train acc: 0.806452 Valid acc: 0.827138\n",
      "Epoch: 6/10 Train loss: 0.437209 Valid loss: 0.621845 Train acc: 0.838710 Valid acc: 0.827149\n",
      "Epoch: 6/10 Train loss: 0.438496 Valid loss: 0.621543 Train acc: 0.838710 Valid acc: 0.827161\n",
      "Epoch: 6/10 Train loss: 0.451073 Valid loss: 0.621239 Train acc: 0.838710 Valid acc: 0.827172\n",
      "Epoch: 6/10 Train loss: 0.517429 Valid loss: 0.620935 Train acc: 0.806452 Valid acc: 0.827184\n",
      "Epoch: 6/10 Train loss: 0.415688 Valid loss: 0.620628 Train acc: 0.838710 Valid acc: 0.827195\n",
      "Epoch: 6/10 Train loss: 0.501989 Valid loss: 0.620319 Train acc: 0.838710 Valid acc: 0.827206\n",
      "Epoch: 6/10 Train loss: 0.478639 Valid loss: 0.620012 Train acc: 0.806452 Valid acc: 0.827218\n",
      "Epoch: 6/10 Train loss: 0.474734 Valid loss: 0.619707 Train acc: 0.838710 Valid acc: 0.827229\n",
      "Epoch: 6/10 Train loss: 0.521689 Valid loss: 0.619404 Train acc: 0.774194 Valid acc: 0.827240\n",
      "Epoch: 6/10 Train loss: 0.393103 Valid loss: 0.619104 Train acc: 0.870968 Valid acc: 0.827251\n",
      "Epoch: 6/10 Train loss: 0.497961 Valid loss: 0.618807 Train acc: 0.806452 Valid acc: 0.827263\n",
      "Epoch: 6/10 Train loss: 0.527663 Valid loss: 0.618512 Train acc: 0.806452 Valid acc: 0.827274\n",
      "Epoch: 6/10 Train loss: 0.407841 Valid loss: 0.618220 Train acc: 0.870968 Valid acc: 0.827285\n",
      "Epoch: 6/10 Train loss: 0.438430 Valid loss: 0.617930 Train acc: 0.838710 Valid acc: 0.827296\n",
      "Epoch: 6/10 Train loss: 0.465328 Valid loss: 0.617646 Train acc: 0.838710 Valid acc: 0.827291\n",
      "Epoch: 6/10 Train loss: 0.533421 Valid loss: 0.617415 Train acc: 0.806452 Valid acc: 0.827266\n",
      "Epoch: 6/10 Train loss: 0.455808 Valid loss: 0.617282 Train acc: 0.838710 Valid acc: 0.827187\n",
      "Epoch: 6/10 Train loss: 1.485761 Valid loss: 0.617046 Train acc: 0.612903 Valid acc: 0.827198\n",
      "Epoch: 6/10 Train loss: 0.525093 Valid loss: 0.616911 Train acc: 0.838710 Valid acc: 0.827209\n",
      "Epoch: 6/10 Train loss: 0.458559 Valid loss: 0.616846 Train acc: 0.838710 Valid acc: 0.827220\n",
      "Epoch: 6/10 Train loss: 0.409635 Valid loss: 0.616857 Train acc: 0.838710 Valid acc: 0.827232\n",
      "Epoch: 6/10 Train loss: 0.527372 Valid loss: 0.616931 Train acc: 0.806452 Valid acc: 0.827242\n",
      "Epoch: 6/10 Train loss: 0.657465 Valid loss: 0.616810 Train acc: 0.838710 Valid acc: 0.827253\n",
      "Epoch: 6/10 Train loss: 0.357815 Valid loss: 0.616578 Train acc: 0.838710 Valid acc: 0.827264\n",
      "Epoch: 6/10 Train loss: 0.488670 Valid loss: 0.616303 Train acc: 0.838710 Valid acc: 0.827275\n",
      "Epoch: 6/10 Train loss: 0.495502 Valid loss: 0.616022 Train acc: 0.806452 Valid acc: 0.827286\n",
      "Epoch: 6/10 Train loss: 0.385168 Valid loss: 0.615738 Train acc: 0.870968 Valid acc: 0.827297\n",
      "Epoch: 6/10 Train loss: 0.531039 Valid loss: 0.615455 Train acc: 0.806452 Valid acc: 0.827308\n",
      "Epoch: 6/10 Train loss: 0.391534 Valid loss: 0.615172 Train acc: 0.870968 Valid acc: 0.827318\n",
      "Epoch: 6/10 Train loss: 0.517595 Valid loss: 0.614891 Train acc: 0.806452 Valid acc: 0.827329\n",
      "Epoch: 6/10 Train loss: 0.445224 Valid loss: 0.614611 Train acc: 0.838710 Valid acc: 0.827340\n",
      "Epoch: 6/10 Train loss: 0.482374 Valid loss: 0.614335 Train acc: 0.806452 Valid acc: 0.827350\n",
      "Epoch: 6/10 Train loss: 0.405675 Valid loss: 0.614060 Train acc: 0.870968 Valid acc: 0.827361\n",
      "Epoch: 6/10 Train loss: 0.441112 Valid loss: 0.613786 Train acc: 0.838710 Valid acc: 0.827371\n",
      "Epoch: 6/10 Train loss: 0.502779 Valid loss: 0.613513 Train acc: 0.806452 Valid acc: 0.827382\n",
      "Epoch: 6/10 Train loss: 0.449652 Valid loss: 0.613241 Train acc: 0.838710 Valid acc: 0.827392\n",
      "Epoch: 6/10 Train loss: 0.441830 Valid loss: 0.612969 Train acc: 0.838710 Valid acc: 0.827403\n",
      "Epoch: 6/10 Train loss: 0.403851 Valid loss: 0.612698 Train acc: 0.838710 Valid acc: 0.827413\n",
      "Epoch: 6/10 Train loss: 0.506365 Valid loss: 0.612429 Train acc: 0.806452 Valid acc: 0.827423\n",
      "Epoch: 6/10 Train loss: 0.377179 Valid loss: 0.612160 Train acc: 0.870968 Valid acc: 0.827434\n",
      "Epoch: 6/10 Train loss: 0.455894 Valid loss: 0.611892 Train acc: 0.838710 Valid acc: 0.827444\n",
      "Epoch: 6/10 Train loss: 0.531749 Valid loss: 0.611630 Train acc: 0.806452 Valid acc: 0.827454\n",
      "Epoch: 6/10 Train loss: 0.415494 Valid loss: 0.611405 Train acc: 0.838710 Valid acc: 0.827465\n",
      "Epoch: 6/10 Train loss: 0.627584 Valid loss: 0.611159 Train acc: 0.806452 Valid acc: 0.827475\n",
      "Epoch: 6/10 Train loss: 0.388583 Valid loss: 0.610916 Train acc: 0.870968 Valid acc: 0.827485\n",
      "Epoch: 6/10 Train loss: 0.436293 Valid loss: 0.610711 Train acc: 0.838710 Valid acc: 0.827495\n",
      "Epoch: 6/10 Train loss: 0.512556 Valid loss: 0.610482 Train acc: 0.806452 Valid acc: 0.827505\n",
      "Epoch: 6/10 Train loss: 0.530719 Valid loss: 0.610252 Train acc: 0.838710 Valid acc: 0.827515\n",
      "Epoch: 6/10 Train loss: 0.441091 Valid loss: 0.610030 Train acc: 0.838710 Valid acc: 0.827525\n",
      "Epoch: 6/10 Train loss: 0.540579 Valid loss: 0.609816 Train acc: 0.838710 Valid acc: 0.827535\n",
      "Epoch: 6/10 Train loss: 0.497066 Valid loss: 0.609612 Train acc: 0.838710 Valid acc: 0.827545\n",
      "Epoch: 6/10 Train loss: 0.513424 Valid loss: 0.609414 Train acc: 0.806452 Valid acc: 0.827555\n",
      "Epoch: 6/10 Train loss: 0.547763 Valid loss: 0.609219 Train acc: 0.806452 Valid acc: 0.827565\n",
      "Epoch: 6/10 Train loss: 0.458019 Valid loss: 0.609024 Train acc: 0.870968 Valid acc: 0.827575\n",
      "Epoch: 6/10 Train loss: 0.492613 Valid loss: 0.608822 Train acc: 0.838710 Valid acc: 0.827584\n",
      "Epoch: 6/10 Train loss: 0.509016 Valid loss: 0.608606 Train acc: 0.838710 Valid acc: 0.827594\n",
      "Epoch: 6/10 Train loss: 0.472075 Valid loss: 0.608370 Train acc: 0.838710 Valid acc: 0.827604\n",
      "Epoch: 6/10 Train loss: 0.528260 Valid loss: 0.608136 Train acc: 0.806452 Valid acc: 0.827614\n",
      "Epoch: 6/10 Train loss: 0.416503 Valid loss: 0.607894 Train acc: 0.870968 Valid acc: 0.827623\n",
      "Epoch: 6/10 Train loss: 0.494662 Valid loss: 0.607649 Train acc: 0.806452 Valid acc: 0.827633\n",
      "Epoch: 6/10 Train loss: 0.435754 Valid loss: 0.607399 Train acc: 0.838710 Valid acc: 0.827643\n",
      "Epoch: 6/10 Train loss: 0.446353 Valid loss: 0.607146 Train acc: 0.838710 Valid acc: 0.827652\n",
      "Epoch: 6/10 Train loss: 0.446206 Valid loss: 0.606890 Train acc: 0.838710 Valid acc: 0.827662\n",
      "Epoch: 6/10 Train loss: 0.511972 Valid loss: 0.606634 Train acc: 0.774194 Valid acc: 0.827671\n",
      "Epoch: 6/10 Train loss: 0.482613 Valid loss: 0.606378 Train acc: 0.838710 Valid acc: 0.827681\n",
      "Epoch: 6/10 Train loss: 0.423371 Valid loss: 0.606122 Train acc: 0.838710 Valid acc: 0.827690\n",
      "Epoch: 6/10 Train loss: 0.434067 Valid loss: 0.605883 Train acc: 0.838710 Valid acc: 0.827700\n",
      "Epoch: 7/10 Train loss: 0.577477 Valid loss: 0.605628 Train acc: 0.870968 Valid acc: 0.827709\n",
      "Epoch: 7/10 Train loss: 0.503562 Valid loss: 0.605376 Train acc: 0.806452 Valid acc: 0.827718\n",
      "Epoch: 7/10 Train loss: 0.514880 Valid loss: 0.605123 Train acc: 0.806452 Valid acc: 0.827728\n",
      "Epoch: 7/10 Train loss: 0.394732 Valid loss: 0.604872 Train acc: 0.870968 Valid acc: 0.827737\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 Train loss: 0.484093 Valid loss: 0.604622 Train acc: 0.806452 Valid acc: 0.827746\n",
      "Epoch: 7/10 Train loss: 0.425927 Valid loss: 0.604373 Train acc: 0.806452 Valid acc: 0.827755\n",
      "Epoch: 7/10 Train loss: 0.490068 Valid loss: 0.604125 Train acc: 0.806452 Valid acc: 0.827765\n",
      "Epoch: 7/10 Train loss: 0.518154 Valid loss: 0.603878 Train acc: 0.774194 Valid acc: 0.827774\n",
      "Epoch: 7/10 Train loss: 0.437316 Valid loss: 0.603633 Train acc: 0.838710 Valid acc: 0.827783\n",
      "Epoch: 7/10 Train loss: 0.439225 Valid loss: 0.603387 Train acc: 0.838710 Valid acc: 0.827792\n",
      "Epoch: 7/10 Train loss: 0.370237 Valid loss: 0.603143 Train acc: 0.870968 Valid acc: 0.827801\n",
      "Epoch: 7/10 Train loss: 0.535326 Valid loss: 0.602900 Train acc: 0.806452 Valid acc: 0.827810\n",
      "Epoch: 7/10 Train loss: 0.423331 Valid loss: 0.602658 Train acc: 0.838710 Valid acc: 0.827819\n",
      "Epoch: 7/10 Train loss: 0.497630 Valid loss: 0.602417 Train acc: 0.806452 Valid acc: 0.827828\n",
      "Epoch: 7/10 Train loss: 0.406305 Valid loss: 0.602178 Train acc: 0.870968 Valid acc: 0.827837\n",
      "Epoch: 7/10 Train loss: 0.498586 Valid loss: 0.601942 Train acc: 0.806452 Valid acc: 0.827846\n",
      "Epoch: 7/10 Train loss: 0.506906 Valid loss: 0.601708 Train acc: 0.838710 Valid acc: 0.827855\n",
      "Epoch: 7/10 Train loss: 0.427969 Valid loss: 0.601474 Train acc: 0.838710 Valid acc: 0.827864\n",
      "Epoch: 7/10 Train loss: 0.455120 Valid loss: 0.601241 Train acc: 0.838710 Valid acc: 0.827873\n",
      "Epoch: 7/10 Train loss: 0.496184 Valid loss: 0.601009 Train acc: 0.774194 Valid acc: 0.827882\n",
      "Epoch: 7/10 Train loss: 0.420342 Valid loss: 0.600778 Train acc: 0.838710 Valid acc: 0.827891\n",
      "Epoch: 7/10 Train loss: 0.422466 Valid loss: 0.600546 Train acc: 0.838710 Valid acc: 0.827899\n",
      "Epoch: 7/10 Train loss: 0.511590 Valid loss: 0.600315 Train acc: 0.838710 Valid acc: 0.827908\n",
      "Epoch: 7/10 Train loss: 0.427664 Valid loss: 0.600084 Train acc: 0.838710 Valid acc: 0.827917\n",
      "Epoch: 7/10 Train loss: 0.344735 Valid loss: 0.599853 Train acc: 0.903226 Valid acc: 0.827926\n",
      "Epoch: 7/10 Train loss: 0.525692 Valid loss: 0.599622 Train acc: 0.806452 Valid acc: 0.827934\n",
      "Epoch: 7/10 Train loss: 0.436017 Valid loss: 0.599407 Train acc: 0.838710 Valid acc: 0.827943\n",
      "Epoch: 7/10 Train loss: 1.010402 Valid loss: 0.599178 Train acc: 0.806452 Valid acc: 0.827951\n",
      "Epoch: 7/10 Train loss: 0.428632 Valid loss: 0.598953 Train acc: 0.838710 Valid acc: 0.827960\n",
      "Epoch: 7/10 Train loss: 0.436869 Valid loss: 0.598730 Train acc: 0.838710 Valid acc: 0.827969\n",
      "Epoch: 7/10 Train loss: 0.449895 Valid loss: 0.598509 Train acc: 0.838710 Valid acc: 0.827977\n",
      "Epoch: 7/10 Train loss: 0.399429 Valid loss: 0.598289 Train acc: 0.870968 Valid acc: 0.827986\n",
      "Epoch: 7/10 Train loss: 0.501063 Valid loss: 0.598070 Train acc: 0.806452 Valid acc: 0.827994\n",
      "Epoch: 7/10 Train loss: 0.438234 Valid loss: 0.597850 Train acc: 0.838710 Valid acc: 0.828003\n",
      "Epoch: 7/10 Train loss: 0.503186 Valid loss: 0.597630 Train acc: 0.806452 Valid acc: 0.828011\n",
      "Epoch: 7/10 Train loss: 0.437025 Valid loss: 0.597410 Train acc: 0.838710 Valid acc: 0.828019\n",
      "Epoch: 7/10 Train loss: 0.449276 Valid loss: 0.597189 Train acc: 0.838710 Valid acc: 0.828028\n",
      "Epoch: 7/10 Train loss: 0.446946 Valid loss: 0.596968 Train acc: 0.838710 Valid acc: 0.828036\n",
      "Epoch: 7/10 Train loss: 0.507675 Valid loss: 0.596748 Train acc: 0.806452 Valid acc: 0.828045\n",
      "Epoch: 7/10 Train loss: 0.442893 Valid loss: 0.596528 Train acc: 0.838710 Valid acc: 0.828053\n",
      "Epoch: 7/10 Train loss: 0.452078 Valid loss: 0.596310 Train acc: 0.838710 Valid acc: 0.828061\n",
      "Epoch: 7/10 Train loss: 0.486576 Valid loss: 0.596093 Train acc: 0.806452 Valid acc: 0.828069\n",
      "Epoch: 7/10 Train loss: 0.382676 Valid loss: 0.595877 Train acc: 0.870968 Valid acc: 0.828078\n",
      "Epoch: 7/10 Train loss: 0.509804 Valid loss: 0.595663 Train acc: 0.806452 Valid acc: 0.828086\n",
      "Epoch: 7/10 Train loss: 0.385339 Valid loss: 0.595447 Train acc: 0.870968 Valid acc: 0.828094\n",
      "Epoch: 7/10 Train loss: 0.507608 Valid loss: 0.595231 Train acc: 0.806452 Valid acc: 0.828102\n",
      "Epoch: 7/10 Train loss: 0.474291 Valid loss: 0.595013 Train acc: 0.806452 Valid acc: 0.828110\n",
      "Epoch: 7/10 Train loss: 0.389644 Valid loss: 0.594795 Train acc: 0.870968 Valid acc: 0.828118\n",
      "Epoch: 7/10 Train loss: 0.432272 Valid loss: 0.594577 Train acc: 0.838710 Valid acc: 0.828126\n",
      "Epoch: 7/10 Train loss: 0.437183 Valid loss: 0.594359 Train acc: 0.838710 Valid acc: 0.828134\n",
      "Epoch: 7/10 Train loss: 0.489905 Valid loss: 0.594141 Train acc: 0.806452 Valid acc: 0.828142\n",
      "Epoch: 7/10 Train loss: 0.418403 Valid loss: 0.593925 Train acc: 0.838710 Valid acc: 0.828151\n",
      "Epoch: 7/10 Train loss: 0.452450 Valid loss: 0.593709 Train acc: 0.838710 Valid acc: 0.828158\n",
      "Epoch: 7/10 Train loss: 0.389144 Valid loss: 0.593493 Train acc: 0.838710 Valid acc: 0.828166\n",
      "Epoch: 7/10 Train loss: 0.439593 Valid loss: 0.593279 Train acc: 0.838710 Valid acc: 0.828174\n",
      "Epoch: 7/10 Train loss: 0.438098 Valid loss: 0.593065 Train acc: 0.838710 Valid acc: 0.828182\n",
      "Epoch: 7/10 Train loss: 0.504319 Valid loss: 0.592852 Train acc: 0.806452 Valid acc: 0.828190\n",
      "Epoch: 7/10 Train loss: 0.442509 Valid loss: 0.592639 Train acc: 0.838710 Valid acc: 0.828198\n",
      "Epoch: 7/10 Train loss: 0.451434 Valid loss: 0.592428 Train acc: 0.838710 Valid acc: 0.828206\n",
      "Epoch: 7/10 Train loss: 0.427119 Valid loss: 0.592217 Train acc: 0.838710 Valid acc: 0.828214\n",
      "Epoch: 7/10 Train loss: 0.513087 Valid loss: 0.592006 Train acc: 0.806452 Valid acc: 0.828221\n",
      "Epoch: 7/10 Train loss: 0.423481 Valid loss: 0.591796 Train acc: 0.870968 Valid acc: 0.828229\n",
      "Epoch: 7/10 Train loss: 0.481386 Valid loss: 0.591587 Train acc: 0.806452 Valid acc: 0.828237\n",
      "Epoch: 7/10 Train loss: 0.396374 Valid loss: 0.591379 Train acc: 0.870968 Valid acc: 0.828245\n",
      "Epoch: 7/10 Train loss: 0.496071 Valid loss: 0.591171 Train acc: 0.806452 Valid acc: 0.828252\n",
      "Epoch: 7/10 Train loss: 0.436847 Valid loss: 0.590963 Train acc: 0.838710 Valid acc: 0.828260\n",
      "Epoch: 7/10 Train loss: 0.488055 Valid loss: 0.590756 Train acc: 0.806452 Valid acc: 0.828268\n",
      "Epoch: 7/10 Train loss: 0.389885 Valid loss: 0.590550 Train acc: 0.870968 Valid acc: 0.828275\n",
      "Epoch: 7/10 Train loss: 0.442169 Valid loss: 0.590344 Train acc: 0.838710 Valid acc: 0.828283\n",
      "Epoch: 7/10 Train loss: 0.528372 Valid loss: 0.590139 Train acc: 0.806452 Valid acc: 0.828291\n",
      "Epoch: 7/10 Train loss: 0.416668 Valid loss: 0.589935 Train acc: 0.838710 Valid acc: 0.828298\n",
      "Epoch: 7/10 Train loss: 0.463343 Valid loss: 0.589731 Train acc: 0.838710 Valid acc: 0.828306\n",
      "Epoch: 7/10 Train loss: 0.441863 Valid loss: 0.589528 Train acc: 0.838710 Valid acc: 0.828313\n",
      "Epoch: 7/10 Train loss: 0.504208 Valid loss: 0.589325 Train acc: 0.806452 Valid acc: 0.828321\n",
      "Epoch: 7/10 Train loss: 0.391999 Valid loss: 0.589123 Train acc: 0.870968 Valid acc: 0.828328\n",
      "Epoch: 7/10 Train loss: 0.432044 Valid loss: 0.588922 Train acc: 0.838710 Valid acc: 0.828336\n",
      "Epoch: 7/10 Train loss: 0.522828 Valid loss: 0.588721 Train acc: 0.806452 Valid acc: 0.828343\n",
      "Epoch: 7/10 Train loss: 0.446432 Valid loss: 0.588521 Train acc: 0.838710 Valid acc: 0.828351\n",
      "Epoch: 7/10 Train loss: 0.478854 Valid loss: 0.588322 Train acc: 0.806452 Valid acc: 0.828358\n",
      "Epoch: 7/10 Train loss: 0.388478 Valid loss: 0.588123 Train acc: 0.870968 Valid acc: 0.828365\n",
      "Epoch: 7/10 Train loss: 0.433630 Valid loss: 0.587924 Train acc: 0.838710 Valid acc: 0.828373\n",
      "Epoch: 7/10 Train loss: 0.490350 Valid loss: 0.587727 Train acc: 0.806452 Valid acc: 0.828380\n",
      "Epoch: 7/10 Train loss: 0.415707 Valid loss: 0.587529 Train acc: 0.838710 Valid acc: 0.828387\n",
      "Epoch: 7/10 Train loss: 0.437453 Valid loss: 0.587332 Train acc: 0.838710 Valid acc: 0.828395\n",
      "Epoch: 7/10 Train loss: 0.442087 Valid loss: 0.587137 Train acc: 0.838710 Valid acc: 0.828402\n",
      "Epoch: 7/10 Train loss: 0.425795 Valid loss: 0.586941 Train acc: 0.838710 Valid acc: 0.828409\n",
      "Epoch: 7/10 Train loss: 0.486393 Valid loss: 0.586748 Train acc: 0.806452 Valid acc: 0.828416\n",
      "Epoch: 7/10 Train loss: 0.457670 Valid loss: 0.586559 Train acc: 0.806452 Valid acc: 0.828423\n",
      "Epoch: 7/10 Train loss: 0.399820 Valid loss: 0.586387 Train acc: 0.870968 Valid acc: 0.828431\n",
      "Epoch: 7/10 Train loss: 0.544654 Valid loss: 0.586197 Train acc: 0.838710 Valid acc: 0.828438\n",
      "Epoch: 7/10 Train loss: 0.465589 Valid loss: 0.586009 Train acc: 0.838710 Valid acc: 0.828445\n",
      "Epoch: 7/10 Train loss: 0.426521 Valid loss: 0.585823 Train acc: 0.838710 Valid acc: 0.828452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 Train loss: 0.496604 Valid loss: 0.585639 Train acc: 0.806452 Valid acc: 0.828459\n",
      "Epoch: 7/10 Train loss: 0.398357 Valid loss: 0.585455 Train acc: 0.870968 Valid acc: 0.828466\n",
      "Epoch: 7/10 Train loss: 0.502597 Valid loss: 0.585271 Train acc: 0.806452 Valid acc: 0.828473\n",
      "Epoch: 7/10 Train loss: 0.449232 Valid loss: 0.585087 Train acc: 0.838710 Valid acc: 0.828480\n",
      "Epoch: 7/10 Train loss: 0.405124 Valid loss: 0.584902 Train acc: 0.838710 Valid acc: 0.828487\n",
      "Epoch: 7/10 Train loss: 0.407873 Valid loss: 0.584717 Train acc: 0.838710 Valid acc: 0.828494\n",
      "Epoch: 7/10 Train loss: 0.504265 Valid loss: 0.584533 Train acc: 0.806452 Valid acc: 0.828501\n",
      "Epoch: 7/10 Train loss: 0.550429 Valid loss: 0.584351 Train acc: 0.838710 Valid acc: 0.828508\n",
      "Epoch: 7/10 Train loss: 0.437201 Valid loss: 0.584173 Train acc: 0.838710 Valid acc: 0.828515\n",
      "Epoch: 7/10 Train loss: 0.442203 Valid loss: 0.583998 Train acc: 0.838710 Valid acc: 0.828522\n",
      "Epoch: 8/10 Train loss: 0.458614 Valid loss: 0.583823 Train acc: 0.838710 Valid acc: 0.828529\n",
      "Epoch: 8/10 Train loss: 0.515421 Valid loss: 0.583650 Train acc: 0.806452 Valid acc: 0.828536\n",
      "Epoch: 8/10 Train loss: 0.493329 Valid loss: 0.583478 Train acc: 0.806452 Valid acc: 0.828543\n",
      "Epoch: 8/10 Train loss: 0.433807 Valid loss: 0.583307 Train acc: 0.870968 Valid acc: 0.828550\n",
      "Epoch: 8/10 Train loss: 0.489554 Valid loss: 0.583135 Train acc: 0.806452 Valid acc: 0.828557\n",
      "Epoch: 8/10 Train loss: 0.400917 Valid loss: 0.582965 Train acc: 0.870968 Valid acc: 0.828563\n",
      "Epoch: 8/10 Train loss: 0.511061 Valid loss: 0.582796 Train acc: 0.806452 Valid acc: 0.828570\n",
      "Epoch: 8/10 Train loss: 0.460079 Valid loss: 0.582628 Train acc: 0.806452 Valid acc: 0.828577\n",
      "Epoch: 8/10 Train loss: 0.433267 Valid loss: 0.582462 Train acc: 0.838710 Valid acc: 0.828584\n",
      "Epoch: 8/10 Train loss: 0.446660 Valid loss: 0.582298 Train acc: 0.838710 Valid acc: 0.828590\n",
      "Epoch: 8/10 Train loss: 0.364880 Valid loss: 0.582139 Train acc: 0.870968 Valid acc: 0.828597\n",
      "Epoch: 8/10 Train loss: 0.494822 Valid loss: 0.581984 Train acc: 0.806452 Valid acc: 0.828604\n",
      "Epoch: 8/10 Train loss: 0.449089 Valid loss: 0.581833 Train acc: 0.838710 Valid acc: 0.828610\n",
      "Epoch: 8/10 Train loss: 0.522896 Valid loss: 0.581686 Train acc: 0.806452 Valid acc: 0.828617\n",
      "Epoch: 8/10 Train loss: 0.386197 Valid loss: 0.581543 Train acc: 0.870968 Valid acc: 0.828624\n",
      "Epoch: 8/10 Train loss: 0.503538 Valid loss: 0.581403 Train acc: 0.806452 Valid acc: 0.828630\n",
      "Epoch: 8/10 Train loss: 0.431506 Valid loss: 0.581268 Train acc: 0.838710 Valid acc: 0.828637\n",
      "Epoch: 8/10 Train loss: 0.393798 Valid loss: 0.581138 Train acc: 0.838710 Valid acc: 0.828644\n",
      "Epoch: 8/10 Train loss: 0.430609 Valid loss: 0.581013 Train acc: 0.838710 Valid acc: 0.828650\n",
      "Epoch: 8/10 Train loss: 0.495595 Valid loss: 0.580894 Train acc: 0.806452 Valid acc: 0.828657\n",
      "Epoch: 8/10 Train loss: 1.331047 Valid loss: 0.580726 Train acc: 0.838710 Valid acc: 0.828663\n",
      "Epoch: 8/10 Train loss: 0.439977 Valid loss: 0.580555 Train acc: 0.838710 Valid acc: 0.828670\n",
      "Epoch: 8/10 Train loss: 0.442171 Valid loss: 0.580387 Train acc: 0.838710 Valid acc: 0.828676\n",
      "Epoch: 8/10 Train loss: 0.469819 Valid loss: 0.580222 Train acc: 0.838710 Valid acc: 0.828683\n",
      "Epoch: 8/10 Train loss: 0.426921 Valid loss: 0.580059 Train acc: 0.870968 Valid acc: 0.828689\n",
      "Epoch: 8/10 Train loss: 0.484249 Valid loss: 0.579896 Train acc: 0.806452 Valid acc: 0.828696\n",
      "Epoch: 8/10 Train loss: 0.456824 Valid loss: 0.579732 Train acc: 0.838710 Valid acc: 0.828702\n",
      "Epoch: 8/10 Train loss: 0.532312 Valid loss: 0.579568 Train acc: 0.806452 Valid acc: 0.828708\n",
      "Epoch: 8/10 Train loss: 0.458302 Valid loss: 0.579403 Train acc: 0.838710 Valid acc: 0.828715\n",
      "Epoch: 8/10 Train loss: 0.455660 Valid loss: 0.579236 Train acc: 0.838710 Valid acc: 0.828721\n",
      "Epoch: 8/10 Train loss: 0.449678 Valid loss: 0.579068 Train acc: 0.838710 Valid acc: 0.828728\n",
      "Epoch: 8/10 Train loss: 0.390900 Valid loss: 0.578897 Train acc: 0.870968 Valid acc: 0.828734\n",
      "Epoch: 8/10 Train loss: 0.494899 Valid loss: 0.578726 Train acc: 0.806452 Valid acc: 0.828740\n",
      "Epoch: 8/10 Train loss: 0.446689 Valid loss: 0.578557 Train acc: 0.838710 Valid acc: 0.828747\n",
      "Epoch: 8/10 Train loss: 0.504227 Valid loss: 0.578387 Train acc: 0.806452 Valid acc: 0.828753\n",
      "Epoch: 8/10 Train loss: 0.419747 Valid loss: 0.578217 Train acc: 0.838710 Valid acc: 0.828759\n",
      "Epoch: 8/10 Train loss: 0.456185 Valid loss: 0.578047 Train acc: 0.838710 Valid acc: 0.828765\n",
      "Epoch: 8/10 Train loss: 0.454762 Valid loss: 0.577878 Train acc: 0.838710 Valid acc: 0.828772\n",
      "Epoch: 8/10 Train loss: 0.450998 Valid loss: 0.577709 Train acc: 0.838710 Valid acc: 0.828778\n",
      "Epoch: 8/10 Train loss: 0.450309 Valid loss: 0.577541 Train acc: 0.838710 Valid acc: 0.828784\n",
      "Epoch: 8/10 Train loss: 0.442001 Valid loss: 0.577374 Train acc: 0.838710 Valid acc: 0.828790\n",
      "Epoch: 8/10 Train loss: 0.488577 Valid loss: 0.577206 Train acc: 0.806452 Valid acc: 0.828796\n",
      "Epoch: 8/10 Train loss: 0.387383 Valid loss: 0.577039 Train acc: 0.870968 Valid acc: 0.828803\n",
      "Epoch: 8/10 Train loss: 0.491531 Valid loss: 0.576873 Train acc: 0.806452 Valid acc: 0.828809\n",
      "Epoch: 8/10 Train loss: 0.395948 Valid loss: 0.576707 Train acc: 0.870968 Valid acc: 0.828815\n",
      "Epoch: 8/10 Train loss: 0.492454 Valid loss: 0.576541 Train acc: 0.806452 Valid acc: 0.828821\n",
      "Epoch: 8/10 Train loss: 0.486561 Valid loss: 0.576375 Train acc: 0.806452 Valid acc: 0.828827\n",
      "Epoch: 8/10 Train loss: 0.408963 Valid loss: 0.576210 Train acc: 0.870968 Valid acc: 0.828833\n",
      "Epoch: 8/10 Train loss: 0.428407 Valid loss: 0.576045 Train acc: 0.838710 Valid acc: 0.828839\n",
      "Epoch: 8/10 Train loss: 0.443885 Valid loss: 0.575880 Train acc: 0.838710 Valid acc: 0.828845\n",
      "Epoch: 8/10 Train loss: 0.494215 Valid loss: 0.575716 Train acc: 0.806452 Valid acc: 0.828851\n",
      "Epoch: 8/10 Train loss: 0.442064 Valid loss: 0.575552 Train acc: 0.838710 Valid acc: 0.828857\n",
      "Epoch: 8/10 Train loss: 0.461008 Valid loss: 0.575389 Train acc: 0.806452 Valid acc: 0.828863\n",
      "Epoch: 8/10 Train loss: 0.423657 Valid loss: 0.575226 Train acc: 0.838710 Valid acc: 0.828869\n",
      "Epoch: 8/10 Train loss: 0.481400 Valid loss: 0.575063 Train acc: 0.838710 Valid acc: 0.828875\n",
      "Epoch: 8/10 Train loss: 0.466436 Valid loss: 0.574901 Train acc: 0.838710 Valid acc: 0.828881\n",
      "Epoch: 8/10 Train loss: 0.539082 Valid loss: 0.574740 Train acc: 0.806452 Valid acc: 0.828887\n",
      "Epoch: 8/10 Train loss: 0.444081 Valid loss: 0.574579 Train acc: 0.838710 Valid acc: 0.828893\n",
      "Epoch: 8/10 Train loss: 0.467075 Valid loss: 0.574419 Train acc: 0.838710 Valid acc: 0.828899\n",
      "Epoch: 8/10 Train loss: 0.468859 Valid loss: 0.574259 Train acc: 0.838710 Valid acc: 0.828905\n",
      "Epoch: 8/10 Train loss: 0.484677 Valid loss: 0.574100 Train acc: 0.806452 Valid acc: 0.828911\n",
      "Epoch: 8/10 Train loss: 0.398428 Valid loss: 0.573941 Train acc: 0.870968 Valid acc: 0.828917\n",
      "Epoch: 8/10 Train loss: 0.502614 Valid loss: 0.573782 Train acc: 0.806452 Valid acc: 0.828922\n",
      "Epoch: 8/10 Train loss: 0.394005 Valid loss: 0.573623 Train acc: 0.870968 Valid acc: 0.828928\n",
      "Epoch: 8/10 Train loss: 0.499644 Valid loss: 0.573464 Train acc: 0.806452 Valid acc: 0.828934\n",
      "Epoch: 8/10 Train loss: 0.437825 Valid loss: 0.573306 Train acc: 0.838710 Valid acc: 0.828940\n",
      "Epoch: 8/10 Train loss: 0.489359 Valid loss: 0.573149 Train acc: 0.806452 Valid acc: 0.828946\n",
      "Epoch: 8/10 Train loss: 0.362609 Valid loss: 0.572992 Train acc: 0.870968 Valid acc: 0.828951\n",
      "Epoch: 8/10 Train loss: 0.433401 Valid loss: 0.572836 Train acc: 0.838710 Valid acc: 0.828957\n",
      "Epoch: 8/10 Train loss: 0.524083 Valid loss: 0.572682 Train acc: 0.806452 Valid acc: 0.828963\n",
      "Epoch: 8/10 Train loss: 0.434242 Valid loss: 0.572529 Train acc: 0.838710 Valid acc: 0.828969\n",
      "Epoch: 8/10 Train loss: 0.449818 Valid loss: 0.572376 Train acc: 0.838710 Valid acc: 0.828974\n",
      "Epoch: 8/10 Train loss: 0.436676 Valid loss: 0.572224 Train acc: 0.838710 Valid acc: 0.828980\n",
      "Epoch: 8/10 Train loss: 0.490200 Valid loss: 0.572073 Train acc: 0.806452 Valid acc: 0.828986\n",
      "Epoch: 8/10 Train loss: 0.387770 Valid loss: 0.571921 Train acc: 0.870968 Valid acc: 0.828991\n",
      "Epoch: 8/10 Train loss: 0.440511 Valid loss: 0.571769 Train acc: 0.838710 Valid acc: 0.828997\n",
      "Epoch: 8/10 Train loss: 0.503094 Valid loss: 0.571616 Train acc: 0.806452 Valid acc: 0.829003\n",
      "Epoch: 8/10 Train loss: 0.445105 Valid loss: 0.571464 Train acc: 0.838710 Valid acc: 0.829008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Train loss: 0.502816 Valid loss: 0.571312 Train acc: 0.806452 Valid acc: 0.829014\n",
      "Epoch: 8/10 Train loss: 0.392519 Valid loss: 0.571160 Train acc: 0.870968 Valid acc: 0.829019\n",
      "Epoch: 8/10 Train loss: 0.430153 Valid loss: 0.571009 Train acc: 0.838710 Valid acc: 0.829025\n",
      "Epoch: 8/10 Train loss: 0.486906 Valid loss: 0.570859 Train acc: 0.806452 Valid acc: 0.829031\n",
      "Epoch: 8/10 Train loss: 0.441057 Valid loss: 0.570708 Train acc: 0.838710 Valid acc: 0.829036\n",
      "Epoch: 8/10 Train loss: 0.443764 Valid loss: 0.570559 Train acc: 0.838710 Valid acc: 0.829042\n",
      "Epoch: 8/10 Train loss: 0.444367 Valid loss: 0.570410 Train acc: 0.838710 Valid acc: 0.829047\n",
      "Epoch: 8/10 Train loss: 0.425556 Valid loss: 0.570261 Train acc: 0.838710 Valid acc: 0.829053\n",
      "Epoch: 8/10 Train loss: 0.515886 Valid loss: 0.570112 Train acc: 0.806452 Valid acc: 0.829058\n",
      "Epoch: 8/10 Train loss: 0.511148 Valid loss: 0.569963 Train acc: 0.806452 Valid acc: 0.829064\n",
      "Epoch: 8/10 Train loss: 0.402433 Valid loss: 0.569815 Train acc: 0.870968 Valid acc: 0.829069\n",
      "Epoch: 8/10 Train loss: 0.434676 Valid loss: 0.569667 Train acc: 0.838710 Valid acc: 0.829075\n",
      "Epoch: 8/10 Train loss: 0.449454 Valid loss: 0.569519 Train acc: 0.838710 Valid acc: 0.829080\n",
      "Epoch: 8/10 Train loss: 0.429537 Valid loss: 0.569371 Train acc: 0.838710 Valid acc: 0.829086\n",
      "Epoch: 8/10 Train loss: 0.498712 Valid loss: 0.569225 Train acc: 0.806452 Valid acc: 0.829091\n",
      "Epoch: 8/10 Train loss: 0.387739 Valid loss: 0.569078 Train acc: 0.870968 Valid acc: 0.829096\n",
      "Epoch: 8/10 Train loss: 0.505768 Valid loss: 0.568932 Train acc: 0.806452 Valid acc: 0.829102\n",
      "Epoch: 8/10 Train loss: 0.445844 Valid loss: 0.568786 Train acc: 0.838710 Valid acc: 0.829107\n",
      "Epoch: 8/10 Train loss: 0.438306 Valid loss: 0.568641 Train acc: 0.838710 Valid acc: 0.829113\n",
      "Epoch: 8/10 Train loss: 0.440753 Valid loss: 0.568496 Train acc: 0.838710 Valid acc: 0.829118\n",
      "Epoch: 8/10 Train loss: 0.492123 Valid loss: 0.568351 Train acc: 0.806452 Valid acc: 0.829123\n",
      "Epoch: 8/10 Train loss: 0.451640 Valid loss: 0.568206 Train acc: 0.838710 Valid acc: 0.829129\n",
      "Epoch: 8/10 Train loss: 0.457846 Valid loss: 0.568062 Train acc: 0.838710 Valid acc: 0.829134\n",
      "Epoch: 8/10 Train loss: 0.438935 Valid loss: 0.567918 Train acc: 0.838710 Valid acc: 0.829139\n",
      "Epoch: 9/10 Train loss: 0.365994 Valid loss: 0.567775 Train acc: 0.870968 Valid acc: 0.829144\n",
      "Epoch: 9/10 Train loss: 0.497338 Valid loss: 0.567631 Train acc: 0.806452 Valid acc: 0.829150\n",
      "Epoch: 9/10 Train loss: 0.512884 Valid loss: 0.567489 Train acc: 0.806452 Valid acc: 0.829155\n",
      "Epoch: 9/10 Train loss: 0.392215 Valid loss: 0.567346 Train acc: 0.870968 Valid acc: 0.829160\n",
      "Epoch: 9/10 Train loss: 0.491032 Valid loss: 0.567204 Train acc: 0.806452 Valid acc: 0.829166\n",
      "Epoch: 9/10 Train loss: 0.393568 Valid loss: 0.567062 Train acc: 0.870968 Valid acc: 0.829171\n",
      "Epoch: 9/10 Train loss: 0.486485 Valid loss: 0.566921 Train acc: 0.806452 Valid acc: 0.829176\n",
      "Epoch: 9/10 Train loss: 0.484025 Valid loss: 0.566780 Train acc: 0.806452 Valid acc: 0.829181\n",
      "Epoch: 9/10 Train loss: 0.434863 Valid loss: 0.566639 Train acc: 0.838710 Valid acc: 0.829186\n",
      "Epoch: 9/10 Train loss: 0.451377 Valid loss: 0.566499 Train acc: 0.838710 Valid acc: 0.829191\n",
      "Epoch: 9/10 Train loss: 0.391465 Valid loss: 0.566359 Train acc: 0.870968 Valid acc: 0.829197\n",
      "Epoch: 9/10 Train loss: 0.493634 Valid loss: 0.566220 Train acc: 0.806452 Valid acc: 0.829202\n",
      "Epoch: 9/10 Train loss: 0.452714 Valid loss: 0.566081 Train acc: 0.838710 Valid acc: 0.829207\n",
      "Epoch: 9/10 Train loss: 0.516570 Valid loss: 0.565943 Train acc: 0.806452 Valid acc: 0.829212\n",
      "Epoch: 9/10 Train loss: 0.386712 Valid loss: 0.565804 Train acc: 0.870968 Valid acc: 0.829217\n",
      "Epoch: 9/10 Train loss: 0.483769 Valid loss: 0.565666 Train acc: 0.806452 Valid acc: 0.829222\n",
      "Epoch: 9/10 Train loss: 0.437199 Valid loss: 0.565528 Train acc: 0.838710 Valid acc: 0.829227\n",
      "Epoch: 9/10 Train loss: 0.451858 Valid loss: 0.565390 Train acc: 0.838710 Valid acc: 0.829232\n",
      "Epoch: 9/10 Train loss: 0.458921 Valid loss: 0.565253 Train acc: 0.838710 Valid acc: 0.829237\n",
      "Epoch: 9/10 Train loss: 0.496611 Valid loss: 0.565116 Train acc: 0.806452 Valid acc: 0.829242\n",
      "Epoch: 9/10 Train loss: 0.447229 Valid loss: 0.564979 Train acc: 0.838710 Valid acc: 0.829248\n",
      "Epoch: 9/10 Train loss: 0.433707 Valid loss: 0.564843 Train acc: 0.838710 Valid acc: 0.829252\n",
      "Epoch: 9/10 Train loss: 0.441467 Valid loss: 0.564706 Train acc: 0.838710 Valid acc: 0.829258\n",
      "Epoch: 9/10 Train loss: 0.442340 Valid loss: 0.564571 Train acc: 0.838710 Valid acc: 0.829263\n",
      "Epoch: 9/10 Train loss: 0.385476 Valid loss: 0.564436 Train acc: 0.870968 Valid acc: 0.829268\n",
      "Epoch: 9/10 Train loss: 0.490533 Valid loss: 0.564301 Train acc: 0.806452 Valid acc: 0.829273\n",
      "Epoch: 9/10 Train loss: 0.449315 Valid loss: 0.564167 Train acc: 0.838710 Valid acc: 0.829278\n",
      "Epoch: 9/10 Train loss: 0.509471 Valid loss: 0.564033 Train acc: 0.806452 Valid acc: 0.829282\n",
      "Epoch: 9/10 Train loss: 0.437795 Valid loss: 0.563900 Train acc: 0.838710 Valid acc: 0.829287\n",
      "Epoch: 9/10 Train loss: 0.452348 Valid loss: 0.563767 Train acc: 0.838710 Valid acc: 0.829292\n",
      "Epoch: 9/10 Train loss: 0.434135 Valid loss: 0.563635 Train acc: 0.838710 Valid acc: 0.829297\n",
      "Epoch: 9/10 Train loss: 0.393406 Valid loss: 0.563503 Train acc: 0.870968 Valid acc: 0.829302\n",
      "Epoch: 9/10 Train loss: 0.498642 Valid loss: 0.563371 Train acc: 0.806452 Valid acc: 0.829307\n",
      "Epoch: 9/10 Train loss: 0.442604 Valid loss: 0.563240 Train acc: 0.838710 Valid acc: 0.829312\n",
      "Epoch: 9/10 Train loss: 0.497956 Valid loss: 0.563109 Train acc: 0.806452 Valid acc: 0.829317\n",
      "Epoch: 9/10 Train loss: 0.444572 Valid loss: 0.562979 Train acc: 0.838710 Valid acc: 0.829322\n",
      "Epoch: 9/10 Train loss: 0.444438 Valid loss: 0.562848 Train acc: 0.838710 Valid acc: 0.829327\n",
      "Epoch: 9/10 Train loss: 0.469321 Valid loss: 0.562718 Train acc: 0.838710 Valid acc: 0.829331\n",
      "Epoch: 9/10 Train loss: 0.515324 Valid loss: 0.562588 Train acc: 0.806452 Valid acc: 0.829336\n",
      "Epoch: 9/10 Train loss: 0.452877 Valid loss: 0.562458 Train acc: 0.838710 Valid acc: 0.829341\n",
      "Epoch: 9/10 Train loss: 0.450196 Valid loss: 0.562328 Train acc: 0.838710 Valid acc: 0.829346\n",
      "Epoch: 9/10 Train loss: 0.483476 Valid loss: 0.562199 Train acc: 0.806452 Valid acc: 0.829351\n",
      "Epoch: 9/10 Train loss: 0.395365 Valid loss: 0.562070 Train acc: 0.870968 Valid acc: 0.829355\n",
      "Epoch: 9/10 Train loss: 0.486095 Valid loss: 0.561942 Train acc: 0.806452 Valid acc: 0.829360\n",
      "Epoch: 9/10 Train loss: 0.405549 Valid loss: 0.561814 Train acc: 0.870968 Valid acc: 0.829365\n",
      "Epoch: 9/10 Train loss: 0.491349 Valid loss: 0.561686 Train acc: 0.806452 Valid acc: 0.829370\n",
      "Epoch: 9/10 Train loss: 0.497931 Valid loss: 0.561558 Train acc: 0.806452 Valid acc: 0.829374\n",
      "Epoch: 9/10 Train loss: 0.385819 Valid loss: 0.561431 Train acc: 0.870968 Valid acc: 0.829379\n",
      "Epoch: 9/10 Train loss: 0.466090 Valid loss: 0.561304 Train acc: 0.838710 Valid acc: 0.829384\n",
      "Epoch: 9/10 Train loss: 0.467824 Valid loss: 0.561177 Train acc: 0.838710 Valid acc: 0.829389\n",
      "Epoch: 9/10 Train loss: 0.486432 Valid loss: 0.561051 Train acc: 0.806452 Valid acc: 0.829393\n",
      "Epoch: 9/10 Train loss: 0.449160 Valid loss: 0.560925 Train acc: 0.838710 Valid acc: 0.829398\n",
      "Epoch: 9/10 Train loss: 0.464689 Valid loss: 0.560800 Train acc: 0.806452 Valid acc: 0.829403\n",
      "Epoch: 9/10 Train loss: 0.400637 Valid loss: 0.560674 Train acc: 0.838710 Valid acc: 0.829407\n",
      "Epoch: 9/10 Train loss: 0.441560 Valid loss: 0.560550 Train acc: 0.838710 Valid acc: 0.829412\n",
      "Epoch: 9/10 Train loss: 0.446768 Valid loss: 0.560425 Train acc: 0.838710 Valid acc: 0.829417\n",
      "Epoch: 9/10 Train loss: 0.479115 Valid loss: 0.560302 Train acc: 0.806452 Valid acc: 0.829421\n",
      "Epoch: 9/10 Train loss: 0.434011 Valid loss: 0.560178 Train acc: 0.838710 Valid acc: 0.829426\n",
      "Epoch: 9/10 Train loss: 0.440272 Valid loss: 0.560056 Train acc: 0.838710 Valid acc: 0.829430\n",
      "Epoch: 9/10 Train loss: 0.442823 Valid loss: 0.559934 Train acc: 0.838710 Valid acc: 0.829435\n",
      "Epoch: 9/10 Train loss: 0.494729 Valid loss: 0.559812 Train acc: 0.806452 Valid acc: 0.829440\n",
      "Epoch: 9/10 Train loss: 0.411940 Valid loss: 0.559690 Train acc: 0.870968 Valid acc: 0.829444\n",
      "Epoch: 9/10 Train loss: 0.491822 Valid loss: 0.559567 Train acc: 0.806452 Valid acc: 0.829449\n",
      "Epoch: 9/10 Train loss: 0.395462 Valid loss: 0.559445 Train acc: 0.870968 Valid acc: 0.829453\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 Train loss: 0.499237 Valid loss: 0.559322 Train acc: 0.806452 Valid acc: 0.829458\n",
      "Epoch: 9/10 Train loss: 0.453066 Valid loss: 0.559200 Train acc: 0.838710 Valid acc: 0.829462\n",
      "Epoch: 9/10 Train loss: 0.487207 Valid loss: 0.559077 Train acc: 0.806452 Valid acc: 0.829467\n",
      "Epoch: 9/10 Train loss: 0.392395 Valid loss: 0.558955 Train acc: 0.870968 Valid acc: 0.829471\n",
      "Epoch: 9/10 Train loss: 0.434553 Valid loss: 0.558833 Train acc: 0.838710 Valid acc: 0.829476\n",
      "Epoch: 9/10 Train loss: 0.494974 Valid loss: 0.558711 Train acc: 0.806452 Valid acc: 0.829480\n",
      "Epoch: 9/10 Train loss: 0.430057 Valid loss: 0.558590 Train acc: 0.838710 Valid acc: 0.829485\n",
      "Epoch: 9/10 Train loss: 0.448095 Valid loss: 0.558469 Train acc: 0.838710 Valid acc: 0.829489\n",
      "Epoch: 9/10 Train loss: 0.444113 Valid loss: 0.558348 Train acc: 0.838710 Valid acc: 0.829494\n",
      "Epoch: 9/10 Train loss: 0.505274 Valid loss: 0.558228 Train acc: 0.806452 Valid acc: 0.829498\n",
      "Epoch: 9/10 Train loss: 0.394344 Valid loss: 0.558107 Train acc: 0.870968 Valid acc: 0.829503\n",
      "Epoch: 9/10 Train loss: 0.443068 Valid loss: 0.557988 Train acc: 0.838710 Valid acc: 0.829507\n",
      "Epoch: 9/10 Train loss: 0.500538 Valid loss: 0.557868 Train acc: 0.806452 Valid acc: 0.829512\n",
      "Epoch: 9/10 Train loss: 0.445420 Valid loss: 0.557750 Train acc: 0.838710 Valid acc: 0.829516\n",
      "Epoch: 9/10 Train loss: 0.509505 Valid loss: 0.557631 Train acc: 0.806452 Valid acc: 0.829520\n",
      "Epoch: 9/10 Train loss: 0.403464 Valid loss: 0.557513 Train acc: 0.870968 Valid acc: 0.829525\n",
      "Epoch: 9/10 Train loss: 0.438869 Valid loss: 0.557396 Train acc: 0.838710 Valid acc: 0.829529\n",
      "Epoch: 9/10 Train loss: 0.511962 Valid loss: 0.557277 Train acc: 0.806452 Valid acc: 0.829534\n",
      "Epoch: 9/10 Train loss: 0.441170 Valid loss: 0.557159 Train acc: 0.838710 Valid acc: 0.829538\n",
      "Epoch: 9/10 Train loss: 0.434434 Valid loss: 0.557041 Train acc: 0.838710 Valid acc: 0.829542\n",
      "Epoch: 9/10 Train loss: 0.443843 Valid loss: 0.556923 Train acc: 0.838710 Valid acc: 0.829547\n",
      "Epoch: 9/10 Train loss: 0.422969 Valid loss: 0.556806 Train acc: 0.838710 Valid acc: 0.829551\n",
      "Epoch: 9/10 Train loss: 0.511045 Valid loss: 0.556688 Train acc: 0.806452 Valid acc: 0.829555\n",
      "Epoch: 9/10 Train loss: 0.481360 Valid loss: 0.556571 Train acc: 0.806452 Valid acc: 0.829560\n",
      "Epoch: 9/10 Train loss: 0.381677 Valid loss: 0.556455 Train acc: 0.870968 Valid acc: 0.829564\n",
      "Epoch: 9/10 Train loss: 0.432476 Valid loss: 0.556338 Train acc: 0.838710 Valid acc: 0.829568\n",
      "Epoch: 9/10 Train loss: 0.464918 Valid loss: 0.556223 Train acc: 0.838710 Valid acc: 0.829572\n",
      "Epoch: 9/10 Train loss: 0.437326 Valid loss: 0.556110 Train acc: 0.838710 Valid acc: 0.829577\n",
      "Epoch: 9/10 Train loss: 0.510724 Valid loss: 0.555995 Train acc: 0.806452 Valid acc: 0.829581\n",
      "Epoch: 9/10 Train loss: 0.386497 Valid loss: 0.555880 Train acc: 0.870968 Valid acc: 0.829585\n",
      "Epoch: 9/10 Train loss: 0.490322 Valid loss: 0.555765 Train acc: 0.806452 Valid acc: 0.829589\n",
      "Epoch: 9/10 Train loss: 0.449514 Valid loss: 0.555650 Train acc: 0.838710 Valid acc: 0.829594\n",
      "Epoch: 9/10 Train loss: 0.443338 Valid loss: 0.555535 Train acc: 0.838710 Valid acc: 0.829598\n",
      "Epoch: 9/10 Train loss: 0.439343 Valid loss: 0.555420 Train acc: 0.838710 Valid acc: 0.829602\n",
      "Epoch: 9/10 Train loss: 0.507392 Valid loss: 0.555306 Train acc: 0.806452 Valid acc: 0.829606\n",
      "Epoch: 9/10 Train loss: 0.427245 Valid loss: 0.555192 Train acc: 0.838710 Valid acc: 0.829611\n",
      "Epoch: 9/10 Train loss: 0.449139 Valid loss: 0.555078 Train acc: 0.838710 Valid acc: 0.829615\n",
      "Epoch: 9/10 Train loss: 0.434131 Valid loss: 0.554964 Train acc: 0.838710 Valid acc: 0.829619\n",
      "Epoch: 10/10 Train loss: 0.373960 Valid loss: 0.554851 Train acc: 0.870968 Valid acc: 0.829623\n",
      "Epoch: 10/10 Train loss: 0.496799 Valid loss: 0.554738 Train acc: 0.806452 Valid acc: 0.829627\n",
      "Epoch: 10/10 Train loss: 0.483761 Valid loss: 0.554625 Train acc: 0.806452 Valid acc: 0.829632\n",
      "Epoch: 10/10 Train loss: 0.378145 Valid loss: 0.554512 Train acc: 0.870968 Valid acc: 0.829636\n",
      "Epoch: 10/10 Train loss: 0.482962 Valid loss: 0.554400 Train acc: 0.806452 Valid acc: 0.829640\n",
      "Epoch: 10/10 Train loss: 0.369421 Valid loss: 0.554288 Train acc: 0.870968 Valid acc: 0.829644\n",
      "Epoch: 10/10 Train loss: 0.515293 Valid loss: 0.554177 Train acc: 0.806452 Valid acc: 0.829648\n",
      "Epoch: 10/10 Train loss: 0.504754 Valid loss: 0.554065 Train acc: 0.806452 Valid acc: 0.829652\n",
      "Epoch: 10/10 Train loss: 0.469317 Valid loss: 0.553955 Train acc: 0.838710 Valid acc: 0.829656\n",
      "Epoch: 10/10 Train loss: 0.431366 Valid loss: 0.553846 Train acc: 0.838710 Valid acc: 0.829660\n",
      "Epoch: 10/10 Train loss: 0.394960 Valid loss: 0.553737 Train acc: 0.870968 Valid acc: 0.829664\n",
      "Epoch: 10/10 Train loss: 0.503253 Valid loss: 0.553629 Train acc: 0.806452 Valid acc: 0.829669\n",
      "Epoch: 10/10 Train loss: 0.466735 Valid loss: 0.553521 Train acc: 0.838710 Valid acc: 0.829673\n",
      "Epoch: 10/10 Train loss: 0.498599 Valid loss: 0.553414 Train acc: 0.806452 Valid acc: 0.829677\n",
      "Epoch: 10/10 Train loss: 0.398688 Valid loss: 0.553306 Train acc: 0.870968 Valid acc: 0.829681\n",
      "Epoch: 10/10 Train loss: 0.502619 Valid loss: 0.553198 Train acc: 0.806452 Valid acc: 0.829685\n",
      "Epoch: 10/10 Train loss: 0.444414 Valid loss: 0.553090 Train acc: 0.838710 Valid acc: 0.829689\n",
      "Epoch: 10/10 Train loss: 0.470265 Valid loss: 0.552981 Train acc: 0.838710 Valid acc: 0.829693\n",
      "Epoch: 10/10 Train loss: 0.442838 Valid loss: 0.552872 Train acc: 0.838710 Valid acc: 0.829697\n",
      "Epoch: 10/10 Train loss: 0.492230 Valid loss: 0.552764 Train acc: 0.806452 Valid acc: 0.829701\n",
      "Epoch: 10/10 Train loss: 0.457272 Valid loss: 0.552655 Train acc: 0.838710 Valid acc: 0.829705\n",
      "Epoch: 10/10 Train loss: 0.436784 Valid loss: 0.552547 Train acc: 0.838710 Valid acc: 0.829709\n",
      "Epoch: 10/10 Train loss: 0.448053 Valid loss: 0.552440 Train acc: 0.838710 Valid acc: 0.829713\n",
      "Epoch: 10/10 Train loss: 0.431699 Valid loss: 0.552332 Train acc: 0.838710 Valid acc: 0.829717\n",
      "Epoch: 10/10 Train loss: 0.393333 Valid loss: 0.552225 Train acc: 0.870968 Valid acc: 0.829721\n",
      "Epoch: 10/10 Train loss: 0.497303 Valid loss: 0.552118 Train acc: 0.806452 Valid acc: 0.829725\n",
      "Epoch: 10/10 Train loss: 0.464024 Valid loss: 0.552011 Train acc: 0.838710 Valid acc: 0.829729\n",
      "Epoch: 10/10 Train loss: 0.490336 Valid loss: 0.551904 Train acc: 0.806452 Valid acc: 0.829733\n",
      "Epoch: 10/10 Train loss: 0.450822 Valid loss: 0.551797 Train acc: 0.838710 Valid acc: 0.829737\n",
      "Epoch: 10/10 Train loss: 0.451883 Valid loss: 0.551691 Train acc: 0.838710 Valid acc: 0.829741\n",
      "Epoch: 10/10 Train loss: 0.430747 Valid loss: 0.551584 Train acc: 0.838710 Valid acc: 0.829744\n",
      "Epoch: 10/10 Train loss: 0.383849 Valid loss: 0.551478 Train acc: 0.870968 Valid acc: 0.829748\n",
      "Epoch: 10/10 Train loss: 0.476229 Valid loss: 0.551372 Train acc: 0.806452 Valid acc: 0.829752\n",
      "Epoch: 10/10 Train loss: 0.438504 Valid loss: 0.551266 Train acc: 0.838710 Valid acc: 0.829756\n",
      "Epoch: 10/10 Train loss: 0.490569 Valid loss: 0.551160 Train acc: 0.806452 Valid acc: 0.829760\n",
      "Epoch: 10/10 Train loss: 0.453106 Valid loss: 0.551055 Train acc: 0.838710 Valid acc: 0.829764\n",
      "Epoch: 10/10 Train loss: 0.423803 Valid loss: 0.550950 Train acc: 0.838710 Valid acc: 0.829768\n",
      "Epoch: 10/10 Train loss: 0.445858 Valid loss: 0.550845 Train acc: 0.838710 Valid acc: 0.829772\n",
      "Epoch: 10/10 Train loss: 0.495935 Valid loss: 0.550740 Train acc: 0.806452 Valid acc: 0.829775\n",
      "Epoch: 10/10 Train loss: 0.438736 Valid loss: 0.550635 Train acc: 0.838710 Valid acc: 0.829779\n",
      "Epoch: 10/10 Train loss: 0.421953 Valid loss: 0.550531 Train acc: 0.838710 Valid acc: 0.829783\n",
      "Epoch: 10/10 Train loss: 0.506940 Valid loss: 0.550427 Train acc: 0.806452 Valid acc: 0.829787\n",
      "Epoch: 10/10 Train loss: 0.378277 Valid loss: 0.550323 Train acc: 0.870968 Valid acc: 0.829791\n",
      "Epoch: 10/10 Train loss: 0.487205 Valid loss: 0.550219 Train acc: 0.806452 Valid acc: 0.829795\n",
      "Epoch: 10/10 Train loss: 0.387810 Valid loss: 0.550115 Train acc: 0.870968 Valid acc: 0.829798\n",
      "Epoch: 10/10 Train loss: 0.494743 Valid loss: 0.550011 Train acc: 0.806452 Valid acc: 0.829802\n",
      "Epoch: 10/10 Train loss: 0.538876 Valid loss: 0.549908 Train acc: 0.806452 Valid acc: 0.829806\n",
      "Epoch: 10/10 Train loss: 0.378522 Valid loss: 0.549805 Train acc: 0.870968 Valid acc: 0.829810\n",
      "Epoch: 10/10 Train loss: 0.458058 Valid loss: 0.549702 Train acc: 0.838710 Valid acc: 0.829814\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 Train loss: 0.477182 Valid loss: 0.549599 Train acc: 0.838710 Valid acc: 0.829817\n",
      "Epoch: 10/10 Train loss: 0.507636 Valid loss: 0.549497 Train acc: 0.806452 Valid acc: 0.829821\n",
      "Epoch: 10/10 Train loss: 0.438538 Valid loss: 0.549394 Train acc: 0.838710 Valid acc: 0.829825\n",
      "Epoch: 10/10 Train loss: 0.403643 Valid loss: 0.549292 Train acc: 0.838710 Valid acc: 0.829829\n",
      "Epoch: 10/10 Train loss: 0.599859 Valid loss: 0.549191 Train acc: 0.838710 Valid acc: 0.829832\n",
      "Epoch: 10/10 Train loss: 0.467760 Valid loss: 0.549092 Train acc: 0.838710 Valid acc: 0.829836\n",
      "Epoch: 10/10 Train loss: 0.445620 Valid loss: 0.548994 Train acc: 0.838710 Valid acc: 0.829840\n",
      "Epoch: 10/10 Train loss: 0.479354 Valid loss: 0.548898 Train acc: 0.806452 Valid acc: 0.829844\n",
      "Epoch: 10/10 Train loss: 0.448641 Valid loss: 0.548804 Train acc: 0.838710 Valid acc: 0.829847\n",
      "Epoch: 10/10 Train loss: 0.445087 Valid loss: 0.548710 Train acc: 0.838710 Valid acc: 0.829851\n",
      "Epoch: 10/10 Train loss: 0.456712 Valid loss: 0.548615 Train acc: 0.838710 Valid acc: 0.829855\n",
      "Epoch: 10/10 Train loss: 0.492303 Valid loss: 0.548519 Train acc: 0.806452 Valid acc: 0.829858\n",
      "Epoch: 10/10 Train loss: 0.395767 Valid loss: 0.548422 Train acc: 0.870968 Valid acc: 0.829862\n",
      "Epoch: 10/10 Train loss: 0.489511 Valid loss: 0.548324 Train acc: 0.806452 Valid acc: 0.829866\n",
      "Epoch: 10/10 Train loss: 0.397692 Valid loss: 0.548224 Train acc: 0.870968 Valid acc: 0.829869\n",
      "Epoch: 10/10 Train loss: 0.510520 Valid loss: 0.548125 Train acc: 0.806452 Valid acc: 0.829873\n",
      "Epoch: 10/10 Train loss: 0.422286 Valid loss: 0.548025 Train acc: 0.838710 Valid acc: 0.829877\n",
      "Epoch: 10/10 Train loss: 0.490637 Valid loss: 0.547926 Train acc: 0.806452 Valid acc: 0.829880\n",
      "Epoch: 10/10 Train loss: 0.379039 Valid loss: 0.547828 Train acc: 0.870968 Valid acc: 0.829884\n",
      "Epoch: 10/10 Train loss: 0.458168 Valid loss: 0.547731 Train acc: 0.838710 Valid acc: 0.829887\n",
      "Epoch: 10/10 Train loss: 0.492291 Valid loss: 0.547635 Train acc: 0.806452 Valid acc: 0.829891\n",
      "Epoch: 10/10 Train loss: 0.439977 Valid loss: 0.547539 Train acc: 0.838710 Valid acc: 0.829895\n",
      "Epoch: 10/10 Train loss: 0.445009 Valid loss: 0.547443 Train acc: 0.838710 Valid acc: 0.829898\n",
      "Epoch: 10/10 Train loss: 0.436768 Valid loss: 0.547347 Train acc: 0.838710 Valid acc: 0.829902\n",
      "Epoch: 10/10 Train loss: 0.491953 Valid loss: 0.547250 Train acc: 0.806452 Valid acc: 0.829905\n",
      "Epoch: 10/10 Train loss: 0.389094 Valid loss: 0.547153 Train acc: 0.870968 Valid acc: 0.829909\n",
      "Epoch: 10/10 Train loss: 0.435346 Valid loss: 0.547056 Train acc: 0.838710 Valid acc: 0.829913\n",
      "Epoch: 10/10 Train loss: 0.482740 Valid loss: 0.546959 Train acc: 0.806452 Valid acc: 0.829916\n",
      "Epoch: 10/10 Train loss: 0.440492 Valid loss: 0.546862 Train acc: 0.838710 Valid acc: 0.829920\n",
      "Epoch: 10/10 Train loss: 0.509233 Valid loss: 0.546765 Train acc: 0.806452 Valid acc: 0.829923\n",
      "Epoch: 10/10 Train loss: 0.369366 Valid loss: 0.546668 Train acc: 0.870968 Valid acc: 0.829927\n",
      "Epoch: 10/10 Train loss: 0.439432 Valid loss: 0.546572 Train acc: 0.838710 Valid acc: 0.829930\n",
      "Epoch: 10/10 Train loss: 0.492460 Valid loss: 0.546476 Train acc: 0.806452 Valid acc: 0.829934\n",
      "Epoch: 10/10 Train loss: 0.458258 Valid loss: 0.546380 Train acc: 0.838710 Valid acc: 0.829937\n",
      "Epoch: 10/10 Train loss: 0.442300 Valid loss: 0.546285 Train acc: 0.838710 Valid acc: 0.829941\n",
      "Epoch: 10/10 Train loss: 0.435774 Valid loss: 0.546190 Train acc: 0.838710 Valid acc: 0.829944\n",
      "Epoch: 10/10 Train loss: 0.442161 Valid loss: 0.546095 Train acc: 0.838710 Valid acc: 0.829948\n",
      "Epoch: 10/10 Train loss: 0.505554 Valid loss: 0.546001 Train acc: 0.806452 Valid acc: 0.829951\n",
      "Epoch: 10/10 Train loss: 0.514268 Valid loss: 0.545913 Train acc: 0.806452 Valid acc: 0.829955\n",
      "Epoch: 10/10 Train loss: 0.431338 Valid loss: 0.545827 Train acc: 0.870968 Valid acc: 0.829958\n",
      "Epoch: 10/10 Train loss: 0.401795 Valid loss: 0.545751 Train acc: 0.838710 Valid acc: 0.829962\n",
      "Epoch: 10/10 Train loss: 0.843007 Valid loss: 0.545659 Train acc: 0.838710 Valid acc: 0.829965\n",
      "Epoch: 10/10 Train loss: 0.447389 Valid loss: 0.545568 Train acc: 0.838710 Valid acc: 0.829969\n",
      "Epoch: 10/10 Train loss: 0.499643 Valid loss: 0.545478 Train acc: 0.806452 Valid acc: 0.829972\n",
      "Epoch: 10/10 Train loss: 0.417823 Valid loss: 0.545388 Train acc: 0.870968 Valid acc: 0.829976\n",
      "Epoch: 10/10 Train loss: 0.479180 Valid loss: 0.545299 Train acc: 0.806452 Valid acc: 0.829979\n",
      "Epoch: 10/10 Train loss: 0.455912 Valid loss: 0.545209 Train acc: 0.838710 Valid acc: 0.829982\n",
      "Epoch: 10/10 Train loss: 0.474900 Valid loss: 0.545117 Train acc: 0.838710 Valid acc: 0.829986\n",
      "Epoch: 10/10 Train loss: 0.427232 Valid loss: 0.545026 Train acc: 0.838710 Valid acc: 0.829989\n",
      "Epoch: 10/10 Train loss: 0.513696 Valid loss: 0.544933 Train acc: 0.806452 Valid acc: 0.829993\n",
      "Epoch: 10/10 Train loss: 0.450005 Valid loss: 0.544840 Train acc: 0.838710 Valid acc: 0.829996\n",
      "Epoch: 10/10 Train loss: 0.454285 Valid loss: 0.544748 Train acc: 0.838710 Valid acc: 0.830000\n",
      "Epoch: 10/10 Train loss: 0.453975 Valid loss: 0.544655 Train acc: 0.838710 Valid acc: 0.830003\n",
      "Epoch: 10/10 Test loss: 0.451158 Test acc: 0.832987\n"
     ]
    }
   ],
   "source": [
    "### Train the network\n",
    "# Plotting the acc and loss curve\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initalize session global variables just in the case they are initialized.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "       \n",
    "        # Loop over batches\n",
    "        for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_:x, labels_:y, keep_prob_:keep_prob, learning_rate_:learning_rate}\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################################ Validation\n",
    "            # Initialize \n",
    "            loss_v_batch, acc_v_batch = [], []\n",
    "\n",
    "            # Loop over batches\n",
    "            for x_v, y_v in get_batches(X_valid_norm, Y_valid_onehot, batch_size):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_:x_v, labels_:y_v, keep_prob_:1.0}\n",
    "                loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                \n",
    "                acc_v_batch.append(acc_v)\n",
    "                loss_v_batch.append(loss_v)\n",
    "                \n",
    "            valid_acc.append(np.mean(acc_v_batch))\n",
    "            valid_loss.append(np.mean(loss_v_batch))\n",
    "            \n",
    "            # Print info\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Train loss: {:6f}\".format(loss),\n",
    "                  \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "                  \"Train acc: {:6f}\".format(acc),\n",
    "                  \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "            \n",
    "    ################################ Test\n",
    "    # Initialize \n",
    "    acc_batch, loss_batch = [], []\n",
    "\n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(X_test_norm, Y_test_onehot, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_:x, labels_:y, keep_prob_:1.0}\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print info\n",
    "    print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "          \"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXoAAAD8CAYAAAB5Pm/hAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\np6AXEWlw/x95mqHnOx/eiQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d946597f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nmiEL7sYY0wz9f+kyaMAmI22GAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d2c041f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
