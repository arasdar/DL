{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18900, 205, 16) float64 (5670, 205, 16) float64 (13230, 205, 16) float64\n",
      "(13230, 205, 16) float64 (9265, 205, 16) float64 (3965, 205, 16) float64\n",
      "(18900, 1) uint8 (5670, 1) uint8 (13230, 205, 16) float64\n",
      "(9265, 205, 16) float64 (3965, 205, 16) float64 (5670, 205, 16) float64\n",
      "(9265, 2) (3965, 2) (5670, 2) (9265, 205, 16) (3965, 205, 16) (5670, 205, 16)\n",
      "float64 float64 float64 float64 float64 float64\n",
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "# Reading the data for the Face from all the subjects\n",
    "BahramFlipp = spio.loadmat(file_name='../data/bci-project-data-RAW/BahramFlipp.mat')\n",
    "DJFlipp = spio.loadmat(file_name='../data/bci-project-data-RAW/DJFlipp.mat')\n",
    "NickFlipp = spio.loadmat(file_name='../data/bci-project-data-RAW/NickFlipp.mat')\n",
    "RoohiFlipp = spio.loadmat(file_name='../data/bci-project-data-RAW/RoohiFlipp.mat')\n",
    "SarahFlipp = spio.loadmat(file_name='../data/bci-project-data-RAW/SarahFlipp.mat')\n",
    "\n",
    "# Deviding the input data into train and test\n",
    "# For creating the training and testing set, \n",
    "# 30% percent of each subject is considered as test and\n",
    "# 70% of each subject is conidered as training.\n",
    "length = int(BahramFlipp['Intensification_Data'].shape[0] * 0.30)\n",
    "# length\n",
    "\n",
    "FlippsDataAll = np.vstack(tup=(BahramFlipp['Intensification_Data'][:], \n",
    "                       DJFlipp['Intensification_Data'][:], \n",
    "                       NickFlipp['Intensification_Data'][:],\n",
    "                      RoohiFlipp['Intensification_Data'][:],\n",
    "                      SarahFlipp['Intensification_Data'][:]))\n",
    "\n",
    "FlippsDataTrainAll = np.vstack(tup=(BahramFlipp['Intensification_Data'][:-length], \n",
    "                       DJFlipp['Intensification_Data'][:-length], \n",
    "                       NickFlipp['Intensification_Data'][:-length],\n",
    "                      RoohiFlipp['Intensification_Data'][:-length],\n",
    "                      SarahFlipp['Intensification_Data'][:-length]))\n",
    "\n",
    "FlippsDataTest = np.vstack(tup=(BahramFlipp['Intensification_Data'][-length:], \n",
    "                       DJFlipp['Intensification_Data'][-length:], \n",
    "                       NickFlipp['Intensification_Data'][-length:],\n",
    "                      RoohiFlipp['Intensification_Data'][-length:],\n",
    "                      SarahFlipp['Intensification_Data'][-length:]))\n",
    "\n",
    "print(FlippsDataAll.shape, FlippsDataAll.dtype,\n",
    " FlippsDataTest.shape, FlippsDataTest.dtype, \n",
    " FlippsDataTrainAll.shape, FlippsDataTrainAll.dtype)\n",
    "\n",
    "BahramFlippDataTrain = BahramFlipp['Intensification_Data'][:-length]\n",
    "DJFlippDataTrain = DJFlipp['Intensification_Data'][:-length]\n",
    "NickFlippDataTrain = NickFlipp['Intensification_Data'][:-length]\n",
    "RoohiFlippDataTrain = RoohiFlipp['Intensification_Data'][:-length]\n",
    "SarahFlippDataTrain = SarahFlipp['Intensification_Data'][:-length]\n",
    "\n",
    "# 30% of the training is validation.\n",
    "# This is applied to every single subject data.\n",
    "length2 = int(BahramFlippDataTrain.shape[0] * 0.30)\n",
    "# length2\n",
    "\n",
    "FlippsDataTrain = np.vstack(tup=(BahramFlippDataTrain[:-length2], \n",
    "                       DJFlippDataTrain[:-length2], \n",
    "                       NickFlippDataTrain[:-length2],\n",
    "                      RoohiFlippDataTrain[:-length2],\n",
    "                      SarahFlippDataTrain[:-length2]))\n",
    "\n",
    "FlippsDataValid = np.vstack(tup=(BahramFlippDataTrain[-length2:], \n",
    "                       DJFlippDataTrain[-length2:],\n",
    "                       NickFlippDataTrain[-length2:],\n",
    "                      RoohiFlippDataTrain[-length2:],\n",
    "                      SarahFlippDataTrain[-length2:]))\n",
    "\n",
    "print(FlippsDataTrainAll.shape, FlippsDataTrainAll.dtype, \n",
    " FlippsDataTrain.shape, FlippsDataTrain.dtype, \n",
    " FlippsDataValid.shape, FlippsDataValid.dtype)\n",
    "\n",
    "FlippsLabelAll = np.vstack(tup=(BahramFlipp['Intensification_Label'][:], \n",
    "                       DJFlipp['Intensification_Label'][:], \n",
    "                       NickFlipp['Intensification_Label'][:],\n",
    "                      RoohiFlipp['Intensification_Label'][:],\n",
    "                      SarahFlipp['Intensification_Label'][:]))\n",
    "\n",
    "FlippsLabelTrainAll = np.vstack(tup=(BahramFlipp['Intensification_Label'][:-length], \n",
    "                       DJFlipp['Intensification_Label'][:-length], \n",
    "                       NickFlipp['Intensification_Label'][:-length],\n",
    "                      RoohiFlipp['Intensification_Label'][:-length],\n",
    "                      SarahFlipp['Intensification_Label'][:-length]))\n",
    "\n",
    "FlippsLabelTest = np.vstack(tup=(BahramFlipp['Intensification_Label'][-length:], \n",
    "                       DJFlipp['Intensification_Label'][-length:], \n",
    "                       NickFlipp['Intensification_Label'][-length:],\n",
    "                      RoohiFlipp['Intensification_Label'][-length:],\n",
    "                      SarahFlipp['Intensification_Label'][-length:]))\n",
    "\n",
    "print(FlippsLabelAll.shape, FlippsLabelAll.dtype,\n",
    " FlippsLabelTest.shape, FlippsLabelTest.dtype, \n",
    " FlippsDataTrainAll.shape, FlippsDataTrainAll.dtype)\n",
    "\n",
    "BahramFlippLabelTrain = BahramFlipp['Intensification_Label'][:-length]\n",
    "DJFlippLabelTrain = DJFlipp['Intensification_Label'][:-length]\n",
    "NickFlippLabelTrain = NickFlipp['Intensification_Label'][:-length]\n",
    "RoohiFlippLabelTrain = RoohiFlipp['Intensification_Label'][:-length]\n",
    "SarahFlippLabelTrain = SarahFlipp['Intensification_Label'][:-length]\n",
    "\n",
    "FlippsLabelTrain = np.vstack(tup=(BahramFlippLabelTrain[:-length2], \n",
    "                       DJFlippLabelTrain[:-length2], \n",
    "                       NickFlippLabelTrain[:-length2],\n",
    "                      RoohiFlippLabelTrain[:-length2],\n",
    "                      SarahFlippLabelTrain[:-length2]))\n",
    "\n",
    "FlippsLabelValid = np.vstack(tup=(BahramFlippLabelTrain[-length2:], \n",
    "                       DJFlippLabelTrain[-length2:], \n",
    "                       NickFlippLabelTrain[-length2:],\n",
    "                      RoohiFlippLabelTrain[-length2:],\n",
    "                      SarahFlippLabelTrain[-length2:]))\n",
    "\n",
    "# # Normalizing input data\n",
    "# def normalize(inputs, inputs_all):\n",
    "#     return (inputs - inputs_all.mean(axis=0)[None,:,:]) / inputs_all.std(axis=0)[None,:,:]\n",
    "# Yalda suggested this normalization.\n",
    "def normalize(inputs):\n",
    "    return (inputs - inputs.mean(axis=0)[None,:,:]) / inputs.std(axis=0)[None,:,:]\n",
    "\n",
    "# onehot vectorizing output labels\n",
    "def one_hot(labels, n_class):\n",
    "    \"\"\" One-hot encoding \"\"\"\n",
    "    expansion = np.eye(n_class)\n",
    "    y = expansion[:, labels-1].T\n",
    "    assert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "    return y\n",
    "\n",
    "# get minibatches for learning\n",
    "def get_batches(X, y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]\n",
    "\n",
    "# Standardize/normalize train and test\n",
    "# X_train_norm_all = normalize(inputs=FacesDataTrain, inputs_all=FacesDataAll)\n",
    "X_train_norm = normalize(inputs=FlippsDataTrain)\n",
    "X_valid_norm = normalize(inputs=FlippsDataValid)\n",
    "X_test_norm = normalize(inputs=FlippsDataTest)\n",
    "\n",
    "print(X_train_norm.shape, X_train_norm.dtype, \n",
    "X_valid_norm.shape, X_valid_norm.dtype,\n",
    "X_test_norm.shape, X_test_norm.dtype)\n",
    "\n",
    "### Hyperparameters\n",
    "\n",
    "# Input data\n",
    "batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "\n",
    "# Output labels\n",
    "n_classes = int(FlippsLabelAll.max() + 1)\n",
    "\n",
    "# Tweekable parameters\n",
    "learning_rate = 0.001 #1e-3\n",
    "epochs = 10 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out\n",
    "\n",
    "Y_train = np.array(FlippsLabelTrain, dtype=int).reshape(-1)\n",
    "Y_valid = np.array(FlippsLabelValid, dtype=int).reshape(-1)\n",
    "Y_test = np.array(FlippsLabelTest, dtype=int).reshape(-1)\n",
    "\n",
    "Y_train_onehot = one_hot(labels=Y_train, n_class=n_classes)\n",
    "Y_valid_onehot = one_hot(labels=Y_valid, n_class=n_classes)\n",
    "Y_test_onehot = one_hot(labels=Y_test, n_class=n_classes)\n",
    "\n",
    "print(Y_train_onehot.shape, Y_valid_onehot.shape, Y_test_onehot.shape, \n",
    " X_train_norm.shape, X_valid_norm.shape, X_test_norm.shape)\n",
    "\n",
    "print(Y_train_onehot.dtype, Y_valid_onehot.dtype, Y_test_onehot.dtype,\n",
    " X_train_norm.dtype, X_valid_norm.dtype, X_test_norm.dtype)\n",
    "\n",
    "# GPUs or CPU\n",
    "\n",
    "\"\"\"\n",
    "DON'T MODIFY ANYTHING IN THIS CELL\n",
    "\"\"\"\n",
    "from distutils.version import LooseVersion\n",
    "import warnings\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "assert LooseVersion(tf.__version__) >= LooseVersion('1.0'), 'Please use TensorFlow version 1.0 or newer.  You are using {}'.format(tf.__version__)\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "if not tf.test.gpu_device_name():\n",
    "    warnings.warn('No GPU found. Please use a GPU to train your neural network.')\n",
    "else:\n",
    "    print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))\n",
    "\n",
    "#  No graphs is needed on tensorflow\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 101, 32)\n",
      "(?, 49, 64)\n",
      "(?, 3136) (?, 6272)\n",
      "(?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass: Convolutional Layers, FC Layer, and Output layer\n",
    "# (batch, 205, 16) --> (batch, 101, 32)\n",
    "# (205 - 5 + 0)/2 + 1 = 100+1= 101\n",
    "# 2/5 with strides/kernel_size is 40% non-overlap/diff region and 60% overlapping window/ common region\n",
    "in_conv = inputs_\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=32, kernel_size=5, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(out_conv.shape)\n",
    "\n",
    "# (batch, 101, 32) --> (batch, 49, 64)\n",
    "# (101 - 5 + 0)/2 + 1 = (96/2)+1= 48+1= 49\n",
    "# 2/5 with strides/kernel_size is 40% non-overlap/diff region and 60% overlapping window/ common region\n",
    "in_conv = out_conv\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=64, kernel_size=5, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(out_conv.shape)\n",
    "\n",
    "# (batch, 49, 64) --> (batch, 49*64) --> (batch, 49*64*2)\n",
    "# 49*64 = 50*64 - 1*64 = 3200 - 64 = 3136, 3136*2 = 6272\n",
    "# (batch, 49, 64) --> (batch, 3136) --> (batch, 6272)\n",
    "in_fc = tf.reshape(tensor=out_conv, shape=(-1, 49*64))\n",
    "out_fc = tf.layers.dense(inputs=in_fc, units=49*64*2)\n",
    "out_fc = tf.layers.batch_normalization(inputs=out_fc)\n",
    "out_fc = tf.nn.relu(features=out_fc)\n",
    "out_fc = tf.nn.dropout(x=out_fc, keep_prob=keep_prob_)\n",
    "print(in_fc.shape, out_fc.shape)\n",
    "\n",
    "# (batch, 49*64*2) --> (batch, 2) \n",
    "logits = tf.layers.dense(inputs=out_fc, units=n_classes)\n",
    "print(logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 0.737126 Valid loss: 6.092399 Train acc: 0.445652 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 5.586700 Valid loss: 5.809558 Train acc: 0.847826 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 5.997727 Valid loss: 5.036255 Train acc: 0.826087 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 3.952035 Valid loss: 4.230284 Train acc: 0.836957 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 2.224748 Valid loss: 3.547608 Train acc: 0.826087 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 1.089820 Valid loss: 3.035498 Train acc: 0.836957 Valid acc: 0.833165\n",
      "Epoch: 1/10 Train loss: 0.558660 Valid loss: 2.687637 Train acc: 0.826087 Valid acc: 0.833093\n",
      "Epoch: 1/10 Train loss: 0.460707 Valid loss: 2.445171 Train acc: 0.847826 Valid acc: 0.754676\n",
      "Epoch: 1/10 Train loss: 0.652259 Valid loss: 2.259620 Train acc: 0.673913 Valid acc: 0.689698\n",
      "Epoch: 1/10 Train loss: 0.722615 Valid loss: 2.108397 Train acc: 0.391304 Valid acc: 0.638296\n",
      "Epoch: 1/10 Train loss: 0.701002 Valid loss: 1.981366 Train acc: 0.510870 Valid acc: 0.603916\n",
      "Epoch: 1/10 Train loss: 0.682333 Valid loss: 1.872811 Train acc: 0.565217 Valid acc: 0.615226\n",
      "Epoch: 1/10 Train loss: 0.644013 Valid loss: 1.778987 Train acc: 0.782609 Valid acc: 0.631913\n",
      "Epoch: 1/10 Train loss: 0.634995 Valid loss: 1.697084 Train acc: 0.826087 Valid acc: 0.646288\n",
      "Epoch: 1/10 Train loss: 0.595788 Valid loss: 1.624912 Train acc: 0.836957 Valid acc: 0.658746\n",
      "Epoch: 1/10 Train loss: 0.578530 Valid loss: 1.560766 Train acc: 0.826087 Valid acc: 0.669647\n",
      "Epoch: 1/10 Train loss: 0.547818 Valid loss: 1.503264 Train acc: 0.847826 Valid acc: 0.679266\n",
      "Epoch: 1/10 Train loss: 0.551112 Valid loss: 1.451348 Train acc: 0.826087 Valid acc: 0.687816\n",
      "Epoch: 1/10 Train loss: 0.531220 Valid loss: 1.404174 Train acc: 0.826087 Valid acc: 0.695466\n",
      "Epoch: 1/10 Train loss: 0.511620 Valid loss: 1.361062 Train acc: 0.826087 Valid acc: 0.702351\n",
      "Epoch: 1/10 Train loss: 0.459440 Valid loss: 1.321470 Train acc: 0.847826 Valid acc: 0.708580\n",
      "Epoch: 1/10 Train loss: 0.479929 Valid loss: 1.284989 Train acc: 0.826087 Valid acc: 0.714243\n",
      "Epoch: 1/10 Train loss: 0.451017 Valid loss: 1.251292 Train acc: 0.836957 Valid acc: 0.719414\n",
      "Epoch: 1/10 Train loss: 0.430881 Valid loss: 1.220095 Train acc: 0.847826 Valid acc: 0.724153\n",
      "Epoch: 1/10 Train loss: 0.477094 Valid loss: 1.191158 Train acc: 0.826087 Valid acc: 0.728514\n",
      "Epoch: 1/10 Train loss: 0.458802 Valid loss: 1.164279 Train acc: 0.826087 Valid acc: 0.732539\n",
      "Epoch: 1/10 Train loss: 0.438978 Valid loss: 1.139277 Train acc: 0.836957 Valid acc: 0.736266\n",
      "Epoch: 1/10 Train loss: 0.469657 Valid loss: 1.115996 Train acc: 0.836957 Valid acc: 0.739726\n",
      "Epoch: 1/10 Train loss: 0.834493 Valid loss: 1.094416 Train acc: 0.826087 Valid acc: 0.742948\n",
      "Epoch: 1/10 Train loss: 0.522613 Valid loss: 1.074411 Train acc: 0.836957 Valid acc: 0.745955\n",
      "Epoch: 1/10 Train loss: 0.485378 Valid loss: 1.055871 Train acc: 0.836957 Valid acc: 0.748769\n",
      "Epoch: 1/10 Train loss: 0.482918 Valid loss: 1.038688 Train acc: 0.826087 Valid acc: 0.751406\n",
      "Epoch: 1/10 Train loss: 0.451887 Valid loss: 1.022740 Train acc: 0.836957 Valid acc: 0.753884\n",
      "Epoch: 1/10 Train loss: 0.483257 Valid loss: 1.007918 Train acc: 0.836957 Valid acc: 0.756215\n",
      "Epoch: 1/10 Train loss: 0.468245 Valid loss: 0.994128 Train acc: 0.836957 Valid acc: 0.758414\n",
      "Epoch: 1/10 Train loss: 0.457727 Valid loss: 0.981271 Train acc: 0.826087 Valid acc: 0.760490\n",
      "Epoch: 1/10 Train loss: 0.450467 Valid loss: 0.969240 Train acc: 0.836957 Valid acc: 0.762454\n",
      "Epoch: 1/10 Train loss: 0.455643 Valid loss: 0.957945 Train acc: 0.826087 Valid acc: 0.764315\n",
      "Epoch: 1/10 Train loss: 0.474674 Valid loss: 0.947313 Train acc: 0.836957 Valid acc: 0.766081\n",
      "Epoch: 1/10 Train loss: 0.711184 Valid loss: 0.937363 Train acc: 0.815217 Valid acc: 0.767758\n",
      "Epoch: 1/10 Train loss: 0.461572 Valid loss: 0.928031 Train acc: 0.847826 Valid acc: 0.769353\n",
      "Epoch: 1/10 Train loss: 0.470886 Valid loss: 0.919219 Train acc: 0.847826 Valid acc: 0.770872\n",
      "Epoch: 1/10 Train loss: 0.480832 Valid loss: 0.910844 Train acc: 0.836957 Valid acc: 0.772321\n",
      "Epoch: 1/10 Train loss: 0.479522 Valid loss: 0.902842 Train acc: 0.836957 Valid acc: 0.773704\n",
      "Epoch: 1/10 Train loss: 0.484833 Valid loss: 0.895162 Train acc: 0.826087 Valid acc: 0.775025\n",
      "Epoch: 1/10 Train loss: 0.484313 Valid loss: 0.887752 Train acc: 0.826087 Valid acc: 0.776289\n",
      "Epoch: 1/10 Train loss: 0.466737 Valid loss: 0.880568 Train acc: 0.836957 Valid acc: 0.777499\n",
      "Epoch: 1/10 Train loss: 0.479747 Valid loss: 0.873575 Train acc: 0.836957 Valid acc: 0.778659\n",
      "Epoch: 1/10 Train loss: 0.476234 Valid loss: 0.866750 Train acc: 0.836957 Valid acc: 0.779771\n",
      "Epoch: 1/10 Train loss: 0.474029 Valid loss: 0.860086 Train acc: 0.826087 Valid acc: 0.780839\n",
      "Epoch: 1/10 Train loss: 0.457999 Valid loss: 0.853577 Train acc: 0.836957 Valid acc: 0.781865\n",
      "Epoch: 1/10 Train loss: 0.445743 Valid loss: 0.847209 Train acc: 0.836957 Valid acc: 0.782852\n",
      "Epoch: 1/10 Train loss: 0.470354 Valid loss: 0.840975 Train acc: 0.815217 Valid acc: 0.783801\n",
      "Epoch: 1/10 Train loss: 0.419553 Valid loss: 0.834861 Train acc: 0.847826 Valid acc: 0.784715\n",
      "Epoch: 1/10 Train loss: 0.433597 Valid loss: 0.828870 Train acc: 0.826087 Valid acc: 0.785596\n",
      "Epoch: 1/10 Train loss: 0.451259 Valid loss: 0.823011 Train acc: 0.826087 Valid acc: 0.786445\n",
      "Epoch: 1/10 Train loss: 0.419023 Valid loss: 0.817281 Train acc: 0.836957 Valid acc: 0.787265\n",
      "Epoch: 1/10 Train loss: 0.449899 Valid loss: 0.811689 Train acc: 0.836957 Valid acc: 0.788056\n",
      "Epoch: 1/10 Train loss: 0.441679 Valid loss: 0.806238 Train acc: 0.836957 Valid acc: 0.788821\n",
      "Epoch: 1/10 Train loss: 0.451463 Valid loss: 0.800935 Train acc: 0.836957 Valid acc: 0.789560\n",
      "Epoch: 1/10 Train loss: 0.464974 Valid loss: 0.795787 Train acc: 0.826087 Valid acc: 0.790275\n",
      "Epoch: 1/10 Train loss: 0.421974 Valid loss: 0.790786 Train acc: 0.847826 Valid acc: 0.790967\n",
      "Epoch: 1/10 Train loss: 0.468359 Valid loss: 0.785934 Train acc: 0.826087 Valid acc: 0.791636\n",
      "Epoch: 1/10 Train loss: 0.443591 Valid loss: 0.781228 Train acc: 0.836957 Valid acc: 0.792285\n",
      "Epoch: 1/10 Train loss: 0.447941 Valid loss: 0.776669 Train acc: 0.836957 Valid acc: 0.792914\n",
      "Epoch: 1/10 Train loss: 0.466514 Valid loss: 0.772258 Train acc: 0.826087 Valid acc: 0.793524\n",
      "Epoch: 1/10 Train loss: 0.424004 Valid loss: 0.767987 Train acc: 0.847826 Valid acc: 0.794116\n",
      "Epoch: 1/10 Train loss: 0.467407 Valid loss: 0.763857 Train acc: 0.826087 Valid acc: 0.794690\n",
      "Epoch: 1/10 Train loss: 0.471437 Valid loss: 0.759867 Train acc: 0.826087 Valid acc: 0.795248\n",
      "Epoch: 1/10 Train loss: 0.468570 Valid loss: 0.756017 Train acc: 0.826087 Valid acc: 0.795789\n",
      "Epoch: 1/10 Train loss: 0.441413 Valid loss: 0.752296 Train acc: 0.836957 Valid acc: 0.796316\n",
      "Epoch: 1/10 Train loss: 0.424772 Valid loss: 0.748703 Train acc: 0.847826 Valid acc: 0.796828\n",
      "Epoch: 1/10 Train loss: 0.470239 Valid loss: 0.745239 Train acc: 0.815217 Valid acc: 0.797325\n",
      "Epoch: 1/10 Train loss: 0.449340 Valid loss: 0.741908 Train acc: 0.836957 Valid acc: 0.797810\n",
      "Epoch: 1/10 Train loss: 0.458145 Valid loss: 0.738700 Train acc: 0.836957 Valid acc: 0.798281\n",
      "Epoch: 1/10 Train loss: 0.460675 Valid loss: 0.735612 Train acc: 0.826087 Valid acc: 0.798740\n",
      "Epoch: 1/10 Train loss: 0.427403 Valid loss: 0.732628 Train acc: 0.847826 Valid acc: 0.799187\n",
      "Epoch: 1/10 Train loss: 0.439835 Valid loss: 0.729733 Train acc: 0.836957 Valid acc: 0.799623\n",
      "Epoch: 1/10 Train loss: 0.449204 Valid loss: 0.726914 Train acc: 0.836957 Valid acc: 0.800047\n",
      "Epoch: 1/10 Train loss: 0.490207 Valid loss: 0.724173 Train acc: 0.826087 Valid acc: 0.800461\n",
      "Epoch: 1/10 Train loss: 0.500342 Valid loss: 0.721529 Train acc: 0.826087 Valid acc: 0.800865\n",
      "Epoch: 1/10 Train loss: 0.547530 Valid loss: 0.719032 Train acc: 0.836957 Valid acc: 0.801259\n",
      "Epoch: 1/10 Train loss: 0.474587 Valid loss: 0.716702 Train acc: 0.836957 Valid acc: 0.801643\n",
      "Epoch: 1/10 Train loss: 0.522442 Valid loss: 0.714560 Train acc: 0.815217 Valid acc: 0.802019\n",
      "Epoch: 1/10 Train loss: 0.446437 Valid loss: 0.712599 Train acc: 0.847826 Valid acc: 0.802385\n",
      "Epoch: 1/10 Train loss: 0.444747 Valid loss: 0.710804 Train acc: 0.836957 Valid acc: 0.802743\n",
      "Epoch: 1/10 Train loss: 0.466428 Valid loss: 0.709154 Train acc: 0.826087 Valid acc: 0.803093\n",
      "Epoch: 1/10 Train loss: 0.450715 Valid loss: 0.707622 Train acc: 0.836957 Valid acc: 0.803434\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/10 Train loss: 0.537835 Valid loss: 0.706209 Train acc: 0.836957 Valid acc: 0.803768\n",
      "Epoch: 1/10 Train loss: 0.469006 Valid loss: 0.704891 Train acc: 0.826087 Valid acc: 0.804095\n",
      "Epoch: 1/10 Train loss: 0.459931 Valid loss: 0.703641 Train acc: 0.836957 Valid acc: 0.804415\n",
      "Epoch: 1/10 Train loss: 0.484923 Valid loss: 0.702439 Train acc: 0.826087 Valid acc: 0.804727\n",
      "Epoch: 1/10 Train loss: 0.471208 Valid loss: 0.701263 Train acc: 0.836957 Valid acc: 0.805033\n",
      "Epoch: 1/10 Train loss: 0.484423 Valid loss: 0.700096 Train acc: 0.836957 Valid acc: 0.805332\n",
      "Epoch: 1/10 Train loss: 0.497389 Valid loss: 0.698927 Train acc: 0.826087 Valid acc: 0.805625\n",
      "Epoch: 1/10 Train loss: 0.459629 Valid loss: 0.697743 Train acc: 0.836957 Valid acc: 0.805912\n",
      "Epoch: 1/10 Train loss: 0.472749 Valid loss: 0.696530 Train acc: 0.836957 Valid acc: 0.806193\n",
      "Epoch: 1/10 Train loss: 0.472522 Valid loss: 0.695282 Train acc: 0.836957 Valid acc: 0.806468\n",
      "Epoch: 1/10 Train loss: 0.462148 Valid loss: 0.693998 Train acc: 0.826087 Valid acc: 0.806738\n",
      "Epoch: 1/10 Train loss: 0.449288 Valid loss: 0.692673 Train acc: 0.836957 Valid acc: 0.807002\n",
      "Epoch: 2/10 Train loss: 0.499713 Valid loss: 0.691294 Train acc: 0.826087 Valid acc: 0.807261\n",
      "Epoch: 2/10 Train loss: 0.460218 Valid loss: 0.689846 Train acc: 0.847826 Valid acc: 0.807515\n",
      "Epoch: 2/10 Train loss: 0.474556 Valid loss: 0.688321 Train acc: 0.826087 Valid acc: 0.807764\n",
      "Epoch: 2/10 Train loss: 0.455392 Valid loss: 0.686711 Train acc: 0.836957 Valid acc: 0.808008\n",
      "Epoch: 2/10 Train loss: 0.460497 Valid loss: 0.685017 Train acc: 0.826087 Valid acc: 0.808248\n",
      "Epoch: 2/10 Train loss: 0.436863 Valid loss: 0.683244 Train acc: 0.836957 Valid acc: 0.808483\n",
      "Epoch: 2/10 Train loss: 0.443342 Valid loss: 0.681406 Train acc: 0.826087 Valid acc: 0.808714\n",
      "Epoch: 2/10 Train loss: 0.414126 Valid loss: 0.679517 Train acc: 0.847826 Valid acc: 0.808940\n",
      "Epoch: 2/10 Train loss: 0.449093 Valid loss: 0.677597 Train acc: 0.826087 Valid acc: 0.809162\n",
      "Epoch: 2/10 Train loss: 0.437263 Valid loss: 0.675665 Train acc: 0.836957 Valid acc: 0.809381\n",
      "Epoch: 2/10 Train loss: 0.487307 Valid loss: 0.673739 Train acc: 0.826087 Valid acc: 0.809595\n",
      "Epoch: 2/10 Train loss: 0.454139 Valid loss: 0.671833 Train acc: 0.836957 Valid acc: 0.809805\n",
      "Epoch: 2/10 Train loss: 0.445732 Valid loss: 0.669954 Train acc: 0.836957 Valid acc: 0.810012\n",
      "Epoch: 2/10 Train loss: 0.490784 Valid loss: 0.668113 Train acc: 0.826087 Valid acc: 0.810215\n",
      "Epoch: 2/10 Train loss: 0.430880 Valid loss: 0.666317 Train acc: 0.836957 Valid acc: 0.810415\n",
      "Epoch: 2/10 Train loss: 0.472657 Valid loss: 0.664571 Train acc: 0.826087 Valid acc: 0.810611\n",
      "Epoch: 2/10 Train loss: 0.406536 Valid loss: 0.662877 Train acc: 0.847826 Valid acc: 0.810804\n",
      "Epoch: 2/10 Train loss: 0.456073 Valid loss: 0.661237 Train acc: 0.826087 Valid acc: 0.810993\n",
      "Epoch: 2/10 Train loss: 0.485394 Valid loss: 0.659658 Train acc: 0.826087 Valid acc: 0.811179\n",
      "Epoch: 2/10 Train loss: 0.435446 Valid loss: 0.658138 Train acc: 0.826087 Valid acc: 0.811363\n",
      "Epoch: 2/10 Train loss: 0.373306 Valid loss: 0.656673 Train acc: 0.847826 Valid acc: 0.811543\n",
      "Epoch: 2/10 Train loss: 0.437988 Valid loss: 0.655270 Train acc: 0.826087 Valid acc: 0.811720\n",
      "Epoch: 2/10 Train loss: 0.381593 Valid loss: 0.653926 Train acc: 0.836957 Valid acc: 0.811894\n",
      "Epoch: 2/10 Train loss: 0.377409 Valid loss: 0.652637 Train acc: 0.847826 Valid acc: 0.812066\n",
      "Epoch: 2/10 Train loss: 0.490756 Valid loss: 0.651404 Train acc: 0.826087 Valid acc: 0.812235\n",
      "Epoch: 2/10 Train loss: 0.429177 Valid loss: 0.650222 Train acc: 0.826087 Valid acc: 0.812401\n",
      "Epoch: 2/10 Train loss: 0.382641 Valid loss: 0.649080 Train acc: 0.836957 Valid acc: 0.812564\n",
      "Epoch: 2/10 Train loss: 0.403904 Valid loss: 0.647968 Train acc: 0.836957 Valid acc: 0.812725\n",
      "Epoch: 2/10 Train loss: 0.467021 Valid loss: 0.646905 Train acc: 0.826087 Valid acc: 0.812883\n",
      "Epoch: 2/10 Train loss: 0.426932 Valid loss: 0.645886 Train acc: 0.836957 Valid acc: 0.813039\n",
      "Epoch: 2/10 Train loss: 0.455192 Valid loss: 0.644905 Train acc: 0.836957 Valid acc: 0.813193\n",
      "Epoch: 2/10 Train loss: 0.422915 Valid loss: 0.643950 Train acc: 0.826087 Valid acc: 0.813344\n",
      "Epoch: 2/10 Train loss: 0.383416 Valid loss: 0.643002 Train acc: 0.836957 Valid acc: 0.813493\n",
      "Epoch: 2/10 Train loss: 0.423576 Valid loss: 0.642051 Train acc: 0.836957 Valid acc: 0.813640\n",
      "Epoch: 2/10 Train loss: 0.485475 Valid loss: 0.641096 Train acc: 0.836957 Valid acc: 0.813785\n",
      "Epoch: 2/10 Train loss: 0.393735 Valid loss: 0.640125 Train acc: 0.826087 Valid acc: 0.813927\n",
      "Epoch: 2/10 Train loss: 0.409190 Valid loss: 0.639128 Train acc: 0.847826 Valid acc: 0.814068\n",
      "Epoch: 2/10 Train loss: 0.413527 Valid loss: 0.638101 Train acc: 0.826087 Valid acc: 0.814206\n",
      "Epoch: 2/10 Train loss: 0.452926 Valid loss: 0.637053 Train acc: 0.836957 Valid acc: 0.814346\n",
      "Epoch: 2/10 Train loss: 0.610589 Valid loss: 0.636017 Train acc: 0.815217 Valid acc: 0.814484\n",
      "Epoch: 2/10 Train loss: 0.381170 Valid loss: 0.634990 Train acc: 0.847826 Valid acc: 0.814624\n",
      "Epoch: 2/10 Train loss: 0.403263 Valid loss: 0.633957 Train acc: 0.847826 Valid acc: 0.814762\n",
      "Epoch: 2/10 Train loss: 0.412843 Valid loss: 0.632903 Train acc: 0.836957 Valid acc: 0.814899\n",
      "Epoch: 2/10 Train loss: 0.412884 Valid loss: 0.631821 Train acc: 0.836957 Valid acc: 0.815037\n",
      "Epoch: 2/10 Train loss: 0.435465 Valid loss: 0.630714 Train acc: 0.826087 Valid acc: 0.815175\n",
      "Epoch: 2/10 Train loss: 0.422552 Valid loss: 0.629581 Train acc: 0.826087 Valid acc: 0.815313\n",
      "Epoch: 2/10 Train loss: 0.458115 Valid loss: 0.628432 Train acc: 0.836957 Valid acc: 0.815448\n",
      "Epoch: 2/10 Train loss: 0.405248 Valid loss: 0.627270 Train acc: 0.836957 Valid acc: 0.815579\n",
      "Epoch: 2/10 Train loss: 0.420500 Valid loss: 0.626102 Train acc: 0.836957 Valid acc: 0.815709\n",
      "Epoch: 2/10 Train loss: 0.447992 Valid loss: 0.624940 Train acc: 0.826087 Valid acc: 0.815841\n",
      "Epoch: 2/10 Train loss: 0.426584 Valid loss: 0.623793 Train acc: 0.836957 Valid acc: 0.815972\n",
      "Epoch: 2/10 Train loss: 0.413203 Valid loss: 0.622663 Train acc: 0.836957 Valid acc: 0.816100\n",
      "Epoch: 2/10 Train loss: 0.435492 Valid loss: 0.621557 Train acc: 0.815217 Valid acc: 0.816228\n",
      "Epoch: 2/10 Train loss: 0.384404 Valid loss: 0.620467 Train acc: 0.847826 Valid acc: 0.816358\n",
      "Epoch: 2/10 Train loss: 0.400535 Valid loss: 0.619397 Train acc: 0.815217 Valid acc: 0.816488\n",
      "Epoch: 2/10 Train loss: 0.420996 Valid loss: 0.618350 Train acc: 0.826087 Valid acc: 0.816621\n",
      "Epoch: 2/10 Train loss: 0.431340 Valid loss: 0.617324 Train acc: 0.836957 Valid acc: 0.816752\n",
      "Epoch: 2/10 Train loss: 0.468141 Valid loss: 0.616320 Train acc: 0.836957 Valid acc: 0.816881\n",
      "Epoch: 2/10 Train loss: 0.382339 Valid loss: 0.615325 Train acc: 0.836957 Valid acc: 0.817012\n",
      "Epoch: 2/10 Train loss: 0.410347 Valid loss: 0.614334 Train acc: 0.847826 Valid acc: 0.817150\n",
      "Epoch: 2/10 Train loss: 0.412649 Valid loss: 0.613344 Train acc: 0.826087 Valid acc: 0.817287\n",
      "Epoch: 2/10 Train loss: 0.421398 Valid loss: 0.612346 Train acc: 0.847826 Valid acc: 0.817424\n",
      "Epoch: 2/10 Train loss: 0.445508 Valid loss: 0.611345 Train acc: 0.826087 Valid acc: 0.817559\n",
      "Epoch: 2/10 Train loss: 0.427733 Valid loss: 0.610340 Train acc: 0.836957 Valid acc: 0.817693\n",
      "Epoch: 2/10 Train loss: 0.432006 Valid loss: 0.609331 Train acc: 0.836957 Valid acc: 0.817825\n",
      "Epoch: 2/10 Train loss: 0.455334 Valid loss: 0.608322 Train acc: 0.826087 Valid acc: 0.817952\n",
      "Epoch: 2/10 Train loss: 0.426900 Valid loss: 0.607314 Train acc: 0.847826 Valid acc: 0.818075\n",
      "Epoch: 2/10 Train loss: 0.421328 Valid loss: 0.606309 Train acc: 0.826087 Valid acc: 0.818194\n",
      "Epoch: 2/10 Train loss: 0.446412 Valid loss: 0.605314 Train acc: 0.826087 Valid acc: 0.818311\n",
      "Epoch: 2/10 Train loss: 0.487405 Valid loss: 0.604339 Train acc: 0.826087 Valid acc: 0.818431\n",
      "Epoch: 2/10 Train loss: 0.458486 Valid loss: 0.603387 Train acc: 0.836957 Valid acc: 0.818551\n",
      "Epoch: 2/10 Train loss: 0.394209 Valid loss: 0.602460 Train acc: 0.847826 Valid acc: 0.818671\n",
      "Epoch: 2/10 Train loss: 0.466049 Valid loss: 0.601566 Train acc: 0.815217 Valid acc: 0.818791\n",
      "Epoch: 2/10 Train loss: 0.446935 Valid loss: 0.600709 Train acc: 0.836957 Valid acc: 0.818912\n",
      "Epoch: 2/10 Train loss: 0.439947 Valid loss: 0.599883 Train acc: 0.836957 Valid acc: 0.819032\n",
      "Epoch: 2/10 Train loss: 0.481336 Valid loss: 0.599094 Train acc: 0.826087 Valid acc: 0.819151\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2/10 Train loss: 0.400274 Valid loss: 0.598331 Train acc: 0.847826 Valid acc: 0.819270\n",
      "Epoch: 2/10 Train loss: 0.436270 Valid loss: 0.597585 Train acc: 0.836957 Valid acc: 0.819387\n",
      "Epoch: 2/10 Train loss: 0.405467 Valid loss: 0.596844 Train acc: 0.836957 Valid acc: 0.819502\n",
      "Epoch: 2/10 Train loss: 0.469452 Valid loss: 0.596106 Train acc: 0.826087 Valid acc: 0.819616\n",
      "Epoch: 2/10 Train loss: 0.458355 Valid loss: 0.595383 Train acc: 0.826087 Valid acc: 0.819732\n",
      "Epoch: 2/10 Train loss: 0.446275 Valid loss: 0.594701 Train acc: 0.836957 Valid acc: 0.819852\n",
      "Epoch: 2/10 Train loss: 0.434898 Valid loss: 0.594069 Train acc: 0.836957 Valid acc: 0.819977\n",
      "Epoch: 2/10 Train loss: 0.466807 Valid loss: 0.593494 Train acc: 0.815217 Valid acc: 0.820119\n",
      "Epoch: 2/10 Train loss: 0.422629 Valid loss: 0.592975 Train acc: 0.847826 Valid acc: 0.820255\n",
      "Epoch: 2/10 Train loss: 0.409563 Valid loss: 0.592503 Train acc: 0.836957 Valid acc: 0.820386\n",
      "Epoch: 2/10 Train loss: 0.421552 Valid loss: 0.592062 Train acc: 0.826087 Valid acc: 0.820508\n",
      "Epoch: 2/10 Train loss: 0.430853 Valid loss: 0.591633 Train acc: 0.836957 Valid acc: 0.820628\n",
      "Epoch: 2/10 Train loss: 0.409118 Valid loss: 0.591211 Train acc: 0.836957 Valid acc: 0.820750\n",
      "Epoch: 2/10 Train loss: 0.408425 Valid loss: 0.590788 Train acc: 0.826087 Valid acc: 0.820877\n",
      "Epoch: 2/10 Train loss: 0.440141 Valid loss: 0.590359 Train acc: 0.836957 Valid acc: 0.820998\n",
      "Epoch: 2/10 Train loss: 0.442796 Valid loss: 0.589917 Train acc: 0.826087 Valid acc: 0.821114\n",
      "Epoch: 2/10 Train loss: 0.434692 Valid loss: 0.589455 Train acc: 0.836957 Valid acc: 0.821220\n",
      "Epoch: 2/10 Train loss: 0.450590 Valid loss: 0.588973 Train acc: 0.836957 Valid acc: 0.821326\n",
      "Epoch: 2/10 Train loss: 0.449113 Valid loss: 0.588468 Train acc: 0.826087 Valid acc: 0.821428\n",
      "Epoch: 2/10 Train loss: 0.407315 Valid loss: 0.587942 Train acc: 0.836957 Valid acc: 0.821528\n",
      "Epoch: 2/10 Train loss: 0.464846 Valid loss: 0.587400 Train acc: 0.836957 Valid acc: 0.821624\n",
      "Epoch: 2/10 Train loss: 0.439903 Valid loss: 0.586848 Train acc: 0.836957 Valid acc: 0.821723\n",
      "Epoch: 2/10 Train loss: 0.429725 Valid loss: 0.586300 Train acc: 0.826087 Valid acc: 0.821821\n",
      "Epoch: 2/10 Train loss: 0.408223 Valid loss: 0.585758 Train acc: 0.847826 Valid acc: 0.821916\n",
      "Epoch: 3/10 Train loss: 0.441347 Valid loss: 0.585208 Train acc: 0.826087 Valid acc: 0.822006\n",
      "Epoch: 3/10 Train loss: 0.393200 Valid loss: 0.584631 Train acc: 0.847826 Valid acc: 0.822095\n",
      "Epoch: 3/10 Train loss: 0.421249 Valid loss: 0.584018 Train acc: 0.826087 Valid acc: 0.822183\n",
      "Epoch: 3/10 Train loss: 0.433089 Valid loss: 0.583366 Train acc: 0.836957 Valid acc: 0.822265\n",
      "Epoch: 3/10 Train loss: 0.416397 Valid loss: 0.582674 Train acc: 0.836957 Valid acc: 0.822345\n",
      "Epoch: 3/10 Train loss: 0.422720 Valid loss: 0.581949 Train acc: 0.836957 Valid acc: 0.822424\n",
      "Epoch: 3/10 Train loss: 0.367491 Valid loss: 0.581194 Train acc: 0.826087 Valid acc: 0.822497\n",
      "Epoch: 3/10 Train loss: 0.338267 Valid loss: 0.580416 Train acc: 0.847826 Valid acc: 0.822568\n",
      "Epoch: 3/10 Train loss: 0.411398 Valid loss: 0.579625 Train acc: 0.826087 Valid acc: 0.822638\n",
      "Epoch: 3/10 Train loss: 0.409240 Valid loss: 0.578829 Train acc: 0.836957 Valid acc: 0.822708\n",
      "Epoch: 3/10 Train loss: 0.404135 Valid loss: 0.578034 Train acc: 0.826087 Valid acc: 0.822777\n",
      "Epoch: 3/10 Train loss: 0.461497 Valid loss: 0.577243 Train acc: 0.836957 Valid acc: 0.822846\n",
      "Epoch: 3/10 Train loss: 0.392978 Valid loss: 0.576458 Train acc: 0.836957 Valid acc: 0.822925\n",
      "Epoch: 3/10 Train loss: 0.454607 Valid loss: 0.575684 Train acc: 0.826087 Valid acc: 0.823003\n",
      "Epoch: 3/10 Train loss: 0.387795 Valid loss: 0.574924 Train acc: 0.836957 Valid acc: 0.823084\n",
      "Epoch: 3/10 Train loss: 0.365207 Valid loss: 0.574180 Train acc: 0.826087 Valid acc: 0.823167\n",
      "Epoch: 3/10 Train loss: 0.367234 Valid loss: 0.573454 Train acc: 0.847826 Valid acc: 0.823258\n",
      "Epoch: 3/10 Train loss: 0.438114 Valid loss: 0.572751 Train acc: 0.826087 Valid acc: 0.823353\n",
      "Epoch: 3/10 Train loss: 0.373695 Valid loss: 0.572069 Train acc: 0.836957 Valid acc: 0.823441\n",
      "Epoch: 3/10 Train loss: 0.415928 Valid loss: 0.571413 Train acc: 0.826087 Valid acc: 0.823534\n",
      "Epoch: 3/10 Train loss: 0.318801 Valid loss: 0.570780 Train acc: 0.891304 Valid acc: 0.823626\n",
      "Epoch: 3/10 Train loss: 0.302789 Valid loss: 0.570164 Train acc: 0.858696 Valid acc: 0.823703\n",
      "Epoch: 3/10 Train loss: 0.291636 Valid loss: 0.569563 Train acc: 0.902174 Valid acc: 0.823766\n",
      "Epoch: 3/10 Train loss: 0.255299 Valid loss: 0.568966 Train acc: 0.869565 Valid acc: 0.823809\n",
      "Epoch: 3/10 Train loss: 0.531502 Valid loss: 0.568377 Train acc: 0.782609 Valid acc: 0.823853\n",
      "Epoch: 3/10 Train loss: 0.377704 Valid loss: 0.567787 Train acc: 0.771739 Valid acc: 0.823905\n",
      "Epoch: 3/10 Train loss: 0.276598 Valid loss: 0.567184 Train acc: 0.880435 Valid acc: 0.823963\n",
      "Epoch: 3/10 Train loss: 0.376355 Valid loss: 0.566566 Train acc: 0.847826 Valid acc: 0.824035\n",
      "Epoch: 3/10 Train loss: 0.442558 Valid loss: 0.565950 Train acc: 0.847826 Valid acc: 0.824108\n",
      "Epoch: 3/10 Train loss: 0.419625 Valid loss: 0.565346 Train acc: 0.847826 Valid acc: 0.824189\n",
      "Epoch: 3/10 Train loss: 0.402755 Valid loss: 0.564753 Train acc: 0.869565 Valid acc: 0.824266\n",
      "Epoch: 3/10 Train loss: 0.429108 Valid loss: 0.564175 Train acc: 0.782609 Valid acc: 0.824337\n",
      "Epoch: 3/10 Train loss: 0.334162 Valid loss: 0.563605 Train acc: 0.869565 Valid acc: 0.824405\n",
      "Epoch: 3/10 Train loss: 0.355085 Valid loss: 0.563039 Train acc: 0.836957 Valid acc: 0.824482\n",
      "Epoch: 3/10 Train loss: 0.448379 Valid loss: 0.562484 Train acc: 0.815217 Valid acc: 0.824564\n",
      "Epoch: 3/10 Train loss: 0.313642 Valid loss: 0.561933 Train acc: 0.847826 Valid acc: 0.824645\n",
      "Epoch: 3/10 Train loss: 0.322694 Valid loss: 0.561378 Train acc: 0.815217 Valid acc: 0.824738\n",
      "Epoch: 3/10 Train loss: 0.383294 Valid loss: 0.560818 Train acc: 0.836957 Valid acc: 0.824836\n",
      "Epoch: 3/10 Train loss: 0.422620 Valid loss: 0.560258 Train acc: 0.858696 Valid acc: 0.824935\n",
      "Epoch: 3/10 Train loss: 0.628914 Valid loss: 0.559728 Train acc: 0.815217 Valid acc: 0.825028\n",
      "Epoch: 3/10 Train loss: 0.386057 Valid loss: 0.559236 Train acc: 0.858696 Valid acc: 0.825112\n",
      "Epoch: 3/10 Train loss: 0.350792 Valid loss: 0.558760 Train acc: 0.869565 Valid acc: 0.825197\n",
      "Epoch: 3/10 Train loss: 0.345054 Valid loss: 0.558284 Train acc: 0.891304 Valid acc: 0.825284\n",
      "Epoch: 3/10 Train loss: 0.339444 Valid loss: 0.557792 Train acc: 0.880435 Valid acc: 0.825368\n",
      "Epoch: 3/10 Train loss: 0.381663 Valid loss: 0.557279 Train acc: 0.847826 Valid acc: 0.825464\n",
      "Epoch: 3/10 Train loss: 0.410067 Valid loss: 0.556743 Train acc: 0.858696 Valid acc: 0.825566\n",
      "Epoch: 3/10 Train loss: 0.361817 Valid loss: 0.556189 Train acc: 0.858696 Valid acc: 0.825675\n",
      "Epoch: 3/10 Train loss: 0.326678 Valid loss: 0.555620 Train acc: 0.858696 Valid acc: 0.825787\n",
      "Epoch: 3/10 Train loss: 0.351987 Valid loss: 0.555040 Train acc: 0.858696 Valid acc: 0.825894\n",
      "Epoch: 3/10 Train loss: 0.467772 Valid loss: 0.554464 Train acc: 0.826087 Valid acc: 0.826000\n",
      "Epoch: 3/10 Train loss: 0.311639 Valid loss: 0.553894 Train acc: 0.836957 Valid acc: 0.826093\n",
      "Epoch: 3/10 Train loss: 0.378551 Valid loss: 0.553333 Train acc: 0.858696 Valid acc: 0.826178\n",
      "Epoch: 3/10 Train loss: 0.428138 Valid loss: 0.552788 Train acc: 0.836957 Valid acc: 0.826256\n",
      "Epoch: 3/10 Train loss: 0.401473 Valid loss: 0.552257 Train acc: 0.869565 Valid acc: 0.826333\n",
      "Epoch: 3/10 Train loss: 0.304675 Valid loss: 0.551738 Train acc: 0.880435 Valid acc: 0.826396\n",
      "Epoch: 3/10 Train loss: 0.370967 Valid loss: 0.551234 Train acc: 0.869565 Valid acc: 0.826450\n",
      "Epoch: 3/10 Train loss: 0.349015 Valid loss: 0.550739 Train acc: 0.891304 Valid acc: 0.826507\n",
      "Epoch: 3/10 Train loss: 0.453800 Valid loss: 0.550255 Train acc: 0.847826 Valid acc: 0.826568\n",
      "Epoch: 3/10 Train loss: 0.329099 Valid loss: 0.549776 Train acc: 0.858696 Valid acc: 0.826629\n",
      "Epoch: 3/10 Train loss: 0.358086 Valid loss: 0.549291 Train acc: 0.869565 Valid acc: 0.826689\n",
      "Epoch: 3/10 Train loss: 0.360205 Valid loss: 0.548795 Train acc: 0.836957 Valid acc: 0.826758\n",
      "Epoch: 3/10 Train loss: 0.404658 Valid loss: 0.548290 Train acc: 0.815217 Valid acc: 0.826841\n",
      "Epoch: 3/10 Train loss: 0.488092 Valid loss: 0.547785 Train acc: 0.793478 Valid acc: 0.826932\n",
      "Epoch: 3/10 Train loss: 0.424685 Valid loss: 0.547285 Train acc: 0.815217 Valid acc: 0.827025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3/10 Train loss: 0.419182 Valid loss: 0.546790 Train acc: 0.836957 Valid acc: 0.827130\n",
      "Epoch: 3/10 Train loss: 0.466152 Valid loss: 0.546307 Train acc: 0.782609 Valid acc: 0.827235\n",
      "Epoch: 3/10 Train loss: 0.439205 Valid loss: 0.545844 Train acc: 0.847826 Valid acc: 0.827340\n",
      "Epoch: 3/10 Train loss: 0.426119 Valid loss: 0.545404 Train acc: 0.815217 Valid acc: 0.827447\n",
      "Epoch: 3/10 Train loss: 0.401754 Valid loss: 0.544987 Train acc: 0.858696 Valid acc: 0.827559\n",
      "Epoch: 3/10 Train loss: 0.486959 Valid loss: 0.544596 Train acc: 0.836957 Valid acc: 0.827666\n",
      "Epoch: 3/10 Train loss: 0.435834 Valid loss: 0.544231 Train acc: 0.815217 Valid acc: 0.827772\n",
      "Epoch: 3/10 Train loss: 0.424736 Valid loss: 0.543882 Train acc: 0.826087 Valid acc: 0.827873\n",
      "Epoch: 3/10 Train loss: 0.516240 Valid loss: 0.543558 Train acc: 0.815217 Valid acc: 0.827960\n",
      "Epoch: 3/10 Train loss: 0.452441 Valid loss: 0.543257 Train acc: 0.858696 Valid acc: 0.828046\n",
      "Epoch: 3/10 Train loss: 0.444182 Valid loss: 0.542974 Train acc: 0.815217 Valid acc: 0.828135\n",
      "Epoch: 3/10 Train loss: 0.434298 Valid loss: 0.542705 Train acc: 0.815217 Valid acc: 0.828220\n",
      "Epoch: 3/10 Train loss: 0.426258 Valid loss: 0.542441 Train acc: 0.826087 Valid acc: 0.828300\n",
      "Epoch: 3/10 Train loss: 0.451352 Valid loss: 0.542178 Train acc: 0.836957 Valid acc: 0.828367\n",
      "Epoch: 3/10 Train loss: 0.395799 Valid loss: 0.541908 Train acc: 0.836957 Valid acc: 0.828431\n",
      "Epoch: 3/10 Train loss: 0.480064 Valid loss: 0.541633 Train acc: 0.826087 Valid acc: 0.828483\n",
      "Epoch: 3/10 Train loss: 0.416192 Valid loss: 0.541357 Train acc: 0.826087 Valid acc: 0.828528\n",
      "Epoch: 3/10 Train loss: 0.470157 Valid loss: 0.541098 Train acc: 0.836957 Valid acc: 0.828572\n",
      "Epoch: 3/10 Train loss: 0.389088 Valid loss: 0.540857 Train acc: 0.836957 Valid acc: 0.828615\n",
      "Epoch: 3/10 Train loss: 0.433148 Valid loss: 0.540637 Train acc: 0.815217 Valid acc: 0.828657\n",
      "Epoch: 3/10 Train loss: 0.431528 Valid loss: 0.540442 Train acc: 0.847826 Valid acc: 0.828703\n",
      "Epoch: 3/10 Train loss: 0.429563 Valid loss: 0.540266 Train acc: 0.847826 Valid acc: 0.828752\n",
      "Epoch: 3/10 Train loss: 0.418982 Valid loss: 0.540104 Train acc: 0.826087 Valid acc: 0.828803\n",
      "Epoch: 3/10 Train loss: 0.421733 Valid loss: 0.539948 Train acc: 0.836957 Valid acc: 0.828858\n",
      "Epoch: 3/10 Train loss: 0.491783 Valid loss: 0.539801 Train acc: 0.847826 Valid acc: 0.828913\n",
      "Epoch: 3/10 Train loss: 0.422772 Valid loss: 0.539655 Train acc: 0.826087 Valid acc: 0.828968\n",
      "Epoch: 3/10 Train loss: 0.381032 Valid loss: 0.539500 Train acc: 0.836957 Valid acc: 0.829020\n",
      "Epoch: 3/10 Train loss: 0.424107 Valid loss: 0.539332 Train acc: 0.826087 Valid acc: 0.829070\n",
      "Epoch: 3/10 Train loss: 0.437990 Valid loss: 0.539150 Train acc: 0.836957 Valid acc: 0.829119\n",
      "Epoch: 3/10 Train loss: 0.405014 Valid loss: 0.538948 Train acc: 0.847826 Valid acc: 0.829170\n",
      "Epoch: 3/10 Train loss: 0.422797 Valid loss: 0.538728 Train acc: 0.826087 Valid acc: 0.829219\n",
      "Epoch: 3/10 Train loss: 0.399552 Valid loss: 0.538492 Train acc: 0.836957 Valid acc: 0.829265\n",
      "Epoch: 3/10 Train loss: 0.441907 Valid loss: 0.538244 Train acc: 0.836957 Valid acc: 0.829311\n",
      "Epoch: 3/10 Train loss: 0.443388 Valid loss: 0.537991 Train acc: 0.836957 Valid acc: 0.829356\n",
      "Epoch: 3/10 Train loss: 0.426866 Valid loss: 0.537743 Train acc: 0.826087 Valid acc: 0.829402\n",
      "Epoch: 3/10 Train loss: 0.431454 Valid loss: 0.537504 Train acc: 0.836957 Valid acc: 0.829448\n",
      "Epoch: 4/10 Train loss: 0.423345 Valid loss: 0.537265 Train acc: 0.826087 Valid acc: 0.829493\n",
      "Epoch: 4/10 Train loss: 0.400326 Valid loss: 0.537011 Train acc: 0.847826 Valid acc: 0.829538\n",
      "Epoch: 4/10 Train loss: 0.397661 Valid loss: 0.536734 Train acc: 0.826087 Valid acc: 0.829580\n",
      "Epoch: 4/10 Train loss: 0.404124 Valid loss: 0.536429 Train acc: 0.836957 Valid acc: 0.829616\n",
      "Epoch: 4/10 Train loss: 0.397423 Valid loss: 0.536094 Train acc: 0.826087 Valid acc: 0.829649\n",
      "Epoch: 4/10 Train loss: 0.388811 Valid loss: 0.535730 Train acc: 0.836957 Valid acc: 0.829678\n",
      "Epoch: 4/10 Train loss: 0.376368 Valid loss: 0.535342 Train acc: 0.826087 Valid acc: 0.829703\n",
      "Epoch: 4/10 Train loss: 0.344465 Valid loss: 0.534936 Train acc: 0.847826 Valid acc: 0.829725\n",
      "Epoch: 4/10 Train loss: 0.400053 Valid loss: 0.534518 Train acc: 0.826087 Valid acc: 0.829747\n",
      "Epoch: 4/10 Train loss: 0.407557 Valid loss: 0.534096 Train acc: 0.836957 Valid acc: 0.829775\n",
      "Epoch: 4/10 Train loss: 0.394222 Valid loss: 0.533674 Train acc: 0.826087 Valid acc: 0.829811\n",
      "Epoch: 4/10 Train loss: 0.493454 Valid loss: 0.533259 Train acc: 0.836957 Valid acc: 0.829849\n",
      "Epoch: 4/10 Train loss: 0.354723 Valid loss: 0.532852 Train acc: 0.847826 Valid acc: 0.829896\n",
      "Epoch: 4/10 Train loss: 0.389671 Valid loss: 0.532457 Train acc: 0.836957 Valid acc: 0.829950\n",
      "Epoch: 4/10 Train loss: 0.413822 Valid loss: 0.532077 Train acc: 0.847826 Valid acc: 0.830000\n",
      "Epoch: 4/10 Train loss: 0.386756 Valid loss: 0.531715 Train acc: 0.826087 Valid acc: 0.830045\n",
      "Epoch: 4/10 Train loss: 0.362217 Valid loss: 0.531370 Train acc: 0.858696 Valid acc: 0.830082\n",
      "Epoch: 4/10 Train loss: 0.440414 Valid loss: 0.531043 Train acc: 0.826087 Valid acc: 0.830108\n",
      "Epoch: 4/10 Train loss: 0.400684 Valid loss: 0.530730 Train acc: 0.836957 Valid acc: 0.830134\n",
      "Epoch: 4/10 Train loss: 0.384391 Valid loss: 0.530421 Train acc: 0.815217 Valid acc: 0.830148\n",
      "Epoch: 4/10 Train loss: 0.253424 Valid loss: 0.530105 Train acc: 0.902174 Valid acc: 0.830163\n",
      "Epoch: 4/10 Train loss: 0.268851 Valid loss: 0.529781 Train acc: 0.891304 Valid acc: 0.830174\n",
      "Epoch: 4/10 Train loss: 0.224404 Valid loss: 0.529448 Train acc: 0.945652 Valid acc: 0.830190\n",
      "Epoch: 4/10 Train loss: 0.294585 Valid loss: 0.529102 Train acc: 0.880435 Valid acc: 0.830209\n",
      "Epoch: 4/10 Train loss: 0.469867 Valid loss: 0.528749 Train acc: 0.815217 Valid acc: 0.830238\n",
      "Epoch: 4/10 Train loss: 0.358397 Valid loss: 0.528391 Train acc: 0.847826 Valid acc: 0.830280\n",
      "Epoch: 4/10 Train loss: 0.295130 Valid loss: 0.528027 Train acc: 0.880435 Valid acc: 0.830322\n",
      "Epoch: 4/10 Train loss: 0.326554 Valid loss: 0.527659 Train acc: 0.858696 Valid acc: 0.830363\n",
      "Epoch: 4/10 Train loss: 0.537604 Valid loss: 0.527307 Train acc: 0.858696 Valid acc: 0.830403\n",
      "Epoch: 4/10 Train loss: 0.399808 Valid loss: 0.526974 Train acc: 0.847826 Valid acc: 0.830432\n",
      "Epoch: 4/10 Train loss: 0.349753 Valid loss: 0.526661 Train acc: 0.880435 Valid acc: 0.830450\n",
      "Epoch: 4/10 Train loss: 0.407577 Valid loss: 0.526370 Train acc: 0.847826 Valid acc: 0.830458\n",
      "Epoch: 4/10 Train loss: 0.341264 Valid loss: 0.526087 Train acc: 0.913043 Valid acc: 0.830467\n",
      "Epoch: 4/10 Train loss: 0.339744 Valid loss: 0.525804 Train acc: 0.869565 Valid acc: 0.830485\n",
      "Epoch: 4/10 Train loss: 0.418696 Valid loss: 0.525521 Train acc: 0.826087 Valid acc: 0.830508\n",
      "Epoch: 4/10 Train loss: 0.350368 Valid loss: 0.525235 Train acc: 0.869565 Valid acc: 0.830537\n",
      "Epoch: 4/10 Train loss: 0.316179 Valid loss: 0.524937 Train acc: 0.858696 Valid acc: 0.830570\n",
      "Epoch: 4/10 Train loss: 0.368823 Valid loss: 0.524624 Train acc: 0.836957 Valid acc: 0.830610\n",
      "Epoch: 4/10 Train loss: 0.428462 Valid loss: 0.524304 Train acc: 0.847826 Valid acc: 0.830665\n",
      "Epoch: 4/10 Train loss: 0.618762 Valid loss: 0.523999 Train acc: 0.793478 Valid acc: 0.830717\n",
      "Epoch: 4/10 Train loss: 0.307682 Valid loss: 0.523706 Train acc: 0.869565 Valid acc: 0.830769\n",
      "Epoch: 4/10 Train loss: 0.323369 Valid loss: 0.523413 Train acc: 0.891304 Valid acc: 0.830819\n",
      "Epoch: 4/10 Train loss: 0.286921 Valid loss: 0.523111 Train acc: 0.891304 Valid acc: 0.830879\n",
      "Epoch: 4/10 Train loss: 0.356750 Valid loss: 0.522799 Train acc: 0.891304 Valid acc: 0.830944\n",
      "Epoch: 4/10 Train loss: 0.353751 Valid loss: 0.522476 Train acc: 0.858696 Valid acc: 0.831008\n",
      "Epoch: 4/10 Train loss: 0.380884 Valid loss: 0.522142 Train acc: 0.847826 Valid acc: 0.831075\n",
      "Epoch: 4/10 Train loss: 0.382262 Valid loss: 0.521797 Train acc: 0.847826 Valid acc: 0.831150\n",
      "Epoch: 4/10 Train loss: 0.326009 Valid loss: 0.521442 Train acc: 0.869565 Valid acc: 0.831224\n",
      "Epoch: 4/10 Train loss: 0.334290 Valid loss: 0.521079 Train acc: 0.891304 Valid acc: 0.831299\n",
      "Epoch: 4/10 Train loss: 0.450665 Valid loss: 0.520715 Train acc: 0.847826 Valid acc: 0.831372\n",
      "Epoch: 4/10 Train loss: 0.310992 Valid loss: 0.520353 Train acc: 0.869565 Valid acc: 0.831443\n",
      "Epoch: 4/10 Train loss: 0.344763 Valid loss: 0.519994 Train acc: 0.847826 Valid acc: 0.831510\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4/10 Train loss: 0.355735 Valid loss: 0.519639 Train acc: 0.891304 Valid acc: 0.831577\n",
      "Epoch: 4/10 Train loss: 0.367720 Valid loss: 0.519290 Train acc: 0.880435 Valid acc: 0.831637\n",
      "Epoch: 4/10 Train loss: 0.308092 Valid loss: 0.518949 Train acc: 0.902174 Valid acc: 0.831694\n",
      "Epoch: 4/10 Train loss: 0.293002 Valid loss: 0.518615 Train acc: 0.891304 Valid acc: 0.831741\n",
      "Epoch: 4/10 Train loss: 0.376705 Valid loss: 0.518283 Train acc: 0.869565 Valid acc: 0.831786\n",
      "Epoch: 4/10 Train loss: 0.394216 Valid loss: 0.517951 Train acc: 0.869565 Valid acc: 0.831835\n",
      "Epoch: 4/10 Train loss: 0.331376 Valid loss: 0.517620 Train acc: 0.847826 Valid acc: 0.831881\n",
      "Epoch: 4/10 Train loss: 0.362673 Valid loss: 0.517292 Train acc: 0.869565 Valid acc: 0.831926\n",
      "Epoch: 4/10 Train loss: 0.429954 Valid loss: 0.516968 Train acc: 0.826087 Valid acc: 0.831971\n",
      "Epoch: 4/10 Train loss: 0.431608 Valid loss: 0.516646 Train acc: 0.826087 Valid acc: 0.832020\n",
      "Epoch: 4/10 Train loss: 0.483609 Valid loss: 0.516332 Train acc: 0.826087 Valid acc: 0.832070\n",
      "Epoch: 4/10 Train loss: 0.447163 Valid loss: 0.516025 Train acc: 0.836957 Valid acc: 0.832125\n",
      "Epoch: 4/10 Train loss: 0.395822 Valid loss: 0.515725 Train acc: 0.847826 Valid acc: 0.832183\n",
      "Epoch: 4/10 Train loss: 0.432192 Valid loss: 0.515434 Train acc: 0.793478 Valid acc: 0.832248\n",
      "Epoch: 4/10 Train loss: 0.412137 Valid loss: 0.515154 Train acc: 0.858696 Valid acc: 0.832316\n",
      "Epoch: 4/10 Train loss: 0.400888 Valid loss: 0.514883 Train acc: 0.815217 Valid acc: 0.832386\n",
      "Epoch: 4/10 Train loss: 0.418942 Valid loss: 0.514622 Train acc: 0.826087 Valid acc: 0.832456\n",
      "Epoch: 4/10 Train loss: 0.507568 Valid loss: 0.514375 Train acc: 0.793478 Valid acc: 0.832520\n",
      "Epoch: 4/10 Train loss: 0.436295 Valid loss: 0.514141 Train acc: 0.836957 Valid acc: 0.832588\n",
      "Epoch: 4/10 Train loss: 0.386769 Valid loss: 0.513915 Train acc: 0.793478 Valid acc: 0.832652\n",
      "Epoch: 4/10 Train loss: 0.439458 Valid loss: 0.513698 Train acc: 0.815217 Valid acc: 0.832714\n",
      "Epoch: 4/10 Train loss: 0.389449 Valid loss: 0.513488 Train acc: 0.836957 Valid acc: 0.832777\n",
      "Epoch: 4/10 Train loss: 0.414133 Valid loss: 0.513282 Train acc: 0.847826 Valid acc: 0.832841\n",
      "Epoch: 4/10 Train loss: 0.413371 Valid loss: 0.513080 Train acc: 0.826087 Valid acc: 0.832904\n",
      "Epoch: 4/10 Train loss: 0.378622 Valid loss: 0.512878 Train acc: 0.836957 Valid acc: 0.832971\n",
      "Epoch: 4/10 Train loss: 0.414129 Valid loss: 0.512675 Train acc: 0.836957 Valid acc: 0.833034\n",
      "Epoch: 4/10 Train loss: 0.398212 Valid loss: 0.512469 Train acc: 0.836957 Valid acc: 0.833096\n",
      "Epoch: 4/10 Train loss: 0.498868 Valid loss: 0.512264 Train acc: 0.826087 Valid acc: 0.833154\n",
      "Epoch: 4/10 Train loss: 0.430607 Valid loss: 0.512064 Train acc: 0.836957 Valid acc: 0.833209\n",
      "Epoch: 4/10 Train loss: 0.405605 Valid loss: 0.511876 Train acc: 0.836957 Valid acc: 0.833263\n",
      "Epoch: 4/10 Train loss: 0.448398 Valid loss: 0.511705 Train acc: 0.836957 Valid acc: 0.833317\n",
      "Epoch: 4/10 Train loss: 0.426713 Valid loss: 0.511555 Train acc: 0.815217 Valid acc: 0.833368\n",
      "Epoch: 4/10 Train loss: 0.453403 Valid loss: 0.511424 Train acc: 0.826087 Valid acc: 0.833423\n",
      "Epoch: 4/10 Train loss: 0.403659 Valid loss: 0.511307 Train acc: 0.826087 Valid acc: 0.833477\n",
      "Epoch: 4/10 Train loss: 0.430872 Valid loss: 0.511203 Train acc: 0.826087 Valid acc: 0.833533\n",
      "Epoch: 4/10 Train loss: 0.469492 Valid loss: 0.511108 Train acc: 0.826087 Valid acc: 0.833587\n",
      "Epoch: 4/10 Train loss: 0.474658 Valid loss: 0.511026 Train acc: 0.847826 Valid acc: 0.833642\n",
      "Epoch: 4/10 Train loss: 0.394725 Valid loss: 0.510951 Train acc: 0.826087 Valid acc: 0.833698\n",
      "Epoch: 4/10 Train loss: 0.395887 Valid loss: 0.510873 Train acc: 0.847826 Valid acc: 0.833751\n",
      "Epoch: 4/10 Train loss: 0.435122 Valid loss: 0.510786 Train acc: 0.826087 Valid acc: 0.833803\n",
      "Epoch: 4/10 Train loss: 0.413784 Valid loss: 0.510686 Train acc: 0.847826 Valid acc: 0.833853\n",
      "Epoch: 4/10 Train loss: 0.414045 Valid loss: 0.510570 Train acc: 0.836957 Valid acc: 0.833903\n",
      "Epoch: 4/10 Train loss: 0.448262 Valid loss: 0.510439 Train acc: 0.826087 Valid acc: 0.833953\n",
      "Epoch: 4/10 Train loss: 0.404466 Valid loss: 0.510291 Train acc: 0.836957 Valid acc: 0.834000\n",
      "Epoch: 4/10 Train loss: 0.423207 Valid loss: 0.510130 Train acc: 0.836957 Valid acc: 0.834044\n",
      "Epoch: 4/10 Train loss: 0.427639 Valid loss: 0.509960 Train acc: 0.836957 Valid acc: 0.834086\n",
      "Epoch: 4/10 Train loss: 0.418819 Valid loss: 0.509789 Train acc: 0.826087 Valid acc: 0.834127\n",
      "Epoch: 4/10 Train loss: 0.390727 Valid loss: 0.509620 Train acc: 0.826087 Valid acc: 0.834171\n",
      "Epoch: 5/10 Train loss: 0.427098 Valid loss: 0.509447 Train acc: 0.826087 Valid acc: 0.834214\n",
      "Epoch: 5/10 Train loss: 0.376314 Valid loss: 0.509264 Train acc: 0.847826 Valid acc: 0.834255\n",
      "Epoch: 5/10 Train loss: 0.374243 Valid loss: 0.509067 Train acc: 0.815217 Valid acc: 0.834293\n",
      "Epoch: 5/10 Train loss: 0.390106 Valid loss: 0.508855 Train acc: 0.836957 Valid acc: 0.834330\n",
      "Epoch: 5/10 Train loss: 0.415135 Valid loss: 0.508627 Train acc: 0.826087 Valid acc: 0.834365\n",
      "Epoch: 5/10 Train loss: 0.377582 Valid loss: 0.508384 Train acc: 0.836957 Valid acc: 0.834398\n",
      "Epoch: 5/10 Train loss: 0.376611 Valid loss: 0.508128 Train acc: 0.826087 Valid acc: 0.834430\n",
      "Epoch: 5/10 Train loss: 0.328152 Valid loss: 0.507861 Train acc: 0.869565 Valid acc: 0.834462\n",
      "Epoch: 5/10 Train loss: 0.426101 Valid loss: 0.507586 Train acc: 0.826087 Valid acc: 0.834494\n",
      "Epoch: 5/10 Train loss: 0.394996 Valid loss: 0.507307 Train acc: 0.836957 Valid acc: 0.834529\n",
      "Epoch: 5/10 Train loss: 0.363479 Valid loss: 0.507026 Train acc: 0.826087 Valid acc: 0.834567\n",
      "Epoch: 5/10 Train loss: 0.460807 Valid loss: 0.506745 Train acc: 0.836957 Valid acc: 0.834605\n",
      "Epoch: 5/10 Train loss: 0.332393 Valid loss: 0.506466 Train acc: 0.836957 Valid acc: 0.834647\n",
      "Epoch: 5/10 Train loss: 0.458485 Valid loss: 0.506193 Train acc: 0.826087 Valid acc: 0.834688\n",
      "Epoch: 5/10 Train loss: 0.383211 Valid loss: 0.505927 Train acc: 0.847826 Valid acc: 0.834724\n",
      "Epoch: 5/10 Train loss: 0.407878 Valid loss: 0.505669 Train acc: 0.826087 Valid acc: 0.834759\n",
      "Epoch: 5/10 Train loss: 0.364691 Valid loss: 0.505421 Train acc: 0.847826 Valid acc: 0.834793\n",
      "Epoch: 5/10 Train loss: 0.443354 Valid loss: 0.505182 Train acc: 0.815217 Valid acc: 0.834826\n",
      "Epoch: 5/10 Train loss: 0.367542 Valid loss: 0.504953 Train acc: 0.858696 Valid acc: 0.834853\n",
      "Epoch: 5/10 Train loss: 0.349024 Valid loss: 0.504733 Train acc: 0.847826 Valid acc: 0.834873\n",
      "Epoch: 5/10 Train loss: 0.273468 Valid loss: 0.504517 Train acc: 0.891304 Valid acc: 0.834897\n",
      "Epoch: 5/10 Train loss: 0.246040 Valid loss: 0.504302 Train acc: 0.891304 Valid acc: 0.834916\n",
      "Epoch: 5/10 Train loss: 0.229455 Valid loss: 0.504085 Train acc: 0.913043 Valid acc: 0.834933\n",
      "Epoch: 5/10 Train loss: 0.234456 Valid loss: 0.503864 Train acc: 0.934783 Valid acc: 0.834948\n",
      "Epoch: 5/10 Train loss: 0.417133 Valid loss: 0.503642 Train acc: 0.847826 Valid acc: 0.834961\n",
      "Epoch: 5/10 Train loss: 0.296721 Valid loss: 0.503417 Train acc: 0.869565 Valid acc: 0.834972\n",
      "Epoch: 5/10 Train loss: 0.226869 Valid loss: 0.503186 Train acc: 0.913043 Valid acc: 0.834984\n",
      "Epoch: 5/10 Train loss: 0.305391 Valid loss: 0.502948 Train acc: 0.847826 Valid acc: 0.835003\n",
      "Epoch: 5/10 Train loss: 0.465606 Valid loss: 0.502712 Train acc: 0.858696 Valid acc: 0.835023\n",
      "Epoch: 5/10 Train loss: 0.368359 Valid loss: 0.502482 Train acc: 0.847826 Valid acc: 0.835037\n",
      "Epoch: 5/10 Train loss: 0.340282 Valid loss: 0.502258 Train acc: 0.869565 Valid acc: 0.835050\n",
      "Epoch: 5/10 Train loss: 0.349398 Valid loss: 0.502042 Train acc: 0.869565 Valid acc: 0.835059\n",
      "Epoch: 5/10 Train loss: 0.273960 Valid loss: 0.501831 Train acc: 0.945652 Valid acc: 0.835059\n",
      "Epoch: 5/10 Train loss: 0.287133 Valid loss: 0.501620 Train acc: 0.880435 Valid acc: 0.835057\n",
      "Epoch: 5/10 Train loss: 0.364979 Valid loss: 0.501410 Train acc: 0.826087 Valid acc: 0.835056\n",
      "Epoch: 5/10 Train loss: 0.319077 Valid loss: 0.501201 Train acc: 0.869565 Valid acc: 0.835052\n",
      "Epoch: 5/10 Train loss: 0.277771 Valid loss: 0.500983 Train acc: 0.880435 Valid acc: 0.835056\n",
      "Epoch: 5/10 Train loss: 0.371722 Valid loss: 0.500758 Train acc: 0.858696 Valid acc: 0.835071\n",
      "Epoch: 5/10 Train loss: 0.400738 Valid loss: 0.500531 Train acc: 0.847826 Valid acc: 0.835087\n",
      "Epoch: 5/10 Train loss: 0.563128 Valid loss: 0.500314 Train acc: 0.826087 Valid acc: 0.835104\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 5/10 Train loss: 0.373846 Valid loss: 0.500110 Train acc: 0.836957 Valid acc: 0.835122\n",
      "Epoch: 5/10 Train loss: 0.327680 Valid loss: 0.499913 Train acc: 0.869565 Valid acc: 0.835147\n",
      "Epoch: 5/10 Train loss: 0.318023 Valid loss: 0.499717 Train acc: 0.869565 Valid acc: 0.835168\n",
      "Epoch: 5/10 Train loss: 0.272920 Valid loss: 0.499517 Train acc: 0.913043 Valid acc: 0.835194\n",
      "Epoch: 5/10 Train loss: 0.337172 Valid loss: 0.499310 Train acc: 0.880435 Valid acc: 0.835226\n",
      "Epoch: 5/10 Train loss: 0.383457 Valid loss: 0.499097 Train acc: 0.891304 Valid acc: 0.835266\n",
      "Epoch: 5/10 Train loss: 0.360999 Valid loss: 0.498878 Train acc: 0.836957 Valid acc: 0.835305\n",
      "Epoch: 5/10 Train loss: 0.313302 Valid loss: 0.498651 Train acc: 0.858696 Valid acc: 0.835346\n",
      "Epoch: 5/10 Train loss: 0.320240 Valid loss: 0.498417 Train acc: 0.880435 Valid acc: 0.835386\n",
      "Epoch: 5/10 Train loss: 0.421271 Valid loss: 0.498181 Train acc: 0.804348 Valid acc: 0.835430\n",
      "Epoch: 5/10 Train loss: 0.306977 Valid loss: 0.497945 Train acc: 0.836957 Valid acc: 0.835475\n",
      "Epoch: 5/10 Train loss: 0.343213 Valid loss: 0.497709 Train acc: 0.836957 Valid acc: 0.835518\n",
      "Epoch: 5/10 Train loss: 0.340195 Valid loss: 0.497477 Train acc: 0.858696 Valid acc: 0.835560\n",
      "Epoch: 5/10 Train loss: 0.314721 Valid loss: 0.497246 Train acc: 0.847826 Valid acc: 0.835600\n",
      "Epoch: 5/10 Train loss: 0.250940 Valid loss: 0.497015 Train acc: 0.869565 Valid acc: 0.835640\n",
      "Epoch: 5/10 Train loss: 0.286393 Valid loss: 0.496785 Train acc: 0.902174 Valid acc: 0.835678\n",
      "Epoch: 5/10 Train loss: 0.335555 Valid loss: 0.496555 Train acc: 0.869565 Valid acc: 0.835714\n",
      "Epoch: 5/10 Train loss: 0.433804 Valid loss: 0.496324 Train acc: 0.804348 Valid acc: 0.835749\n",
      "Epoch: 5/10 Train loss: 0.273953 Valid loss: 0.496090 Train acc: 0.891304 Valid acc: 0.835783\n",
      "Epoch: 5/10 Train loss: 0.361028 Valid loss: 0.495853 Train acc: 0.880435 Valid acc: 0.835822\n",
      "Epoch: 5/10 Train loss: 0.398892 Valid loss: 0.495617 Train acc: 0.847826 Valid acc: 0.835863\n",
      "Epoch: 5/10 Train loss: 0.403522 Valid loss: 0.495384 Train acc: 0.826087 Valid acc: 0.835902\n",
      "Epoch: 5/10 Train loss: 0.473832 Valid loss: 0.495158 Train acc: 0.804348 Valid acc: 0.835941\n",
      "Epoch: 5/10 Train loss: 0.422598 Valid loss: 0.494943 Train acc: 0.826087 Valid acc: 0.835979\n",
      "Epoch: 5/10 Train loss: 0.395431 Valid loss: 0.494744 Train acc: 0.847826 Valid acc: 0.836017\n",
      "Epoch: 5/10 Train loss: 0.408898 Valid loss: 0.494560 Train acc: 0.815217 Valid acc: 0.836053\n",
      "Epoch: 5/10 Train loss: 0.475197 Valid loss: 0.494393 Train acc: 0.847826 Valid acc: 0.836089\n",
      "Epoch: 5/10 Train loss: 0.356736 Valid loss: 0.494239 Train acc: 0.847826 Valid acc: 0.836123\n",
      "Epoch: 5/10 Train loss: 0.407977 Valid loss: 0.494097 Train acc: 0.836957 Valid acc: 0.836156\n",
      "Epoch: 5/10 Train loss: 0.484021 Valid loss: 0.493962 Train acc: 0.804348 Valid acc: 0.836187\n",
      "Epoch: 5/10 Train loss: 0.440346 Valid loss: 0.493833 Train acc: 0.815217 Valid acc: 0.836221\n",
      "Epoch: 5/10 Train loss: 0.463888 Valid loss: 0.493701 Train acc: 0.793478 Valid acc: 0.836259\n",
      "Epoch: 5/10 Train loss: 0.442035 Valid loss: 0.493570 Train acc: 0.826087 Valid acc: 0.836305\n",
      "Epoch: 5/10 Train loss: 0.426017 Valid loss: 0.493439 Train acc: 0.815217 Valid acc: 0.836351\n",
      "Epoch: 5/10 Train loss: 0.446012 Valid loss: 0.493307 Train acc: 0.836957 Valid acc: 0.836395\n",
      "Epoch: 5/10 Train loss: 0.392342 Valid loss: 0.493175 Train acc: 0.826087 Valid acc: 0.836442\n",
      "Epoch: 5/10 Train loss: 0.394144 Valid loss: 0.493042 Train acc: 0.836957 Valid acc: 0.836489\n",
      "Epoch: 5/10 Train loss: 0.412301 Valid loss: 0.492906 Train acc: 0.826087 Valid acc: 0.836532\n",
      "Epoch: 5/10 Train loss: 0.372868 Valid loss: 0.492766 Train acc: 0.847826 Valid acc: 0.836575\n",
      "Epoch: 5/10 Train loss: 0.485306 Valid loss: 0.492625 Train acc: 0.826087 Valid acc: 0.836615\n",
      "Epoch: 5/10 Train loss: 0.443947 Valid loss: 0.492489 Train acc: 0.836957 Valid acc: 0.836653\n",
      "Epoch: 5/10 Train loss: 0.455773 Valid loss: 0.492365 Train acc: 0.836957 Valid acc: 0.836691\n",
      "Epoch: 5/10 Train loss: 0.416415 Valid loss: 0.492257 Train acc: 0.836957 Valid acc: 0.836730\n",
      "Epoch: 5/10 Train loss: 0.425800 Valid loss: 0.492164 Train acc: 0.815217 Valid acc: 0.836771\n",
      "Epoch: 5/10 Train loss: 0.444544 Valid loss: 0.492086 Train acc: 0.836957 Valid acc: 0.836810\n",
      "Epoch: 5/10 Train loss: 0.434874 Valid loss: 0.492020 Train acc: 0.847826 Valid acc: 0.836849\n",
      "Epoch: 5/10 Train loss: 0.395140 Valid loss: 0.491961 Train acc: 0.826087 Valid acc: 0.836891\n",
      "Epoch: 5/10 Train loss: 0.402768 Valid loss: 0.491904 Train acc: 0.836957 Valid acc: 0.836933\n",
      "Epoch: 5/10 Train loss: 0.368586 Valid loss: 0.491847 Train acc: 0.858696 Valid acc: 0.836974\n",
      "Epoch: 5/10 Train loss: 0.382554 Valid loss: 0.491787 Train acc: 0.836957 Valid acc: 0.837016\n",
      "Epoch: 5/10 Train loss: 0.411473 Valid loss: 0.491722 Train acc: 0.836957 Valid acc: 0.837058\n",
      "Epoch: 5/10 Train loss: 0.445346 Valid loss: 0.491652 Train acc: 0.815217 Valid acc: 0.837098\n",
      "Epoch: 5/10 Train loss: 0.389059 Valid loss: 0.491575 Train acc: 0.836957 Valid acc: 0.837138\n",
      "Epoch: 5/10 Train loss: 0.404300 Valid loss: 0.491494 Train acc: 0.847826 Valid acc: 0.837177\n",
      "Epoch: 5/10 Train loss: 0.438702 Valid loss: 0.491409 Train acc: 0.815217 Valid acc: 0.837219\n",
      "Epoch: 5/10 Train loss: 0.434900 Valid loss: 0.491320 Train acc: 0.836957 Valid acc: 0.837260\n",
      "Epoch: 5/10 Train loss: 0.457469 Valid loss: 0.491229 Train acc: 0.836957 Valid acc: 0.837301\n",
      "Epoch: 5/10 Train loss: 0.407422 Valid loss: 0.491137 Train acc: 0.836957 Valid acc: 0.837341\n",
      "Epoch: 5/10 Train loss: 0.466178 Valid loss: 0.491048 Train acc: 0.826087 Valid acc: 0.837380\n",
      "Epoch: 5/10 Train loss: 0.377702 Valid loss: 0.490959 Train acc: 0.847826 Valid acc: 0.837418\n",
      "Epoch: 6/10 Train loss: 0.410929 Valid loss: 0.490868 Train acc: 0.836957 Valid acc: 0.837455\n",
      "Epoch: 6/10 Train loss: 0.354039 Valid loss: 0.490769 Train acc: 0.869565 Valid acc: 0.837489\n",
      "Epoch: 6/10 Train loss: 0.365121 Valid loss: 0.490658 Train acc: 0.847826 Valid acc: 0.837521\n",
      "Epoch: 6/10 Train loss: 0.383672 Valid loss: 0.490533 Train acc: 0.847826 Valid acc: 0.837553\n",
      "Epoch: 6/10 Train loss: 0.382169 Valid loss: 0.490394 Train acc: 0.836957 Valid acc: 0.837584\n",
      "Epoch: 6/10 Train loss: 0.330872 Valid loss: 0.490241 Train acc: 0.836957 Valid acc: 0.837614\n",
      "Epoch: 6/10 Train loss: 0.340338 Valid loss: 0.490074 Train acc: 0.836957 Valid acc: 0.837644\n",
      "Epoch: 6/10 Train loss: 0.351568 Valid loss: 0.489897 Train acc: 0.858696 Valid acc: 0.837673\n",
      "Epoch: 6/10 Train loss: 0.426178 Valid loss: 0.489712 Train acc: 0.826087 Valid acc: 0.837703\n",
      "Epoch: 6/10 Train loss: 0.398143 Valid loss: 0.489521 Train acc: 0.836957 Valid acc: 0.837734\n",
      "Epoch: 6/10 Train loss: 0.385181 Valid loss: 0.489328 Train acc: 0.836957 Valid acc: 0.837764\n",
      "Epoch: 6/10 Train loss: 0.457282 Valid loss: 0.489137 Train acc: 0.836957 Valid acc: 0.837792\n",
      "Epoch: 6/10 Train loss: 0.306378 Valid loss: 0.488946 Train acc: 0.869565 Valid acc: 0.837823\n",
      "Epoch: 6/10 Train loss: 0.399312 Valid loss: 0.488760 Train acc: 0.836957 Valid acc: 0.837854\n",
      "Epoch: 6/10 Train loss: 0.379316 Valid loss: 0.488580 Train acc: 0.847826 Valid acc: 0.837880\n",
      "Epoch: 6/10 Train loss: 0.362779 Valid loss: 0.488409 Train acc: 0.836957 Valid acc: 0.837899\n",
      "Epoch: 6/10 Train loss: 0.328762 Valid loss: 0.488245 Train acc: 0.847826 Valid acc: 0.837910\n",
      "Epoch: 6/10 Train loss: 0.401241 Valid loss: 0.488093 Train acc: 0.793478 Valid acc: 0.837915\n",
      "Epoch: 6/10 Train loss: 0.359956 Valid loss: 0.487949 Train acc: 0.836957 Valid acc: 0.837910\n",
      "Epoch: 6/10 Train loss: 0.378668 Valid loss: 0.487812 Train acc: 0.836957 Valid acc: 0.837897\n",
      "Epoch: 6/10 Train loss: 0.277933 Valid loss: 0.487675 Train acc: 0.891304 Valid acc: 0.837883\n",
      "Epoch: 6/10 Train loss: 0.254826 Valid loss: 0.487533 Train acc: 0.891304 Valid acc: 0.837871\n",
      "Epoch: 6/10 Train loss: 0.229871 Valid loss: 0.487380 Train acc: 0.923913 Valid acc: 0.837864\n",
      "Epoch: 6/10 Train loss: 0.248260 Valid loss: 0.487215 Train acc: 0.923913 Valid acc: 0.837868\n",
      "Epoch: 6/10 Train loss: 0.381389 Valid loss: 0.487040 Train acc: 0.858696 Valid acc: 0.837879\n",
      "Epoch: 6/10 Train loss: 0.311381 Valid loss: 0.486858 Train acc: 0.891304 Valid acc: 0.837896\n",
      "Epoch: 6/10 Train loss: 0.256643 Valid loss: 0.486668 Train acc: 0.902174 Valid acc: 0.837917\n",
      "Epoch: 6/10 Train loss: 0.306095 Valid loss: 0.486470 Train acc: 0.869565 Valid acc: 0.837946\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 6/10 Train loss: 0.444293 Valid loss: 0.486273 Train acc: 0.836957 Valid acc: 0.837975\n",
      "Epoch: 6/10 Train loss: 0.436211 Valid loss: 0.486080 Train acc: 0.869565 Valid acc: 0.838001\n",
      "Epoch: 6/10 Train loss: 0.285906 Valid loss: 0.485891 Train acc: 0.891304 Valid acc: 0.838028\n",
      "Epoch: 6/10 Train loss: 0.340617 Valid loss: 0.485710 Train acc: 0.869565 Valid acc: 0.838051\n",
      "Epoch: 6/10 Train loss: 0.269952 Valid loss: 0.485538 Train acc: 0.956522 Valid acc: 0.838072\n",
      "Epoch: 6/10 Train loss: 0.259058 Valid loss: 0.485371 Train acc: 0.880435 Valid acc: 0.838091\n",
      "Epoch: 6/10 Train loss: 0.345245 Valid loss: 0.485212 Train acc: 0.847826 Valid acc: 0.838100\n",
      "Epoch: 6/10 Train loss: 0.349521 Valid loss: 0.485057 Train acc: 0.847826 Valid acc: 0.838104\n",
      "Epoch: 6/10 Train loss: 0.242220 Valid loss: 0.484903 Train acc: 0.891304 Valid acc: 0.838107\n",
      "Epoch: 6/10 Train loss: 0.335288 Valid loss: 0.484749 Train acc: 0.869565 Valid acc: 0.838108\n",
      "Epoch: 6/10 Train loss: 0.427936 Valid loss: 0.484595 Train acc: 0.826087 Valid acc: 0.838111\n",
      "Epoch: 6/10 Train loss: 0.577249 Valid loss: 0.484447 Train acc: 0.869565 Valid acc: 0.838117\n",
      "Epoch: 6/10 Train loss: 0.345384 Valid loss: 0.484301 Train acc: 0.836957 Valid acc: 0.838123\n",
      "Epoch: 6/10 Train loss: 0.292623 Valid loss: 0.484154 Train acc: 0.869565 Valid acc: 0.838135\n",
      "Epoch: 6/10 Train loss: 0.251004 Valid loss: 0.484002 Train acc: 0.913043 Valid acc: 0.838152\n",
      "Epoch: 6/10 Train loss: 0.273610 Valid loss: 0.483841 Train acc: 0.923913 Valid acc: 0.838169\n",
      "Epoch: 6/10 Train loss: 0.311796 Valid loss: 0.483672 Train acc: 0.847826 Valid acc: 0.838189\n",
      "Epoch: 6/10 Train loss: 0.402788 Valid loss: 0.483495 Train acc: 0.815217 Valid acc: 0.838214\n",
      "Epoch: 6/10 Train loss: 0.331316 Valid loss: 0.483313 Train acc: 0.891304 Valid acc: 0.838243\n",
      "Epoch: 6/10 Train loss: 0.289290 Valid loss: 0.483129 Train acc: 0.858696 Valid acc: 0.838274\n",
      "Epoch: 6/10 Train loss: 0.324073 Valid loss: 0.482945 Train acc: 0.891304 Valid acc: 0.838307\n",
      "Epoch: 6/10 Train loss: 0.363214 Valid loss: 0.482765 Train acc: 0.858696 Valid acc: 0.838335\n",
      "Epoch: 6/10 Train loss: 0.252025 Valid loss: 0.482589 Train acc: 0.891304 Valid acc: 0.838361\n",
      "Epoch: 6/10 Train loss: 0.315891 Valid loss: 0.482416 Train acc: 0.869565 Valid acc: 0.838383\n",
      "Epoch: 6/10 Train loss: 0.335585 Valid loss: 0.482247 Train acc: 0.869565 Valid acc: 0.838406\n",
      "Epoch: 6/10 Train loss: 0.352375 Valid loss: 0.482085 Train acc: 0.880435 Valid acc: 0.838426\n",
      "Epoch: 6/10 Train loss: 0.283406 Valid loss: 0.481926 Train acc: 0.880435 Valid acc: 0.838442\n",
      "Epoch: 6/10 Train loss: 0.296766 Valid loss: 0.481769 Train acc: 0.934783 Valid acc: 0.838457\n",
      "Epoch: 6/10 Train loss: 0.339603 Valid loss: 0.481612 Train acc: 0.869565 Valid acc: 0.838475\n",
      "Epoch: 6/10 Train loss: 0.430064 Valid loss: 0.481453 Train acc: 0.836957 Valid acc: 0.838494\n",
      "Epoch: 6/10 Train loss: 0.258655 Valid loss: 0.481293 Train acc: 0.891304 Valid acc: 0.838516\n",
      "Epoch: 6/10 Train loss: 0.308360 Valid loss: 0.481128 Train acc: 0.880435 Valid acc: 0.838537\n",
      "Epoch: 6/10 Train loss: 0.424962 Valid loss: 0.480963 Train acc: 0.826087 Valid acc: 0.838558\n",
      "Epoch: 6/10 Train loss: 0.381709 Valid loss: 0.480796 Train acc: 0.826087 Valid acc: 0.838581\n",
      "Epoch: 6/10 Train loss: 0.474288 Valid loss: 0.480630 Train acc: 0.815217 Valid acc: 0.838601\n",
      "Epoch: 6/10 Train loss: 0.362178 Valid loss: 0.480469 Train acc: 0.847826 Valid acc: 0.838620\n",
      "Epoch: 6/10 Train loss: 0.391352 Valid loss: 0.480312 Train acc: 0.836957 Valid acc: 0.838642\n",
      "Epoch: 6/10 Train loss: 0.487415 Valid loss: 0.480159 Train acc: 0.782609 Valid acc: 0.838667\n",
      "Epoch: 6/10 Train loss: 0.495705 Valid loss: 0.480014 Train acc: 0.826087 Valid acc: 0.838694\n",
      "Epoch: 6/10 Train loss: 0.395903 Valid loss: 0.479877 Train acc: 0.836957 Valid acc: 0.838721\n",
      "Epoch: 6/10 Train loss: 0.369386 Valid loss: 0.479748 Train acc: 0.847826 Valid acc: 0.838751\n",
      "Epoch: 6/10 Train loss: 0.559763 Valid loss: 0.479633 Train acc: 0.804348 Valid acc: 0.838784\n",
      "Epoch: 6/10 Train loss: 0.404897 Valid loss: 0.479531 Train acc: 0.847826 Valid acc: 0.838817\n",
      "Epoch: 6/10 Train loss: 0.405183 Valid loss: 0.479434 Train acc: 0.804348 Valid acc: 0.838853\n",
      "Epoch: 6/10 Train loss: 0.388923 Valid loss: 0.479341 Train acc: 0.815217 Valid acc: 0.838889\n",
      "Epoch: 6/10 Train loss: 0.388922 Valid loss: 0.479249 Train acc: 0.826087 Valid acc: 0.838926\n",
      "Epoch: 6/10 Train loss: 0.466988 Valid loss: 0.479156 Train acc: 0.815217 Valid acc: 0.838963\n",
      "Epoch: 6/10 Train loss: 0.508422 Valid loss: 0.479066 Train acc: 0.804348 Valid acc: 0.839001\n",
      "Epoch: 6/10 Train loss: 0.382191 Valid loss: 0.478975 Train acc: 0.836957 Valid acc: 0.839037\n",
      "Epoch: 6/10 Train loss: 0.451454 Valid loss: 0.478883 Train acc: 0.836957 Valid acc: 0.839072\n",
      "Epoch: 6/10 Train loss: 0.377905 Valid loss: 0.478787 Train acc: 0.847826 Valid acc: 0.839106\n",
      "Epoch: 6/10 Train loss: 0.653980 Valid loss: 0.478695 Train acc: 0.826087 Valid acc: 0.839139\n",
      "Epoch: 6/10 Train loss: 0.416407 Valid loss: 0.478606 Train acc: 0.826087 Valid acc: 0.839171\n",
      "Epoch: 6/10 Train loss: 0.410872 Valid loss: 0.478519 Train acc: 0.826087 Valid acc: 0.839199\n",
      "Epoch: 6/10 Train loss: 0.425777 Valid loss: 0.478438 Train acc: 0.836957 Valid acc: 0.839228\n",
      "Epoch: 6/10 Train loss: 0.391153 Valid loss: 0.478362 Train acc: 0.826087 Valid acc: 0.839255\n",
      "Epoch: 6/10 Train loss: 0.394069 Valid loss: 0.478292 Train acc: 0.847826 Valid acc: 0.839282\n",
      "Epoch: 6/10 Train loss: 0.414745 Valid loss: 0.478228 Train acc: 0.836957 Valid acc: 0.839311\n",
      "Epoch: 6/10 Train loss: 0.447974 Valid loss: 0.478171 Train acc: 0.815217 Valid acc: 0.839341\n",
      "Epoch: 6/10 Train loss: 0.438636 Valid loss: 0.478118 Train acc: 0.847826 Valid acc: 0.839370\n",
      "Epoch: 6/10 Train loss: 0.349084 Valid loss: 0.478069 Train acc: 0.847826 Valid acc: 0.839401\n",
      "Epoch: 6/10 Train loss: 0.389213 Valid loss: 0.478021 Train acc: 0.836957 Valid acc: 0.839431\n",
      "Epoch: 6/10 Train loss: 0.352242 Valid loss: 0.477968 Train acc: 0.847826 Valid acc: 0.839462\n",
      "Epoch: 6/10 Train loss: 0.431910 Valid loss: 0.477909 Train acc: 0.826087 Valid acc: 0.839493\n",
      "Epoch: 6/10 Train loss: 0.423193 Valid loss: 0.477843 Train acc: 0.836957 Valid acc: 0.839524\n",
      "Epoch: 6/10 Train loss: 0.388596 Valid loss: 0.477769 Train acc: 0.836957 Valid acc: 0.839555\n",
      "Epoch: 6/10 Train loss: 0.443681 Valid loss: 0.477690 Train acc: 0.826087 Valid acc: 0.839584\n",
      "Epoch: 6/10 Train loss: 0.437584 Valid loss: 0.477609 Train acc: 0.836957 Valid acc: 0.839614\n",
      "Epoch: 6/10 Train loss: 0.412003 Valid loss: 0.477524 Train acc: 0.836957 Valid acc: 0.839644\n",
      "Epoch: 6/10 Train loss: 0.458755 Valid loss: 0.477438 Train acc: 0.836957 Valid acc: 0.839674\n",
      "Epoch: 6/10 Train loss: 0.436819 Valid loss: 0.477355 Train acc: 0.826087 Valid acc: 0.839703\n",
      "Epoch: 6/10 Train loss: 0.422005 Valid loss: 0.477274 Train acc: 0.847826 Valid acc: 0.839732\n",
      "Epoch: 7/10 Train loss: 0.391212 Valid loss: 0.477191 Train acc: 0.826087 Valid acc: 0.839761\n",
      "Epoch: 7/10 Train loss: 0.355124 Valid loss: 0.477101 Train acc: 0.847826 Valid acc: 0.839792\n",
      "Epoch: 7/10 Train loss: 0.351831 Valid loss: 0.476999 Train acc: 0.836957 Valid acc: 0.839821\n",
      "Epoch: 7/10 Train loss: 0.385446 Valid loss: 0.476885 Train acc: 0.847826 Valid acc: 0.839851\n",
      "Epoch: 7/10 Train loss: 0.381735 Valid loss: 0.476759 Train acc: 0.836957 Valid acc: 0.839878\n",
      "Epoch: 7/10 Train loss: 0.371649 Valid loss: 0.476624 Train acc: 0.836957 Valid acc: 0.839904\n",
      "Epoch: 7/10 Train loss: 0.323549 Valid loss: 0.476479 Train acc: 0.836957 Valid acc: 0.839930\n",
      "Epoch: 7/10 Train loss: 0.339041 Valid loss: 0.476328 Train acc: 0.847826 Valid acc: 0.839956\n",
      "Epoch: 7/10 Train loss: 0.401709 Valid loss: 0.476173 Train acc: 0.836957 Valid acc: 0.839977\n",
      "Epoch: 7/10 Train loss: 0.391148 Valid loss: 0.476017 Train acc: 0.847826 Valid acc: 0.839999\n",
      "Epoch: 7/10 Train loss: 0.376653 Valid loss: 0.475862 Train acc: 0.815217 Valid acc: 0.840024\n",
      "Epoch: 7/10 Train loss: 0.419940 Valid loss: 0.475708 Train acc: 0.826087 Valid acc: 0.840048\n",
      "Epoch: 7/10 Train loss: 0.300226 Valid loss: 0.475557 Train acc: 0.847826 Valid acc: 0.840074\n",
      "Epoch: 7/10 Train loss: 0.418779 Valid loss: 0.475411 Train acc: 0.815217 Valid acc: 0.840094\n",
      "Epoch: 7/10 Train loss: 0.324824 Valid loss: 0.475270 Train acc: 0.869565 Valid acc: 0.840111\n",
      "Epoch: 7/10 Train loss: 0.376590 Valid loss: 0.475136 Train acc: 0.804348 Valid acc: 0.840124\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7/10 Train loss: 0.306183 Valid loss: 0.475010 Train acc: 0.869565 Valid acc: 0.840133\n",
      "Epoch: 7/10 Train loss: 0.374869 Valid loss: 0.474891 Train acc: 0.836957 Valid acc: 0.840139\n",
      "Epoch: 7/10 Train loss: 0.382305 Valid loss: 0.474778 Train acc: 0.804348 Valid acc: 0.840133\n",
      "Epoch: 7/10 Train loss: 0.366141 Valid loss: 0.474670 Train acc: 0.836957 Valid acc: 0.840120\n",
      "Epoch: 7/10 Train loss: 0.296962 Valid loss: 0.474558 Train acc: 0.847826 Valid acc: 0.840109\n",
      "Epoch: 7/10 Train loss: 0.227762 Valid loss: 0.474437 Train acc: 0.902174 Valid acc: 0.840103\n",
      "Epoch: 7/10 Train loss: 0.160202 Valid loss: 0.474305 Train acc: 0.945652 Valid acc: 0.840106\n",
      "Epoch: 7/10 Train loss: 0.220190 Valid loss: 0.474162 Train acc: 0.923913 Valid acc: 0.840117\n",
      "Epoch: 7/10 Train loss: 0.345713 Valid loss: 0.474010 Train acc: 0.847826 Valid acc: 0.840135\n",
      "Epoch: 7/10 Train loss: 0.318162 Valid loss: 0.473853 Train acc: 0.847826 Valid acc: 0.840156\n",
      "Epoch: 7/10 Train loss: 0.258399 Valid loss: 0.473691 Train acc: 0.902174 Valid acc: 0.840179\n",
      "Epoch: 7/10 Train loss: 0.279678 Valid loss: 0.473526 Train acc: 0.902174 Valid acc: 0.840203\n",
      "Epoch: 7/10 Train loss: 0.303278 Valid loss: 0.473360 Train acc: 0.902174 Valid acc: 0.840225\n",
      "Epoch: 7/10 Train loss: 0.354754 Valid loss: 0.473197 Train acc: 0.880435 Valid acc: 0.840244\n",
      "Epoch: 7/10 Train loss: 0.318152 Valid loss: 0.473039 Train acc: 0.891304 Valid acc: 0.840261\n",
      "Epoch: 7/10 Train loss: 0.355828 Valid loss: 0.472888 Train acc: 0.858696 Valid acc: 0.840277\n",
      "Epoch: 7/10 Train loss: 0.307233 Valid loss: 0.472745 Train acc: 0.934783 Valid acc: 0.840287\n",
      "Epoch: 7/10 Train loss: 0.309925 Valid loss: 0.472605 Train acc: 0.836957 Valid acc: 0.840294\n",
      "Epoch: 7/10 Train loss: 0.353458 Valid loss: 0.472466 Train acc: 0.847826 Valid acc: 0.840301\n",
      "Epoch: 7/10 Train loss: 0.263826 Valid loss: 0.472326 Train acc: 0.913043 Valid acc: 0.840310\n",
      "Epoch: 7/10 Train loss: 0.261808 Valid loss: 0.472184 Train acc: 0.902174 Valid acc: 0.840326\n",
      "Epoch: 7/10 Train loss: 0.351956 Valid loss: 0.472038 Train acc: 0.869565 Valid acc: 0.840341\n",
      "Epoch: 7/10 Train loss: 0.510146 Valid loss: 0.471895 Train acc: 0.826087 Valid acc: 0.840355\n",
      "Epoch: 7/10 Train loss: 0.416563 Valid loss: 0.471759 Train acc: 0.847826 Valid acc: 0.840369\n",
      "Epoch: 7/10 Train loss: 0.268252 Valid loss: 0.471628 Train acc: 0.880435 Valid acc: 0.840385\n",
      "Epoch: 7/10 Train loss: 0.291608 Valid loss: 0.471501 Train acc: 0.869565 Valid acc: 0.840402\n",
      "Epoch: 7/10 Train loss: 0.282035 Valid loss: 0.471373 Train acc: 0.869565 Valid acc: 0.840420\n",
      "Epoch: 7/10 Train loss: 0.259898 Valid loss: 0.471244 Train acc: 0.923913 Valid acc: 0.840439\n",
      "Epoch: 7/10 Train loss: 0.323536 Valid loss: 0.471112 Train acc: 0.858696 Valid acc: 0.840457\n",
      "Epoch: 7/10 Train loss: 0.340580 Valid loss: 0.470979 Train acc: 0.880435 Valid acc: 0.840477\n",
      "Epoch: 7/10 Train loss: 0.351595 Valid loss: 0.470845 Train acc: 0.880435 Valid acc: 0.840498\n",
      "Epoch: 7/10 Train loss: 0.316555 Valid loss: 0.470710 Train acc: 0.869565 Valid acc: 0.840520\n",
      "Epoch: 7/10 Train loss: 0.303247 Valid loss: 0.470575 Train acc: 0.891304 Valid acc: 0.840542\n",
      "Epoch: 7/10 Train loss: 0.346394 Valid loss: 0.470442 Train acc: 0.869565 Valid acc: 0.840563\n",
      "Epoch: 7/10 Train loss: 0.283860 Valid loss: 0.470311 Train acc: 0.858696 Valid acc: 0.840585\n",
      "Epoch: 7/10 Train loss: 0.314256 Valid loss: 0.470183 Train acc: 0.858696 Valid acc: 0.840602\n",
      "Epoch: 7/10 Train loss: 0.331556 Valid loss: 0.470057 Train acc: 0.869565 Valid acc: 0.840618\n",
      "Epoch: 7/10 Train loss: 0.338894 Valid loss: 0.469934 Train acc: 0.880435 Valid acc: 0.840635\n",
      "Epoch: 7/10 Train loss: 0.262551 Valid loss: 0.469810 Train acc: 0.923913 Valid acc: 0.840650\n",
      "Epoch: 7/10 Train loss: 0.253114 Valid loss: 0.469686 Train acc: 0.923913 Valid acc: 0.840663\n",
      "Epoch: 7/10 Train loss: 0.305093 Valid loss: 0.469558 Train acc: 0.858696 Valid acc: 0.840676\n",
      "Epoch: 7/10 Train loss: 0.375936 Valid loss: 0.469429 Train acc: 0.847826 Valid acc: 0.840691\n",
      "Epoch: 7/10 Train loss: 0.265404 Valid loss: 0.469299 Train acc: 0.913043 Valid acc: 0.840703\n",
      "Epoch: 7/10 Train loss: 0.287736 Valid loss: 0.469168 Train acc: 0.923913 Valid acc: 0.840713\n",
      "Epoch: 7/10 Train loss: 0.392927 Valid loss: 0.469038 Train acc: 0.815217 Valid acc: 0.840725\n",
      "Epoch: 7/10 Train loss: 0.402760 Valid loss: 0.468909 Train acc: 0.836957 Valid acc: 0.840738\n",
      "Epoch: 7/10 Train loss: 0.487041 Valid loss: 0.468784 Train acc: 0.804348 Valid acc: 0.840748\n",
      "Epoch: 7/10 Train loss: 0.405750 Valid loss: 0.468665 Train acc: 0.836957 Valid acc: 0.840757\n",
      "Epoch: 7/10 Train loss: 0.406517 Valid loss: 0.468554 Train acc: 0.826087 Valid acc: 0.840766\n",
      "Epoch: 7/10 Train loss: 0.444267 Valid loss: 0.468451 Train acc: 0.804348 Valid acc: 0.840774\n",
      "Epoch: 7/10 Train loss: 0.439715 Valid loss: 0.468355 Train acc: 0.858696 Valid acc: 0.840784\n",
      "Epoch: 7/10 Train loss: 0.392978 Valid loss: 0.468262 Train acc: 0.804348 Valid acc: 0.840795\n",
      "Epoch: 7/10 Train loss: 0.425104 Valid loss: 0.468169 Train acc: 0.847826 Valid acc: 0.840808\n",
      "Epoch: 7/10 Train loss: 0.578537 Valid loss: 0.468078 Train acc: 0.793478 Valid acc: 0.840825\n",
      "Epoch: 7/10 Train loss: 0.449316 Valid loss: 0.467986 Train acc: 0.826087 Valid acc: 0.840844\n",
      "Epoch: 7/10 Train loss: 0.403894 Valid loss: 0.467889 Train acc: 0.826087 Valid acc: 0.840868\n",
      "Epoch: 7/10 Train loss: 0.411340 Valid loss: 0.467793 Train acc: 0.815217 Valid acc: 0.840894\n",
      "Epoch: 7/10 Train loss: 0.374993 Valid loss: 0.467697 Train acc: 0.836957 Valid acc: 0.840923\n",
      "Epoch: 7/10 Train loss: 0.414721 Valid loss: 0.467603 Train acc: 0.858696 Valid acc: 0.840954\n",
      "Epoch: 7/10 Train loss: 0.470688 Valid loss: 0.467515 Train acc: 0.815217 Valid acc: 0.840985\n",
      "Epoch: 7/10 Train loss: 0.341900 Valid loss: 0.467429 Train acc: 0.836957 Valid acc: 0.841014\n",
      "Epoch: 7/10 Train loss: 0.405685 Valid loss: 0.467346 Train acc: 0.847826 Valid acc: 0.841041\n",
      "Epoch: 7/10 Train loss: 0.347291 Valid loss: 0.467263 Train acc: 0.847826 Valid acc: 0.841067\n",
      "Epoch: 7/10 Train loss: 0.467306 Valid loss: 0.467184 Train acc: 0.826087 Valid acc: 0.841094\n",
      "Epoch: 7/10 Train loss: 0.470107 Valid loss: 0.467110 Train acc: 0.826087 Valid acc: 0.841122\n",
      "Epoch: 7/10 Train loss: 0.380469 Valid loss: 0.467043 Train acc: 0.826087 Valid acc: 0.841149\n",
      "Epoch: 7/10 Train loss: 0.462671 Valid loss: 0.466983 Train acc: 0.826087 Valid acc: 0.841176\n",
      "Epoch: 7/10 Train loss: 0.424035 Valid loss: 0.466931 Train acc: 0.826087 Valid acc: 0.841202\n",
      "Epoch: 7/10 Train loss: 0.427835 Valid loss: 0.466884 Train acc: 0.836957 Valid acc: 0.841228\n",
      "Epoch: 7/10 Train loss: 0.398982 Valid loss: 0.466841 Train acc: 0.836957 Valid acc: 0.841254\n",
      "Epoch: 7/10 Train loss: 0.448158 Valid loss: 0.466800 Train acc: 0.815217 Valid acc: 0.841280\n",
      "Epoch: 7/10 Train loss: 0.435326 Valid loss: 0.466761 Train acc: 0.836957 Valid acc: 0.841306\n",
      "Epoch: 7/10 Train loss: 0.402494 Valid loss: 0.466724 Train acc: 0.836957 Valid acc: 0.841332\n",
      "Epoch: 7/10 Train loss: 0.382287 Valid loss: 0.466687 Train acc: 0.858696 Valid acc: 0.841359\n",
      "Epoch: 7/10 Train loss: 0.344670 Valid loss: 0.466646 Train acc: 0.847826 Valid acc: 0.841385\n",
      "Epoch: 7/10 Train loss: 0.410329 Valid loss: 0.466599 Train acc: 0.826087 Valid acc: 0.841412\n",
      "Epoch: 7/10 Train loss: 0.438479 Valid loss: 0.466544 Train acc: 0.804348 Valid acc: 0.841439\n",
      "Epoch: 7/10 Train loss: 0.452803 Valid loss: 0.466483 Train acc: 0.836957 Valid acc: 0.841466\n",
      "Epoch: 7/10 Train loss: 0.411466 Valid loss: 0.466415 Train acc: 0.815217 Valid acc: 0.841493\n",
      "Epoch: 7/10 Train loss: 0.368655 Valid loss: 0.466340 Train acc: 0.826087 Valid acc: 0.841518\n",
      "Epoch: 7/10 Train loss: 0.398753 Valid loss: 0.466259 Train acc: 0.836957 Valid acc: 0.841541\n",
      "Epoch: 7/10 Train loss: 0.390771 Valid loss: 0.466177 Train acc: 0.826087 Valid acc: 0.841564\n",
      "Epoch: 7/10 Train loss: 0.403716 Valid loss: 0.466095 Train acc: 0.826087 Valid acc: 0.841588\n",
      "Epoch: 7/10 Train loss: 0.420752 Valid loss: 0.466016 Train acc: 0.836957 Valid acc: 0.841613\n",
      "Epoch: 8/10 Train loss: 0.392450 Valid loss: 0.465939 Train acc: 0.826087 Valid acc: 0.841636\n",
      "Epoch: 8/10 Train loss: 0.332765 Valid loss: 0.465860 Train acc: 0.858696 Valid acc: 0.841659\n",
      "Epoch: 8/10 Train loss: 0.352563 Valid loss: 0.465779 Train acc: 0.826087 Valid acc: 0.841682\n",
      "Epoch: 8/10 Train loss: 0.401503 Valid loss: 0.465694 Train acc: 0.847826 Valid acc: 0.841704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Train loss: 0.376269 Valid loss: 0.465604 Train acc: 0.836957 Valid acc: 0.841727\n",
      "Epoch: 8/10 Train loss: 0.364211 Valid loss: 0.465508 Train acc: 0.858696 Valid acc: 0.841749\n",
      "Epoch: 8/10 Train loss: 0.342634 Valid loss: 0.465406 Train acc: 0.847826 Valid acc: 0.841771\n",
      "Epoch: 8/10 Train loss: 0.315138 Valid loss: 0.465298 Train acc: 0.880435 Valid acc: 0.841793\n",
      "Epoch: 8/10 Train loss: 0.390857 Valid loss: 0.465186 Train acc: 0.826087 Valid acc: 0.841815\n",
      "Epoch: 8/10 Train loss: 0.361432 Valid loss: 0.465073 Train acc: 0.847826 Valid acc: 0.841838\n",
      "Epoch: 8/10 Train loss: 0.327178 Valid loss: 0.464958 Train acc: 0.836957 Valid acc: 0.841862\n",
      "Epoch: 8/10 Train loss: 0.415477 Valid loss: 0.464845 Train acc: 0.826087 Valid acc: 0.841886\n",
      "Epoch: 8/10 Train loss: 0.318347 Valid loss: 0.464734 Train acc: 0.869565 Valid acc: 0.841908\n",
      "Epoch: 8/10 Train loss: 0.400419 Valid loss: 0.464626 Train acc: 0.815217 Valid acc: 0.841921\n",
      "Epoch: 8/10 Train loss: 0.331539 Valid loss: 0.464522 Train acc: 0.869565 Valid acc: 0.841934\n",
      "Epoch: 8/10 Train loss: 0.331281 Valid loss: 0.464422 Train acc: 0.858696 Valid acc: 0.841943\n",
      "Epoch: 8/10 Train loss: 0.343246 Valid loss: 0.464327 Train acc: 0.869565 Valid acc: 0.841945\n",
      "Epoch: 8/10 Train loss: 0.435514 Valid loss: 0.464235 Train acc: 0.847826 Valid acc: 0.841945\n",
      "Epoch: 8/10 Train loss: 0.385075 Valid loss: 0.464147 Train acc: 0.836957 Valid acc: 0.841938\n",
      "Epoch: 8/10 Train loss: 0.368581 Valid loss: 0.464063 Train acc: 0.836957 Valid acc: 0.841929\n",
      "Epoch: 8/10 Train loss: 0.219866 Valid loss: 0.463974 Train acc: 0.923913 Valid acc: 0.841923\n",
      "Epoch: 8/10 Train loss: 0.233093 Valid loss: 0.463872 Train acc: 0.891304 Valid acc: 0.841924\n",
      "Epoch: 8/10 Train loss: 0.191411 Valid loss: 0.463756 Train acc: 0.923913 Valid acc: 0.841935\n",
      "Epoch: 8/10 Train loss: 0.158484 Valid loss: 0.463630 Train acc: 0.934783 Valid acc: 0.841952\n",
      "Epoch: 8/10 Train loss: 0.401721 Valid loss: 0.463498 Train acc: 0.826087 Valid acc: 0.841970\n",
      "Epoch: 8/10 Train loss: 0.330501 Valid loss: 0.463362 Train acc: 0.869565 Valid acc: 0.841990\n",
      "Epoch: 8/10 Train loss: 0.151444 Valid loss: 0.463223 Train acc: 0.956522 Valid acc: 0.842009\n",
      "Epoch: 8/10 Train loss: 0.197062 Valid loss: 0.463081 Train acc: 0.913043 Valid acc: 0.842031\n",
      "Epoch: 8/10 Train loss: 0.387856 Valid loss: 0.462939 Train acc: 0.847826 Valid acc: 0.842053\n",
      "Epoch: 8/10 Train loss: 0.391846 Valid loss: 0.462798 Train acc: 0.858696 Valid acc: 0.842075\n",
      "Epoch: 8/10 Train loss: 0.345571 Valid loss: 0.462659 Train acc: 0.869565 Valid acc: 0.842093\n",
      "Epoch: 8/10 Train loss: 0.308441 Valid loss: 0.462526 Train acc: 0.902174 Valid acc: 0.842108\n",
      "Epoch: 8/10 Train loss: 0.250240 Valid loss: 0.462400 Train acc: 0.945652 Valid acc: 0.842118\n",
      "Epoch: 8/10 Train loss: 0.275847 Valid loss: 0.462278 Train acc: 0.880435 Valid acc: 0.842129\n",
      "Epoch: 8/10 Train loss: 0.316656 Valid loss: 0.462161 Train acc: 0.858696 Valid acc: 0.842136\n",
      "Epoch: 8/10 Train loss: 0.246476 Valid loss: 0.462045 Train acc: 0.934783 Valid acc: 0.842144\n",
      "Epoch: 8/10 Train loss: 0.213935 Valid loss: 0.461927 Train acc: 0.902174 Valid acc: 0.842153\n",
      "Epoch: 8/10 Train loss: 0.300438 Valid loss: 0.461807 Train acc: 0.891304 Valid acc: 0.842162\n",
      "Epoch: 8/10 Train loss: 0.338113 Valid loss: 0.461686 Train acc: 0.891304 Valid acc: 0.842171\n",
      "Epoch: 8/10 Train loss: 0.378081 Valid loss: 0.461569 Train acc: 0.902174 Valid acc: 0.842178\n",
      "Epoch: 8/10 Train loss: 0.288104 Valid loss: 0.461454 Train acc: 0.869565 Valid acc: 0.842187\n",
      "Epoch: 8/10 Train loss: 0.289195 Valid loss: 0.461341 Train acc: 0.902174 Valid acc: 0.842198\n",
      "Epoch: 8/10 Train loss: 0.315195 Valid loss: 0.461226 Train acc: 0.869565 Valid acc: 0.842208\n",
      "Epoch: 8/10 Train loss: 0.250807 Valid loss: 0.461107 Train acc: 0.945652 Valid acc: 0.842219\n",
      "Epoch: 8/10 Train loss: 0.294086 Valid loss: 0.460983 Train acc: 0.902174 Valid acc: 0.842233\n",
      "Epoch: 8/10 Train loss: 0.384986 Valid loss: 0.460856 Train acc: 0.847826 Valid acc: 0.842251\n",
      "Epoch: 8/10 Train loss: 0.351776 Valid loss: 0.460727 Train acc: 0.902174 Valid acc: 0.842270\n",
      "Epoch: 8/10 Train loss: 0.258969 Valid loss: 0.460596 Train acc: 0.913043 Valid acc: 0.842290\n",
      "Epoch: 8/10 Train loss: 0.256434 Valid loss: 0.460466 Train acc: 0.902174 Valid acc: 0.842309\n",
      "Epoch: 8/10 Train loss: 0.374651 Valid loss: 0.460338 Train acc: 0.847826 Valid acc: 0.842327\n",
      "Epoch: 8/10 Train loss: 0.318846 Valid loss: 0.460215 Train acc: 0.836957 Valid acc: 0.842342\n",
      "Epoch: 8/10 Train loss: 0.310305 Valid loss: 0.460099 Train acc: 0.858696 Valid acc: 0.842352\n",
      "Epoch: 8/10 Train loss: 0.314241 Valid loss: 0.459986 Train acc: 0.869565 Valid acc: 0.842359\n",
      "Epoch: 8/10 Train loss: 0.339589 Valid loss: 0.459877 Train acc: 0.880435 Valid acc: 0.842366\n",
      "Epoch: 8/10 Train loss: 0.218255 Valid loss: 0.459768 Train acc: 0.923913 Valid acc: 0.842373\n",
      "Epoch: 8/10 Train loss: 0.263471 Valid loss: 0.459660 Train acc: 0.913043 Valid acc: 0.842380\n",
      "Epoch: 8/10 Train loss: 0.334931 Valid loss: 0.459549 Train acc: 0.891304 Valid acc: 0.842387\n",
      "Epoch: 8/10 Train loss: 0.382438 Valid loss: 0.459433 Train acc: 0.847826 Valid acc: 0.842400\n",
      "Epoch: 8/10 Train loss: 0.293697 Valid loss: 0.459313 Train acc: 0.880435 Valid acc: 0.842416\n",
      "Epoch: 8/10 Train loss: 0.264258 Valid loss: 0.459189 Train acc: 0.945652 Valid acc: 0.842435\n",
      "Epoch: 8/10 Train loss: 0.479750 Valid loss: 0.459064 Train acc: 0.826087 Valid acc: 0.842457\n",
      "Epoch: 8/10 Train loss: 0.397943 Valid loss: 0.458939 Train acc: 0.815217 Valid acc: 0.842477\n",
      "Epoch: 8/10 Train loss: 0.468941 Valid loss: 0.458818 Train acc: 0.804348 Valid acc: 0.842497\n",
      "Epoch: 8/10 Train loss: 0.384559 Valid loss: 0.458701 Train acc: 0.836957 Valid acc: 0.842518\n",
      "Epoch: 8/10 Train loss: 0.382646 Valid loss: 0.458588 Train acc: 0.847826 Valid acc: 0.842535\n",
      "Epoch: 8/10 Train loss: 0.452965 Valid loss: 0.458483 Train acc: 0.804348 Valid acc: 0.842555\n",
      "Epoch: 8/10 Train loss: 0.421476 Valid loss: 0.458386 Train acc: 0.815217 Valid acc: 0.842574\n",
      "Epoch: 8/10 Train loss: 0.393335 Valid loss: 0.458297 Train acc: 0.847826 Valid acc: 0.842593\n",
      "Epoch: 8/10 Train loss: 0.376734 Valid loss: 0.458215 Train acc: 0.847826 Valid acc: 0.842611\n",
      "Epoch: 8/10 Train loss: 0.463069 Valid loss: 0.458142 Train acc: 0.836957 Valid acc: 0.842628\n",
      "Epoch: 8/10 Train loss: 0.447386 Valid loss: 0.458075 Train acc: 0.847826 Valid acc: 0.842643\n",
      "Epoch: 8/10 Train loss: 0.384630 Valid loss: 0.458007 Train acc: 0.782609 Valid acc: 0.842659\n",
      "Epoch: 8/10 Train loss: 0.458862 Valid loss: 0.457940 Train acc: 0.793478 Valid acc: 0.842679\n",
      "Epoch: 8/10 Train loss: 0.386200 Valid loss: 0.457870 Train acc: 0.826087 Valid acc: 0.842699\n",
      "Epoch: 8/10 Train loss: 0.415075 Valid loss: 0.457797 Train acc: 0.815217 Valid acc: 0.842720\n",
      "Epoch: 8/10 Train loss: 0.438650 Valid loss: 0.457717 Train acc: 0.782609 Valid acc: 0.842739\n",
      "Epoch: 8/10 Train loss: 0.351611 Valid loss: 0.457629 Train acc: 0.836957 Valid acc: 0.842759\n",
      "Epoch: 8/10 Train loss: 0.408306 Valid loss: 0.457537 Train acc: 0.836957 Valid acc: 0.842779\n",
      "Epoch: 8/10 Train loss: 0.416945 Valid loss: 0.457442 Train acc: 0.815217 Valid acc: 0.842799\n",
      "Epoch: 8/10 Train loss: 0.487801 Valid loss: 0.457349 Train acc: 0.826087 Valid acc: 0.842819\n",
      "Epoch: 8/10 Train loss: 0.461914 Valid loss: 0.457260 Train acc: 0.826087 Valid acc: 0.842837\n",
      "Epoch: 8/10 Train loss: 0.353539 Valid loss: 0.457176 Train acc: 0.858696 Valid acc: 0.842857\n",
      "Epoch: 8/10 Train loss: 0.419921 Valid loss: 0.457098 Train acc: 0.836957 Valid acc: 0.842876\n",
      "Epoch: 8/10 Train loss: 0.380832 Valid loss: 0.457025 Train acc: 0.826087 Valid acc: 0.842895\n",
      "Epoch: 8/10 Train loss: 0.386779 Valid loss: 0.456960 Train acc: 0.826087 Valid acc: 0.842915\n",
      "Epoch: 8/10 Train loss: 0.394203 Valid loss: 0.456900 Train acc: 0.826087 Valid acc: 0.842935\n",
      "Epoch: 8/10 Train loss: 0.441749 Valid loss: 0.456845 Train acc: 0.804348 Valid acc: 0.842953\n",
      "Epoch: 8/10 Train loss: 0.444702 Valid loss: 0.456796 Train acc: 0.836957 Valid acc: 0.842972\n",
      "Epoch: 8/10 Train loss: 0.375903 Valid loss: 0.456753 Train acc: 0.858696 Valid acc: 0.842991\n",
      "Epoch: 8/10 Train loss: 0.396771 Valid loss: 0.456713 Train acc: 0.826087 Valid acc: 0.843008\n",
      "Epoch: 8/10 Train loss: 0.319513 Valid loss: 0.456673 Train acc: 0.836957 Valid acc: 0.843027\n",
      "Epoch: 8/10 Train loss: 0.386264 Valid loss: 0.456631 Train acc: 0.826087 Valid acc: 0.843044\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 8/10 Train loss: 0.414966 Valid loss: 0.456586 Train acc: 0.836957 Valid acc: 0.843064\n",
      "Epoch: 8/10 Train loss: 0.431029 Valid loss: 0.456538 Train acc: 0.847826 Valid acc: 0.843083\n",
      "Epoch: 8/10 Train loss: 0.375376 Valid loss: 0.456486 Train acc: 0.847826 Valid acc: 0.843103\n",
      "Epoch: 8/10 Train loss: 0.373154 Valid loss: 0.456430 Train acc: 0.847826 Valid acc: 0.843122\n",
      "Epoch: 8/10 Train loss: 0.420559 Valid loss: 0.456370 Train acc: 0.836957 Valid acc: 0.843140\n",
      "Epoch: 8/10 Train loss: 0.440293 Valid loss: 0.456308 Train acc: 0.826087 Valid acc: 0.843157\n",
      "Epoch: 8/10 Train loss: 0.381644 Valid loss: 0.456245 Train acc: 0.847826 Valid acc: 0.843175\n",
      "Epoch: 8/10 Train loss: 0.385106 Valid loss: 0.456181 Train acc: 0.826087 Valid acc: 0.843193\n",
      "Epoch: 9/10 Train loss: 0.365284 Valid loss: 0.456116 Train acc: 0.815217 Valid acc: 0.843210\n",
      "Epoch: 9/10 Train loss: 0.341016 Valid loss: 0.456047 Train acc: 0.836957 Valid acc: 0.843227\n",
      "Epoch: 9/10 Train loss: 0.354116 Valid loss: 0.455973 Train acc: 0.826087 Valid acc: 0.843243\n",
      "Epoch: 9/10 Train loss: 0.353412 Valid loss: 0.455894 Train acc: 0.858696 Valid acc: 0.843259\n",
      "Epoch: 9/10 Train loss: 0.364272 Valid loss: 0.455809 Train acc: 0.836957 Valid acc: 0.843275\n",
      "Epoch: 9/10 Train loss: 0.327412 Valid loss: 0.455720 Train acc: 0.847826 Valid acc: 0.843291\n",
      "Epoch: 9/10 Train loss: 0.307895 Valid loss: 0.455626 Train acc: 0.826087 Valid acc: 0.843308\n",
      "Epoch: 9/10 Train loss: 0.334162 Valid loss: 0.455528 Train acc: 0.880435 Valid acc: 0.843325\n",
      "Epoch: 9/10 Train loss: 0.389732 Valid loss: 0.455428 Train acc: 0.836957 Valid acc: 0.843342\n",
      "Epoch: 9/10 Train loss: 0.379686 Valid loss: 0.455328 Train acc: 0.836957 Valid acc: 0.843360\n",
      "Epoch: 9/10 Train loss: 0.350575 Valid loss: 0.455228 Train acc: 0.836957 Valid acc: 0.843375\n",
      "Epoch: 9/10 Train loss: 0.442239 Valid loss: 0.455130 Train acc: 0.826087 Valid acc: 0.843389\n",
      "Epoch: 9/10 Train loss: 0.298937 Valid loss: 0.455034 Train acc: 0.880435 Valid acc: 0.843401\n",
      "Epoch: 9/10 Train loss: 0.418769 Valid loss: 0.454942 Train acc: 0.815217 Valid acc: 0.843412\n",
      "Epoch: 9/10 Train loss: 0.331167 Valid loss: 0.454853 Train acc: 0.891304 Valid acc: 0.843422\n",
      "Epoch: 9/10 Train loss: 0.335347 Valid loss: 0.454768 Train acc: 0.826087 Valid acc: 0.843431\n",
      "Epoch: 9/10 Train loss: 0.330302 Valid loss: 0.454684 Train acc: 0.869565 Valid acc: 0.843442\n",
      "Epoch: 9/10 Train loss: 0.451655 Valid loss: 0.454602 Train acc: 0.836957 Valid acc: 0.843452\n",
      "Epoch: 9/10 Train loss: 0.384818 Valid loss: 0.454519 Train acc: 0.858696 Valid acc: 0.843463\n",
      "Epoch: 9/10 Train loss: 0.376797 Valid loss: 0.454435 Train acc: 0.826087 Valid acc: 0.843472\n",
      "Epoch: 9/10 Train loss: 0.295092 Valid loss: 0.454348 Train acc: 0.902174 Valid acc: 0.843483\n",
      "Epoch: 9/10 Train loss: 0.238088 Valid loss: 0.454256 Train acc: 0.913043 Valid acc: 0.843494\n",
      "Epoch: 9/10 Train loss: 0.198001 Valid loss: 0.454159 Train acc: 0.945652 Valid acc: 0.843509\n",
      "Epoch: 9/10 Train loss: 0.261724 Valid loss: 0.454055 Train acc: 0.934783 Valid acc: 0.843527\n",
      "Epoch: 9/10 Train loss: 0.385616 Valid loss: 0.453945 Train acc: 0.847826 Valid acc: 0.843546\n",
      "Epoch: 9/10 Train loss: 0.344079 Valid loss: 0.453832 Train acc: 0.847826 Valid acc: 0.843568\n",
      "Epoch: 9/10 Train loss: 0.181456 Valid loss: 0.453715 Train acc: 0.945652 Valid acc: 0.843592\n",
      "Epoch: 9/10 Train loss: 0.258460 Valid loss: 0.453595 Train acc: 0.913043 Valid acc: 0.843617\n",
      "Epoch: 9/10 Train loss: 0.336414 Valid loss: 0.453477 Train acc: 0.869565 Valid acc: 0.843643\n",
      "Epoch: 9/10 Train loss: 0.349373 Valid loss: 0.453360 Train acc: 0.913043 Valid acc: 0.843664\n",
      "Epoch: 9/10 Train loss: 0.276758 Valid loss: 0.453246 Train acc: 0.913043 Valid acc: 0.843686\n",
      "Epoch: 9/10 Train loss: 0.303739 Valid loss: 0.453136 Train acc: 0.923913 Valid acc: 0.843703\n",
      "Epoch: 9/10 Train loss: 0.231231 Valid loss: 0.453030 Train acc: 0.956522 Valid acc: 0.843717\n",
      "Epoch: 9/10 Train loss: 0.218654 Valid loss: 0.452924 Train acc: 0.880435 Valid acc: 0.843731\n",
      "Epoch: 9/10 Train loss: 0.268080 Valid loss: 0.452819 Train acc: 0.880435 Valid acc: 0.843746\n",
      "Epoch: 9/10 Train loss: 0.212812 Valid loss: 0.452711 Train acc: 0.923913 Valid acc: 0.843761\n",
      "Epoch: 9/10 Train loss: 0.247803 Valid loss: 0.452600 Train acc: 0.913043 Valid acc: 0.843778\n",
      "Epoch: 9/10 Train loss: 0.369470 Valid loss: 0.452487 Train acc: 0.858696 Valid acc: 0.843795\n",
      "Epoch: 9/10 Train loss: 0.376790 Valid loss: 0.452375 Train acc: 0.847826 Valid acc: 0.843811\n",
      "Epoch: 9/10 Train loss: 0.542724 Valid loss: 0.452269 Train acc: 0.847826 Valid acc: 0.843828\n",
      "Epoch: 9/10 Train loss: 0.329487 Valid loss: 0.452169 Train acc: 0.869565 Valid acc: 0.843844\n",
      "Epoch: 9/10 Train loss: 0.282225 Valid loss: 0.452076 Train acc: 0.880435 Valid acc: 0.843861\n",
      "Epoch: 9/10 Train loss: 0.298119 Valid loss: 0.451989 Train acc: 0.869565 Valid acc: 0.843876\n",
      "Epoch: 9/10 Train loss: 0.261177 Valid loss: 0.451903 Train acc: 0.934783 Valid acc: 0.843890\n",
      "Epoch: 9/10 Train loss: 0.266093 Valid loss: 0.451817 Train acc: 0.902174 Valid acc: 0.843906\n",
      "Epoch: 9/10 Train loss: 0.349781 Valid loss: 0.451727 Train acc: 0.858696 Valid acc: 0.843925\n",
      "Epoch: 9/10 Train loss: 0.320118 Valid loss: 0.451632 Train acc: 0.880435 Valid acc: 0.843942\n",
      "Epoch: 9/10 Train loss: 0.315122 Valid loss: 0.451534 Train acc: 0.902174 Valid acc: 0.843958\n",
      "Epoch: 9/10 Train loss: 0.301535 Valid loss: 0.451431 Train acc: 0.858696 Valid acc: 0.843975\n",
      "Epoch: 9/10 Train loss: 0.329907 Valid loss: 0.451326 Train acc: 0.836957 Valid acc: 0.843991\n",
      "Epoch: 9/10 Train loss: 0.291832 Valid loss: 0.451221 Train acc: 0.847826 Valid acc: 0.844007\n",
      "Epoch: 9/10 Train loss: 0.351253 Valid loss: 0.451117 Train acc: 0.869565 Valid acc: 0.844023\n",
      "Epoch: 9/10 Train loss: 0.406442 Valid loss: 0.451015 Train acc: 0.815217 Valid acc: 0.844037\n",
      "Epoch: 9/10 Train loss: 0.294526 Valid loss: 0.450914 Train acc: 0.902174 Valid acc: 0.844050\n",
      "Epoch: 9/10 Train loss: 0.247789 Valid loss: 0.450813 Train acc: 0.891304 Valid acc: 0.844062\n",
      "Epoch: 9/10 Train loss: 0.227554 Valid loss: 0.450711 Train acc: 0.934783 Valid acc: 0.844074\n",
      "Epoch: 9/10 Train loss: 0.318216 Valid loss: 0.450609 Train acc: 0.880435 Valid acc: 0.844088\n",
      "Epoch: 9/10 Train loss: 0.438344 Valid loss: 0.450505 Train acc: 0.804348 Valid acc: 0.844102\n",
      "Epoch: 9/10 Train loss: 0.273178 Valid loss: 0.450402 Train acc: 0.880435 Valid acc: 0.844118\n",
      "Epoch: 9/10 Train loss: 0.279125 Valid loss: 0.450298 Train acc: 0.913043 Valid acc: 0.844136\n",
      "Epoch: 9/10 Train loss: 0.389215 Valid loss: 0.450193 Train acc: 0.815217 Valid acc: 0.844155\n",
      "Epoch: 9/10 Train loss: 0.363142 Valid loss: 0.450088 Train acc: 0.858696 Valid acc: 0.844172\n",
      "Epoch: 9/10 Train loss: 0.417971 Valid loss: 0.449984 Train acc: 0.836957 Valid acc: 0.844189\n",
      "Epoch: 9/10 Train loss: 0.357534 Valid loss: 0.449881 Train acc: 0.804348 Valid acc: 0.844207\n",
      "Epoch: 9/10 Train loss: 0.349756 Valid loss: 0.449780 Train acc: 0.858696 Valid acc: 0.844225\n",
      "Epoch: 9/10 Train loss: 0.479134 Valid loss: 0.449681 Train acc: 0.804348 Valid acc: 0.844244\n",
      "Epoch: 9/10 Train loss: 0.462409 Valid loss: 0.449588 Train acc: 0.836957 Valid acc: 0.844262\n",
      "Epoch: 9/10 Train loss: 0.390129 Valid loss: 0.449500 Train acc: 0.847826 Valid acc: 0.844280\n",
      "Epoch: 9/10 Train loss: 0.372452 Valid loss: 0.449415 Train acc: 0.826087 Valid acc: 0.844299\n",
      "Epoch: 9/10 Train loss: 0.495695 Valid loss: 0.449337 Train acc: 0.771739 Valid acc: 0.844316\n",
      "Epoch: 9/10 Train loss: 0.412202 Valid loss: 0.449263 Train acc: 0.826087 Valid acc: 0.844333\n",
      "Epoch: 9/10 Train loss: 0.470854 Valid loss: 0.449190 Train acc: 0.804348 Valid acc: 0.844352\n",
      "Epoch: 9/10 Train loss: 0.430793 Valid loss: 0.449117 Train acc: 0.815217 Valid acc: 0.844370\n",
      "Epoch: 9/10 Train loss: 0.392846 Valid loss: 0.449044 Train acc: 0.836957 Valid acc: 0.844388\n",
      "Epoch: 9/10 Train loss: 0.391167 Valid loss: 0.448970 Train acc: 0.836957 Valid acc: 0.844406\n",
      "Epoch: 9/10 Train loss: 0.401027 Valid loss: 0.448895 Train acc: 0.815217 Valid acc: 0.844426\n",
      "Epoch: 9/10 Train loss: 0.371855 Valid loss: 0.448817 Train acc: 0.847826 Valid acc: 0.844447\n",
      "Epoch: 9/10 Train loss: 0.474763 Valid loss: 0.448740 Train acc: 0.836957 Valid acc: 0.844465\n",
      "Epoch: 9/10 Train loss: 0.405995 Valid loss: 0.448663 Train acc: 0.836957 Valid acc: 0.844482\n",
      "Epoch: 9/10 Train loss: 0.525500 Valid loss: 0.448589 Train acc: 0.804348 Valid acc: 0.844499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 9/10 Train loss: 0.359160 Valid loss: 0.448519 Train acc: 0.836957 Valid acc: 0.844516\n",
      "Epoch: 9/10 Train loss: 0.417108 Valid loss: 0.448453 Train acc: 0.836957 Valid acc: 0.844531\n",
      "Epoch: 9/10 Train loss: 0.444236 Valid loss: 0.448391 Train acc: 0.826087 Valid acc: 0.844545\n",
      "Epoch: 9/10 Train loss: 0.357423 Valid loss: 0.448334 Train acc: 0.826087 Valid acc: 0.844560\n",
      "Epoch: 9/10 Train loss: 0.382698 Valid loss: 0.448281 Train acc: 0.815217 Valid acc: 0.844574\n",
      "Epoch: 9/10 Train loss: 0.433426 Valid loss: 0.448234 Train acc: 0.836957 Valid acc: 0.844590\n",
      "Epoch: 9/10 Train loss: 0.407972 Valid loss: 0.448188 Train acc: 0.826087 Valid acc: 0.844608\n",
      "Epoch: 9/10 Train loss: 0.421367 Valid loss: 0.448143 Train acc: 0.836957 Valid acc: 0.844626\n",
      "Epoch: 9/10 Train loss: 0.389189 Valid loss: 0.448101 Train acc: 0.869565 Valid acc: 0.844643\n",
      "Epoch: 9/10 Train loss: 0.388680 Valid loss: 0.448057 Train acc: 0.847826 Valid acc: 0.844661\n",
      "Epoch: 9/10 Train loss: 0.320153 Valid loss: 0.448011 Train acc: 0.847826 Valid acc: 0.844677\n",
      "Epoch: 9/10 Train loss: 0.481698 Valid loss: 0.447963 Train acc: 0.826087 Valid acc: 0.844693\n",
      "Epoch: 9/10 Train loss: 0.393464 Valid loss: 0.447912 Train acc: 0.847826 Valid acc: 0.844709\n",
      "Epoch: 9/10 Train loss: 0.369312 Valid loss: 0.447860 Train acc: 0.858696 Valid acc: 0.844724\n",
      "Epoch: 9/10 Train loss: 0.391505 Valid loss: 0.447804 Train acc: 0.836957 Valid acc: 0.844741\n",
      "Epoch: 9/10 Train loss: 0.373230 Valid loss: 0.447746 Train acc: 0.836957 Valid acc: 0.844758\n",
      "Epoch: 9/10 Train loss: 0.438774 Valid loss: 0.447686 Train acc: 0.836957 Valid acc: 0.844774\n",
      "Epoch: 9/10 Train loss: 0.401258 Valid loss: 0.447625 Train acc: 0.836957 Valid acc: 0.844790\n",
      "Epoch: 9/10 Train loss: 0.423376 Valid loss: 0.447565 Train acc: 0.826087 Valid acc: 0.844807\n",
      "Epoch: 9/10 Train loss: 0.383568 Valid loss: 0.447506 Train acc: 0.826087 Valid acc: 0.844825\n",
      "Epoch: 10/10 Train loss: 0.355404 Valid loss: 0.447448 Train acc: 0.836957 Valid acc: 0.844843\n",
      "Epoch: 10/10 Train loss: 0.300318 Valid loss: 0.447387 Train acc: 0.869565 Valid acc: 0.844859\n",
      "Epoch: 10/10 Train loss: 0.339392 Valid loss: 0.447322 Train acc: 0.836957 Valid acc: 0.844874\n",
      "Epoch: 10/10 Train loss: 0.365247 Valid loss: 0.447253 Train acc: 0.869565 Valid acc: 0.844889\n",
      "Epoch: 10/10 Train loss: 0.344456 Valid loss: 0.447179 Train acc: 0.836957 Valid acc: 0.844903\n",
      "Epoch: 10/10 Train loss: 0.330011 Valid loss: 0.447099 Train acc: 0.880435 Valid acc: 0.844917\n",
      "Epoch: 10/10 Train loss: 0.304838 Valid loss: 0.447015 Train acc: 0.847826 Valid acc: 0.844930\n",
      "Epoch: 10/10 Train loss: 0.292946 Valid loss: 0.446927 Train acc: 0.880435 Valid acc: 0.844944\n",
      "Epoch: 10/10 Train loss: 0.357804 Valid loss: 0.446837 Train acc: 0.847826 Valid acc: 0.844958\n",
      "Epoch: 10/10 Train loss: 0.338189 Valid loss: 0.446746 Train acc: 0.880435 Valid acc: 0.844972\n",
      "Epoch: 10/10 Train loss: 0.301492 Valid loss: 0.446654 Train acc: 0.858696 Valid acc: 0.844986\n",
      "Epoch: 10/10 Train loss: 0.372322 Valid loss: 0.446565 Train acc: 0.836957 Valid acc: 0.845001\n",
      "Epoch: 10/10 Train loss: 0.284867 Valid loss: 0.446479 Train acc: 0.869565 Valid acc: 0.845015\n",
      "Epoch: 10/10 Train loss: 0.438230 Valid loss: 0.446397 Train acc: 0.815217 Valid acc: 0.845025\n",
      "Epoch: 10/10 Train loss: 0.320994 Valid loss: 0.446322 Train acc: 0.891304 Valid acc: 0.845028\n",
      "Epoch: 10/10 Train loss: 0.378494 Valid loss: 0.446255 Train acc: 0.793478 Valid acc: 0.845024\n",
      "Epoch: 10/10 Train loss: 0.274145 Valid loss: 0.446194 Train acc: 0.891304 Valid acc: 0.845014\n",
      "Epoch: 10/10 Train loss: 0.459003 Valid loss: 0.446136 Train acc: 0.858696 Valid acc: 0.844998\n",
      "Epoch: 10/10 Train loss: 0.324170 Valid loss: 0.446079 Train acc: 0.826087 Valid acc: 0.844981\n",
      "Epoch: 10/10 Train loss: 0.350441 Valid loss: 0.446019 Train acc: 0.826087 Valid acc: 0.844970\n",
      "Epoch: 10/10 Train loss: 0.224146 Valid loss: 0.445949 Train acc: 0.913043 Valid acc: 0.844970\n",
      "Epoch: 10/10 Train loss: 0.279704 Valid loss: 0.445869 Train acc: 0.869565 Valid acc: 0.844980\n",
      "Epoch: 10/10 Train loss: 0.132649 Valid loss: 0.445782 Train acc: 0.967391 Valid acc: 0.844998\n",
      "Epoch: 10/10 Train loss: 0.148148 Valid loss: 0.445689 Train acc: 0.945652 Valid acc: 0.845015\n",
      "Epoch: 10/10 Train loss: 0.349361 Valid loss: 0.445592 Train acc: 0.858696 Valid acc: 0.845034\n",
      "Epoch: 10/10 Train loss: 0.236464 Valid loss: 0.445493 Train acc: 0.923913 Valid acc: 0.845056\n",
      "Epoch: 10/10 Train loss: 0.145036 Valid loss: 0.445391 Train acc: 0.934783 Valid acc: 0.845078\n",
      "Epoch: 10/10 Train loss: 0.209639 Valid loss: 0.445288 Train acc: 0.880435 Valid acc: 0.845100\n",
      "Epoch: 10/10 Train loss: 0.369957 Valid loss: 0.445184 Train acc: 0.869565 Valid acc: 0.845123\n",
      "Epoch: 10/10 Train loss: 0.343061 Valid loss: 0.445080 Train acc: 0.902174 Valid acc: 0.845145\n",
      "Epoch: 10/10 Train loss: 0.272264 Valid loss: 0.444977 Train acc: 0.913043 Valid acc: 0.845164\n",
      "Epoch: 10/10 Train loss: 0.286074 Valid loss: 0.444879 Train acc: 0.902174 Valid acc: 0.845184\n",
      "Epoch: 10/10 Train loss: 0.240248 Valid loss: 0.444785 Train acc: 0.956522 Valid acc: 0.845200\n",
      "Epoch: 10/10 Train loss: 0.192214 Valid loss: 0.444694 Train acc: 0.913043 Valid acc: 0.845214\n",
      "Epoch: 10/10 Train loss: 0.329834 Valid loss: 0.444607 Train acc: 0.836957 Valid acc: 0.845225\n",
      "Epoch: 10/10 Train loss: 0.248339 Valid loss: 0.444523 Train acc: 0.923913 Valid acc: 0.845235\n",
      "Epoch: 10/10 Train loss: 0.205063 Valid loss: 0.444438 Train acc: 0.934783 Valid acc: 0.845244\n",
      "Epoch: 10/10 Train loss: 0.248274 Valid loss: 0.444350 Train acc: 0.836957 Valid acc: 0.845254\n",
      "Epoch: 10/10 Train loss: 0.353560 Valid loss: 0.444260 Train acc: 0.902174 Valid acc: 0.845266\n",
      "Epoch: 10/10 Train loss: 0.400865 Valid loss: 0.444164 Train acc: 0.869565 Valid acc: 0.845279\n",
      "Epoch: 10/10 Train loss: 0.278172 Valid loss: 0.444063 Train acc: 0.902174 Valid acc: 0.845295\n",
      "Epoch: 10/10 Train loss: 0.252053 Valid loss: 0.443959 Train acc: 0.880435 Valid acc: 0.845313\n",
      "Epoch: 10/10 Train loss: 0.258909 Valid loss: 0.443853 Train acc: 0.913043 Valid acc: 0.845331\n",
      "Epoch: 10/10 Train loss: 0.204407 Valid loss: 0.443747 Train acc: 0.913043 Valid acc: 0.845348\n",
      "Epoch: 10/10 Train loss: 0.290363 Valid loss: 0.443642 Train acc: 0.880435 Valid acc: 0.845366\n",
      "Epoch: 10/10 Train loss: 0.348574 Valid loss: 0.443537 Train acc: 0.891304 Valid acc: 0.845386\n",
      "Epoch: 10/10 Train loss: 0.438098 Valid loss: 0.443436 Train acc: 0.836957 Valid acc: 0.845405\n",
      "Epoch: 10/10 Train loss: 0.308620 Valid loss: 0.443338 Train acc: 0.880435 Valid acc: 0.845422\n",
      "Epoch: 10/10 Train loss: 0.240388 Valid loss: 0.443245 Train acc: 0.923913 Valid acc: 0.845440\n",
      "Epoch: 10/10 Train loss: 0.336262 Valid loss: 0.443158 Train acc: 0.891304 Valid acc: 0.845455\n",
      "Epoch: 10/10 Train loss: 0.339261 Valid loss: 0.443077 Train acc: 0.858696 Valid acc: 0.845470\n",
      "Epoch: 10/10 Train loss: 0.330295 Valid loss: 0.443003 Train acc: 0.858696 Valid acc: 0.845482\n",
      "Epoch: 10/10 Train loss: 0.340793 Valid loss: 0.442932 Train acc: 0.891304 Valid acc: 0.845495\n",
      "Epoch: 10/10 Train loss: 0.368904 Valid loss: 0.442863 Train acc: 0.880435 Valid acc: 0.845507\n",
      "Epoch: 10/10 Train loss: 0.349147 Valid loss: 0.442793 Train acc: 0.869565 Valid acc: 0.845520\n",
      "Epoch: 10/10 Train loss: 0.251815 Valid loss: 0.442720 Train acc: 0.913043 Valid acc: 0.845534\n",
      "Epoch: 10/10 Train loss: 0.307410 Valid loss: 0.442644 Train acc: 0.891304 Valid acc: 0.845551\n",
      "Epoch: 10/10 Train loss: 0.425753 Valid loss: 0.442565 Train acc: 0.847826 Valid acc: 0.845570\n",
      "Epoch: 10/10 Train loss: 0.283508 Valid loss: 0.442483 Train acc: 0.902174 Valid acc: 0.845590\n",
      "Epoch: 10/10 Train loss: 0.291346 Valid loss: 0.442398 Train acc: 0.913043 Valid acc: 0.845611\n",
      "Epoch: 10/10 Train loss: 0.387602 Valid loss: 0.442311 Train acc: 0.826087 Valid acc: 0.845631\n",
      "Epoch: 10/10 Train loss: 0.348708 Valid loss: 0.442224 Train acc: 0.836957 Valid acc: 0.845652\n",
      "Epoch: 10/10 Train loss: 0.419947 Valid loss: 0.442139 Train acc: 0.847826 Valid acc: 0.845673\n",
      "Epoch: 10/10 Train loss: 0.382918 Valid loss: 0.442056 Train acc: 0.836957 Valid acc: 0.845691\n",
      "Epoch: 10/10 Train loss: 0.370130 Valid loss: 0.441978 Train acc: 0.826087 Valid acc: 0.845710\n",
      "Epoch: 10/10 Train loss: 0.424457 Valid loss: 0.441905 Train acc: 0.793478 Valid acc: 0.845727\n",
      "Epoch: 10/10 Train loss: 0.444264 Valid loss: 0.441837 Train acc: 0.847826 Valid acc: 0.845743\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 10/10 Train loss: 0.401687 Valid loss: 0.441776 Train acc: 0.793478 Valid acc: 0.845758\n",
      "Epoch: 10/10 Train loss: 0.408318 Valid loss: 0.441721 Train acc: 0.847826 Valid acc: 0.845771\n",
      "Epoch: 10/10 Train loss: 0.496771 Valid loss: 0.441672 Train acc: 0.836957 Valid acc: 0.845782\n",
      "Epoch: 10/10 Train loss: 0.433404 Valid loss: 0.441628 Train acc: 0.836957 Valid acc: 0.845795\n",
      "Epoch: 10/10 Train loss: 0.445770 Valid loss: 0.441585 Train acc: 0.826087 Valid acc: 0.845810\n",
      "Epoch: 10/10 Train loss: 0.450014 Valid loss: 0.441542 Train acc: 0.826087 Valid acc: 0.845827\n",
      "Epoch: 10/10 Train loss: 0.365838 Valid loss: 0.441499 Train acc: 0.815217 Valid acc: 0.845845\n",
      "Epoch: 10/10 Train loss: 0.450890 Valid loss: 0.441453 Train acc: 0.826087 Valid acc: 0.845865\n",
      "Epoch: 10/10 Train loss: 0.336351 Valid loss: 0.441402 Train acc: 0.836957 Valid acc: 0.845885\n",
      "Epoch: 10/10 Train loss: 0.328335 Valid loss: 0.441346 Train acc: 0.858696 Valid acc: 0.845903\n",
      "Epoch: 10/10 Train loss: 0.381882 Valid loss: 0.441285 Train acc: 0.847826 Valid acc: 0.845919\n",
      "Epoch: 10/10 Train loss: 0.404606 Valid loss: 0.441222 Train acc: 0.826087 Valid acc: 0.845935\n",
      "Epoch: 10/10 Train loss: 0.490708 Valid loss: 0.441157 Train acc: 0.826087 Valid acc: 0.845949\n",
      "Epoch: 10/10 Train loss: 0.433958 Valid loss: 0.441094 Train acc: 0.826087 Valid acc: 0.845963\n",
      "Epoch: 10/10 Train loss: 0.341876 Valid loss: 0.441034 Train acc: 0.858696 Valid acc: 0.845976\n",
      "Epoch: 10/10 Train loss: 0.403008 Valid loss: 0.440978 Train acc: 0.836957 Valid acc: 0.845989\n",
      "Epoch: 10/10 Train loss: 0.362919 Valid loss: 0.440928 Train acc: 0.847826 Valid acc: 0.846004\n",
      "Epoch: 10/10 Train loss: 0.431443 Valid loss: 0.440882 Train acc: 0.836957 Valid acc: 0.846021\n",
      "Epoch: 10/10 Train loss: 0.442475 Valid loss: 0.440842 Train acc: 0.847826 Valid acc: 0.846038\n",
      "Epoch: 10/10 Train loss: 0.424805 Valid loss: 0.440809 Train acc: 0.826087 Valid acc: 0.846055\n",
      "Epoch: 10/10 Train loss: 0.482064 Valid loss: 0.440780 Train acc: 0.804348 Valid acc: 0.846070\n",
      "Epoch: 10/10 Train loss: 0.352245 Valid loss: 0.440753 Train acc: 0.858696 Valid acc: 0.846085\n",
      "Epoch: 10/10 Train loss: 0.371514 Valid loss: 0.440725 Train acc: 0.836957 Valid acc: 0.846100\n",
      "Epoch: 10/10 Train loss: 0.361582 Valid loss: 0.440694 Train acc: 0.815217 Valid acc: 0.846116\n",
      "Epoch: 10/10 Train loss: 0.397390 Valid loss: 0.440661 Train acc: 0.836957 Valid acc: 0.846132\n",
      "Epoch: 10/10 Train loss: 0.392162 Valid loss: 0.440624 Train acc: 0.836957 Valid acc: 0.846149\n",
      "Epoch: 10/10 Train loss: 0.415074 Valid loss: 0.440584 Train acc: 0.836957 Valid acc: 0.846164\n",
      "Epoch: 10/10 Train loss: 0.457814 Valid loss: 0.440541 Train acc: 0.826087 Valid acc: 0.846179\n",
      "Epoch: 10/10 Train loss: 0.378528 Valid loss: 0.440494 Train acc: 0.826087 Valid acc: 0.846194\n",
      "Epoch: 10/10 Train loss: 0.359945 Valid loss: 0.440444 Train acc: 0.836957 Valid acc: 0.846210\n",
      "Epoch: 10/10 Train loss: 0.403915 Valid loss: 0.440392 Train acc: 0.815217 Valid acc: 0.846224\n",
      "Epoch: 10/10 Train loss: 0.409291 Valid loss: 0.440339 Train acc: 0.836957 Valid acc: 0.846239\n",
      "Epoch: 10/10 Train loss: 0.381728 Valid loss: 0.440285 Train acc: 0.847826 Valid acc: 0.846253\n",
      "Epoch: 10/10 Test loss: 0.407054 Test acc: 0.854419\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "# Plotting the acc and loss curve\n",
    "train_acc = []\n",
    "train_loss = []\n",
    "\n",
    "valid_acc = []\n",
    "valid_loss = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initalize session global variables just in the case they are initialized.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "       \n",
    "        # Loop over batches\n",
    "        for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_:x, labels_:y, keep_prob_: keep_prob, learning_rate_:learning_rate}\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################################ Validation\n",
    "            # Initialize \n",
    "            loss_v_batch, acc_v_batch = [], []\n",
    "\n",
    "            # Loop over batches\n",
    "            for x_v, y_v in get_batches(X_valid_norm, Y_valid_onehot, batch_size):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_:x_v, labels_:y_v, keep_prob_: 1.0}\n",
    "                loss_v, acc_v = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                \n",
    "                acc_v_batch.append(acc_v)\n",
    "                loss_v_batch.append(loss_v)\n",
    "                \n",
    "            valid_acc.append(np.mean(acc_v_batch))\n",
    "            valid_loss.append(np.mean(loss_v_batch))\n",
    "            \n",
    "            # Print info\n",
    "            print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "                  \"Train loss: {:6f}\".format(loss),\n",
    "                  \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "                  \"Train acc: {:6f}\".format(acc),\n",
    "                  \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "            \n",
    "    ################################ Test\n",
    "    # Initialize \n",
    "    acc_batch, loss_batch = [], []\n",
    "\n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(X_test_norm, Y_test_onehot, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_:x, labels_:y, keep_prob_:1.0}\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print info\n",
    "    print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "          \"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD8CAYAAABXe05zAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9cb433df28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n67gAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9c50020f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
