{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3072, 13, 1380) float64\n",
      "(1380, 3072, 13)\n",
      "(1380, 3072, 13) float64 (966, 3072, 13) float64 (414, 3072, 13) float64\n",
      "(966, 3072, 13) float64 (677, 3072, 13) float64 (289, 3072, 13) float64\n"
     ]
    }
   ],
   "source": [
    "# Input data\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "new_executive = spio.loadmat(file_name='../data/bci_EEG_data-new/new_executive.mat')\n",
    "new_executive_data = new_executive['new_executive']\n",
    "print(new_executive_data.shape, new_executive_data.dtype)\n",
    "\n",
    "new_executive_data_transposed = new_executive_data.transpose(2, 0, 1)\n",
    "print(new_executive_data_transposed.shape)\n",
    "\n",
    "# Deviding the input data into train and validation\n",
    "# For creating the training and testing set, 30% percent of each subject is considered as test and\n",
    "# 70% of each subject is conidered as training.\n",
    "length = int(new_executive_data_transposed.shape[0] * 0.30)\n",
    "# length\n",
    "\n",
    "train_data_all = new_executive_data_transposed[:-length]\n",
    "test_data = new_executive_data_transposed[-length:]\n",
    "\n",
    "print(new_executive_data_transposed.shape, new_executive_data_transposed.dtype, \n",
    " train_data_all.shape, train_data_all.dtype, \n",
    " test_data.shape, test_data.dtype)\n",
    "\n",
    "# 30% of the total training data is validation,\n",
    "# 70% of the total training data is training\n",
    "# This is applied to every single subject data.\n",
    "length2 = int(train_data_all.shape[0] * 0.30)\n",
    "# length2\n",
    "\n",
    "train_data = train_data_all[:-length2]\n",
    "valid_data = train_data_all[-length2:]\n",
    "\n",
    "print(train_data_all.shape, train_data_all.dtype, \n",
    " train_data.shape, train_data.dtype, \n",
    " valid_data.shape, valid_data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1380, 1) uint16 [3]\n",
      "(1380, 1) uint16 (414, 1) uint16 (966, 1) uint16\n",
      "(677, 1) (289, 1)\n"
     ]
    }
   ],
   "source": [
    "# Output data: class labels\n",
    "new_executive_label = spio.loadmat(file_name='../data/bci_EEG_data-new/new_executive_label.mat')\n",
    "# new_executive_label.keys()\n",
    "new_executive_label_all = new_executive_label['new_executive_label']\n",
    "print(new_executive_label_all.shape, new_executive_label_all.dtype, \n",
    "      new_executive_label_all.max(axis=0))\n",
    "\n",
    "label_train_all = new_executive_label_all[:-length]\n",
    "label_test = new_executive_label_all[-length:]\n",
    "\n",
    "print(new_executive_label_all.shape, new_executive_label_all.dtype,\n",
    " label_test.shape, label_test.dtype, \n",
    " label_train_all.shape, label_train_all.dtype)\n",
    "\n",
    "label_train = label_train_all[:-length2]\n",
    "label_valid = label_train_all[-length2:]\n",
    "print(label_train.shape, label_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 3072, 13) float64 (289, 3072, 13) float64 (414, 3072, 13) float64\n"
     ]
    }
   ],
   "source": [
    "# # Normalizing input data\n",
    "# def normalize(inputs, inputs_all):\n",
    "#     return (inputs - inputs_all.mean(axis=0)[None,:,:]) / inputs_all.std(axis=0)[None,:,:]\n",
    "# Yalda suggested this normalization.\n",
    "def normalize(inputs):\n",
    "    return (inputs - inputs.mean(axis=0)[None,:,:]) / inputs.std(axis=0)[None,:,:]\n",
    "\n",
    "# onehot vectorizing output labels\n",
    "def one_hot(labels, n_class):\n",
    "    \"\"\" One-hot encoding \"\"\"\n",
    "    expansion = np.eye(n_class)\n",
    "    y = expansion[:, labels-1].T\n",
    "    assert y.shape[1] == n_class, \"Wrong number of labels!\"\n",
    "\n",
    "    return y\n",
    "\n",
    "# get minibatches for learning\n",
    "def get_batches(X, y, batch_size):\n",
    "    \"\"\" Return a generator for batches \"\"\"\n",
    "    n_batches = len(X) // batch_size\n",
    "    X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over batches and yield\n",
    "    for b in range(0, len(X), batch_size):\n",
    "        yield X[b:b+batch_size], y[b:b+batch_size]\n",
    "\n",
    "# Standardize/normalize train and test\n",
    "# X_train_norm_all = normalize(inputs=FacesDataTrain, inputs_all=FacesDataAll)\n",
    "X_train_norm = normalize(inputs=train_data)\n",
    "X_valid_norm = normalize(inputs=valid_data)\n",
    "X_test_norm = normalize(inputs=test_data)\n",
    "\n",
    "print(X_train_norm.shape, X_train_norm.dtype, \n",
    "X_valid_norm.shape, X_valid_norm.dtype,\n",
    "X_test_norm.shape, X_test_norm.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch_size, seq_len, n_channels 67 3072 13\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'new_executive_label_all' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-751f64ba760c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Output labels\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m# n_classes = int(new_executive_label_all.max(axis=0) + 1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m \u001b[0mn_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_executive_label_all\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'n_classes'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'new_executive_label_all' is not defined"
     ]
    }
   ],
   "source": [
    "### Hyperparameters\n",
    "\n",
    "# Input data\n",
    "batch_size = X_train_norm.shape[0]// 10 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "\n",
    "# Output labels\n",
    "# n_classes = int(new_executive_label_all.max(axis=0) + 1)\n",
    "n_classes = int(new_executive_label_all.max(axis=0))\n",
    "print('n_classes', n_classes)\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.001 #1e-3\n",
    "epochs = 1000 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(677, 3) (289, 3) (414, 3) (677, 3072, 13) (289, 3072, 13) (414, 3072, 13)\n",
      "float64 float64 float64 float64 float64 float64\n"
     ]
    }
   ],
   "source": [
    "Y_train = np.array(label_train, dtype=int).reshape(-1)\n",
    "Y_valid = np.array(label_valid, dtype=int).reshape(-1)\n",
    "Y_test = np.array(label_test, dtype=int).reshape(-1)\n",
    "\n",
    "Y_train_onehot = one_hot(labels=Y_train, n_class=n_classes)\n",
    "Y_valid_onehot = one_hot(labels=Y_valid, n_class=n_classes)\n",
    "Y_test_onehot = one_hot(labels=Y_test, n_class=n_classes)\n",
    "\n",
    "print(Y_train_onehot.shape, Y_valid_onehot.shape, Y_test_onehot.shape, \n",
    " X_train_norm.shape, X_valid_norm.shape, X_test_norm.shape)\n",
    "\n",
    "print(Y_train_onehot.dtype, Y_valid_onehot.dtype, Y_test_onehot.dtype,\n",
    " X_train_norm.dtype, X_valid_norm.dtype, X_test_norm.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Buffering/ placeholders to transfer the data from py to tf\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')# Construct the LSTM inputs and LSTM cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 3072, 13) (?, 1534, 26)\n",
      "(?, 1534, 26) (?, 511, 26)\n",
      "(?, 511, 26) (?, 254, 52)\n",
      "(?, 254, 52) (?, 25, 52)\n",
      "(?, 25, 52) (?, 1300) (?, 2600)\n",
      "(?, 2600) (?, 3)\n"
     ]
    }
   ],
   "source": [
    "# Forward pass: Convolutional Layers, FC Layer, and Output layer\n",
    "# 677, 3072, 13\n",
    "# (batch, 3072, 13) --> (batch, 1534, 26)\n",
    "# (3072 - 6 + 0)/2 + 1 = (3066/2)+1= 1533 +1 = 1534\n",
    "# 2/6 with strides/kernel_size is 33.333% non-overlap/diff region and \n",
    "# 66.666% overlapping window/ common region\n",
    "# tf.layers.conv2d (actually _Conv) uses tf.nn.convolution as the backend. \n",
    "# I would use tf.nn.conv2d when loading a pretrained model, \n",
    "# and tf.layers.conv2d for a model trained from scratch.\n",
    "in_conv = inputs_\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=26, kernel_size=6, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(in_conv.shape, out_conv.shape)\n",
    "\n",
    "# To reduce the size for memory efficiency & equivariancy/invariency/ minicolumns\n",
    "# (batch, 1534, 26) --> (batch, 511, 26)\n",
    "# (1534 - 4 + 0)/3 + 1 = (1530/3)+1= 510 +1 = 511\n",
    "# 3/4 with strides/kernel_size is \n",
    "# 75% non-overlap/diff region and \n",
    "# 25% overlapping window/ common region\n",
    "in_pool = out_conv\n",
    "out_pool = tf.layers.max_pooling1d(inputs=in_pool, pool_size=4, strides=3, padding='valid')\n",
    "print(in_pool.shape, out_pool.shape)\n",
    "\n",
    "# (batch, 511, 26) --> (batch, 254, 52)\n",
    "# (511 - 5 + 0)/2 + 1 = (506/2)+1= 253+1= 254\n",
    "# 2/5 with strides/kernel_size is 40% non-overlap/diff region and \n",
    "# 60% overlapping window/ common region\n",
    "in_conv = out_pool\n",
    "out_conv = tf.layers.conv1d(inputs=in_conv, filters=52, kernel_size=5, strides=2, padding='valid')\n",
    "out_conv = tf.layers.batch_normalization(inputs=out_conv)\n",
    "out_conv = tf.nn.relu(features=out_conv)\n",
    "out_conv = tf.nn.dropout(x=out_conv, keep_prob=keep_prob_)\n",
    "print(in_conv.shape, out_conv.shape)\n",
    "\n",
    "# To reduce the size for memory efficiency & equivariancy/invariency/ minicolumns\n",
    "# (batch, 254, 52) --> (batch, 25, 52)\n",
    "# (254 - 14 + 0)/10 + 1 = (240/10)+1= 24 +1 = 25\n",
    "# 10/14 with strides/kernel_size is \n",
    "# ~66.666% non-overlap/diff region and \n",
    "# ~33.33% overlapping window/ common region\n",
    "in_pool = out_conv\n",
    "out_pool = tf.layers.max_pooling1d(inputs=in_pool, pool_size=14, strides=10, padding='valid')\n",
    "print(in_pool.shape, out_pool.shape)\n",
    "\n",
    "# (batch, 25, 52) --> (batch, 25*52) --> (batch, 25*52*2)\n",
    "in_fc = tf.reshape(tensor=out_pool, shape=(-1, 25*52))\n",
    "out_fc = tf.layers.dense(inputs=in_fc, units=25*52*2)\n",
    "out_fc = tf.layers.batch_normalization(inputs=out_fc)\n",
    "out_fc = tf.nn.relu(features=out_fc)\n",
    "out_fc = tf.nn.dropout(x=out_fc, keep_prob=keep_prob_)\n",
    "print(out_pool.shape, in_fc.shape, out_fc.shape)\n",
    "\n",
    "# (batch, 25*52*2) --> (batch, 3) \n",
    "logits = tf.layers.dense(inputs=out_fc, units=n_classes)\n",
    "print(out_fc.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"Equal_3:0\", shape=(?,), dtype=bool) Tensor(\"accuracy_3:0\", shape=(), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "print(correct_pred, accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/1000 Train loss: 13.605702 Valid loss: 4.456787 Train acc: 0.335821 Valid acc: 0.333209\n",
      "Epoch: 2/1000 Train loss: 7.804236 Valid loss: 2.821270 Train acc: 0.338806 Valid acc: 0.331903\n",
      "Epoch: 3/1000 Train loss: 5.627068 Valid loss: 2.248756 Train acc: 0.343781 Valid acc: 0.332338\n",
      "Epoch: 4/1000 Train loss: 4.513288 Valid loss: 1.961892 Train acc: 0.336567 Valid acc: 0.334422\n",
      "Epoch: 5/1000 Train loss: 3.831779 Valid loss: 1.789342 Train acc: 0.342985 Valid acc: 0.337388\n",
      "Epoch: 6/1000 Train loss: 3.375536 Valid loss: 1.674261 Train acc: 0.351493 Valid acc: 0.339801\n",
      "Epoch: 7/1000 Train loss: 3.050729 Valid loss: 1.592064 Train acc: 0.355011 Valid acc: 0.340672\n",
      "Epoch: 8/1000 Train loss: 2.805316 Valid loss: 1.530447 Train acc: 0.356343 Valid acc: 0.341511\n",
      "Epoch: 9/1000 Train loss: 2.614046 Valid loss: 1.482548 Train acc: 0.360862 Valid acc: 0.341086\n",
      "Epoch: 10/1000 Train loss: 2.459950 Valid loss: 1.444232 Train acc: 0.367313 Valid acc: 0.340634\n",
      "Epoch: 11/1000 Train loss: 2.333438 Valid loss: 1.412895 Train acc: 0.372049 Valid acc: 0.341045\n",
      "Epoch: 12/1000 Train loss: 2.227973 Valid loss: 1.386789 Train acc: 0.376617 Valid acc: 0.343097\n",
      "Epoch: 13/1000 Train loss: 2.136739 Valid loss: 1.364714 Train acc: 0.382204 Valid acc: 0.344489\n",
      "Epoch: 14/1000 Train loss: 2.059355 Valid loss: 1.345832 Train acc: 0.385714 Valid acc: 0.345256\n",
      "Epoch: 15/1000 Train loss: 1.991543 Valid loss: 1.329522 Train acc: 0.390348 Valid acc: 0.346716\n",
      "Epoch: 16/1000 Train loss: 1.930142 Valid loss: 1.315356 Train acc: 0.396269 Valid acc: 0.347715\n",
      "Epoch: 17/1000 Train loss: 1.876796 Valid loss: 1.302987 Train acc: 0.400790 Valid acc: 0.349451\n",
      "Epoch: 18/1000 Train loss: 1.828783 Valid loss: 1.292135 Train acc: 0.405141 Valid acc: 0.350580\n",
      "Epoch: 19/1000 Train loss: 1.785217 Valid loss: 1.282548 Train acc: 0.409191 Valid acc: 0.351002\n",
      "Epoch: 20/1000 Train loss: 1.744725 Valid loss: 1.274094 Train acc: 0.413657 Valid acc: 0.351269\n",
      "Epoch: 21/1000 Train loss: 1.707852 Valid loss: 1.266616 Train acc: 0.419332 Valid acc: 0.351119\n",
      "Epoch: 22/1000 Train loss: 1.673675 Valid loss: 1.259920 Train acc: 0.424288 Valid acc: 0.350644\n",
      "Epoch: 23/1000 Train loss: 1.641754 Valid loss: 1.253831 Train acc: 0.429526 Valid acc: 0.350487\n",
      "Epoch: 24/1000 Train loss: 1.611271 Valid loss: 1.248346 Train acc: 0.435012 Valid acc: 0.350746\n",
      "Epoch: 25/1000 Train loss: 1.581792 Valid loss: 1.243633 Train acc: 0.440418 Valid acc: 0.350567\n",
      "Epoch: 26/1000 Train loss: 1.555542 Valid loss: 1.239518 Train acc: 0.445178 Valid acc: 0.349613\n",
      "Epoch: 27/1000 Train loss: 1.530728 Valid loss: 1.235864 Train acc: 0.450470 Valid acc: 0.348715\n",
      "Epoch: 28/1000 Train loss: 1.506944 Valid loss: 1.232339 Train acc: 0.455117 Valid acc: 0.348228\n",
      "Epoch: 29/1000 Train loss: 1.484093 Valid loss: 1.229132 Train acc: 0.460268 Valid acc: 0.347452\n",
      "Epoch: 30/1000 Train loss: 1.465041 Valid loss: 1.226327 Train acc: 0.464179 Valid acc: 0.347114\n",
      "Epoch: 31/1000 Train loss: 1.449688 Valid loss: 1.223131 Train acc: 0.466298 Valid acc: 0.346690\n",
      "Epoch: 32/1000 Train loss: 1.433850 Valid loss: 1.219740 Train acc: 0.468750 Valid acc: 0.346922\n",
      "Epoch: 33/1000 Train loss: 1.417428 Valid loss: 1.216167 Train acc: 0.472320 Valid acc: 0.346687\n",
      "Epoch: 34/1000 Train loss: 1.400445 Valid loss: 1.213015 Train acc: 0.476866 Valid acc: 0.347256\n",
      "Epoch: 35/1000 Train loss: 1.384031 Valid loss: 1.210288 Train acc: 0.481322 Valid acc: 0.347697\n",
      "Epoch: 36/1000 Train loss: 1.367760 Valid loss: 1.208212 Train acc: 0.485489 Valid acc: 0.348000\n",
      "Epoch: 37/1000 Train loss: 1.353131 Valid loss: 1.206503 Train acc: 0.489351 Valid acc: 0.348144\n",
      "Epoch: 38/1000 Train loss: 1.338247 Valid loss: 1.204977 Train acc: 0.493244 Valid acc: 0.348164\n",
      "Epoch: 39/1000 Train loss: 1.324207 Valid loss: 1.203538 Train acc: 0.497015 Valid acc: 0.347838\n",
      "Epoch: 40/1000 Train loss: 1.308910 Valid loss: 1.202210 Train acc: 0.501530 Valid acc: 0.347360\n",
      "Epoch: 41/1000 Train loss: 1.294661 Valid loss: 1.201212 Train acc: 0.505351 Valid acc: 0.347033\n",
      "Epoch: 42/1000 Train loss: 1.280166 Valid loss: 1.200330 Train acc: 0.509986 Valid acc: 0.346571\n",
      "Epoch: 43/1000 Train loss: 1.266635 Valid loss: 1.199569 Train acc: 0.513988 Valid acc: 0.346364\n",
      "Epoch: 44/1000 Train loss: 1.254347 Valid loss: 1.198853 Train acc: 0.517639 Valid acc: 0.346031\n",
      "Epoch: 45/1000 Train loss: 1.241963 Valid loss: 1.198162 Train acc: 0.521161 Valid acc: 0.345788\n",
      "Epoch: 46/1000 Train loss: 1.229790 Valid loss: 1.197622 Train acc: 0.525178 Valid acc: 0.345587\n",
      "Epoch: 47/1000 Train loss: 1.217986 Valid loss: 1.197602 Train acc: 0.528517 Valid acc: 0.345491\n",
      "Epoch: 48/1000 Train loss: 1.207118 Valid loss: 1.197721 Train acc: 0.532214 Valid acc: 0.345313\n",
      "Epoch: 49/1000 Train loss: 1.198377 Valid loss: 1.197106 Train acc: 0.533902 Valid acc: 0.344829\n",
      "Epoch: 50/1000 Train loss: 1.188954 Valid loss: 1.196059 Train acc: 0.536627 Valid acc: 0.344276\n",
      "Epoch: 51/1000 Train loss: 1.179365 Valid loss: 1.195047 Train acc: 0.539625 Valid acc: 0.343781\n",
      "Epoch: 52/1000 Train loss: 1.168520 Valid loss: 1.194218 Train acc: 0.543542 Valid acc: 0.343154\n",
      "Epoch: 53/1000 Train loss: 1.158193 Valid loss: 1.193846 Train acc: 0.547226 Valid acc: 0.342798\n",
      "Epoch: 54/1000 Train loss: 1.146929 Valid loss: 1.193641 Train acc: 0.551271 Valid acc: 0.342261\n",
      "Epoch: 55/1000 Train loss: 1.135448 Valid loss: 1.193836 Train acc: 0.555794 Valid acc: 0.341689\n",
      "Epoch: 56/1000 Train loss: 1.124340 Valid loss: 1.194410 Train acc: 0.560181 Valid acc: 0.341465\n",
      "Epoch: 57/1000 Train loss: 1.113628 Valid loss: 1.195035 Train acc: 0.564362 Valid acc: 0.341208\n",
      "Epoch: 58/1000 Train loss: 1.102817 Valid loss: 1.195722 Train acc: 0.568425 Valid acc: 0.341096\n",
      "Epoch: 59/1000 Train loss: 1.091825 Valid loss: 1.196371 Train acc: 0.572451 Valid acc: 0.340836\n",
      "Epoch: 60/1000 Train loss: 1.081493 Valid loss: 1.196895 Train acc: 0.576244 Valid acc: 0.340578\n",
      "Epoch: 61/1000 Train loss: 1.070888 Valid loss: 1.197462 Train acc: 0.580206 Valid acc: 0.340311\n",
      "Epoch: 62/1000 Train loss: 1.060003 Valid loss: 1.198686 Train acc: 0.584521 Valid acc: 0.339865\n",
      "Epoch: 63/1000 Train loss: 1.049913 Valid loss: 1.200168 Train acc: 0.588605 Valid acc: 0.339226\n",
      "Epoch: 64/1000 Train loss: 1.040218 Valid loss: 1.201290 Train acc: 0.592467 Valid acc: 0.338759\n",
      "Epoch: 65/1000 Train loss: 1.030448 Valid loss: 1.202344 Train acc: 0.596119 Valid acc: 0.338416\n",
      "Epoch: 66/1000 Train loss: 1.021191 Valid loss: 1.203407 Train acc: 0.599457 Valid acc: 0.338229\n",
      "Epoch: 67/1000 Train loss: 1.012188 Valid loss: 1.204376 Train acc: 0.602963 Valid acc: 0.338227\n",
      "Epoch: 68/1000 Train loss: 1.004551 Valid loss: 1.205391 Train acc: 0.605904 Valid acc: 0.338093\n",
      "Epoch: 69/1000 Train loss: 0.996194 Valid loss: 1.206375 Train acc: 0.609150 Valid acc: 0.338065\n",
      "Epoch: 70/1000 Train loss: 0.989135 Valid loss: 1.207522 Train acc: 0.611834 Valid acc: 0.337889\n",
      "Epoch: 71/1000 Train loss: 0.982245 Valid loss: 1.207899 Train acc: 0.614148 Valid acc: 0.337461\n",
      "Epoch: 72/1000 Train loss: 0.975234 Valid loss: 1.207937 Train acc: 0.616895 Valid acc: 0.337500\n",
      "Epoch: 73/1000 Train loss: 0.967798 Valid loss: 1.208056 Train acc: 0.619832 Valid acc: 0.337615\n",
      "Epoch: 74/1000 Train loss: 0.959860 Valid loss: 1.208300 Train acc: 0.622832 Valid acc: 0.337439\n",
      "Epoch: 75/1000 Train loss: 0.950950 Valid loss: 1.208592 Train acc: 0.626547 Valid acc: 0.337423\n",
      "Epoch: 76/1000 Train loss: 0.941579 Valid loss: 1.209500 Train acc: 0.630440 Valid acc: 0.337294\n",
      "Epoch: 77/1000 Train loss: 0.932839 Valid loss: 1.211058 Train acc: 0.633960 Valid acc: 0.337265\n",
      "Epoch: 78/1000 Train loss: 0.924112 Valid loss: 1.212971 Train acc: 0.637466 Valid acc: 0.337146\n",
      "Epoch: 79/1000 Train loss: 0.915685 Valid loss: 1.215458 Train acc: 0.640827 Valid acc: 0.337063\n",
      "Epoch: 80/1000 Train loss: 0.907788 Valid loss: 1.217311 Train acc: 0.643993 Valid acc: 0.336833\n",
      "Epoch: 81/1000 Train loss: 0.899883 Valid loss: 1.218529 Train acc: 0.647245 Valid acc: 0.336830\n",
      "Epoch: 82/1000 Train loss: 0.892127 Valid loss: 1.219522 Train acc: 0.650328 Valid acc: 0.336881\n",
      "Epoch: 83/1000 Train loss: 0.884424 Valid loss: 1.220662 Train acc: 0.653300 Valid acc: 0.336760\n",
      "Epoch: 84/1000 Train loss: 0.876186 Valid loss: 1.222162 Train acc: 0.656574 Valid acc: 0.336691\n",
      "Epoch: 85/1000 Train loss: 0.868295 Valid loss: 1.223869 Train acc: 0.659860 Valid acc: 0.336506\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 86/1000 Train loss: 0.860180 Valid loss: 1.225537 Train acc: 0.663051 Valid acc: 0.336355\n",
      "Epoch: 87/1000 Train loss: 0.852342 Valid loss: 1.227722 Train acc: 0.666272 Valid acc: 0.336108\n",
      "Epoch: 88/1000 Train loss: 0.844856 Valid loss: 1.230098 Train acc: 0.669183 Valid acc: 0.335974\n",
      "Epoch: 89/1000 Train loss: 0.837512 Valid loss: 1.232190 Train acc: 0.672145 Valid acc: 0.335796\n",
      "Epoch: 90/1000 Train loss: 0.831041 Valid loss: 1.234409 Train acc: 0.674677 Valid acc: 0.335871\n",
      "Epoch: 91/1000 Train loss: 0.824219 Valid loss: 1.236567 Train acc: 0.677284 Valid acc: 0.335804\n",
      "Epoch: 92/1000 Train loss: 0.817198 Valid loss: 1.239498 Train acc: 0.680127 Valid acc: 0.335622\n",
      "Epoch: 93/1000 Train loss: 0.810298 Valid loss: 1.242108 Train acc: 0.682892 Valid acc: 0.335331\n",
      "Epoch: 94/1000 Train loss: 0.804035 Valid loss: 1.244456 Train acc: 0.685487 Valid acc: 0.335039\n",
      "Epoch: 95/1000 Train loss: 0.797438 Valid loss: 1.246164 Train acc: 0.688154 Valid acc: 0.334709\n",
      "Epoch: 96/1000 Train loss: 0.791012 Valid loss: 1.248075 Train acc: 0.690781 Valid acc: 0.334453\n",
      "Epoch: 97/1000 Train loss: 0.784627 Valid loss: 1.250782 Train acc: 0.693276 Valid acc: 0.334140\n",
      "Epoch: 98/1000 Train loss: 0.778610 Valid loss: 1.253565 Train acc: 0.695659 Valid acc: 0.333780\n",
      "Epoch: 99/1000 Train loss: 0.772266 Valid loss: 1.256150 Train acc: 0.698131 Valid acc: 0.333443\n",
      "Epoch: 100/1000 Train loss: 0.766203 Valid loss: 1.258854 Train acc: 0.700582 Valid acc: 0.333175\n",
      "Epoch: 101/1000 Train loss: 0.760291 Valid loss: 1.261662 Train acc: 0.702955 Valid acc: 0.332995\n",
      "Epoch: 102/1000 Train loss: 0.754734 Valid loss: 1.265031 Train acc: 0.705165 Valid acc: 0.332887\n",
      "Epoch: 103/1000 Train loss: 0.749631 Valid loss: 1.267136 Train acc: 0.707361 Valid acc: 0.332890\n",
      "Epoch: 104/1000 Train loss: 0.744375 Valid loss: 1.269131 Train acc: 0.709486 Valid acc: 0.332685\n",
      "Epoch: 105/1000 Train loss: 0.738807 Valid loss: 1.271783 Train acc: 0.711741 Valid acc: 0.332633\n",
      "Epoch: 106/1000 Train loss: 0.733288 Valid loss: 1.274651 Train acc: 0.714024 Valid acc: 0.332470\n",
      "Epoch: 107/1000 Train loss: 0.727520 Valid loss: 1.277295 Train acc: 0.716237 Valid acc: 0.332316\n",
      "Epoch: 108/1000 Train loss: 0.721902 Valid loss: 1.279381 Train acc: 0.718518 Valid acc: 0.332145\n",
      "Epoch: 109/1000 Train loss: 0.716484 Valid loss: 1.281449 Train acc: 0.720731 Valid acc: 0.331857\n",
      "Epoch: 110/1000 Train loss: 0.710937 Valid loss: 1.283651 Train acc: 0.722931 Valid acc: 0.331635\n",
      "Epoch: 111/1000 Train loss: 0.705512 Valid loss: 1.286370 Train acc: 0.725131 Valid acc: 0.331360\n",
      "Epoch: 112/1000 Train loss: 0.700472 Valid loss: 1.289360 Train acc: 0.727172 Valid acc: 0.331243\n",
      "Epoch: 113/1000 Train loss: 0.695416 Valid loss: 1.292087 Train acc: 0.729256 Valid acc: 0.331178\n",
      "Epoch: 114/1000 Train loss: 0.690273 Valid loss: 1.294568 Train acc: 0.731343 Valid acc: 0.330996\n",
      "Epoch: 115/1000 Train loss: 0.685128 Valid loss: 1.297561 Train acc: 0.733472 Valid acc: 0.330785\n",
      "Epoch: 116/1000 Train loss: 0.680050 Valid loss: 1.300650 Train acc: 0.735448 Valid acc: 0.330533\n",
      "Epoch: 117/1000 Train loss: 0.675421 Valid loss: 1.303251 Train acc: 0.737288 Valid acc: 0.330316\n",
      "Epoch: 118/1000 Train loss: 0.670337 Valid loss: 1.305842 Train acc: 0.739375 Valid acc: 0.330176\n",
      "Epoch: 119/1000 Train loss: 0.665447 Valid loss: 1.308876 Train acc: 0.741314 Valid acc: 0.330139\n",
      "Epoch: 120/1000 Train loss: 0.661028 Valid loss: 1.311745 Train acc: 0.743072 Valid acc: 0.330028\n",
      "Epoch: 121/1000 Train loss: 0.656378 Valid loss: 1.313951 Train acc: 0.744862 Valid acc: 0.329956\n",
      "Epoch: 122/1000 Train loss: 0.652055 Valid loss: 1.316241 Train acc: 0.746587 Valid acc: 0.329808\n",
      "Epoch: 123/1000 Train loss: 0.647426 Valid loss: 1.318707 Train acc: 0.748465 Valid acc: 0.329729\n",
      "Epoch: 124/1000 Train loss: 0.642890 Valid loss: 1.321089 Train acc: 0.750313 Valid acc: 0.329664\n",
      "Epoch: 125/1000 Train loss: 0.638283 Valid loss: 1.323666 Train acc: 0.752179 Valid acc: 0.329519\n",
      "Epoch: 126/1000 Train loss: 0.633807 Valid loss: 1.326660 Train acc: 0.753933 Valid acc: 0.329270\n",
      "Epoch: 127/1000 Train loss: 0.629584 Valid loss: 1.329612 Train acc: 0.755647 Valid acc: 0.329028\n",
      "Epoch: 128/1000 Train loss: 0.625595 Valid loss: 1.332415 Train acc: 0.757253 Valid acc: 0.328728\n",
      "Epoch: 129/1000 Train loss: 0.621870 Valid loss: 1.335229 Train acc: 0.758718 Valid acc: 0.328512\n",
      "Epoch: 130/1000 Train loss: 0.618342 Valid loss: 1.337863 Train acc: 0.760218 Valid acc: 0.328352\n",
      "Epoch: 131/1000 Train loss: 0.614364 Valid loss: 1.340138 Train acc: 0.761764 Valid acc: 0.328199\n",
      "Epoch: 132/1000 Train loss: 0.610299 Valid loss: 1.341773 Train acc: 0.763388 Valid acc: 0.328002\n",
      "Epoch: 133/1000 Train loss: 0.606522 Valid loss: 1.343931 Train acc: 0.764920 Valid acc: 0.327772\n",
      "Epoch: 134/1000 Train loss: 0.602452 Valid loss: 1.346091 Train acc: 0.766585 Valid acc: 0.327551\n",
      "Epoch: 135/1000 Train loss: 0.598457 Valid loss: 1.348233 Train acc: 0.768181 Valid acc: 0.327230\n",
      "Epoch: 136/1000 Train loss: 0.594688 Valid loss: 1.350237 Train acc: 0.769710 Valid acc: 0.326992\n",
      "Epoch: 137/1000 Train loss: 0.590752 Valid loss: 1.352004 Train acc: 0.771282 Valid acc: 0.326762\n",
      "Epoch: 138/1000 Train loss: 0.587035 Valid loss: 1.354027 Train acc: 0.772745 Valid acc: 0.326566\n",
      "Epoch: 139/1000 Train loss: 0.583433 Valid loss: 1.356590 Train acc: 0.774144 Valid acc: 0.326595\n",
      "Epoch: 140/1000 Train loss: 0.579816 Valid loss: 1.358609 Train acc: 0.775618 Valid acc: 0.326538\n",
      "Epoch: 141/1000 Train loss: 0.576087 Valid loss: 1.360766 Train acc: 0.777093 Valid acc: 0.326429\n",
      "Epoch: 142/1000 Train loss: 0.572404 Valid loss: 1.362901 Train acc: 0.778526 Valid acc: 0.326209\n",
      "Epoch: 143/1000 Train loss: 0.568726 Valid loss: 1.365146 Train acc: 0.779971 Valid acc: 0.325911\n",
      "Epoch: 144/1000 Train loss: 0.565106 Valid loss: 1.367687 Train acc: 0.781395 Valid acc: 0.325653\n",
      "Epoch: 145/1000 Train loss: 0.561669 Valid loss: 1.370257 Train acc: 0.782800 Valid acc: 0.325450\n",
      "Epoch: 146/1000 Train loss: 0.558248 Valid loss: 1.372731 Train acc: 0.784114 Valid acc: 0.325266\n",
      "Epoch: 147/1000 Train loss: 0.554868 Valid loss: 1.375148 Train acc: 0.785471 Valid acc: 0.325046\n",
      "Epoch: 148/1000 Train loss: 0.551646 Valid loss: 1.377634 Train acc: 0.786769 Valid acc: 0.324864\n",
      "Epoch: 149/1000 Train loss: 0.548298 Valid loss: 1.380071 Train acc: 0.788070 Valid acc: 0.324717\n",
      "Epoch: 150/1000 Train loss: 0.545012 Valid loss: 1.382239 Train acc: 0.789373 Valid acc: 0.324614\n",
      "Epoch: 151/1000 Train loss: 0.541734 Valid loss: 1.384663 Train acc: 0.790649 Valid acc: 0.324498\n",
      "Epoch: 152/1000 Train loss: 0.538576 Valid loss: 1.387188 Train acc: 0.791919 Valid acc: 0.324300\n",
      "Epoch: 153/1000 Train loss: 0.535391 Valid loss: 1.390079 Train acc: 0.793191 Valid acc: 0.324110\n",
      "Epoch: 154/1000 Train loss: 0.532358 Valid loss: 1.392842 Train acc: 0.794418 Valid acc: 0.323859\n",
      "Epoch: 155/1000 Train loss: 0.529313 Valid loss: 1.395473 Train acc: 0.795628 Valid acc: 0.323782\n",
      "Epoch: 156/1000 Train loss: 0.526211 Valid loss: 1.398629 Train acc: 0.796871 Valid acc: 0.323481\n",
      "Epoch: 157/1000 Train loss: 0.523221 Valid loss: 1.401639 Train acc: 0.797985 Valid acc: 0.323403\n",
      "Epoch: 158/1000 Train loss: 0.520101 Valid loss: 1.404134 Train acc: 0.799178 Valid acc: 0.323243\n",
      "Epoch: 159/1000 Train loss: 0.517101 Valid loss: 1.406623 Train acc: 0.800319 Valid acc: 0.323024\n",
      "Epoch: 160/1000 Train loss: 0.514213 Valid loss: 1.409864 Train acc: 0.801474 Valid acc: 0.322936\n",
      "Epoch: 161/1000 Train loss: 0.511289 Valid loss: 1.412573 Train acc: 0.802642 Valid acc: 0.322828\n",
      "Epoch: 162/1000 Train loss: 0.508530 Valid loss: 1.414986 Train acc: 0.803741 Valid acc: 0.322625\n",
      "Epoch: 163/1000 Train loss: 0.505607 Valid loss: 1.417315 Train acc: 0.804880 Valid acc: 0.322470\n",
      "Epoch: 164/1000 Train loss: 0.502845 Valid loss: 1.420155 Train acc: 0.805970 Valid acc: 0.322413\n",
      "Epoch: 165/1000 Train loss: 0.500105 Valid loss: 1.422854 Train acc: 0.807019 Valid acc: 0.322200\n",
      "Epoch: 166/1000 Train loss: 0.497353 Valid loss: 1.425428 Train acc: 0.808083 Valid acc: 0.322037\n",
      "Epoch: 167/1000 Train loss: 0.494633 Valid loss: 1.427865 Train acc: 0.809143 Valid acc: 0.322024\n",
      "Epoch: 168/1000 Train loss: 0.491862 Valid loss: 1.430206 Train acc: 0.810226 Valid acc: 0.322050\n",
      "Epoch: 169/1000 Train loss: 0.489266 Valid loss: 1.432388 Train acc: 0.811225 Valid acc: 0.322037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 170/1000 Train loss: 0.486600 Valid loss: 1.434782 Train acc: 0.812283 Valid acc: 0.321993\n",
      "Epoch: 171/1000 Train loss: 0.483974 Valid loss: 1.437083 Train acc: 0.813311 Valid acc: 0.321921\n",
      "Epoch: 172/1000 Train loss: 0.481367 Valid loss: 1.439766 Train acc: 0.814327 Valid acc: 0.321818\n",
      "Epoch: 173/1000 Train loss: 0.478981 Valid loss: 1.442243 Train acc: 0.815296 Valid acc: 0.321661\n",
      "Epoch: 174/1000 Train loss: 0.476660 Valid loss: 1.444795 Train acc: 0.816221 Valid acc: 0.321470\n",
      "Epoch: 175/1000 Train loss: 0.474227 Valid loss: 1.446941 Train acc: 0.817143 Valid acc: 0.321213\n",
      "Epoch: 176/1000 Train loss: 0.471724 Valid loss: 1.449156 Train acc: 0.818148 Valid acc: 0.321078\n",
      "Epoch: 177/1000 Train loss: 0.469336 Valid loss: 1.451099 Train acc: 0.819074 Valid acc: 0.320940\n",
      "Epoch: 178/1000 Train loss: 0.467014 Valid loss: 1.453417 Train acc: 0.819973 Valid acc: 0.320751\n",
      "Epoch: 179/1000 Train loss: 0.464693 Valid loss: 1.455560 Train acc: 0.820870 Valid acc: 0.320533\n",
      "Epoch: 180/1000 Train loss: 0.462322 Valid loss: 1.458041 Train acc: 0.821783 Valid acc: 0.320311\n",
      "Epoch: 181/1000 Train loss: 0.460069 Valid loss: 1.460618 Train acc: 0.822693 Valid acc: 0.320106\n",
      "Epoch: 182/1000 Train loss: 0.457720 Valid loss: 1.463318 Train acc: 0.823610 Valid acc: 0.319868\n",
      "Epoch: 183/1000 Train loss: 0.455385 Valid loss: 1.465695 Train acc: 0.824509 Valid acc: 0.319660\n",
      "Epoch: 184/1000 Train loss: 0.453231 Valid loss: 1.467974 Train acc: 0.825333 Valid acc: 0.319555\n",
      "Epoch: 185/1000 Train loss: 0.450978 Valid loss: 1.470225 Train acc: 0.826212 Valid acc: 0.319474\n",
      "Epoch: 186/1000 Train loss: 0.448853 Valid loss: 1.472358 Train acc: 0.827018 Valid acc: 0.319397\n",
      "Epoch: 187/1000 Train loss: 0.446807 Valid loss: 1.474285 Train acc: 0.827855 Valid acc: 0.319335\n",
      "Epoch: 188/1000 Train loss: 0.444601 Valid loss: 1.475876 Train acc: 0.828716 Valid acc: 0.319260\n",
      "Epoch: 189/1000 Train loss: 0.442386 Valid loss: 1.478161 Train acc: 0.829574 Valid acc: 0.319275\n",
      "Epoch: 190/1000 Train loss: 0.440341 Valid loss: 1.480411 Train acc: 0.830369 Valid acc: 0.319197\n",
      "Epoch: 191/1000 Train loss: 0.438315 Valid loss: 1.482951 Train acc: 0.831187 Valid acc: 0.319081\n",
      "Epoch: 192/1000 Train loss: 0.436190 Valid loss: 1.484943 Train acc: 0.832020 Valid acc: 0.318940\n",
      "Epoch: 193/1000 Train loss: 0.434183 Valid loss: 1.487113 Train acc: 0.832828 Valid acc: 0.318794\n",
      "Epoch: 194/1000 Train loss: 0.432130 Valid loss: 1.488948 Train acc: 0.833644 Valid acc: 0.318674\n",
      "Epoch: 195/1000 Train loss: 0.430124 Valid loss: 1.490507 Train acc: 0.834428 Valid acc: 0.318561\n",
      "Epoch: 196/1000 Train loss: 0.428113 Valid loss: 1.492700 Train acc: 0.835196 Valid acc: 0.318396\n",
      "Epoch: 197/1000 Train loss: 0.426201 Valid loss: 1.494779 Train acc: 0.835919 Valid acc: 0.318261\n",
      "Epoch: 198/1000 Train loss: 0.424474 Valid loss: 1.497185 Train acc: 0.836605 Valid acc: 0.318157\n",
      "Epoch: 199/1000 Train loss: 0.422533 Valid loss: 1.499695 Train acc: 0.837343 Valid acc: 0.317995\n",
      "Epoch: 200/1000 Train loss: 0.420722 Valid loss: 1.501687 Train acc: 0.838067 Valid acc: 0.317851\n",
      "Epoch: 201/1000 Train loss: 0.418845 Valid loss: 1.503164 Train acc: 0.838821 Valid acc: 0.317704\n",
      "Epoch: 202/1000 Train loss: 0.416976 Valid loss: 1.504666 Train acc: 0.839560 Valid acc: 0.317574\n",
      "Epoch: 203/1000 Train loss: 0.415125 Valid loss: 1.506482 Train acc: 0.840262 Valid acc: 0.317407\n",
      "Epoch: 204/1000 Train loss: 0.413250 Valid loss: 1.508436 Train acc: 0.840979 Valid acc: 0.317221\n",
      "Epoch: 205/1000 Train loss: 0.411511 Valid loss: 1.510216 Train acc: 0.841653 Valid acc: 0.317079\n",
      "Epoch: 206/1000 Train loss: 0.409731 Valid loss: 1.511827 Train acc: 0.842349 Valid acc: 0.317003\n",
      "Epoch: 207/1000 Train loss: 0.407912 Valid loss: 1.513521 Train acc: 0.843067 Valid acc: 0.316906\n",
      "Epoch: 208/1000 Train loss: 0.406178 Valid loss: 1.515044 Train acc: 0.843743 Valid acc: 0.316829\n",
      "Epoch: 209/1000 Train loss: 0.404526 Valid loss: 1.516693 Train acc: 0.844412 Valid acc: 0.316696\n",
      "Epoch: 210/1000 Train loss: 0.402786 Valid loss: 1.518350 Train acc: 0.845096 Valid acc: 0.316574\n",
      "Epoch: 211/1000 Train loss: 0.401058 Valid loss: 1.519971 Train acc: 0.845788 Valid acc: 0.316448\n",
      "Epoch: 212/1000 Train loss: 0.399417 Valid loss: 1.521480 Train acc: 0.846417 Valid acc: 0.316326\n",
      "Epoch: 213/1000 Train loss: 0.397694 Valid loss: 1.522541 Train acc: 0.847095 Valid acc: 0.316227\n",
      "Epoch: 214/1000 Train loss: 0.395947 Valid loss: 1.523846 Train acc: 0.847775 Valid acc: 0.316040\n",
      "Epoch: 215/1000 Train loss: 0.394268 Valid loss: 1.525319 Train acc: 0.848421 Valid acc: 0.315866\n",
      "Epoch: 216/1000 Train loss: 0.392607 Valid loss: 1.526933 Train acc: 0.849074 Valid acc: 0.315679\n",
      "Epoch: 217/1000 Train loss: 0.390957 Valid loss: 1.528751 Train acc: 0.849721 Valid acc: 0.315486\n",
      "Epoch: 218/1000 Train loss: 0.389310 Valid loss: 1.530724 Train acc: 0.850370 Valid acc: 0.315322\n",
      "Epoch: 219/1000 Train loss: 0.387626 Valid loss: 1.532904 Train acc: 0.851033 Valid acc: 0.315128\n",
      "Epoch: 220/1000 Train loss: 0.385987 Valid loss: 1.535203 Train acc: 0.851669 Valid acc: 0.314988\n",
      "Epoch: 221/1000 Train loss: 0.384460 Valid loss: 1.538307 Train acc: 0.852252 Valid acc: 0.314914\n",
      "Epoch: 222/1000 Train loss: 0.382992 Valid loss: 1.540579 Train acc: 0.852844 Valid acc: 0.314838\n",
      "Epoch: 223/1000 Train loss: 0.381472 Valid loss: 1.542406 Train acc: 0.853430 Valid acc: 0.314765\n",
      "Epoch: 224/1000 Train loss: 0.379873 Valid loss: 1.543736 Train acc: 0.854058 Valid acc: 0.314664\n",
      "Epoch: 225/1000 Train loss: 0.378373 Valid loss: 1.545128 Train acc: 0.854653 Valid acc: 0.314498\n",
      "Epoch: 226/1000 Train loss: 0.376847 Valid loss: 1.546726 Train acc: 0.855230 Valid acc: 0.314400\n",
      "Epoch: 227/1000 Train loss: 0.375370 Valid loss: 1.548421 Train acc: 0.855822 Valid acc: 0.314288\n",
      "Epoch: 228/1000 Train loss: 0.373871 Valid loss: 1.550153 Train acc: 0.856415 Valid acc: 0.314195\n",
      "Epoch: 229/1000 Train loss: 0.372485 Valid loss: 1.552666 Train acc: 0.856964 Valid acc: 0.314047\n",
      "Epoch: 230/1000 Train loss: 0.371148 Valid loss: 1.554632 Train acc: 0.857495 Valid acc: 0.313908\n",
      "Epoch: 231/1000 Train loss: 0.369681 Valid loss: 1.556319 Train acc: 0.858073 Valid acc: 0.313821\n",
      "Epoch: 232/1000 Train loss: 0.368184 Valid loss: 1.557530 Train acc: 0.858659 Valid acc: 0.313763\n",
      "Epoch: 233/1000 Train loss: 0.366705 Valid loss: 1.558950 Train acc: 0.859227 Valid acc: 0.313657\n",
      "Epoch: 234/1000 Train loss: 0.365253 Valid loss: 1.560463 Train acc: 0.859772 Valid acc: 0.313552\n",
      "Epoch: 235/1000 Train loss: 0.363788 Valid loss: 1.561779 Train acc: 0.860330 Valid acc: 0.313457\n",
      "Epoch: 236/1000 Train loss: 0.362348 Valid loss: 1.563130 Train acc: 0.860897 Valid acc: 0.313425\n",
      "Epoch: 237/1000 Train loss: 0.360952 Valid loss: 1.564763 Train acc: 0.861446 Valid acc: 0.313327\n",
      "Epoch: 238/1000 Train loss: 0.359554 Valid loss: 1.566304 Train acc: 0.861984 Valid acc: 0.313249\n",
      "Epoch: 239/1000 Train loss: 0.358148 Valid loss: 1.568099 Train acc: 0.862530 Valid acc: 0.313085\n",
      "Epoch: 240/1000 Train loss: 0.356860 Valid loss: 1.570060 Train acc: 0.863016 Valid acc: 0.312940\n",
      "Epoch: 241/1000 Train loss: 0.355499 Valid loss: 1.571970 Train acc: 0.863535 Valid acc: 0.312874\n",
      "Epoch: 242/1000 Train loss: 0.354143 Valid loss: 1.573713 Train acc: 0.864074 Valid acc: 0.312771\n",
      "Epoch: 243/1000 Train loss: 0.352768 Valid loss: 1.575523 Train acc: 0.864615 Valid acc: 0.312708\n",
      "Epoch: 244/1000 Train loss: 0.351501 Valid loss: 1.577687 Train acc: 0.865127 Valid acc: 0.312624\n",
      "Epoch: 245/1000 Train loss: 0.350228 Valid loss: 1.579284 Train acc: 0.865617 Valid acc: 0.312588\n",
      "Epoch: 246/1000 Train loss: 0.348906 Valid loss: 1.580939 Train acc: 0.866133 Valid acc: 0.312526\n",
      "Epoch: 247/1000 Train loss: 0.347594 Valid loss: 1.582774 Train acc: 0.866638 Valid acc: 0.312424\n",
      "Epoch: 248/1000 Train loss: 0.346244 Valid loss: 1.584824 Train acc: 0.867158 Valid acc: 0.312220\n",
      "Epoch: 249/1000 Train loss: 0.344947 Valid loss: 1.586963 Train acc: 0.867662 Valid acc: 0.312066\n",
      "Epoch: 250/1000 Train loss: 0.343651 Valid loss: 1.588912 Train acc: 0.868161 Valid acc: 0.311921\n",
      "Epoch: 251/1000 Train loss: 0.342379 Valid loss: 1.590753 Train acc: 0.868663 Valid acc: 0.311795\n",
      "Epoch: 252/1000 Train loss: 0.341084 Valid loss: 1.592769 Train acc: 0.869172 Valid acc: 0.311653\n",
      "Epoch: 253/1000 Train loss: 0.339800 Valid loss: 1.594644 Train acc: 0.869671 Valid acc: 0.311552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 254/1000 Train loss: 0.338542 Valid loss: 1.596501 Train acc: 0.870167 Valid acc: 0.311438\n",
      "Epoch: 255/1000 Train loss: 0.337330 Valid loss: 1.598676 Train acc: 0.870629 Valid acc: 0.311378\n",
      "Epoch: 256/1000 Train loss: 0.336055 Valid loss: 1.600599 Train acc: 0.871129 Valid acc: 0.311397\n",
      "Epoch: 257/1000 Train loss: 0.334826 Valid loss: 1.602557 Train acc: 0.871607 Valid acc: 0.311365\n",
      "Epoch: 258/1000 Train loss: 0.333599 Valid loss: 1.604672 Train acc: 0.872081 Valid acc: 0.311362\n",
      "Epoch: 259/1000 Train loss: 0.332413 Valid loss: 1.606811 Train acc: 0.872541 Valid acc: 0.311325\n",
      "Epoch: 260/1000 Train loss: 0.331233 Valid loss: 1.608975 Train acc: 0.872991 Valid acc: 0.311277\n",
      "Epoch: 261/1000 Train loss: 0.330038 Valid loss: 1.610499 Train acc: 0.873443 Valid acc: 0.311220\n",
      "Epoch: 262/1000 Train loss: 0.328855 Valid loss: 1.612203 Train acc: 0.873909 Valid acc: 0.311203\n",
      "Epoch: 263/1000 Train loss: 0.327659 Valid loss: 1.613842 Train acc: 0.874371 Valid acc: 0.311173\n",
      "Epoch: 264/1000 Train loss: 0.326482 Valid loss: 1.615546 Train acc: 0.874836 Valid acc: 0.311133\n",
      "Epoch: 265/1000 Train loss: 0.325402 Valid loss: 1.617211 Train acc: 0.875275 Valid acc: 0.311100\n",
      "Epoch: 266/1000 Train loss: 0.324322 Valid loss: 1.618646 Train acc: 0.875699 Valid acc: 0.311068\n",
      "Epoch: 267/1000 Train loss: 0.323252 Valid loss: 1.620038 Train acc: 0.876119 Valid acc: 0.311082\n",
      "Epoch: 268/1000 Train loss: 0.322104 Valid loss: 1.621536 Train acc: 0.876559 Valid acc: 0.311116\n",
      "Epoch: 269/1000 Train loss: 0.321007 Valid loss: 1.622787 Train acc: 0.876985 Valid acc: 0.311066\n",
      "Epoch: 270/1000 Train loss: 0.319908 Valid loss: 1.623940 Train acc: 0.877407 Valid acc: 0.311003\n",
      "Epoch: 271/1000 Train loss: 0.318826 Valid loss: 1.625222 Train acc: 0.877810 Valid acc: 0.310974\n",
      "Epoch: 272/1000 Train loss: 0.317860 Valid loss: 1.626315 Train acc: 0.878205 Valid acc: 0.310921\n",
      "Epoch: 273/1000 Train loss: 0.316750 Valid loss: 1.627504 Train acc: 0.878634 Valid acc: 0.310889\n",
      "Epoch: 274/1000 Train loss: 0.315654 Valid loss: 1.628771 Train acc: 0.879050 Valid acc: 0.310825\n",
      "Epoch: 275/1000 Train loss: 0.314596 Valid loss: 1.630128 Train acc: 0.879474 Valid acc: 0.310767\n",
      "Epoch: 276/1000 Train loss: 0.313556 Valid loss: 1.631795 Train acc: 0.879889 Valid acc: 0.310702\n",
      "Epoch: 277/1000 Train loss: 0.312534 Valid loss: 1.633535 Train acc: 0.880301 Valid acc: 0.310692\n",
      "Epoch: 278/1000 Train loss: 0.311510 Valid loss: 1.634843 Train acc: 0.880683 Valid acc: 0.310632\n",
      "Epoch: 279/1000 Train loss: 0.310478 Valid loss: 1.636195 Train acc: 0.881084 Valid acc: 0.310568\n",
      "Epoch: 280/1000 Train loss: 0.309470 Valid loss: 1.637922 Train acc: 0.881482 Valid acc: 0.310448\n",
      "Epoch: 281/1000 Train loss: 0.308464 Valid loss: 1.639647 Train acc: 0.881877 Valid acc: 0.310385\n",
      "Epoch: 282/1000 Train loss: 0.307475 Valid loss: 1.641308 Train acc: 0.882259 Valid acc: 0.310339\n",
      "Epoch: 283/1000 Train loss: 0.306468 Valid loss: 1.642983 Train acc: 0.882643 Valid acc: 0.310286\n",
      "Epoch: 284/1000 Train loss: 0.305471 Valid loss: 1.645384 Train acc: 0.883030 Valid acc: 0.310259\n",
      "Epoch: 285/1000 Train loss: 0.304512 Valid loss: 1.647587 Train acc: 0.883409 Valid acc: 0.310247\n",
      "Epoch: 286/1000 Train loss: 0.303548 Valid loss: 1.649135 Train acc: 0.883786 Valid acc: 0.310281\n",
      "Epoch: 287/1000 Train loss: 0.302549 Valid loss: 1.651283 Train acc: 0.884180 Valid acc: 0.310266\n",
      "Epoch: 288/1000 Train loss: 0.301706 Valid loss: 1.653690 Train acc: 0.884530 Valid acc: 0.310246\n",
      "Epoch: 289/1000 Train loss: 0.300808 Valid loss: 1.655961 Train acc: 0.884889 Valid acc: 0.310183\n",
      "Epoch: 290/1000 Train loss: 0.299971 Valid loss: 1.658352 Train acc: 0.885234 Valid acc: 0.310103\n",
      "Epoch: 291/1000 Train loss: 0.299146 Valid loss: 1.660402 Train acc: 0.885557 Valid acc: 0.310023\n",
      "Epoch: 292/1000 Train loss: 0.298228 Valid loss: 1.662052 Train acc: 0.885913 Valid acc: 0.310006\n",
      "Epoch: 293/1000 Train loss: 0.297315 Valid loss: 1.663584 Train acc: 0.886246 Valid acc: 0.309943\n",
      "Epoch: 294/1000 Train loss: 0.296512 Valid loss: 1.665298 Train acc: 0.886598 Valid acc: 0.309903\n",
      "Epoch: 295/1000 Train loss: 0.295696 Valid loss: 1.667123 Train acc: 0.886936 Valid acc: 0.309927\n",
      "Epoch: 296/1000 Train loss: 0.294837 Valid loss: 1.668935 Train acc: 0.887263 Valid acc: 0.309927\n",
      "Epoch: 297/1000 Train loss: 0.294035 Valid loss: 1.670327 Train acc: 0.887572 Valid acc: 0.309920\n",
      "Epoch: 298/1000 Train loss: 0.293214 Valid loss: 1.671464 Train acc: 0.887909 Valid acc: 0.309893\n",
      "Epoch: 299/1000 Train loss: 0.292380 Valid loss: 1.672511 Train acc: 0.888244 Valid acc: 0.309828\n",
      "Epoch: 300/1000 Train loss: 0.291541 Valid loss: 1.673573 Train acc: 0.888572 Valid acc: 0.309754\n",
      "Epoch: 301/1000 Train loss: 0.290719 Valid loss: 1.674493 Train acc: 0.888912 Valid acc: 0.309679\n",
      "Epoch: 302/1000 Train loss: 0.289922 Valid loss: 1.675435 Train acc: 0.889246 Valid acc: 0.309622\n",
      "Epoch: 303/1000 Train loss: 0.289053 Valid loss: 1.676542 Train acc: 0.889597 Valid acc: 0.309541\n",
      "Epoch: 304/1000 Train loss: 0.288195 Valid loss: 1.677984 Train acc: 0.889925 Valid acc: 0.309466\n",
      "Epoch: 305/1000 Train loss: 0.287488 Valid loss: 1.679234 Train acc: 0.890232 Valid acc: 0.309369\n",
      "Epoch: 306/1000 Train loss: 0.286671 Valid loss: 1.680213 Train acc: 0.890562 Valid acc: 0.309311\n",
      "Epoch: 307/1000 Train loss: 0.285844 Valid loss: 1.681226 Train acc: 0.890870 Valid acc: 0.309225\n",
      "Epoch: 308/1000 Train loss: 0.285022 Valid loss: 1.682432 Train acc: 0.891180 Valid acc: 0.309216\n",
      "Epoch: 309/1000 Train loss: 0.284164 Valid loss: 1.684189 Train acc: 0.891513 Valid acc: 0.309206\n",
      "Epoch: 310/1000 Train loss: 0.283402 Valid loss: 1.686181 Train acc: 0.891805 Valid acc: 0.309191\n",
      "Epoch: 311/1000 Train loss: 0.282588 Valid loss: 1.687944 Train acc: 0.892120 Valid acc: 0.309110\n",
      "Epoch: 312/1000 Train loss: 0.281819 Valid loss: 1.689813 Train acc: 0.892422 Valid acc: 0.309082\n",
      "Epoch: 313/1000 Train loss: 0.281077 Valid loss: 1.691362 Train acc: 0.892733 Valid acc: 0.309072\n",
      "Epoch: 314/1000 Train loss: 0.280290 Valid loss: 1.692765 Train acc: 0.893055 Valid acc: 0.309063\n",
      "Epoch: 315/1000 Train loss: 0.279519 Valid loss: 1.693744 Train acc: 0.893357 Valid acc: 0.309077\n",
      "Epoch: 316/1000 Train loss: 0.278822 Valid loss: 1.694740 Train acc: 0.893643 Valid acc: 0.309050\n",
      "Epoch: 317/1000 Train loss: 0.278056 Valid loss: 1.695969 Train acc: 0.893955 Valid acc: 0.308978\n",
      "Epoch: 318/1000 Train loss: 0.277254 Valid loss: 1.697016 Train acc: 0.894260 Valid acc: 0.308914\n",
      "Epoch: 319/1000 Train loss: 0.276443 Valid loss: 1.697826 Train acc: 0.894582 Valid acc: 0.308837\n",
      "Epoch: 320/1000 Train loss: 0.275683 Valid loss: 1.698646 Train acc: 0.894879 Valid acc: 0.308780\n",
      "Epoch: 321/1000 Train loss: 0.274929 Valid loss: 1.699332 Train acc: 0.895178 Valid acc: 0.308754\n",
      "Epoch: 322/1000 Train loss: 0.274118 Valid loss: 1.699974 Train acc: 0.895495 Valid acc: 0.308703\n",
      "Epoch: 323/1000 Train loss: 0.273305 Valid loss: 1.700614 Train acc: 0.895809 Valid acc: 0.308650\n",
      "Epoch: 324/1000 Train loss: 0.272515 Valid loss: 1.701476 Train acc: 0.896112 Valid acc: 0.308550\n",
      "Epoch: 325/1000 Train loss: 0.271692 Valid loss: 1.702449 Train acc: 0.896427 Valid acc: 0.308465\n",
      "Epoch: 326/1000 Train loss: 0.270889 Valid loss: 1.703487 Train acc: 0.896736 Valid acc: 0.308366\n",
      "Epoch: 327/1000 Train loss: 0.270115 Valid loss: 1.704448 Train acc: 0.897029 Valid acc: 0.308297\n",
      "Epoch: 328/1000 Train loss: 0.269336 Valid loss: 1.705205 Train acc: 0.897329 Valid acc: 0.308270\n",
      "Epoch: 329/1000 Train loss: 0.268609 Valid loss: 1.705701 Train acc: 0.897618 Valid acc: 0.308252\n",
      "Epoch: 330/1000 Train loss: 0.267909 Valid loss: 1.706369 Train acc: 0.897892 Valid acc: 0.308201\n",
      "Epoch: 331/1000 Train loss: 0.267297 Valid loss: 1.707089 Train acc: 0.898160 Valid acc: 0.308175\n",
      "Epoch: 332/1000 Train loss: 0.266595 Valid loss: 1.707989 Train acc: 0.898431 Valid acc: 0.308156\n",
      "Epoch: 333/1000 Train loss: 0.265920 Valid loss: 1.708987 Train acc: 0.898691 Valid acc: 0.308142\n",
      "Epoch: 334/1000 Train loss: 0.265198 Valid loss: 1.710041 Train acc: 0.898968 Valid acc: 0.308099\n",
      "Epoch: 335/1000 Train loss: 0.264613 Valid loss: 1.710767 Train acc: 0.899225 Valid acc: 0.308045\n",
      "Epoch: 336/1000 Train loss: 0.263972 Valid loss: 1.711484 Train acc: 0.899489 Valid acc: 0.307976\n",
      "Epoch: 337/1000 Train loss: 0.263236 Valid loss: 1.712256 Train acc: 0.899765 Valid acc: 0.307929\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 338/1000 Train loss: 0.262617 Valid loss: 1.712946 Train acc: 0.900018 Valid acc: 0.307894\n",
      "Epoch: 339/1000 Train loss: 0.261955 Valid loss: 1.713762 Train acc: 0.900269 Valid acc: 0.307871\n",
      "Epoch: 340/1000 Train loss: 0.261257 Valid loss: 1.714811 Train acc: 0.900544 Valid acc: 0.307872\n",
      "Epoch: 341/1000 Train loss: 0.260571 Valid loss: 1.715920 Train acc: 0.900801 Valid acc: 0.307946\n",
      "Epoch: 342/1000 Train loss: 0.259903 Valid loss: 1.717316 Train acc: 0.901061 Valid acc: 0.307933\n",
      "Epoch: 343/1000 Train loss: 0.259226 Valid loss: 1.718384 Train acc: 0.901314 Valid acc: 0.307934\n",
      "Epoch: 344/1000 Train loss: 0.258513 Valid loss: 1.719440 Train acc: 0.901588 Valid acc: 0.307936\n",
      "Epoch: 345/1000 Train loss: 0.257832 Valid loss: 1.720263 Train acc: 0.901856 Valid acc: 0.307928\n",
      "Epoch: 346/1000 Train loss: 0.257252 Valid loss: 1.721218 Train acc: 0.902092 Valid acc: 0.307879\n",
      "Epoch: 347/1000 Train loss: 0.256575 Valid loss: 1.722607 Train acc: 0.902353 Valid acc: 0.307850\n",
      "Epoch: 348/1000 Train loss: 0.256003 Valid loss: 1.724089 Train acc: 0.902591 Valid acc: 0.307836\n",
      "Epoch: 349/1000 Train loss: 0.255432 Valid loss: 1.725423 Train acc: 0.902822 Valid acc: 0.307818\n",
      "Epoch: 350/1000 Train loss: 0.254833 Valid loss: 1.726526 Train acc: 0.903070 Valid acc: 0.307744\n",
      "Epoch: 351/1000 Train loss: 0.254221 Valid loss: 1.727701 Train acc: 0.903308 Valid acc: 0.307676\n",
      "Epoch: 352/1000 Train loss: 0.253737 Valid loss: 1.729068 Train acc: 0.903511 Valid acc: 0.307590\n",
      "Epoch: 353/1000 Train loss: 0.253138 Valid loss: 1.730283 Train acc: 0.903746 Valid acc: 0.307560\n",
      "Epoch: 354/1000 Train loss: 0.252516 Valid loss: 1.731517 Train acc: 0.903989 Valid acc: 0.307529\n",
      "Epoch: 355/1000 Train loss: 0.251865 Valid loss: 1.733114 Train acc: 0.904230 Valid acc: 0.307494\n",
      "Epoch: 356/1000 Train loss: 0.251334 Valid loss: 1.734595 Train acc: 0.904457 Valid acc: 0.307450\n",
      "Epoch: 357/1000 Train loss: 0.250797 Valid loss: 1.735999 Train acc: 0.904682 Valid acc: 0.307400\n",
      "Epoch: 358/1000 Train loss: 0.250247 Valid loss: 1.737190 Train acc: 0.904903 Valid acc: 0.307389\n",
      "Epoch: 359/1000 Train loss: 0.249878 Valid loss: 1.738548 Train acc: 0.905085 Valid acc: 0.307386\n",
      "Epoch: 360/1000 Train loss: 0.249376 Valid loss: 1.739641 Train acc: 0.905294 Valid acc: 0.307428\n",
      "Epoch: 361/1000 Train loss: 0.248909 Valid loss: 1.740441 Train acc: 0.905491 Valid acc: 0.307497\n",
      "Epoch: 362/1000 Train loss: 0.248463 Valid loss: 1.741375 Train acc: 0.905710 Valid acc: 0.307507\n",
      "Epoch: 363/1000 Train loss: 0.247851 Valid loss: 1.741750 Train acc: 0.905945 Valid acc: 0.307547\n",
      "Epoch: 364/1000 Train loss: 0.247281 Valid loss: 1.742253 Train acc: 0.906171 Valid acc: 0.307553\n",
      "Epoch: 365/1000 Train loss: 0.246647 Valid loss: 1.743010 Train acc: 0.906408 Valid acc: 0.307556\n",
      "Epoch: 366/1000 Train loss: 0.246089 Valid loss: 1.743743 Train acc: 0.906631 Valid acc: 0.307541\n",
      "Epoch: 367/1000 Train loss: 0.245465 Valid loss: 1.744467 Train acc: 0.906865 Valid acc: 0.307527\n",
      "Epoch: 368/1000 Train loss: 0.244884 Valid loss: 1.744943 Train acc: 0.907090 Valid acc: 0.307487\n",
      "Epoch: 369/1000 Train loss: 0.244266 Valid loss: 1.745389 Train acc: 0.907333 Valid acc: 0.307490\n",
      "Epoch: 370/1000 Train loss: 0.243685 Valid loss: 1.745971 Train acc: 0.907560 Valid acc: 0.307514\n",
      "Epoch: 371/1000 Train loss: 0.243085 Valid loss: 1.746853 Train acc: 0.907793 Valid acc: 0.307526\n",
      "Epoch: 372/1000 Train loss: 0.242498 Valid loss: 1.747824 Train acc: 0.908008 Valid acc: 0.307539\n",
      "Epoch: 373/1000 Train loss: 0.241897 Valid loss: 1.748796 Train acc: 0.908235 Valid acc: 0.307561\n",
      "Epoch: 374/1000 Train loss: 0.241311 Valid loss: 1.749640 Train acc: 0.908444 Valid acc: 0.307541\n",
      "Epoch: 375/1000 Train loss: 0.240708 Valid loss: 1.750598 Train acc: 0.908681 Valid acc: 0.307562\n",
      "Epoch: 376/1000 Train loss: 0.240127 Valid loss: 1.751824 Train acc: 0.908904 Valid acc: 0.307586\n",
      "Epoch: 377/1000 Train loss: 0.239539 Valid loss: 1.753030 Train acc: 0.909122 Valid acc: 0.307535\n",
      "Epoch: 378/1000 Train loss: 0.238960 Valid loss: 1.754575 Train acc: 0.909350 Valid acc: 0.307509\n",
      "Epoch: 379/1000 Train loss: 0.238367 Valid loss: 1.756148 Train acc: 0.909581 Valid acc: 0.307482\n",
      "Epoch: 380/1000 Train loss: 0.237762 Valid loss: 1.757777 Train acc: 0.909804 Valid acc: 0.307459\n",
      "Epoch: 381/1000 Train loss: 0.237175 Valid loss: 1.759267 Train acc: 0.910021 Valid acc: 0.307412\n",
      "Epoch: 382/1000 Train loss: 0.236567 Valid loss: 1.760780 Train acc: 0.910256 Valid acc: 0.307369\n",
      "Epoch: 383/1000 Train loss: 0.235981 Valid loss: 1.762233 Train acc: 0.910475 Valid acc: 0.307342\n",
      "Epoch: 384/1000 Train loss: 0.235437 Valid loss: 1.763650 Train acc: 0.910677 Valid acc: 0.307331\n",
      "Epoch: 385/1000 Train loss: 0.234898 Valid loss: 1.764904 Train acc: 0.910890 Valid acc: 0.307341\n",
      "Epoch: 386/1000 Train loss: 0.234320 Valid loss: 1.766045 Train acc: 0.911113 Valid acc: 0.307329\n",
      "Epoch: 387/1000 Train loss: 0.233823 Valid loss: 1.767164 Train acc: 0.911308 Valid acc: 0.307296\n",
      "Epoch: 388/1000 Train loss: 0.233275 Valid loss: 1.768327 Train acc: 0.911513 Valid acc: 0.307254\n",
      "Epoch: 389/1000 Train loss: 0.232751 Valid loss: 1.769739 Train acc: 0.911729 Valid acc: 0.307230\n",
      "Epoch: 390/1000 Train loss: 0.232306 Valid loss: 1.770973 Train acc: 0.911921 Valid acc: 0.307206\n",
      "Epoch: 391/1000 Train loss: 0.231759 Valid loss: 1.772235 Train acc: 0.912127 Valid acc: 0.307169\n",
      "Epoch: 392/1000 Train loss: 0.231202 Valid loss: 1.773918 Train acc: 0.912340 Valid acc: 0.307120\n",
      "Epoch: 393/1000 Train loss: 0.230655 Valid loss: 1.775810 Train acc: 0.912552 Valid acc: 0.307064\n",
      "Epoch: 394/1000 Train loss: 0.230134 Valid loss: 1.777268 Train acc: 0.912743 Valid acc: 0.307001\n",
      "Epoch: 395/1000 Train loss: 0.229595 Valid loss: 1.778812 Train acc: 0.912945 Valid acc: 0.306955\n",
      "Epoch: 396/1000 Train loss: 0.229039 Valid loss: 1.780163 Train acc: 0.913158 Valid acc: 0.306920\n",
      "Epoch: 397/1000 Train loss: 0.228489 Valid loss: 1.781476 Train acc: 0.913369 Valid acc: 0.306909\n",
      "Epoch: 398/1000 Train loss: 0.227941 Valid loss: 1.782817 Train acc: 0.913579 Valid acc: 0.306887\n",
      "Epoch: 399/1000 Train loss: 0.227505 Valid loss: 1.784374 Train acc: 0.913762 Valid acc: 0.306869\n",
      "Epoch: 400/1000 Train loss: 0.226992 Valid loss: 1.786043 Train acc: 0.913952 Valid acc: 0.306796\n",
      "Epoch: 401/1000 Train loss: 0.226508 Valid loss: 1.787448 Train acc: 0.914151 Valid acc: 0.306774\n",
      "Epoch: 402/1000 Train loss: 0.226059 Valid loss: 1.788955 Train acc: 0.914331 Valid acc: 0.306768\n",
      "Epoch: 403/1000 Train loss: 0.225579 Valid loss: 1.790312 Train acc: 0.914518 Valid acc: 0.306757\n",
      "Epoch: 404/1000 Train loss: 0.225071 Valid loss: 1.791249 Train acc: 0.914715 Valid acc: 0.306770\n",
      "Epoch: 405/1000 Train loss: 0.224656 Valid loss: 1.792356 Train acc: 0.914903 Valid acc: 0.306749\n",
      "Epoch: 406/1000 Train loss: 0.224166 Valid loss: 1.793898 Train acc: 0.915087 Valid acc: 0.306678\n",
      "Epoch: 407/1000 Train loss: 0.223659 Valid loss: 1.795516 Train acc: 0.915285 Valid acc: 0.306602\n",
      "Epoch: 408/1000 Train loss: 0.223152 Valid loss: 1.797206 Train acc: 0.915481 Valid acc: 0.306547\n",
      "Epoch: 409/1000 Train loss: 0.222635 Valid loss: 1.799003 Train acc: 0.915673 Valid acc: 0.306527\n",
      "Epoch: 410/1000 Train loss: 0.222141 Valid loss: 1.800723 Train acc: 0.915865 Valid acc: 0.306506\n",
      "Epoch: 411/1000 Train loss: 0.221640 Valid loss: 1.802374 Train acc: 0.916055 Valid acc: 0.306500\n",
      "Epoch: 412/1000 Train loss: 0.221127 Valid loss: 1.803901 Train acc: 0.916251 Valid acc: 0.306427\n",
      "Epoch: 413/1000 Train loss: 0.220651 Valid loss: 1.805537 Train acc: 0.916429 Valid acc: 0.306374\n",
      "Epoch: 414/1000 Train loss: 0.220215 Valid loss: 1.807279 Train acc: 0.916602 Valid acc: 0.306333\n",
      "Epoch: 415/1000 Train loss: 0.219770 Valid loss: 1.808981 Train acc: 0.916778 Valid acc: 0.306280\n",
      "Epoch: 416/1000 Train loss: 0.219287 Valid loss: 1.810680 Train acc: 0.916960 Valid acc: 0.306238\n",
      "Epoch: 417/1000 Train loss: 0.218840 Valid loss: 1.812404 Train acc: 0.917152 Valid acc: 0.306191\n",
      "Epoch: 418/1000 Train loss: 0.218417 Valid loss: 1.814240 Train acc: 0.917325 Valid acc: 0.306169\n",
      "Epoch: 419/1000 Train loss: 0.217915 Valid loss: 1.816010 Train acc: 0.917519 Valid acc: 0.306136\n",
      "Epoch: 420/1000 Train loss: 0.217435 Valid loss: 1.817471 Train acc: 0.917704 Valid acc: 0.306087\n",
      "Epoch: 421/1000 Train loss: 0.216963 Valid loss: 1.818644 Train acc: 0.917882 Valid acc: 0.306075\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 422/1000 Train loss: 0.216491 Valid loss: 1.819852 Train acc: 0.918063 Valid acc: 0.306015\n",
      "Epoch: 423/1000 Train loss: 0.216037 Valid loss: 1.821036 Train acc: 0.918239 Valid acc: 0.305963\n",
      "Epoch: 424/1000 Train loss: 0.215549 Valid loss: 1.822117 Train acc: 0.918421 Valid acc: 0.305915\n",
      "Epoch: 425/1000 Train loss: 0.215088 Valid loss: 1.823203 Train acc: 0.918595 Valid acc: 0.305889\n",
      "Epoch: 426/1000 Train loss: 0.214602 Valid loss: 1.824334 Train acc: 0.918783 Valid acc: 0.305823\n",
      "Epoch: 427/1000 Train loss: 0.214122 Valid loss: 1.825514 Train acc: 0.918959 Valid acc: 0.305770\n",
      "Epoch: 428/1000 Train loss: 0.213652 Valid loss: 1.826600 Train acc: 0.919134 Valid acc: 0.305737\n",
      "Epoch: 429/1000 Train loss: 0.213172 Valid loss: 1.827752 Train acc: 0.919320 Valid acc: 0.305734\n",
      "Epoch: 430/1000 Train loss: 0.212732 Valid loss: 1.829156 Train acc: 0.919483 Valid acc: 0.305729\n",
      "Epoch: 431/1000 Train loss: 0.212354 Valid loss: 1.830899 Train acc: 0.919635 Valid acc: 0.305722\n",
      "Epoch: 432/1000 Train loss: 0.212067 Valid loss: 1.831868 Train acc: 0.919780 Valid acc: 0.305754\n",
      "Epoch: 433/1000 Train loss: 0.211658 Valid loss: 1.832389 Train acc: 0.919941 Valid acc: 0.305807\n",
      "Epoch: 434/1000 Train loss: 0.211220 Valid loss: 1.833101 Train acc: 0.920108 Valid acc: 0.305849\n",
      "Epoch: 435/1000 Train loss: 0.210796 Valid loss: 1.833869 Train acc: 0.920264 Valid acc: 0.305870\n",
      "Epoch: 436/1000 Train loss: 0.210365 Valid loss: 1.834749 Train acc: 0.920437 Valid acc: 0.305858\n",
      "Epoch: 437/1000 Train loss: 0.209937 Valid loss: 1.835852 Train acc: 0.920598 Valid acc: 0.305878\n",
      "Epoch: 438/1000 Train loss: 0.209559 Valid loss: 1.836954 Train acc: 0.920749 Valid acc: 0.305916\n",
      "Epoch: 439/1000 Train loss: 0.209179 Valid loss: 1.837617 Train acc: 0.920892 Valid acc: 0.305957\n",
      "Epoch: 440/1000 Train loss: 0.208761 Valid loss: 1.838342 Train acc: 0.921062 Valid acc: 0.305967\n",
      "Epoch: 441/1000 Train loss: 0.208338 Valid loss: 1.839233 Train acc: 0.921231 Valid acc: 0.305950\n",
      "Epoch: 442/1000 Train loss: 0.207937 Valid loss: 1.840145 Train acc: 0.921382 Valid acc: 0.305944\n",
      "Epoch: 443/1000 Train loss: 0.207515 Valid loss: 1.841139 Train acc: 0.921539 Valid acc: 0.305926\n",
      "Epoch: 444/1000 Train loss: 0.207099 Valid loss: 1.842346 Train acc: 0.921692 Valid acc: 0.305937\n",
      "Epoch: 445/1000 Train loss: 0.206701 Valid loss: 1.843081 Train acc: 0.921841 Valid acc: 0.305915\n",
      "Epoch: 446/1000 Train loss: 0.206295 Valid loss: 1.843677 Train acc: 0.922000 Valid acc: 0.305939\n",
      "Epoch: 447/1000 Train loss: 0.205863 Valid loss: 1.844402 Train acc: 0.922164 Valid acc: 0.305929\n",
      "Epoch: 448/1000 Train loss: 0.205443 Valid loss: 1.845235 Train acc: 0.922321 Valid acc: 0.305908\n",
      "Epoch: 449/1000 Train loss: 0.205033 Valid loss: 1.846123 Train acc: 0.922474 Valid acc: 0.305859\n",
      "Epoch: 450/1000 Train loss: 0.204587 Valid loss: 1.846990 Train acc: 0.922643 Valid acc: 0.305818\n",
      "Epoch: 451/1000 Train loss: 0.204181 Valid loss: 1.847899 Train acc: 0.922799 Valid acc: 0.305801\n",
      "Epoch: 452/1000 Train loss: 0.203742 Valid loss: 1.848928 Train acc: 0.922966 Valid acc: 0.305780\n",
      "Epoch: 453/1000 Train loss: 0.203327 Valid loss: 1.849955 Train acc: 0.923123 Valid acc: 0.305755\n",
      "Epoch: 454/1000 Train loss: 0.202888 Valid loss: 1.850953 Train acc: 0.923289 Valid acc: 0.305756\n",
      "Epoch: 455/1000 Train loss: 0.202472 Valid loss: 1.851804 Train acc: 0.923451 Valid acc: 0.305754\n",
      "Epoch: 456/1000 Train loss: 0.202076 Valid loss: 1.852533 Train acc: 0.923593 Valid acc: 0.305766\n",
      "Epoch: 457/1000 Train loss: 0.201645 Valid loss: 1.853119 Train acc: 0.923757 Valid acc: 0.305753\n",
      "Epoch: 458/1000 Train loss: 0.201253 Valid loss: 1.853685 Train acc: 0.923913 Valid acc: 0.305740\n",
      "Epoch: 459/1000 Train loss: 0.200873 Valid loss: 1.854474 Train acc: 0.924059 Valid acc: 0.305761\n",
      "Epoch: 460/1000 Train loss: 0.200476 Valid loss: 1.855773 Train acc: 0.924215 Valid acc: 0.305758\n",
      "Epoch: 461/1000 Train loss: 0.200136 Valid loss: 1.857619 Train acc: 0.924344 Valid acc: 0.305750\n",
      "Epoch: 462/1000 Train loss: 0.199826 Valid loss: 1.858971 Train acc: 0.924469 Valid acc: 0.305771\n",
      "Epoch: 463/1000 Train loss: 0.199468 Valid loss: 1.859787 Train acc: 0.924619 Valid acc: 0.305764\n",
      "Epoch: 464/1000 Train loss: 0.199061 Valid loss: 1.860603 Train acc: 0.924775 Valid acc: 0.305772\n",
      "Epoch: 465/1000 Train loss: 0.198735 Valid loss: 1.861663 Train acc: 0.924914 Valid acc: 0.305794\n",
      "Epoch: 466/1000 Train loss: 0.198353 Valid loss: 1.863104 Train acc: 0.925056 Valid acc: 0.305806\n",
      "Epoch: 467/1000 Train loss: 0.197948 Valid loss: 1.864372 Train acc: 0.925210 Valid acc: 0.305820\n",
      "Epoch: 468/1000 Train loss: 0.197571 Valid loss: 1.865774 Train acc: 0.925363 Valid acc: 0.305842\n",
      "Epoch: 469/1000 Train loss: 0.197204 Valid loss: 1.866910 Train acc: 0.925507 Valid acc: 0.305841\n",
      "Epoch: 470/1000 Train loss: 0.196828 Valid loss: 1.868134 Train acc: 0.925649 Valid acc: 0.305891\n",
      "Epoch: 471/1000 Train loss: 0.196428 Valid loss: 1.869248 Train acc: 0.925795 Valid acc: 0.305946\n",
      "Epoch: 472/1000 Train loss: 0.196044 Valid loss: 1.870110 Train acc: 0.925942 Valid acc: 0.306007\n",
      "Epoch: 473/1000 Train loss: 0.195653 Valid loss: 1.870812 Train acc: 0.926089 Valid acc: 0.306032\n",
      "Epoch: 474/1000 Train loss: 0.195258 Valid loss: 1.871416 Train acc: 0.926239 Valid acc: 0.306057\n",
      "Epoch: 475/1000 Train loss: 0.194881 Valid loss: 1.872340 Train acc: 0.926379 Valid acc: 0.306056\n",
      "Epoch: 476/1000 Train loss: 0.194530 Valid loss: 1.873441 Train acc: 0.926511 Valid acc: 0.306041\n",
      "Epoch: 477/1000 Train loss: 0.194296 Valid loss: 1.874289 Train acc: 0.926634 Valid acc: 0.306016\n",
      "Epoch: 478/1000 Train loss: 0.193991 Valid loss: 1.874974 Train acc: 0.926769 Valid acc: 0.305979\n",
      "Epoch: 479/1000 Train loss: 0.193642 Valid loss: 1.875754 Train acc: 0.926897 Valid acc: 0.305957\n",
      "Epoch: 480/1000 Train loss: 0.193274 Valid loss: 1.876776 Train acc: 0.927043 Valid acc: 0.305973\n",
      "Epoch: 481/1000 Train loss: 0.192928 Valid loss: 1.877924 Train acc: 0.927179 Valid acc: 0.305961\n",
      "Epoch: 482/1000 Train loss: 0.192591 Valid loss: 1.879052 Train acc: 0.927318 Valid acc: 0.305996\n",
      "Epoch: 483/1000 Train loss: 0.192271 Valid loss: 1.879264 Train acc: 0.927444 Valid acc: 0.306010\n",
      "Epoch: 484/1000 Train loss: 0.191901 Valid loss: 1.879587 Train acc: 0.927584 Valid acc: 0.306003\n",
      "Epoch: 485/1000 Train loss: 0.191562 Valid loss: 1.880115 Train acc: 0.927712 Valid acc: 0.306006\n",
      "Epoch: 486/1000 Train loss: 0.191196 Valid loss: 1.880679 Train acc: 0.927851 Valid acc: 0.305972\n",
      "Epoch: 487/1000 Train loss: 0.190839 Valid loss: 1.881394 Train acc: 0.927987 Valid acc: 0.305931\n",
      "Epoch: 488/1000 Train loss: 0.190552 Valid loss: 1.882216 Train acc: 0.928120 Valid acc: 0.305892\n",
      "Epoch: 489/1000 Train loss: 0.190183 Valid loss: 1.883047 Train acc: 0.928261 Valid acc: 0.305847\n",
      "Epoch: 490/1000 Train loss: 0.189817 Valid loss: 1.883831 Train acc: 0.928401 Valid acc: 0.305793\n",
      "Epoch: 491/1000 Train loss: 0.189453 Valid loss: 1.884816 Train acc: 0.928541 Valid acc: 0.305757\n",
      "Epoch: 492/1000 Train loss: 0.189089 Valid loss: 1.885861 Train acc: 0.928680 Valid acc: 0.305704\n",
      "Epoch: 493/1000 Train loss: 0.188727 Valid loss: 1.887071 Train acc: 0.928818 Valid acc: 0.305639\n",
      "Epoch: 494/1000 Train loss: 0.188379 Valid loss: 1.888150 Train acc: 0.928950 Valid acc: 0.305598\n",
      "Epoch: 495/1000 Train loss: 0.188035 Valid loss: 1.889205 Train acc: 0.929079 Valid acc: 0.305565\n",
      "Epoch: 496/1000 Train loss: 0.187665 Valid loss: 1.890498 Train acc: 0.929222 Valid acc: 0.305554\n",
      "Epoch: 497/1000 Train loss: 0.187318 Valid loss: 1.891741 Train acc: 0.929355 Valid acc: 0.305524\n",
      "Epoch: 498/1000 Train loss: 0.186949 Valid loss: 1.893093 Train acc: 0.929497 Valid acc: 0.305528\n",
      "Epoch: 499/1000 Train loss: 0.186597 Valid loss: 1.894355 Train acc: 0.929632 Valid acc: 0.305534\n",
      "Epoch: 500/1000 Train loss: 0.186282 Valid loss: 1.895541 Train acc: 0.929755 Valid acc: 0.305496\n",
      "Epoch: 501/1000 Train loss: 0.185937 Valid loss: 1.896474 Train acc: 0.929887 Valid acc: 0.305475\n",
      "Epoch: 502/1000 Train loss: 0.185609 Valid loss: 1.897914 Train acc: 0.930014 Valid acc: 0.305466\n",
      "Epoch: 503/1000 Train loss: 0.185252 Valid loss: 1.899126 Train acc: 0.930147 Valid acc: 0.305468\n",
      "Epoch: 504/1000 Train loss: 0.184901 Valid loss: 1.900543 Train acc: 0.930280 Valid acc: 0.305463\n",
      "Epoch: 505/1000 Train loss: 0.184556 Valid loss: 1.902020 Train acc: 0.930409 Valid acc: 0.305470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 506/1000 Train loss: 0.184213 Valid loss: 1.903382 Train acc: 0.930544 Valid acc: 0.305491\n",
      "Epoch: 507/1000 Train loss: 0.183884 Valid loss: 1.904629 Train acc: 0.930669 Valid acc: 0.305481\n",
      "Epoch: 508/1000 Train loss: 0.183539 Valid loss: 1.905652 Train acc: 0.930803 Valid acc: 0.305503\n",
      "Epoch: 509/1000 Train loss: 0.183239 Valid loss: 1.906829 Train acc: 0.930924 Valid acc: 0.305510\n",
      "Epoch: 510/1000 Train loss: 0.182965 Valid loss: 1.907950 Train acc: 0.931042 Valid acc: 0.305447\n",
      "Epoch: 511/1000 Train loss: 0.182657 Valid loss: 1.909188 Train acc: 0.931165 Valid acc: 0.305401\n",
      "Epoch: 512/1000 Train loss: 0.182331 Valid loss: 1.910985 Train acc: 0.931285 Valid acc: 0.305365\n",
      "Epoch: 513/1000 Train loss: 0.181991 Valid loss: 1.912558 Train acc: 0.931413 Valid acc: 0.305358\n",
      "Epoch: 514/1000 Train loss: 0.181672 Valid loss: 1.913990 Train acc: 0.931532 Valid acc: 0.305321\n",
      "Epoch: 515/1000 Train loss: 0.181393 Valid loss: 1.915477 Train acc: 0.931656 Valid acc: 0.305282\n",
      "Epoch: 516/1000 Train loss: 0.181061 Valid loss: 1.916809 Train acc: 0.931780 Valid acc: 0.305257\n",
      "Epoch: 517/1000 Train loss: 0.180744 Valid loss: 1.917998 Train acc: 0.931903 Valid acc: 0.305273\n",
      "Epoch: 518/1000 Train loss: 0.180463 Valid loss: 1.919055 Train acc: 0.932012 Valid acc: 0.305305\n",
      "Epoch: 519/1000 Train loss: 0.180149 Valid loss: 1.920213 Train acc: 0.932126 Valid acc: 0.305341\n",
      "Epoch: 520/1000 Train loss: 0.179866 Valid loss: 1.921178 Train acc: 0.932242 Valid acc: 0.305329\n",
      "Epoch: 521/1000 Train loss: 0.179541 Valid loss: 1.921851 Train acc: 0.932363 Valid acc: 0.305285\n",
      "Epoch: 522/1000 Train loss: 0.179216 Valid loss: 1.922525 Train acc: 0.932487 Valid acc: 0.305233\n",
      "Epoch: 523/1000 Train loss: 0.178908 Valid loss: 1.923311 Train acc: 0.932605 Valid acc: 0.305181\n",
      "Epoch: 524/1000 Train loss: 0.178609 Valid loss: 1.924152 Train acc: 0.932716 Valid acc: 0.305161\n",
      "Epoch: 525/1000 Train loss: 0.178310 Valid loss: 1.925102 Train acc: 0.932830 Valid acc: 0.305153\n",
      "Epoch: 526/1000 Train loss: 0.177993 Valid loss: 1.926220 Train acc: 0.932946 Valid acc: 0.305157\n",
      "Epoch: 527/1000 Train loss: 0.177694 Valid loss: 1.927562 Train acc: 0.933068 Valid acc: 0.305191\n",
      "Epoch: 528/1000 Train loss: 0.177393 Valid loss: 1.928662 Train acc: 0.933178 Valid acc: 0.305189\n",
      "Epoch: 529/1000 Train loss: 0.177109 Valid loss: 1.929678 Train acc: 0.933293 Valid acc: 0.305138\n",
      "Epoch: 530/1000 Train loss: 0.176827 Valid loss: 1.930677 Train acc: 0.933407 Valid acc: 0.305098\n",
      "Epoch: 531/1000 Train loss: 0.176529 Valid loss: 1.931887 Train acc: 0.933519 Valid acc: 0.305062\n",
      "Epoch: 532/1000 Train loss: 0.176216 Valid loss: 1.933096 Train acc: 0.933635 Valid acc: 0.305064\n",
      "Epoch: 533/1000 Train loss: 0.175902 Valid loss: 1.934275 Train acc: 0.933754 Valid acc: 0.305043\n",
      "Epoch: 534/1000 Train loss: 0.175606 Valid loss: 1.935325 Train acc: 0.933870 Valid acc: 0.305001\n",
      "Epoch: 535/1000 Train loss: 0.175292 Valid loss: 1.936300 Train acc: 0.933988 Valid acc: 0.304946\n",
      "Epoch: 536/1000 Train loss: 0.174992 Valid loss: 1.937128 Train acc: 0.934103 Valid acc: 0.304911\n",
      "Epoch: 537/1000 Train loss: 0.174692 Valid loss: 1.938001 Train acc: 0.934217 Valid acc: 0.304895\n",
      "Epoch: 538/1000 Train loss: 0.174394 Valid loss: 1.938920 Train acc: 0.934331 Valid acc: 0.304882\n",
      "Epoch: 539/1000 Train loss: 0.174098 Valid loss: 1.939815 Train acc: 0.934445 Valid acc: 0.304866\n",
      "Epoch: 540/1000 Train loss: 0.173791 Valid loss: 1.940787 Train acc: 0.934558 Valid acc: 0.304870\n",
      "Epoch: 541/1000 Train loss: 0.173495 Valid loss: 1.941662 Train acc: 0.934671 Valid acc: 0.304909\n",
      "Epoch: 542/1000 Train loss: 0.173213 Valid loss: 1.942404 Train acc: 0.934780 Valid acc: 0.304933\n",
      "Epoch: 543/1000 Train loss: 0.172955 Valid loss: 1.943299 Train acc: 0.934878 Valid acc: 0.304969\n",
      "Epoch: 544/1000 Train loss: 0.172714 Valid loss: 1.944587 Train acc: 0.934981 Valid acc: 0.304998\n",
      "Epoch: 545/1000 Train loss: 0.172450 Valid loss: 1.946046 Train acc: 0.935084 Valid acc: 0.305014\n",
      "Epoch: 546/1000 Train loss: 0.172207 Valid loss: 1.947400 Train acc: 0.935189 Valid acc: 0.305028\n",
      "Epoch: 547/1000 Train loss: 0.171919 Valid loss: 1.948580 Train acc: 0.935300 Valid acc: 0.305034\n",
      "Epoch: 548/1000 Train loss: 0.171641 Valid loss: 1.949804 Train acc: 0.935407 Valid acc: 0.305053\n",
      "Epoch: 549/1000 Train loss: 0.171386 Valid loss: 1.950959 Train acc: 0.935503 Valid acc: 0.305045\n",
      "Epoch: 550/1000 Train loss: 0.171142 Valid loss: 1.951658 Train acc: 0.935604 Valid acc: 0.305037\n",
      "Epoch: 551/1000 Train loss: 0.170939 Valid loss: 1.952550 Train acc: 0.935694 Valid acc: 0.305031\n",
      "Epoch: 552/1000 Train loss: 0.170824 Valid loss: 1.953306 Train acc: 0.935783 Valid acc: 0.305017\n",
      "Epoch: 553/1000 Train loss: 0.170637 Valid loss: 1.954142 Train acc: 0.935875 Valid acc: 0.305034\n",
      "Epoch: 554/1000 Train loss: 0.170431 Valid loss: 1.955216 Train acc: 0.935966 Valid acc: 0.305041\n",
      "Epoch: 555/1000 Train loss: 0.170160 Valid loss: 1.956277 Train acc: 0.936068 Valid acc: 0.305013\n",
      "Epoch: 556/1000 Train loss: 0.169877 Valid loss: 1.957397 Train acc: 0.936170 Valid acc: 0.305004\n",
      "Epoch: 557/1000 Train loss: 0.169678 Valid loss: 1.958830 Train acc: 0.936258 Valid acc: 0.304983\n",
      "Epoch: 558/1000 Train loss: 0.169424 Valid loss: 1.959641 Train acc: 0.936353 Valid acc: 0.304970\n",
      "Epoch: 559/1000 Train loss: 0.169154 Valid loss: 1.960273 Train acc: 0.936462 Valid acc: 0.304946\n",
      "Epoch: 560/1000 Train loss: 0.168908 Valid loss: 1.960863 Train acc: 0.936556 Valid acc: 0.304945\n",
      "Epoch: 561/1000 Train loss: 0.168665 Valid loss: 1.961301 Train acc: 0.936648 Valid acc: 0.304944\n",
      "Epoch: 562/1000 Train loss: 0.168444 Valid loss: 1.961763 Train acc: 0.936753 Valid acc: 0.304922\n",
      "Epoch: 563/1000 Train loss: 0.168215 Valid loss: 1.962500 Train acc: 0.936852 Valid acc: 0.304896\n",
      "Epoch: 564/1000 Train loss: 0.167970 Valid loss: 1.963412 Train acc: 0.936956 Valid acc: 0.304882\n",
      "Epoch: 565/1000 Train loss: 0.167693 Valid loss: 1.964472 Train acc: 0.937063 Valid acc: 0.304873\n",
      "Epoch: 566/1000 Train loss: 0.167444 Valid loss: 1.965622 Train acc: 0.937163 Valid acc: 0.304876\n",
      "Epoch: 567/1000 Train loss: 0.167244 Valid loss: 1.966670 Train acc: 0.937253 Valid acc: 0.304849\n",
      "Epoch: 568/1000 Train loss: 0.166987 Valid loss: 1.967717 Train acc: 0.937345 Valid acc: 0.304793\n",
      "Epoch: 569/1000 Train loss: 0.166726 Valid loss: 1.968797 Train acc: 0.937447 Valid acc: 0.304804\n",
      "Epoch: 570/1000 Train loss: 0.166487 Valid loss: 1.969917 Train acc: 0.937544 Valid acc: 0.304817\n",
      "Epoch: 571/1000 Train loss: 0.166219 Valid loss: 1.971081 Train acc: 0.937638 Valid acc: 0.304798\n",
      "Epoch: 572/1000 Train loss: 0.165938 Valid loss: 1.972309 Train acc: 0.937744 Valid acc: 0.304778\n",
      "Epoch: 573/1000 Train loss: 0.165676 Valid loss: 1.973416 Train acc: 0.937847 Valid acc: 0.304762\n",
      "Epoch: 574/1000 Train loss: 0.165448 Valid loss: 1.974428 Train acc: 0.937937 Valid acc: 0.304760\n",
      "Epoch: 575/1000 Train loss: 0.165202 Valid loss: 1.975505 Train acc: 0.938030 Valid acc: 0.304703\n",
      "Epoch: 576/1000 Train loss: 0.164984 Valid loss: 1.976753 Train acc: 0.938127 Valid acc: 0.304653\n",
      "Epoch: 577/1000 Train loss: 0.164802 Valid loss: 1.977768 Train acc: 0.938216 Valid acc: 0.304631\n",
      "Epoch: 578/1000 Train loss: 0.164556 Valid loss: 1.978833 Train acc: 0.938305 Valid acc: 0.304566\n",
      "Epoch: 579/1000 Train loss: 0.164288 Valid loss: 1.979906 Train acc: 0.938406 Valid acc: 0.304529\n",
      "Epoch: 580/1000 Train loss: 0.164031 Valid loss: 1.980990 Train acc: 0.938502 Valid acc: 0.304486\n",
      "Epoch: 581/1000 Train loss: 0.163783 Valid loss: 1.982005 Train acc: 0.938598 Valid acc: 0.304420\n",
      "Epoch: 582/1000 Train loss: 0.163561 Valid loss: 1.983084 Train acc: 0.938688 Valid acc: 0.304388\n",
      "Epoch: 583/1000 Train loss: 0.163310 Valid loss: 1.984184 Train acc: 0.938775 Valid acc: 0.304360\n",
      "Epoch: 584/1000 Train loss: 0.163057 Valid loss: 1.985174 Train acc: 0.938867 Valid acc: 0.304364\n",
      "Epoch: 585/1000 Train loss: 0.162820 Valid loss: 1.986112 Train acc: 0.938956 Valid acc: 0.304386\n",
      "Epoch: 586/1000 Train loss: 0.162579 Valid loss: 1.986958 Train acc: 0.939045 Valid acc: 0.304377\n",
      "Epoch: 587/1000 Train loss: 0.162360 Valid loss: 1.988037 Train acc: 0.939137 Valid acc: 0.304385\n",
      "Epoch: 588/1000 Train loss: 0.162110 Valid loss: 1.989810 Train acc: 0.939230 Valid acc: 0.304360\n",
      "Epoch: 589/1000 Train loss: 0.162005 Valid loss: 1.991281 Train acc: 0.939315 Valid acc: 0.304361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 590/1000 Train loss: 0.161860 Valid loss: 1.992334 Train acc: 0.939375 Valid acc: 0.304351\n",
      "Epoch: 591/1000 Train loss: 0.161633 Valid loss: 1.993435 Train acc: 0.939463 Valid acc: 0.304355\n",
      "Epoch: 592/1000 Train loss: 0.161407 Valid loss: 1.994870 Train acc: 0.939552 Valid acc: 0.304333\n",
      "Epoch: 593/1000 Train loss: 0.161172 Valid loss: 1.996060 Train acc: 0.939644 Valid acc: 0.304330\n",
      "Epoch: 594/1000 Train loss: 0.160925 Valid loss: 1.996807 Train acc: 0.939738 Valid acc: 0.304306\n",
      "Epoch: 595/1000 Train loss: 0.160687 Valid loss: 1.997729 Train acc: 0.939827 Valid acc: 0.304286\n",
      "Epoch: 596/1000 Train loss: 0.160438 Valid loss: 1.999095 Train acc: 0.939923 Valid acc: 0.304266\n",
      "Epoch: 597/1000 Train loss: 0.160198 Valid loss: 2.000802 Train acc: 0.940019 Valid acc: 0.304218\n",
      "Epoch: 598/1000 Train loss: 0.159973 Valid loss: 2.002082 Train acc: 0.940106 Valid acc: 0.304183\n",
      "Epoch: 599/1000 Train loss: 0.159744 Valid loss: 2.003194 Train acc: 0.940199 Valid acc: 0.304133\n",
      "Epoch: 600/1000 Train loss: 0.159525 Valid loss: 2.004448 Train acc: 0.940281 Valid acc: 0.304082\n",
      "Epoch: 601/1000 Train loss: 0.159299 Valid loss: 2.006066 Train acc: 0.940365 Valid acc: 0.304068\n",
      "Epoch: 602/1000 Train loss: 0.159065 Valid loss: 2.007791 Train acc: 0.940452 Valid acc: 0.304039\n",
      "Epoch: 603/1000 Train loss: 0.158827 Valid loss: 2.009361 Train acc: 0.940544 Valid acc: 0.304010\n",
      "Epoch: 604/1000 Train loss: 0.158594 Valid loss: 2.010319 Train acc: 0.940635 Valid acc: 0.304021\n",
      "Epoch: 605/1000 Train loss: 0.158363 Valid loss: 2.011518 Train acc: 0.940715 Valid acc: 0.304014\n",
      "Epoch: 606/1000 Train loss: 0.158124 Valid loss: 2.012426 Train acc: 0.940803 Valid acc: 0.304021\n",
      "Epoch: 607/1000 Train loss: 0.157931 Valid loss: 2.013629 Train acc: 0.940884 Valid acc: 0.304042\n",
      "Epoch: 608/1000 Train loss: 0.157679 Valid loss: 2.015047 Train acc: 0.940979 Valid acc: 0.304074\n",
      "Epoch: 609/1000 Train loss: 0.157437 Valid loss: 2.016358 Train acc: 0.941066 Valid acc: 0.304104\n",
      "Epoch: 610/1000 Train loss: 0.157192 Valid loss: 2.017556 Train acc: 0.941157 Valid acc: 0.304116\n",
      "Epoch: 611/1000 Train loss: 0.156968 Valid loss: 2.018587 Train acc: 0.941246 Valid acc: 0.304133\n",
      "Epoch: 612/1000 Train loss: 0.156737 Valid loss: 2.019607 Train acc: 0.941337 Valid acc: 0.304176\n",
      "Epoch: 613/1000 Train loss: 0.156496 Valid loss: 2.020585 Train acc: 0.941426 Valid acc: 0.304212\n",
      "Epoch: 614/1000 Train loss: 0.156258 Valid loss: 2.021487 Train acc: 0.941519 Valid acc: 0.304221\n",
      "Epoch: 615/1000 Train loss: 0.156023 Valid loss: 2.022529 Train acc: 0.941607 Valid acc: 0.304251\n",
      "Epoch: 616/1000 Train loss: 0.155819 Valid loss: 2.023511 Train acc: 0.941689 Valid acc: 0.304274\n",
      "Epoch: 617/1000 Train loss: 0.155618 Valid loss: 2.024414 Train acc: 0.941774 Valid acc: 0.304276\n",
      "Epoch: 618/1000 Train loss: 0.155394 Valid loss: 2.025553 Train acc: 0.941859 Valid acc: 0.304267\n",
      "Epoch: 619/1000 Train loss: 0.155172 Valid loss: 2.026776 Train acc: 0.941943 Valid acc: 0.304249\n",
      "Epoch: 620/1000 Train loss: 0.154959 Valid loss: 2.028022 Train acc: 0.942027 Valid acc: 0.304249\n",
      "Epoch: 621/1000 Train loss: 0.154782 Valid loss: 2.029316 Train acc: 0.942104 Valid acc: 0.304226\n",
      "Epoch: 622/1000 Train loss: 0.154571 Valid loss: 2.030532 Train acc: 0.942187 Valid acc: 0.304195\n",
      "Epoch: 623/1000 Train loss: 0.154375 Valid loss: 2.031373 Train acc: 0.942261 Valid acc: 0.304155\n",
      "Epoch: 624/1000 Train loss: 0.154186 Valid loss: 2.032138 Train acc: 0.942341 Valid acc: 0.304141\n",
      "Epoch: 625/1000 Train loss: 0.154003 Valid loss: 2.033474 Train acc: 0.942407 Valid acc: 0.304143\n",
      "Epoch: 626/1000 Train loss: 0.153788 Valid loss: 2.034862 Train acc: 0.942494 Valid acc: 0.304127\n",
      "Epoch: 627/1000 Train loss: 0.153603 Valid loss: 2.036023 Train acc: 0.942572 Valid acc: 0.304085\n",
      "Epoch: 628/1000 Train loss: 0.153400 Valid loss: 2.036968 Train acc: 0.942654 Valid acc: 0.304069\n",
      "Epoch: 629/1000 Train loss: 0.153185 Valid loss: 2.037944 Train acc: 0.942735 Valid acc: 0.304049\n",
      "Epoch: 630/1000 Train loss: 0.152959 Valid loss: 2.038681 Train acc: 0.942819 Valid acc: 0.304023\n",
      "Epoch: 631/1000 Train loss: 0.152776 Valid loss: 2.039205 Train acc: 0.942900 Valid acc: 0.304009\n",
      "Epoch: 632/1000 Train loss: 0.152546 Valid loss: 2.039584 Train acc: 0.942986 Valid acc: 0.303959\n",
      "Epoch: 633/1000 Train loss: 0.152345 Valid loss: 2.040048 Train acc: 0.943064 Valid acc: 0.303932\n",
      "Epoch: 634/1000 Train loss: 0.152127 Valid loss: 2.040769 Train acc: 0.943147 Valid acc: 0.303930\n",
      "Epoch: 635/1000 Train loss: 0.151894 Valid loss: 2.041550 Train acc: 0.943234 Valid acc: 0.303923\n",
      "Epoch: 636/1000 Train loss: 0.151696 Valid loss: 2.042397 Train acc: 0.943314 Valid acc: 0.303924\n",
      "Epoch: 637/1000 Train loss: 0.151485 Valid loss: 2.043178 Train acc: 0.943396 Valid acc: 0.303931\n",
      "Epoch: 638/1000 Train loss: 0.151287 Valid loss: 2.043848 Train acc: 0.943480 Valid acc: 0.303920\n",
      "Epoch: 639/1000 Train loss: 0.151071 Valid loss: 2.044456 Train acc: 0.943559 Valid acc: 0.303909\n",
      "Epoch: 640/1000 Train loss: 0.150848 Valid loss: 2.045320 Train acc: 0.943643 Valid acc: 0.303882\n",
      "Epoch: 641/1000 Train loss: 0.150634 Valid loss: 2.046327 Train acc: 0.943726 Valid acc: 0.303870\n",
      "Epoch: 642/1000 Train loss: 0.150411 Valid loss: 2.047297 Train acc: 0.943811 Valid acc: 0.303856\n",
      "Epoch: 643/1000 Train loss: 0.150196 Valid loss: 2.048289 Train acc: 0.943896 Valid acc: 0.303839\n",
      "Epoch: 644/1000 Train loss: 0.150011 Valid loss: 2.049127 Train acc: 0.943972 Valid acc: 0.303811\n",
      "Epoch: 645/1000 Train loss: 0.149788 Valid loss: 2.049880 Train acc: 0.944054 Valid acc: 0.303798\n",
      "Epoch: 646/1000 Train loss: 0.149617 Valid loss: 2.050547 Train acc: 0.944118 Valid acc: 0.303791\n",
      "Epoch: 647/1000 Train loss: 0.149409 Valid loss: 2.051175 Train acc: 0.944195 Valid acc: 0.303758\n",
      "Epoch: 648/1000 Train loss: 0.149196 Valid loss: 2.052001 Train acc: 0.944274 Valid acc: 0.303736\n",
      "Epoch: 649/1000 Train loss: 0.148989 Valid loss: 2.053276 Train acc: 0.944348 Valid acc: 0.303746\n",
      "Epoch: 650/1000 Train loss: 0.148792 Valid loss: 2.054397 Train acc: 0.944427 Valid acc: 0.303753\n",
      "Epoch: 651/1000 Train loss: 0.148591 Valid loss: 2.055526 Train acc: 0.944506 Valid acc: 0.303745\n",
      "Epoch: 652/1000 Train loss: 0.148379 Valid loss: 2.056587 Train acc: 0.944584 Valid acc: 0.303755\n",
      "Epoch: 653/1000 Train loss: 0.148170 Valid loss: 2.057554 Train acc: 0.944664 Valid acc: 0.303730\n",
      "Epoch: 654/1000 Train loss: 0.147978 Valid loss: 2.058491 Train acc: 0.944740 Valid acc: 0.303702\n",
      "Epoch: 655/1000 Train loss: 0.147793 Valid loss: 2.059305 Train acc: 0.944810 Valid acc: 0.303678\n",
      "Epoch: 656/1000 Train loss: 0.147608 Valid loss: 2.059861 Train acc: 0.944881 Valid acc: 0.303689\n",
      "Epoch: 657/1000 Train loss: 0.147491 Valid loss: 2.060477 Train acc: 0.944951 Valid acc: 0.303675\n",
      "Epoch: 658/1000 Train loss: 0.147282 Valid loss: 2.061713 Train acc: 0.945028 Valid acc: 0.303697\n",
      "Epoch: 659/1000 Train loss: 0.147106 Valid loss: 2.062605 Train acc: 0.945098 Valid acc: 0.303706\n",
      "Epoch: 660/1000 Train loss: 0.146947 Valid loss: 2.063425 Train acc: 0.945163 Valid acc: 0.303706\n",
      "Epoch: 661/1000 Train loss: 0.146818 Valid loss: 2.064508 Train acc: 0.945230 Valid acc: 0.303711\n",
      "Epoch: 662/1000 Train loss: 0.146659 Valid loss: 2.065678 Train acc: 0.945290 Valid acc: 0.303721\n",
      "Epoch: 663/1000 Train loss: 0.146536 Valid loss: 2.066403 Train acc: 0.945341 Valid acc: 0.303736\n",
      "Epoch: 664/1000 Train loss: 0.146406 Valid loss: 2.066778 Train acc: 0.945401 Valid acc: 0.303744\n",
      "Epoch: 665/1000 Train loss: 0.146257 Valid loss: 2.067738 Train acc: 0.945449 Valid acc: 0.303767\n",
      "Epoch: 666/1000 Train loss: 0.146226 Valid loss: 2.068914 Train acc: 0.945507 Valid acc: 0.303768\n",
      "Epoch: 667/1000 Train loss: 0.146054 Valid loss: 2.069953 Train acc: 0.945579 Valid acc: 0.303771\n",
      "Epoch: 668/1000 Train loss: 0.145917 Valid loss: 2.071070 Train acc: 0.945641 Valid acc: 0.303783\n",
      "Epoch: 669/1000 Train loss: 0.145780 Valid loss: 2.072378 Train acc: 0.945704 Valid acc: 0.303793\n",
      "Epoch: 670/1000 Train loss: 0.145607 Valid loss: 2.073396 Train acc: 0.945772 Valid acc: 0.303810\n",
      "Epoch: 671/1000 Train loss: 0.145417 Valid loss: 2.074272 Train acc: 0.945846 Valid acc: 0.303815\n",
      "Epoch: 672/1000 Train loss: 0.145238 Valid loss: 2.075626 Train acc: 0.945909 Valid acc: 0.303829\n",
      "Epoch: 673/1000 Train loss: 0.145087 Valid loss: 2.077192 Train acc: 0.945971 Valid acc: 0.303837\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 674/1000 Train loss: 0.144937 Valid loss: 2.078542 Train acc: 0.946034 Valid acc: 0.303819\n",
      "Epoch: 675/1000 Train loss: 0.144796 Valid loss: 2.079869 Train acc: 0.946098 Valid acc: 0.303776\n",
      "Epoch: 676/1000 Train loss: 0.144611 Valid loss: 2.080993 Train acc: 0.946165 Valid acc: 0.303733\n",
      "Epoch: 677/1000 Train loss: 0.144456 Valid loss: 2.082199 Train acc: 0.946229 Valid acc: 0.303716\n",
      "Epoch: 678/1000 Train loss: 0.144259 Valid loss: 2.083701 Train acc: 0.946302 Valid acc: 0.303678\n",
      "Epoch: 679/1000 Train loss: 0.144081 Valid loss: 2.085406 Train acc: 0.946368 Valid acc: 0.303690\n",
      "Epoch: 680/1000 Train loss: 0.143929 Valid loss: 2.087323 Train acc: 0.946431 Valid acc: 0.303716\n",
      "Epoch: 681/1000 Train loss: 0.143804 Valid loss: 2.089056 Train acc: 0.946490 Valid acc: 0.303734\n",
      "Epoch: 682/1000 Train loss: 0.143613 Valid loss: 2.090393 Train acc: 0.946560 Valid acc: 0.303747\n",
      "Epoch: 683/1000 Train loss: 0.143430 Valid loss: 2.091723 Train acc: 0.946629 Valid acc: 0.303766\n",
      "Epoch: 684/1000 Train loss: 0.143284 Valid loss: 2.093133 Train acc: 0.946692 Valid acc: 0.303809\n",
      "Epoch: 685/1000 Train loss: 0.143125 Valid loss: 2.094372 Train acc: 0.946755 Valid acc: 0.303801\n",
      "Epoch: 686/1000 Train loss: 0.142972 Valid loss: 2.095466 Train acc: 0.946815 Valid acc: 0.303784\n",
      "Epoch: 687/1000 Train loss: 0.142795 Valid loss: 2.097120 Train acc: 0.946886 Valid acc: 0.303782\n",
      "Epoch: 688/1000 Train loss: 0.142650 Valid loss: 2.098482 Train acc: 0.946952 Valid acc: 0.303764\n",
      "Epoch: 689/1000 Train loss: 0.142487 Valid loss: 2.099832 Train acc: 0.947014 Valid acc: 0.303760\n",
      "Epoch: 690/1000 Train loss: 0.142327 Valid loss: 2.101065 Train acc: 0.947082 Valid acc: 0.303745\n",
      "Epoch: 691/1000 Train loss: 0.142130 Valid loss: 2.101928 Train acc: 0.947152 Valid acc: 0.303706\n",
      "Epoch: 692/1000 Train loss: 0.141960 Valid loss: 2.102638 Train acc: 0.947220 Valid acc: 0.303675\n",
      "Epoch: 693/1000 Train loss: 0.141782 Valid loss: 2.103683 Train acc: 0.947290 Valid acc: 0.303660\n",
      "Epoch: 694/1000 Train loss: 0.141638 Valid loss: 2.104840 Train acc: 0.947348 Valid acc: 0.303632\n",
      "Epoch: 695/1000 Train loss: 0.141463 Valid loss: 2.105940 Train acc: 0.947420 Valid acc: 0.303586\n",
      "Epoch: 696/1000 Train loss: 0.141308 Valid loss: 2.106759 Train acc: 0.947491 Valid acc: 0.303544\n",
      "Epoch: 697/1000 Train loss: 0.141122 Valid loss: 2.107521 Train acc: 0.947562 Valid acc: 0.303511\n",
      "Epoch: 698/1000 Train loss: 0.140977 Valid loss: 2.108133 Train acc: 0.947624 Valid acc: 0.303473\n",
      "Epoch: 699/1000 Train loss: 0.140787 Valid loss: 2.109289 Train acc: 0.947695 Valid acc: 0.303442\n",
      "Epoch: 700/1000 Train loss: 0.140594 Valid loss: 2.110753 Train acc: 0.947768 Valid acc: 0.303445\n",
      "Epoch: 701/1000 Train loss: 0.140459 Valid loss: 2.112124 Train acc: 0.947834 Valid acc: 0.303444\n",
      "Epoch: 702/1000 Train loss: 0.140327 Valid loss: 2.113255 Train acc: 0.947899 Valid acc: 0.303427\n",
      "Epoch: 703/1000 Train loss: 0.140156 Valid loss: 2.114509 Train acc: 0.947965 Valid acc: 0.303418\n",
      "Epoch: 704/1000 Train loss: 0.139966 Valid loss: 2.115796 Train acc: 0.948037 Valid acc: 0.303398\n",
      "Epoch: 705/1000 Train loss: 0.139779 Valid loss: 2.117126 Train acc: 0.948104 Valid acc: 0.303374\n",
      "Epoch: 706/1000 Train loss: 0.139586 Valid loss: 2.118453 Train acc: 0.948175 Valid acc: 0.303340\n",
      "Epoch: 707/1000 Train loss: 0.139403 Valid loss: 2.119785 Train acc: 0.948240 Valid acc: 0.303310\n",
      "Epoch: 708/1000 Train loss: 0.139209 Valid loss: 2.121258 Train acc: 0.948313 Valid acc: 0.303284\n",
      "Epoch: 709/1000 Train loss: 0.139035 Valid loss: 2.122562 Train acc: 0.948378 Valid acc: 0.303268\n",
      "Epoch: 710/1000 Train loss: 0.138859 Valid loss: 2.123519 Train acc: 0.948444 Valid acc: 0.303257\n",
      "Epoch: 711/1000 Train loss: 0.138696 Valid loss: 2.124439 Train acc: 0.948511 Valid acc: 0.303236\n",
      "Epoch: 712/1000 Train loss: 0.138643 Valid loss: 2.125567 Train acc: 0.948564 Valid acc: 0.303209\n",
      "Epoch: 713/1000 Train loss: 0.138502 Valid loss: 2.126921 Train acc: 0.948624 Valid acc: 0.303205\n",
      "Epoch: 714/1000 Train loss: 0.138361 Valid loss: 2.128649 Train acc: 0.948681 Valid acc: 0.303196\n",
      "Epoch: 715/1000 Train loss: 0.138208 Valid loss: 2.130191 Train acc: 0.948738 Valid acc: 0.303211\n",
      "Epoch: 716/1000 Train loss: 0.138031 Valid loss: 2.131518 Train acc: 0.948806 Valid acc: 0.303201\n",
      "Epoch: 717/1000 Train loss: 0.137869 Valid loss: 2.132910 Train acc: 0.948873 Valid acc: 0.303173\n",
      "Epoch: 718/1000 Train loss: 0.137695 Valid loss: 2.134461 Train acc: 0.948940 Valid acc: 0.303159\n",
      "Epoch: 719/1000 Train loss: 0.137555 Valid loss: 2.135741 Train acc: 0.948996 Valid acc: 0.303140\n",
      "Epoch: 720/1000 Train loss: 0.137389 Valid loss: 2.136803 Train acc: 0.949057 Valid acc: 0.303124\n",
      "Epoch: 721/1000 Train loss: 0.137222 Valid loss: 2.137784 Train acc: 0.949121 Valid acc: 0.303106\n",
      "Epoch: 722/1000 Train loss: 0.137083 Valid loss: 2.139257 Train acc: 0.949179 Valid acc: 0.303109\n",
      "Epoch: 723/1000 Train loss: 0.136936 Valid loss: 2.141303 Train acc: 0.949239 Valid acc: 0.303098\n",
      "Epoch: 724/1000 Train loss: 0.136795 Valid loss: 2.142796 Train acc: 0.949297 Valid acc: 0.303120\n",
      "Epoch: 725/1000 Train loss: 0.136636 Valid loss: 2.144079 Train acc: 0.949355 Valid acc: 0.303135\n",
      "Epoch: 726/1000 Train loss: 0.136520 Valid loss: 2.145184 Train acc: 0.949416 Valid acc: 0.303132\n",
      "Epoch: 727/1000 Train loss: 0.136344 Valid loss: 2.145983 Train acc: 0.949482 Valid acc: 0.303144\n",
      "Epoch: 728/1000 Train loss: 0.136220 Valid loss: 2.147053 Train acc: 0.949535 Valid acc: 0.303147\n",
      "Epoch: 729/1000 Train loss: 0.136042 Valid loss: 2.148138 Train acc: 0.949602 Valid acc: 0.303148\n",
      "Epoch: 730/1000 Train loss: 0.135899 Valid loss: 2.149279 Train acc: 0.949654 Valid acc: 0.303163\n",
      "Epoch: 731/1000 Train loss: 0.135720 Valid loss: 2.150111 Train acc: 0.949719 Valid acc: 0.303180\n",
      "Epoch: 732/1000 Train loss: 0.135582 Valid loss: 2.150882 Train acc: 0.949780 Valid acc: 0.303199\n",
      "Epoch: 733/1000 Train loss: 0.135428 Valid loss: 2.151627 Train acc: 0.949836 Valid acc: 0.303215\n",
      "Epoch: 734/1000 Train loss: 0.135248 Valid loss: 2.152490 Train acc: 0.949902 Valid acc: 0.303245\n",
      "Epoch: 735/1000 Train loss: 0.135072 Valid loss: 2.153490 Train acc: 0.949965 Valid acc: 0.303270\n",
      "Epoch: 736/1000 Train loss: 0.134893 Valid loss: 2.154680 Train acc: 0.950030 Valid acc: 0.303277\n",
      "Epoch: 737/1000 Train loss: 0.134738 Valid loss: 2.155891 Train acc: 0.950088 Valid acc: 0.303288\n",
      "Epoch: 738/1000 Train loss: 0.134580 Valid loss: 2.157049 Train acc: 0.950152 Valid acc: 0.303308\n",
      "Epoch: 739/1000 Train loss: 0.134410 Valid loss: 2.158038 Train acc: 0.950213 Valid acc: 0.303311\n",
      "Epoch: 740/1000 Train loss: 0.134238 Valid loss: 2.158942 Train acc: 0.950276 Valid acc: 0.303320\n",
      "Epoch: 741/1000 Train loss: 0.134070 Valid loss: 2.159884 Train acc: 0.950337 Valid acc: 0.303335\n",
      "Epoch: 742/1000 Train loss: 0.133912 Valid loss: 2.160939 Train acc: 0.950400 Valid acc: 0.303333\n",
      "Epoch: 743/1000 Train loss: 0.133745 Valid loss: 2.162335 Train acc: 0.950463 Valid acc: 0.303353\n",
      "Epoch: 744/1000 Train loss: 0.133577 Valid loss: 2.163762 Train acc: 0.950528 Valid acc: 0.303360\n",
      "Epoch: 745/1000 Train loss: 0.133399 Valid loss: 2.165256 Train acc: 0.950594 Valid acc: 0.303343\n",
      "Epoch: 746/1000 Train loss: 0.133236 Valid loss: 2.166754 Train acc: 0.950654 Valid acc: 0.303327\n",
      "Epoch: 747/1000 Train loss: 0.133063 Valid loss: 2.168143 Train acc: 0.950718 Valid acc: 0.303342\n",
      "Epoch: 748/1000 Train loss: 0.132895 Valid loss: 2.169378 Train acc: 0.950780 Valid acc: 0.303355\n",
      "Epoch: 749/1000 Train loss: 0.132720 Valid loss: 2.170568 Train acc: 0.950846 Valid acc: 0.303355\n",
      "Epoch: 750/1000 Train loss: 0.132579 Valid loss: 2.171639 Train acc: 0.950907 Valid acc: 0.303345\n",
      "Epoch: 751/1000 Train loss: 0.132416 Valid loss: 2.172419 Train acc: 0.950969 Valid acc: 0.303339\n",
      "Epoch: 752/1000 Train loss: 0.132251 Valid loss: 2.173071 Train acc: 0.951032 Valid acc: 0.303340\n",
      "Epoch: 753/1000 Train loss: 0.132104 Valid loss: 2.173621 Train acc: 0.951089 Valid acc: 0.303333\n",
      "Epoch: 754/1000 Train loss: 0.131935 Valid loss: 2.174316 Train acc: 0.951150 Valid acc: 0.303322\n",
      "Epoch: 755/1000 Train loss: 0.131792 Valid loss: 2.175155 Train acc: 0.951203 Valid acc: 0.303339\n",
      "Epoch: 756/1000 Train loss: 0.131620 Valid loss: 2.176280 Train acc: 0.951267 Valid acc: 0.303357\n",
      "Epoch: 757/1000 Train loss: 0.131450 Valid loss: 2.177586 Train acc: 0.951330 Valid acc: 0.303368\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 758/1000 Train loss: 0.131281 Valid loss: 2.178930 Train acc: 0.951394 Valid acc: 0.303371\n",
      "Epoch: 759/1000 Train loss: 0.131111 Valid loss: 2.180213 Train acc: 0.951456 Valid acc: 0.303371\n",
      "Epoch: 760/1000 Train loss: 0.130946 Valid loss: 2.181449 Train acc: 0.951518 Valid acc: 0.303384\n",
      "Epoch: 761/1000 Train loss: 0.130814 Valid loss: 2.182651 Train acc: 0.951578 Valid acc: 0.303396\n",
      "Epoch: 762/1000 Train loss: 0.130669 Valid loss: 2.183684 Train acc: 0.951639 Valid acc: 0.303413\n",
      "Epoch: 763/1000 Train loss: 0.130546 Valid loss: 2.184579 Train acc: 0.951697 Valid acc: 0.303434\n",
      "Epoch: 764/1000 Train loss: 0.130402 Valid loss: 2.185658 Train acc: 0.951752 Valid acc: 0.303462\n",
      "Epoch: 765/1000 Train loss: 0.130255 Valid loss: 2.186911 Train acc: 0.951810 Valid acc: 0.303487\n",
      "Epoch: 766/1000 Train loss: 0.130114 Valid loss: 2.188033 Train acc: 0.951869 Valid acc: 0.303494\n",
      "Epoch: 767/1000 Train loss: 0.129959 Valid loss: 2.189013 Train acc: 0.951927 Valid acc: 0.303481\n",
      "Epoch: 768/1000 Train loss: 0.129810 Valid loss: 2.189915 Train acc: 0.951986 Valid acc: 0.303462\n",
      "Epoch: 769/1000 Train loss: 0.129650 Valid loss: 2.190916 Train acc: 0.952043 Valid acc: 0.303418\n",
      "Epoch: 770/1000 Train loss: 0.129505 Valid loss: 2.191963 Train acc: 0.952095 Valid acc: 0.303369\n",
      "Epoch: 771/1000 Train loss: 0.129342 Valid loss: 2.192835 Train acc: 0.952156 Valid acc: 0.303345\n",
      "Epoch: 772/1000 Train loss: 0.129199 Valid loss: 2.193396 Train acc: 0.952210 Valid acc: 0.303335\n",
      "Epoch: 773/1000 Train loss: 0.129042 Valid loss: 2.194098 Train acc: 0.952268 Valid acc: 0.303287\n",
      "Epoch: 774/1000 Train loss: 0.128879 Valid loss: 2.194737 Train acc: 0.952330 Valid acc: 0.303247\n",
      "Epoch: 775/1000 Train loss: 0.128748 Valid loss: 2.195484 Train acc: 0.952383 Valid acc: 0.303223\n",
      "Epoch: 776/1000 Train loss: 0.128604 Valid loss: 2.196455 Train acc: 0.952439 Valid acc: 0.303218\n",
      "Epoch: 777/1000 Train loss: 0.128445 Valid loss: 2.197578 Train acc: 0.952498 Valid acc: 0.303202\n",
      "Epoch: 778/1000 Train loss: 0.128407 Valid loss: 2.198515 Train acc: 0.952548 Valid acc: 0.303184\n",
      "Epoch: 779/1000 Train loss: 0.128296 Valid loss: 2.199270 Train acc: 0.952599 Valid acc: 0.303161\n",
      "Epoch: 780/1000 Train loss: 0.128160 Valid loss: 2.199650 Train acc: 0.952652 Valid acc: 0.303171\n",
      "Epoch: 781/1000 Train loss: 0.128049 Valid loss: 2.200166 Train acc: 0.952701 Valid acc: 0.303167\n",
      "Epoch: 782/1000 Train loss: 0.127902 Valid loss: 2.201110 Train acc: 0.952756 Valid acc: 0.303171\n",
      "Epoch: 783/1000 Train loss: 0.127766 Valid loss: 2.202279 Train acc: 0.952813 Valid acc: 0.303157\n",
      "Epoch: 784/1000 Train loss: 0.127630 Valid loss: 2.203229 Train acc: 0.952867 Valid acc: 0.303117\n",
      "Epoch: 785/1000 Train loss: 0.127490 Valid loss: 2.203982 Train acc: 0.952919 Valid acc: 0.303105\n",
      "Epoch: 786/1000 Train loss: 0.127380 Valid loss: 2.204626 Train acc: 0.952968 Valid acc: 0.303125\n",
      "Epoch: 787/1000 Train loss: 0.127229 Valid loss: 2.205290 Train acc: 0.953022 Valid acc: 0.303115\n",
      "Epoch: 788/1000 Train loss: 0.127078 Valid loss: 2.206022 Train acc: 0.953078 Valid acc: 0.303097\n",
      "Epoch: 789/1000 Train loss: 0.126939 Valid loss: 2.206847 Train acc: 0.953128 Valid acc: 0.303071\n",
      "Epoch: 790/1000 Train loss: 0.126797 Valid loss: 2.207416 Train acc: 0.953180 Valid acc: 0.303062\n",
      "Epoch: 791/1000 Train loss: 0.126648 Valid loss: 2.207874 Train acc: 0.953233 Valid acc: 0.303076\n",
      "Epoch: 792/1000 Train loss: 0.126516 Valid loss: 2.208184 Train acc: 0.953287 Valid acc: 0.303097\n",
      "Epoch: 793/1000 Train loss: 0.126373 Valid loss: 2.208668 Train acc: 0.953342 Valid acc: 0.303137\n",
      "Epoch: 794/1000 Train loss: 0.126257 Valid loss: 2.209147 Train acc: 0.953391 Valid acc: 0.303174\n",
      "Epoch: 795/1000 Train loss: 0.126108 Valid loss: 2.209412 Train acc: 0.953448 Valid acc: 0.303203\n",
      "Epoch: 796/1000 Train loss: 0.125955 Valid loss: 2.209735 Train acc: 0.953504 Valid acc: 0.303229\n",
      "Epoch: 797/1000 Train loss: 0.125804 Valid loss: 2.210235 Train acc: 0.953557 Valid acc: 0.303253\n",
      "Epoch: 798/1000 Train loss: 0.125649 Valid loss: 2.211015 Train acc: 0.953614 Valid acc: 0.303274\n",
      "Epoch: 799/1000 Train loss: 0.125507 Valid loss: 2.211873 Train acc: 0.953668 Valid acc: 0.303304\n",
      "Epoch: 800/1000 Train loss: 0.125374 Valid loss: 2.212966 Train acc: 0.953720 Valid acc: 0.303313\n",
      "Epoch: 801/1000 Train loss: 0.125261 Valid loss: 2.214085 Train acc: 0.953771 Valid acc: 0.303343\n",
      "Epoch: 802/1000 Train loss: 0.125153 Valid loss: 2.215055 Train acc: 0.953817 Valid acc: 0.303383\n",
      "Epoch: 803/1000 Train loss: 0.125053 Valid loss: 2.215801 Train acc: 0.953860 Valid acc: 0.303412\n",
      "Epoch: 804/1000 Train loss: 0.124937 Valid loss: 2.216324 Train acc: 0.953910 Valid acc: 0.303445\n",
      "Epoch: 805/1000 Train loss: 0.124823 Valid loss: 2.216969 Train acc: 0.953956 Valid acc: 0.303473\n",
      "Epoch: 806/1000 Train loss: 0.124700 Valid loss: 2.217857 Train acc: 0.954009 Valid acc: 0.303497\n",
      "Epoch: 807/1000 Train loss: 0.124555 Valid loss: 2.219109 Train acc: 0.954064 Valid acc: 0.303499\n",
      "Epoch: 808/1000 Train loss: 0.124424 Valid loss: 2.220573 Train acc: 0.954117 Valid acc: 0.303512\n",
      "Epoch: 809/1000 Train loss: 0.124314 Valid loss: 2.221749 Train acc: 0.954169 Valid acc: 0.303525\n",
      "Epoch: 810/1000 Train loss: 0.124164 Valid loss: 2.222649 Train acc: 0.954223 Valid acc: 0.303535\n",
      "Epoch: 811/1000 Train loss: 0.124022 Valid loss: 2.223459 Train acc: 0.954274 Valid acc: 0.303541\n",
      "Epoch: 812/1000 Train loss: 0.123885 Valid loss: 2.224269 Train acc: 0.954323 Valid acc: 0.303504\n",
      "Epoch: 813/1000 Train loss: 0.123752 Valid loss: 2.225081 Train acc: 0.954374 Valid acc: 0.303499\n",
      "Epoch: 814/1000 Train loss: 0.123612 Valid loss: 2.225834 Train acc: 0.954423 Valid acc: 0.303499\n",
      "Epoch: 815/1000 Train loss: 0.123464 Valid loss: 2.226547 Train acc: 0.954475 Valid acc: 0.303501\n",
      "Epoch: 816/1000 Train loss: 0.123341 Valid loss: 2.227289 Train acc: 0.954527 Valid acc: 0.303510\n",
      "Epoch: 817/1000 Train loss: 0.123239 Valid loss: 2.228209 Train acc: 0.954575 Valid acc: 0.303509\n",
      "Epoch: 818/1000 Train loss: 0.123176 Valid loss: 2.229261 Train acc: 0.954613 Valid acc: 0.303513\n",
      "Epoch: 819/1000 Train loss: 0.123118 Valid loss: 2.230115 Train acc: 0.954646 Valid acc: 0.303503\n",
      "Epoch: 820/1000 Train loss: 0.123031 Valid loss: 2.231133 Train acc: 0.954692 Valid acc: 0.303530\n",
      "Epoch: 821/1000 Train loss: 0.122914 Valid loss: 2.231999 Train acc: 0.954737 Valid acc: 0.303557\n",
      "Epoch: 822/1000 Train loss: 0.122825 Valid loss: 2.232894 Train acc: 0.954785 Valid acc: 0.303611\n",
      "Epoch: 823/1000 Train loss: 0.122736 Valid loss: 2.233224 Train acc: 0.954830 Valid acc: 0.303656\n",
      "Epoch: 824/1000 Train loss: 0.122669 Valid loss: 2.233431 Train acc: 0.954873 Valid acc: 0.303701\n",
      "Epoch: 825/1000 Train loss: 0.122585 Valid loss: 2.233745 Train acc: 0.954916 Valid acc: 0.303734\n",
      "Epoch: 826/1000 Train loss: 0.122479 Valid loss: 2.234282 Train acc: 0.954964 Valid acc: 0.303772\n",
      "Epoch: 827/1000 Train loss: 0.122368 Valid loss: 2.234695 Train acc: 0.955007 Valid acc: 0.303817\n",
      "Epoch: 828/1000 Train loss: 0.122255 Valid loss: 2.235072 Train acc: 0.955054 Valid acc: 0.303858\n",
      "Epoch: 829/1000 Train loss: 0.122185 Valid loss: 2.235507 Train acc: 0.955094 Valid acc: 0.303878\n",
      "Epoch: 830/1000 Train loss: 0.122054 Valid loss: 2.235982 Train acc: 0.955143 Valid acc: 0.303904\n",
      "Epoch: 831/1000 Train loss: 0.121942 Valid loss: 2.236370 Train acc: 0.955188 Valid acc: 0.303941\n",
      "Epoch: 832/1000 Train loss: 0.121809 Valid loss: 2.236719 Train acc: 0.955240 Valid acc: 0.303945\n",
      "Epoch: 833/1000 Train loss: 0.121681 Valid loss: 2.237099 Train acc: 0.955287 Valid acc: 0.303950\n",
      "Epoch: 834/1000 Train loss: 0.121578 Valid loss: 2.237596 Train acc: 0.955337 Valid acc: 0.303985\n",
      "Epoch: 835/1000 Train loss: 0.121439 Valid loss: 2.238069 Train acc: 0.955388 Valid acc: 0.303999\n",
      "Epoch: 836/1000 Train loss: 0.121337 Valid loss: 2.238598 Train acc: 0.955433 Valid acc: 0.304020\n",
      "Epoch: 837/1000 Train loss: 0.121196 Valid loss: 2.239325 Train acc: 0.955484 Valid acc: 0.304032\n",
      "Epoch: 838/1000 Train loss: 0.121057 Valid loss: 2.240202 Train acc: 0.955536 Valid acc: 0.304047\n",
      "Epoch: 839/1000 Train loss: 0.120915 Valid loss: 2.241043 Train acc: 0.955587 Valid acc: 0.304072\n",
      "Epoch: 840/1000 Train loss: 0.120788 Valid loss: 2.241881 Train acc: 0.955636 Valid acc: 0.304084\n",
      "Epoch: 841/1000 Train loss: 0.120647 Valid loss: 2.242541 Train acc: 0.955687 Valid acc: 0.304070\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 842/1000 Train loss: 0.120512 Valid loss: 2.243170 Train acc: 0.955736 Valid acc: 0.304070\n",
      "Epoch: 843/1000 Train loss: 0.120373 Valid loss: 2.243891 Train acc: 0.955787 Valid acc: 0.304075\n",
      "Epoch: 844/1000 Train loss: 0.120240 Valid loss: 2.244788 Train acc: 0.955836 Valid acc: 0.304081\n",
      "Epoch: 845/1000 Train loss: 0.120143 Valid loss: 2.245736 Train acc: 0.955883 Valid acc: 0.304106\n",
      "Epoch: 846/1000 Train loss: 0.120015 Valid loss: 2.246374 Train acc: 0.955928 Valid acc: 0.304127\n",
      "Epoch: 847/1000 Train loss: 0.119920 Valid loss: 2.247038 Train acc: 0.955973 Valid acc: 0.304141\n",
      "Epoch: 848/1000 Train loss: 0.119787 Valid loss: 2.247733 Train acc: 0.956021 Valid acc: 0.304136\n",
      "Epoch: 849/1000 Train loss: 0.119652 Valid loss: 2.248425 Train acc: 0.956070 Valid acc: 0.304137\n",
      "Epoch: 850/1000 Train loss: 0.119531 Valid loss: 2.249142 Train acc: 0.956116 Valid acc: 0.304147\n",
      "Epoch: 851/1000 Train loss: 0.119395 Valid loss: 2.250064 Train acc: 0.956166 Valid acc: 0.304148\n",
      "Epoch: 852/1000 Train loss: 0.119263 Valid loss: 2.251080 Train acc: 0.956214 Valid acc: 0.304135\n",
      "Epoch: 853/1000 Train loss: 0.119123 Valid loss: 2.252085 Train acc: 0.956265 Valid acc: 0.304144\n",
      "Epoch: 854/1000 Train loss: 0.119051 Valid loss: 2.253024 Train acc: 0.956311 Valid acc: 0.304151\n",
      "Epoch: 855/1000 Train loss: 0.118950 Valid loss: 2.253957 Train acc: 0.956357 Valid acc: 0.304135\n",
      "Epoch: 856/1000 Train loss: 0.118878 Valid loss: 2.254610 Train acc: 0.956399 Valid acc: 0.304112\n",
      "Epoch: 857/1000 Train loss: 0.118941 Valid loss: 2.255541 Train acc: 0.956427 Valid acc: 0.304116\n",
      "Epoch: 858/1000 Train loss: 0.118955 Valid loss: 2.256526 Train acc: 0.956461 Valid acc: 0.304142\n",
      "Epoch: 859/1000 Train loss: 0.118867 Valid loss: 2.257042 Train acc: 0.956501 Valid acc: 0.304150\n",
      "Epoch: 860/1000 Train loss: 0.118772 Valid loss: 2.257714 Train acc: 0.956545 Valid acc: 0.304196\n",
      "Epoch: 861/1000 Train loss: 0.118669 Valid loss: 2.258564 Train acc: 0.956581 Valid acc: 0.304251\n",
      "Epoch: 862/1000 Train loss: 0.118582 Valid loss: 2.259692 Train acc: 0.956613 Valid acc: 0.304313\n",
      "Epoch: 863/1000 Train loss: 0.118533 Valid loss: 2.260687 Train acc: 0.956647 Valid acc: 0.304355\n",
      "Epoch: 864/1000 Train loss: 0.118431 Valid loss: 2.261677 Train acc: 0.956689 Valid acc: 0.304381\n",
      "Epoch: 865/1000 Train loss: 0.118299 Valid loss: 2.262674 Train acc: 0.956735 Valid acc: 0.304410\n",
      "Epoch: 866/1000 Train loss: 0.118177 Valid loss: 2.263712 Train acc: 0.956782 Valid acc: 0.304423\n",
      "Epoch: 867/1000 Train loss: 0.118074 Valid loss: 2.264650 Train acc: 0.956828 Valid acc: 0.304470\n",
      "Epoch: 868/1000 Train loss: 0.118002 Valid loss: 2.265378 Train acc: 0.956864 Valid acc: 0.304510\n",
      "Epoch: 869/1000 Train loss: 0.117905 Valid loss: 2.266055 Train acc: 0.956900 Valid acc: 0.304533\n",
      "Epoch: 870/1000 Train loss: 0.117792 Valid loss: 2.266856 Train acc: 0.956943 Valid acc: 0.304580\n",
      "Epoch: 871/1000 Train loss: 0.117674 Valid loss: 2.267885 Train acc: 0.956989 Valid acc: 0.304592\n",
      "Epoch: 872/1000 Train loss: 0.117556 Valid loss: 2.268797 Train acc: 0.957035 Valid acc: 0.304601\n",
      "Epoch: 873/1000 Train loss: 0.117432 Valid loss: 2.269597 Train acc: 0.957081 Valid acc: 0.304613\n",
      "Epoch: 874/1000 Train loss: 0.117321 Valid loss: 2.270522 Train acc: 0.957121 Valid acc: 0.304634\n",
      "Epoch: 875/1000 Train loss: 0.117192 Valid loss: 2.271453 Train acc: 0.957169 Valid acc: 0.304658\n",
      "Epoch: 876/1000 Train loss: 0.117061 Valid loss: 2.272311 Train acc: 0.957216 Valid acc: 0.304685\n",
      "Epoch: 877/1000 Train loss: 0.116935 Valid loss: 2.273216 Train acc: 0.957263 Valid acc: 0.304698\n",
      "Epoch: 878/1000 Train loss: 0.116815 Valid loss: 2.274093 Train acc: 0.957306 Valid acc: 0.304713\n",
      "Epoch: 879/1000 Train loss: 0.116691 Valid loss: 2.274969 Train acc: 0.957350 Valid acc: 0.304715\n",
      "Epoch: 880/1000 Train loss: 0.116604 Valid loss: 2.275943 Train acc: 0.957385 Valid acc: 0.304694\n",
      "Epoch: 881/1000 Train loss: 0.116481 Valid loss: 2.277014 Train acc: 0.957431 Valid acc: 0.304676\n",
      "Epoch: 882/1000 Train loss: 0.116382 Valid loss: 2.278111 Train acc: 0.957471 Valid acc: 0.304649\n",
      "Epoch: 883/1000 Train loss: 0.116253 Valid loss: 2.279360 Train acc: 0.957518 Valid acc: 0.304628\n",
      "Epoch: 884/1000 Train loss: 0.116144 Valid loss: 2.280391 Train acc: 0.957557 Valid acc: 0.304606\n",
      "Epoch: 885/1000 Train loss: 0.116035 Valid loss: 2.281430 Train acc: 0.957600 Valid acc: 0.304572\n",
      "Epoch: 886/1000 Train loss: 0.115908 Valid loss: 2.282355 Train acc: 0.957646 Valid acc: 0.304529\n",
      "Epoch: 887/1000 Train loss: 0.115787 Valid loss: 2.283226 Train acc: 0.957692 Valid acc: 0.304499\n",
      "Epoch: 888/1000 Train loss: 0.115671 Valid loss: 2.284185 Train acc: 0.957737 Valid acc: 0.304455\n",
      "Epoch: 889/1000 Train loss: 0.115567 Valid loss: 2.285251 Train acc: 0.957779 Valid acc: 0.304399\n",
      "Epoch: 890/1000 Train loss: 0.115455 Valid loss: 2.286178 Train acc: 0.957822 Valid acc: 0.304367\n",
      "Epoch: 891/1000 Train loss: 0.115344 Valid loss: 2.287107 Train acc: 0.957864 Valid acc: 0.304323\n",
      "Epoch: 892/1000 Train loss: 0.115228 Valid loss: 2.288128 Train acc: 0.957906 Valid acc: 0.304270\n",
      "Epoch: 893/1000 Train loss: 0.115111 Valid loss: 2.289097 Train acc: 0.957948 Valid acc: 0.304230\n",
      "Epoch: 894/1000 Train loss: 0.114984 Valid loss: 2.290099 Train acc: 0.957995 Valid acc: 0.304206\n",
      "Epoch: 895/1000 Train loss: 0.114883 Valid loss: 2.291126 Train acc: 0.958036 Valid acc: 0.304179\n",
      "Epoch: 896/1000 Train loss: 0.114799 Valid loss: 2.292187 Train acc: 0.958072 Valid acc: 0.304142\n",
      "Epoch: 897/1000 Train loss: 0.114679 Valid loss: 2.293234 Train acc: 0.958118 Valid acc: 0.304119\n",
      "Epoch: 898/1000 Train loss: 0.114565 Valid loss: 2.294301 Train acc: 0.958157 Valid acc: 0.304090\n",
      "Epoch: 899/1000 Train loss: 0.114455 Valid loss: 2.295415 Train acc: 0.958197 Valid acc: 0.304085\n",
      "Epoch: 900/1000 Train loss: 0.114330 Valid loss: 2.296614 Train acc: 0.958244 Valid acc: 0.304097\n",
      "Epoch: 901/1000 Train loss: 0.114230 Valid loss: 2.297765 Train acc: 0.958285 Valid acc: 0.304104\n",
      "Epoch: 902/1000 Train loss: 0.114122 Valid loss: 2.298955 Train acc: 0.958322 Valid acc: 0.304111\n",
      "Epoch: 903/1000 Train loss: 0.114019 Valid loss: 2.300123 Train acc: 0.958358 Valid acc: 0.304121\n",
      "Epoch: 904/1000 Train loss: 0.113901 Valid loss: 2.301458 Train acc: 0.958399 Valid acc: 0.304104\n",
      "Epoch: 905/1000 Train loss: 0.113856 Valid loss: 2.302707 Train acc: 0.958435 Valid acc: 0.304097\n",
      "Epoch: 906/1000 Train loss: 0.113744 Valid loss: 2.303785 Train acc: 0.958476 Valid acc: 0.304087\n",
      "Epoch: 907/1000 Train loss: 0.113659 Valid loss: 2.304726 Train acc: 0.958512 Valid acc: 0.304087\n",
      "Epoch: 908/1000 Train loss: 0.113568 Valid loss: 2.306042 Train acc: 0.958551 Valid acc: 0.304078\n",
      "Epoch: 909/1000 Train loss: 0.113457 Valid loss: 2.307391 Train acc: 0.958590 Valid acc: 0.304054\n",
      "Epoch: 910/1000 Train loss: 0.113365 Valid loss: 2.308430 Train acc: 0.958632 Valid acc: 0.304019\n",
      "Epoch: 911/1000 Train loss: 0.113255 Valid loss: 2.309422 Train acc: 0.958676 Valid acc: 0.303987\n",
      "Epoch: 912/1000 Train loss: 0.113156 Valid loss: 2.310582 Train acc: 0.958715 Valid acc: 0.303977\n",
      "Epoch: 913/1000 Train loss: 0.113043 Valid loss: 2.311865 Train acc: 0.958755 Valid acc: 0.303961\n",
      "Epoch: 914/1000 Train loss: 0.112949 Valid loss: 2.313403 Train acc: 0.958795 Valid acc: 0.303941\n",
      "Epoch: 915/1000 Train loss: 0.112845 Valid loss: 2.315104 Train acc: 0.958835 Valid acc: 0.303909\n",
      "Epoch: 916/1000 Train loss: 0.112737 Valid loss: 2.316356 Train acc: 0.958877 Valid acc: 0.303885\n",
      "Epoch: 917/1000 Train loss: 0.112625 Valid loss: 2.317427 Train acc: 0.958919 Valid acc: 0.303875\n",
      "Epoch: 918/1000 Train loss: 0.112538 Valid loss: 2.318595 Train acc: 0.958955 Valid acc: 0.303871\n",
      "Epoch: 919/1000 Train loss: 0.112438 Valid loss: 2.319952 Train acc: 0.958995 Valid acc: 0.303876\n",
      "Epoch: 920/1000 Train loss: 0.112354 Valid loss: 2.321277 Train acc: 0.959033 Valid acc: 0.303864\n",
      "Epoch: 921/1000 Train loss: 0.112271 Valid loss: 2.322372 Train acc: 0.959063 Valid acc: 0.303855\n",
      "Epoch: 922/1000 Train loss: 0.112162 Valid loss: 2.323367 Train acc: 0.959101 Valid acc: 0.303863\n",
      "Epoch: 923/1000 Train loss: 0.112117 Valid loss: 2.324261 Train acc: 0.959137 Valid acc: 0.303870\n",
      "Epoch: 924/1000 Train loss: 0.112011 Valid loss: 2.325119 Train acc: 0.959175 Valid acc: 0.303895\n",
      "Epoch: 925/1000 Train loss: 0.111924 Valid loss: 2.326335 Train acc: 0.959208 Valid acc: 0.303891\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 926/1000 Train loss: 0.111855 Valid loss: 2.327996 Train acc: 0.959242 Valid acc: 0.303884\n",
      "Epoch: 927/1000 Train loss: 0.111747 Valid loss: 2.329298 Train acc: 0.959281 Valid acc: 0.303898\n",
      "Epoch: 928/1000 Train loss: 0.111649 Valid loss: 2.330309 Train acc: 0.959322 Valid acc: 0.303929\n",
      "Epoch: 929/1000 Train loss: 0.111539 Valid loss: 2.331255 Train acc: 0.959363 Valid acc: 0.303952\n",
      "Epoch: 930/1000 Train loss: 0.111425 Valid loss: 2.332402 Train acc: 0.959401 Valid acc: 0.303973\n",
      "Epoch: 931/1000 Train loss: 0.111314 Valid loss: 2.333484 Train acc: 0.959440 Valid acc: 0.303975\n",
      "Epoch: 932/1000 Train loss: 0.111231 Valid loss: 2.334366 Train acc: 0.959474 Valid acc: 0.303988\n",
      "Epoch: 933/1000 Train loss: 0.111124 Valid loss: 2.335087 Train acc: 0.959511 Valid acc: 0.303987\n",
      "Epoch: 934/1000 Train loss: 0.111018 Valid loss: 2.335846 Train acc: 0.959551 Valid acc: 0.303986\n",
      "Epoch: 935/1000 Train loss: 0.110912 Valid loss: 2.336590 Train acc: 0.959593 Valid acc: 0.303986\n",
      "Epoch: 936/1000 Train loss: 0.110799 Valid loss: 2.337374 Train acc: 0.959635 Valid acc: 0.303989\n",
      "Epoch: 937/1000 Train loss: 0.110690 Valid loss: 2.338323 Train acc: 0.959676 Valid acc: 0.303985\n",
      "Epoch: 938/1000 Train loss: 0.110580 Valid loss: 2.339063 Train acc: 0.959714 Valid acc: 0.303982\n",
      "Epoch: 939/1000 Train loss: 0.110471 Valid loss: 2.339597 Train acc: 0.959754 Valid acc: 0.303969\n",
      "Epoch: 940/1000 Train loss: 0.110359 Valid loss: 2.340180 Train acc: 0.959794 Valid acc: 0.303943\n",
      "Epoch: 941/1000 Train loss: 0.110256 Valid loss: 2.340894 Train acc: 0.959832 Valid acc: 0.303916\n",
      "Epoch: 942/1000 Train loss: 0.110153 Valid loss: 2.341750 Train acc: 0.959868 Valid acc: 0.303906\n",
      "Epoch: 943/1000 Train loss: 0.110047 Valid loss: 2.342694 Train acc: 0.959906 Valid acc: 0.303903\n",
      "Epoch: 944/1000 Train loss: 0.109932 Valid loss: 2.343693 Train acc: 0.959948 Valid acc: 0.303904\n",
      "Epoch: 945/1000 Train loss: 0.109836 Valid loss: 2.344675 Train acc: 0.959984 Valid acc: 0.303906\n",
      "Epoch: 946/1000 Train loss: 0.109732 Valid loss: 2.345610 Train acc: 0.960023 Valid acc: 0.303902\n",
      "Epoch: 947/1000 Train loss: 0.109626 Valid loss: 2.346413 Train acc: 0.960061 Valid acc: 0.303890\n",
      "Epoch: 948/1000 Train loss: 0.109526 Valid loss: 2.347105 Train acc: 0.960098 Valid acc: 0.303883\n",
      "Epoch: 949/1000 Train loss: 0.109420 Valid loss: 2.347901 Train acc: 0.960139 Valid acc: 0.303891\n",
      "Epoch: 950/1000 Train loss: 0.109310 Valid loss: 2.348811 Train acc: 0.960179 Valid acc: 0.303898\n",
      "Epoch: 951/1000 Train loss: 0.109198 Valid loss: 2.349747 Train acc: 0.960220 Valid acc: 0.303913\n",
      "Epoch: 952/1000 Train loss: 0.109089 Valid loss: 2.350561 Train acc: 0.960258 Valid acc: 0.303921\n",
      "Epoch: 953/1000 Train loss: 0.108984 Valid loss: 2.351297 Train acc: 0.960295 Valid acc: 0.303933\n",
      "Epoch: 954/1000 Train loss: 0.108878 Valid loss: 2.352043 Train acc: 0.960334 Valid acc: 0.303927\n",
      "Epoch: 955/1000 Train loss: 0.108766 Valid loss: 2.352904 Train acc: 0.960375 Valid acc: 0.303902\n",
      "Epoch: 956/1000 Train loss: 0.108653 Valid loss: 2.353858 Train acc: 0.960417 Valid acc: 0.303877\n",
      "Epoch: 957/1000 Train loss: 0.108555 Valid loss: 2.354898 Train acc: 0.960453 Valid acc: 0.303864\n",
      "Epoch: 958/1000 Train loss: 0.108457 Valid loss: 2.356134 Train acc: 0.960491 Valid acc: 0.303851\n",
      "Epoch: 959/1000 Train loss: 0.108393 Valid loss: 2.357164 Train acc: 0.960523 Valid acc: 0.303852\n",
      "Epoch: 960/1000 Train loss: 0.108301 Valid loss: 2.358277 Train acc: 0.960561 Valid acc: 0.303873\n",
      "Epoch: 961/1000 Train loss: 0.108212 Valid loss: 2.359328 Train acc: 0.960595 Valid acc: 0.303889\n",
      "Epoch: 962/1000 Train loss: 0.108115 Valid loss: 2.360207 Train acc: 0.960634 Valid acc: 0.303894\n",
      "Epoch: 963/1000 Train loss: 0.108007 Valid loss: 2.361037 Train acc: 0.960673 Valid acc: 0.303909\n",
      "Epoch: 964/1000 Train loss: 0.107897 Valid loss: 2.361837 Train acc: 0.960713 Valid acc: 0.303909\n",
      "Epoch: 965/1000 Train loss: 0.107789 Valid loss: 2.362668 Train acc: 0.960750 Valid acc: 0.303917\n",
      "Epoch: 966/1000 Train loss: 0.107701 Valid loss: 2.363591 Train acc: 0.960789 Valid acc: 0.303927\n",
      "Epoch: 967/1000 Train loss: 0.107601 Valid loss: 2.364544 Train acc: 0.960825 Valid acc: 0.303931\n",
      "Epoch: 968/1000 Train loss: 0.107511 Valid loss: 2.365390 Train acc: 0.960863 Valid acc: 0.303935\n",
      "Epoch: 969/1000 Train loss: 0.107424 Valid loss: 2.366361 Train acc: 0.960897 Valid acc: 0.303940\n",
      "Epoch: 970/1000 Train loss: 0.107367 Valid loss: 2.367876 Train acc: 0.960932 Valid acc: 0.303948\n",
      "Epoch: 971/1000 Train loss: 0.107286 Valid loss: 2.369763 Train acc: 0.960964 Valid acc: 0.303940\n",
      "Epoch: 972/1000 Train loss: 0.107201 Valid loss: 2.372140 Train acc: 0.960999 Valid acc: 0.303957\n",
      "Epoch: 973/1000 Train loss: 0.107147 Valid loss: 2.373936 Train acc: 0.961031 Valid acc: 0.303950\n",
      "Epoch: 974/1000 Train loss: 0.107039 Valid loss: 2.375010 Train acc: 0.961071 Valid acc: 0.303935\n",
      "Epoch: 975/1000 Train loss: 0.106941 Valid loss: 2.376030 Train acc: 0.961107 Valid acc: 0.303934\n",
      "Epoch: 976/1000 Train loss: 0.106849 Valid loss: 2.377067 Train acc: 0.961142 Valid acc: 0.303947\n",
      "Epoch: 977/1000 Train loss: 0.106759 Valid loss: 2.378270 Train acc: 0.961177 Valid acc: 0.303959\n",
      "Epoch: 978/1000 Train loss: 0.106660 Valid loss: 2.379775 Train acc: 0.961215 Valid acc: 0.303972\n",
      "Epoch: 979/1000 Train loss: 0.106560 Valid loss: 2.381279 Train acc: 0.961251 Valid acc: 0.303975\n",
      "Epoch: 980/1000 Train loss: 0.106468 Valid loss: 2.383013 Train acc: 0.961284 Valid acc: 0.303985\n",
      "Epoch: 981/1000 Train loss: 0.106379 Valid loss: 2.384681 Train acc: 0.961314 Valid acc: 0.304006\n",
      "Epoch: 982/1000 Train loss: 0.106284 Valid loss: 2.386439 Train acc: 0.961352 Valid acc: 0.303986\n",
      "Epoch: 983/1000 Train loss: 0.106217 Valid loss: 2.388483 Train acc: 0.961387 Valid acc: 0.303970\n",
      "Epoch: 984/1000 Train loss: 0.106166 Valid loss: 2.389809 Train acc: 0.961416 Valid acc: 0.303943\n",
      "Epoch: 985/1000 Train loss: 0.106071 Valid loss: 2.390887 Train acc: 0.961450 Valid acc: 0.303919\n",
      "Epoch: 986/1000 Train loss: 0.105971 Valid loss: 2.391944 Train acc: 0.961485 Valid acc: 0.303893\n",
      "Epoch: 987/1000 Train loss: 0.105865 Valid loss: 2.393030 Train acc: 0.961524 Valid acc: 0.303878\n",
      "Epoch: 988/1000 Train loss: 0.105770 Valid loss: 2.394150 Train acc: 0.961555 Valid acc: 0.303866\n",
      "Epoch: 989/1000 Train loss: 0.105669 Valid loss: 2.395098 Train acc: 0.961592 Valid acc: 0.303852\n",
      "Epoch: 990/1000 Train loss: 0.105572 Valid loss: 2.395992 Train acc: 0.961628 Valid acc: 0.303847\n",
      "Epoch: 991/1000 Train loss: 0.105468 Valid loss: 2.396819 Train acc: 0.961666 Valid acc: 0.303842\n",
      "Epoch: 992/1000 Train loss: 0.105389 Valid loss: 2.397650 Train acc: 0.961698 Valid acc: 0.303841\n",
      "Epoch: 993/1000 Train loss: 0.105329 Valid loss: 2.398542 Train acc: 0.961728 Valid acc: 0.303824\n",
      "Epoch: 994/1000 Train loss: 0.105240 Valid loss: 2.399512 Train acc: 0.961762 Valid acc: 0.303813\n",
      "Epoch: 995/1000 Train loss: 0.105161 Valid loss: 2.400590 Train acc: 0.961794 Valid acc: 0.303821\n",
      "Epoch: 996/1000 Train loss: 0.105076 Valid loss: 2.401761 Train acc: 0.961825 Valid acc: 0.303833\n",
      "Epoch: 997/1000 Train loss: 0.105000 Valid loss: 2.402842 Train acc: 0.961859 Valid acc: 0.303831\n",
      "Epoch: 998/1000 Train loss: 0.104918 Valid loss: 2.403923 Train acc: 0.961893 Valid acc: 0.303835\n",
      "Epoch: 999/1000 Train loss: 0.104864 Valid loss: 2.405394 Train acc: 0.961923 Valid acc: 0.303858\n",
      "Epoch: 1000/1000 Train loss: 0.104787 Valid loss: 2.406618 Train acc: 0.961954 Valid acc: 0.303880\n",
      "Epoch: 1000/1000 Test loss: 2.297651 Test acc: 0.420398\n"
     ]
    }
   ],
   "source": [
    "# Train the network\n",
    "# Plotting the acc and loss curve\n",
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # initalize session global variables just in the case they are initialized.\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    \n",
    "    for e in range(epochs):\n",
    "       \n",
    "        # Loop over batches\n",
    "        for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "            \n",
    "            # Feed dictionary\n",
    "            feed = {inputs_:x, labels_:y, keep_prob_:keep_prob, learning_rate_:learning_rate}\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            \n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################################ Validation\n",
    "            # Loop over batches\n",
    "            acc_batch, loss_batch = [], []\n",
    "            for x, y in get_batches(X_valid_norm, Y_train_onehot, batch_size):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_:x, labels_:y, keep_prob_:1.0}\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                \n",
    "                # list of accuracy and loss for validation batch\n",
    "                acc_batch.append(acc)\n",
    "                loss_batch.append(loss)\n",
    "\n",
    "            valid_acc.append(np.mean(acc_batch))\n",
    "            valid_loss.append(np.mean(loss_batch))\n",
    "            \n",
    "        # Print info in every iteration/epochs\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "              \"Train loss: {:6f}\".format(np.mean(train_loss)),\n",
    "              \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "              \"Train acc: {:6f}\".format(np.mean(train_acc)),\n",
    "              \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "        \n",
    "    ################################ Test\n",
    "    # Loop over batches\n",
    "    acc_batch, loss_batch = [], []\n",
    "    for x, y in get_batches(X_test_norm, Y_test_onehot, batch_size):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_:x, labels_:y, keep_prob_:1.0}\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "\n",
    "        # Initialize \n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Print info\n",
    "    print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "          \"Test loss: {:6f}\".format(np.mean(loss_batch)),\n",
    "          \"Test acc: {:6f}\".format(np.mean(acc_batch)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD8CAYAAABn919SAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQoEuIhISCnQRkZBQoIuIhMT/Bwr67UPwU3uGAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ca85d4b70>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='train_loss')\n",
    "mplot.plot(valid_loss, label='valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1ca83b1dd8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_acc, label='train_acc')\n",
    "mplot.plot(valid_acc, label='valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
