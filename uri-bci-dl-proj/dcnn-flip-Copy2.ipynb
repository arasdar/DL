{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18900, 205, 16) float64 (18900, 1) uint8\n",
      "0.833333333333 0.166666666667 0.0 0.0\n",
      "[2]\n"
     ]
    }
   ],
   "source": [
    "# Read the dataset\n",
    "import scipy.io as spio\n",
    "import numpy as np\n",
    "\n",
    "BahramFlip = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/BahramFlipp.mat')\n",
    "DJFlip = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/DJFlipp.mat')\n",
    "NickFlip = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/NickFlipp.mat')\n",
    "RoohiFlip = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/RoohiFlipp.mat')\n",
    "SarahFlip = spio.loadmat(file_name='/home/arasdar/datasets/bci-project-data-RAW/SarahFlipp.mat')\n",
    "\n",
    "AllData = np.concatenate((BahramFlip['Intensification_Data'],\n",
    "                            DJFlip['Intensification_Data'],\n",
    "                            NickFlip['Intensification_Data'],\n",
    "                            RoohiFlip['Intensification_Data'],\n",
    "                            SarahFlip['Intensification_Data']), axis=0)\n",
    "\n",
    "AllLabels = np.concatenate((BahramFlip['Intensification_Label'],\n",
    "                            DJFlip['Intensification_Label'],\n",
    "                            NickFlip['Intensification_Label'],\n",
    "                            RoohiFlip['Intensification_Label'],\n",
    "                            SarahFlip['Intensification_Label']), axis=0)\n",
    "\n",
    "print(AllData.shape, AllData.dtype, AllLabels.shape, AllLabels.dtype)\n",
    "print(np.mean(AllLabels==0), np.mean(AllLabels==1), np.mean(AllLabels==2), np.mean(AllLabels==3))\n",
    "print((AllLabels +  1).max(axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(13230, 205, 16) (5670, 205, 16) (13230, 1) (5670, 1)\n"
     ]
    }
   ],
   "source": [
    "# Train and test split\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "\n",
    "print(X_train_valid.shape, X_test.shape, Y_train_valid.shape, Y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0 0.832501889645 0.167498110355 0.0\n",
      "0.0 0.835273368607 0.164726631393 0.0\n",
      "(5670, 2) float64\n"
     ]
    }
   ],
   "source": [
    "from utilities import *\n",
    "\n",
    "# Normalizing/standardizing the input data features\n",
    "X_train_valid_norm, X_test_norm = standardize(test=X_test, train=X_train_valid)\n",
    "\n",
    "# Onehot encoding/vectorizing the output data labels\n",
    "print(np.mean((Y_train_valid+1).reshape(-1)==0), np.mean((Y_train_valid+1).reshape(-1)==1),\n",
    "     np.mean((Y_train_valid+1).reshape(-1)==2), np.mean((Y_train_valid+1).reshape(-1)==3))\n",
    "\n",
    "print(np.mean((Y_test+1).reshape(-1)==0), np.mean((Y_test+1).reshape(-1)==1),\n",
    "     np.mean((Y_test+1).reshape(-1)==2), np.mean((Y_test+1).reshape(-1)==3))\n",
    "\n",
    "# Y_train_valid_onehot = one_hot(labels=(Y_train_valid+1).reshape(-1), n_class=2) \n",
    "# print(Y_train_valid_onehot.shape, Y_train_valid_onehot.dtype, \n",
    "Y_test_onehot = one_hot(labels=(Y_test+1).reshape(-1), n_class=2) \n",
    "print(Y_test_onehot.shape, Y_test_onehot.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 70% train 30 % valid\n",
    "# get_batches from each train and valid the same\n",
    "# still it will be 70% to 30%\n",
    "# get_batches 83% vs 16%\n",
    "# get_batch 16% vs 16% each time\n",
    "# X_train_valid, X_test, Y_train_valid, Y_test = train_test_split(AllData, AllLabels, test_size=0.30)\n",
    "X_train_norm, X_valid_norm, Y_train, Y_valid = train_test_split(X_train_valid_norm, Y_train_valid, \n",
    "                                                                              test_size=0.30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batches2(X_norm, Y_labels):\n",
    "    # Input train or valid\n",
    "    # This is not-applicable to test\n",
    "    X, Y = X_norm, Y_labels #_onehot\n",
    "    AllLabels = Y_labels # 100%\n",
    "\n",
    "    # non = 0 is 87%  AllLabelZero\n",
    "    # tgt = 1 is 13%  AllLabelOne\n",
    "    AllLabelZero = (AllLabels==0).reshape(-1) # 87%\n",
    "    AllLabelOne = (AllLabels==1).reshape(-1) # 13%\n",
    "\n",
    "    X_non, Y_non = X[AllLabelZero], Y[AllLabelZero] # 87%\n",
    "    X_tgt, Y_tgt = X[AllLabelOne], Y[AllLabelOne] # 13%\n",
    "    #     print('X_non.shape, Y_non.shape', X_non.shape, Y_non.shape)\n",
    "    #     print('X_tgt.shape, Y_tgt.shape', X_tgt.shape, Y_tgt.shape)\n",
    "\n",
    "    # Non-target batch size for get_batches from non-target data\n",
    "    batch_size = X_tgt.shape[0] # 13% -> tgt = 1 is 13%  AllLabelOne\n",
    "    assert X_tgt.shape[0] == Y_tgt.shape[0]\n",
    "    #     print(batch_size)\n",
    "\n",
    "    # # 87% - 13% +1: non - tgt + 1\n",
    "    # n_batches = X_non.shape[0] - tgt_batch_size + 1 # stride=1 \n",
    "    # # max overlap for non-tgt 87% - 13% +1\n",
    "\n",
    "    #     # 87% // 13%: non/ tgt\n",
    "    #     # max overlap for non-tgt 87%// 13%\n",
    "    #     num_non_batches = X_non.shape[0]// tgt_batch_size # stride= tgt_batch_size \n",
    "    # #     print(num_non_batches)\n",
    "    #     # # n_batches = len(X) // batch_size # stride=batch_size # min overlap\n",
    "    #     X_non_, Y_non_ = X_non[:num_non_batches*tgt_batch_size], Y_non[:num_non_batches*tgt_batch_size]\n",
    "\n",
    "    n_batches = X_non.shape[0] // batch_size\n",
    "    X_non, Y_non = X_non[:n_batches*batch_size], Y_non[:n_batches*batch_size]\n",
    "    \n",
    "    #     \"\"\" Return a generator for batches \"\"\"\n",
    "    #     n_batches = len(X) // batch_size\n",
    "    #     X, y = X[:n_batches*batch_size], y[:n_batches*batch_size]\n",
    "\n",
    "    # Loop over target batches: start, stop, step\n",
    "    for i in range(0, X_non.shape[0], batch_size):\n",
    "        #         print(i)\n",
    "        # each_train_valid_batch\n",
    "        each_X_norm = np.concatenate((X_non[i:i+batch_size], X_tgt), axis=0)\n",
    "        each_Y = np.concatenate((Y_non[i:i+batch_size], Y_tgt), axis=0)\n",
    "        each_Y_onehot = one_hot(labels=(each_Y+1).reshape(-1), n_class=2)\n",
    "#         np.random.shuffle(each_X_norm)\n",
    "#         np.random.shuffle(each_Y_onehot)\n",
    "        #         print('each_X_norm.shape, each_Y_onehot.shape', each_X_norm.shape, each_Y_onehot.shape)\n",
    "        #         print('each_X_norm.dtype, each_Y_onehot.dtype', each_X_norm.dtype, each_Y_onehot.dtype)\n",
    "        yield each_X_norm, each_Y_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "seq_len, n_channels 205 16\n",
      "n_classes [2]\n"
     ]
    }
   ],
   "source": [
    "## Hyperparameters\n",
    "# Input data\n",
    "# batch_size = X_train_norm.shape[0]// 100 # minibatch size & number of minibatches\n",
    "seq_len = X_train_norm.shape[1] # Number of steps: each trial length\n",
    "n_channels = X_train_norm.shape[2] # number of channels in each trial\n",
    "# print('batch_size, seq_len, n_channels', batch_size, seq_len, n_channels)\n",
    "print('seq_len, n_channels', seq_len, n_channels)\n",
    "\n",
    "# Output labels\n",
    "n_classes = Y_train_valid.max(axis=0)+1\n",
    "assert Y_train_valid.max(axis=0) == Y_test.max(axis=0)\n",
    "print('n_classes', n_classes)\n",
    "\n",
    "# learning parameters\n",
    "learning_rate = 0.0001 #1e-4\n",
    "epochs = 200 # num iterations for updating model\n",
    "keep_prob = 0.50 # 90% neurons are kept and 10% are dropped out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow Version: 1.3.0\n",
      "Default GPU Device: /gpu:0\n"
     ]
    }
   ],
   "source": [
    "# GPUs or CPU\n",
    "import tensorflow as tf\n",
    "\n",
    "# Check TensorFlow Version\n",
    "print('TensorFlow Version: {}'.format(tf.__version__))\n",
    "\n",
    "# Check for a GPU\n",
    "print('Default GPU Device: {}'.format(tf.test.gpu_device_name()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# Feed the data from python/numpy to tensorflow framework\n",
    "inputs_ = tf.placeholder(tf.float32, [None, seq_len, n_channels], name = 'inputs_')\n",
    "labels_ = tf.placeholder(tf.float32, [None, n_classes], name = 'labels_')\n",
    "keep_prob_ = tf.placeholder(tf.float32, name = 'keep_prob_')\n",
    "learning_rate_ = tf.placeholder(tf.float32, name = 'learning_rate_')\n",
    "print('inputs_.shape, labels_.shape', inputs_.shape, labels_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs_.shape, conv1.shape, max_pool_1.shape (?, 205, 16) (?, 204, 32) (?, 102, 32)\n",
      "max_pool_1.shape, conv2.shape, max_pool_2.shape (?, 102, 32) (?, 102, 64) (?, 51, 64)\n",
      "max_pool_2.shape, conv3.shape, max_pool_3.shape (?, 51, 64) (?, 50, 128) (?, 25, 128)\n",
      "max_pool_3.shape, conv4.shape, max_pool_4.shape (?, 25, 128) (?, 24, 256) (?, 12, 256)\n",
      "max_pool_4.shape, flat.shape, logits.shape (?, 12, 256) (?, 3072) (?, 2)\n"
     ]
    }
   ],
   "source": [
    "# inputs_.shape, labels_.shape (?, 205, 16) (?, 2)\n",
    "# (batch, 205, 16) --> (batch, 102, 32)\n",
    "# conv valid: (205-2+0)/1 + 1 = (203/1)+1 = 203 + 1=204\n",
    "# pool same: (204-2+0)/2 + 1 = (202/2)+1 = 101 + 1=102\n",
    "conv1 = tf.layers.conv1d(inputs=inputs_, filters=32, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_1 = tf.layers.max_pooling1d(inputs=conv1, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_1 = tf.nn.dropout(max_pool_1, keep_prob=keep_prob_)\n",
    "print('inputs_.shape, conv1.shape, max_pool_1.shape', inputs_.shape, conv1.shape, max_pool_1.shape)\n",
    "\n",
    "# (batch, 102, 32) --> (batch, 51, 64)\n",
    "# conv same\n",
    "# pool same: (102-2+0)/2 + 1 = (100/2)+1 = 50 + 1=51\n",
    "conv2 = tf.layers.conv1d(inputs=max_pool_1, filters=64, kernel_size=2, strides=1, padding='same', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_2 = tf.layers.max_pooling1d(inputs=conv2, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_2 = tf.nn.dropout(max_pool_2, keep_prob=keep_prob_)\n",
    "print('max_pool_1.shape, conv2.shape, max_pool_2.shape', max_pool_1.shape, conv2.shape, max_pool_2.shape)\n",
    "\n",
    "# (batch, 51, 64) --> (batch, 25, 128)\n",
    "# conv valid: (51-2+0)/1 + 1 = (49/1)+1 = 49 + 1=50\n",
    "# pool same: (50-2+0)/2 + 1 = (48/2)+1 = 24 + 1=25\n",
    "conv3 = tf.layers.conv1d(inputs=max_pool_2, filters=128, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_3 = tf.layers.max_pooling1d(inputs=conv3, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_3 = tf.nn.dropout(max_pool_3, keep_prob=keep_prob_)\n",
    "print('max_pool_2.shape, conv3.shape, max_pool_3.shape', max_pool_2.shape, conv3.shape, max_pool_3.shape)\n",
    "\n",
    "# (batch, 25, 128) --> (batch, 12, 256)\n",
    "# conv valid: (25-2+0)/1 + 1 = (23/1)+1 = 23 + 1=24\n",
    "# pool same: (24-2+0)/2 + 1 = (22/2)+1 = 11 + 1=12\n",
    "conv4 = tf.layers.conv1d(inputs=max_pool_3, filters=256, kernel_size=2, strides=1, padding='valid', \n",
    "                         activation = tf.nn.relu)\n",
    "max_pool_4 = tf.layers.max_pooling1d(inputs=conv4, pool_size=2, strides=2, padding='same')\n",
    "# max_pool_4 = tf.nn.dropout(max_pool_4, keep_prob=keep_prob_)\n",
    "print('max_pool_3.shape, conv4.shape, max_pool_4.shape', max_pool_3.shape, conv4.shape, max_pool_4.shape)\n",
    "\n",
    "# Flatten and add dropout + predicted output\n",
    "flat = tf.reshape(max_pool_4, (-1, 12*256))\n",
    "flat = tf.nn.dropout(flat, keep_prob=keep_prob_)\n",
    "logits = tf.layers.dense(flat, n_classes)\n",
    "print('max_pool_4.shape, flat.shape, logits.shape', max_pool_4.shape, flat.shape, logits.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost_tensor, cost Tensor(\"Reshape_3:0\", shape=(?,), dtype=float32) Tensor(\"Mean:0\", shape=(), dtype=float32)\n",
      "optimizer name: \"Adam\"\n",
      "op: \"NoOp\"\n",
      "input: \"^Adam/update_conv1d/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_1/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_1/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_2/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_2/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_3/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_conv1d_3/bias/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/kernel/ApplyAdam\"\n",
      "input: \"^Adam/update_dense/bias/ApplyAdam\"\n",
      "input: \"^Adam/Assign\"\n",
      "input: \"^Adam/Assign_1\"\n",
      "\n",
      "correct_pred, accuracy Tensor(\"Equal:0\", shape=(?,), dtype=bool) Tensor(\"accuracy:0\", shape=(), dtype=float32)\n",
      "confusion_matrix Tensor(\"confusion_matrix/SparseTensorDenseAdd:0\", shape=(?, ?), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "# Backward pass: error backpropagation\n",
    "# Cost function\n",
    "cost_tensor = tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=labels_)\n",
    "cost = tf.reduce_mean(input_tensor=cost_tensor)\n",
    "print('cost_tensor, cost', cost_tensor, cost)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate_).minimize(cost)\n",
    "print('optimizer', optimizer)\n",
    "\n",
    "# Accuracy\n",
    "correct_pred = tf.equal(tf.argmax(logits, 1), tf.argmax(labels_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred, tf.float32), name='accuracy')\n",
    "print('correct_pred, accuracy', correct_pred, accuracy)\n",
    "\n",
    "# Confusion matrix\n",
    "confusion_matrix = tf.confusion_matrix(predictions=tf.argmax(logits, 1),\n",
    "                                       labels=tf.argmax(labels_, 1))\n",
    "print('confusion_matrix', confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1/200 Train loss: 0.743418 Valid loss: 0.712558 Train acc: 0.499805 Valid acc: 0.498715\n",
      "Epoch: 2/200 Train loss: 0.730782 Valid loss: 0.707700 Train acc: 0.497883 Valid acc: 0.494934\n",
      "Epoch: 3/200 Train loss: 0.725428 Valid loss: 0.704765 Train acc: 0.501368 Valid acc: 0.494873\n",
      "Epoch: 4/200 Train loss: 0.720960 Valid loss: 0.701527 Train acc: 0.503534 Valid acc: 0.502276\n",
      "Epoch: 5/200 Train loss: 0.716956 Valid loss: 0.699526 Train acc: 0.506984 Valid acc: 0.506924\n",
      "Epoch: 6/200 Train loss: 0.713796 Valid loss: 0.697588 Train acc: 0.510923 Valid acc: 0.513779\n",
      "Epoch: 7/200 Train loss: 0.710674 Valid loss: 0.695739 Train acc: 0.515244 Valid acc: 0.522693\n",
      "Epoch: 8/200 Train loss: 0.708107 Valid loss: 0.694085 Train acc: 0.518795 Valid acc: 0.529235\n",
      "Epoch: 9/200 Train loss: 0.705632 Valid loss: 0.692477 Train acc: 0.522895 Valid acc: 0.537563\n",
      "Epoch: 10/200 Train loss: 0.703196 Valid loss: 0.690918 Train acc: 0.527205 Valid acc: 0.544846\n",
      "Epoch: 11/200 Train loss: 0.700764 Valid loss: 0.689376 Train acc: 0.532052 Valid acc: 0.551495\n",
      "Epoch: 12/200 Train loss: 0.698526 Valid loss: 0.687811 Train acc: 0.536743 Valid acc: 0.558211\n",
      "Epoch: 13/200 Train loss: 0.696133 Valid loss: 0.686210 Train acc: 0.541969 Valid acc: 0.564673\n",
      "Epoch: 14/200 Train loss: 0.693804 Valid loss: 0.684547 Train acc: 0.546882 Valid acc: 0.570728\n",
      "Epoch: 15/200 Train loss: 0.691398 Valid loss: 0.682807 Train acc: 0.551809 Valid acc: 0.576253\n",
      "Epoch: 16/200 Train loss: 0.688921 Valid loss: 0.680979 Train acc: 0.556710 Valid acc: 0.581473\n",
      "Epoch: 17/200 Train loss: 0.686479 Valid loss: 0.679058 Train acc: 0.561207 Valid acc: 0.586344\n",
      "Epoch: 18/200 Train loss: 0.683860 Valid loss: 0.677041 Train acc: 0.566088 Valid acc: 0.591157\n",
      "Epoch: 19/200 Train loss: 0.681134 Valid loss: 0.674919 Train acc: 0.570845 Valid acc: 0.595753\n",
      "Epoch: 20/200 Train loss: 0.678506 Valid loss: 0.672694 Train acc: 0.575182 Valid acc: 0.600009\n",
      "Epoch: 21/200 Train loss: 0.675826 Valid loss: 0.670386 Train acc: 0.579439 Valid acc: 0.603935\n",
      "Epoch: 22/200 Train loss: 0.673088 Valid loss: 0.668022 Train acc: 0.583411 Valid acc: 0.607532\n",
      "Epoch: 23/200 Train loss: 0.670321 Valid loss: 0.665614 Train acc: 0.587424 Valid acc: 0.611034\n",
      "Epoch: 24/200 Train loss: 0.667287 Valid loss: 0.663184 Train acc: 0.591504 Valid acc: 0.614432\n",
      "Epoch: 25/200 Train loss: 0.664472 Valid loss: 0.660753 Train acc: 0.595242 Valid acc: 0.617624\n",
      "Epoch: 26/200 Train loss: 0.661677 Valid loss: 0.658337 Train acc: 0.598730 Valid acc: 0.620749\n",
      "Epoch: 27/200 Train loss: 0.658780 Valid loss: 0.655950 Train acc: 0.602302 Valid acc: 0.623605\n",
      "Epoch: 28/200 Train loss: 0.656018 Valid loss: 0.653607 Train acc: 0.605498 Valid acc: 0.626396\n",
      "Epoch: 29/200 Train loss: 0.653249 Valid loss: 0.651314 Train acc: 0.608754 Valid acc: 0.629142\n",
      "Epoch: 30/200 Train loss: 0.650506 Valid loss: 0.649068 Train acc: 0.611983 Valid acc: 0.631789\n",
      "Epoch: 31/200 Train loss: 0.647854 Valid loss: 0.646870 Train acc: 0.615146 Valid acc: 0.634327\n",
      "Epoch: 32/200 Train loss: 0.645151 Valid loss: 0.644714 Train acc: 0.618206 Valid acc: 0.636776\n",
      "Epoch: 33/200 Train loss: 0.642491 Valid loss: 0.642603 Train acc: 0.621109 Valid acc: 0.639175\n",
      "Epoch: 34/200 Train loss: 0.639875 Valid loss: 0.640546 Train acc: 0.623913 Valid acc: 0.641467\n",
      "Epoch: 35/200 Train loss: 0.637341 Valid loss: 0.638525 Train acc: 0.626669 Valid acc: 0.643568\n",
      "Epoch: 36/200 Train loss: 0.634788 Valid loss: 0.636556 Train acc: 0.629298 Valid acc: 0.645613\n",
      "Epoch: 37/200 Train loss: 0.632287 Valid loss: 0.634639 Train acc: 0.632001 Valid acc: 0.647642\n",
      "Epoch: 38/200 Train loss: 0.629817 Valid loss: 0.632767 Train acc: 0.634665 Valid acc: 0.649562\n",
      "Epoch: 39/200 Train loss: 0.627383 Valid loss: 0.630939 Train acc: 0.637217 Valid acc: 0.651384\n",
      "Epoch: 40/200 Train loss: 0.625053 Valid loss: 0.629152 Train acc: 0.639645 Valid acc: 0.653132\n",
      "Epoch: 41/200 Train loss: 0.622669 Valid loss: 0.627413 Train acc: 0.642073 Valid acc: 0.654858\n",
      "Epoch: 42/200 Train loss: 0.620370 Valid loss: 0.625714 Train acc: 0.644459 Valid acc: 0.656528\n",
      "Epoch: 43/200 Train loss: 0.618089 Valid loss: 0.624053 Train acc: 0.646833 Valid acc: 0.658124\n",
      "Epoch: 44/200 Train loss: 0.615871 Valid loss: 0.622451 Train acc: 0.649082 Valid acc: 0.659644\n",
      "Epoch: 45/200 Train loss: 0.613633 Valid loss: 0.620868 Train acc: 0.651370 Valid acc: 0.661104\n",
      "Epoch: 46/200 Train loss: 0.611434 Valid loss: 0.619326 Train acc: 0.653597 Valid acc: 0.662515\n",
      "Epoch: 47/200 Train loss: 0.609243 Valid loss: 0.617813 Train acc: 0.655721 Valid acc: 0.663918\n",
      "Epoch: 48/200 Train loss: 0.607056 Valid loss: 0.616332 Train acc: 0.657860 Valid acc: 0.665284\n",
      "Epoch: 49/200 Train loss: 0.604936 Valid loss: 0.614887 Train acc: 0.659928 Valid acc: 0.666605\n",
      "Epoch: 50/200 Train loss: 0.602777 Valid loss: 0.613473 Train acc: 0.662000 Valid acc: 0.667854\n",
      "Epoch: 51/200 Train loss: 0.600684 Valid loss: 0.612087 Train acc: 0.664026 Valid acc: 0.669049\n",
      "Epoch: 52/200 Train loss: 0.598651 Valid loss: 0.610736 Train acc: 0.665967 Valid acc: 0.670208\n",
      "Epoch: 53/200 Train loss: 0.596560 Valid loss: 0.609413 Train acc: 0.668039 Valid acc: 0.671346\n",
      "Epoch: 54/200 Train loss: 0.594516 Valid loss: 0.608112 Train acc: 0.669874 Valid acc: 0.672470\n",
      "Epoch: 55/200 Train loss: 0.592489 Valid loss: 0.606836 Train acc: 0.671809 Valid acc: 0.673611\n",
      "Epoch: 56/200 Train loss: 0.590481 Valid loss: 0.605594 Train acc: 0.673674 Valid acc: 0.674746\n",
      "Epoch: 57/200 Train loss: 0.588533 Valid loss: 0.604373 Train acc: 0.675480 Valid acc: 0.675856\n",
      "Epoch: 58/200 Train loss: 0.586605 Valid loss: 0.603181 Train acc: 0.677202 Valid acc: 0.676967\n",
      "Epoch: 59/200 Train loss: 0.584648 Valid loss: 0.601997 Train acc: 0.679029 Valid acc: 0.678018\n",
      "Epoch: 60/200 Train loss: 0.582695 Valid loss: 0.600845 Train acc: 0.680826 Valid acc: 0.679049\n",
      "Epoch: 61/200 Train loss: 0.580798 Valid loss: 0.599728 Train acc: 0.682529 Valid acc: 0.680082\n",
      "Epoch: 62/200 Train loss: 0.578892 Valid loss: 0.598623 Train acc: 0.684231 Valid acc: 0.681096\n",
      "Epoch: 63/200 Train loss: 0.577024 Valid loss: 0.597545 Train acc: 0.685851 Valid acc: 0.682087\n",
      "Epoch: 64/200 Train loss: 0.575125 Valid loss: 0.596480 Train acc: 0.687490 Valid acc: 0.683060\n",
      "Epoch: 65/200 Train loss: 0.573291 Valid loss: 0.595445 Train acc: 0.689034 Valid acc: 0.684026\n",
      "Epoch: 66/200 Train loss: 0.571449 Valid loss: 0.594425 Train acc: 0.690603 Valid acc: 0.684984\n",
      "Epoch: 67/200 Train loss: 0.569647 Valid loss: 0.593438 Train acc: 0.692157 Valid acc: 0.685921\n",
      "Epoch: 68/200 Train loss: 0.567816 Valid loss: 0.592460 Train acc: 0.693749 Valid acc: 0.686849\n",
      "Epoch: 69/200 Train loss: 0.566017 Valid loss: 0.591517 Train acc: 0.695314 Valid acc: 0.687745\n",
      "Epoch: 70/200 Train loss: 0.564223 Valid loss: 0.590587 Train acc: 0.696823 Valid acc: 0.688630\n",
      "Epoch: 71/200 Train loss: 0.562447 Valid loss: 0.589668 Train acc: 0.698323 Valid acc: 0.689490\n",
      "Epoch: 72/200 Train loss: 0.560665 Valid loss: 0.588780 Train acc: 0.699840 Valid acc: 0.690347\n",
      "Epoch: 73/200 Train loss: 0.558904 Valid loss: 0.587896 Train acc: 0.701316 Valid acc: 0.691176\n",
      "Epoch: 74/200 Train loss: 0.557184 Valid loss: 0.587045 Train acc: 0.702754 Valid acc: 0.691989\n",
      "Epoch: 75/200 Train loss: 0.555461 Valid loss: 0.586209 Train acc: 0.704212 Valid acc: 0.692801\n",
      "Epoch: 76/200 Train loss: 0.553754 Valid loss: 0.585382 Train acc: 0.705651 Valid acc: 0.693610\n",
      "Epoch: 77/200 Train loss: 0.552055 Valid loss: 0.584588 Train acc: 0.707060 Valid acc: 0.694380\n",
      "Epoch: 78/200 Train loss: 0.550368 Valid loss: 0.583801 Train acc: 0.708414 Valid acc: 0.695138\n",
      "Epoch: 79/200 Train loss: 0.548676 Valid loss: 0.583039 Train acc: 0.709809 Valid acc: 0.695882\n",
      "Epoch: 80/200 Train loss: 0.546986 Valid loss: 0.582276 Train acc: 0.711164 Valid acc: 0.696629\n",
      "Epoch: 81/200 Train loss: 0.545369 Valid loss: 0.581544 Train acc: 0.712441 Valid acc: 0.697352\n",
      "Epoch: 82/200 Train loss: 0.543715 Valid loss: 0.580819 Train acc: 0.713761 Valid acc: 0.698070\n",
      "Epoch: 83/200 Train loss: 0.542061 Valid loss: 0.580119 Train acc: 0.715090 Valid acc: 0.698764\n",
      "Epoch: 84/200 Train loss: 0.540460 Valid loss: 0.579447 Train acc: 0.716332 Valid acc: 0.699436\n",
      "Epoch: 85/200 Train loss: 0.538825 Valid loss: 0.578770 Train acc: 0.717633 Valid acc: 0.700142\n",
      "Epoch: 86/200 Train loss: 0.537230 Valid loss: 0.578111 Train acc: 0.718893 Valid acc: 0.700839\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87/200 Train loss: 0.535630 Valid loss: 0.577470 Train acc: 0.720160 Valid acc: 0.701507\n",
      "Epoch: 88/200 Train loss: 0.534025 Valid loss: 0.576842 Train acc: 0.721415 Valid acc: 0.702162\n",
      "Epoch: 89/200 Train loss: 0.532403 Valid loss: 0.576235 Train acc: 0.722698 Valid acc: 0.702793\n",
      "Epoch: 90/200 Train loss: 0.530803 Valid loss: 0.575633 Train acc: 0.723902 Valid acc: 0.703421\n",
      "Epoch: 91/200 Train loss: 0.529241 Valid loss: 0.575051 Train acc: 0.725118 Valid acc: 0.704044\n",
      "Epoch: 92/200 Train loss: 0.527651 Valid loss: 0.574483 Train acc: 0.726337 Valid acc: 0.704659\n",
      "Epoch: 93/200 Train loss: 0.526070 Valid loss: 0.573931 Train acc: 0.727562 Valid acc: 0.705272\n",
      "Epoch: 94/200 Train loss: 0.524479 Valid loss: 0.573411 Train acc: 0.728763 Valid acc: 0.705841\n",
      "Epoch: 95/200 Train loss: 0.522924 Valid loss: 0.572881 Train acc: 0.729964 Valid acc: 0.706407\n",
      "Epoch: 96/200 Train loss: 0.521393 Valid loss: 0.572373 Train acc: 0.731122 Valid acc: 0.706953\n",
      "Epoch: 97/200 Train loss: 0.519855 Valid loss: 0.571885 Train acc: 0.732307 Valid acc: 0.707469\n",
      "Epoch: 98/200 Train loss: 0.518315 Valid loss: 0.571400 Train acc: 0.733468 Valid acc: 0.707977\n",
      "Epoch: 99/200 Train loss: 0.516793 Valid loss: 0.570939 Train acc: 0.734603 Valid acc: 0.708452\n",
      "Epoch: 100/200 Train loss: 0.515250 Valid loss: 0.570484 Train acc: 0.735748 Valid acc: 0.708918\n",
      "Epoch: 101/200 Train loss: 0.513720 Valid loss: 0.570036 Train acc: 0.736880 Valid acc: 0.709369\n",
      "Epoch: 102/200 Train loss: 0.512168 Valid loss: 0.569611 Train acc: 0.738029 Valid acc: 0.709801\n",
      "Epoch: 103/200 Train loss: 0.510647 Valid loss: 0.569192 Train acc: 0.739118 Valid acc: 0.710237\n",
      "Epoch: 104/200 Train loss: 0.509138 Valid loss: 0.568809 Train acc: 0.740231 Valid acc: 0.710649\n",
      "Epoch: 105/200 Train loss: 0.507607 Valid loss: 0.568420 Train acc: 0.741364 Valid acc: 0.711075\n",
      "Epoch: 106/200 Train loss: 0.506086 Valid loss: 0.568056 Train acc: 0.742442 Valid acc: 0.711481\n",
      "Epoch: 107/200 Train loss: 0.504587 Valid loss: 0.567701 Train acc: 0.743531 Valid acc: 0.711883\n",
      "Epoch: 108/200 Train loss: 0.503114 Valid loss: 0.567346 Train acc: 0.744607 Valid acc: 0.712285\n",
      "Epoch: 109/200 Train loss: 0.501635 Valid loss: 0.567010 Train acc: 0.745640 Valid acc: 0.712677\n",
      "Epoch: 110/200 Train loss: 0.500135 Valid loss: 0.566687 Train acc: 0.746740 Valid acc: 0.713059\n",
      "Epoch: 111/200 Train loss: 0.498654 Valid loss: 0.566359 Train acc: 0.747810 Valid acc: 0.713442\n",
      "Epoch: 112/200 Train loss: 0.497160 Valid loss: 0.566067 Train acc: 0.748887 Valid acc: 0.713800\n",
      "Epoch: 113/200 Train loss: 0.495691 Valid loss: 0.565791 Train acc: 0.749938 Valid acc: 0.714164\n",
      "Epoch: 114/200 Train loss: 0.494230 Valid loss: 0.565524 Train acc: 0.750975 Valid acc: 0.714513\n",
      "Epoch: 115/200 Train loss: 0.492753 Valid loss: 0.565255 Train acc: 0.751987 Valid acc: 0.714867\n",
      "Epoch: 116/200 Train loss: 0.491332 Valid loss: 0.565007 Train acc: 0.752970 Valid acc: 0.715200\n",
      "Epoch: 117/200 Train loss: 0.489867 Valid loss: 0.564764 Train acc: 0.753995 Valid acc: 0.715535\n",
      "Epoch: 118/200 Train loss: 0.488403 Valid loss: 0.564540 Train acc: 0.754999 Valid acc: 0.715863\n",
      "Epoch: 119/200 Train loss: 0.486934 Valid loss: 0.564323 Train acc: 0.756000 Valid acc: 0.716191\n",
      "Epoch: 120/200 Train loss: 0.485490 Valid loss: 0.564102 Train acc: 0.757001 Valid acc: 0.716517\n",
      "Epoch: 121/200 Train loss: 0.484069 Valid loss: 0.563929 Train acc: 0.757994 Valid acc: 0.716826\n",
      "Epoch: 122/200 Train loss: 0.482646 Valid loss: 0.563729 Train acc: 0.758969 Valid acc: 0.717138\n",
      "Epoch: 123/200 Train loss: 0.481231 Valid loss: 0.563562 Train acc: 0.759934 Valid acc: 0.717437\n",
      "Epoch: 124/200 Train loss: 0.479813 Valid loss: 0.563402 Train acc: 0.760893 Valid acc: 0.717733\n",
      "Epoch: 125/200 Train loss: 0.478417 Valid loss: 0.563234 Train acc: 0.761867 Valid acc: 0.718032\n",
      "Epoch: 126/200 Train loss: 0.477011 Valid loss: 0.563106 Train acc: 0.762829 Valid acc: 0.718318\n",
      "Epoch: 127/200 Train loss: 0.475617 Valid loss: 0.562972 Train acc: 0.763780 Valid acc: 0.718600\n",
      "Epoch: 128/200 Train loss: 0.474237 Valid loss: 0.562874 Train acc: 0.764722 Valid acc: 0.718888\n",
      "Epoch: 129/200 Train loss: 0.472831 Valid loss: 0.562758 Train acc: 0.765676 Valid acc: 0.719163\n",
      "Epoch: 130/200 Train loss: 0.471459 Valid loss: 0.562659 Train acc: 0.766596 Valid acc: 0.719435\n",
      "Epoch: 131/200 Train loss: 0.470077 Valid loss: 0.562579 Train acc: 0.767528 Valid acc: 0.719706\n",
      "Epoch: 132/200 Train loss: 0.468703 Valid loss: 0.562487 Train acc: 0.768457 Valid acc: 0.719965\n",
      "Epoch: 133/200 Train loss: 0.467347 Valid loss: 0.562398 Train acc: 0.769365 Valid acc: 0.720222\n",
      "Epoch: 134/200 Train loss: 0.465993 Valid loss: 0.562370 Train acc: 0.770265 Valid acc: 0.720475\n",
      "Epoch: 135/200 Train loss: 0.464632 Valid loss: 0.562311 Train acc: 0.771184 Valid acc: 0.720725\n",
      "Epoch: 136/200 Train loss: 0.463286 Valid loss: 0.562267 Train acc: 0.772076 Valid acc: 0.720970\n",
      "Epoch: 137/200 Train loss: 0.461937 Valid loss: 0.562239 Train acc: 0.772969 Valid acc: 0.721213\n",
      "Epoch: 138/200 Train loss: 0.460591 Valid loss: 0.562226 Train acc: 0.773851 Valid acc: 0.721443\n",
      "Epoch: 139/200 Train loss: 0.459247 Valid loss: 0.562203 Train acc: 0.774744 Valid acc: 0.721672\n",
      "Epoch: 140/200 Train loss: 0.457907 Valid loss: 0.562186 Train acc: 0.775641 Valid acc: 0.721906\n",
      "Epoch: 141/200 Train loss: 0.456584 Valid loss: 0.562207 Train acc: 0.776509 Valid acc: 0.722128\n",
      "Epoch: 142/200 Train loss: 0.455255 Valid loss: 0.562195 Train acc: 0.777383 Valid acc: 0.722346\n",
      "Epoch: 143/200 Train loss: 0.453933 Valid loss: 0.562220 Train acc: 0.778261 Valid acc: 0.722561\n",
      "Epoch: 144/200 Train loss: 0.452603 Valid loss: 0.562267 Train acc: 0.779135 Valid acc: 0.722774\n",
      "Epoch: 145/200 Train loss: 0.451297 Valid loss: 0.562297 Train acc: 0.779986 Valid acc: 0.722988\n",
      "Epoch: 146/200 Train loss: 0.449974 Valid loss: 0.562352 Train acc: 0.780836 Valid acc: 0.723190\n",
      "Epoch: 147/200 Train loss: 0.448680 Valid loss: 0.562424 Train acc: 0.781665 Valid acc: 0.723387\n",
      "Epoch: 148/200 Train loss: 0.447388 Valid loss: 0.562475 Train acc: 0.782500 Valid acc: 0.723588\n",
      "Epoch: 149/200 Train loss: 0.446081 Valid loss: 0.562552 Train acc: 0.783341 Valid acc: 0.723775\n",
      "Epoch: 150/200 Train loss: 0.444797 Valid loss: 0.562646 Train acc: 0.784175 Valid acc: 0.723956\n",
      "Epoch: 151/200 Train loss: 0.443524 Valid loss: 0.562727 Train acc: 0.784998 Valid acc: 0.724136\n",
      "Epoch: 152/200 Train loss: 0.442249 Valid loss: 0.562828 Train acc: 0.785819 Valid acc: 0.724312\n",
      "Epoch: 153/200 Train loss: 0.440970 Valid loss: 0.562947 Train acc: 0.786629 Valid acc: 0.724489\n",
      "Epoch: 154/200 Train loss: 0.439712 Valid loss: 0.563055 Train acc: 0.787452 Valid acc: 0.724663\n",
      "Epoch: 155/200 Train loss: 0.438428 Valid loss: 0.563173 Train acc: 0.788266 Valid acc: 0.724829\n",
      "Epoch: 156/200 Train loss: 0.437162 Valid loss: 0.563309 Train acc: 0.789065 Valid acc: 0.724983\n",
      "Epoch: 157/200 Train loss: 0.435893 Valid loss: 0.563448 Train acc: 0.789857 Valid acc: 0.725147\n",
      "Epoch: 158/200 Train loss: 0.434623 Valid loss: 0.563596 Train acc: 0.790672 Valid acc: 0.725298\n",
      "Epoch: 159/200 Train loss: 0.433371 Valid loss: 0.563777 Train acc: 0.791467 Valid acc: 0.725442\n",
      "Epoch: 160/200 Train loss: 0.432138 Valid loss: 0.563955 Train acc: 0.792237 Valid acc: 0.725583\n",
      "Epoch: 161/200 Train loss: 0.430903 Valid loss: 0.564115 Train acc: 0.793009 Valid acc: 0.725726\n",
      "Epoch: 162/200 Train loss: 0.429661 Valid loss: 0.564285 Train acc: 0.793796 Valid acc: 0.725869\n",
      "Epoch: 163/200 Train loss: 0.428432 Valid loss: 0.564510 Train acc: 0.794552 Valid acc: 0.725998\n",
      "Epoch: 164/200 Train loss: 0.427201 Valid loss: 0.564700 Train acc: 0.795315 Valid acc: 0.726141\n",
      "Epoch: 165/200 Train loss: 0.425973 Valid loss: 0.564895 Train acc: 0.796069 Valid acc: 0.726282\n",
      "Epoch: 166/200 Train loss: 0.424747 Valid loss: 0.565109 Train acc: 0.796845 Valid acc: 0.726411\n",
      "Epoch: 167/200 Train loss: 0.423535 Valid loss: 0.565349 Train acc: 0.797594 Valid acc: 0.726535\n",
      "Epoch: 168/200 Train loss: 0.422293 Valid loss: 0.565557 Train acc: 0.798366 Valid acc: 0.726665\n",
      "Epoch: 169/200 Train loss: 0.421088 Valid loss: 0.565832 Train acc: 0.799116 Valid acc: 0.726781\n",
      "Epoch: 170/200 Train loss: 0.419891 Valid loss: 0.566077 Train acc: 0.799852 Valid acc: 0.726896\n",
      "Epoch: 171/200 Train loss: 0.418689 Valid loss: 0.566320 Train acc: 0.800597 Valid acc: 0.727011\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 172/200 Train loss: 0.417490 Valid loss: 0.566579 Train acc: 0.801334 Valid acc: 0.727120\n",
      "Epoch: 173/200 Train loss: 0.416298 Valid loss: 0.566838 Train acc: 0.802061 Valid acc: 0.727236\n",
      "Epoch: 174/200 Train loss: 0.415111 Valid loss: 0.567113 Train acc: 0.802788 Valid acc: 0.727352\n",
      "Epoch: 175/200 Train loss: 0.413947 Valid loss: 0.567411 Train acc: 0.803506 Valid acc: 0.727449\n",
      "Epoch: 176/200 Train loss: 0.412766 Valid loss: 0.567714 Train acc: 0.804223 Valid acc: 0.727548\n",
      "Epoch: 177/200 Train loss: 0.411580 Valid loss: 0.568030 Train acc: 0.804951 Valid acc: 0.727635\n",
      "Epoch: 178/200 Train loss: 0.410407 Valid loss: 0.568360 Train acc: 0.805652 Valid acc: 0.727730\n",
      "Epoch: 179/200 Train loss: 0.409229 Valid loss: 0.568680 Train acc: 0.806368 Valid acc: 0.727828\n",
      "Epoch: 180/200 Train loss: 0.408069 Valid loss: 0.568999 Train acc: 0.807068 Valid acc: 0.727922\n",
      "Epoch: 181/200 Train loss: 0.406912 Valid loss: 0.569348 Train acc: 0.807761 Valid acc: 0.728002\n",
      "Epoch: 182/200 Train loss: 0.405772 Valid loss: 0.569664 Train acc: 0.808444 Valid acc: 0.728093\n",
      "Epoch: 183/200 Train loss: 0.404637 Valid loss: 0.570023 Train acc: 0.809123 Valid acc: 0.728180\n",
      "Epoch: 184/200 Train loss: 0.403497 Valid loss: 0.570399 Train acc: 0.809808 Valid acc: 0.728260\n",
      "Epoch: 185/200 Train loss: 0.402353 Valid loss: 0.570770 Train acc: 0.810502 Valid acc: 0.728333\n",
      "Epoch: 186/200 Train loss: 0.401211 Valid loss: 0.571135 Train acc: 0.811178 Valid acc: 0.728413\n",
      "Epoch: 187/200 Train loss: 0.400093 Valid loss: 0.571496 Train acc: 0.811848 Valid acc: 0.728498\n",
      "Epoch: 188/200 Train loss: 0.398962 Valid loss: 0.571880 Train acc: 0.812522 Valid acc: 0.728580\n",
      "Epoch: 189/200 Train loss: 0.397828 Valid loss: 0.572306 Train acc: 0.813208 Valid acc: 0.728644\n",
      "Epoch: 190/200 Train loss: 0.396710 Valid loss: 0.572689 Train acc: 0.813866 Valid acc: 0.728720\n",
      "Epoch: 191/200 Train loss: 0.395581 Valid loss: 0.573073 Train acc: 0.814534 Valid acc: 0.728791\n",
      "Epoch: 192/200 Train loss: 0.394481 Valid loss: 0.573509 Train acc: 0.815176 Valid acc: 0.728854\n",
      "Epoch: 193/200 Train loss: 0.393357 Valid loss: 0.573922 Train acc: 0.815843 Valid acc: 0.728934\n",
      "Epoch: 194/200 Train loss: 0.392252 Valid loss: 0.574349 Train acc: 0.816491 Valid acc: 0.729001\n",
      "Epoch: 195/200 Train loss: 0.391156 Valid loss: 0.574791 Train acc: 0.817133 Valid acc: 0.729056\n",
      "Epoch: 196/200 Train loss: 0.390069 Valid loss: 0.575258 Train acc: 0.817772 Valid acc: 0.729101\n",
      "Epoch: 197/200 Train loss: 0.388970 Valid loss: 0.575706 Train acc: 0.818409 Valid acc: 0.729148\n",
      "Epoch: 198/200 Train loss: 0.387875 Valid loss: 0.576129 Train acc: 0.819043 Valid acc: 0.729200\n",
      "Epoch: 199/200 Train loss: 0.386802 Valid loss: 0.576606 Train acc: 0.819668 Valid acc: 0.729246\n",
      "Epoch: 200/200 Train loss: 0.385736 Valid loss: 0.577084 Train acc: 0.820284 Valid acc: 0.729305\n"
     ]
    }
   ],
   "source": [
    "train_acc, train_loss = [], []\n",
    "valid_acc, valid_loss = [], []\n",
    "\n",
    "# Save the training result or trained and validated model params\n",
    "saver = tf.train.Saver()\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "   \n",
    "    # Loop over epochs\n",
    "    for e in range(epochs):\n",
    "        \n",
    "        # Loop over batches\n",
    "        #         for x, y in get_batches(X_train_norm, Y_train_onehot, batch_size):\n",
    "        for x, y in get_batches2(X_norm=X_train_norm, Y_labels=Y_train):\n",
    "            \n",
    "            ######################## Training\n",
    "            # Feed dictionary\n",
    "            feed = {inputs_ : x, labels_ : y, keep_prob_ : keep_prob, learning_rate_ : learning_rate}\n",
    "            \n",
    "            # Loss\n",
    "            loss, _ , acc = sess.run([cost, optimizer, accuracy], feed_dict = feed)\n",
    "            train_acc.append(acc)\n",
    "            train_loss.append(loss)\n",
    "            \n",
    "            ################## Validation\n",
    "            acc_batch = []\n",
    "            loss_batch = []    \n",
    "            # Loop over batches\n",
    "            #             for x, y in get_batches(X_valid_norm, Y_valid_onehot, batch_size):\n",
    "            for x, y in get_batches2(X_norm=X_valid_norm, Y_labels=Y_valid):\n",
    "\n",
    "                # Feed dictionary\n",
    "                feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "                # Loss\n",
    "                loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "                acc_batch.append(acc)\n",
    "                loss_batch.append(loss)\n",
    "\n",
    "            # Store\n",
    "            valid_acc.append(np.mean(acc_batch))\n",
    "            valid_loss.append(np.mean(loss_batch))\n",
    "            \n",
    "        # Print info for every iter/epoch\n",
    "        print(\"Epoch: {}/{}\".format(e+1, epochs),\n",
    "              \"Train loss: {:6f}\".format(np.mean(train_loss)),\n",
    "              \"Valid loss: {:.6f}\".format(np.mean(valid_loss)),\n",
    "              \"Train acc: {:6f}\".format(np.mean(train_acc)),\n",
    "              \"Valid acc: {:.6f}\".format(np.mean(valid_acc)))\n",
    "                \n",
    "    saver.save(sess,\"checkpoints/dcnn-flip-Copy2.ckpt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nfNVfMARJAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f444c67c320>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as mplot\n",
    "\n",
    "mplot.plot(train_loss, label='Flip train_loss')\n",
    "mplot.plot(valid_loss, label='Flip valid_loss')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4444665c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# import matplotlib.pyplot as mplot\n",
    "mplot.plot(train_acc, label='Flip train_acc')\n",
    "mplot.plot(valid_acc, label='Flip valid_acc')\n",
    "mplot.legend()\n",
    "mplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from checkpoints/dcnn-flip-Copy2.ckpt\n",
      "Test loss: 0.408567 Test acc: 0.834464\n"
     ]
    }
   ],
   "source": [
    "test_acc, test_loss = [], []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    # Restore the validated model\n",
    "    saver.restore(sess, tf.train.latest_checkpoint('checkpoints/'))\n",
    "    \n",
    "    ################## Test\n",
    "    acc_batch = []\n",
    "    loss_batch = []    \n",
    "    # Loop over batches\n",
    "    for x, y in get_batches(batch_size=100, X=X_test_norm, y=Y_test_onehot):\n",
    "\n",
    "        # Feed dictionary\n",
    "        feed = {inputs_ : x, labels_ : y, keep_prob_ : 1.0}\n",
    "\n",
    "        # Loss\n",
    "        loss, acc = sess.run([cost, accuracy], feed_dict = feed)\n",
    "        acc_batch.append(acc)\n",
    "        loss_batch.append(loss)\n",
    "\n",
    "    # Store\n",
    "    test_acc.append(np.mean(acc_batch))\n",
    "    test_loss.append(np.mean(loss_batch))\n",
    "\n",
    "    # Print info for every iter/epoch\n",
    "    print(\"Test loss: {:6f}\".format(np.mean(test_loss)),\n",
    "          \"Test acc: {:.6f}\".format(np.mean(test_acc)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
